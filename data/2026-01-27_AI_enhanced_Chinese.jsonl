{"id": "2601.17551", "categories": ["cs.PF", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17551", "abs": "https://arxiv.org/abs/2601.17551", "authors": ["Thomas Ziller", "Shashikant Ilager", "Alessandro Tundo", "Ezio Bartocci", "Leonardo Mariani", "Ivona Brandic"], "title": "GreenServ: Energy-Efficient Context-Aware Dynamic Routing for Multi-Model LLM Inference", "comment": "Paper under submisison", "summary": "Large language models (LLMs) demonstrate remarkable capabilities, but their broad deployment is limited by significant computational resource demands, particularly energy consumption during inference. Static, one-model-fits-all inference strategies are often inefficient, as they do not exploit the diverse range of available models or adapt to varying query requirements.\n  This paper presents GreenServ, a dynamic, context-aware routing framework that optimizes the trade-off between inference accuracy and energy efficiency. GreenServ extracts lightweight contextual features from each query, including task type, semantic cluster, and text complexity, and routes queries to the most suitable model from a heterogeneous pool, based on observed accuracy and energy usage. We employ a multi-armed bandit approach to learn adaptive routing policies online. This approach operates under partial feedback, eliminates the need for extensive offline calibration, and streamlines the integration of new models into the inference pipeline.\n  We evaluated GreenServ across five benchmark tasks and a pool of 16 contemporary open-access LLMs. Experimental results show that GreenServ consistently outperforms static (single-model) and random baselines. In particular, compared to random routing, GreenServ achieved a 22% increase in accuracy while reducing cumulative energy consumption by 31%. Finally, we evaluated GreenServ with RouterBench, achieving an average accuracy of 71.7% with a peak accuracy of 75.7%. All artifacts are open-source and available as an anonymous repository for review purposes here: https://anonymous.4open.science/r/llm-inference-router-EBEA/README.md", "AI": {"tldr": "GreenServ\u662f\u4e00\u4e2a\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u67e5\u8be2\u7684\u8f7b\u91cf\u7ea7\u7279\u5f81\uff0c\u5c06\u67e5\u8be2\u8def\u7531\u5230\u5f02\u6784\u6a21\u578b\u6c60\u4e2d\u6700\u5408\u9002\u7684\u6a21\u578b\uff0c\u5728\u51c6\u786e\u6027\u548c\u80fd\u6e90\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u529b\u5f3a\u5927\uff0c\u4f46\u5e7f\u6cdb\u90e8\u7f72\u53d7\u5230\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff08\u7279\u522b\u662f\u63a8\u7406\u65f6\u7684\u80fd\u8017\uff09\u7684\u9650\u5236\u3002\u9759\u6001\u7684\u4e00\u5200\u5207\u63a8\u7406\u7b56\u7565\u6548\u7387\u4f4e\u4e0b\uff0c\u65e0\u6cd5\u5229\u7528\u53ef\u7528\u6a21\u578b\u7684\u591a\u6837\u6027\u6216\u9002\u5e94\u4e0d\u540c\u7684\u67e5\u8be2\u9700\u6c42\u3002", "method": "\u4ece\u6bcf\u4e2a\u67e5\u8be2\u4e2d\u63d0\u53d6\u8f7b\u91cf\u7ea7\u4e0a\u4e0b\u6587\u7279\u5f81\uff08\u4efb\u52a1\u7c7b\u578b\u3001\u8bed\u4e49\u805a\u7c7b\u3001\u6587\u672c\u590d\u6742\u5ea6\uff09\uff0c\u57fa\u4e8e\u89c2\u5bdf\u5230\u7684\u51c6\u786e\u6027\u548c\u80fd\u8017\uff0c\u5c06\u67e5\u8be2\u8def\u7531\u5230\u5f02\u6784\u6a21\u578b\u6c60\u4e2d\u6700\u5408\u9002\u7684\u6a21\u578b\u3002\u91c7\u7528\u591a\u81c2\u8001\u864e\u673a\u65b9\u6cd5\u5728\u7ebf\u5b66\u4e60\u81ea\u9002\u5e94\u8def\u7531\u7b56\u7565\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u4efb\u52a1\u548c16\u4e2a\u5f53\u4ee3\u5f00\u6e90LLM\u7684\u6a21\u578b\u6c60\u4e0a\u8bc4\u4f30\uff0cGreenServ\u59cb\u7ec8\u4f18\u4e8e\u9759\u6001\uff08\u5355\u6a21\u578b\uff09\u548c\u968f\u673a\u57fa\u7ebf\u3002\u4e0e\u968f\u673a\u8def\u7531\u76f8\u6bd4\uff0c\u51c6\u786e\u6027\u63d0\u9ad822%\uff0c\u7d2f\u8ba1\u80fd\u8017\u964d\u4f4e31%\u3002\u5728RouterBench\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523071.7%\uff0c\u5cf0\u503c\u8fbe\u523075.7%\u3002", "conclusion": "GreenServ\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u52a8\u6001\u8def\u7531\u6846\u67b6\uff0c\u80fd\u591f\u4f18\u5316LLM\u63a8\u7406\u7684\u51c6\u786e\u6027\u4e0e\u80fd\u8017\u5e73\u8861\uff0c\u652f\u6301\u5728\u7ebf\u5b66\u4e60\u548c\u65b0\u6a21\u578b\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u6240\u6709\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.18400", "categories": ["cs.DC", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.18400", "abs": "https://arxiv.org/abs/2601.18400", "authors": ["Andrei Lebedev", "Vincent Gramoli"], "title": "On the Bandwidth Consumption of Blockchains", "comment": "11 pages, 6 figures", "summary": "With the advent of blockchain technology, the number of proposals has boomed. The network traffic imposed by these blockchain proposals increases the cost of hosting nodes. Unfortunately, as of today, we are not aware of any comparative study of the bandwidth consumption of blockchains.\n  In this paper, we propose the first empirical comparison of blockchain bandwidth consumption. To this end, we measure the network traffic of blockchain network nodes of five blockchain protocols: Algorand, Aptos, Avalanche, Redbelly and Solana. We study the variation over time, differentiate the receiving and sending traffic and analyze how this traffic varies with the number of nodes and validators.\n  We conclude that the transport protocol is the main factor impacting the network traffic, segregating node roles helps reduce traffic and different blockchains are differently impacted by the network size.", "AI": {"tldr": "\u9996\u6b21\u5bf9\u4e94\u79cd\u533a\u5757\u94fe\u534f\u8bae\uff08Algorand\u3001Aptos\u3001Avalanche\u3001Redbelly\u3001Solana\uff09\u7684\u7f51\u7edc\u5e26\u5bbd\u6d88\u8017\u8fdb\u884c\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u53d1\u73b0\u4f20\u8f93\u534f\u8bae\u662f\u5f71\u54cd\u7f51\u7edc\u6d41\u91cf\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "motivation": "\u968f\u7740\u533a\u5757\u94fe\u6280\u672f\u7684\u53d1\u5c55\uff0c\u63d0\u6848\u6570\u91cf\u6fc0\u589e\uff0c\u533a\u5757\u94fe\u63d0\u6848\u5e26\u6765\u7684\u7f51\u7edc\u6d41\u91cf\u589e\u52a0\u4e86\u8282\u70b9\u6258\u7ba1\u6210\u672c\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u533a\u5757\u94fe\u5e26\u5bbd\u6d88\u8017\u7684\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u6d4b\u91cf\u4e94\u79cd\u533a\u5757\u94fe\u534f\u8bae\u7f51\u7edc\u8282\u70b9\u7684\u7f51\u7edc\u6d41\u91cf\uff0c\u7814\u7a76\u968f\u65f6\u95f4\u53d8\u5316\u3001\u6536\u53d1\u6d41\u91cf\u5dee\u5f02\uff0c\u5206\u6790\u6d41\u91cf\u5982\u4f55\u968f\u8282\u70b9\u548c\u9a8c\u8bc1\u8005\u6570\u91cf\u53d8\u5316\u3002", "result": "\u4f20\u8f93\u534f\u8bae\u662f\u5f71\u54cd\u7f51\u7edc\u6d41\u91cf\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u8282\u70b9\u89d2\u8272\u5206\u79bb\u6709\u52a9\u4e8e\u51cf\u5c11\u6d41\u91cf\uff0c\u4e0d\u540c\u533a\u5757\u94fe\u53d7\u7f51\u7edc\u89c4\u6a21\u5f71\u54cd\u7a0b\u5ea6\u4e0d\u540c\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u533a\u5757\u94fe\u5e26\u5bbd\u6d88\u8017\u7684\u5b9e\u8bc1\u6bd4\u8f83\u7814\u7a76\uff0c\u4e3a\u533a\u5757\u94fe\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.17256", "categories": ["cs.ET", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.17256", "abs": "https://arxiv.org/abs/2601.17256", "authors": ["Gabriel Geffen", "Jun Zhao", "Mingfeng Shang", "Shian Wang", "Yao-Jan Wu"], "title": "Safety, Mobility, and Environmental Impacts of Driver-Assistance-Enabled Electric Vehicles: An Empirical Study", "comment": null, "summary": "The advancement of vehicle automation and the growing adoption of electric vehicles (EVs) are reshaping transportation systems. While fully automated vehicles are expected to improve traffic stability, efficiency, and sustainability, recent studies suggest that partially automated vehicles, such as those equipped with adaptive cruise control (ACC), may adversely affect traffic flow. These drawbacks may not extend to ACC-enabled EVs due to their distinct mechanical characteristics, including regenerative braking and smoother torque delivery. As a result, the impacts of EVs operating under ACC remain insufficiently understood.\n  To address this gap, this study develops an empirical framework using the OpenACC dataset to compare ACC-enabled EVs and internal combustion engine vehicles. Dynamic time warping aligns comparable lead-vehicle trajectories. Results show that EVs exhibit smoother speed profiles, lower speed variability, and shorter spacing, leading to higher efficiency. EVs reduce critical safety events by over 85% and lower platoon-level emissions by up to 26.2%.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u914d\u5907\u81ea\u9002\u5e94\u5de1\u822a\u63a7\u5236\uff08ACC\uff09\u7684\u7535\u52a8\u6c7d\u8f66\u4e0e\u5185\u71c3\u673a\u6c7d\u8f66\uff0c\u53d1\u73b0\u7535\u52a8\u6c7d\u8f66\u5728\u4ea4\u901a\u6d41\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5177\u6709\u66f4\u5e73\u6ed1\u7684\u901f\u5ea6\u66f2\u7ebf\u3001\u66f4\u4f4e\u7684\u901f\u5ea6\u53d8\u5f02\u6027\u548c\u66f4\u77ed\u7684\u8f66\u95f4\u8ddd\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u8f66\u8f86\u81ea\u52a8\u5316\u548c\u7535\u52a8\u6c7d\u8f66\u666e\u53ca\uff0c\u4ea4\u901a\u7cfb\u7edf\u6b63\u5728\u91cd\u5851\u3002\u867d\u7136\u5168\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6709\u671b\u6539\u5584\u4ea4\u901a\u7a33\u5b9a\u6027\u3001\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\uff0c\u4f46\u90e8\u5206\u81ea\u52a8\u5316\u8f66\u8f86\uff08\u5982\u914d\u5907ACC\uff09\u53ef\u80fd\u5bf9\u4ea4\u901a\u6d41\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u7531\u4e8e\u7535\u52a8\u6c7d\u8f66\u5177\u6709\u518d\u751f\u5236\u52a8\u548c\u5e73\u6ed1\u626d\u77e9\u8f93\u51fa\u7b49\u72ec\u7279\u673a\u68b0\u7279\u6027\uff0cACC\u5bf9\u7535\u52a8\u6c7d\u8f66\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u3002", "method": "\u4f7f\u7528OpenACC\u6570\u636e\u96c6\u6784\u5efa\u5b9e\u8bc1\u6846\u67b6\uff0c\u6bd4\u8f83ACC\u7535\u52a8\u6c7d\u8f66\u548c\u5185\u71c3\u673a\u6c7d\u8f66\u3002\u91c7\u7528\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u6280\u672f\u5bf9\u9f50\u53ef\u6bd4\u8f83\u7684\u524d\u8f66\u8f68\u8ff9\uff0c\u5206\u6790\u8f66\u8f86\u884c\u4e3a\u5dee\u5f02\u3002", "result": "\u7535\u52a8\u6c7d\u8f66\u8868\u73b0\u51fa\u66f4\u5e73\u6ed1\u7684\u901f\u5ea6\u66f2\u7ebf\u3001\u66f4\u4f4e\u7684\u901f\u5ea6\u53d8\u5f02\u6027\u3001\u66f4\u77ed\u7684\u8f66\u95f4\u8ddd\uff0c\u4ece\u800c\u5e26\u6765\u66f4\u9ad8\u6548\u7387\u3002\u7535\u52a8\u6c7d\u8f66\u5c06\u5173\u952e\u5b89\u5168\u4e8b\u4ef6\u51cf\u5c1185%\u4ee5\u4e0a\uff0c\u8f66\u961f\u7ea7\u6392\u653e\u964d\u4f4e\u9ad8\u8fbe26.2%\u3002", "conclusion": "\u914d\u5907ACC\u7684\u7535\u52a8\u6c7d\u8f66\u76f8\u6bd4\u5185\u71c3\u673a\u6c7d\u8f66\u5728\u4ea4\u901a\u6d41\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u4e0d\u4ec5\u63d0\u5347\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u8fd8\u80fd\u663e\u8457\u964d\u4f4e\u6392\u653e\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u53d1\u5c55\u63d0\u4f9b\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2601.17279", "categories": ["cs.AR", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.17279", "abs": "https://arxiv.org/abs/2601.17279", "authors": ["Sonu Kumar", "Lavanya Vinnakota", "Mukul Lokhande", "Santosh Kumar Vishvakarma", "Adam Teman"], "title": "SPADE: A SIMD Posit-enabled compute engine for Accelerating DNN Efficiency", "comment": null, "summary": "The growing demand for edge-AI systems requires arithmetic units that balance numerical precision, energy efficiency, and compact hardware while supporting diverse formats. Posit arithmetic offers advantages over floating- and fixed-point representations through its tapered precision, wide dynamic range, and improved numerical robustness. This work presents SPADE, a unified multi-precision SIMD Posit-based multiplyaccumulate (MAC) architecture supporting Posit (8,0), Posit (16,1), and Posit (32,2) within a single framework. Unlike prior single-precision or floating/fixed-point SIMD MACs, SPADE introduces a regime-aware, lane-fused SIMD Posit datapath that hierarchically reuses Posit-specific submodules (LOD, complementor, shifter, and multiplier) across 8/16/32-bit precisions without datapath replication. FPGA implementation on a Xilinx Virtex-7 shows 45.13% LUT and 80% slice reduction for Posit (8,0), and up to 28.44% and 17.47% improvement for Posit (16,1) and Posit (32,2) over prior work, with only 6.9% LUT and 14.9% register overhead for multi-precision support. ASIC results across TSMC nodes achieve 1.38 GHz at 6.1 mW (28 nm). Evaluation on MNIST, CIFAR-10/100, and alphabet datasets confirms competitive inference accuracy.", "AI": {"tldr": "SPADE\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u7cbe\u5ea6SIMD Posit MAC\u67b6\u6784\uff0c\u652f\u6301Posit(8,0)\u3001(16,1)\u3001(32,2)\u683c\u5f0f\uff0c\u901a\u8fc7\u5206\u5c42\u590d\u7528\u5b50\u6a21\u5757\u51cf\u5c11\u786c\u4ef6\u5f00\u9500\uff0c\u5728FPGA\u548cASIC\u4e0a\u5b9e\u73b0\u9ad8\u6548\u80fd\u3002", "motivation": "\u8fb9\u7f18AI\u7cfb\u7edf\u9700\u8981\u5e73\u8861\u6570\u503c\u7cbe\u5ea6\u3001\u80fd\u6548\u548c\u786c\u4ef6\u7d27\u51d1\u6027\u7684\u7b97\u672f\u5355\u5143\u3002Posit\u7b97\u672f\u76f8\u6bd4\u6d6e\u70b9\u548c\u5b9a\u70b9\u8868\u793a\u5177\u6709\u9525\u5f62\u7cbe\u5ea6\u3001\u5bbd\u52a8\u6001\u8303\u56f4\u548c\u66f4\u597d\u7684\u6570\u503c\u9c81\u68d2\u6027\u4f18\u52bf\u3002", "method": "\u63d0\u51faSPADE\u67b6\u6784\uff0c\u91c7\u7528\u57fa\u4e8eregime\u611f\u77e5\u7684lane-fused SIMD Posit\u6570\u636e\u901a\u8def\uff0c\u5206\u5c42\u590d\u7528Posit\u7279\u5b9a\u5b50\u6a21\u5757\uff08LOD\u3001\u8865\u7801\u5668\u3001\u79fb\u4f4d\u5668\u3001\u4e58\u6cd5\u5668\uff09\u652f\u63018/16/32\u4f4d\u7cbe\u5ea6\uff0c\u65e0\u9700\u6570\u636e\u901a\u8def\u590d\u5236\u3002", "result": "FPGA\u5b9e\u73b0\u663e\u793a\uff1aPosit(8,0)\u51cf\u5c1145.13% LUT\u548c80% slice\uff1bPosit(16,1)\u548c(32,2)\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u63d0\u534728.44%\u548c17.47%\uff1b\u591a\u7cbe\u5ea6\u652f\u6301\u4ec5\u589e\u52a06.9% LUT\u548c14.9%\u5bc4\u5b58\u5668\u5f00\u9500\u3002ASIC\u572828nm\u8fbe\u52301.38GHz/6.1mW\u3002\u5728MNIST\u3001CIFAR-10/100\u7b49\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u7ade\u4e89\u6027\u63a8\u7406\u7cbe\u5ea6\u3002", "conclusion": "SPADE\u901a\u8fc7\u7edf\u4e00\u7684SIMD Posit MAC\u67b6\u6784\u6709\u6548\u652f\u6301\u591a\u7cbe\u5ea6Posit\u8fd0\u7b97\uff0c\u5728\u786c\u4ef6\u6548\u7387\u548c\u6570\u503c\u7cbe\u5ea6\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18AI\u5e94\u7528\u3002"}}
{"id": "2601.17136", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17136", "abs": "https://arxiv.org/abs/2601.17136", "authors": ["Julian Bellavita", "Matthew Rubino", "Nakul Iyer", "Andrew Chang", "Aditya Devarakonda", "Flavio Vella", "Giulia Guidi"], "title": "Communication-Avoiding Linear Algebraic Kernel K-Means on GPUs", "comment": null, "summary": "Clustering is an important tool in data analysis, with K-means being popular for its simplicity and versatility. However, it cannot handle non-linearly separable clusters. Kernel K-means addresses this limitation but requires a large kernel matrix, making it computationally and memory intensive. Prior work has accelerated Kernel K-means by formulating it using sparse linear algebra primitives and implementing it on a single GPU. However, that approach cannot run on datasets with more than approximately 80,000 samples due to limited GPU memory.\n  In this work, we address this issue by presenting a suite of distributed-memory parallel algorithms for large-scale Kernel K-means clustering on multi-GPU systems. Our approach maps the most computationally expensive components of Kernel K-means onto communication-efficient distributed linear algebra primitives uniquely tailored for Kernel K-means, enabling highly scalable implementations that efficiently cluster million-scale datasets. Central to our work is the design of partitioning schemes that enable communication-efficient composition of the linear algebra primitives that appear in Kernel K-means.\n  Our 1.5D algorithm consistently achieves the highest performance, enabling Kernel K-means to scale to data one to two orders of magnitude larger than previously practical. On 256 GPUs, it achieves a geometric mean weak scaling efficiency of $79.7\\%$ and a geometric mean strong scaling speedup of $4.2\\times$. Compared to our 1D algorithm, the 1.5D approach achieves up to a $3.6\\times$ speedup on 256 GPUs and reduces clustering time from over an hour to under two seconds relative to a single-GPU sliding window implementation. Our results show that distributed algorithms designed with application-specific linear algebraic formulations can achieve substantial performance improvement.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u5f0f\u591aGPU\u5e76\u884c\u7b97\u6cd5\uff0c\u89e3\u51b3\u5927\u89c4\u6a21\u6838K-means\u805a\u7c7b\u5185\u5b58\u9650\u5236\u95ee\u9898\uff0c\u53ef\u5904\u7406\u767e\u4e07\u7ea7\u6570\u636e\u96c6", "motivation": "\u4f20\u7edf\u6838K-means\u9700\u8981\u5b58\u50a8\u5927\u578b\u6838\u77e9\u9635\uff0c\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u5927\uff0c\u5355GPU\u65b9\u6cd5\u53ea\u80fd\u5904\u7406\u7ea68\u4e07\u4e2a\u6837\u672c\uff0c\u65e0\u6cd5\u5904\u7406\u66f4\u5927\u89c4\u6a21\u6570\u636e\u96c6", "method": "\u8bbe\u8ba1\u5206\u5e03\u5f0f\u5185\u5b58\u5e76\u884c\u7b97\u6cd5\uff0c\u5c06\u6838K-means\u8ba1\u7b97\u5bc6\u96c6\u90e8\u5206\u6620\u5c04\u5230\u901a\u4fe1\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u7ebf\u6027\u4ee3\u6570\u539f\u8bed\uff0c\u91c7\u75281.5D\u5206\u533a\u65b9\u6848\u4f18\u5316\u901a\u4fe1\u6548\u7387", "result": "1.5D\u7b97\u6cd5\u6027\u80fd\u6700\u4f18\uff0c\u53ef\u5c06\u6838K-means\u6269\u5c55\u5230\u6bd4\u4ee5\u5f80\u59271-2\u4e2a\u6570\u91cf\u7ea7\u7684\u6570\u636e\u96c6\uff0c\u5728256\u4e2aGPU\u4e0a\u5b9e\u73b079.7%\u7684\u5f31\u6269\u5c55\u6548\u7387\u548c4.2\u500d\u7684\u5f3a\u6269\u5c55\u52a0\u901f\u6bd4", "conclusion": "\u9488\u5bf9\u7279\u5b9a\u5e94\u7528\u8bbe\u8ba1\u7684\u5206\u5e03\u5f0f\u7ebf\u6027\u4ee3\u6570\u7b97\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f7f\u5927\u89c4\u6a21\u6838K-means\u805a\u7c7b\u53d8\u5f97\u5b9e\u7528"}}
{"id": "2601.16984", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.16984", "abs": "https://arxiv.org/abs/2601.16984", "authors": ["Rahul Ghosh", "Chun-Hao Liu", "Gaurav Rele", "Vidya Sagar Ravipati", "Hazar Aouad"], "title": "TelcoAI: Advancing 3GPP Technical Specification Search through Agentic Multi-Modal Retrieval-Augmented Generation", "comment": "Accepted to IJCNLP-AACL 2025", "summary": "The 3rd Generation Partnership Project (3GPP) produces complex technical specifications essential to global telecommunications, yet their hierarchical structure, dense formatting, and multi-modal content make them difficult to process. While Large Language Models (LLMs) show promise, existing approaches fall short in handling complex queries, visual information, and document interdependencies. We present TelcoAI, an agentic, multi-modal Retrieval-Augmented Generation (RAG) system tailored for 3GPP documentation. TelcoAI introduces section-aware chunking, structured query planning, metadata-guided retrieval, and multi-modal fusion of text and diagrams. Evaluated on multiple benchmarks-including expert-curated queries-our system achieves $87\\%$ recall, $83\\%$ claim recall, and $92\\%$ faithfulness, representing a $16\\%$ improvement over state-of-the-art baselines. These results demonstrate the effectiveness of agentic and multi-modal reasoning in technical document understanding, advancing practical solutions for real-world telecommunications research and engineering.", "AI": {"tldr": "TelcoAI\uff1a\u9488\u5bf93GPP\u6280\u672f\u89c4\u8303\u7684\u667a\u80fd\u591a\u6a21\u6001RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ee3\u7406\u5f0f\u63a8\u7406\u548c\u591a\u6a21\u6001\u878d\u5408\u663e\u8457\u63d0\u5347\u6280\u672f\u6587\u6863\u7406\u89e3\u80fd\u529b", "motivation": "3GPP\u6280\u672f\u89c4\u8303\u7ed3\u6784\u590d\u6742\u3001\u683c\u5f0f\u5bc6\u96c6\u4e14\u5305\u542b\u591a\u6a21\u6001\u5185\u5bb9\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u590d\u6742\u67e5\u8be2\u3001\u89c6\u89c9\u4fe1\u606f\u548c\u6587\u6863\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1\u4e86TelcoAI\u7cfb\u7edf\uff0c\u91c7\u7528\u57fa\u4e8e\u7ae0\u8282\u611f\u77e5\u7684\u5206\u5757\u3001\u7ed3\u6784\u5316\u67e5\u8be2\u89c4\u5212\u3001\u5143\u6570\u636e\u5f15\u5bfc\u68c0\u7d22\u4ee5\u53ca\u6587\u672c\u4e0e\u56fe\u8868\u7684\u591a\u6a21\u6001\u878d\u5408\u6280\u672f", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523087%\u53ec\u56de\u7387\u300183%\u58f0\u660e\u53ec\u56de\u7387\u548c92%\u5fe0\u5b9e\u5ea6\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u534716%", "conclusion": "\u4ee3\u7406\u5f0f\u548c\u591a\u6a21\u6001\u63a8\u7406\u5728\u6280\u672f\u6587\u6863\u7406\u89e3\u4e2d\u6548\u679c\u663e\u8457\uff0c\u4e3a\u7535\u4fe1\u7814\u7a76\u548c\u5de5\u7a0b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18015", "categories": ["cs.ET", "cs.CC", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.18015", "abs": "https://arxiv.org/abs/2601.18015", "authors": ["Hyun-Gee Jei", "Mustafa Demir", "Farzan Sasangohar"], "title": "Eyes on the Mission: Mixed Methods Assessment of Eye-Tracker-Enabled Interactive Decision Support in a Simulated Unmanned Aerial Vehicle System", "comment": "27 pages, 6 figures, 4 tables, under review", "summary": "Supervisors in military command and control (C2) environments face dynamic conditions. Dynamically changing information continuously flows to the supervisors through multiple displays. In this environment, important pieces of information can be overlooked due to the complexity of tasks and environments. This study examined the efficacy of an eye-tracker-based adaptive attention-guided decision support tool (DST) for supervisors in a simulated C2 environment. The DST monitors supervisors' visual attention allocation in real time and displays visually salient cues if critical changes or events are missed. Twenty-five military students participated in a simulated intelligence task. Results indicated significant performance enhancement when the adaptive DST was present. Eye-tracking analysis also showed that longer, more frequent fixations on critical areas of interest were negatively correlated with performance. Additionally, post-experiment interviews revealed that the adaptive DST was unobtrusive and positively received. These findings underscore the potential of real-time gaze-based interventions to optimize supervisory decision-making. Future research could incorporate AI-driven approaches to better support supervisors in complex task environments.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u773c\u52a8\u8ffd\u8e2a\u7684\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u5f15\u5bfc\u51b3\u7b56\u652f\u6301\u5de5\u5177\u5728\u6a21\u62df\u519b\u4e8b\u6307\u6325\u63a7\u5236\u73af\u5883\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u8be5\u5de5\u5177\u80fd\u663e\u8457\u63d0\u5347\u76d1\u7763\u8005\u7ee9\u6548\u4e14\u4e0d\u5e72\u6270\u5de5\u4f5c\u3002", "motivation": "\u519b\u4e8b\u6307\u6325\u63a7\u5236\u73af\u5883\u4e2d\uff0c\u76d1\u7763\u8005\u9762\u4e34\u52a8\u6001\u53d8\u5316\u7684\u4fe1\u606f\u6d41\u548c\u590d\u6742\u4efb\u52a1\uff0c\u5bb9\u6613\u9057\u6f0f\u5173\u952e\u4fe1\u606f\uff0c\u9700\u8981\u6709\u6548\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u6765\u8f85\u52a9\u6ce8\u610f\u529b\u5206\u914d\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u773c\u52a8\u8ffd\u8e2a\u7684\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u5f15\u5bfc\u51b3\u7b56\u652f\u6301\u5de5\u5177\uff0c\u5b9e\u65f6\u76d1\u6d4b\u76d1\u7763\u8005\u89c6\u89c9\u6ce8\u610f\u529b\u5206\u914d\uff0c\u5f53\u9057\u6f0f\u5173\u952e\u53d8\u5316\u6216\u4e8b\u4ef6\u65f6\u663e\u793a\u89c6\u89c9\u663e\u8457\u63d0\u793a\u3002\u5728\u6a21\u62df\u60c5\u62a5\u4efb\u52a1\u4e2d\uff0c25\u540d\u519b\u4e8b\u5b66\u5458\u53c2\u4e0e\u5b9e\u9a8c\uff0c\u7ed3\u5408\u773c\u52a8\u8ffd\u8e2a\u5206\u6790\u548c\u4e8b\u540e\u8bbf\u8c08\u8bc4\u4f30\u5de5\u5177\u6548\u679c\u3002", "result": "\u81ea\u9002\u5e94\u51b3\u7b56\u652f\u6301\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86\u76d1\u7763\u8005\u7ee9\u6548\uff1b\u773c\u52a8\u5206\u6790\u663e\u793a\u5bf9\u5173\u952e\u5174\u8da3\u533a\u7684\u66f4\u957f\u3001\u66f4\u9891\u7e41\u6ce8\u89c6\u4e0e\u7ee9\u6548\u8d1f\u76f8\u5173\uff1b\u8bbf\u8c08\u8868\u660e\u8be5\u5de5\u5177\u4e0d\u5177\u5e72\u6270\u6027\u4e14\u53d7\u5230\u79ef\u6781\u8bc4\u4ef7\u3002", "conclusion": "\u5b9e\u65f6\u57fa\u4e8e\u6ce8\u89c6\u7684\u5e72\u9884\u63aa\u65bd\u6709\u6f5c\u529b\u4f18\u5316\u76d1\u7763\u51b3\u7b56\uff0c\u672a\u6765\u7814\u7a76\u53ef\u7ed3\u5408AI\u9a71\u52a8\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u73af\u5883\u4e2d\u66f4\u597d\u5730\u652f\u6301\u76d1\u7763\u8005\u3002"}}
{"id": "2601.17615", "categories": ["cs.AR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17615", "abs": "https://arxiv.org/abs/2601.17615", "authors": ["Rahul Bera", "Zhenrong Lang", "Caroline Hengartner", "Konstantinos Kanellopoulos", "Rakesh Kumar", "Mohammad Sadrosadati", "Onur Mutlu"], "title": "Athena: Synergizing Data Prefetching and Off-Chip Prediction via Online Reinforcement Learning", "comment": null, "summary": "Prefetching and off-chip prediction are two techniques proposed to hide long memory access latencies in high-performance processors. In this work, we demonstrate that: (1) prefetching and off-chip prediction often provide complementary performance benefits, yet (2) naively combining them often fails to realize their full performance potential, and (3) existing prefetcher control policies leave significant room for performance improvement behind.\n  Our goal is to design a holistic framework that can autonomously learn to coordinate an off-chip predictor with multiple prefetchers employed at various cache levels. To this end, we propose a new technique called Athena, which models the coordination between prefetchers and off-chip predictor (OCP) as a reinforcement learning (RL) problem. Athena acts as the RL agent that observes multiple system-level features (e.g., prefetcher/OCP accuracy, bandwidth usage) over an epoch of program execution, and uses them as state information to select a coordination action (i.e., enabling the prefetcher and/or OCP, and adjusting prefetcher aggressiveness). At the end of every epoch, Athena receives a numerical reward that measures the change in multiple system-level metrics (e.g., number of cycles taken to execute an epoch). Athena uses this reward to autonomously and continuously learn a policy to coordinate prefetchers with OCP.\n  Our extensive evaluation using a diverse set of memory-intensive workloads shows that Athena consistently outperforms prior state-of-the-art coordination policies across a wide range of system configurations with various combinations of underlying prefetchers, OCPs, and main memory bandwidths, while incurring only modest storage overhead. Athena is freely available at https://github.com/CMU-SAFARI/Athena.", "AI": {"tldr": "Athena\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u8c03\u591a\u7ea7\u7f13\u5b58\u9884\u53d6\u5668\u548c\u7247\u5916\u9884\u6d4b\u5668\uff0c\u4ee5\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u73b0\u6709\u534f\u8c03\u7b56\u7565\u5728\u5404\u79cd\u914d\u7f6e\u4e0b\u90fd\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u9884\u53d6\u548c\u7247\u5916\u9884\u6d4b\u662f\u9690\u85cf\u5185\u5b58\u8bbf\u95ee\u5ef6\u8fdf\u7684\u4e24\u79cd\u6280\u672f\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u63d0\u4f9b\u4e92\u8865\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u7b80\u5355\u7ec4\u5408\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u6f5c\u529b\uff0c\u73b0\u6709\u9884\u53d6\u5668\u63a7\u5236\u7b56\u7565\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51faAthena\u6846\u67b6\uff0c\u5c06\u9884\u53d6\u5668\u548c\u7247\u5916\u9884\u6d4b\u5668\u7684\u534f\u8c03\u5efa\u6a21\u4e3a\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u3002Athena\u4f5c\u4e3aRL\u4ee3\u7406\uff0c\u89c2\u5bdf\u7cfb\u7edf\u7ea7\u7279\u5f81\uff08\u5982\u51c6\u786e\u6027\u3001\u5e26\u5bbd\u4f7f\u7528\uff09\uff0c\u9009\u62e9\u534f\u8c03\u52a8\u4f5c\uff08\u542f\u7528/\u7981\u7528\u9884\u53d6\u5668\u548cOCP\uff0c\u8c03\u6574\u9884\u53d6\u5668\u6fc0\u8fdb\u7a0b\u5ea6\uff09\uff0c\u5e76\u6839\u636e\u6267\u884c\u5468\u671f\u7684\u53d8\u5316\u7b49\u6307\u6807\u83b7\u5f97\u5956\u52b1\uff0c\u6301\u7eed\u5b66\u4e60\u534f\u8c03\u7b56\u7565\u3002", "result": "\u5728\u591a\u79cd\u5185\u5b58\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cAthena\u5728\u5404\u79cd\u7cfb\u7edf\u914d\u7f6e\uff08\u4e0d\u540c\u9884\u53d6\u5668\u3001OCP\u548c\u4e3b\u5185\u5b58\u5e26\u5bbd\u7ec4\u5408\uff09\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u534f\u8c03\u7b56\u7565\uff0c\u540c\u65f6\u53ea\u4ea7\u751f\u9002\u5ea6\u7684\u5b58\u50a8\u5f00\u9500\u3002", "conclusion": "Athena\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u548c\u534f\u8c03\u591a\u7ea7\u7f13\u5b58\u9884\u53d6\u5668\u4e0e\u7247\u5916\u9884\u6d4b\u5668\uff0c\u663e\u8457\u63d0\u5347\u5904\u7406\u5668\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90\u3002"}}
{"id": "2601.17546", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.17546", "abs": "https://arxiv.org/abs/2601.17546", "authors": ["Ravi Kiran Kodali", "Vinoth Punniyamoorthy", "Akash Kumar Agarwal", "Bikesh Kumar", "Balakrishna Pothineni", "Aswathnarayan Muthukrishnan Kirubakaran", "Sumit Saha", "Nachiappan Chockalingam"], "title": "Push Down Optimization for Distributed Multi Cloud Data Integration", "comment": null, "summary": "Enterprises increasingly adopt multi cloud architectures to take advantage of diverse database engines, regional availability, and cost models. In these environments, ETL pipelines must process large, distributed datasets while minimizing latency and transfer cost. Push down optimization, which executes transformation logic within database engines rather than within the ETL tool, has proven highly effective in single cloud systems. However, when applied across multiple clouds, it faces challenges related to data movement, heterogeneous SQL engines, orchestration complexity, and fragmented security controls. This paper examines the feasibility of push down optimization in multi cloud ETL pipelines and analyzes its benefits and limitations. It evaluates localized push down, hybrid models, and data federation techniques that reduce cross cloud traffic while improving performance. A case study across Redshift and BigQuery demonstrates measurable gains, including lower end to end runtime, reduced transfer volume, and improved cost efficiency. The study highlights practical strategies that organizations can adopt to improve ETL scalability and reliability in distributed cloud environments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u591a\u4e91\u73af\u5883\u4e2dETL\u7ba1\u9053\u4e0b\u63a8\u4f18\u5316\u7684\u53ef\u884c\u6027\u4e0e\u7b56\u7565\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5728Redshift\u548cBigQuery\u4e0a\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u548c\u6210\u672c\u964d\u4f4e\u7684\u6548\u679c\u3002", "motivation": "\u4f01\u4e1a\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u591a\u4e91\u67b6\u6784\u4ee5\u5229\u7528\u4e0d\u540c\u6570\u636e\u5e93\u5f15\u64ce\u3001\u533a\u57df\u53ef\u7528\u6027\u548c\u6210\u672c\u6a21\u578b\u3002\u5728\u8fd9\u4e9b\u73af\u5883\u4e2d\uff0cETL\u7ba1\u9053\u9700\u8981\u5904\u7406\u5927\u91cf\u5206\u5e03\u5f0f\u6570\u636e\u96c6\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5ef6\u8fdf\u548c\u4f20\u8f93\u6210\u672c\u3002\u4e0b\u63a8\u4f18\u5316\u5728\u5355\u4e91\u7cfb\u7edf\u4e2d\u5df2\u88ab\u8bc1\u660e\u975e\u5e38\u6709\u6548\uff0c\u4f46\u5728\u591a\u4e91\u73af\u5883\u4e2d\u9762\u4e34\u6570\u636e\u79fb\u52a8\u3001\u5f02\u6784SQL\u5f15\u64ce\u3001\u7f16\u6392\u590d\u6742\u6027\u548c\u788e\u7247\u5316\u5b89\u5168\u63a7\u5236\u7b49\u6311\u6218\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u4e91ETL\u7ba1\u9053\u4e2d\u4e0b\u63a8\u4f18\u5316\u7684\u53ef\u884c\u6027\uff0c\u5206\u6790\u4e86\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002\u8bc4\u4f30\u4e86\u672c\u5730\u5316\u4e0b\u63a8\u3001\u6df7\u5408\u6a21\u578b\u548c\u6570\u636e\u8054\u90a6\u6280\u672f\uff0c\u8fd9\u4e9b\u6280\u672f\u53ef\u4ee5\u51cf\u5c11\u8de8\u4e91\u6d41\u91cf\u540c\u65f6\u63d0\u9ad8\u6027\u80fd\u3002\u901a\u8fc7Redshift\u548cBigQuery\u7684\u6848\u4f8b\u7814\u7a76\u6765\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\u4e86\u53ef\u8861\u91cf\u7684\u6536\u76ca\uff0c\u5305\u62ec\u964d\u4f4e\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u3001\u51cf\u5c11\u4f20\u8f93\u91cf\u4ee5\u53ca\u63d0\u9ad8\u6210\u672c\u6548\u7387\u3002\u7814\u7a76\u7a81\u51fa\u4e86\u7ec4\u7ec7\u53ef\u4ee5\u5728\u5206\u5e03\u5f0f\u4e91\u73af\u5883\u4e2d\u91c7\u7528\u7684\u5b9e\u9645\u7b56\u7565\uff0c\u4ee5\u6539\u5584ETL\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u591a\u4e91\u73af\u5883\u4e2d\u7684\u4e0b\u63a8\u4f18\u5316\u867d\u7136\u9762\u4e34\u6311\u6218\uff0c\u4f46\u901a\u8fc7\u9002\u5f53\u7684\u7b56\u7565\uff08\u5982\u672c\u5730\u5316\u4e0b\u63a8\u3001\u6df7\u5408\u6a21\u578b\u548c\u6570\u636e\u8054\u90a6\u6280\u672f\uff09\u53ef\u4ee5\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u6210\u672c\u8282\u7ea6\u3002\u7ec4\u7ec7\u53ef\u4ee5\u91c7\u7528\u8fd9\u4e9b\u7b56\u7565\u6765\u6539\u5584\u5206\u5e03\u5f0f\u4e91\u73af\u5883\u4e2dETL\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2601.16991", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16991", "abs": "https://arxiv.org/abs/2601.16991", "authors": ["Longteng Zhang", "Sen Wu", "Shuai Hou", "Zhengyu Qing", "Zhuo Zheng", "Danning Ke", "Qihong Lin", "Qiang Wang", "Shaohuai Shi", "Xiaowen Chu"], "title": "Sparsity-Aware Low-Rank Representation for Efficient Fine-Tuning of Large Language Models", "comment": null, "summary": "Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\\times$, and delivers up to a $1.7\\times$ inference speedup.", "AI": {"tldr": "SALR\u662f\u4e00\u79cd\u7ed3\u5408\u4f4e\u79e9\u9002\u5e94\u4e0e\u7a00\u758f\u526a\u679d\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u9759\u6001\u526a\u679d\u51bb\u7ed3\u6743\u91cd\u5e76\u5229\u7528\u622a\u65adSVD\u4f4e\u79e9\u9002\u914d\u5668\u6062\u590d\u4fe1\u606f\uff0c\u5b9e\u73b050%\u7a00\u758f\u5ea6\u30012\u500d\u6a21\u578b\u538b\u7f29\u548c1.7\u500d\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u5927\u578b\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u9700\u8981\u8c03\u6574\u6570\u767e\u4e07\u53c2\u6570\u6216\u90e8\u7f72\u6602\u8d35\u7684\u5bc6\u96c6\u6743\u91cd\u66f4\u65b0\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u96be\u4ee5\u4f7f\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u5982LoRA\u867d\u7136\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u4f46\u5e95\u5c42\u5bc6\u96c6\u6743\u91cd\u4ecd\u5e26\u6765\u9ad8\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51faSALR\uff08\u7a00\u758f\u611f\u77e5\u4f4e\u79e9\u8868\u793a\uff09\u65b9\u6cd5\uff1a1\uff09\u9759\u6001\u526a\u679d\u51bb\u7ed3\u7684\u57fa\u7840\u6743\u91cd\u4ee5\u6700\u5c0f\u5316\u526a\u679d\u8bef\u5dee\u754c\uff1b2\uff09\u4f7f\u7528\u622a\u65adSVD\u4f4e\u79e9\u9002\u914d\u5668\u6062\u590d\u88ab\u4e22\u5f03\u7684\u6b8b\u5dee\u4fe1\u606f\uff1b3\uff09\u878d\u5408\u591a\u4e2a\u4f4e\u79e9\u9002\u914d\u5668\u4e3a\u5355\u4e2a\u62fc\u63a5GEMM\uff1b4\uff09\u91c7\u7528\u57fa\u4e8e\u4f4d\u56fe\u7684\u7f16\u7801\u548c\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\u89e3\u7801+GEMM\u8bbe\u8ba1\u3002", "result": "\u5728\u5404\u79cdLLM\u4e0a\u5b9e\u73b050%\u7a00\u758f\u5ea6\uff0c\u5728GSM8K\u548cMMLU\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0eLoRA\u76f8\u5f53\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c112\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u6700\u9ad8\u8fbe1.7\u500d\u3002", "conclusion": "SALR\u6210\u529f\u7edf\u4e00\u4e86\u4f4e\u79e9\u9002\u5e94\u4e0e\u7a00\u758f\u526a\u679d\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6a21\u578b\u538b\u7f29\u548c\u63a8\u7406\u52a0\u901f\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5927\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18435", "categories": ["cs.ET", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.18435", "abs": "https://arxiv.org/abs/2601.18435", "authors": ["Biraja Ghoshal"], "title": "The Quantum Cliff: A Critical Proton Tunneling Threshold Determines Clinical Severity in RPE65-Mediated Retinal Disease", "comment": null, "summary": "Predicting clinical severity from genotype remains a fundamental challenge in molecular medicine, particularly for enzymes whose function depends on sub-atomic-scale geometry. Mutations in the \\textit{RPE65} isomerohydrolase cause Leber Congenital Amaurosis (LCA) and related retinal diseases; however, the kinetic mechanisms connecting sub-atomic-scale perturbations to blindness remain unclear. In this study, we demonstrate that mutations in the human visual isomerase RPE65 are governed by a quantum-mechanical threshold effect arising from proton tunneling in the active site. We established a hybrid quantum-classical structure-to-phenotype pipeline combining AlphaFold structure prediction with \\textit{ab initio} quantum simulation using the Variational Quantum Eigensolver (VQE) to analyze minimal proton-coupled electron transfer in the visual cycle. Our analysis reveals that many pathogenic mutations do not merely occlude the active site, but rather strongly reduce the quantum probability of proton tunneling. We observed a sharp non-linear effect, termed the \"Quantum Cliff,\" where minute structural changes (below 0.1 \u00c5) reduce the reaction rate by multiple orders of magnitude. Based on these findings, we introduce a dimensionless Relative Quantum Activity Score (RQAS) that isolates the geometry-controlled exponential sensitivity of the reaction rate and successfully distinguishes between mild and severe patient phenotypes. These results suggest that RPE65 operates near a quantum-critical point, where sub-Angstrom structural perturbations induce a catastrophic loss of function. Furthermore, our findings establish quantum tunneling as a predictive mechanistic link between atomic structure and clinical phenotype, proposing a general framework for quantum-structural disease modeling.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86RPE65\u9176\u81f4\u75c5\u7a81\u53d8\u901a\u8fc7\u91cf\u5b50\u96a7\u7a7f\u9608\u503c\u6548\u5e94\u5bfc\u81f4\u529f\u80fd\u4e27\u5931\u7684\u673a\u5236\uff0c\u5efa\u7acb\u4e86\u91cf\u5b50\u529b\u5b66\u4e0e\u4e34\u5e8a\u8868\u578b\u4e4b\u95f4\u7684\u9884\u6d4b\u6027\u8054\u7cfb\u3002", "motivation": "\u4ece\u57fa\u56e0\u578b\u9884\u6d4b\u4e34\u5e8a\u4e25\u91cd\u7a0b\u5ea6\u662f\u5206\u5b50\u533b\u5b66\u7684\u57fa\u672c\u6311\u6218\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u529f\u80fd\u4f9d\u8d56\u4e8e\u4e9a\u539f\u5b50\u5c3a\u5ea6\u51e0\u4f55\u7ed3\u6784\u7684\u9176\u3002RPE65\u7a81\u53d8\u5bfc\u81f4Leber\u5148\u5929\u6027\u9ed1\u8499\u7b49\u89c6\u7f51\u819c\u75be\u75c5\uff0c\u4f46\u4e9a\u539f\u5b50\u5c3a\u5ea6\u6270\u52a8\u5bfc\u81f4\u5931\u660e\u7684\u52a8\u529b\u5b66\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5efa\u7acb\u4e86\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7ed3\u6784\u5230\u8868\u578b\u5206\u6790\u6d41\u7a0b\uff0c\u7ed3\u5408AlphaFold\u7ed3\u6784\u9884\u6d4b\u548c\u53d8\u5206\u91cf\u5b50\u672c\u5f81\u6c42\u89e3\u5668(VQE)\u8fdb\u884c\u4ece\u5934\u7b97\u91cf\u5b50\u6a21\u62df\uff0c\u5206\u6790\u89c6\u89c9\u5faa\u73af\u4e2d\u7684\u6700\u5c0f\u8d28\u5b50\u8026\u5408\u7535\u5b50\u8f6c\u79fb\u3002", "result": "\u53d1\u73b0\u8bb8\u591a\u81f4\u75c5\u7a81\u53d8\u5e76\u975e\u7b80\u5355\u963b\u585e\u6d3b\u6027\u4f4d\u70b9\uff0c\u800c\u662f\u663e\u8457\u964d\u4f4e\u8d28\u5b50\u96a7\u7a7f\u7684\u91cf\u5b50\u6982\u7387\u3002\u89c2\u5bdf\u5230\"\u91cf\u5b50\u60ac\u5d16\"\u6548\u5e94\u2014\u2014\u5fae\u5c0f\u7ed3\u6784\u53d8\u5316\uff08<0.1\u00c5\uff09\u4f7f\u53cd\u5e94\u901f\u7387\u964d\u4f4e\u591a\u4e2a\u6570\u91cf\u7ea7\u3002\u5efa\u7acb\u4e86\u76f8\u5bf9\u91cf\u5b50\u6d3b\u6027\u8bc4\u5206(RQAS)\uff0c\u6210\u529f\u533a\u5206\u8f7b\u5ea6\u548c\u91cd\u5ea6\u60a3\u8005\u8868\u578b\u3002", "conclusion": "RPE65\u5728\u91cf\u5b50\u4e34\u754c\u70b9\u9644\u8fd1\u8fd0\u4f5c\uff0c\u4e9a\u57c3\u7ea7\u7ed3\u6784\u6270\u52a8\u5bfc\u81f4\u529f\u80fd\u707e\u96be\u6027\u4e27\u5931\u3002\u91cf\u5b50\u96a7\u7a7f\u5efa\u7acb\u4e86\u539f\u5b50\u7ed3\u6784\u4e0e\u4e34\u5e8a\u8868\u578b\u4e4b\u95f4\u7684\u9884\u6d4b\u6027\u673a\u5236\u8054\u7cfb\uff0c\u4e3a\u91cf\u5b50\u7ed3\u6784\u75be\u75c5\u5efa\u6a21\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2601.17633", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17633", "abs": "https://arxiv.org/abs/2601.17633", "authors": ["Rakesh Nadig", "Vamanan Arulchelvan", "Mayank Kabra", "Harshita Gupta", "Rahul Bera", "Nika Mansouri Ghiasi", "Nanditha Rao", "Qingcai Jiang", "Andreas Kosmas Kakolyris", "Yu Liang", "Mohammad Sadrosadati", "Onur Mutlu"], "title": "Conduit: Programmer-Transparent Near-Data Processing Using Multiple Compute-Capable Resources in Solid State Drives", "comment": "To appear in IEEE International Symposium on High-Performance Computer Architecture (HPCA) 2026", "summary": "Solid-state drives (SSDs) are well suited for near-data processing (NDP) because they: (1) store large application datasets, and (2) support three NDP paradigms: in-storage processing (ISP), processing using DRAM in the SSD (PuD-SSD), and in-flash processing (IFP). A large body of prior SSD-based NDP techniques operate in isolation, mapping computations to only one or two NDP paradigms (i.e., ISP, PuD-SSD, or IFP) within the SSD. These techniques (1) are tailored to specific workloads or kernels, (2) do not exploit the full computational potential of an SSD, and (3) lack programmer-transparency. While several prior works propose techniques to partition computation between the host and near-memory accelerators, adapting these techniques to SSDs has limited benefits because they (1) ignore the heterogeneity of the SSD resources, and (2) make offloading decisions based on limited factors such as bandwidth utilization, or data movement cost. We propose Conduit, a general-purpose, programmer-transparent NDP framework for SSDs that leverages multiple SSD computation resources. At compile time, Conduit executes a custom compiler (e.g., LLVM) pass that (i) vectorizes suitable application code segments into SIMD operations that align with the SSD's page layout, and (ii) embeds metadata (e.g., operation type, operand sizes) into the vectorized instructions to guide runtime offloading decisions. At runtime, within the SSD, Conduit performs instruction-granularity offloading by evaluating six key features, and uses a cost function to select the most suitable SSD resource. We evaluate Conduit and two prior NDP offloading techniques using an in-house event-driven SSD simulator on six data-intensive workloads. Conduit outperforms the best-performing prior offloading policy by 1.8x and reduces energy consumption by 46%.", "AI": {"tldr": "Conduit\u662f\u4e00\u4e2a\u901a\u7528\u7684\u3001\u5bf9\u7a0b\u5e8f\u5458\u900f\u660e\u7684SSD\u8fd1\u6570\u636e\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528SSD\u7684\u591a\u79cd\u8ba1\u7b97\u8d44\u6e90\uff0c\u5b9e\u73b0\u6307\u4ee4\u7c92\u5ea6\u7684\u5378\u8f7d\u51b3\u7b56\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u6027\u80fd\u63d0\u53471.8\u500d\uff0c\u80fd\u8017\u964d\u4f4e46%\u3002", "motivation": "\u73b0\u6709SSD\u8fd1\u6570\u636e\u5904\u7406\u6280\u672f\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u53ea\u9488\u5bf9\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u6216\u5185\u6838\uff1b2) \u672a\u5145\u5206\u5229\u7528SSD\u7684\u5168\u90e8\u8ba1\u7b97\u6f5c\u529b\uff1b3) \u7f3a\u4e4f\u5bf9\u7a0b\u5e8f\u5458\u7684\u900f\u660e\u5ea6\u3002\u540c\u65f6\uff0c\u73b0\u6709\u4e3b\u673a\u4e0e\u8fd1\u5185\u5b58\u52a0\u901f\u5668\u4e4b\u95f4\u7684\u8ba1\u7b97\u5212\u5206\u6280\u672f\u4e5f\u4e0d\u9002\u7528\u4e8eSSD\uff0c\u56e0\u4e3a\u5b83\u4eec\u5ffd\u7565\u4e86SSD\u8d44\u6e90\u7684\u5f02\u6784\u6027\uff0c\u4e14\u5378\u8f7d\u51b3\u7b56\u57fa\u4e8e\u6709\u9650\u56e0\u7d20\u3002", "method": "Conduit\u91c7\u7528\u7f16\u8bd1\u65f6\u548c\u8fd0\u884c\u65f6\u76f8\u7ed3\u5408\u7684\u65b9\u6848\u3002\u7f16\u8bd1\u65f6\u901a\u8fc7\u81ea\u5b9a\u4e49\u7f16\u8bd1\u5668\uff08\u5982LLVM\uff09\u5c06\u9002\u5408\u7684\u4ee3\u7801\u6bb5\u5411\u91cf\u5316\u4e3a\u4e0eSSD\u9875\u9762\u5e03\u5c40\u5bf9\u9f50\u7684SIMD\u64cd\u4f5c\uff0c\u5e76\u5d4c\u5165\u5143\u6570\u636e\u6307\u5bfc\u8fd0\u884c\u65f6\u5378\u8f7d\u51b3\u7b56\u3002\u8fd0\u884c\u65f6\u5728SSD\u5185\u90e8\uff0c\u57fa\u4e8e\u516d\u4e2a\u5173\u952e\u7279\u5f81\u8bc4\u4f30\uff0c\u4f7f\u7528\u6210\u672c\u51fd\u6570\u9009\u62e9\u6700\u5408\u9002\u7684SSD\u8d44\u6e90\u8fdb\u884c\u6307\u4ee4\u7c92\u5ea6\u5378\u8f7d\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0c\u4f7f\u7528\u5185\u90e8\u4e8b\u4ef6\u9a71\u52a8\u7684SSD\u6a21\u62df\u5668\u8fdb\u884c\u8bc4\u4f30\u3002Conduit\u76f8\u6bd4\u6027\u80fd\u6700\u4f73\u7684\u73b0\u6709\u5378\u8f7d\u7b56\u7565\uff0c\u6027\u80fd\u63d0\u53471.8\u500d\uff0c\u80fd\u8017\u964d\u4f4e46%\u3002", "conclusion": "Conduit\u901a\u8fc7\u5145\u5206\u5229\u7528SSD\u7684\u5f02\u6784\u8ba1\u7b97\u8d44\u6e90\uff0c\u5b9e\u73b0\u901a\u7528\u3001\u900f\u660e\u7684\u8fd1\u6570\u636e\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2601.17578", "categories": ["cs.DC", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.17578", "abs": "https://arxiv.org/abs/2601.17578", "authors": ["Henrik Bengtsson"], "title": "A Unified Approach to Concurrent, Parallel Map-Reduce in R using Futures", "comment": "16 pages including 2.5 pages references, 1 figure", "summary": "The R ecosystem offers a rich variety of map-reduce application programming interfaces (APIs) for iterative computations, yet parallelizing code across these diverse frameworks requires learning multiple, often incompatible, parallel APIs. The futurize package addresses this challenge by providing a single function, futurize(), which transpiles sequential map-reduce expressions into their parallel equivalents in the future ecosystem, which performs all the heavy lifting. By leveraging R's native pipe operator, users can parallelize existing code with minimal refactoring -- often by simply appending `|> futurize()' to an expression. The package supports classical map-reduce functions from base R, purrr, crossmap, foreach, plyr, BiocParallel, e.g., lapply(xs, fcn) |> futurize() and map(xs, fcn) |> futurize(), as well as a growing set of domain-specific packages, e.g., boot, caret, glmnet, lme4, mgcv, and tm. By abstracting away the underlying parallel machinery, and unifying handling of future options, the package enables developers to declare what to parallelize via futurize(), and end-users to choose how via plan(). This article describes the philosophy, design, and implementation of futurize, demonstrates its usage across various map-reduce paradigms, and discusses its role in simplifying parallel computing in R.", "AI": {"tldr": "futurize\u5305\u63d0\u4f9b\u5355\u4e00\u51fd\u6570futurize()\uff0c\u53ef\u5c06\u987a\u5e8fmap-reduce\u8868\u8fbe\u5f0f\u8f6c\u6362\u4e3afuture\u751f\u6001\u7cfb\u7edf\u7684\u5e76\u884c\u7248\u672c\uff0c\u7b80\u5316R\u4e2d\u7684\u5e76\u884c\u8ba1\u7b97", "motivation": "R\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684map-reduce API\u7528\u4e8e\u8fed\u4ee3\u8ba1\u7b97\uff0c\u4f46\u8de8\u4e0d\u540c\u6846\u67b6\u5e76\u884c\u5316\u4ee3\u7801\u9700\u8981\u5b66\u4e60\u591a\u4e2a\u4e0d\u517c\u5bb9\u7684\u5e76\u884cAPI\u3002futurize\u5305\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u901a\u8fc7\u5355\u4e00\u63a5\u53e3\u7b80\u5316\u5e76\u884c\u5316\u8fc7\u7a0b\u3002", "method": "\u63d0\u4f9bfuturize()\u51fd\u6570\uff0c\u5c06\u987a\u5e8fmap-reduce\u8868\u8fbe\u5f0f\u8f6c\u8bd1\u4e3afuture\u751f\u6001\u7cfb\u7edf\u7684\u5e76\u884c\u7b49\u4ef7\u5f62\u5f0f\u3002\u5229\u7528R\u7684\u539f\u751f\u7ba1\u9053\u8fd0\u7b97\u7b26\uff0c\u7528\u6237\u53ea\u9700\u5728\u8868\u8fbe\u5f0f\u540e\u8ffd\u52a0`|> futurize()`\u5373\u53ef\u5e76\u884c\u5316\u73b0\u6709\u4ee3\u7801\u3002\u652f\u6301base R\u3001purrr\u3001crossmap\u3001foreach\u3001plyr\u3001BiocParallel\u7b49\u591a\u79cd\u5305\u4e2d\u7684map-reduce\u51fd\u6570\u3002", "result": "futurize\u5305\u62bd\u8c61\u4e86\u5e95\u5c42\u5e76\u884c\u673a\u5236\uff0c\u7edf\u4e00\u5904\u7406future\u9009\u9879\uff0c\u4f7f\u5f00\u53d1\u8005\u901a\u8fc7futurize()\u58f0\u660e\u8981\u5e76\u884c\u5316\u7684\u5185\u5bb9\uff0c\u7ec8\u7aef\u7528\u6237\u901a\u8fc7plan()\u9009\u62e9\u5e76\u884c\u65b9\u5f0f\u3002\u652f\u6301\u591a\u79cdmap-reduce\u8303\u5f0f\uff0c\u7b80\u5316\u4e86R\u4e2d\u7684\u5e76\u884c\u8ba1\u7b97\u3002", "conclusion": "futurize\u5305\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u5e76\u884c\u5316\u63a5\u53e3\uff0c\u663e\u8457\u964d\u4f4e\u4e86R\u4e2d\u5e76\u884c\u8ba1\u7b97\u7684\u590d\u6742\u6027\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u4e13\u6ce8\u4e8e\"\u505a\u4ec0\u4e48\"\u800c\u975e\"\u600e\u4e48\u505a\"\uff0c\u4fc3\u8fdb\u4e86\u5e76\u884c\u8ba1\u7b97\u7684\u666e\u53ca\u548c\u5e94\u7528\u3002"}}
{"id": "2601.16994", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.16994", "abs": "https://arxiv.org/abs/2601.16994", "authors": ["Lucas M. Morello", "Matheus Lima Castro", "Pedro Cesar M. G. Camargo", "Liliane Moreira Nery", "Darllan Collins da Cunha e Silva", "Leopoldo Lusquino Filho"], "title": "A Dataset of Dengue Hospitalizations in Brazil (1999 to 2021) with Weekly Disaggregation from Monthly Counts", "comment": null, "summary": "This data paper describes and publicly releases this dataset (v1.0.0), published on Zenodo under DOI 10.5281/zenodo.18189192. Motivated by the need to increase the temporal granularity of originally monthly data to enable more effective training of AI models for epidemiological forecasting, the dataset harmonizes municipal-level dengue hospitalization time series across Brazil and disaggregates them to weekly resolution (epidemiological weeks) through an interpolation protocol with a correction step that preserves monthly totals. The statistical and temporal validity of this disaggregation was assessed using a high-resolution reference dataset from the state of Sao Paulo (2024), which simultaneously provides monthly and epidemiological-week counts, enabling a direct comparison of three strategies: linear interpolation, jittering, and cubic spline. Results indicated that cubic spline interpolation achieved the highest adherence to the reference data, and this strategy was therefore adopted to generate weekly series for the 1999 to 2021 period. In addition to hospitalization time series, the dataset includes a comprehensive set of explanatory variables commonly used in epidemiological and environmental modeling, such as demographic density, CH4, CO2, and NO2 emissions, poverty and urbanization indices, maximum temperature, mean monthly precipitation, minimum relative humidity, and municipal latitude and longitude, following the same temporal disaggregation scheme to ensure multivariate compatibility. The paper documents the datasets provenance, structure, formats, licenses, limitations, and quality metrics (MAE, RMSE, R2, KL, JSD, DTW, and the KS test), and provides usage recommendations for multivariate time-series analysis, environmental health studies, and the development of machine learning and deep learning models for outbreak forecasting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u5e03\u4e86\u4e00\u4e2a\u5df4\u897f\u5e02\u7ea7\u767b\u9769\u70ed\u4f4f\u9662\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u5c06\u539f\u59cb\u6708\u5ea6\u6570\u636e\u901a\u8fc7\u4e09\u6b21\u6837\u6761\u63d2\u503c\u6cd5\u5206\u89e3\u4e3a\u5468\u5ea6\u5206\u8fa8\u7387\uff0c\u5e76\u5305\u542b\u591a\u79cd\u73af\u5883\u548c\u793e\u4f1a\u7ecf\u6d4e\u89e3\u91ca\u53d8\u91cf\uff0c\u7528\u4e8e\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u7684AI\u6a21\u578b\u8bad\u7ec3\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347AI\u6a21\u578b\u5728\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u4e2d\u7684\u8bad\u7ec3\u6548\u679c\uff0c\u9700\u8981\u5c06\u539f\u59cb\u7684\u6708\u5ea6\u6570\u636e\u63d0\u5347\u5230\u66f4\u9ad8\u7684\u65f6\u95f4\u7c92\u5ea6\uff08\u5468\u5ea6\u5206\u8fa8\u7387\uff09\uff0c\u4ece\u800c\u66f4\u597d\u5730\u6355\u6349\u767b\u9769\u70ed\u4f20\u64ad\u7684\u52a8\u6001\u53d8\u5316\u3002", "method": "\u91c7\u7528\u4e09\u6b21\u6837\u6761\u63d2\u503c\u6cd5\u5c06\u5df4\u897f\u5e02\u7ea7\u767b\u9769\u70ed\u4f4f\u9662\u6708\u5ea6\u6570\u636e\u5206\u89e3\u4e3a\u6d41\u884c\u75c5\u5b66\u5468\u5ea6\u6570\u636e\uff0c\u901a\u8fc7\u5723\u4fdd\u7f57\u5dde\u7684\u9ad8\u5206\u8fa8\u7387\u53c2\u8003\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u786e\u4fdd\u6708\u5ea6\u603b\u6570\u4fdd\u6301\u4e0d\u53d8\u3002", "result": "\u4e09\u6b21\u6837\u6761\u63d2\u503c\u6cd5\u5728\u4e09\u79cd\u7b56\u7565\uff08\u7ebf\u6027\u63d2\u503c\u3001\u6296\u52a8\u3001\u4e09\u6b21\u6837\u6761\uff09\u4e2d\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u6570\u636e\u62df\u5408\u5ea6\uff0c\u56e0\u6b64\u88ab\u91c7\u7528\u6765\u751f\u62101999-2021\u5e74\u671f\u95f4\u7684\u5468\u5ea6\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u3001\u591a\u53d8\u91cf\u7684\u5df4\u897f\u767b\u9769\u70ed\u5468\u5ea6\u6570\u636e\u96c6\uff0c\u4e3a\u6d41\u884c\u75c5\u5b66\u5efa\u6a21\u3001\u73af\u5883\u5065\u5eb7\u7814\u7a76\u548c\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2601.18710", "categories": ["cs.ET", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.18710", "abs": "https://arxiv.org/abs/2601.18710", "authors": ["A. Bano", "L. Liebovitch"], "title": "Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia", "comment": "5 pages, 1 figure, 2 tables", "summary": "This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy).\n  Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.", "AI": {"tldr": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u533b\u5b66\u5f71\u50cf\u8bca\u65ad\u4e2d\u5c55\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u5728\u4e25\u91cd\u7ea6\u675f\u4e0b\u4ec5\u6bd4\u7ecf\u5178CNN\u4f4e12-15%\u51c6\u786e\u7387\uff0c\u4e14\u6570\u636e\u6548\u7387\u66f4\u9ad8", "motivation": "\u63a2\u7d22\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u73b0\u5b9e\u4e16\u754c\u533b\u5b66\u5f71\u50cf\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u7279\u522b\u662f\u5728NISQ\u65f6\u4ee3\u786c\u4ef6\u9650\u5236\u4e0b\uff0c\u9a8c\u8bc1\u91cf\u5b50\u65b9\u6cd5\u80fd\u5426\u5728\u533b\u7597\u5065\u5eb7\u9886\u57df\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd", "method": "\u4f7f\u7528\u4e24\u79cd\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff1a1) \u5e73\u8861\u4f20\u64ad\uff08EP\uff09- \u4e00\u79cd\u4e0d\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7684\u57fa\u4e8e\u80fd\u91cf\u7684\u5b66\u4e60\u65b9\u6cd5\uff1b2) \u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09- 4\u91cf\u5b50\u6bd4\u7279\u7535\u8def\u3002\u5728AML-Cytomorphology\u6570\u636e\u96c6\u4e0a\u5bf9\u6025\u6027\u9ad3\u7cfb\u767d\u8840\u75c5\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\uff0c\u4f7f\u7528\u6709\u9650\u6837\u672c\uff08\u6bcf\u7c7b50-250\u4e2a\uff09\uff0c\u56fe\u50cf\u964d\u5206\u8fa8\u7387\u523064x64\u50cf\u7d20\uff0c\u63d0\u53d620\u7ef4\u5de5\u7a0b\u7279\u5f81\uff0c\u901a\u8fc7Qiskit\u8fdb\u884c\u7ecf\u5178\u6a21\u62df", "result": "\u91cf\u5b50\u65b9\u6cd5\u4ec5\u6bd4\u7ecf\u5178CNN\u4f4e12-15%\u51c6\u786e\u7387\uff1aEP\u8fbe\u523086.4%\u51c6\u786e\u7387\uff08\u6bd4CNN\u4f4e12%\uff09\uff0c4\u91cf\u5b50\u6bd4\u7279VQC\u8fbe\u523083.0%\u51c6\u786e\u7387\u3002VQC\u6570\u636e\u6548\u7387\u663e\u8457\u66f4\u9ad8\uff1a\u4ec5\u9700\u6bcf\u7c7b50\u4e2a\u6837\u672c\u5373\u53ef\u7ef4\u630183%\u7a33\u5b9a\u6027\u80fd\uff0c\u800cCNN\u9700\u8981\u6bcf\u7c7b250\u4e2a\u6837\u672c\uff085\u500d\u6570\u636e\u91cf\uff09\u624d\u80fd\u8fbe\u523098%\u51c6\u786e\u7387", "conclusion": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u533b\u7597\u5065\u5eb7\u9886\u57df\u5177\u6709\u53ef\u884c\u6027\uff0c\u5373\u4f7f\u5728\u5f53\u524dNISQ\u65f6\u4ee3\u7684\u9650\u5236\u4e0b\u4e5f\u80fd\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u4e3a\u533b\u7597\u9886\u57df\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u51c6"}}
{"id": "2601.17940", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.17940", "abs": "https://arxiv.org/abs/2601.17940", "authors": ["Luca Colagrande", "Luca Benini"], "title": "Late Breaking Results: Boosting Efficient Dual-Issue Execution on Lightweight RISC-V Cores", "comment": "Accepted at DATE 2026", "summary": "Large-scale ML accelerators rely on large numbers of PEs, imposing strict bounds on the area and energy budget of each PE. Prior work demonstrates that limited dual-issue capabilities can be efficiently integrated into a lightweight in-order open-source RISC-V core (Snitch), with a geomean IPC boost of 1.6x and a geomean energy efficiency gain of 1.3x, obtained by concurrently executing integer and FP instructions. Unfortunately, this required a complex and error-prone low level programming model (COPIFT). We introduce COPIFTv2 which augments Snitch with lightweight queues enabling direct, fine-grained communication and synchronization between integer and FP threads. By eliminating the tiling and software pipelining steps of COPIFT, we can remove much of its complexity and software overheads. As a result, COPIFTv2 achieves up to a 1.49x speedup and a 1.47x energy-efficiency gain over COPIFT, and a peak IPC of 1.81. Overall, COPIFTv2 significantly enhances the efficiency and programmability of dual-issue execution on lightweight cores. Our implementation is fully open source and performance experiments are reproducible using free software.", "AI": {"tldr": "COPIFTv2\u5728Snitch RISC-V\u6838\u5fc3\u4e0a\u5f15\u5165\u8f7b\u91cf\u7ea7\u961f\u5217\uff0c\u7b80\u5316\u4e86\u6574\u6570\u548c\u6d6e\u70b9\u7ebf\u7a0b\u95f4\u7684\u901a\u4fe1\uff0c\u76f8\u6bd4COPIFT\u5b9e\u73b0\u4e861.49\u500d\u52a0\u901f\u548c1.47\u500d\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u5927\u89c4\u6a21ML\u52a0\u901f\u5668\u9700\u8981\u5927\u91cfPE\uff0c\u6bcf\u4e2aPE\u7684\u9762\u79ef\u548c\u80fd\u8017\u9884\u7b97\u4e25\u683c\u53d7\u9650\u3002\u73b0\u6709COPIFT\u867d\u7136\u80fd\u63d0\u5347\u6027\u80fd\uff08IPC\u63d0\u53471.6x\uff0c\u80fd\u6548\u63d0\u53471.3x\uff09\uff0c\u4f46\u7f16\u7a0b\u6a21\u578b\u590d\u6742\u4e14\u6613\u51fa\u9519\uff0c\u9700\u8981\u7e41\u7410\u7684\u5e73\u94fa\u548c\u8f6f\u4ef6\u6d41\u6c34\u7ebf\u6b65\u9aa4\u3002", "method": "COPIFTv2\u5728Snitch\u6838\u5fc3\u4e0a\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u961f\u5217\uff0c\u652f\u6301\u6574\u6570\u548c\u6d6e\u70b9\u7ebf\u7a0b\u95f4\u7684\u76f4\u63a5\u7ec6\u7c92\u5ea6\u901a\u4fe1\u548c\u540c\u6b65\uff0c\u6d88\u9664\u4e86COPIFT\u4e2d\u7684\u5e73\u94fa\u548c\u8f6f\u4ef6\u6d41\u6c34\u7ebf\u6b65\u9aa4\uff0c\u7b80\u5316\u4e86\u7f16\u7a0b\u6a21\u578b\u3002", "result": "\u76f8\u6bd4COPIFT\uff0cCOPIFTv2\u5b9e\u73b0\u4e86\u6700\u9ad81.49\u500d\u52a0\u901f\u548c1.47\u500d\u80fd\u6548\u63d0\u5347\uff0c\u5cf0\u503cIPC\u8fbe\u52301.81\u3002\u663e\u8457\u63d0\u5347\u4e86\u8f7b\u91cf\u7ea7\u6838\u5fc3\u4e0a\u53cc\u53d1\u5c04\u6267\u884c\u7684\u6548\u7387\u548c\u53ef\u7f16\u7a0b\u6027\u3002", "conclusion": "COPIFTv2\u901a\u8fc7\u8f7b\u91cf\u7ea7\u961f\u5217\u673a\u5236\u663e\u8457\u7b80\u5316\u4e86\u53cc\u53d1\u5c04\u6267\u884c\u7684\u7f16\u7a0b\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8f6f\u4ef6\u590d\u6742\u6027\uff0c\u4e3a\u5927\u89c4\u6a21ML\u52a0\u901f\u5668\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684PE\u8bbe\u8ba1\u65b9\u6848\u3002"}}
{"id": "2601.17589", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17589", "abs": "https://arxiv.org/abs/2601.17589", "authors": ["Thomas Sandholm", "Bernardo A. Huberman", "Klas Segeljakt", "Paris Carbone"], "title": "Lightspeed Data Compute for the Space Era", "comment": null, "summary": "While thousands of satellites photograph Earth every day, most of that data never makes it to the ground because downlink bandwidth simply cannot keep up. Processing data in the Low Earth Orbit (LEO) zone offers promising capabilities to overcome this limitation. We propose SpaceCoMP, a MapReduce-inspired processing model for LEO satellite mesh networks. Ground stations submit queries over an area of interest; satellites collect sensor data, process it cooperatively at light-speed using inter-satellite laser links, and return only the results. Our compute model leverages space physics to accelerate computations on LEO megaconstellations. Our distance-aware routing protocol exploits orbital geometry. In addition, our bipartite match scheduling strategy places map and reduce tasks within orbital regions while minimizing aggregation costs. We have simulated constellations of 1,000-10,000 satellites showcasing 61-79% improvement in map placement efficiency over baselines, 18-28% over greedy allocation, and 67-72% reduction in aggregation cost. SpaceCoMP demonstrates that the orbital mesh is not merely useful as a communication relay, as seen today, but can provide the foundations for faster data processing above the skies.", "AI": {"tldr": "SpaceCoMP\uff1a\u4e00\u79cd\u53d7MapReduce\u542f\u53d1\u7684\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7f51\u7edc\u5904\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u661f\u95f4\u6fc0\u5149\u94fe\u8def\u534f\u540c\u5904\u7406\u9065\u611f\u6570\u636e\uff0c\u53ea\u8fd4\u56de\u7ed3\u679c\u800c\u975e\u539f\u59cb\u6570\u636e\uff0c\u89e3\u51b3\u4e0b\u884c\u5e26\u5bbd\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u6bcf\u5929\u6570\u5343\u9897\u536b\u661f\u62cd\u6444\u5730\u7403\uff0c\u4f46\u5927\u90e8\u5206\u6570\u636e\u65e0\u6cd5\u4f20\u56de\u5730\u9762\uff0c\u56e0\u4e3a\u4e0b\u884c\u5e26\u5bbd\u65e0\u6cd5\u8ddf\u4e0a\u6570\u636e\u751f\u6210\u901f\u5ea6\u3002\u5728\u4f4e\u5730\u7403\u8f68\u9053\u533a\u57df\u5904\u7406\u6570\u636e\u6709\u671b\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51faSpaceCoMP\u5904\u7406\u6a21\u578b\uff1a\u5730\u9762\u7ad9\u63d0\u4ea4\u611f\u5174\u8da3\u533a\u57df\u67e5\u8be2\uff1b\u536b\u661f\u6536\u96c6\u4f20\u611f\u5668\u6570\u636e\uff0c\u5229\u7528\u661f\u95f4\u6fc0\u5149\u94fe\u8def\u534f\u540c\u5904\u7406\uff1b\u91c7\u7528\u8ddd\u79bb\u611f\u77e5\u8def\u7531\u534f\u8bae\u5229\u7528\u8f68\u9053\u51e0\u4f55\uff1b\u4f7f\u7528\u4e8c\u5206\u56fe\u5339\u914d\u8c03\u5ea6\u7b56\u7565\u5728\u8f68\u9053\u533a\u57df\u5185\u5206\u914dmap\u548creduce\u4efb\u52a1\u4ee5\u6700\u5c0f\u5316\u805a\u5408\u6210\u672c\u3002", "result": "\u57281000-10000\u9897\u536b\u661f\u7684\u661f\u5ea7\u6a21\u62df\u4e2d\uff0cmap\u4efb\u52a1\u653e\u7f6e\u6548\u7387\u6bd4\u57fa\u7ebf\u63d0\u9ad861-79%\uff0c\u6bd4\u8d2a\u5a6a\u5206\u914d\u63d0\u9ad818-28%\uff0c\u805a\u5408\u6210\u672c\u964d\u4f4e67-72%\u3002", "conclusion": "\u8f68\u9053\u7f51\u72b6\u7f51\u7edc\u4e0d\u4ec5\u53ef\u7528\u4f5c\u901a\u4fe1\u4e2d\u7ee7\uff08\u5982\u5f53\u524d\u6240\u89c1\uff09\uff0c\u8fd8\u80fd\u4e3a\u5929\u7a7a\u4e4b\u4e0a\u7684\u66f4\u5feb\u6570\u636e\u5904\u7406\u63d0\u4f9b\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5728\u8f68\u5904\u7406\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2601.17006", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17006", "abs": "https://arxiv.org/abs/2601.17006", "authors": ["Xuchen Li", "Jing Chen", "Xuzhao Li", "Hao Liang", "Xiaohuan Zhou", "Taifeng Wang", "Wentao Zhang"], "title": "MathMixup: Boosting LLM Mathematical Reasoning with Difficulty-Controllable Data Synthesis and Curriculum Learning", "comment": "Preprint, Under review", "summary": "In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.", "AI": {"tldr": "MathMixup\uff1a\u901a\u8fc7\u6df7\u5408\u4e0e\u5206\u89e3\u7b56\u7565\u751f\u6210\u96be\u5ea6\u53ef\u63a7\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\uff0c\u6784\u5efa\u5206\u7ea7\u6570\u636e\u96c6\u5e76\u8bbe\u8ba1\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347LLM\u6570\u5b66\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u6570\u636e\u5408\u6210\u65b9\u6cd5\u591a\u6837\u6027\u6709\u9650\u4e14\u96be\u4ee5\u7cbe\u786e\u63a7\u5236\u95ee\u9898\u96be\u5ea6\uff0c\u65e0\u6cd5\u6709\u6548\u652f\u6301\u8bfe\u7a0b\u5b66\u4e60\u7b49\u9ad8\u6548\u8bad\u7ec3\u8303\u5f0f\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u96be\u5ea6\u53ef\u63a7\u6570\u5b66\u63a8\u7406\u95ee\u9898\u7684\u65b0\u65b9\u6cd5", "method": "\u63d0\u51faMathMixup\u6570\u636e\u5408\u6210\u8303\u5f0f\uff0c\u91c7\u7528\u6df7\u5408\u4e0e\u5206\u89e3\u7b56\u7565\u7cfb\u7edf\u751f\u6210\u96be\u5ea6\u53ef\u63a7\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u81ea\u68c0\u548c\u4eba\u5de5\u7b5b\u9009\u786e\u4fdd\u8bed\u4e49\u6e05\u6670\u548c\u96be\u5ea6\u68af\u5ea6\uff0c\u6784\u5efaMathMixupQA\u6570\u636e\u96c6\u5e76\u8bbe\u8ba1\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565", "result": "\u5fae\u8c03\u7684Qwen2.5-7B\u5728\u4e03\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u5f97\u520652.6%\uff0c\u8d85\u8d8a\u5148\u524d\u6700\u4f18\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86MathMixup\u5728\u63d0\u5347LLM\u6570\u5b66\u63a8\u7406\u80fd\u529b\u548c\u63a8\u8fdb\u6570\u636e\u4e2d\u5fc3\u8bfe\u7a0b\u5b66\u4e60\u65b9\u9762\u7684\u6709\u6548\u6027", "conclusion": "MathMixup\u901a\u8fc7\u7cfb\u7edf\u751f\u6210\u96be\u5ea6\u53ef\u63a7\u7684\u9ad8\u8d28\u91cf\u6570\u5b66\u63a8\u7406\u95ee\u9898\uff0c\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u6570\u5b66\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u6570\u636e\u4e2d\u5fc3\u7684\u8bfe\u7a0b\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18761", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.18761", "abs": "https://arxiv.org/abs/2601.18761", "authors": ["Wout Slabbinck", "Wouter Termont", "Ruben Dedecker", "Beatriz Esteves"], "title": "From Access Control to Usage Control with User-Managed Access", "comment": null, "summary": "Recent data protection and data governance regulations have intensified the demand for interoperable, decentralized data ecosystems that can support not only access control but also legally-aligned governance over data use. Existing Web-based data storage platforms increasingly struggle to meet these regulatory and practical requirements, as their authorization mechanisms rely on tightly coupled, document-centric access control models that lack expressiveness for legal constraints and fail to separate data management from authorization concerns. In parallel, widely adopted authorization standards remain poorly aligned with decentralized, semantically rich usage-control scenarios. To bridge this gap, this work introduces an architecture that replaces Solid's native access control mechanisms with a UMA authorization flow, enabling the enforcement of usage control policies expressed with the W3C ODRL standard. This article details the conceptual background motivating this approach, presents the proposed UMA-based architecture, and describes a prototype implementation that integrates an ODRL-enabled Authorization Server with a Solid-compatible Resource Server. The prototype demonstrates that decoupling authorization from storage enables more flexible, interoperable, and legally expressive control over data use, while remaining compatible with existing Solid infrastructure. It also highlights practical design choices required to evaluate ODRL policies in the absence of a fully standardized evaluation semantics. Moreover, this work shows how usage control can be operationalized using existing Web standards, offering a concrete path beyond permission-based access control toward policy-aware, legally informed data governance. Future research will focus on policy management interfaces, richer claim verification mechanisms, and techniques for communicating and enforcing obligations over time.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u67b6\u6784\uff0c\u7528UMA\u6388\u6743\u6d41\u7a0b\u66ff\u4ee3Solid\u539f\u751f\u8bbf\u95ee\u63a7\u5236\u673a\u5236\uff0c\u652f\u6301\u4f7f\u7528W3C ODRL\u6807\u51c6\u8868\u8fbe\u4f7f\u7528\u63a7\u5236\u7b56\u7565\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u3001\u53ef\u4e92\u64cd\u4f5c\u4e14\u7b26\u5408\u6cd5\u5f8b\u8981\u6c42\u7684\u6570\u636e\u6cbb\u7406\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eWeb\u7684\u6570\u636e\u5b58\u50a8\u5e73\u53f0\u96be\u4ee5\u6ee1\u8db3\u65e5\u76ca\u4e25\u683c\u7684\u6570\u636e\u4fdd\u62a4\u548c\u6cbb\u7406\u6cd5\u89c4\u8981\u6c42\uff0c\u5176\u6388\u6743\u673a\u5236\u91c7\u7528\u7d27\u8026\u5408\u3001\u6587\u6863\u4e2d\u5fc3\u7684\u8bbf\u95ee\u63a7\u5236\u6a21\u578b\uff0c\u7f3a\u4e4f\u6cd5\u5f8b\u7ea6\u675f\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4e14\u672a\u80fd\u5206\u79bb\u6570\u636e\u7ba1\u7406\u4e0e\u6388\u6743\u5173\u6ce8\u70b9\u3002\u540c\u65f6\uff0c\u5e7f\u6cdb\u91c7\u7528\u7684\u6388\u6743\u6807\u51c6\u4e0e\u53bb\u4e2d\u5fc3\u5316\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u4f7f\u7528\u63a7\u5236\u573a\u666f\u4e0d\u5339\u914d\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u67b6\u6784\uff0c\u7528UMA\u6388\u6743\u6d41\u7a0b\u66ff\u4ee3Solid\u539f\u751f\u8bbf\u95ee\u63a7\u5236\u673a\u5236\uff0c\u652f\u6301\u4f7f\u7528W3C ODRL\u6807\u51c6\u8868\u8fbe\u4f7f\u7528\u63a7\u5236\u7b56\u7565\u3002\u5f00\u53d1\u539f\u578b\u7cfb\u7edf\uff0c\u96c6\u6210ODRL\u6388\u6743\u670d\u52a1\u5668\u4e0eSolid\u517c\u5bb9\u7684\u8d44\u6e90\u670d\u52a1\u5668\uff0c\u5b9e\u73b0\u6388\u6743\u4e0e\u5b58\u50a8\u7684\u89e3\u8026\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u8bc1\u660e\uff0c\u5c06\u6388\u6743\u4e0e\u5b58\u50a8\u89e3\u8026\u80fd\u591f\u5b9e\u73b0\u5bf9\u6570\u636e\u4f7f\u7528\u7684\u66f4\u7075\u6d3b\u3001\u53ef\u4e92\u64cd\u4f5c\u4e14\u7b26\u5408\u6cd5\u5f8b\u8981\u6c42\u7684\u63a7\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u73b0\u6709Solid\u57fa\u7840\u8bbe\u65bd\u7684\u517c\u5bb9\u6027\u3002\u5c55\u793a\u4e86\u5728\u6ca1\u6709\u5b8c\u5168\u6807\u51c6\u5316\u8bc4\u4f30\u8bed\u4e49\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30ODRL\u7b56\u7565\u6240\u9700\u7684\u5b9e\u9645\u8bbe\u8ba1\u9009\u62e9\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u73b0\u6709Web\u6807\u51c6\u5b9e\u73b0\u4f7f\u7528\u63a7\u5236\uff0c\u4e3a\u8d85\u8d8a\u57fa\u4e8e\u6743\u9650\u7684\u8bbf\u95ee\u63a7\u5236\u3001\u5b9e\u73b0\u7b56\u7565\u611f\u77e5\u4e14\u6cd5\u5f8b\u77e5\u60c5\u7684\u6570\u636e\u6cbb\u7406\u63d0\u4f9b\u4e86\u5177\u4f53\u8def\u5f84\u3002\u672a\u6765\u7814\u7a76\u5c06\u5173\u6ce8\u7b56\u7565\u7ba1\u7406\u754c\u9762\u3001\u66f4\u4e30\u5bcc\u7684\u58f0\u660e\u9a8c\u8bc1\u673a\u5236\u4ee5\u53ca\u968f\u65f6\u95f4\u901a\u4fe1\u548c\u6267\u884c\u4e49\u52a1\u7684\u6280\u672f\u3002"}}
{"id": "2601.18007", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18007", "abs": "https://arxiv.org/abs/2601.18007", "authors": ["Duckgyu Shin", "Naoya Onizawa", "Warren J. Gross", "Takahiro Hanyu"], "title": "Memory-Efficient FPGA Implementation of Stochastic Simulated Annealing", "comment": "11 pages", "summary": "Simulated annealing (SA) is a well-known algorithm for solving combinatorial optimization problems. However, the computation time of SA increases rapidly, as the size of the problem grows. Recently, a stochastic simulated annealing (SSA) algorithm that converges faster than conventional SA has been reported. In this paper, we present a hardware-aware SSA (HA- SSA) algorithm for memory-efficient FPGA implementations. HA-SSA can reduce the memory usage of storing intermediate results while maintaining the computing speed of SSA. For evaluation purposes, the proposed algorithm is compared with the conventional SSA and SA approaches on maximum cut combinatorial optimization problems. HA-SSA achieves a convergence speed that is up to 114-times faster than that of the conventional SA algorithm depending on the maximum cut problem selected from the G-set which is a dataset of the maximum cut problems. HA-SSA is implemented on a field-programmable gate array (FPGA) (Xilinx Kintex-7), and it achieves up to 6-times the memory efficiency of conventional SSA while maintaining high solution quality for optimization problems.", "AI": {"tldr": "\u63d0\u51fa\u786c\u4ef6\u611f\u77e5\u7684\u968f\u673a\u6a21\u62df\u9000\u706b\u7b97\u6cd5\uff08HA-SSA\uff09\uff0c\u5728FPGA\u4e0a\u5b9e\u73b0\u5185\u5b58\u9ad8\u6548\u5b9e\u73b0\uff0c\u76f8\u6bd4\u4f20\u7edfSA\u52a0\u901f114\u500d\uff0c\u5185\u5b58\u6548\u7387\u63d0\u53476\u500d\u3002", "motivation": "\u4f20\u7edf\u6a21\u62df\u9000\u706b\u7b97\u6cd5\uff08SA\uff09\u5728\u95ee\u9898\u89c4\u6a21\u589e\u5927\u65f6\u8ba1\u7b97\u65f6\u95f4\u6025\u5267\u589e\u52a0\uff0c\u867d\u7136\u968f\u673a\u6a21\u62df\u9000\u706b\uff08SSA\uff09\u6536\u655b\u66f4\u5feb\uff0c\u4f46FPGA\u5b9e\u73b0\u65f6\u5185\u5b58\u5360\u7528\u8f83\u5927\uff0c\u9700\u8981\u5185\u5b58\u9ad8\u6548\u7684\u786c\u4ef6\u5b9e\u73b0\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u786c\u4ef6\u611f\u77e5\u7684\u968f\u673a\u6a21\u62df\u9000\u706b\u7b97\u6cd5\uff08HA-SSA\uff09\uff0c\u901a\u8fc7\u51cf\u5c11\u4e2d\u95f4\u7ed3\u679c\u7684\u5b58\u50a8\u6765\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301SSA\u7684\u8ba1\u7b97\u901f\u5ea6\u3002\u5728FPGA\uff08Xilinx Kintex-7\uff09\u4e0a\u5b9e\u73b0\uff0c\u5e76\u5728\u6700\u5927\u5272\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "HA-SSA\u5728G-set\u6700\u5927\u5272\u95ee\u9898\u4e0a\u6bd4\u4f20\u7edfSA\u6536\u655b\u901f\u5ea6\u5feb114\u500d\uff0c\u5728FPGA\u4e0a\u5b9e\u73b0\u65f6\u5185\u5b58\u6548\u7387\u6bd4\u4f20\u7edfSSA\u9ad86\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4f18\u5316\u95ee\u9898\u7684\u9ad8\u89e3\u8d28\u91cf\u3002", "conclusion": "HA-SSA\u7b97\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5185\u5b58\u9ad8\u6548\u7684FPGA\u5b9e\u73b0\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u901f\u5ea6\u548c\u89e3\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u4e3a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u786c\u4ef6\u52a0\u901f\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.17606", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17606", "abs": "https://arxiv.org/abs/2601.17606", "authors": ["Shannon Kinkead", "Jackson Wesley", "Whit Schonbein", "David DeBonis", "Matthew G. F. Dosanjh", "Amanda Bienz"], "title": "Scaling All-to-all Operations Across Emerging Many-Core Supercomputers", "comment": null, "summary": "Performant all-to-all collective operations in MPI are critical to fast Fourier transforms, transposition, and machine learning applications. There are many existing implementations for all-to-all exchanges on emerging systems, with the achieved performance dependent on many factors, including message size, process count, architecture, and parallel system partition. This paper presents novel all-to-all algorithms for emerging many-core systems. Further, the paper presents a performance analysis against existing algorithms and system MPI, with novel algorithms achieving up to 3x speedup over system MPI at 32 nodes of state-of-the-art Sapphire Rapids systems.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u65b0\u5174\u591a\u6838\u7cfb\u7edf\u63d0\u51fa\u4e86\u65b0\u9896\u7684all-to-all\u7b97\u6cd5\uff0c\u5728Sapphire Rapids\u7cfb\u7edf\u4e0a\u76f8\u6bd4\u7cfb\u7edfMPI\u5b9e\u73b0\u4e86\u6700\u9ad83\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "MPI\u4e2d\u7684\u9ad8\u6027\u80fdall-to-all\u96c6\u5408\u64cd\u4f5c\u5bf9\u4e8e\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\u3001\u8f6c\u7f6e\u548c\u673a\u5668\u5b66\u4e60\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u5b9e\u73b0\u5728\u65b0\u5174\u7cfb\u7edf\u4e0a\u7684\u6027\u80fd\u53d7\u6d88\u606f\u5927\u5c0f\u3001\u8fdb\u7a0b\u6570\u91cf\u3001\u67b6\u6784\u548c\u5e76\u884c\u7cfb\u7edf\u5206\u533a\u7b49\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\uff0c\u9700\u8981\u9488\u5bf9\u65b0\u5174\u591a\u6838\u7cfb\u7edf\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u9488\u5bf9\u65b0\u5174\u591a\u6838\u7cfb\u7edf\u7684\u65b0\u578ball-to-all\u7b97\u6cd5\uff0c\u5e76\u5bf9\u73b0\u6709\u7b97\u6cd5\u548c\u7cfb\u7edfMPI\u8fdb\u884c\u4e86\u6027\u80fd\u5206\u6790\u6bd4\u8f83\u3002", "result": "\u572832\u4e2a\u8282\u70b9\u7684\u5148\u8fdbSapphire Rapids\u7cfb\u7edf\u4e0a\uff0c\u65b0\u7b97\u6cd5\u76f8\u6bd4\u7cfb\u7edfMPI\u5b9e\u73b0\u4e86\u6700\u9ad83\u500d\u7684\u52a0\u901f\u6bd4\u3002", "conclusion": "\u9488\u5bf9\u65b0\u5174\u591a\u6838\u7cfb\u7edf\u8bbe\u8ba1\u7684\u4e13\u7528all-to-all\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5bf9\u4e8e\u4f9d\u8d56all-to-all\u64cd\u4f5c\u7684\u5e94\u7528\uff08\u5982FFT\u3001\u8f6c\u7f6e\u548c\u673a\u5668\u5b66\u4e60\uff09\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.17007", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17007", "abs": "https://arxiv.org/abs/2601.17007", "authors": ["Beatriz P\u00e9rez-S\u00e1nchez", "Noelia S\u00e1nchez-Maro\u00f1o", "Miguel A. D\u00edaz-Freire"], "title": "Analysis of voice recordings features for Classification of Parkinson's Disease", "comment": null, "summary": "Parkinson's disease (PD) is a chronic neurodegenerative disease. Early diagnosis is essential to mitigate the progressive deterioration of patients' quality of life. The most characteristic motor symptoms are very mild in the early stages, making diagnosis difficult. Recent studies have shown that the use of patient voice recordings can aid in early diagnosis. Although the analysis of such recordings is costly from a clinical point of view, advances in machine learning techniques are making the processing of this type of data increasingly accurate and efficient. Vocal recordings contain many features, but it is not known whether all of them are relevant for diagnosing the disease.\n  This paper proposes the use of different types of machine learning models combined with feature selection methods to detect the disease. The selection techniques allow to reduce the number of features used by the classifiers by determining which ones provide the most information about the problem. The results show that machine learning methods, in particular neural networks, are suitable for PD classification and that the number of features can be significantly reduced without affecting the performance of the models.", "AI": {"tldr": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7ed3\u5408\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u8fdb\u884c\u5e15\u91d1\u68ee\u75c5\u65e9\u671f\u8bca\u65ad\uff0c\u901a\u8fc7\u5206\u6790\u8bed\u97f3\u8bb0\u5f55\u51cf\u5c11\u7279\u5f81\u6570\u91cf\u800c\u4e0d\u5f71\u54cd\u5206\u7c7b\u6027\u80fd", "motivation": "\u5e15\u91d1\u68ee\u75c5\u65e9\u671f\u8bca\u65ad\u56f0\u96be\uff0c\u4f20\u7edf\u65b9\u6cd5\u6210\u672c\u9ad8\uff0c\u9700\u8981\u5229\u7528\u8bed\u97f3\u8bb0\u5f55\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\u5b9e\u73b0\u51c6\u786e\u9ad8\u6548\u7684\u65e9\u671f\u68c0\u6d4b", "method": "\u7ed3\u5408\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0e\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u4ece\u8bed\u97f3\u8bb0\u5f55\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u6280\u672f\u51cf\u5c11\u7279\u5f81\u6570\u91cf\uff0c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u7b49\u5206\u7c7b\u5668\u8fdb\u884c\u75be\u75c5\u68c0\u6d4b", "result": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7279\u522b\u662f\u795e\u7ecf\u7f51\u7edc\u9002\u5408\u5e15\u91d1\u68ee\u75c5\u5206\u7c7b\uff0c\u7279\u5f81\u6570\u91cf\u53ef\u663e\u8457\u51cf\u5c11\u800c\u4e0d\u5f71\u54cd\u6a21\u578b\u6027\u80fd", "conclusion": "\u673a\u5668\u5b66\u4e60\u7ed3\u5408\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u5e15\u91d1\u68ee\u75c5\u7684\u65e9\u671f\u8bca\u65ad\uff0c\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\u540c\u65f6\u4fdd\u6301\u8bca\u65ad\u51c6\u786e\u6027"}}
{"id": "2601.17303", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.17303", "abs": "https://arxiv.org/abs/2601.17303", "authors": ["Samaresh Kumar Singh", "Joyjit Roy"], "title": "Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach", "comment": "9 pages, 8 figures, and Submitted to IEEE SoutheastCon 2026", "summary": "As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital \"immune system\" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u7fa4\u67b6\u6784\uff0c\u7528\u4e8e\u5de5\u4e1a\u7269\u8054\u7f51\u5b89\u5168\u76d1\u63a7\uff0c\u5b9e\u73b0\u4e9a\u6beb\u79d2\u7ea7\u54cd\u5e94\u548c97.3%\u6076\u610f\u6d3b\u52a8\u68c0\u6d4b\u51c6\u786e\u7387", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\u73af\u5883\u6269\u5c55\u5230\u6570\u4e07\u53f0\u8bbe\u5907\u65f6\uff0c\u96c6\u4e2d\u5f0f\u5b89\u5168\u76d1\u63a7\u67b6\u6784\u5b58\u5728\u4e25\u91cd\u5ef6\u8fdf\u95ee\u9898\uff0c\u653b\u51fb\u8005\u53ef\u5229\u7528\u6b64\u6f0f\u6d1e\u7834\u574f\u6574\u4e2a\u5236\u9020\u751f\u6001\u7cfb\u7edf", "method": "\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u7fa4\u67b6\u6784\uff0c\u5728\u6bcf\u4e2a\u8fb9\u7f18\u7f51\u5173\u90e8\u7f72\u81ea\u4e3bAI\u4ee3\u7406\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7P2P\u534f\u8bae\u534f\u4f5c\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\uff0c\u91c7\u7528\u5171\u8bc6\u5f0f\u5a01\u80c1\u9a8c\u8bc1\u6d41\u7a0b\u8fdb\u884c\u6295\u7968\u51b3\u7b56", "result": "\u5728\u6a21\u62df2000\u53f0IIoT\u8bbe\u5907\u7684\u521b\u65b0\u5de5\u5382\u6d4b\u8bd5\u4e2d\uff0cDMAS\u5b9e\u73b0\u5e73\u57470.85ms\u54cd\u5e94\u65f6\u95f4\uff0c\u9ad8\u8d1f\u8f7d\u4e0b\u6076\u610f\u6d3b\u52a8\u68c0\u6d4b\u51c6\u786e\u738797.3%\uff0c\u96f6\u65e5\u653b\u51fb\u68c0\u6d4b\u51c6\u786e\u738787%\uff0c\u7f51\u7edc\u5e26\u5bbd\u4f7f\u7528\u6bd4\u4e91\u65b9\u6848\u51cf\u5c1189%", "conclusion": "DMAS\u67b6\u6784\u663e\u8457\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u8fb9\u7f18\u8ba1\u7b97\u57fa\u7ebf\uff0c\u80fd\u9884\u9632\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u7684\u5b9e\u65f6\u7ea7\u8054\u6545\u969c\uff0c\u4e3a\u5927\u89c4\u6a21IIoT\u7f51\u7edc\u63d0\u4f9b\u9ad8\u6548\u5b89\u5168\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18070", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.18070", "abs": "https://arxiv.org/abs/2601.18070", "authors": ["Jinwu Chen", "Yuhui Shi", "He Wang", "Zhe Jiang", "Jun Yang", "Xin Si", "Zhenhua Zhu"], "title": "CIM-Tuner: Balancing the Compute and Storage Capacity of SRAM-CIM Accelerator via Hardware-mapping Co-exploration", "comment": null, "summary": "As an emerging type of AI computing accelerator, SRAM Computing-In-Memory (CIM) accelerators feature high energy efficiency and throughput. However, various CIM designs and under-explored mapping strategies impede the full exploration of compute and storage balancing in SRAM-CIM accelerator, potentially leading to significant performance degradation. To address this issue, we propose CIM-Tuner, an automatic tool for hardware balancing and optimal mapping strategy under area constraint via hardware-mapping co-exploration. It ensures universality across various CIM designs through a matrix abstraction of CIM macros and a generalized accelerator template. For efficient mapping with different hardware configurations, it employs fine-grained two-level strategies comprising accelerator-level scheduling and macro-level tiling. Compared to prior CIM mapping, CIM-Tuner's extended strategy space achieves 1.58$\\times$ higher energy efficiency and 2.11$\\times$ higher throughput. Applied to SOTA CIM accelerators with identical area budget, CIM-Tuner also delivers comparable improvements. The simulation accuracy is silicon-verified and CIM-Tuner tool is open-sourced at https://github.com/champloo2878/CIM-Tuner.git.", "AI": {"tldr": "CIM-Tuner\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u786c\u4ef6\u5e73\u8861\u548c\u6620\u5c04\u7b56\u7565\u4f18\u5316\u5de5\u5177\uff0c\u901a\u8fc7\u786c\u4ef6-\u6620\u5c04\u534f\u540c\u63a2\u7d22\u6765\u89e3\u51b3SRAM-CIM\u52a0\u901f\u5668\u4e2d\u8ba1\u7b97\u4e0e\u5b58\u50a8\u5e73\u8861\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "SRAM-CIM\u52a0\u901f\u5668\u867d\u7136\u5177\u6709\u9ad8\u80fd\u6548\u548c\u9ad8\u541e\u5410\u91cf\uff0c\u4f46\u5404\u79cd\u4e0d\u540c\u7684CIM\u8bbe\u8ba1\u548c\u672a\u5145\u5206\u63a2\u7d22\u7684\u6620\u5c04\u7b56\u7565\u963b\u788d\u4e86\u5bf9\u8ba1\u7b97\u4e0e\u5b58\u50a8\u5e73\u8861\u7684\u5168\u9762\u63a2\u7d22\uff0c\u53ef\u80fd\u5bfc\u81f4\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faCIM-Tuner\u5de5\u5177\uff0c\u91c7\u7528\u77e9\u9635\u62bd\u8c61CIM\u5b8f\u548c\u901a\u7528\u52a0\u901f\u5668\u6a21\u677f\u786e\u4fdd\u8de8\u8bbe\u8ba1\u901a\u7528\u6027\uff0c\u4f7f\u7528\u7ec6\u7c92\u5ea6\u4e24\u7ea7\u6620\u5c04\u7b56\u7565\uff08\u52a0\u901f\u5668\u7ea7\u8c03\u5ea6\u548c\u5b8f\u7ea7\u5206\u5757\uff09\uff0c\u5728\u9762\u79ef\u7ea6\u675f\u4e0b\u8fdb\u884c\u786c\u4ef6-\u6620\u5c04\u534f\u540c\u63a2\u7d22\u3002", "result": "\u76f8\u6bd4\u73b0\u6709CIM\u6620\u5c04\u65b9\u6cd5\uff0cCIM-Tuner\u6269\u5c55\u7684\u7b56\u7565\u7a7a\u95f4\u5b9e\u73b0\u4e861.58\u500d\u66f4\u9ad8\u7684\u80fd\u6548\u548c2.11\u500d\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u3002\u5e94\u7528\u4e8e\u6700\u5148\u8fdb\u7684CIM\u52a0\u901f\u5668\u65f6\uff0c\u5728\u76f8\u540c\u9762\u79ef\u9884\u7b97\u4e0b\u4e5f\u63d0\u4f9b\u4e86\u76f8\u5f53\u7684\u6539\u8fdb\u3002", "conclusion": "CIM-Tuner\u662f\u4e00\u4e2a\u6709\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u80fd\u591f\u4f18\u5316SRAM-CIM\u52a0\u901f\u5668\u7684\u786c\u4ef6\u5e73\u8861\u548c\u6620\u5c04\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u80fd\u6548\u548c\u541e\u5410\u91cf\uff0c\u4e14\u5df2\u901a\u8fc7\u7845\u9a8c\u8bc1\u5e76\u5f00\u6e90\u3002"}}
{"id": "2601.17707", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17707", "abs": "https://arxiv.org/abs/2601.17707", "authors": ["Mekala Kiran", "Apurba Das", "Suman Banerjee", "Tathagata Ray"], "title": "Multi-core & GPU-based Balanced Butterfly Counting in Signed Bipartite Graphs", "comment": null, "summary": "Balanced butterfly counting, corresponding to counting balanced (2, 2)-bicliques, is a fundamental primitive in the analysis of signed bipartite graphs and provides a basis for studying higher-order structural properties such as clustering coefficients and community structure. Although prior work has proposed an efficient CPU-based serial method for counting balanced (2, k)-bicliques. The computational cost of balanced butterfly counting remains a major bottleneck on large-scale graphs. In this work, we present the highly parallel implementations for balanced butterfly counting for both multicore CPUs and GPUs. The proposed multi-core algorithm (M-BBC) employs fine-grained vertex-level parallelism to accelerate wedge-based counting while eliminating the generation of unbalanced substructures. To improve scalability, we develop a GPU-based method (G-BBC) that uses a tile-based parallel approach to effectively leverage shared memory while handling large vertex sets. We then present an improved variation, G-BBC++, which integrates dynamic scheduling to mitigate workload imbalance and maximize throughput. We conduct an experimental assessment of the proposed methods across 15 real-world datasets. Experimental results exhibit that M-BBC achieves speedups of up to 71.13x (average 38.13x) over the sequential baseline BB2K. The GPU-based algorithms deliver even greater improvements, achieving up to 13,320x speedup (average 2,600x) over BB2K and outperforming M-BBC by up to 186x (average 50x). These results indicate the substantial scalability and efficiency of our parallel algorithms and establish a robust foundation for high-performance signed motif analysis on massive bipartite graphs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u6709\u7b26\u53f7\u4e8c\u5206\u56fe\u7684\u5e73\u8861\u8774\u8776\u8ba1\u6570\u5e76\u884c\u7b97\u6cd5\uff0c\u5305\u62ec\u591a\u6838CPU\u7684M-BBC\u548cGPU\u7684G-BBC/G-BBC++\uff0c\u572815\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad813,320\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u5e73\u8861\u8774\u8776\u8ba1\u6570\u662f\u5206\u6790\u6709\u7b26\u53f7\u4e8c\u5206\u56fe\u7684\u57fa\u7840\u539f\u8bed\uff0c\u7528\u4e8e\u7814\u7a76\u9ad8\u9636\u7ed3\u6784\u7279\u6027\u5982\u805a\u7c7b\u7cfb\u6570\u548c\u793e\u533a\u7ed3\u6784\u3002\u5c3d\u7ba1\u5df2\u6709CPU\u4e32\u884c\u65b9\u6cd5\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u7684\u8ba1\u7b97\u6210\u672c\u4ecd\u7136\u662f\u4e3b\u8981\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u591a\u6838CPU\u7b97\u6cd5M-BBC\u91c7\u7528\u7ec6\u7c92\u5ea6\u9876\u70b9\u7ea7\u5e76\u884c\u52a0\u901f\u6954\u5f62\u8ba1\u6570\uff0c\u6d88\u9664\u4e0d\u5e73\u8861\u5b50\u7ed3\u6784\u751f\u6210\uff1bGPU\u65b9\u6cd5G-BBC\u4f7f\u7528\u57fa\u4e8etile\u7684\u5e76\u884c\u65b9\u6cd5\u6709\u6548\u5229\u7528\u5171\u4eab\u5185\u5b58\uff1b\u6539\u8fdb\u7248G-BBC++\u96c6\u6210\u52a8\u6001\u8c03\u5ea6\u7f13\u89e3\u8d1f\u8f7d\u4e0d\u5747\u8861\u3002", "result": "M-BBC\u76f8\u6bd4\u4e32\u884c\u57fa\u7ebfBB2K\u5b9e\u73b0\u6700\u9ad871.13\u500d\uff08\u5e73\u574738.13\u500d\uff09\u52a0\u901f\uff1bGPU\u7b97\u6cd5\u5b9e\u73b0\u6700\u9ad813,320\u500d\uff08\u5e73\u57472,600\u500d\uff09\u52a0\u901f\uff0c\u76f8\u6bd4M-BBC\u6700\u9ad8186\u500d\uff08\u5e73\u574750\u500d\uff09\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e76\u884c\u7b97\u6cd5\u5177\u6709\u663e\u8457\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u4e8c\u5206\u56fe\u4e0a\u7684\u9ad8\u6027\u80fd\u6709\u7b26\u53f7\u6a21\u4f53\u5206\u6790\u5efa\u7acb\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2601.17008", "categories": ["cs.LG", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.17008", "abs": "https://arxiv.org/abs/2601.17008", "authors": ["Haochong Xia", "Simin Li", "Ruixiao Xu", "Zhixia Zhang", "Hongxiang Wang", "Zhiqian Liu", "Teng Yao Long", "Molei Qin", "Chuqiao Zong", "Bo An"], "title": "Bayesian Robust Financial Trading with Adversarial Synthetic Market Data", "comment": null, "summary": "Algorithmic trading relies on machine learning models to make trading decisions. Despite strong in-sample performance, these models often degrade when confronted with evolving real-world market regimes, which can shift dramatically due to macroeconomic changes-e.g., monetary policy updates or unanticipated fluctuations in participant behavior. We identify two challenges that perpetuate this mismatch: (1) insufficient robustness in existing policy against uncertainties in high-level market fluctuations, and (2) the absence of a realistic and diverse simulation environment for training, leading to policy overfitting. To address these issues, we propose a Bayesian Robust Framework that systematically integrates a macro-conditioned generative model with robust policy learning. On the data side, to generate realistic and diverse data, we propose a macro-conditioned GAN-based generator that leverages macroeconomic indicators as primary control variables, synthesizing data with faithful temporal, cross-instrument, and macro correlations. On the policy side, to learn robust policy against market fluctuations, we cast the trading process as a two-player zero-sum Bayesian Markov game, wherein an adversarial agent simulates shifting regimes by perturbing macroeconomic indicators in the macro-conditioned generator, while the trading agent-guided by a quantile belief network-maintains and updates its belief over hidden market states. The trading agent seeks a Robust Perfect Bayesian Equilibrium via Bayesian neural fictitious self-play, stabilizing learning under adversarial market perturbations. Extensive experiments on 9 financial instruments demonstrate that our framework outperforms 9 state-of-the-art baselines. In extreme events like the COVID, our method shows improved profitability and risk management, offering a reliable solution for trading under uncertain and shifting market dynamics.", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af\u9c81\u68d2\u6846\u67b6\uff0c\u901a\u8fc7\u5b8f\u89c2\u6761\u4ef6GAN\u751f\u6210\u591a\u6837\u5316\u5e02\u573a\u6570\u636e\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u5b66\u4e60\u9c81\u68d2\u4ea4\u6613\u7b56\u7565\uff0c\u5728\u52a8\u6001\u5e02\u573a\u73af\u5883\u4e2d\u63d0\u5347\u4ea4\u6613\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u4ea4\u6613\u6a21\u578b\u5728\u6837\u672c\u5185\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9762\u5bf9\u771f\u5b9e\u5e02\u573a\u52a8\u6001\u53d8\u5316\u65f6\u6027\u80fd\u4e0b\u964d\u3002\u4e3b\u8981\u95ee\u9898\u5305\u62ec\uff1a\u73b0\u6709\u7b56\u7565\u5bf9\u9ad8\u5c42\u6b21\u5e02\u573a\u6ce2\u52a8\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u771f\u5b9e\u591a\u6837\u7684\u6a21\u62df\u8bad\u7ec3\u73af\u5883\u5bfc\u81f4\u7b56\u7565\u8fc7\u62df\u5408\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u9c81\u68d2\u6846\u67b6\uff1a1) \u6570\u636e\u4fa7\uff1a\u4f7f\u7528\u5b8f\u89c2\u6761\u4ef6GAN\u751f\u6210\u5668\uff0c\u4ee5\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u4e3a\u4e3b\u8981\u63a7\u5236\u53d8\u91cf\uff0c\u5408\u6210\u5177\u6709\u771f\u5b9e\u65f6\u95f4\u3001\u8de8\u5de5\u5177\u548c\u5b8f\u89c2\u76f8\u5173\u6027\u7684\u6570\u636e\uff1b2) \u7b56\u7565\u4fa7\uff1a\u5c06\u4ea4\u6613\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u4e24\u4eba\u96f6\u548c\u8d1d\u53f6\u65af\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff0c\u5bf9\u6297\u4ee3\u7406\u901a\u8fc7\u6270\u52a8\u5b8f\u89c2\u6307\u6807\u6a21\u62df\u5e02\u573a\u53d8\u5316\uff0c\u4ea4\u6613\u4ee3\u7406\u901a\u8fc7\u5206\u4f4d\u6570\u4fe1\u5ff5\u7f51\u7edc\u7ef4\u62a4\u548c\u66f4\u65b0\u5bf9\u9690\u85cf\u5e02\u573a\u72b6\u6001\u7684\u4fe1\u5ff5\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u795e\u7ecf\u865a\u6784\u81ea\u535a\u5f08\u5bfb\u6c42\u9c81\u68d2\u5b8c\u7f8e\u8d1d\u53f6\u65af\u5747\u8861\u3002", "result": "\u57289\u79cd\u91d1\u878d\u5de5\u5177\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u4f18\u4e8e9\u79cd\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u5728COVID\u7b49\u6781\u7aef\u4e8b\u4ef6\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u793a\u51fa\u6539\u8fdb\u7684\u76c8\u5229\u80fd\u529b\u548c\u98ce\u9669\u7ba1\u7406\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0d\u786e\u5b9a\u548c\u53d8\u5316\u7684\u5e02\u573a\u52a8\u6001\u4e0b\u7684\u4ea4\u6613\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7cfb\u7edf\u6574\u5408\u5b8f\u89c2\u6761\u4ef6\u751f\u6210\u6a21\u578b\u548c\u9c81\u68d2\u7b56\u7565\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\u4ea4\u6613\u6a21\u578b\u5728\u52a8\u6001\u5e02\u573a\u73af\u5883\u4e2d\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002"}}
{"id": "2601.17754", "categories": ["cs.DC", "cs.ET", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.17754", "abs": "https://arxiv.org/abs/2601.17754", "authors": ["Nicolai Stawinoga", "David Katz", "Anton Lydike", "Justs Zarins", "Nick Brown", "George Bisbas", "Tobias Grosser"], "title": "An MLIR Lowering Pipeline for Stencils at Wafer-Scale", "comment": "Paper in ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS '26)", "summary": "The Cerebras Wafer-Scale Engine (WSE) delivers performance at an unprecedented scale of over 900,000 compute units, all connected via a single-wafer on-chip interconnect. Initially designed for AI, the WSE architecture is also well-suited for High Performance Computing (HPC). However, its distributed asynchronous programming model diverges significantly from the simple sequential or bulk-synchronous programs that one would typically derive for a given mathematical program description. Targeting the WSE requires a bespoke re-implementation when porting existing code. The absence of WSE support in compilers such as MLIR, meant that there was little hope for automating this process.\n  Stencils are ubiquitous in HPC, and in this paper we explore the hypothesis that domain specific information about stencils can be leveraged by the compiler to automatically target the WSE without requiring application-level code changes. We present a compiler pipeline that transforms stencil-based kernels into highly optimized CSL code for the WSE, bridging the semantic gap between the mathematical representation of the problem and the WSE's asynchronous execution model. Based upon five benchmarks across three HPC programming technologies, running on both the Cerebras WSE2 and WSE3, our approach delivers comparable, if not slightly better, performance than manually optimized code. Furthermore, without requiring any application level code changes, performance on the WSE3 is around 14 times faster than 128 Nvidia A100 GPUs and 20 times faster than 128 nodes of a CPU-based Cray-EX supercomputer when using our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7f16\u8bd1\u5668\u6d41\u6c34\u7ebf\uff0c\u80fd\u5c06stencil\u8ba1\u7b97\u81ea\u52a8\u8f6c\u6362\u4e3a\u9488\u5bf9Cerebras WSE\u4f18\u5316\u7684\u4ee3\u7801\uff0c\u65e0\u9700\u4fee\u6539\u5e94\u7528\u5c42\u4ee3\u7801\uff0c\u6027\u80fd\u8d85\u8d8aGPU\u548cCPU\u96c6\u7fa4\u3002", "motivation": "Cerebras WSE\u867d\u7136\u6027\u80fd\u5f3a\u5927\uff0c\u4f46\u5176\u5206\u5e03\u5f0f\u5f02\u6b65\u7f16\u7a0b\u6a21\u578b\u4e0e\u4f20\u7edf\u987a\u5e8f\u6216BSP\u7a0b\u5e8f\u5dee\u5f02\u5f88\u5927\uff0c\u79fb\u690d\u73b0\u6709\u4ee3\u7801\u9700\u8981\u5927\u91cf\u624b\u5de5\u91cd\u5199\u3002\u7f16\u8bd1\u5668\u7f3a\u4e4fWSE\u652f\u6301\uff0c\u81ea\u52a8\u5316\u8f6c\u6362\u56f0\u96be\u3002", "method": "\u5229\u7528stencil\u8ba1\u7b97\u7684\u9886\u57df\u7279\u5b9a\u4fe1\u606f\uff0c\u8bbe\u8ba1\u7f16\u8bd1\u5668\u6d41\u6c34\u7ebf\u5c06stencil\u5185\u6838\u81ea\u52a8\u8f6c\u6362\u4e3a\u9ad8\u5ea6\u4f18\u5316\u7684CSL\u4ee3\u7801\uff0c\u5f25\u5408\u95ee\u9898\u6570\u5b66\u8868\u793a\u4e0eWSE\u5f02\u6b65\u6267\u884c\u6a21\u578b\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u3002", "result": "\u5728WSE2\u548cWSE3\u4e0a\u6d4b\u8bd55\u4e2a\u57fa\u51c6\u7a0b\u5e8f\uff0c\u6027\u80fd\u4e0e\u624b\u5de5\u4f18\u5316\u4ee3\u7801\u76f8\u5f53\u6216\u7565\u4f18\u3002WSE3\u6027\u80fd\u6bd4128\u4e2aNvidia A100 GPU\u5feb\u7ea614\u500d\uff0c\u6bd4128\u4e2aCPU\u8282\u70b9\u7684Cray-EX\u8d85\u7b97\u5feb20\u500d\u3002", "conclusion": "\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u7f16\u8bd1\u5668\u6280\u672f\uff0c\u53ef\u4ee5\u81ea\u52a8\u5c06stencil\u8ba1\u7b97\u9ad8\u6548\u6620\u5c04\u5230WSE\u67b6\u6784\uff0c\u65e0\u9700\u5e94\u7528\u5c42\u4ee3\u7801\u4fee\u6539\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u7b80\u5316\u79fb\u690d\u8fc7\u7a0b\u3002"}}
{"id": "2601.18140", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.18140", "abs": "https://arxiv.org/abs/2601.18140", "authors": ["Yan Zhu", "Boru Chen", "Christopher W. Fletcher", "Nandeeka Nayak"], "title": "RTeAAL Sim: Using Tensor Algebra to Represent and Accelerate RTL Simulation (Extended Version)", "comment": null, "summary": "RTL simulation on CPUs remains a persistent bottleneck in hardware design. State-of-the-art simulators embed the circuit directly into the simulation binary, resulting in long compilation times and execution that is fundamentally CPU frontend-bound, with severe instruction-cache pressure.\n  This work proposes RTeAAL Sim, which reformulates RTL simulation as a sparse tensor algebra problem. By representing RTL circuits as tensors and simulation as a sparse tensor algebra kernel, RTeAAL Sim decouples simulation behavior from binary size and makes RTL simulation amenable to well-studied tensor algebra optimizations. We demonstrate that a prototype of our tensor-based simulator, even with a subset of these optimizations, already mitigates the compilation overhead and frontend pressure and achieves performance competitive with the highly optimized Verilator simulator across multiple CPUs and ISAs.", "AI": {"tldr": "RTeAAL Sim\u5c06RTL\u4eff\u771f\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7a00\u758f\u5f20\u91cf\u4ee3\u6570\u95ee\u9898\uff0c\u901a\u8fc7\u5f20\u91cf\u8868\u793a\u7535\u8def\u548c\u4eff\u771f\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4eff\u771f\u5668\u7f16\u8bd1\u65f6\u95f4\u957f\u3001CPU\u524d\u7aef\u74f6\u9888\u548c\u6307\u4ee4\u7f13\u5b58\u538b\u529b\u5927\u7684\u95ee\u9898\u3002", "motivation": "CPU\u4e0a\u7684RTL\u4eff\u771f\u4ecd\u7136\u662f\u786c\u4ef6\u8bbe\u8ba1\u7684\u74f6\u9888\u3002\u73b0\u6709\u4eff\u771f\u5668\u5c06\u7535\u8def\u76f4\u63a5\u5d4c\u5165\u4eff\u771f\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u5bfc\u81f4\u7f16\u8bd1\u65f6\u95f4\u957f\uff0c\u6267\u884c\u65f6\u53d7CPU\u524d\u7aef\u9650\u5236\uff0c\u4e14\u6307\u4ee4\u7f13\u5b58\u538b\u529b\u5927\u3002", "method": "\u5c06RTL\u4eff\u771f\u91cd\u65b0\u8868\u8ff0\u4e3a\u7a00\u758f\u5f20\u91cf\u4ee3\u6570\u95ee\u9898\uff1a\u5c06RTL\u7535\u8def\u8868\u793a\u4e3a\u5f20\u91cf\uff0c\u4eff\u771f\u8fc7\u7a0b\u4f5c\u4e3a\u7a00\u758f\u5f20\u91cf\u4ee3\u6570\u5185\u6838\u3002\u8fd9\u79cd\u65b9\u6cd5\u5c06\u4eff\u771f\u884c\u4e3a\u4e0e\u4e8c\u8fdb\u5236\u5927\u5c0f\u89e3\u8026\uff0c\u5e76\u4f7f\u5176\u9002\u7528\u4e8e\u6210\u719f\u7684\u5f20\u91cf\u4ee3\u6570\u4f18\u5316\u6280\u672f\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5373\u4f7f\u53ea\u5e94\u7528\u4e86\u90e8\u5206\u4f18\u5316\uff0c\u5df2\u7ecf\u80fd\u591f\u7f13\u89e3\u7f16\u8bd1\u5f00\u9500\u548c\u524d\u7aef\u538b\u529b\uff0c\u5728\u591a\u79cdCPU\u548cISA\u4e0a\u8fbe\u5230\u4e86\u4e0e\u9ad8\u5ea6\u4f18\u5316\u7684Verilator\u4eff\u771f\u5668\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5c06RTL\u4eff\u771f\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5f20\u91cf\u4ee3\u6570\u95ee\u9898\uff0cRTeAAL Sim\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u4f20\u7edf\u4eff\u771f\u5668\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u786c\u4ef6\u4eff\u771f\u5f00\u8f9f\u4e86\u65b0\u7684\u4f18\u5316\u9014\u5f84\u3002"}}
{"id": "2601.17010", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.17010", "abs": "https://arxiv.org/abs/2601.17010", "authors": ["Hudson Golino"], "title": "Optimizing the Landscape of LLM Embeddings with Dynamic Exploratory Graph Analysis for Generative Psychometrics: A Monte Carlo Study", "comment": "18 pages, 6 figures, conference paper", "summary": "Large language model (LLM) embeddings are increasingly used to estimate dimensional structure in psychological item pools prior to data collection, yet current applications treat embeddings as static, cross-sectional representations. This approach implicitly assumes uniform contribution across all embedding coordinates and overlooks the possibility that optimal structural information may be concentrated in specific regions of the embedding space. This study reframes embeddings as searchable landscapes and adapts Dynamic Exploratory Graph Analysis (DynEGA) to systematically traverse embedding coordinates, treating the dimension index as a pseudo-temporal ordering analogous to intensive longitudinal trajectories. A large-scale Monte Carlo simulation embedded items representing five dimensions of grandiose narcissism using OpenAI's text-embedding-3-small model, generating network estimations across systematically varied item pool sizes (3-40 items per dimension) and embedding depths (3-1,298 dimensions). Results reveal that Total Entropy Fit Index (TEFI) and Normalized Mutual Information (NMI) leads to competing optimization trajectories across the embedding landscape. TEFI achieves minima at deep embedding ranges (900--1,200 dimensions) where entropy-based organization is maximal but structural accuracy degrades, whereas NMI peaks at shallow depths where dimensional recovery is strongest but entropy-based fit remains suboptimal. Single-metric optimization produces structurally incoherent solutions, whereas a weighted composite criterion identifies embedding dimensions depth regions that jointly balance accuracy and organization. Optimal embedding depth scales systematically with item pool size. These findings establish embedding landscapes as non-uniform semantic spaces requiring principled optimization rather than default full-vector usage.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u5c06LLM\u5d4c\u5165\u89c6\u4e3a\u53ef\u641c\u7d22\u7684\u8bed\u4e49\u7a7a\u95f4\uff0c\u901a\u8fc7\u52a8\u6001\u63a2\u7d22\u56fe\u5206\u6790\u5728\u5d4c\u5165\u7ef4\u5ea6\u4e2d\u5bfb\u627e\u6700\u4f18\u7ed3\u6784\u4fe1\u606f\uff0c\u53d1\u73b0\u4e0d\u540c\u6307\u6807\u5728\u5d4c\u5165\u6df1\u5ea6\u4e0a\u5b58\u5728\u7ade\u4e89\u4f18\u5316\u8f68\u8ff9", "motivation": "\u5f53\u524d\u4f7f\u7528LLM\u5d4c\u5165\u4f30\u8ba1\u5fc3\u7406\u9879\u76ee\u7ef4\u5ea6\u7ed3\u6784\u65f6\uff0c\u5c06\u5d4c\u5165\u89c6\u4e3a\u9759\u6001\u3001\u6a2a\u622a\u9762\u7684\u8868\u793a\uff0c\u5047\u8bbe\u6240\u6709\u5d4c\u5165\u5750\u6807\u8d21\u732e\u5747\u5300\uff0c\u5ffd\u7565\u4e86\u6700\u4f18\u7ed3\u6784\u4fe1\u606f\u53ef\u80fd\u96c6\u4e2d\u5728\u5d4c\u5165\u7a7a\u95f4\u7279\u5b9a\u533a\u57df\u7684\u53ef\u80fd\u6027", "method": "\u5c06\u5d4c\u5165\u91cd\u6784\u4e3a\u53ef\u641c\u7d22\u7684\u666f\u89c2\uff0c\u91c7\u7528\u52a8\u6001\u63a2\u7d22\u56fe\u5206\u6790(DynEGA)\u7cfb\u7edf\u904d\u5386\u5d4c\u5165\u5750\u6807\uff0c\u5c06\u7ef4\u5ea6\u7d22\u5f15\u89c6\u4e3a\u7c7b\u4f3c\u5bc6\u96c6\u7eb5\u5411\u8f68\u8ff9\u7684\u4f2a\u65f6\u95f4\u987a\u5e8f\u3002\u4f7f\u7528OpenAI\u7684text-embedding-3-small\u6a21\u578b\u5bf9\u4ee3\u8868\u81ea\u604b\u4e94\u4e2a\u7ef4\u5ea6\u7684\u9879\u76ee\u8fdb\u884c\u5927\u89c4\u6a21\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff0c\u5728\u4e0d\u540c\u9879\u76ee\u6c60\u5927\u5c0f(\u6bcf\u4e2a\u7ef4\u5ea63-40\u4e2a\u9879\u76ee)\u548c\u5d4c\u5165\u6df1\u5ea6(3-1,298\u7ef4\u5ea6)\u4e0b\u751f\u6210\u7f51\u7edc\u4f30\u8ba1", "result": "\u603b\u71b5\u62df\u5408\u6307\u6570(TEFI)\u548c\u5f52\u4e00\u5316\u4e92\u4fe1\u606f(NMI)\u5728\u5d4c\u5165\u666f\u89c2\u4e2d\u5448\u73b0\u7ade\u4e89\u4f18\u5316\u8f68\u8ff9\uff1aTEFI\u5728\u6df1\u5c42\u5d4c\u5165\u8303\u56f4(900-1200\u7ef4\u5ea6)\u8fbe\u5230\u6700\u5c0f\u503c\uff0c\u6b64\u65f6\u57fa\u4e8e\u71b5\u7684\u7ec4\u7ec7\u6700\u5927\u5316\u4f46\u7ed3\u6784\u51c6\u786e\u6027\u4e0b\u964d\uff1bNMI\u5728\u6d45\u5c42\u6df1\u5ea6\u8fbe\u5230\u5cf0\u503c\uff0c\u6b64\u65f6\u7ef4\u5ea6\u6062\u590d\u6700\u5f3a\u4f46\u57fa\u4e8e\u71b5\u7684\u62df\u5408\u4ecd\u4e0d\u7406\u60f3\u3002\u5355\u6307\u6807\u4f18\u5316\u4ea7\u751f\u7ed3\u6784\u4e0d\u8fde\u8d2f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u52a0\u6743\u590d\u5408\u6807\u51c6\u80fd\u8bc6\u522b\u540c\u65f6\u5e73\u8861\u51c6\u786e\u6027\u548c\u7ec4\u7ec7\u7684\u5d4c\u5165\u7ef4\u5ea6\u6df1\u5ea6\u533a\u57df\u3002\u6700\u4f18\u5d4c\u5165\u6df1\u5ea6\u968f\u9879\u76ee\u6c60\u5927\u5c0f\u7cfb\u7edf\u7f29\u653e", "conclusion": "\u5d4c\u5165\u666f\u89c2\u662f\u975e\u5747\u5300\u7684\u8bed\u4e49\u7a7a\u95f4\uff0c\u9700\u8981\u539f\u5219\u6027\u4f18\u5316\u800c\u975e\u9ed8\u8ba4\u4f7f\u7528\u5b8c\u6574\u5411\u91cf\u3002\u7814\u7a76\u5efa\u7acb\u4e86\u5728\u5d4c\u5165\u7ef4\u5ea6\u4e2d\u5bfb\u627e\u6700\u4f18\u7ed3\u6784\u4fe1\u606f\u7684\u65b9\u6cd5\u8bba\u6846\u67b6"}}
{"id": "2601.18159", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.18159", "abs": "https://arxiv.org/abs/2601.18159", "authors": ["Zizhen Liu", "Fangzhiyi Wang", "Mengdi Wang", "Jing Ye", "Hayden Kwok-Hay So", "Cheng Liu", "Huawei Li"], "title": "Lifecycle Cost-Effectiveness Modeling for Redundancy-Enhanced Multi-Chiplet Architectures", "comment": null, "summary": "The growing demand for compute-intensive applications has made multi-chiplet architectures a promising alternative to monolithic designs, offering improved scalability and manufacturing flexibility. However, effectively managing the economic effectiveness remains challenging. Existing cost models either overlook the amortization of compute value over a chip's operational lifetime or fail to evaluate how redundancy strategies, which are widely adopted to enhance yield and fault tolerance, impact long-term cost efficiency. This paper presents a comprehensive cost-effectiveness framework for multi-chiplet architectures, introducing a novel Lifecycle Cost Effectiveness (LCE) metric that evaluates amortized compute costs by jointly optimizing manufacturing expenses and operational lifetime. Our approach uniquely integrates: (1) redundancy-aware cost modeling spanning both intra- and inter-chiplet levels, (2) reliability-driven lifetime estimation, and (3) quantitative analysis of how redundancy configurations on overall economic effectiveness. Extensive trade-off and multi-objective optimization studies demonstrate the effectiveness of the model and reveal essential co-optimization strategies between module and chiplet-level redundancy to achieve cost-efficient multi-chiplet architecture designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u82af\u7247\u67b6\u6784\u7684\u751f\u547d\u5468\u671f\u6210\u672c\u6548\u76ca\u6846\u67b6\uff0c\u5f15\u5165LCE\u6307\u6807\u6765\u8bc4\u4f30\u644a\u9500\u8ba1\u7b97\u6210\u672c\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5236\u9020\u8d39\u7528\u548c\u8fd0\u884c\u5bff\u547d\uff0c\u5e76\u6574\u5408\u5197\u4f59\u611f\u77e5\u6210\u672c\u5efa\u6a21\u548c\u53ef\u9760\u6027\u9a71\u52a8\u7684\u5bff\u547d\u4f30\u8ba1\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u5bc6\u96c6\u578b\u5e94\u7528\u9700\u6c42\u589e\u957f\uff0c\u591a\u82af\u7247\u67b6\u6784\u6210\u4e3a\u6709\u524d\u666f\u7684\u5355\u7247\u8bbe\u8ba1\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u6709\u6548\u7ba1\u7406\u7ecf\u6d4e\u6548\u7387\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u6210\u672c\u6a21\u578b\u8981\u4e48\u5ffd\u7565\u4e86\u82af\u7247\u8fd0\u884c\u5bff\u547d\u671f\u95f4\u8ba1\u7b97\u4ef7\u503c\u7684\u644a\u9500\uff0c\u8981\u4e48\u672a\u80fd\u8bc4\u4f30\u5e7f\u6cdb\u91c7\u7528\u7684\u5197\u4f59\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u957f\u671f\u6210\u672c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u591a\u82af\u7247\u67b6\u6784\u6210\u672c\u6548\u76ca\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u9896\u7684\u751f\u547d\u5468\u671f\u6210\u672c\u6548\u76ca(LCE)\u6307\u6807\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5236\u9020\u8d39\u7528\u548c\u8fd0\u884c\u5bff\u547d\u6765\u8bc4\u4f30\u644a\u9500\u8ba1\u7b97\u6210\u672c\u3002\u8be5\u65b9\u6cd5\u72ec\u7279\u5730\u6574\u5408\u4e86\uff1a(1) \u6db5\u76d6\u82af\u7247\u5185\u548c\u82af\u7247\u95f4\u7ea7\u522b\u7684\u5197\u4f59\u611f\u77e5\u6210\u672c\u5efa\u6a21\uff0c(2) \u53ef\u9760\u6027\u9a71\u52a8\u7684\u5bff\u547d\u4f30\u8ba1\uff0c(3) \u5197\u4f59\u914d\u7f6e\u5bf9\u6574\u4f53\u7ecf\u6d4e\u6548\u76ca\u7684\u5b9a\u91cf\u5206\u6790\u3002", "result": "\u5e7f\u6cdb\u7684\u6743\u8861\u7814\u7a76\u548c\u591a\u76ee\u6807\u4f18\u5316\u7814\u7a76\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u5757\u7ea7\u548c\u82af\u7247\u7ea7\u5197\u4f59\u4e4b\u95f4\u7684\u5fc5\u8981\u534f\u540c\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u6210\u672c\u9ad8\u6548\u7684\u591a\u82af\u7247\u67b6\u6784\u8bbe\u8ba1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u82af\u7247\u67b6\u6784\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6210\u672c\u6548\u76ca\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u5197\u4f59\u7b56\u7565\u548c\u5bff\u547d\u8003\u8651\uff0c\u63ed\u793a\u4e86\u5b9e\u73b0\u7ecf\u6d4e\u9ad8\u6548\u8bbe\u8ba1\u7684\u5173\u952e\u534f\u540c\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2601.17774", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17774", "abs": "https://arxiv.org/abs/2601.17774", "authors": ["Zizhao Zhang", "Yihan Xue", "Haotian Zhu", "Sijia Li", "Zhijun Wang", "Yujie Xiao"], "title": "CondenseGraph: Communication-Efficient Distributed GNN Training via On-the-Fly Graph Condensation", "comment": null, "summary": "Distributed Graph Neural Network (GNN) training suffers from substantial communication overhead due to the inherent neighborhood dependency in graph-structured data. This neighbor explosion problem requires workers to frequently exchange boundary node features across partitions, creating a communication bottleneck that severely limits training scalability. Existing approaches rely on static graph partitioning strategies that cannot adapt to dynamic network conditions. In this paper, we propose CondenseGraph, a novel communication-efficient framework for distributed GNN training. Our key innovation is an on-the-fly graph condensation mechanism that dynamically compresses boundary node features into compact super nodes before transmission. To compensate for the information loss introduced by compression, we develop a gradient-based error feedback mechanism that maintains convergence guarantees while reducing communication volume by 40-60%. Extensive experiments on four benchmark datasets demonstrate that CondenseGraph achieves comparable accuracy to full-precision baselines while significantly reducing communication costs and training time.", "AI": {"tldr": "CondenseGraph\u901a\u8fc7\u52a8\u6001\u56fe\u538b\u7f29\u548c\u68af\u5ea6\u8bef\u5dee\u53cd\u9988\u673a\u5236\uff0c\u5728\u5206\u5e03\u5f0fGNN\u8bad\u7ec3\u4e2d\u51cf\u5c1140-60%\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u5206\u5e03\u5f0f\u56fe\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u5b58\u5728\u4e25\u91cd\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u7531\u4e8e\u56fe\u6570\u636e\u7684\u90bb\u57df\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u9891\u7e41\u4ea4\u6362\u8fb9\u754c\u8282\u70b9\u7279\u5f81\uff0c\u73b0\u6709\u9759\u6001\u56fe\u5206\u533a\u65b9\u6cd5\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u7f51\u7edc\u6761\u4ef6\u3002", "method": "\u63d0\u51faCondenseGraph\u6846\u67b6\uff0c\u5305\u542b\u52a8\u6001\u56fe\u538b\u7f29\u673a\u5236\uff08\u5c06\u8fb9\u754c\u8282\u70b9\u7279\u5f81\u538b\u7f29\u4e3a\u7d27\u51d1\u8d85\u8282\u70b9\uff09\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u8bef\u5dee\u53cd\u9988\u673a\u5236\uff08\u8865\u507f\u538b\u7f29\u5e26\u6765\u7684\u4fe1\u606f\u635f\u5931\uff09\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCondenseGraph\u5728\u4fdd\u6301\u4e0e\u5168\u7cbe\u5ea6\u57fa\u7ebf\u76f8\u5f53\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u548c\u8bad\u7ec3\u65f6\u95f4\uff0c\u901a\u4fe1\u91cf\u51cf\u5c1140-60%\u3002", "conclusion": "CondenseGraph\u901a\u8fc7\u521b\u65b0\u7684\u52a8\u6001\u538b\u7f29\u548c\u8bef\u5dee\u53cd\u9988\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0fGNN\u8bad\u7ec3\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u6548\u7387\u4e0e\u6a21\u578b\u7cbe\u5ea6\u7684\u5e73\u8861\u3002"}}
{"id": "2601.17063", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17063", "abs": "https://arxiv.org/abs/2601.17063", "authors": ["Byeongju Kim", "Jungwan Lee", "Donghyeon Han", "Hoi-Jun Yoo", "Sangyeob Kim"], "title": "FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices", "comment": null, "summary": "Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.", "AI": {"tldr": "FlashMoE\u662f\u4e00\u4e2a\u5c06\u4e0d\u6d3b\u8dc3\u4e13\u5bb6\u5378\u8f7d\u5230SSD\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u6709\u9650RAM\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684MoE\u63a8\u7406\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7ML\u7f13\u5b58\u7b56\u7565\u63d0\u5347\u4e13\u5bb6\u91cd\u7528\u7387\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u5b9e\u73b0\u6700\u9ad82.6\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709MoE\u63a8\u7406\u7cfb\u7edf\uff08\u5982Fiddler\u3001DAOP\uff09\u4f9d\u8d56DRAM\u5378\u8f7d\uff0c\u4e0d\u9002\u5408\u5185\u5b58\u53d7\u9650\u7684\u79fb\u52a8\u8bbe\u5907\u73af\u5883\u3002\u968f\u7740MoE\u6a21\u578b\u589e\u957f\u5230\u6570\u767eGB\uff0cRAM\u5378\u8f7d\u65b9\u6848\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFlashMoE\u7cfb\u7edf\uff0c\u5c06\u4e0d\u6d3b\u8dc3\u4e13\u5bb6\u5378\u8f7d\u5230SSD\uff1b\u91c7\u7528\u8f7b\u91cf\u7ea7\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7f13\u5b58\u7b56\u7565\uff0c\u81ea\u9002\u5e94\u7ed3\u5408\u6700\u8fd1\u4f7f\u7528\u548c\u9891\u7387\u4fe1\u53f7\u4ee5\u6700\u5927\u5316\u4e13\u5bb6\u91cd\u7528\uff1b\u6784\u5efa\u7528\u6237\u7ea7\u684c\u9762\u5e73\u53f0\u9a8c\u8bc1\u5b9e\u7528\u6027\u3002", "result": "\u5728\u771f\u5b9e\u786c\u4ef6\u8bbe\u7f6e\u4e0a\uff0cFlashMoE\u76f8\u6bd4LRU\u548cLFU\u7b49\u5e38\u89c1\u5378\u8f7d\u7b56\u7565\u63d0\u5347\u7f13\u5b58\u547d\u4e2d\u7387\u6700\u9ad8\u8fbe51%\uff1b\u76f8\u6bd4\u73b0\u6709MoE\u63a8\u7406\u7cfb\u7edf\u5b9e\u73b0\u6700\u9ad82.6\u500d\u52a0\u901f\u3002", "conclusion": "FlashMoE\u901a\u8fc7SSD\u5378\u8f7d\u548c\u667a\u80fd\u7f13\u5b58\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u6a21\u578bMoE\u5728\u5185\u5b58\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u63a8\u7406\u95ee\u9898\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u5927\u89c4\u6a21MoE\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.18702", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.18702", "abs": "https://arxiv.org/abs/2601.18702", "authors": ["Hansheng Ren"], "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic", "comment": "8 pages, 6 figures. Submitted to UAI 2026", "summary": "Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u4f18\u5148\u8ba1\u7b97\u541e\u5410\u91cf\u800c\u975e\u6570\u503c\u7cbe\u5ea6\u7684\u8303\u5f0f\uff0c\u63d0\u51fa\u7cbe\u786e\u6027\u5047\u8bf4\uff1a\u901a\u7528\u667a\u80fd\u9700\u8981\u4efb\u610f\u7cbe\u5ea6\u7b97\u672f\u8ba1\u7b97\u57fa\u677f\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u6709\u7406\u6570\u7b97\u672f\u7684Halo\u67b6\u6784\u6765\u51cf\u5c11\u903b\u8f91\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u8303\u5f0f\u8fc7\u4e8e\u5173\u6ce8\u8ba1\u7b97\u541e\u5410\u91cf\u800c\u5ffd\u89c6\u6570\u503c\u7cbe\u5ea6\uff0c\u5047\u8bbe\u667a\u80fd\u6765\u81ea\u5927\u89c4\u6a21\u7edf\u8ba1\u76f8\u5173\u6027\u3002\u4f5c\u8005\u8ba4\u4e3a\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\"\u5e7b\u89c9\"\u548c\u903b\u8f91\u4e0d\u4e00\u81f4\u662fIEEE 754\u6d6e\u70b9\u6570\u8fd1\u4f3c\u8bef\u5dee\u5728\u6df1\u5ea6\u7ec4\u5408\u51fd\u6570\u4e2d\u7d2f\u79ef\u7684\u7ed3\u679c\uff0c\u9700\u8981\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7cbe\u786e\u6027\u5047\u8bf4\uff0c\u8ba4\u4e3a\u901a\u7528\u667a\u80fd\u9700\u8981\u4efb\u610f\u7cbe\u5ea6\u7b97\u672f\u8ba1\u7b97\u57fa\u677f\u3002\u5f15\u5165Halo\u67b6\u6784\uff0c\u91c7\u7528\u6709\u7406\u6570\u7b97\u672f\uff08\u211a\uff09\u4f5c\u4e3a\u8ba1\u7b97\u57fa\u7840\uff0c\u5e76\u8bbe\u8ba1\u65b0\u578b\u7cbe\u786e\u63a8\u7406\u5355\u5143\uff08EIU\uff09\u6765\u652f\u6301\u8fd9\u4e00\u67b6\u6784\u3002", "result": "\u5728Huginn-0125\u539f\u578b\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u663e\u793a\uff0c6000\u4ebf\u53c2\u6570\u7684BF16\u57fa\u7ebf\u5728\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u5d29\u6e83\uff0c\u800cHalo\u67b6\u6784\u80fd\u591f\u65e0\u9650\u671f\u4fdd\u6301\u96f6\u6570\u503c\u53d1\u6563\uff0c\u8bc1\u660e\u4e86\u7cbe\u786e\u7b97\u672f\u5728\u51cf\u5c11\u903b\u8f91\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7cbe\u786e\u7b97\u672f\u662f\u51cf\u5c11System 2 AGI\u903b\u8f91\u4e0d\u786e\u5b9a\u6027\u7684\u5148\u51b3\u6761\u4ef6\uff0c\u4e3a\u901a\u7528\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u8ba1\u7b97\u57fa\u7840\uff0c\u6311\u6218\u4e86\u5f53\u524d\u4ee5\u8fd1\u4f3c\u8ba1\u7b97\u4e3a\u6838\u5fc3\u7684\u6df1\u5ea6\u5b66\u4e60\u8303\u5f0f\u3002"}}
{"id": "2601.17855", "categories": ["cs.DC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.17855", "abs": "https://arxiv.org/abs/2601.17855", "authors": ["Zixi Chen", "Tianci Bu", "Chendong Song", "Xin Lu", "Yinyu Ye", "Zijie Zhou"], "title": "A Universal Load Balancing Principle and Its Application to Large Language Model Serving", "comment": null, "summary": "Load balancing-the allocation of work across parallel resources to reduce delay, energy and cost-is a pervasive challenge in science and engineering, from large-scale simulation and data processing to cloud and manufacturing operations. Motivated by the emerging bottleneck in large language model (LLM) serving, we study a particularly stringent regime of load balancing that arises in barrier-synchronized, stateful systems: work cannot be freely migrated and progress is gated by the slowest participant at each step, so heterogeneity and temporal drift in workloads create persistent stragglers and substantial idle time. LLM serving under data-parallel decoding provides a prominent modern instance: in production traces, barrier-induced idle can exceed 40% of compute time per decode step. Here we develop a universal load-balancing principle, which admits a step-wise finite-horizon integer-optimization formulation and yields worst-case guarantees: across LLM decode models and a broader class of non-decreasing workload drift processes, it reduces long-run imbalance by a factor that grows with batch size and system scale. Extensive experiments corroborate the theory, showing substantial improvements in throughput and latency together with reductions in energy consumption. These results provide a general, theoretically grounded framework for load balancing, with immediate implications for sustainable LLM serving and broad relevance to other synchronization-gated resource-allocation problems.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u4e2d\u7684\u8d1f\u8f7d\u5747\u8861\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u8d1f\u8f7d\u5747\u8861\u539f\u5219\uff0c\u901a\u8fc7\u9010\u6b65\u6709\u9650\u65f6\u57df\u6574\u6570\u4f18\u5316\u516c\u5f0f\uff0c\u663e\u8457\u51cf\u5c11\u5c4f\u969c\u540c\u6b65\u7cfb\u7edf\u4e2d\u7684\u7a7a\u95f2\u65f6\u95f4\uff0c\u63d0\u9ad8\u541e\u5410\u91cf\u548c\u80fd\u6548\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u4e2d\u7684\u5c4f\u969c\u540c\u6b65\u72b6\u6001\u7cfb\u7edf\u5b58\u5728\u4e25\u91cd\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u5de5\u4f5c\u65e0\u6cd5\u81ea\u7531\u8fc1\u79fb\uff0c\u8fdb\u5ea6\u53d7\u6700\u6162\u53c2\u4e0e\u8005\u9650\u5236\uff0c\u5f02\u6784\u6027\u548c\u65f6\u95f4\u6f02\u79fb\u5bfc\u81f4\u6301\u7eed\u843d\u540e\u8005\u548c\u5927\u91cf\u7a7a\u95f2\u65f6\u95f4\u3002\u751f\u4ea7\u8ddf\u8e2a\u663e\u793a\u5c4f\u969c\u5f15\u8d77\u7684\u7a7a\u95f2\u65f6\u95f4\u53ef\u8d85\u8fc7\u6bcf\u4e2a\u89e3\u7801\u6b65\u9aa4\u8ba1\u7b97\u65f6\u95f4\u768440%\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u901a\u7528\u8d1f\u8f7d\u5747\u8861\u539f\u5219\uff0c\u91c7\u7528\u9010\u6b65\u6709\u9650\u65f6\u57df\u6574\u6570\u4f18\u5316\u516c\u5f0f\uff0c\u9488\u5bf9\u975e\u9012\u51cf\u5de5\u4f5c\u8d1f\u8f7d\u6f02\u79fb\u8fc7\u7a0b\uff0c\u63d0\u4f9b\u6700\u574f\u60c5\u51b5\u4fdd\u8bc1\u3002\u8be5\u65b9\u6cd5\u53ef\u51cf\u5c11\u957f\u671f\u4e0d\u5e73\u8861\uff0c\u5176\u6539\u5584\u56e0\u5b50\u968f\u6279\u5904\u7406\u5927\u5c0f\u548c\u7cfb\u7edf\u89c4\u6a21\u589e\u957f\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\uff0c\u663e\u793a\u5728\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u548c\u80fd\u8017\u65b9\u9762\u5747\u6709\u663e\u8457\u6539\u5584\u3002\u8be5\u65b9\u6cd5\u5728LLM\u89e3\u7801\u6a21\u578b\u548c\u66f4\u5e7f\u6cdb\u7684\u975e\u9012\u51cf\u5de5\u4f5c\u8d1f\u8f7d\u6f02\u79fb\u8fc7\u7a0b\u4e2d\u90fd\u80fd\u6709\u6548\u51cf\u5c11\u957f\u671f\u4e0d\u5e73\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u3001\u7406\u8bba\u57fa\u7840\u7684\u8d1f\u8f7d\u5747\u8861\u6846\u67b6\uff0c\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7684\u53ef\u6301\u7eed\u6027\u6709\u76f4\u63a5\u610f\u4e49\uff0c\u5e76\u5bf9\u5176\u4ed6\u540c\u6b65\u95e8\u63a7\u8d44\u6e90\u5206\u914d\u95ee\u9898\u5177\u6709\u5e7f\u6cdb\u76f8\u5173\u6027\u3002"}}
{"id": "2601.17065", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.17065", "abs": "https://arxiv.org/abs/2601.17065", "authors": ["Haoxuan Li", "He Chang", "Yunshan Ma", "Yi Bin", "Yang Yang", "See-Kiong Ng", "Tat-Seng Chua"], "title": "ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting", "comment": null, "summary": "Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.", "AI": {"tldr": "\u63d0\u51faThinkTank-ME\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u73b0\u5b9e\u4e16\u754c\u667a\u5e93\u534f\u4f5c\u7684\u591a\u4e13\u5bb6\u7cfb\u7edf\u6765\u6539\u8fdb\u4e2d\u4e1c\u4e8b\u4ef6\u9884\u6d4b\uff0c\u514b\u670d\u73b0\u6709\u5355\u4e00\u6a21\u578b\u67b6\u6784\u7684\u5c40\u9650\u6027", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u4e8b\u4ef6\u9884\u6d4b\u65b9\u6cd5\u91c7\u7528\u5355\u4e00\u6a21\u578b\u67b6\u6784\uff0c\u53ea\u80fd\u6cbf\u7740\u5355\u4e00\u663e\u5f0f\u8f68\u8ff9\u751f\u6210\u9884\u6d4b\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u533a\u57df\u80cc\u666f\u4e0b\u591a\u6837\u5316\u7684\u5730\u7f18\u653f\u6cbb\u7ec6\u5fae\u5dee\u522b\u3002\u4e8b\u4ef6\u9884\u6d4b\u672c\u8d28\u4e0a\u53d7\u5230\u591a\u65b9\u9762\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u56fd\u9645\u5173\u7cfb\u3001\u533a\u57df\u5386\u53f2\u52a8\u6001\u548c\u6587\u5316\u80cc\u666f\u3002", "method": "\u5f15\u5165ThinkTank-ME\u6846\u67b6\uff0c\u6a21\u62df\u73b0\u5b9e\u4e16\u754c\u6218\u7565\u51b3\u7b56\u4e2d\u7684\u534f\u4f5c\u4e13\u5bb6\u5206\u6790\u3002\u6784\u5efaPOLECAT-FOR-ME\u57fa\u51c6\u6570\u636e\u96c6\u6765\u4fc3\u8fdb\u4e13\u5bb6\u4e13\u4e1a\u5316\u548c\u4e25\u683c\u8bc4\u4f30\u3002\u91c7\u7528\u591a\u4e13\u5bb6\u534f\u4f5c\u67b6\u6784\u5904\u7406\u590d\u6742\u7684\u5730\u7f18\u653f\u6cbb\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u591a\u4e13\u5bb6\u534f\u4f5c\u5728\u5904\u7406\u590d\u6742\u7684\u65f6\u95f4\u6027\u5730\u7f18\u653f\u6cbb\u9884\u6d4b\u4efb\u52a1\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u5728GitHub\u4e0a\u3002", "conclusion": "\u591a\u4e13\u5bb6\u534f\u4f5c\u7684\u667a\u5e93\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u4e2d\u4e1c\u5730\u533a\u590d\u6742\u7684\u5730\u7f18\u653f\u6cbb\u7ec6\u5fae\u5dee\u522b\uff0c\u4e3a\u4e8b\u4ef6\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18158", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.18158", "abs": "https://arxiv.org/abs/2601.18158", "authors": ["Karame Mohammadiporshokooh", "Panagiotis Syskakis", "Hartmut Kaiser"], "title": "An Initial Evaluation of Distributed Graph Algorithms using NWGraph and HPX", "comment": "Initial technical report. Extended version of work under submission", "summary": "Graphs are central to modeling relationships in scientific computing, data analysis, and AI/ML, but their growing scale can exceed the memory and compute capacity of single nodes, requiring distributed solutions. Existing distributed graph framework, however, face fundamental challenges: graph algorithms are latency-bound, suffer from irregular memory access, and often impose synchronization costs that limit scalability and efficiency. In this work, we present a distributed implementation of the NWGraph library integrated with the HPX runtime system. By leveraging HPX's asynchronous many-task model, our approach aims to reduce synchronization overhead, improve load balance, and provide a foundation for distributed graph analytics. We evaluate this approach using two representative algorithms: Breadth-First-Search (BFS) and (PageRank). Our initial results show that BFS achieves better performance than the distributed Boost Graph Library (BGL), while PageRank remains more challenging, with current implementation not yet outperforming BGL. These findings highlight both the promise and the open challenges of applying asynchronous task-based runtimes to graph processing, and point to opportunities for future optimizations and extensions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06NWGraph\u5e93\u4e0eHPX\u8fd0\u884c\u65f6\u7cfb\u7edf\u96c6\u6210\u7684\u5206\u5e03\u5f0f\u5b9e\u73b0\uff0c\u65e8\u5728\u901a\u8fc7\u5f02\u6b65\u591a\u4efb\u52a1\u6a21\u578b\u51cf\u5c11\u540c\u6b65\u5f00\u9500\u3001\u6539\u5584\u8d1f\u8f7d\u5747\u8861\uff0c\u4e3a\u5206\u5e03\u5f0f\u56fe\u5206\u6790\u63d0\u4f9b\u57fa\u7840\u3002\u5728BFS\u7b97\u6cd5\u4e0a\u8868\u73b0\u4f18\u4e8e\u5206\u5e03\u5f0fBoost Graph Library\uff0c\u4f46PageRank\u7b97\u6cd5\u4ecd\u6709\u6311\u6218\u3002", "motivation": "\u56fe\u5728\u79d1\u5b66\u8ba1\u7b97\u3001\u6570\u636e\u5206\u6790\u548cAI/ML\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56fe\u89c4\u6a21\u7684\u589e\u957f\u53ef\u80fd\u8d85\u8fc7\u5355\u8282\u70b9\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u80fd\u529b\uff0c\u9700\u8981\u5206\u5e03\u5f0f\u89e3\u51b3\u65b9\u6848\u3002\u73b0\u6709\u5206\u5e03\u5f0f\u56fe\u6846\u67b6\u9762\u4e34\u57fa\u672c\u6311\u6218\uff1a\u56fe\u7b97\u6cd5\u53d7\u5ef6\u8fdf\u9650\u5236\u3001\u5b58\u5728\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u3001\u540c\u6b65\u6210\u672c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002", "method": "\u5c06NWGraph\u5e93\u4e0eHPX\u8fd0\u884c\u65f6\u7cfb\u7edf\u96c6\u6210\uff0c\u5229\u7528HPX\u7684\u5f02\u6b65\u591a\u4efb\u52a1\u6a21\u578b\u6765\u51cf\u5c11\u540c\u6b65\u5f00\u9500\u3001\u6539\u5584\u8d1f\u8f7d\u5747\u8861\uff0c\u4e3a\u5206\u5e03\u5f0f\u56fe\u5206\u6790\u63d0\u4f9b\u57fa\u7840\u3002\u4f7f\u7528\u4e24\u79cd\u4ee3\u8868\u6027\u7b97\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff1a\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\uff08BFS\uff09\u548cPageRank\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0cBFS\u7b97\u6cd5\u6bd4\u5206\u5e03\u5f0fBoost Graph Library\uff08BGL\uff09\u8868\u73b0\u66f4\u597d\uff0c\u800cPageRank\u7b97\u6cd5\u66f4\u5177\u6311\u6218\u6027\uff0c\u5f53\u524d\u5b9e\u73b0\u5c1a\u672a\u8d85\u8d8aBGL\u3002\u8fd9\u4e9b\u53d1\u73b0\u51f8\u663e\u4e86\u5f02\u6b65\u4efb\u52a1\u8fd0\u884c\u65f6\u5728\u56fe\u5904\u7406\u4e2d\u7684\u6f5c\u529b\u548c\u5f00\u653e\u6311\u6218\u3002", "conclusion": "\u5f02\u6b65\u4efb\u52a1\u8fd0\u884c\u65f6\u5728\u56fe\u5904\u7406\u4e2d\u5177\u6709\u524d\u666f\uff0c\u4f46PageRank\u7b49\u7b97\u6cd5\u4ecd\u9762\u4e34\u6311\u6218\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u4f18\u5316\u548c\u6269\u5c55\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5982\u4f55\u66f4\u597d\u5730\u5e94\u7528\u5f02\u6b65\u4efb\u52a1\u6a21\u578b\u89e3\u51b3\u5206\u5e03\u5f0f\u56fe\u5904\u7406\u95ee\u9898\u3002"}}
{"id": "2601.17069", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17069", "abs": "https://arxiv.org/abs/2601.17069", "authors": ["Shahil Shaik", "Jonathon M. Smereka", "Yue Wang"], "title": "Multi-Agent Deep Reinforcement Learning Under Constrained Communications", "comment": "21 pages, 8 figures, Under review at ICLR", "summary": "Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6DG-MAPPO\uff0c\u901a\u8fc7\u591a\u8df3\u901a\u4fe1\u548c\u5206\u5e03\u5f0f\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u5b8c\u5168\u6d88\u9664\u5bf9\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u548c\u5168\u5c40\u4fe1\u606f\u7684\u4f9d\u8d56\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u5206\u5e03\u5f0f\u6267\u884c\uff08CTDE\uff09\u8303\u5f0f\u5b58\u5728\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u74f6\u9888\uff0c\u4f9d\u8d56\u8bad\u7ec3\u65f6\u7684\u5168\u5c40\u72b6\u6001\u4fe1\u606f\uff0c\u5728\u5b9e\u9645\u573a\u666f\u4e2d\uff08\u5982\u961f\u53cb\u589e\u51cf\u3001\u73af\u5883\u52a8\u6001\u53d8\u5316\uff09\u8106\u5f31\u4e14\u91cd\u8bad\u7ec3\u6210\u672c\u9ad8\u3002\u5206\u5e03\u5f0f\u65b9\u6cd5\u5141\u8bb8\u667a\u80fd\u4f53\u4ec5\u4f7f\u7528\u672c\u5730\u4fe1\u606f\u548c\u70b9\u5bf9\u70b9\u901a\u4fe1\u8fdb\u884c\u9002\u5e94\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u5f0f\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08D-GAT\uff09\uff0c\u901a\u8fc7\u591a\u8df3\u901a\u4fe1\u8fdb\u884c\u5168\u5c40\u72b6\u6001\u63a8\u65ad\uff0c\u667a\u80fd\u4f53\u4ee5\u5b8c\u5168\u5206\u5e03\u5f0f\u65b9\u5f0f\u901a\u8fc7\u8f93\u5165\u4f9d\u8d56\u7684\u6ce8\u610f\u529b\u6743\u91cd\u6574\u5408\u90bb\u5c45\u7279\u5f81\u3002\u57fa\u4e8eD-GAT\u5f00\u53d1\u5206\u5e03\u5f0f\u56fe\u6ce8\u610f\u529bMAPPO\uff08DG-MAPPO\uff09\uff0c\u667a\u80fd\u4f53\u4f7f\u7528\u672c\u5730\u89c2\u5bdf\u3001\u591a\u8df3\u901a\u4fe1\u548c\u5171\u4eab/\u5e73\u5747\u5956\u52b1\u6765\u4f18\u5316\u672c\u5730\u7b56\u7565\u548c\u4ef7\u503c\u51fd\u6570\u3002", "result": "\u5728StarCraftII\u591a\u667a\u80fd\u4f53\u6311\u6218\u3001Google Research Football\u548cMulti-Agent Mujoco\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5e7f\u6cdb\u5408\u4f5c\u4efb\u52a1\u4e2d\uff08\u5305\u62ec\u540c\u8d28\u548c\u5f02\u8d28\u56e2\u961f\uff09\u59cb\u7ec8\u4f18\u4e8e\u5f3aCTDE\u57fa\u7ebf\uff0c\u5b9e\u73b0\u66f4\u4f18\u7684\u534f\u8c03\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5e03\u5f0fMARL\u6846\u67b6\u4e3a\u9c81\u68d2\u534f\u4f5c\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6d88\u9664\u4e86\u5bf9\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u6216\u5168\u5c40\u53ef\u89c2\u6d4b\u6027\u7684\u9700\u6c42\u3002\u636e\u4f5c\u8005\u6240\u77e5\uff0cDG-MAPPO\u662f\u9996\u4e2a\u5b8c\u5168\u6d88\u9664\u5bf9\u7279\u6743\u96c6\u4e2d\u4fe1\u606f\u4f9d\u8d56\u7684\u65b9\u6cd5\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u4ec5\u901a\u8fc7\u70b9\u5bf9\u70b9\u901a\u4fe1\u8fdb\u884c\u5b66\u4e60\u548c\u884c\u52a8\u3002"}}
{"id": "2601.17073", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.17073", "abs": "https://arxiv.org/abs/2601.17073", "authors": ["Yifei Zhang", "Meimei Liu", "Zhengwu Zhang"], "title": "Attention-Based Variational Framework for Joint and Individual Components Learning with Applications in Brain Network Analysis", "comment": null, "summary": "Brain organization is increasingly characterized through multiple imaging modalities, most notably structural connectivity (SC) and functional connectivity (FC). Integrating these inherently distinct yet complementary data sources is essential for uncovering the cross-modal patterns that drive behavioral phenotypes. However, effective integration is hindered by the high dimensionality and non-linearity of connectome data, complex non-linear SC-FC coupling, and the challenge of disentangling shared information from modality-specific variations. To address these issues, we propose the Cross-Modal Joint-Individual Variational Network (CM-JIVNet), a unified probabilistic framework designed to learn factorized latent representations from paired SC-FC datasets. Our model utilizes a multi-head attention fusion module to capture non-linear cross-modal dependencies while isolating independent, modality-specific signals. Validated on Human Connectome Project Young Adult (HCP-YA) data, CM-JIVNet demonstrates superior performance in cross-modal reconstruction and behavioral trait prediction. By effectively disentangling joint and individual feature spaces, CM-JIVNet provides a robust, interpretable, and scalable solution for large-scale multimodal brain analysis.", "AI": {"tldr": "CM-JIVNet\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u8111\u8fde\u63a5\u7ec4\u5206\u6790\u7684\u7edf\u4e00\u6982\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u878d\u5408\u6a21\u5757\u5206\u79bb\u5171\u4eab\u548c\u6a21\u6001\u7279\u5f02\u6027\u7279\u5f81\uff0c\u5728SC-FC\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u8111\u7ec4\u7ec7\u5206\u6790\u9700\u8981\u6574\u5408\u7ed3\u6784\u548c\u529f\u80fd\u8fde\u63a5\u7ec4\u6570\u636e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u9ad8\u7ef4\u975e\u7ebf\u6027\u3001\u590d\u6742SC-FC\u8026\u5408\u4ee5\u53ca\u96be\u4ee5\u533a\u5206\u5171\u4eab\u4e0e\u7279\u5f02\u6027\u4fe1\u606f\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u8de8\u6a21\u6001\u8054\u5408-\u4e2a\u4f53\u53d8\u5206\u7f51\u7edc(CM-JIVNet)\uff0c\u4f7f\u7528\u591a\u5934\u6ce8\u610f\u529b\u878d\u5408\u6a21\u5757\u6355\u83b7\u975e\u7ebf\u6027\u8de8\u6a21\u6001\u4f9d\u8d56\uff0c\u540c\u65f6\u5206\u79bb\u72ec\u7acb\u7684\u6a21\u6001\u7279\u5f02\u6027\u4fe1\u53f7\u3002", "result": "\u5728HCP-YA\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0cCM-JIVNet\u5728\u8de8\u6a21\u6001\u91cd\u5efa\u548c\u884c\u4e3a\u7279\u5f81\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6709\u6548\u89e3\u8026\u8054\u5408\u548c\u4e2a\u4f53\u7279\u5f81\u7a7a\u95f4\u3002", "conclusion": "CM-JIVNet\u4e3a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u8111\u5206\u6790\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6709\u6548\u5206\u79bb\u5171\u4eab\u548c\u6a21\u6001\u7279\u5f02\u6027\u4fe1\u606f\u3002"}}
{"id": "2601.17133", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.17133", "abs": "https://arxiv.org/abs/2601.17133", "authors": ["Inderjeet Singh", "Eleonore Vissol-Gaudin", "Andikan Otung", "Motoyoshi Sekiya"], "title": "Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation", "comment": "Accepted to AAAI 2026. 13 pages, 3 figures, 10 tables. Code available at: https://github.com/FujitsuResearch/knexa-fl", "summary": "Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.", "AI": {"tldr": "KNEXA-FL\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e2d\u592e\u5339\u914d\u5668\u4f18\u5316\u5f02\u6784LLM\u4ee3\u7406\u4e4b\u95f4\u7684P2P\u77e5\u8bc6\u4ea4\u6362\uff0c\u89e3\u51b3\u6570\u636e\u9690\u79c1\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u4e13\u4e1a\u9886\u57dfLLM\u5fae\u8c03\u4e2d\u5b58\u5728\u77db\u76fe\uff1a\u9700\u8981\u8de8\u7ec4\u7ec7\u6570\u636e\u4f46\u9762\u4e34\u9690\u79c1\u4fdd\u62a4\u8981\u6c42\u3002\u96c6\u4e2d\u5f0fFL\u5b58\u5728\u5355\u70b9\u6545\u969c\u548c\u6a21\u578b\u53cd\u8f6c\u653b\u51fb\u98ce\u9669\uff0c\u800c\u53bb\u4e2d\u5fc3\u5316FL\u7684\u968f\u673aP2P\u914d\u5bf9\u6548\u7387\u4f4e\u4e0b\u4e14\u53ef\u80fd\u5bfc\u81f4\u8d1f\u8fc1\u79fb\u3002", "method": "\u63d0\u51faKNEXA-FL\u6846\u67b6\uff0c\u91c7\u7528\u975e\u805a\u5408\u7684\u4e2d\u592e\u5206\u6790\u5668/\u5339\u914d\u5668\uff0c\u5c06P2P\u534f\u4f5c\u5efa\u6a21\u4e3a\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u4f7f\u7528LinUCB\u7b97\u6cd5\u57fa\u4e8e\u62bd\u8c61\u4ee3\u7406\u914d\u7f6e\u6587\u4ef6\u5b66\u4e60\u6700\u4f18\u5339\u914d\u7b56\u7565\uff0c\u901a\u8fc7\u5b89\u5168\u84b8\u998f\u5b9e\u73b0\u5f02\u6784PEFT-based LLM\u4ee3\u7406\u4e4b\u95f4\u7684\u76f4\u63a5\u77e5\u8bc6\u4ea4\u6362\u3002", "result": "\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cKNEXA-FL\u76f8\u6bd4\u968f\u673aP2P\u534f\u4f5c\u5c06Pass@1\u63d0\u9ad8\u4e86\u7ea650%\uff0c\u4e14\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u6536\u655b\u6027\uff0c\u800c\u5f3a\u5927\u7684\u96c6\u4e2d\u5f0f\u84b8\u998f\u57fa\u7ebf\u5219\u51fa\u73b0\u707e\u96be\u6027\u6027\u80fd\u5d29\u6e83\u3002", "conclusion": "\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u5b66\u4e60\u7684\u7f16\u6392\u662f\u6784\u5efa\u7a33\u5065\u6709\u6548\u53bb\u4e2d\u5fc3\u5316AI\u751f\u6001\u7cfb\u7edf\u7684\u57fa\u672c\u539f\u5219\uff0cKNEXA-FL\u6210\u529f\u89e3\u51b3\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2601.17074", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17074", "abs": "https://arxiv.org/abs/2601.17074", "authors": ["Akila Sampath", "Vandana Janeja", "Jianwu Wang"], "title": "PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction", "comment": null, "summary": "The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided inference.Our core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.", "AI": {"tldr": "PhysE-Inv\uff1a\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b0\u578b\u53cd\u6f14\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u7a00\u758f\u566a\u58f0\u6570\u636e\u4e2d\u51c6\u786e\u4f30\u8ba1\u5317\u6781\u79ef\u96ea\u6df1\u5ea6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8bef\u5dee\u964d\u4f4e20%", "motivation": "\u5317\u6781\u79ef\u96ea\u6df1\u5ea6\u4f30\u8ba1\u662f\u91cd\u8981\u7684\u65f6\u53d8\u53cd\u6f14\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u6570\u636e\u7a00\u758f\u548c\u566a\u58f0\u7684\u6311\u6218\uff1a\u57fa\u4e8e\u8fc7\u7a0b\u7684\u65b9\u6cd5\u5bf9\u7a00\u758f\u6570\u636e\u654f\u611f\uff0c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7f3a\u4e4f\u7269\u7406\u53ef\u89e3\u91ca\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6c14\u5019\u5173\u952e\u5e94\u7528\u7684\u9700\u6c42", "method": "\u63d0\u51faPhysE-Inv\u6846\u67b6\uff0c\u6838\u5fc3\u521b\u65b0\u662f\"\u6ee1\u5c04\u7269\u7406\u7ea6\u675f\u53cd\u6f14\u65b9\u6cd5\"\uff1a1) \u5229\u7528\u9759\u6c34\u5e73\u8861\u524d\u5411\u6a21\u578b\u4f5c\u4e3a\u76ee\u6807\u516c\u5f0f\u4ee3\u7406\uff0c\u5728\u6ca1\u6709\u76f4\u63a5\u5730\u9762\u771f\u503c\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5b66\u4e60\uff1b2) \u5728\u6f5c\u5728\u7a7a\u95f4\u4e0a\u4f7f\u7528\u91cd\u5efa\u7269\u7406\u6b63\u5219\u5316\uff0c\u4ece\u566a\u58f0\u4e0d\u5b8c\u6574\u65f6\u95f4\u5e8f\u5217\u8f93\u5165\u4e2d\u52a8\u6001\u53d1\u73b0\u9690\u85cf\u7269\u7406\u53c2\u6570\uff1b\u6846\u67b6\u7ed3\u5408LSTM\u7f16\u7801\u5668-\u89e3\u7801\u5668\u591a\u5934\u6ce8\u610f\u529b\u548c\u7269\u7406\u5f15\u5bfc\u5bf9\u6bd4\u5b66\u4e60", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0cPhysE-Inv\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u8bef\u5dee\u964d\u4f4e20%\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u7269\u7406\u4e00\u81f4\u6027\u548c\u5bf9\u6570\u636e\u7a00\u758f\u6027\u7684\u9c81\u68d2\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u5f00\u521b\u4e86\u566a\u58f0\u5bb9\u5fcd\u3001\u53ef\u89e3\u91ca\u7684\u53cd\u6f14\u5efa\u6a21\u65b0\u8def\u5f84\uff0c\u5728\u5730\u7406\u7a7a\u95f4\u548c\u51b0\u51bb\u5708\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4e3a\u6c14\u5019\u5173\u952e\u5e94\u7528\u63d0\u4f9b\u4e86\u7269\u7406\u4e00\u81f4\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.17076", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17076", "abs": "https://arxiv.org/abs/2601.17076", "authors": ["Jiajun Chen", "Yue Wu", "Kai Huang", "Wen Xi", "Yangyang Wu", "Xiaoye Miao", "Mengying Zhu", "Meng Xi", "Guanjie Cheng"], "title": "E2PL: Effective and Efficient Prompt Learning for Incomplete Multi-view Multi-Label Class Incremental Learning", "comment": "11 pages", "summary": "Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \\emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \\textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \\textsf{E2PL} unifies two novel prompt designs: \\emph{task-tailored prompts} for class-incremental adaptation and \\emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \\emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \\emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \\textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.", "AI": {"tldr": "\u63d0\u51faE2PL\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u591a\u6807\u7b7e\u5206\u7c7b\u589e\u91cf\u5b66\u4e60\u4efb\u52a1\uff0c\u901a\u8fc7\u4efb\u52a1\u5b9a\u5236\u63d0\u793a\u548c\u7f3a\u5931\u611f\u77e5\u63d0\u793a\u89e3\u51b3\u89c6\u56fe\u7f3a\u5931\u548c\u7c7b\u522b\u52a8\u6001\u6269\u5c55\u95ee\u9898\uff0c\u5e76\u5229\u7528\u9ad8\u6548\u539f\u578b\u5f20\u91cf\u5316\u964d\u4f4e\u53c2\u6570\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7f51\u7edc\u5e94\u7528\u4e2d\u5b58\u5728\u89c6\u56fe\u7f3a\u5931\u548c\u7c7b\u522b\u6301\u7eed\u6d8c\u73b0\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u5bf9\u65b0\u7c7b\u522b\u7684\u9002\u5e94\u6027\uff0c\u8981\u4e48\u5728\u5904\u7406\u6240\u6709\u53ef\u80fd\u7684\u7f3a\u5931\u89c6\u56fe\u6a21\u5f0f\u65f6\u53c2\u6570\u5448\u6307\u6570\u589e\u957f\uff0c\u9650\u5236\u4e86\u5728Web\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faE2PL\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u4efb\u52a1\u5b9a\u5236\u63d0\u793a\u7528\u4e8e\u7c7b\u522b\u589e\u91cf\u9002\u5e94\uff1b2\uff09\u7f3a\u5931\u611f\u77e5\u63d0\u793a\u7528\u4e8e\u7075\u6d3b\u96c6\u6210\u4efb\u610f\u89c6\u56fe\u7f3a\u5931\u573a\u666f\uff1b3\uff09\u9ad8\u6548\u539f\u578b\u5f20\u91cf\u5316\u6a21\u5757\uff0c\u5229\u7528\u539f\u5b50\u5f20\u91cf\u5206\u89e3\u5c06\u63d0\u793a\u53c2\u6570\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u7ebf\u6027\u7ea7\uff1b4\uff09\u52a8\u6001\u5bf9\u6bd4\u5b66\u4e60\u7b56\u7565\u663e\u5f0f\u5efa\u6a21\u4e0d\u540c\u7f3a\u5931\u89c6\u56fe\u6a21\u5f0f\u95f4\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cE2PL\u5728\u6709\u6548\u6027\u548c\u6548\u7387\u65b9\u9762\u90fd\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "E2PL\u6846\u67b6\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u4e86\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u591a\u6807\u7b7e\u5206\u7c7b\u589e\u91cf\u5b66\u4e60\u4efb\u52a1\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u63d0\u793a\u8bbe\u8ba1\u548c\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u89c6\u56fe\u7f3a\u5931\u548c\u7c7b\u522b\u52a8\u6001\u6269\u5c55\u7684\u6709\u6548\u5904\u7406\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.17090", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17090", "abs": "https://arxiv.org/abs/2601.17090", "authors": ["Noam Koren", "Rafael Moschopoulos", "Kira Radinsky", "Elad Hazan"], "title": "SFO: Learning PDE Operators via Spectral Filtering", "comment": null, "summary": "Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.", "AI": {"tldr": "SFO\u662f\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7b97\u5b50\uff0c\u4f7f\u7528\u901a\u7528\u8c31\u57fa\u53c2\u6570\u5316\u79ef\u5206\u6838\uff0c\u901a\u8fc7\u5feb\u901f\u8870\u51cf\u7279\u5f81\u503c\u7684\u5149\u8c31\u7cfb\u6570\u5b66\u4e60\uff0c\u5728PDE\u6c42\u89e3\u4e2d\u5b9e\u73b0\u9ad8\u6548\u8868\u793a\u548cSOTA\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7b97\u5b50\u5728\u6355\u6349\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u6620\u5c04\u4e2d\u7684\u957f\u7a0b\u975e\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u79bb\u6563\u683c\u6797\u51fd\u6570\u5177\u6709\u7a7a\u95f4\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7ed3\u6784\uff0c\u8fd9\u4e3a\u9ad8\u6548\u8868\u793a\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u8c31\u6ee4\u6ce2\u7b97\u5b50(SFO)\uff0c\u4f7f\u7528\u4ece\u5e0c\u5c14\u4f2f\u7279\u77e9\u9635\u7279\u5f81\u6a21\u6001\u63a8\u5bfc\u7684\u901a\u7528\u8c31\u57fa(USB)\u53c2\u6570\u5316\u79ef\u5206\u6838\uff0c\u4ec5\u5b66\u4e60\u5feb\u901f\u8870\u51cf\u7279\u5f81\u503c\u7684\u5149\u8c31\u7cfb\u6570\uff0c\u5b9e\u73b0\u7d27\u51d1\u8fd1\u4f3c\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u53cd\u5e94\u6269\u6563\u3001\u6d41\u4f53\u52a8\u529b\u5b66\u548c3D\u7535\u78c1\u5b66\uff09\u4e2d\uff0cSFO\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u76f8\u5bf9\u4e8e\u5f3a\u57fa\u7ebf\u8bef\u5dee\u51cf\u5c11\u9ad8\u8fbe40%\uff0c\u540c\u65f6\u4f7f\u7528\u66f4\u5c11\u53c2\u6570\u3002", "conclusion": "SFO\u901a\u8fc7\u8c31\u57fa\u8868\u793a\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u795e\u7ecf\u7b97\u5b50\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u6355\u6349PDE\u89e3\u6620\u5c04\u4e2d\u7684\u957f\u7a0b\u975e\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.17091", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17091", "abs": "https://arxiv.org/abs/2601.17091", "authors": ["Ole St\u00fcven", "Keno Moenck", "Thorsten Sch\u00fcppstuhl"], "title": "CUROCKET: Optimizing ROCKET for GPU", "comment": null, "summary": "ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.", "AI": {"tldr": "CUROCKET\u63d0\u51fa\u4e86\u4e00\u79cd\u5728GPU\u4e0a\u9ad8\u6548\u6267\u884cROCKET\u7279\u5f81\u63d0\u53d6\u7684\u7b97\u6cd5\uff0c\u76f8\u6bd4CPU\u7248\u672c\u5b9e\u73b0\u4e86\u6700\u9ad811\u500d\u7684\u6bcf\u74e6\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002", "motivation": "ROCKET\u662f\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u9ad8\u6548\u7279\u5f81\u63d0\u53d6\u7b97\u6cd5\uff0c\u4f46\u73b0\u6709\u5b9e\u73b0\u4e3b\u8981\u9650\u4e8eCPU\u6267\u884c\u3002\u5377\u79ef\u8ba1\u7b97\u9ad8\u5ea6\u53ef\u5e76\u884c\u5316\uff0c\u9002\u5408GPU\u52a0\u901f\uff0c\u4f46ROCKET\u4f7f\u7528\u7684\u975e\u5747\u5300\u6838\u4f7f\u5f97\u6807\u51c6GPU\u5377\u79ef\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u95e8\u7b97\u6cd5\uff0c\u80fd\u591f\u5728GPU\u4e0a\u9ad8\u6548\u6267\u884cROCKET\u7684\u7279\u5f81\u63d0\u53d6\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u975e\u5747\u5300\u5377\u79ef\u6838\u5728GPU\u4e0a\u6267\u884c\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "result": "CUROCKET\u5728GPU\u4e0a\u5b9e\u73b0\u4e86\u6bd4CPU\u7248\u672c\u6700\u9ad811\u500d\u7684\u6bcf\u74e6\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90\u3002", "conclusion": "\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684GPU\u7b97\u6cd5\uff0c\u6210\u529f\u5c06ROCKET\u7684\u9ad8\u6548\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u6269\u5c55\u5230GPU\u5e73\u53f0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2601.17654", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17654", "abs": "https://arxiv.org/abs/2601.17654", "authors": ["Ruofan Wu", "Jae-Won Chung", "Mosharaf Chowdhury"], "title": "Kareus: Joint Reduction of Dynamic and Static Energy in Large Model Training", "comment": null, "summary": "The computing demand of AI is growing at an unprecedented rate, but energy supply is not keeping pace. As a result, energy has become an expensive, contended resource that requires explicit management and optimization. Although recent works have made significant progress in large model training optimization, they focus only on a single aspect of energy consumption: dynamic or static energy.\n  We find that fine-grained kernel scheduling and frequency scaling jointly and interdependently impact both dynamic and static energy consumption. Based on this finding, we design Kareus, a training system that pushes the time--energy tradeoff frontier by optimizing both aspects. Kareus decomposes the intractable joint optimization problem into local, partition-based subproblems. It then uses a multi-pass multi-objective optimization algorithm to find execution schedules that push the time--energy tradeoff frontier. Compared to the state of the art, Kareus reduces training energy by up to 28.3% at the same training time, or reduces training time by up to 27.5% at the same energy consumption.", "AI": {"tldr": "Kareus\u662f\u4e00\u4e2aAI\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7ec6\u7c92\u5ea6\u5185\u6838\u8c03\u5ea6\u548c\u9891\u7387\u8c03\u8282\u6765\u540c\u65f6\u4f18\u5316\u52a8\u6001\u548c\u9759\u6001\u80fd\u8017\uff0c\u5728\u65f6\u95f4-\u80fd\u8017\u6743\u8861\u524d\u6cbf\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "AI\u8ba1\u7b97\u9700\u6c42\u5feb\u901f\u589e\u957f\uff0c\u4f46\u80fd\u6e90\u4f9b\u5e94\u8ddf\u4e0d\u4e0a\uff0c\u80fd\u6e90\u5df2\u6210\u4e3a\u6602\u8d35\u4e14\u7ade\u4e89\u6fc0\u70c8\u7684\u8d44\u6e90\uff0c\u9700\u8981\u660e\u786e\u7684\u7ba1\u7406\u548c\u4f18\u5316\u3002\u73b0\u6709\u5de5\u4f5c\u53ea\u5173\u6ce8\u80fd\u8017\u7684\u5355\u4e00\u65b9\u9762\uff08\u52a8\u6001\u6216\u9759\u6001\u80fd\u8017\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u5185\u6838\u8c03\u5ea6\u548c\u9891\u7387\u8c03\u8282\u5bf9\u4e24\u8005\u7684\u8054\u5408\u5f71\u54cd\u3002", "method": "Kareus\u5c06\u96be\u4ee5\u5904\u7406\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u5c40\u90e8\u7684\u3001\u57fa\u4e8e\u5206\u533a\u7684\u5b50\u95ee\u9898\uff0c\u7136\u540e\u4f7f\u7528\u591a\u901a\u9053\u591a\u76ee\u6807\u4f18\u5316\u7b97\u6cd5\u6765\u5bfb\u627e\u80fd\u591f\u63a8\u52a8\u65f6\u95f4-\u80fd\u8017\u6743\u8861\u524d\u6cbf\u7684\u6267\u884c\u8c03\u5ea6\u65b9\u6848\u3002", "result": "\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0cKareus\u5728\u76f8\u540c\u8bad\u7ec3\u65f6\u95f4\u4e0b\u51cf\u5c11\u8bad\u7ec3\u80fd\u8017\u9ad8\u8fbe28.3%\uff0c\u6216\u5728\u76f8\u540c\u80fd\u8017\u4e0b\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u9ad8\u8fbe27.5%\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5185\u6838\u8c03\u5ea6\u548c\u9891\u7387\u8c03\u8282\u6765\u540c\u65f6\u5904\u7406\u52a8\u6001\u548c\u9759\u6001\u80fd\u8017\uff0cKareus\u6210\u529f\u63a8\u52a8\u4e86AI\u8bad\u7ec3\u7684\u65f6\u95f4-\u80fd\u8017\u6743\u8861\u524d\u6cbf\uff0c\u4e3a\u89e3\u51b3AI\u8ba1\u7b97\u80fd\u8017\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.17093", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17093", "abs": "https://arxiv.org/abs/2601.17093", "authors": ["Olha Sirikova", "Alvin Chan"], "title": "The Triangle of Similarity: A Multi-Faceted Framework for Comparing Neural Network Representations", "comment": "Accepted to AAAI 2026 Workshop on AI for Scientific Research (AI4Research)", "summary": "Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.", "AI": {"tldr": "\u63d0\u51faTriangle of Similarity\u6846\u67b6\uff0c\u7ed3\u5408\u9759\u6001\u8868\u5f81\u76f8\u4f3c\u6027\u3001\u529f\u80fd\u76f8\u4f3c\u6027\u548c\u7a00\u758f\u6027\u76f8\u4f3c\u6027\u4e09\u4e2a\u4e92\u8865\u89c6\u89d2\uff0c\u7528\u4e8e\u66f4\u5168\u9762\u5730\u6bd4\u8f83\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6bd4\u8f83\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u65f6\u5f80\u5f80\u63d0\u4f9b\u6709\u9650\u89c6\u89d2\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6846\u67b6\u6765\u7406\u89e3\u6a21\u578b\u5728\u79d1\u5b66\u5e94\u7528\u4e2d\u7684\u5185\u90e8\u673a\u5236\u3002", "method": "\u63d0\u51faTriangle of Similarity\u6846\u67b6\uff0c\u7ed3\u5408\u4e09\u79cd\u76f8\u4f3c\u6027\u5ea6\u91cf\uff1a\u9759\u6001\u8868\u5f81\u76f8\u4f3c\u6027\uff08CKA/Procrustes\uff09\u3001\u529f\u80fd\u76f8\u4f3c\u6027\uff08\u7ebf\u6027\u6a21\u5f0f\u8fde\u63a5\u6216\u9884\u6d4b\u76f8\u4f3c\u6027\uff09\u548c\u7a00\u758f\u6027\u76f8\u4f3c\u6027\uff08\u526a\u679d\u4e0b\u7684\u9c81\u68d2\u6027\uff09\u3002\u5206\u6790CNN\u3001Vision Transformer\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u7528ImageNetV2\uff08\u5206\u5e03\u5185\uff09\u548cCIFAR-10\uff08\u5206\u5e03\u5916\uff09\u6d4b\u8bd5\u96c6\u3002", "result": "1) \u67b6\u6784\u5bb6\u65cf\u662f\u8868\u5f81\u76f8\u4f3c\u6027\u7684\u4e3b\u8981\u51b3\u5b9a\u56e0\u7d20\uff0c\u5f62\u6210\u660e\u663e\u805a\u7c7b\uff1b2) CKA\u81ea\u76f8\u4f3c\u6027\u548c\u4efb\u52a1\u51c6\u786e\u7387\u5728\u526a\u679d\u8fc7\u7a0b\u4e2d\u5f3a\u76f8\u5173\uff0c\u4f46\u51c6\u786e\u7387\u4e0b\u964d\u66f4\u5feb\uff1b3) \u67d0\u4e9b\u6a21\u578b\u5bf9\u5728\u526a\u679d\u540e\u8868\u73b0\u51fa\u6b63\u5219\u5316\u6548\u679c\uff0c\u66b4\u9732\u51fa\u5171\u4eab\u7684\u8ba1\u7b97\u6838\u5fc3\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u6536\u655b\u5230\u76f8\u4f3c\u5185\u90e8\u673a\u5236\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u65b9\u6cd5\uff0c\u662f\u79d1\u5b66\u7814\u7a76\u4e2d\u6a21\u578b\u9009\u62e9\u548c\u5206\u6790\u7684\u6709\u7528\u5de5\u5177\u3002"}}
{"id": "2601.17768", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17768", "abs": "https://arxiv.org/abs/2601.17768", "authors": ["Raja Gond", "Aditya K Kamath", "Arkaprava Basu", "Ramachandran Ramjee", "Ashish Panwar"], "title": "LLM-42: Enabling Determinism in LLM Inference with Verified Speculation", "comment": "https://github.com/microsoft/llm-42", "summary": "In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.\n  Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.", "AI": {"tldr": "LLM-42\uff1a\u57fa\u4e8e\u8c03\u5ea6\u7684\u786e\u5b9a\u6027LLM\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u9a8c\u8bc1-\u56de\u6eda\u673a\u5236\u5b9e\u73b0\u786e\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u52a8\u6001\u6279\u5904\u7406\u7684\u9ad8\u541e\u5410\u91cf", "motivation": "LLM\u63a8\u7406\u4e2d\u7684\u975e\u786e\u5b9a\u6027\u6e90\u4e8e\u6d6e\u70b9\u975e\u7ed3\u5408\u6027\u4e0e\u52a8\u6001\u6279\u5904\u7406\u7684\u7ed3\u5408\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u727a\u7272\u541e\u5410\u91cf\uff08\u7981\u7528\u52a8\u6001\u6279\u5904\u7406\uff09\uff0c\u8981\u4e48\u9700\u8981\u91cd\u65b0\u5b9e\u73b0\u5185\u6838\u4e14\u5e26\u6765\u56fa\u5b9a\u5f00\u9500\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u53c8\u80fd\u6309\u9700\u63d0\u4f9b\u786e\u5b9a\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u53d7\u63a8\u6d4b\u89e3\u7801\u542f\u53d1\uff0c\u63d0\u51faLLM-42\u8c03\u5ea6\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u975e\u786e\u5b9a\u6027\u5feb\u901f\u8def\u5f84\u89e3\u7801\u4ee4\u724c\uff1b2\uff09\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9a8c\u8bc1-\u56de\u6eda\u5faa\u73af\u5f3a\u5236\u786e\u5b9a\u6027\uff1b3\uff09\u9a8c\u8bc1\u5668\u5728\u56fa\u5b9a\u5f62\u72b6\u7f29\u51cf\u8c03\u5ea6\u4e0b\u91cd\u653e\u5019\u9009\u4ee4\u724c\uff0c\u63d0\u4ea4\u4fdd\u8bc1\u4e00\u81f4\u7684\u4ee4\u724c\uff0c\u56de\u6eda\u8fdd\u53cd\u786e\u5b9a\u6027\u7684\u4ee4\u724c\u3002", "result": "LLM-42\u80fd\u591f\uff1a1\uff09\u5927\u90e8\u5206\u91cd\u7528\u73b0\u6709\u5185\u6838\uff1b2\uff09\u4ec5\u5bf9\u9700\u8981\u786e\u5b9a\u6027\u7684\u6d41\u91cf\u4ea7\u751f\u5f00\u9500\uff1b3\uff09\u5728\u4fdd\u6301\u52a8\u6001\u6279\u5904\u7406\u9ad8\u541e\u5410\u91cf\u7684\u540c\u65f6\u63d0\u4f9b\u786e\u5b9a\u6027\u4fdd\u8bc1\u3002", "conclusion": "LLM-42\u901a\u8fc7\u8c03\u5ea6\u800c\u975e\u5185\u6838\u4fee\u6539\u5b9e\u73b0\u4e86LLM\u63a8\u7406\u7684\u786e\u5b9a\u6027\uff0c\u5728\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u7684\u540c\u65f6\u6309\u9700\u63d0\u4f9b\u786e\u5b9a\u6027\u4fdd\u8bc1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.17094", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17094", "abs": "https://arxiv.org/abs/2601.17094", "authors": ["Junichiro Niimi"], "title": "Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation", "comment": null, "summary": "Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u5634\u4e0d\u662f\u5927\u8111\"\u67b6\u6784\u539f\u5219\uff0c\u5c06\u4e16\u754c\u6a21\u578b\u4e0e\u8bed\u8a00\u6a21\u578b\u5206\u79bb\uff0c\u901a\u8fc7DBM\u4e16\u754c\u6a21\u578b\u3001\u9002\u914d\u5668\u548c\u51bb\u7ed3GPT-2\u5b9e\u73b0\u53ef\u63a7\u751f\u6210\uff0c\u5728\u6d88\u8d39\u8005\u8bc4\u8bba\u9886\u57df\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u751f\u6210\u6d41\u7545\u6587\u672c\uff0c\u4f46\u4eba\u4eec\u8d28\u7591\u5b83\u4eec\u662f\u5426\u771f\u6b63\u7406\u89e3\u4e16\u754c\u8fd8\u662f\u4ec5\u4ec5\u4ea7\u751f\u770b\u4f3c\u5408\u7406\u7684\u8bed\u8a00\u3002\u9700\u8981\u660e\u786e\u5206\u79bb\u4e16\u754c\u7406\u89e3\u548c\u8bed\u8a00\u80fd\u529b\uff0c\u5b9e\u73b0\u66f4\u4e00\u81f4\u53ef\u63a7\u7684\u751f\u6210\u3002", "method": "\u63d0\u51fa\u4e09\u7ec4\u4ef6\u67b6\u6784\uff1a1) DBM\u4f5c\u4e3a\u57fa\u4e8e\u80fd\u91cf\u7684\u4e16\u754c\u6a21\u578b\u6355\u83b7\u9886\u57df\u7ed3\u6784\uff1b2) \u9002\u914d\u5668\u5c06\u6f5c\u5728\u4fe1\u5ff5\u72b6\u6001\u6295\u5f71\u5230\u5d4c\u5165\u7a7a\u95f4\uff1b3) \u51bb\u7ed3\u7684GPT-2\u63d0\u4f9b\u8bed\u8a00\u80fd\u529b\u4f46\u4e0d\u542b\u9886\u57df\u77e5\u8bc6\u3002\u5728\u4e9a\u9a6c\u900a\u624b\u673a\u8bc4\u8bba\u9886\u57df\u5b9e\u4f8b\u5316\u8be5\u6846\u67b6\u3002", "result": "1) \u901a\u8fc7\u4e16\u754c\u6a21\u578b\u8c03\u8282\u663e\u8457\u63d0\u9ad8\u60c5\u611f\u76f8\u5173\u6027\u3001\u964d\u4f4e\u56f0\u60d1\u5ea6\u3001\u589e\u5f3a\u8bed\u4e49\u76f8\u4f3c\u6027\uff1b2) DBM\u80fd\u91cf\u51fd\u6570\u80fd\u533a\u5206\u8fde\u8d2f\u4e0e\u4e0d\u8fde\u8d2f\u5e02\u573a\u914d\u7f6e\uff1b3) \u5bf9\u7279\u5b9a\u5c5e\u6027\u7684\u5e72\u9884\u80fd\u56e0\u679c\u4f20\u64ad\u5230\u751f\u6210\u6587\u672c\uff0c\u5e72\u9884\u8f93\u51fa\u4e0e\u81ea\u7136\u6837\u672c\u7edf\u8ba1\u4e00\u81f4\u3002", "conclusion": "\u5373\u4f7f\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8fde\u63a5\u5230\u9002\u5f53\u7684\u4e16\u754c\u6a21\u578b\u4e5f\u80fd\u5b9e\u73b0\u4e00\u81f4\u53ef\u63a7\u7684\u751f\u6210\uff0c\u4e3a\u5206\u79bb\u8bed\u8a00\u80fd\u529b\u4e0e\u4e16\u754c\u7406\u89e3\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\uff0c\u8868\u660e\"\u5634\u4e0d\u662f\u5927\u8111\"\u67b6\u6784\u539f\u5219\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.17108", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.17108", "abs": "https://arxiv.org/abs/2601.17108", "authors": ["Dianxin Luan", "Chengsi Liang", "Jie Huang", "Zheng Lin", "Kaitao Meng", "John Thompson", "Cheng-Xiang Wang"], "title": "MambaNet: Mamba-assisted Channel Estimation Neural Network With Attention Mechanism", "comment": null, "summary": "This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408Mamba\u67b6\u6784\u4e0e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u4e8eOFDM\u6ce2\u5f62\u7684\u5927\u89c4\u6a21\u5b50\u8f7d\u6ce2\u4fe1\u9053\u4f30\u8ba1\uff0c\u5728\u964d\u4f4e\u590d\u6742\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u9488\u5bf9\u5177\u6709\u5927\u91cf\u5b50\u8f7d\u6ce2\u7684OFDM\u914d\u7f6e\uff0c\u4f20\u7edf\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u5b50\u8f7d\u6ce2\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u4e14\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff08\u5982\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff09\u7a7a\u95f4\u590d\u6742\u5ea6\u8f83\u9ad8\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6709\u6548\u6355\u83b7\u5b50\u8f7d\u6ce2\u95f4\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\uff0c\u53c8\u5177\u6709\u4f4e\u590d\u6742\u5ea6\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6848\u3002", "method": "\u63d0\u51faMamba\u8f85\u52a9\u7684\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u96c6\u6210\u5b9a\u5236\u5316\u7684Mamba\u67b6\u6784\u6765\u5904\u7406\u5927\u89c4\u6a21\u5b50\u8f7d\u6ce2\u4fe1\u9053\u4f30\u8ba1\u3002\u5173\u952e\u521b\u65b0\u5305\u62ec\uff1a1\uff09\u5b9e\u73b0\u53cc\u5411\u9009\u62e9\u6027\u626b\u63cf\u673a\u5236\uff08\u800c\u975e\u4f20\u7edfMamba\u7684\u5355\u5411\u626b\u63cf\uff09\uff0c\u4ee5\u9002\u5e94\u4fe1\u9053\u589e\u76ca\u5728\u4e0d\u540c\u5b50\u8f7d\u6ce2\u95f4\u7684\u975e\u56e0\u679c\u7279\u6027\uff1b2\uff09\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u6027\u80fd\uff1b3\uff09\u76f8\u6bd4Transformer\u67b6\u6784\u5177\u6709\u66f4\u4f4e\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\u3002", "result": "\u57283GPP TS 36.101\u4fe1\u9053\u4e0a\u7684\u4eff\u771f\u6d4b\u8bd5\u8868\u660e\uff0c\u76f8\u6bd4\u5176\u4ed6\u57fa\u7ebf\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u65b9\u6848\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u51cf\u5c11\u53ef\u8c03\u53c2\u6570\u6570\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u6539\u8fdb\u7684\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u5b50\u8f7d\u6ce2OFDM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7Mamba\u67b6\u6784\u4e0e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u8f83\u4f4e\u590d\u6742\u5ea6\u7684\u540c\u65f6\u6709\u6548\u6355\u83b7\u5b50\u8f7d\u6ce2\u95f4\u7684\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.17111", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17111", "abs": "https://arxiv.org/abs/2601.17111", "authors": ["Xuan-Phi Nguyen", "Shrey Pandit", "Austin Xu", "Caiming Xiong", "Shafiq Joty"], "title": "Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts", "comment": "Preprint", "summary": "Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.", "AI": {"tldr": "\u63d0\u51faLLEP\u7b97\u6cd5\u89e3\u51b3MoE\u6a21\u578b\u4e13\u5bb6\u5e76\u884c\u4e2d\u8def\u7531\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u8bbe\u5907\u8fc7\u8f7d\u95ee\u9898\uff0c\u5b9e\u73b0\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\uff0c\u63d0\u5347\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1MoE\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u65f6\u4f7f\u7528\u4e86\u8d1f\u8f7d\u5747\u8861\u7ea6\u675f\uff0c\u4f46\u5b9e\u9645\u8def\u7531\u4ecd\u7136\u5b58\u5728\u663e\u8457\u4e0d\u5e73\u8861\u3002\u8fd9\u79cd\u4e0d\u5e73\u8861\u867d\u7136\u6709\u52a9\u4e8e\u9886\u57df\u77e5\u8bc6\u96c6\u4e2d\uff0c\u4f46\u5728\u4e13\u5bb6\u5e76\u884c\u67b6\u6784\u4e0b\u4f1a\u5bfc\u81f4\u8bbe\u5907\u8fc7\u8f7d\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u540e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u65e0\u6cd5\u5e94\u7528\u663e\u5f0f\u8d1f\u8f7d\u5747\u8861\u65f6\uff0c\u53ef\u80fd\u5f15\u53d1\u8ba1\u7b97\u548c\u5185\u5b58\u6545\u969c\u3002", "method": "\u63d0\u51faLeast-Loaded Expert Parallelism (LLEP)\u7b97\u6cd5\uff0c\u52a8\u6001\u5730\u5c06\u8fc7\u8f7d\u8bbe\u5907\u4e0a\u7684\u591a\u4f59token\u548c\u76f8\u5173\u4e13\u5bb6\u53c2\u6570\u91cd\u65b0\u8def\u7531\u5230\u5229\u7528\u7387\u4e0d\u8db3\u7684\u8bbe\u5907\u4e0a\u3002\u8be5\u65b9\u6cd5\u786e\u4fdd\u6240\u6709\u8bbe\u5907\u5728\u6700\u5c0f\u96c6\u4f53\u5ef6\u8fdf\u5185\u5b8c\u6210\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u540c\u65f6\u6ee1\u8db3\u5185\u5b58\u7ea6\u675f\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\uff0cLLEP\u76f8\u6bd4\u6807\u51c6EP\u5b9e\u73b0\u4e86\u9ad8\u8fbe5\u500d\u7684\u52a0\u901f\u548c4\u500d\u7684\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u3002\u5bf9\u4e8egpt-oss-120b\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u7ea61.9\u500d\u7684\u63a8\u7406\u52a0\u901f\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "LLEP\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MoE\u6a21\u578b\u4e13\u5bb6\u5e76\u884c\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86\u540e\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e3a\u786c\u4ef6\u7279\u5b9a\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5173\u952e\u6743\u8861\u3002"}}
{"id": "2601.17112", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17112", "abs": "https://arxiv.org/abs/2601.17112", "authors": ["A. El Ichi", "K. Jbilou"], "title": "Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8ecproduct\u7684\u5f20\u91cf\u538b\u7f29\u6846\u67b6\uff0c\u7528\u4e8eLLM\u7684\u4f4e\u79e9\u8fd1\u4f3c\uff0c\u4ee5\u964d\u4f4e\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u6210\u672c", "motivation": "LLM\u867d\u7136\u5728\u5404\u79cd\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u6781\u5927\u7684\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u9700\u8981\u9ad8\u6548\u7684\u538b\u7f29\u65b9\u6cd5", "method": "\u5229\u7528cproduct\u7684\u4ee3\u6570\u7ed3\u6784\uff0c\u5728\u53d8\u6362\u57df\u4e2d\u8868\u793a\u6743\u91cd\u5f20\u91cf\uff08\u5982\u5d4c\u5165\u5c42\u3001\u6ce8\u610f\u529b\u6295\u5f71\u3001\u524d\u9988\u7f51\u7edc\uff09\uff0c\u4f7f\u6b63\u9762\u5207\u7247\u80fd\u591f\u901a\u8fc7\u4f4e\u79e9\u5f20\u91cf\u56e0\u5b50\u8054\u5408\u8fd1\u4f3c", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u8ba1\u7b97\u9ad8\u6548\u7684\u538b\u7f29\uff0c\u5229\u7528\u591a\u7ef4\u76f8\u5173\u6027\uff0c\u8d85\u8d8a\u4f20\u7edf\u7684SVD\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684cproduct\u5f20\u91cf\u538b\u7f29\u6846\u67b6\u4e3aLLM\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u79e9\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42"}}
{"id": "2601.17130", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.17130", "abs": "https://arxiv.org/abs/2601.17130", "authors": ["Megha Khosla"], "title": "How does Graph Structure Modulate Membership-Inference Risk for Graph Neural Networks?", "comment": null, "summary": "Graph neural networks (GNNs) have become the standard tool for encoding data and their complex relationships into continuous representations, improving prediction accuracy in several machine learning tasks like node classification and link prediction. However, their use in sensitive applications has raised concerns about the potential leakage of training data. Research on privacy leakage in GNNs has largely been shaped by findings from non-graph domains, such as images and tabular data. We emphasize the need of graph specific analysis and investigate the impact of graph structure on node level membership inference. We formalize MI over node-neighbourhood tuples and investigate two important dimensions: (i) training graph construction and (ii) inference-time edge access. Empirically, snowball's coverage bias often harms generalisation relative to random sampling, while enabling inter-train-test edges at inference improves test accuracy, shrinks the train-test gap, and yields the lowest membership advantage across most of the models and datasets. We further show that the generalisation gap empirically measured as the performance difference between the train and test nodes is an incomplete proxy for MI risk: access to edges dominates-MI can rise or fall independent of gap changes. Finally, we examine the auditability of differentially private GNNs, adapting the definition of statistical exchangeability of train-test data points for graph based models. We show that for node level tasks the inductive splits (random or snowball sampled) break exchangeability, limiting the applicability of standard bounds for membership advantage of differential private models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u91cd\u70b9\u5173\u6ce8\u56fe\u7ed3\u6784\u5bf9\u9690\u79c1\u6cc4\u9732\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8bad\u7ec3\u56fe\u6784\u5efa\u65b9\u5f0f\u548c\u63a8\u7406\u65f6\u8fb9\u8bbf\u95ee\u662f\u5f71\u54cd\u9690\u79c1\u98ce\u9669\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "GNN\u5728\u654f\u611f\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u5f15\u53d1\u4e86\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u7684\u62c5\u5fe7\uff0c\u73b0\u6709\u9690\u79c1\u6cc4\u9732\u7814\u7a76\u4e3b\u8981\u57fa\u4e8e\u975e\u56fe\u9886\u57df\uff08\u5982\u56fe\u50cf\u548c\u8868\u683c\u6570\u636e\uff09\uff0c\u9700\u8981\u9488\u5bf9\u56fe\u7ed3\u6784\u7684\u7279\u5b9a\u5206\u6790\u6765\u7406\u89e3\u56fe\u7ed3\u6784\u5bf9\u8282\u70b9\u7ea7\u6210\u5458\u63a8\u7406\u7684\u5f71\u54cd\u3002", "method": "\u5f62\u5f0f\u5316\u8282\u70b9-\u90bb\u57df\u5143\u7ec4\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u7814\u7a76\u4e24\u4e2a\u5173\u952e\u7ef4\u5ea6\uff1a(1)\u8bad\u7ec3\u56fe\u6784\u5efa\u65b9\u6cd5\uff08\u968f\u673a\u91c7\u6837vs\u96ea\u7403\u91c7\u6837\uff09\uff0c(2)\u63a8\u7406\u65f6\u8fb9\u8bbf\u95ee\u6743\u9650\u3002\u5b9e\u8bc1\u5206\u6790\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\uff0c\u5e76\u68c0\u67e5\u5dee\u5206\u9690\u79c1GNN\u7684\u53ef\u5ba1\u8ba1\u6027\u3002", "result": "\u96ea\u7403\u91c7\u6837\u7684\u8986\u76d6\u504f\u5dee\u901a\u5e38\u635f\u5bb3\u6cdb\u5316\u80fd\u529b\uff1b\u63a8\u7406\u65f6\u5141\u8bb8\u8bbf\u95ee\u8bad\u7ec3-\u6d4b\u8bd5\u8fb9\u80fd\u63d0\u9ad8\u6d4b\u8bd5\u7cbe\u5ea6\u3001\u7f29\u5c0f\u8bad\u7ec3-\u6d4b\u8bd5\u5dee\u8ddd\uff0c\u5e76\u5728\u5927\u591a\u6570\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u4ea7\u751f\u6700\u4f4e\u7684\u6210\u5458\u4f18\u52bf\u3002\u6cdb\u5316\u5dee\u8ddd\u4e0d\u662f\u6210\u5458\u63a8\u7406\u98ce\u9669\u7684\u5b8c\u6574\u4ee3\u7406\u6307\u6807\uff0c\u8fb9\u8bbf\u95ee\u6743\u9650\u5bf9\u9690\u79c1\u98ce\u9669\u6709\u4e3b\u5bfc\u5f71\u54cd\u3002", "conclusion": "\u56fe\u7ed3\u6784\u5bf9GNN\u9690\u79c1\u6cc4\u9732\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u56fe\u7279\u5b9a\u7684\u9690\u79c1\u5206\u6790\u3002\u5bf9\u4e8e\u8282\u70b9\u7ea7\u4efb\u52a1\uff0c\u5f52\u7eb3\u5206\u5272\uff08\u968f\u673a\u6216\u96ea\u7403\u91c7\u6837\uff09\u7834\u574f\u4e86\u6570\u636e\u70b9\u7684\u7edf\u8ba1\u53ef\u4ea4\u6362\u6027\uff0c\u9650\u5236\u4e86\u5dee\u5206\u9690\u79c1\u6a21\u578b\u6210\u5458\u4f18\u52bf\u6807\u51c6\u754c\u9650\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2601.17135", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.17135", "abs": "https://arxiv.org/abs/2601.17135", "authors": ["Jakob Karalus", "Friedhelm Schwenker"], "title": "ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning", "comment": null, "summary": "Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.", "AI": {"tldr": "ConceptACT\u901a\u8fc7\u5229\u7528\u6f14\u793a\u4e2d\u7684\u8bed\u4e49\u6982\u5ff5\u6ce8\u91ca\uff08\u7269\u4f53\u5c5e\u6027\u3001\u7a7a\u95f4\u5173\u7cfb\u3001\u4efb\u52a1\u7ea6\u675f\uff09\u6765\u63d0\u5347\u6a21\u4eff\u5b66\u4e60\u7684\u6548\u7387\uff0c\u91c7\u7528\u6982\u5ff5\u611f\u77e5\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u8bed\u4e49\u76d1\u7763\u4f46\u4e0d\u9700\u90e8\u7f72\u65f6\u8f93\u5165\u8bed\u4e49\u4fe1\u606f\u3002", "motivation": "\u5f53\u524d\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u4f4e\u7ea7\u4f20\u611f\u5668\u6570\u636e\uff0c\u5ffd\u7565\u4e86\u4eba\u7c7b\u81ea\u7136\u62e5\u6709\u7684\u4e30\u5bcc\u8bed\u4e49\u77e5\u8bc6\u3002\u4eba\u7c7b\u5728\u5b8c\u6210\u4efb\u52a1\u65f6\u7406\u89e3\u7269\u4f53\u5c5e\u6027\u3001\u7a7a\u95f4\u5173\u7cfb\u548c\u4efb\u52a1\u7ea6\u675f\u7b49\u6982\u5ff5\uff0c\u8fd9\u4e9b\u8bed\u4e49\u77e5\u8bc6\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u673a\u5668\u4eba\u5b66\u4e60\u6548\u7387\u3002", "method": "\u6269\u5c55Action Chunking with Transformers (ACT)\uff0c\u5728\u6f14\u793a\u6536\u96c6\u65f6\u52a0\u5165\u4eba\u7c7b\u63d0\u4f9b\u7684\u8bed\u4e49\u6982\u5ff5\u6ce8\u91ca\u3002\u91c7\u7528\u4fee\u6539\u7684transformer\u67b6\u6784\uff0c\u5728\u6700\u7ec8\u7f16\u7801\u5c42\u5b9e\u73b0\u6982\u5ff5\u611f\u77e5\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u4e0e\u4eba\u7c7b\u6ce8\u91ca\u5bf9\u9f50\u3002\u8bed\u4e49\u6982\u5ff5\u4ec5\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\uff0c\u4e0d\u589e\u52a0\u90e8\u7f72\u8d1f\u62c5\u3002", "result": "\u5728\u4e24\u4e2a\u5177\u6709\u903b\u8f91\u7ea6\u675f\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\uff0cConceptACT\u6bd4\u6807\u51c6ACT\u6536\u655b\u66f4\u5feb\uff0c\u6837\u672c\u6548\u7387\u66f4\u9ad8\u3002\u6ce8\u610f\u529b\u673a\u5236\u96c6\u6210\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u7b80\u5355\u7684\u8f85\u52a9\u9884\u6d4b\u635f\u5931\u6216\u8bed\u8a00\u6761\u4ef6\u6a21\u578b\u3002", "conclusion": "\u9002\u5f53\u96c6\u6210\u7684\u8bed\u4e49\u76d1\u7763\u4e3a\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002\u6982\u5ff5\u611f\u77e5\u7684\u6ce8\u610f\u529b\u673a\u5236\u662f\u6709\u6548\u5229\u7528\u8bed\u4e49\u77e5\u8bc6\u7684\u5173\u952e\u3002"}}
{"id": "2601.17180", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17180", "abs": "https://arxiv.org/abs/2601.17180", "authors": ["In\u00e9s Gonzalez-Pepe", "Vinuyan Sivakolunthu", "Jacob Fortin", "Yohan Chatelain", "Tristan Glatard"], "title": "Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging", "comment": null, "summary": "Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u6570\u503c\u4e0d\u786e\u5b9a\u6027\u7684CNN\u4f18\u5316\u65b9\u6cd5\uff1aConservative & Aggressive NaNs\uff0c\u901a\u8fc7\u8bc6\u522b\u6570\u503c\u4e0d\u7a33\u5b9a\u4f53\u7d20\u5e76\u7528NaN\u66ff\u6362\uff0c\u8df3\u8fc7\u5197\u4f59\u8ba1\u7b97\uff0c\u5728\u795e\u7ecf\u5f71\u50cf\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5e73\u57471.67\u500d\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u795e\u7ecf\u5f71\u50cf\u9886\u57df\u65e5\u76ca\u5e9e\u5927\uff0c\u8ba1\u7b97\u6548\u7387\u6210\u4e3a\u6301\u7eed\u5173\u6ce8\u70b9\u3002\u7814\u7a76\u53d1\u73b0CNN\u4e2d\u8bb8\u591a\u64cd\u4f5c\u5e94\u7528\u4e8e\u6570\u503c\u566a\u58f0\u4e3b\u5bfc\u7684\u503c\uff0c\u5bf9\u6a21\u578b\u8f93\u51fa\u5f71\u54cd\u53ef\u5ffd\u7565\uff0c\u90e8\u5206\u6a21\u578b\u4e2d\u9ad8\u8fbe\u4e09\u5206\u4e4b\u4e8c\u7684\u5377\u79ef\u64cd\u4f5c\u662f\u5197\u4f59\u7684\u3002", "method": "\u63d0\u51faConservative & Aggressive NaNs\u4e24\u79cd\u65b9\u6cd5\uff1a\u5728\u6700\u5927\u6c60\u5316\u548c\u53cd\u6c60\u5316\u64cd\u4f5c\u4e2d\u8bc6\u522b\u6570\u503c\u4e0d\u7a33\u5b9a\u4f53\u7d20\uff0c\u7528NaN\u66ff\u6362\uff0c\u4f7f\u540e\u7eed\u5c42\u80fd\u591f\u8df3\u8fc7\u65e0\u5173\u6570\u636e\u7684\u8ba1\u7b97\u3002\u4e24\u79cd\u65b9\u6cd5\u5728PyTorch\u4e2d\u5b9e\u73b0\uff0c\u65e0\u9700\u67b6\u6784\u4fee\u6539\u3002", "result": "\u5728\u5305\u542b\u81f3\u5c1150% NaN\u7684\u8f93\u5165\u4e2d\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u8fd0\u884c\u65f6\u6539\u8fdb\uff1b\u5728\u8d85\u8fc7\u4e09\u5206\u4e4b\u4e8cNaN\u7684\u6570\u636e\u4e2d\uff08\u5e38\u89c1\u4e8e\u795e\u7ecf\u5f71\u50cf\u573a\u666f\uff09\uff0c\u5e73\u5747\u63a8\u7406\u52a0\u901f1.67\u500d\u3002Conservative NaNs\u5e73\u5747\u51cf\u5c1130%\u5377\u79ef\u64cd\u4f5c\uff0c\u65e0\u6027\u80fd\u635f\u5931\uff1bAggressive NaNs\u53ef\u8df3\u8fc7\u6700\u591a69.30%\u5377\u79ef\uff0c\u4f46\u53ef\u80fd\u5076\u5c14\u5f71\u54cd\u6027\u80fd\u3002", "conclusion": "\u6570\u503c\u4e0d\u786e\u5b9a\u6027\u53ef\u88ab\u5229\u7528\u6765\u51cf\u5c11CNN\u4e2d\u7684\u5197\u4f59\u8ba1\u7b97\u5e76\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.17183", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17183", "abs": "https://arxiv.org/abs/2601.17183", "authors": ["Farzam Asad", "Junaid Saif Khan", "Maria Tariq", "Sundus Munir", "Muhammad Adnan Khan"], "title": "Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data", "comment": "27 pages, 7 figures, 4 tables", "summary": "Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u533b\u9662\u95f4\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\uff0c\u9a8c\u8bc1\u4e86FedProx\u5728\u5fc3\u810f\u75c5\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u5b64\u7acb\u6a21\u578b\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u533b\u7597\u6570\u636e\u56e0\u9690\u79c1\u6cd5\u89c4\u65e0\u6cd5\u76f4\u63a5\u5171\u4eab\uff0c\u800c\u8054\u90a6\u5b66\u4e60\u80fd\u5b9e\u73b0\u534f\u4f5c\u8bad\u7ec3\u3002\u4f46\u4e34\u5e8a\u6570\u636e\u5b58\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7279\u6027\uff0c\u9700\u8981\u89e3\u51b3\u5ba2\u6237\u7aef\u6f02\u79fb\u95ee\u9898\u3002", "method": "\u4f7f\u7528UCI\u5fc3\u810f\u75c5\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4eba\u53e3\u7edf\u8ba1\u5206\u5c42\u6a21\u62df4\u4e2a\u5f02\u8d28\u533b\u9662\u5ba2\u6237\u7aef\uff0c\u91c7\u7528FedProx\u7b97\u6cd5\uff0c\u8bbe\u7f6e\u8fd1\u7aef\u53c2\u6570mu=0.05\uff0c\u8fdb\u884c50\u6b21\u72ec\u7acb\u8fd0\u884c\u7684\u6d88\u878d\u7814\u7a76\u3002", "result": "FedProx\u8fbe\u523085.00%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u5b66\u4e60(83.33%)\u548c\u5b64\u7acb\u672c\u5730\u6a21\u578b(\u5e73\u574778.45%)\uff0c\u8fd1\u7aef\u6b63\u5219\u5316\u6709\u6548\u6291\u5236\u4e86\u5f02\u8d28\u73af\u5883\u4e2d\u7684\u5ba2\u6237\u7aef\u6f02\u79fb\u3002", "conclusion": "FedProx\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u8054\u90a6\u533b\u7597\u7cfb\u7edf\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a\u533b\u9662IT\u7ba1\u7406\u5458\u63d0\u4f9b\u4e86\u53ef\u90e8\u7f72\u7684\u7b97\u6cd5\u89c1\u89e3\u548c\u6307\u5357\u3002"}}
{"id": "2601.17189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17189", "abs": "https://arxiv.org/abs/2601.17189", "authors": ["Sabrina Mokhtari", "Sara Kodeiri", "Shubhankar Mohapatra", "Florian Tramer", "Gautam Kamath"], "title": "Rethinking Benchmarks for Differentially Private Image Classification", "comment": null, "summary": "We revisit benchmarks for differentially private image classification. We suggest a comprehensive set of benchmarks, allowing researchers to evaluate techniques for differentially private machine learning in a variety of settings, including with and without additional data, in convex settings, and on a variety of qualitatively different datasets. We further test established techniques on these benchmarks in order to see which ideas remain effective in different settings. Finally, we create a publicly available leader board for the community to track progress in differentially private machine learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u5dee\u5206\u9690\u79c1\u56fe\u50cf\u5206\u7c7b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u5168\u9762\u7684\u57fa\u51c6\u96c6\uff0c\u5e76\u521b\u5efa\u4e86\u516c\u5f00\u6392\u884c\u699c\u6765\u8ffd\u8e2a\u793e\u533a\u8fdb\u5c55\u3002", "motivation": "\u73b0\u6709\u5dee\u5206\u9690\u79c1\u673a\u5668\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u591f\u5168\u9762\uff0c\u65e0\u6cd5\u8ba9\u7814\u7a76\u8005\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u6709\u6548\u8bc4\u4f30\u6280\u672f\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u57fa\u51c6\u6765\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e00\u5957\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u6db5\u76d6\u4e0d\u540c\u8bbe\u7f6e\uff08\u6709\u65e0\u989d\u5916\u6570\u636e\u3001\u51f8\u4f18\u5316\u8bbe\u7f6e\u3001\u4e0d\u540c\u6570\u636e\u96c6\u7c7b\u578b\uff09\uff0c\u5e76\u5bf9\u73b0\u6709\u6280\u672f\u5728\u8fd9\u4e9b\u57fa\u51c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5efa\u7acb\u4e86\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e86\u73b0\u6709\u6280\u672f\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5e76\u521b\u5efa\u4e86\u516c\u5f00\u53ef\u7528\u7684\u6392\u884c\u699c\u4f9b\u793e\u533a\u8ffd\u8e2a\u8fdb\u5c55\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u516c\u5f00\u6392\u884c\u699c\uff0c\u8be5\u5de5\u4f5c\u5c06\u6709\u52a9\u4e8e\u63a8\u52a8\u5dee\u5206\u9690\u79c1\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u53d1\u5c55\uff0c\u8ba9\u7814\u7a76\u8005\u80fd\u66f4\u597d\u5730\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u6280\u672f\u3002"}}
{"id": "2601.17192", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17192", "abs": "https://arxiv.org/abs/2601.17192", "authors": ["Sukirt Thakur", "Marcus Roper", "Yang Zhou", "Reza Akbarian Bafghi", "Brahmajee K. Nallamothu", "C. Alberto Figueroa", "Srinivas Paruchuri", "Scott Burger", "Maziar Raissi"], "title": "PUNCH: Physics-informed Uncertainty-aware Network for Coronary Hemodynamics", "comment": null, "summary": "Coronary microvascular dysfunction (CMD) affects millions worldwide yet remains underdiagnosed because gold-standard physiological measurements are invasive and variably reproducible. We introduce a non-invasive, uncertainty-aware framework for estimating coronary flow reserve (CFR) directly from standard angiography. The system integrates physics-informed neural networks with variational inference to infer coronary blood flow from first-principles models of contrast transport, without requiring ground-truth flow measurements. The pipeline runs in approximately three minutes per patient on a single GPU, with no population-level training.\n  Using 1{,}000 synthetic spatiotemporal intensity maps (kymographs) with controlled noise and artifacts, the framework reliably identifies degraded data and outputs appropriately inflated uncertainty estimates, showing strong correspondence between predictive uncertainty and error (Pearson $r = 0.997$, Spearman $\u03c1= 0.998$). Clinical validation in 12 patients shows strong agreement between PUNCH-derived CFR and invasive bolus thermodilution (Pearson $r = 0.90$, $p = 6.3 \\times 10^{-5}$). We focus on the LAD, the artery most commonly assessed in routine CMD testing. Probabilistic CFR estimates have confidence intervals narrower than the variability of repeated invasive measurements.\n  By transforming routine angiography into quantitative, uncertainty-aware assessment, this approach enables scalable, safer, and more reproducible evaluation of coronary microvascular function. Because standard angiography is widely available globally, the framework could expand access to CMD diagnosis and establish a new paradigm for physics-informed, patient-specific inference from clinical imaging.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u975e\u4fb5\u5165\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6846\u67b6\uff0c\u76f4\u63a5\u4ece\u6807\u51c6\u8840\u7ba1\u9020\u5f71\u4e2d\u4f30\u8ba1\u51a0\u72b6\u52a8\u8109\u8840\u6d41\u50a8\u5907\uff0c\u65e0\u9700\u771f\u5b9e\u8840\u6d41\u6d4b\u91cf\uff0c\u53ef\u5728\u5355GPU\u4e0a3\u5206\u949f\u5185\u5b8c\u6210\u60a3\u8005\u8bc4\u4f30\u3002", "motivation": "\u51a0\u72b6\u52a8\u8109\u5fae\u8840\u7ba1\u529f\u80fd\u969c\u788d\u5f71\u54cd\u6570\u767e\u4e07\u4eba\uff0c\u4f46\u73b0\u6709\u91d1\u6807\u51c6\u6d4b\u91cf\u65b9\u6cd5\u5177\u6709\u4fb5\u5165\u6027\u4e14\u53ef\u91cd\u590d\u6027\u5dee\uff0c\u9700\u8981\u975e\u4fb5\u5165\u6027\u3001\u53ef\u6269\u5c55\u7684\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u6574\u5408\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u4e0e\u53d8\u5206\u63a8\u65ad\uff0c\u4ece\u9020\u5f71\u5242\u4f20\u8f93\u7684\u7b2c\u4e00\u6027\u539f\u7406\u6a21\u578b\u63a8\u65ad\u51a0\u72b6\u52a8\u8109\u8840\u6d41\uff0c\u65e0\u9700\u771f\u5b9e\u8840\u6d41\u6d4b\u91cf\u6570\u636e\uff0c\u4f7f\u7528\u5408\u6210\u65f6\u7a7a\u5f3a\u5ea6\u56fe\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e2d\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0e\u8bef\u5dee\u9ad8\u5ea6\u76f8\u5173\uff08Pearson r=0.997\uff09\uff1b\u4e34\u5e8a\u9a8c\u8bc1\u663e\u793a\u4e0e\u4fb5\u5165\u6027\u70ed\u7a00\u91ca\u6cd5CFR\u5f3a\u76f8\u5173\uff08r=0.90\uff0cp=6.3\u00d710^-5\uff09\uff0c\u7f6e\u4fe1\u533a\u95f4\u5c0f\u4e8e\u91cd\u590d\u4fb5\u5165\u6d4b\u91cf\u7684\u53d8\u5f02\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u5e38\u89c4\u8840\u7ba1\u9020\u5f71\u8f6c\u5316\u4e3a\u5b9a\u91cf\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u8bc4\u4f30\uff0c\u53ef\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u66f4\u5b89\u5168\u3001\u53ef\u91cd\u590d\u7684\u51a0\u72b6\u52a8\u8109\u5fae\u8840\u7ba1\u529f\u80fd\u8bc4\u4f30\uff0c\u6709\u671b\u6269\u5927CMD\u8bca\u65ad\u7684\u53ef\u53ca\u6027\u3002"}}
{"id": "2601.17196", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17196", "abs": "https://arxiv.org/abs/2601.17196", "authors": ["Nghia Thu Truong", "Qui Phu Pham", "Quang Nguyen", "Dung Luong", "Mai Tran"], "title": "Accelerated Sinkhorn Algorithms for Partial Optimal Transport", "comment": null, "summary": "Partial Optimal Transport (POT) addresses the problem of transporting only a fraction of the total mass between two distributions, making it suitable when marginals have unequal size or contain outliers. While Sinkhorn-based methods are widely used, their complexity bounds for POT remain suboptimal and can limit scalability. We introduce Accelerated Sinkhorn for POT (ASPOT), which integrates alternating minimization with Nesterov-style acceleration in the POT setting, yielding a complexity of $\\mathcal{O}(n^{7/3}\\varepsilon^{-5/3})$. We also show that an informed choice of the entropic parameter $\u03b3$ improves rates for the classical Sinkhorn method. Experiments on real-world applications validate our theories and demonstrate the favorable performance of our proposed methods.", "AI": {"tldr": "ASPOT\u7b97\u6cd5\u5c06\u4ea4\u66ff\u6700\u5c0f\u5316\u4e0eNesterov\u52a0\u901f\u7ed3\u5408\uff0c\u7528\u4e8e\u90e8\u5206\u6700\u4f18\u4f20\u8f93\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86O(n^{7/3}\u03b5^{-5/3})\u7684\u590d\u6742\u5ea6\uff0c\u4f18\u4e8e\u4f20\u7edfSinkhorn\u65b9\u6cd5\u3002", "motivation": "\u90e8\u5206\u6700\u4f18\u4f20\u8f93(POT)\u5904\u7406\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u4ec5\u4f20\u8f93\u90e8\u5206\u8d28\u91cf\u7684\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u5206\u5e03\u5927\u5c0f\u4e0d\u7b49\u6216\u5305\u542b\u5f02\u5e38\u503c\u7684\u60c5\u51b5\u3002\u867d\u7136Sinkhorn\u65b9\u6cd5\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u5728POT\u4e2d\u7684\u590d\u6742\u5ea6\u754c\u9650\u4ecd\u4e0d\u7406\u60f3\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u52a0\u901fSinkhorn\u7528\u4e8ePOT(ASPOT)\uff0c\u5c06\u4ea4\u66ff\u6700\u5c0f\u5316\u4e0eNesterov\u98ce\u683c\u52a0\u901f\u7ed3\u5408\u5728POT\u8bbe\u7f6e\u4e2d\u3002\u540c\u65f6\u5c55\u793a\u4e86\u901a\u8fc7\u660e\u667a\u9009\u62e9\u71b5\u53c2\u6570\u03b3\u53ef\u4ee5\u6539\u8fdb\u7ecf\u5178Sinkhorn\u65b9\u6cd5\u7684\u6536\u655b\u901f\u7387\u3002", "result": "ASPOT\u5b9e\u73b0\u4e86O(n^{7/3}\u03b5^{-5/3})\u7684\u590d\u6742\u5ea6\uff0c\u4f18\u4e8e\u4f20\u7edfSinkhorn\u65b9\u6cd5\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u5e76\u5c55\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "ASPOT\u4e3a\u90e8\u5206\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a0\u901f\u6280\u672f\u663e\u8457\u6539\u5584\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u4f18\u5316\u71b5\u53c2\u6570\u9009\u62e9\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u4f20\u7edfSinkhorn\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2601.17204", "categories": ["cs.LG", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.17204", "abs": "https://arxiv.org/abs/2601.17204", "authors": ["Yinkai Wang", "Yan Zhou Chen", "Xiaohui Chen", "Li-Ping Liu", "Soha Hassoun"], "title": "SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment", "comment": "preprint", "summary": "Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at https://github.com/HassounLab/SpecBridge.", "AI": {"tldr": "SpecBridge\uff1a\u4e00\u79cd\u65b0\u9896\u7684\u9690\u5f0f\u5bf9\u9f50\u6846\u67b6\uff0c\u5c06\u8d28\u8c31\u7ed3\u6784\u8bc6\u522b\u89c6\u4e3a\u51e0\u4f55\u5bf9\u9f50\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u8d28\u8c31\u7f16\u7801\u5668\u6295\u5f71\u5230\u51bb\u7ed3\u5206\u5b50\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u5206\u5b50\u8bc6\u522b\u51c6\u786e\u7387", "motivation": "\u5f53\u524d\u5c0f\u5206\u5b50\u8d28\u8c31\u8bc6\u522b\u5b58\u5728\u74f6\u9888\uff1a\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u91c7\u7528\u539f\u5b50\u7ea7\u6784\u5efa\u5206\u5b50\u56fe\u7684\u663e\u5f0f\u751f\u6210\u6a21\u578b\uff0c\u8981\u4e48\u4ece\u5934\u5b66\u4e60\u8de8\u6a21\u6001\u5b50\u7a7a\u95f4\u7684\u8054\u5408\u5bf9\u6bd4\u6a21\u578b\uff0c\u8fd9\u4e24\u79cd\u6781\u7aef\u65b9\u6cd5\u90fd\u6709\u5c40\u9650\u6027", "method": "SpecBridge\u91c7\u7528\u9690\u5f0f\u5bf9\u9f50\u6846\u67b6\uff0c\u5fae\u8c03\u81ea\u76d1\u7763\u8d28\u8c31\u7f16\u7801\u5668\uff08DreaMS\uff09\u76f4\u63a5\u6295\u5f71\u5230\u51bb\u7ed3\u5206\u5b50\u57fa\u7840\u6a21\u578b\uff08ChemBERTa\uff09\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u7136\u540e\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5728\u9884\u8ba1\u7b97\u5206\u5b50\u5d4c\u5165\u5e93\u4e2d\u8fdb\u884c\u68c0\u7d22", "result": "\u5728MassSpecGym\u3001Spectraverse\u548cMSnLib\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSpecBridge\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u795e\u7ecf\u65b9\u6cd5\u5c06top-1\u68c0\u7d22\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u7ea620-25%\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u8f83\u5c11", "conclusion": "\u5bf9\u9f50\u51bb\u7ed3\u57fa\u7840\u6a21\u578b\u662f\u8bbe\u8ba1\u65b0\u67b6\u6784\u7684\u5b9e\u7528\u7a33\u5b9a\u66ff\u4ee3\u65b9\u6848\uff0cSpecBridge\u6846\u67b6\u4e3a\u5c0f\u5206\u5b50\u8d28\u8c31\u8bc6\u522b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.17207", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17207", "abs": "https://arxiv.org/abs/2601.17207", "authors": ["Maedeh Makki", "Satish Chandran", "Maziar Raissi", "Adrien Grenier", "Behzad Mohebbi"], "title": "NewPINNs: Physics-Informing Neural Networks Using Conventional Solvers for Partial Differential Equations", "comment": null, "summary": "We introduce NewPINNs, a physics-informing learning framework that couples neural networks with conventional numerical solvers for solving differential equations. Rather than enforcing governing equations and boundary conditions through residual-based loss terms, NewPINNs integrates the solver directly into the training loop and defines learning objectives through solver-consistency. The neural network produces candidate solution states that are advanced by the numerical solver, and training minimizes the discrepancy between the network prediction and the solver-evolved state. This pull-push interaction enables the network to learn physically admissible solutions through repeated exposure to the solver's action, without requiring problem-specific loss engineering or explicit evaluation of differential equation residuals. By delegating the enforcement of physics, boundary conditions, and numerical stability to established numerical solvers, NewPINNs mitigates several well-known failure modes of standard physics-informed neural networks, including optimization pathologies, sensitivity to loss weighting, and poor performance in stiff or nonlinear regimes. We demonstrate the effectiveness of the proposed approach across multiple forward and inverse problems involving finite volume, finite element, and spectral solvers.", "AI": {"tldr": "NewPINNs \u662f\u4e00\u79cd\u65b0\u7684\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u795e\u7ecf\u7f51\u7edc\u4e0e\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u7ed3\u5408\u6c42\u89e3\u5fae\u5206\u65b9\u7a0b\uff0c\u901a\u8fc7\u6c42\u89e3\u5668\u4e00\u81f4\u6027\u800c\u975e\u6b8b\u5dee\u635f\u5931\u6765\u6267\u884c\u7269\u7406\u7ea6\u675f\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u5b58\u5728\u4f18\u5316\u75c5\u7406\u3001\u635f\u5931\u6743\u91cd\u654f\u611f\u3001\u5728\u521a\u6027\u95ee\u9898\u6216\u975e\u7ebf\u6027\u533a\u57df\u8868\u73b0\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u95ee\u9898\u7279\u5b9a\u7684\u635f\u5931\u51fd\u6570\u3002", "method": "\u5c06\u6570\u503c\u6c42\u89e3\u5668\u76f4\u63a5\u96c6\u6210\u5230\u8bad\u7ec3\u5faa\u73af\u4e2d\uff0c\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u5019\u9009\u89e3\u72b6\u6001\uff0c\u6570\u503c\u6c42\u89e3\u5668\u63a8\u8fdb\u8fd9\u4e9b\u72b6\u6001\uff0c\u8bad\u7ec3\u6700\u5c0f\u5316\u7f51\u7edc\u9884\u6d4b\u4e0e\u6c42\u89e3\u5668\u6f14\u5316\u72b6\u6001\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "NewPINNs \u5728\u6d89\u53ca\u6709\u9650\u4f53\u79ef\u3001\u6709\u9650\u5143\u548c\u8c31\u6c42\u89e3\u5668\u7684\u591a\u4e2a\u6b63\u5411\u548c\u9006\u5411\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u7f13\u89e3\u4e86\u6807\u51c6PINNs\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7269\u7406\u7ea6\u675f\u3001\u8fb9\u754c\u6761\u4ef6\u548c\u6570\u503c\u7a33\u5b9a\u6027\u7684\u6267\u884c\u59d4\u6258\u7ed9\u6210\u719f\u7684\u6570\u503c\u6c42\u89e3\u5668\uff0cNewPINNs \u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u95ee\u9898\u7279\u5b9a\u7684\u635f\u5931\u5de5\u7a0b\u3002"}}
{"id": "2601.17215", "categories": ["cs.LG", "hep-ex"], "pdf": "https://arxiv.org/pdf/2601.17215", "abs": "https://arxiv.org/abs/2601.17215", "authors": ["Ruoqing Zheng", "Chang Sun", "Qibin Liu", "Lauri Laatu", "Arianna Cox", "Benedikt Maier", "Alexander Tapper", "Jose G. F. Coutinho", "Wayne Luk", "Zhiqiang Que"], "title": "JetFormer: A Scalable and Efficient Transformer for Jet Tagging from Offline Analysis to FPGA Triggers", "comment": "15 pages,", "summary": "We present JetFormer, a versatile and scalable encoder-only Transformer architecture for particle jet tagging at the Large Hadron Collider (LHC). Unlike prior approaches that are often tailored to specific deployment regimes, JetFormer is designed to operate effectively across the full spectrum of jet tagging scenarios, from high-accuracy offline analysis to ultra-low-latency online triggering. The model processes variable-length sets of particle features without relying on input of explicit pairwise interactions, yet achieves competitive or superior performance compared to state-of-the-art methods. On the large-scale JetClass dataset, a large-scale JetFormer matches the accuracy of the interaction-rich ParT model (within 0.7%) while using 37.4% fewer FLOPs, demonstrating its computational efficiency and strong generalization. On benchmark HLS4ML 150P datasets, JetFormer consistently outperforms existing models such as MLPs, Deep Sets, and Interaction Networks by 3-4% in accuracy. To bridge the gap to hardware deployment, we further introduce a hardware-aware optimization pipeline based on multi-objective hyperparameter search, yielding compact variants like JetFormer-tiny suitable for FPGA-based trigger systems with sub-microsecond latency requirements. Through structured pruning and quantization, we show that JetFormer can be aggressively compressed with minimal accuracy loss. By unifying high-performance modeling and deployability within a single architectural framework, JetFormer provides a practical pathway for deploying Transformer-based jet taggers in both offline and online environments at the LHC. Code is available at https://github.com/walkieq/JetFormer.", "AI": {"tldr": "JetFormer\u662f\u4e00\u4e2a\u7528\u4e8e\u7c92\u5b50\u55b7\u6ce8\u6807\u8bb0\u7684Transformer\u67b6\u6784\uff0c\u5728\u79bb\u7ebf\u5206\u6790\u548c\u5728\u7ebf\u89e6\u53d1\u573a\u666f\u4e2d\u90fd\u80fd\u9ad8\u6548\u8fd0\u884c\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\u4e14\u6613\u4e8e\u786c\u4ef6\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u90e8\u7f72\u573a\u666f\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u5728LHC\u5168\u8c31\u55b7\u6ce8\u6807\u8bb0\u573a\u666f\uff08\u4ece\u9ad8\u7cbe\u5ea6\u79bb\u7ebf\u5206\u6790\u5230\u8d85\u4f4e\u5ef6\u8fdf\u5728\u7ebf\u89e6\u53d1\uff09\u4e2d\u7edf\u4e00\u5de5\u4f5c\u7684\u67b6\u6784\u3002", "method": "\u63d0\u51faJetFormer\uff0c\u4e00\u4e2a\u4ec5\u7f16\u7801\u5668\u7684Transformer\u67b6\u6784\uff0c\u5904\u7406\u53d8\u957f\u7c92\u5b50\u7279\u5f81\u96c6\u800c\u4e0d\u4f9d\u8d56\u663e\u5f0f\u6210\u5bf9\u4ea4\u4e92\u3002\u91c7\u7528\u786c\u4ef6\u611f\u77e5\u4f18\u5316\u6d41\u7a0b\uff0c\u5305\u62ec\u591a\u76ee\u6807\u8d85\u53c2\u6570\u641c\u7d22\u3001\u7ed3\u6784\u5316\u526a\u679d\u548c\u91cf\u5316\uff0c\u751f\u6210\u9002\u5408FPGA\u90e8\u7f72\u7684\u7d27\u51d1\u53d8\u4f53\u3002", "result": "\u5728JetClass\u6570\u636e\u96c6\u4e0a\uff0cJetFormer\u4e0eParT\u6a21\u578b\u7cbe\u5ea6\u76f8\u5f53\uff08\u76f8\u5dee0.7%\u5185\uff09\u4f46FLOPs\u51cf\u5c1137.4%\u3002\u5728HLS4ML 150P\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u6bd4MLPs\u3001Deep Sets\u548cInteraction Networks\u51c6\u786e\u7387\u9ad83-4%\u3002\u901a\u8fc7\u538b\u7f29\uff0cJetFormer-tiny\u53d8\u4f53\u53ef\u6ee1\u8db3\u4e9a\u5fae\u79d2\u7ea7\u5ef6\u8fdf\u7684FPGA\u89e6\u53d1\u7cfb\u7edf\u9700\u6c42\u3002", "conclusion": "JetFormer\u5c06\u9ad8\u6027\u80fd\u5efa\u6a21\u4e0e\u53ef\u90e8\u7f72\u6027\u7edf\u4e00\u5728\u5355\u4e00\u67b6\u6784\u6846\u67b6\u5185\uff0c\u4e3a\u5728LHC\u79bb\u7ebf\u548c\u5728\u7ebf\u73af\u5883\u4e2d\u90e8\u7f72\u57fa\u4e8eTransformer\u7684\u55b7\u6ce8\u6807\u8bb0\u5668\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2601.17224", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17224", "abs": "https://arxiv.org/abs/2601.17224", "authors": ["Dmitrii Torbunov", "Yihui Ren", "Lijun Wu", "Yimei Zhu"], "title": "Parameter Inference and Uncertainty Quantification with Diffusion Models: Extending CDI to 2D Spatial Conditioning", "comment": null, "summary": "Uncertainty quantification is critical in scientific inverse problems to distinguish identifiable parameters from those that remain ambiguous given available measurements. The Conditional Diffusion Model-based Inverse Problem Solver (CDI) has previously demonstrated effective probabilistic inference for one-dimensional temporal signals, but its applicability to higher-dimensional spatial data remains unexplored. We extend CDI to two-dimensional spatial conditioning, enabling probabilistic parameter inference directly from spatial observations. We validate this extension on convergent beam electron diffraction (CBED) parameter inference - a challenging multi-parameter inverse problem in materials characterization where sample geometry, electronic structure, and thermal properties must be extracted from 2D diffraction patterns. Using simulated CBED data with ground-truth parameters, we demonstrate that CDI produces well-calibrated posterior distributions that accurately reflect measurement constraints: tight distributions for well-determined quantities and appropriately broad distributions for ambiguous parameters. In contrast, standard regression methods - while appearing accurate on aggregate metrics - mask this underlying uncertainty by predicting training set means for poorly constrained parameters. Our results confirm that CDI successfully extends from temporal to spatial domains, providing the genuine uncertainty information required for robust scientific inference.", "AI": {"tldr": "\u5c06\u6761\u4ef6\u6269\u6563\u6a21\u578b\u4ece\u4e00\u7ef4\u65f6\u95f4\u4fe1\u53f7\u6269\u5c55\u5230\u4e8c\u7ef4\u7a7a\u95f4\u6570\u636e\uff0c\u7528\u4e8e\u79d1\u5b66\u9006\u95ee\u9898\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5728\u6750\u6599\u8868\u5f81\u7684CBED\u53c2\u6570\u63a8\u65ad\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u79d1\u5b66\u9006\u95ee\u9898\u4e2d\u9700\u8981\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u4ee5\u533a\u5206\u53ef\u8bc6\u522b\u53c2\u6570\u548c\u6a21\u7cca\u53c2\u6570\u3002\u867d\u7136CDI\u5728\u4e00\u7ef4\u65f6\u95f4\u4fe1\u53f7\u4e0a\u6709\u6548\uff0c\u4f46\u5176\u5728\u66f4\u9ad8\u7ef4\u7a7a\u95f4\u6570\u636e\u4e0a\u7684\u9002\u7528\u6027\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u5c06\u6761\u4ef6\u6269\u6563\u6a21\u578b\u9006\u95ee\u9898\u6c42\u89e3\u5668\uff08CDI\uff09\u6269\u5c55\u5230\u4e8c\u7ef4\u7a7a\u95f4\u6761\u4ef6\uff0c\u76f4\u63a5\u4ece\u7a7a\u95f4\u89c2\u6d4b\u4e2d\u8fdb\u884c\u6982\u7387\u53c2\u6570\u63a8\u65ad\u3002\u5728\u4f1a\u805a\u675f\u7535\u5b50\u884d\u5c04\uff08CBED\uff09\u53c2\u6570\u63a8\u65ad\u8fd9\u4e00\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u53c2\u6570\u9006\u95ee\u9898\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "CDI\u4ea7\u751f\u4e86\u6821\u51c6\u826f\u597d\u7684\u540e\u9a8c\u5206\u5e03\uff1a\u5bf9\u4e8e\u786e\u5b9a\u6027\u597d\u7684\u53c2\u6570\u6709\u7d27\u5bc6\u5206\u5e03\uff0c\u5bf9\u4e8e\u6a21\u7cca\u53c2\u6570\u6709\u9002\u5f53\u5bbd\u6cdb\u7684\u5206\u5e03\u3002\u800c\u6807\u51c6\u56de\u5f52\u65b9\u6cd5\u867d\u7136\u805a\u5408\u6307\u6807\u770b\u4f3c\u51c6\u786e\uff0c\u5374\u901a\u8fc7\u9884\u6d4b\u8bad\u7ec3\u96c6\u5747\u503c\u6765\u63a9\u76d6\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "CDI\u6210\u529f\u4ece\u65f6\u95f4\u57df\u6269\u5c55\u5230\u7a7a\u95f4\u57df\uff0c\u4e3a\u7a33\u5065\u7684\u79d1\u5b66\u63a8\u65ad\u63d0\u4f9b\u4e86\u771f\u5b9e\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\u3002"}}
{"id": "2601.17257", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17257", "abs": "https://arxiv.org/abs/2601.17257", "authors": ["Javier Porras-Valenzuela", "Samar Hadou", "Alejandro Ribeiro"], "title": "A Constrained Optimization Perspective of Unrolled Transformers", "comment": null, "summary": "We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ea6\u675f\u4f18\u5316\u6846\u67b6\uff0c\u8bad\u7ec3transformer\u50cf\u4f18\u5316\u4e0b\u964d\u7b97\u6cd5\u4e00\u6837\u5de5\u4f5c\uff0c\u901a\u8fc7\u5c42\u95f4\u4e0b\u964d\u7ea6\u675f\u548c\u539f\u59cb-\u5bf9\u5076\u8bad\u7ec3\u65b9\u6848\uff0c\u4f7f\u4e2d\u95f4\u8868\u793a\u5728\u671f\u671b\u4e0a\u5355\u8c03\u964d\u4f4e\u635f\u5931", "motivation": "\u4f20\u7edftransformer\u8bad\u7ec3\u4f7f\u7528\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff08ERM\uff09\uff0c\u4f46\u7f3a\u4e4f\u4f18\u5316\u7b97\u6cd5\u7684\u7406\u8bba\u4fdd\u8bc1\u3002\u5e0c\u671b\u8ba9transformer\u5177\u6709\u7c7b\u4f3c\u4f18\u5316\u4e0b\u964d\u7b97\u6cd5\u7684\u884c\u4e3a\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b", "method": "\u5f15\u5165\u7ea6\u675f\u4f18\u5316\u6846\u67b6\uff1a1\uff09\u5728\u76ee\u6807\u51fd\u6570\u4e0a\u65bd\u52a0\u5c42\u95f4\u4e0b\u964d\u7ea6\u675f\uff1b2\uff09\u7528\u539f\u59cb-\u5bf9\u5076\u8bad\u7ec3\u65b9\u6848\u66ff\u4ee3\u6807\u51c6ERM\uff1b3\uff09\u786e\u4fdd\u4e2d\u95f4\u8868\u793a\u5728\u671f\u671b\u4e0a\u5355\u8c03\u964d\u4f4e\u635f\u5931\uff1b\u5e94\u7528\u4e8e\u5c55\u5f00\u5f0ftransformer\u548c\u9884\u8bad\u7ec3transformer", "result": "\u5728\u89c6\u9891\u53bb\u566a\u548c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u7ea6\u675ftransformer\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6270\u52a8\u9c81\u68d2\u6027\uff0c\u4fdd\u6301\u66f4\u9ad8\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u5206\u5e03\u5185\u6027\u80fd", "conclusion": "\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u6846\u67b6\u8bad\u7ec3transformer\u5177\u6709\u4f18\u5316\u4e0b\u964d\u7b97\u6cd5\u7684\u7279\u6027\uff0c\u80fd\u591f\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3atransformer\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6307\u5bfc"}}
{"id": "2601.17260", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17260", "abs": "https://arxiv.org/abs/2601.17260", "authors": ["Marco Pollanen"], "title": "The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment", "comment": "10 Pages, 5 Figures", "summary": "Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $\u03b2$) yields progressively \"better\" behavior. We instead treat $\u03b2$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $\u03b2\\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $\u03b2$ induces capability losses that persist even after $\u03b2$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $\u03b2$ landscape rather than reliance on margins or aggregate benchmarks.", "AI": {"tldr": "DPO\u7684\u03b2\u53c2\u6570\u4e0d\u662f\u7b80\u5355\u7684\"\u8d8a\u5927\u8d8a\u597d\"\u7684\u5bf9\u9f50\u538b\u529b\u63a7\u5236\uff0c\u800c\u662f\u4f1a\u4ee5\u590d\u6742\u65b9\u5f0f\u5f71\u54cd\u6a21\u578b\u80fd\u529b\uff0c\u4e0d\u540c\u67b6\u6784\u54cd\u5e94\u6a21\u5f0f\u4e0d\u540c\uff0c\u504f\u597d\u8fb9\u754c\u53ef\u80fd\u4e0e\u63a8\u7406\u80fd\u529b\u53cd\u76f8\u5173\uff0c\u4e14\u5b58\u5728\u8bad\u7ec3\u8def\u5f84\u4f9d\u8d56\u7684\u6ede\u540e\u6548\u5e94\u3002", "motivation": "\u5f53\u524dDPO\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u589e\u52a0\u03b2\u53c2\u6570\uff08\u5bf9\u9f50\u538b\u529b\uff09\u4f1a\u6301\u7eed\u6539\u5584\u6a21\u578b\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u03b2\u4f5c\u4e3a\u63a7\u5236\u53c2\u6570\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u03b2\u503c\u4e0b\u6a21\u578b\u80fd\u529b\u7684\u771f\u5b9e\u53d8\u5316\u6a21\u5f0f\u3002", "method": "\u5bf9\u4e09\u4e2a7B\u5f00\u6e90\u6a21\u578b\u5bb6\u65cf\uff08Mistral\u3001Llama\u3001Qwen\uff09\u5728\u56fa\u5b9aDPO\u914d\u65b9\u4e0b\u5bc6\u96c6\u626b\u63cf\u03b2\u53c2\u6570\uff0c\u901a\u8fc7\u903b\u8f91\u63a2\u9488\u7b49\u5de5\u5177\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u53d8\u5316\uff0c\u5206\u6790\u4e0d\u540c\u67b6\u6784\u7684\u54cd\u5e94\u6a21\u5f0f\u3002", "result": "1. Mistral\u80fd\u529b\u5448\u5c16\u9510\u975e\u5355\u8c03\u53d8\u5316\uff0c\u4ec5\u5728\u03b2\u224810\u207b\u00b2\u7a84\u5e26\u5185\u903b\u8f91\u63a2\u9488\u8fb9\u754c\u4e3a\u6b63\uff1b2. \u4e0d\u540c\u67b6\u6784\u54cd\u5e94\u6a21\u5f0f\u4e0d\u540c\uff1aMistral\u6025\u5267\u91cd\u7ec4\uff0cLlama\u9009\u62e9\u6027\u53d8\u5316\uff0cQwen\u5e73\u6ed1\u6743\u8861\uff1b3. DPO\u504f\u597d\u8fb9\u754c\u4e0e\u63a8\u7406\u80fd\u529b\u53cd\u76f8\u5173\uff08Llama\u903b\u8f91r=-0.91\uff09\uff1b4. \u9ad8\u03b2\u8bad\u7ec3\u5bfc\u81f4\u80fd\u529b\u635f\u5931\uff0c\u5373\u4f7f\u964d\u4f4e\u03b2\u4e5f\u65e0\u6cd5\u6062\u590d\uff08\u6ede\u540e\u6548\u5e94\uff09\u3002", "conclusion": "\u4e0d\u80fd\u7b80\u5355\u4f9d\u8d56\u504f\u597d\u8fb9\u754c\u6216\u805a\u5408\u57fa\u51c6\u6765\u9009\u62e9DPO\u6a21\u578b\uff0c\u9700\u8981\u5728\u03b2\u53c2\u6570\u7a7a\u95f4\u8fdb\u884c\u80fd\u529b\u89e3\u6790\u8bc4\u4f30\u3002\u03b2\u5e94\u88ab\u89c6\u4e3a\u63a7\u5236\u53c2\u6570\u800c\u975e\u7b80\u5355\u5bf9\u9f50\u538b\u529b\u6307\u6807\uff0c\u8bad\u7ec3\u8def\u5f84\u5bf9\u6700\u7ec8\u80fd\u529b\u6709\u6301\u4e45\u5f71\u54cd\u3002"}}
{"id": "2601.17261", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17261", "abs": "https://arxiv.org/abs/2601.17261", "authors": ["Wei Lin", "Yining Jiang", "Qingyu Song", "Qiao Xiang", "Hong Xu"], "title": "AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning", "comment": "21 pages in total, including 9 pages of main text, with 4 figures and 3 tables. This manuscript is submitted to arXiv", "summary": "Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.", "AI": {"tldr": "AGZO\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6fc0\u6d3b\u7ed3\u6784\u6307\u5bfc\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u524d\u5411\u4f20\u64ad\u4e2d\u7684\u6fc0\u6d3b\u4fe1\u606f\u6784\u5efa\u4f4e\u79e9\u6270\u52a8\u5b50\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347LLM\u5fae\u8c03\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u5404\u5411\u540c\u6027\u6270\u52a8\uff0c\u5ffd\u7565\u4e86\u524d\u5411\u4f20\u64ad\u4e2d\u4e30\u5bcc\u7684\u7ed3\u6784\u4fe1\u606f\u3002\u4f5c\u8005\u53d1\u73b0\u7ebf\u6027\u5c42\u7684\u68af\u5ea6\u88ab\u9650\u5236\u5728\u5176\u8f93\u5165\u6fc0\u6d3b\u5f20\u6210\u7684\u5b50\u7a7a\u95f4\u4e2d\uff0c\u8fd9\u4e3a\u6539\u8fdb\u96f6\u9636\u4f18\u5316\u63d0\u4f9b\u4e86\u5173\u952e\u6d1e\u89c1\u3002", "method": "\u63d0\u51faAGZO\u65b9\u6cd5\uff1a\u5728\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u5b9e\u65f6\u63d0\u53d6\u7d27\u51d1\u7684\u6fc0\u6d3b\u4fe1\u606f\u5b50\u7a7a\u95f4\uff0c\u5c06\u6270\u52a8\u9650\u5236\u5728\u8fd9\u4e2a\u4f4e\u79e9\u5b50\u7a7a\u95f4\u4e2d\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u5404\u5411\u540c\u6027\u6270\u52a8\u3002", "result": "AGZO\u5728Qwen3\u548cPangu\u6a21\u578b\u4e0a\u4f18\u4e8e\u73b0\u6709\u96f6\u9636\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u4e00\u9636\u5fae\u8c03\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u5176\u4ed6\u96f6\u9636\u65b9\u6cd5\u51e0\u4e4e\u76f8\u540c\u7684\u5cf0\u503c\u5185\u5b58\u5360\u7528\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u6fc0\u6d3b\u7ed3\u6784\u4fe1\u606f\u6307\u5bfc\u96f6\u9636\u4f18\u5316\uff0cAGZO\u5728\u4fdd\u6301\u5185\u5b58\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86LLM\u5fae\u8c03\u6027\u80fd\uff0c\u4e3a\u96f6\u9636\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2601.17274", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17274", "abs": "https://arxiv.org/abs/2601.17274", "authors": ["Samar Hadou", "Alejandro Ribeiro"], "title": "Unrolled Neural Networks for Constrained Optimization", "comment": null, "summary": "In this paper, we develop unrolled neural networks to solve constrained optimization problems, offering accelerated, learnable counterparts to dual ascent (DA) algorithms. Our framework, termed constrained dual unrolling (CDU), comprises two coupled neural networks that jointly approximate the saddle point of the Lagrangian. The primal network emulates an iterative optimizer that finds a stationary point of the Lagrangian for a given dual multiplier, sampled from an unknown distribution. The dual network generates trajectories towards the optimal multipliers across its layers while querying the primal network at each layer. Departing from standard unrolling, we induce DA dynamics by imposing primal-descent and dual-ascent constraints through constrained learning. We formulate training the two networks as a nested optimization problem and propose an alternating procedure that updates the primal and dual networks in turn, mitigating uncertainty in the multiplier distribution required for primal network training. We numerically evaluate the framework on mixed-integer quadratic programs (MIQPs) and power allocation in wireless networks. In both cases, our approach yields near-optimal near-feasible solutions and exhibits strong out-of-distribution (OOD) generalization.", "AI": {"tldr": "\u63d0\u51fa\u7ea6\u675f\u5bf9\u5076\u5c55\u5f00\uff08CDU\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u4e2a\u8026\u5408\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u8fd1\u4f3c\u62c9\u683c\u6717\u65e5\u51fd\u6570\u7684\u978d\u70b9\uff0c\u52a0\u901f\u6c42\u89e3\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5728\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212\u548c\u65e0\u7ebf\u7f51\u7edc\u529f\u7387\u5206\u914d\u4e2d\u5b9e\u73b0\u8fd1\u6700\u4f18\u89e3\u5e76\u5177\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5bf9\u5076\u4e0a\u5347\u7b97\u6cd5\u5728\u6c42\u89e3\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u65f6\u6536\u655b\u8f83\u6162\uff0c\u9700\u8981\u4e3a\u4e0d\u540c\u95ee\u9898\u5b9e\u4f8b\u91cd\u65b0\u8ba1\u7b97\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u53ef\u5b66\u4e60\u7684\u52a0\u901f\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u4f18\u5316\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u6c42\u89e3\u6548\u7387\u3002", "method": "\u63d0\u51fa\u7ea6\u675f\u5bf9\u5076\u5c55\u5f00\uff08CDU\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u8026\u5408\u795e\u7ecf\u7f51\u7edc\uff1a\u539f\u59cb\u7f51\u7edc\u6a21\u62df\u8fed\u4ee3\u4f18\u5316\u5668\u5bfb\u627e\u62c9\u683c\u6717\u65e5\u51fd\u6570\u7684\u9a7b\u70b9\uff0c\u5bf9\u5076\u7f51\u7edc\u751f\u6210\u6700\u4f18\u4e58\u5b50\u8f68\u8ff9\u3002\u901a\u8fc7\u7ea6\u675f\u5b66\u4e60\u65bd\u52a0\u539f\u59cb\u4e0b\u964d\u548c\u5bf9\u5076\u4e0a\u5347\u7ea6\u675f\uff0c\u91c7\u7528\u4ea4\u66ff\u8bad\u7ec3\u7b56\u7565\u66f4\u65b0\u4e24\u4e2a\u7f51\u7edc\u3002", "result": "\u5728\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212\uff08MIQPs\uff09\u548c\u65e0\u7ebf\u7f51\u7edc\u529f\u7387\u5206\u914d\u95ee\u9898\u4e0a\uff0cCDU\u6846\u67b6\u80fd\u591f\u4ea7\u751f\u8fd1\u6700\u4f18\u4e14\u8fd1\u53ef\u884c\u7684\u89e3\uff0c\u5e76\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CDU\u6846\u67b6\u6210\u529f\u5730\u5c06\u5bf9\u5076\u4e0a\u5347\u7b97\u6cd5\u5c55\u5f00\u4e3a\u53ef\u5b66\u4e60\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6c42\u89e3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u7406\u8bba\u4fdd\u8bc1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u52a0\u901f\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.17275", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17275", "abs": "https://arxiv.org/abs/2601.17275", "authors": ["Lianlei Shan", "Han Chen", "Yixuan Wang", "Zhenjie Liu", "Wei Li"], "title": "Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning", "comment": "12 pages,", "summary": "While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \\textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \\textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.", "AI": {"tldr": "DLR\u63d0\u51fa\u4e86\u4e00\u79cd\u6f5c\u5728\u7a7a\u95f4\u53cc\u5411\u5bf9\u6bd4\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u8fc7\u7a0b\u4ece\u9ad8\u7ef4\u79bb\u6563token\u7a7a\u95f4\u8f6c\u79fb\u5230\u8fde\u7eed\u6f5c\u5728\u6d41\u5f62\uff0c\u901a\u8fc7\u51bb\u7ed3\u4e3b\u6a21\u578b\u53c2\u6570\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5b9e\u73b0\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684LLM\u63a8\u7406\u8bad\u7ec3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u65f6\u5f80\u5f80\u53ea\u662f\"\u7edf\u8ba1\u62df\u5408\"\u800c\u975e\u7cfb\u7edf\u903b\u8f91\u63a8\u7406\u3002\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u5f15\u5165\"\u4e09\u601d\u800c\u540e\u8a00\"\u8303\u5f0f\uff0c\u4f46\u5728\u9ad8\u7ef4\u79bb\u6563token\u7a7a\u95f4\u4e2d\u9762\u4e34\u6837\u672c\u6548\u7387\u4f4e\u3001\u68af\u5ea6\u4f30\u8ba1\u65b9\u5dee\u5927\u548c\u707e\u96be\u6027\u9057\u5fd8\u4e09\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faDeepLatent Reasoning (DLR)\u6846\u67b6\uff1a1) \u4f7f\u7528\u8f7b\u91cf\u7ea7\u8f85\u52a9\u6a21\u578b\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u91c7\u6837K\u4e2a\u63a8\u7406\u94fe\u7f16\u7801\uff1b2) \u57fa\u4e8e\u6b63\u786e\u6027\u548c\u683c\u5f0f\u7684\u53cc\u91cd\u5956\u52b1\u673a\u5236\u7b5b\u9009\u9ad8\u4ef7\u503c\u6f5c\u5728\u8f68\u8ff9\uff1b3) \u4ec5\u5c06\u9ad8\u8d28\u91cf\u8f68\u8ff9\u8f93\u5165\u51bb\u7ed3\u4e3b\u6a21\u578b\u8fdb\u884c\u5355\u6b21\u89e3\u7801\uff1b4) \u8bbe\u8ba1\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u4ee5\u6700\u5927\u5316\u63a8\u7406\u591a\u6837\u6027\u540c\u65f6\u4fdd\u6301\u8fde\u8d2f\u6027\u3002", "result": "\u5728\u53ef\u6bd4GPU\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0cDLR\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u6536\u655b\uff0c\u652f\u6301\u66f4\u957f\u7684\u63a8\u7406\u94fe\uff0c\u4fc3\u8fdb\u4e86\u63a8\u7406\u80fd\u529b\u7684\u53ef\u6301\u7eed\u79ef\u7d2f\uff0c\u4e3aLLM\u7684\u53ef\u9760\u548c\u53ef\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002", "conclusion": "DLR\u901a\u8fc7\u5c06\u8bd5\u9519\u6210\u672c\u4ece\u6602\u8d35\u7684token\u7ea7\u5168\u5e8f\u5217\u751f\u6210\u8f6c\u79fb\u5230\u8fde\u7eed\u6f5c\u5728\u6d41\u5f62\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86\u4f20\u7edfRL\u5728LLM\u63a8\u7406\u8bad\u7ec3\u4e2d\u7684\u7ed3\u6784\u74f6\u9888\uff0c\u540c\u65f6\u901a\u8fc7\u51bb\u7ed3\u4e3b\u6a21\u578b\u53c2\u6570\u6570\u5b66\u4e0a\u6d88\u9664\u4e86\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002"}}
{"id": "2601.17301", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17301", "abs": "https://arxiv.org/abs/2601.17301", "authors": ["Yunhui Liu", "Tieke He", "Yongchao Liu", "Can Yi", "Hong Jin", "Chuntao Hong"], "title": "Tabular Foundation Models are Strong Graph Anomaly Detectors", "comment": "Accepted by WWW 2026 (Short Paper)", "summary": "Graph anomaly detection (GAD), which aims to identify abnormal nodes that deviate from the majority, has become increasingly important in high-stakes Web domains. However, existing GAD methods follow a \"one model per dataset\" paradigm, leading to high computational costs, substantial data demands, and poor generalization when transferred to new datasets. This calls for a foundation model that enables a \"one-for-all\" GAD solution capable of detecting anomalies across diverse graphs without retraining. Yet, achieving this is challenging due to the large structural and feature heterogeneity across domains. In this paper, we propose TFM4GAD, a simple yet effective framework that adapts tabular foundation models (TFMs) for graph anomaly detection. Our key insight is that the core challenges of foundation GAD, handling heterogeneous features, generalizing across domains, and operating with scarce labels, are the exact problems that modern TFMs are designed to solve via synthetic pre-training and powerful in-context learning. The primary challenge thus becomes structural: TFMs are agnostic to graph topology. TFM4GAD bridges this gap by \"flattening\" the graph, constructing an augmented feature table that enriches raw node features with Laplacian embeddings, local and global structural characteristics, and anomaly-sensitive neighborhood aggregations. This augmented table is processed by a TFM in a fully in-context regime. Extensive experiments on multiple datasets with various TFM backbones reveal that TFM4GAD surprisingly achieves significant performance gains over specialized GAD models trained from scratch. Our work offers a new perspective and a practical paradigm for leveraging TFMs as powerful, generalist graph anomaly detectors.", "AI": {"tldr": "TFM4GAD\uff1a\u901a\u8fc7\u5c06\u56fe\u6570\u636e\u6241\u5e73\u5316\u4e3a\u589e\u5f3a\u7279\u5f81\u8868\uff0c\u5229\u7528\u8868\u683c\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u56fe\u5f02\u5e38\u68c0\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u8de8\u6570\u636e\u96c6\u68c0\u6d4b\u5f02\u5e38", "motivation": "\u73b0\u6709\u56fe\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u9075\u5faa\"\u4e00\u4e2a\u6570\u636e\u96c6\u4e00\u4e2a\u6a21\u578b\"\u8303\u5f0f\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u6570\u636e\u9700\u6c42\u5927\u3001\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u9700\u8981\u80fd\u591f\u8de8\u591a\u6837\u56fe\u6570\u636e\u96c6\u68c0\u6d4b\u5f02\u5e38\u7684\u901a\u7528\u57fa\u7840\u6a21\u578b", "method": "\u5c06\u56fe\"\u6241\u5e73\u5316\"\u4e3a\u589e\u5f3a\u7279\u5f81\u8868\uff0c\u5305\u542b\u539f\u59cb\u8282\u70b9\u7279\u5f81\u3001\u62c9\u666e\u62c9\u65af\u5d4c\u5165\u3001\u5c40\u90e8\u548c\u5168\u5c40\u7ed3\u6784\u7279\u5f81\u3001\u5f02\u5e38\u654f\u611f\u90bb\u57df\u805a\u5408\u7b49\uff0c\u7136\u540e\u4f7f\u7528\u8868\u683c\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5b8c\u5168\u4e0a\u4e0b\u6587\u5b66\u4e60\u5904\u7406", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4e0d\u540c\u8868\u683c\u57fa\u7840\u6a21\u578b\u9aa8\u5e72\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0cTFM4GAD\u663e\u8457\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684\u4e13\u4e1a\u56fe\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b", "conclusion": "TFM4GAD\u4e3a\u5229\u7528\u8868\u683c\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\u5f3a\u5927\u3001\u901a\u7528\u7684\u56fe\u5f02\u5e38\u68c0\u6d4b\u5668\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u548c\u5b9e\u7528\u8303\u5f0f"}}
{"id": "2601.17307", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17307", "abs": "https://arxiv.org/abs/2601.17307", "authors": ["Haobing Liu", "Yinuo Zhang", "Tingting Wang", "Ruobing Jiang", "Yanwei Yu"], "title": "Weighted Graph Clustering via Scale Contraction and Graph Structure Learning", "comment": null, "summary": "Graph clustering aims to partition nodes into distinct clusters based on their similarity, thereby revealing relationships among nodes. Nevertheless, most existing methods do not fully utilize these edge weights. Leveraging edge weights in graph clustering tasks faces two critical challenges. (1) The introduction of edge weights may significantly increase storage space and training time, making it essential to reduce the graph scale while preserving nodes that are beneficial for the clustering task. (2) Edge weight information may inherently contain noise that negatively impacts clustering results. However, few studies can jointly optimize clustering and edge weights, which is crucial for mitigating the negative impact of noisy edges on clustering task. To address these challenges, we propose a contractile edge-weight-aware graph clustering network. Specifically, a cluster-oriented graph contraction module is designed to reduce the graph scale while preserving important nodes. An edge-weight-aware attention network is designed to identify and weaken noisy connections. In this way, we can more easily identify and mitigate the impact of noisy edges during the clustering process, thus enhancing clustering effectiveness. We conducted extensive experiments on three real-world weighted graph datasets. In particular, our model outperforms the best baseline, demonstrating its superior performance. Furthermore, experiments also show that the proposed graph contraction module can significantly reduce training time and storage space.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6536\u7f29\u8fb9\u6743\u91cd\u611f\u77e5\u56fe\u805a\u7c7b\u7f51\u7edc\uff0c\u901a\u8fc7\u56fe\u6536\u7f29\u6a21\u5757\u51cf\u5c11\u56fe\u89c4\u6a21\uff0c\u540c\u65f6\u901a\u8fc7\u8fb9\u6743\u91cd\u611f\u77e5\u6ce8\u610f\u529b\u7f51\u7edc\u8bc6\u522b\u548c\u524a\u5f31\u566a\u58f0\u8fde\u63a5\uff0c\u4ece\u800c\u63d0\u5347\u805a\u7c7b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u56fe\u805a\u7c7b\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u8fb9\u6743\u91cd\u4fe1\u606f\uff0c\u800c\u8fb9\u6743\u91cd\u5f15\u5165\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u589e\u52a0\u5b58\u50a8\u7a7a\u95f4\u548c\u8bad\u7ec3\u65f6\u95f4\uff1b2) \u8fb9\u6743\u91cd\u53ef\u80fd\u5305\u542b\u566a\u58f0\u5f71\u54cd\u805a\u7c7b\u7ed3\u679c\u3002\u9700\u8981\u540c\u65f6\u4f18\u5316\u805a\u7c7b\u548c\u8fb9\u6743\u91cd\u4ee5\u51cf\u8f7b\u566a\u58f0\u8fb9\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u6536\u7f29\u8fb9\u6743\u91cd\u611f\u77e5\u56fe\u805a\u7c7b\u7f51\u7edc\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1) \u9762\u5411\u805a\u7c7b\u7684\u56fe\u6536\u7f29\u6a21\u5757\uff0c\u51cf\u5c11\u56fe\u89c4\u6a21\u540c\u65f6\u4fdd\u7559\u91cd\u8981\u8282\u70b9\uff1b2) \u8fb9\u6743\u91cd\u611f\u77e5\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u8bc6\u522b\u5e76\u524a\u5f31\u566a\u58f0\u8fde\u63a5\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u52a0\u6743\u56fe\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u3002\u56fe\u6536\u7f29\u6a21\u5757\u80fd\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u5b58\u50a8\u7a7a\u95f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u8fb9\u6743\u91cd\u4fe1\u606f\uff0c\u901a\u8fc7\u56fe\u6536\u7f29\u548c\u566a\u58f0\u8fb9\u524a\u5f31\u673a\u5236\u63d0\u5347\u805a\u7c7b\u6548\u679c\uff0c\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2601.17309", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17309", "abs": "https://arxiv.org/abs/2601.17309", "authors": ["Anagha Sabu", "Vidhya S", "Narayanan C Krishnan"], "title": "PAR: Plausibility-aware Amortized Recourse Generation", "comment": null, "summary": "Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.", "AI": {"tldr": "PAR\uff1a\u4e00\u79cd\u57fa\u4e8e\u644a\u9500\u8fd1\u4f3c\u63a8\u7406\u7684\u7b97\u6cd5\u8ffd\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ea6\u675f\u6700\u5927\u540e\u9a8c\u63a8\u65ad\u751f\u6210\u9ad8\u4f3c\u7136\u3001\u73b0\u5b9e\u53ef\u884c\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u8ffd\u7d22\u65b9\u6cd5\u5728\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65f6\uff0c\u5f80\u5f80\u96be\u4ee5\u540c\u65f6\u4fdd\u8bc1\u9ad8\u4f3c\u7136\u6027\uff08\u73b0\u5b9e\u53ef\u884c\u6027\uff09\u548c\u6ee1\u8db3\u5404\u79cd\u8ffd\u7d22\u7ea6\u675f\uff08\u5982\u6709\u6548\u6027\u3001\u7a00\u758f\u6027\u3001\u76f8\u4f3c\u6027\u7b49\uff09\u3002\u9700\u8981\u4e00\u79cd\u80fd\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u8ffd\u7d22\u5efa\u8bae\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u8ffd\u7d22\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u7ea6\u675f\u6700\u5927\u540e\u9a8c\uff08MAP\uff09\u63a8\u65ad\u95ee\u9898\uff0c\u5728\u53ef\u63a5\u53d7\u7c7b\u6570\u636e\u5206\u5e03\u4e0b\u5bfb\u627e\u9ad8\u4f3c\u7136\u53cd\u4e8b\u5b9e\u3002\u63d0\u51faPAR\u65b9\u6cd5\uff1a\u4f7f\u7528\u53ef\u7cbe\u786e\u8ba1\u7b97\u4f3c\u7136\u7684\u9ad8\u6548\u6982\u7387\u6a21\u578b\u4f30\u8ba1\u8ffd\u7d22\u4f3c\u7136\uff1b\u901a\u8fc7\u644a\u9500\u8fd1\u4f3c\u63a8\u7406\u9ad8\u6548\u751f\u6210\u8ffd\u7d22\uff1b\u8bad\u7ec3\u76ee\u6807\u5305\u62ec\u6700\u5927\u5316\u53ef\u63a5\u53d7\u7c7b\u5206\u5e03\u4e0b\u7684\u4f3c\u7136\u3001\u6700\u5c0f\u5316\u62d2\u7edd\u7c7b\u5206\u5e03\u4e0b\u7684\u4f3c\u7136\uff0c\u4ee5\u53ca\u7f16\u7801\u8ffd\u7d22\u7ea6\u675f\u7684\u5176\u4ed6\u635f\u5931\uff1b\u5f15\u5165\u57fa\u4e8e\u90bb\u57df\u7684\u8c03\u8282\u673a\u5236\u4e3a\u5177\u4f53\u4e8b\u5b9e\u5b9a\u5236\u8ffd\u7d22\u751f\u6210\u3002", "result": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u7b97\u6cd5\u8ffd\u7d22\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cPAR\u80fd\u9ad8\u6548\u751f\u6210\u6709\u6548\u3001\u4e0e\u4e8b\u5b9e\u76f8\u4f3c\u3001\u7a00\u758f\u4e14\u9ad8\u5ea6\u53ef\u4fe1\u7684\u8ffd\u7d22\u5efa\u8bae\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "PAR\u901a\u8fc7\u5c06\u8ffd\u7d22\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u7ea6\u675fMAP\u63a8\u65ad\uff0c\u7ed3\u5408\u644a\u9500\u8fd1\u4f3c\u63a8\u7406\u548c\u57fa\u4e8e\u90bb\u57df\u7684\u8c03\u8282\u673a\u5236\uff0c\u80fd\u591f\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u9ad8\u4f3c\u7136\u7684\u53cd\u4e8b\u5b9e\u8ffd\u7d22\u5efa\u8bae\uff0c\u4e3a\u7b97\u6cd5\u8ffd\u7d22\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17329", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17329", "abs": "https://arxiv.org/abs/2601.17329", "authors": ["Tiejin Chen", "Xiaoou Liu", "Vishnu Nandam", "Kuan-Ru Liou", "Hua Wei"], "title": "Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment", "comment": "Accetped to Findings of EACL", "summary": "Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \\emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \\emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.", "AI": {"tldr": "CFA\u6846\u67b6\u5229\u7528\u5171\u5f62\u9884\u6d4b\u91cf\u5316\u7b54\u6848\u53ef\u9760\u6027\uff0c\u4e3aDPO\u548cPPO\u8bad\u7ec3\u63d0\u4f9b\u57fa\u4e8e\u7edf\u8ba1\u4fdd\u8bc1\u7684\u504f\u597d\u6743\u91cd\uff0c\u63d0\u5347\u5bf9\u9f50\u7684\u9c81\u68d2\u6027\u548c\u6570\u636e\u6548\u7387", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\u53ea\u5173\u6ce8\u504f\u597d\u6743\u91cd\uff0c\u5ffd\u7565\u4e86\u88ab\u6bd4\u8f83\u7b54\u6848\u672c\u8eab\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002\u504f\u597d\u6807\u7b7e\u901a\u5e38\u5b58\u5728\u566a\u58f0\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u66f4\u57fa\u7840\u5730\u8003\u8651\u7b54\u6848\u5c42\u9762\u7684\u53ef\u9760\u6027", "method": "\u63d0\u51faConformal Feedback Alignment (CFA)\u6846\u67b6\uff0c\u5229\u7528\u5171\u5f62\u9884\u6d4b\u6784\u5efa\u5177\u6709\u53ef\u63a7\u8986\u76d6\u7387\u7684\u9884\u6d4b\u96c6\u6765\u91cf\u5316\u7b54\u6848\u7ea7\u53ef\u9760\u6027\uff0c\u5c06\u8fd9\u4e9b\u53ef\u9760\u6027\u805a\u5408\u4e3aDPO\u548cPPO\u8bad\u7ec3\u7684\u539f\u5219\u6027\u6743\u91cd", "result": "\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCFA\u63d0\u9ad8\u4e86\u5bf9\u9f50\u7684\u9c81\u68d2\u6027\u548c\u6570\u636e\u6548\u7387\uff0c\u8bc1\u660e\u5efa\u6a21\u7b54\u6848\u4fa7\u4e0d\u786e\u5b9a\u6027\u53ef\u4ee5\u8865\u5145\u504f\u597d\u7ea7\u52a0\u6743\uff0c\u5b9e\u73b0\u66f4\u7a33\u5065\u3001\u9ad8\u6548\u7684\u5bf9\u9f50", "conclusion": "CFA\u901a\u8fc7\u5171\u5f62\u9884\u6d4b\u4e3a\u504f\u597d\u5bf9\u9f50\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u7684\u7b54\u6848\u53ef\u9760\u6027\u91cf\u5316\uff0c\u5c06\u7b54\u6848\u4fa7\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u4e0e\u504f\u597d\u6743\u91cd\u76f8\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u9f50\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u6570\u636e\u6548\u7387"}}
{"id": "2601.17330", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.17330", "abs": "https://arxiv.org/abs/2601.17330", "authors": ["Laurent Caraffa"], "title": "Thermodynamically Optimal Regularization under Information-Geometric Constraints", "comment": "7 pages, 0 figures", "summary": "Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.\n  Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.\n  We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u70ed\u529b\u5b66\u6700\u4f18\u6027\u3001\u4fe1\u606f\u51e0\u4f55\u548c\u6b63\u5219\u5316\u8054\u7cfb\u8d77\u6765\uff0c\u8bc1\u660e\u5728\u7279\u5b9a\u5047\u8bbe\u4e0bFisher-Rao\u5ea6\u91cf\u662f\u4fe1\u5ff5\u7a7a\u95f4\u552f\u4e00\u53ef\u63a5\u53d7\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u70ed\u529b\u5b66\u6700\u4f18\u6b63\u5219\u5316\u5bf9\u5e94\u4e8e\u6700\u5c0f\u5316\u5230\u53c2\u8003\u72b6\u6001\u7684Fisher-Rao\u8ddd\u79bb\u5e73\u65b9\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4f9d\u8d56\u4e8e\u4e00\u7cfb\u5217\u7ecf\u9a8c\u4e0a\u6210\u529f\u4f46\u7406\u8bba\u4e0a\u5f02\u8d28\u7684\u6b63\u5219\u5316\u6280\u672f\uff08\u5982\u6743\u91cd\u8870\u51cf\u3001dropout\u3001\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff09\uff0c\u540c\u65f6\u8bad\u7ec3\u5927\u578b\u6a21\u578b\u7684\u80fd\u8017\u6210\u672c\u6025\u5267\u589e\u52a0\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9\u5b66\u4e60\u7b97\u6cd5\u662f\u5426\u63a5\u8fd1\u4efb\u4f55\u57fa\u672c\u6548\u7387\u754c\u9650\u7684\u7591\u95ee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u57fa\u4e8e\u4e09\u4e2a\u660e\u786e\u5047\u8bbe\uff1a(A1)\u6700\u4f18\u6027\u9700\u8981\u5185\u5728\u7684\u3001\u53c2\u6570\u5316\u4e0d\u53d8\u7684\u4fe1\u606f\u5ea6\u91cf\uff1b(A2)\u4fe1\u5ff5\u72b6\u6001\u7531\u5df2\u77e5\u7ea6\u675f\u4e0b\u7684\u6700\u5927\u71b5\u5206\u5e03\u5efa\u6a21\uff1b(A3)\u6700\u4f18\u8fc7\u7a0b\u662f\u51c6\u9759\u6001\u7684\u3002\u5728\u6b64\u6846\u67b6\u4e0b\u8bc1\u660e\u4e86\u6761\u4ef6\u6700\u4f18\u6027\u5b9a\u7406\uff0c\u63a8\u5bfc\u4e86\u9ad8\u65af\u548c\u5706\u5f62\u4fe1\u5ff5\u6a21\u578b\u7684\u8bf1\u5bfc\u51e0\u4f55\u7ed3\u6784\u3002", "result": "\u8bc1\u660e\u4e86Fisher-Rao\u5ea6\u91cf\u662f\u4fe1\u5ff5\u7a7a\u95f4\u552f\u4e00\u53ef\u63a5\u53d7\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u70ed\u529b\u5b66\u6700\u4f18\u6b63\u5219\u5316\u5bf9\u5e94\u4e8e\u6700\u5c0f\u5316\u5230\u53c2\u8003\u72b6\u6001\u7684Fisher-Rao\u8ddd\u79bb\u5e73\u65b9\u3002\u63a8\u5bfc\u51fa\u9ad8\u65af\u4fe1\u5ff5\u6a21\u578b\u5bf9\u5e94\u53cc\u66f2\u6d41\u5f62\uff0c\u5706\u5f62\u4fe1\u5ff5\u6a21\u578b\u5bf9\u5e94von Mises\u6d41\u5f62\uff0c\u5e76\u8868\u660e\u7ecf\u5178\u6b63\u5219\u5316\u65b9\u6848\u5728\u7ed3\u6784\u4e0a\u65e0\u6cd5\u4fdd\u8bc1\u70ed\u529b\u5b66\u6700\u4f18\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6b63\u5219\u5316\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u51e0\u4f55\u548c\u70ed\u529b\u5b66\u57fa\u7840\uff0c\u5f15\u5165\u4e86\u5b66\u4e60\u7684\u70ed\u529b\u5b66\u6548\u7387\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u9884\u6d4b\uff0c\u4e3a\u7406\u89e3\u6b63\u5219\u5316\u6280\u672f\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2601.17334", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17334", "abs": "https://arxiv.org/abs/2601.17334", "authors": ["Yufeng Huang"], "title": "Power-based Partial Attention: Bridging Linear-Complexity and Full Attention", "comment": "12 pages, 3 figures", "summary": "It is widely accepted from transformer research that \"attention is all we need\", but the amount of attention required has never been systematically quantified. Is quadratic $O(L^2)$ attention necessary, or is there a sub-quadratic attention mechanism that can achieve comparable performance? To answer this question, we introduce power-based partial attention (PPA), an attention mechanism of order $O(L^{1+p})$, where $0 \\leq p \\leq 1$, such that $p=0$ corresponds to sliding window attention with linear complexity, and $p=1$ corresponds to full attention. With this attention construction, we can explore how transformer architecture performance varies as a function of the attention scaling behavior controlled by $p$. The overall trend from our experiments shows an S-curve-like behavior where the performance transitions from sliding-window (linear-complexity) attention to full attention over a narrow window of $p$ values, and plateaus as $p$ approaches $1$. In our experiments, we show that there exists $0<p<1$ such that $O(L^{1+p})$ attention is sufficient to achieve similar results as $O(L^2)$ full attention.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e42\u7684\u90e8\u5206\u6ce8\u610f\u529b\u673a\u5236\uff08PPA\uff09\uff0c\u5176\u590d\u6742\u5ea6\u4e3aO(L^{1+p})\uff0c\u5176\u4e2d0\u2264p\u22641\uff0c\u53ef\u4ee5\u5728\u4f4e\u4e8e\u4e8c\u6b21\u590d\u6742\u5ea6\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0e\u5168\u6ce8\u610f\u529b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u867d\u7136Transformer\u7814\u7a76\u666e\u904d\u8ba4\u4e3a\"\u6ce8\u610f\u529b\u5c31\u662f\u4e00\u5207\"\uff0c\u4f46\u4ece\u672a\u7cfb\u7edf\u91cf\u5316\u8fc7\u9700\u8981\u591a\u5c11\u6ce8\u610f\u529b\u3002\u9700\u8981\u63a2\u7a76\u4e8c\u6b21\u590d\u6742\u5ea6O(L^2)\u7684\u6ce8\u610f\u529b\u662f\u5426\u5fc5\u8981\uff0c\u662f\u5426\u5b58\u5728\u80fd\u8fbe\u5230\u76f8\u5f53\u6027\u80fd\u7684\u6b21\u4e8c\u6b21\u6ce8\u610f\u529b\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5e42\u7684\u90e8\u5206\u6ce8\u610f\u529b\u673a\u5236\uff08PPA\uff09\uff0c\u901a\u8fc7\u53c2\u6570p\u63a7\u5236\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u5728O(L^{1+p})\u8303\u56f4\u5185\u53d8\u5316\u3002p=0\u5bf9\u5e94\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\uff0cp=1\u5bf9\u5e94\u5168\u6ce8\u610f\u529b\u3002\u901a\u8fc7\u8fd9\u4e00\u673a\u5236\u53ef\u4ee5\u63a2\u7d22Transformer\u6027\u80fd\u968f\u6ce8\u610f\u529b\u7f29\u653e\u884c\u4e3a\u7684\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u5448\u73b0S\u66f2\u7ebf\u884c\u4e3a\uff1a\u5728p\u503c\u7684\u72ed\u7a84\u7a97\u53e3\u5185\uff0c\u6027\u80fd\u4ece\u6ed1\u52a8\u7a97\u53e3\uff08\u7ebf\u6027\u590d\u6742\u5ea6\uff09\u6ce8\u610f\u529b\u8fc7\u6e21\u5230\u5168\u6ce8\u610f\u529b\uff0c\u5e76\u5728p\u63a5\u8fd11\u65f6\u8d8b\u4e8e\u5e73\u7a33\u3002\u5b58\u57280<p<1\u4f7f\u5f97O(L^{1+p})\u6ce8\u610f\u529b\u8db3\u4ee5\u8fbe\u5230\u4e0eO(L^2)\u5168\u6ce8\u610f\u529b\u76f8\u4f3c\u7684\u7ed3\u679c\u3002", "conclusion": "\u4e8c\u6b21\u590d\u6742\u5ea6\u7684\u5168\u6ce8\u610f\u529b\u5e76\u975e\u5fc5\u8981\uff0c\u5b58\u5728\u6b21\u4e8c\u6b21\u590d\u6742\u5ea6\u7684\u6ce8\u610f\u529b\u673a\u5236\uff08O(L^{1+p})\uff0c\u5176\u4e2d0<p<1\uff09\u80fd\u591f\u8fbe\u5230\u4e0e\u5168\u6ce8\u610f\u529b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548Transformer\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.17357", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17357", "abs": "https://arxiv.org/abs/2601.17357", "authors": ["Davide Ettori"], "title": "Spectral Geometry for Deep Learning: Compression and Hallucination Detection via Random Matrix Theory", "comment": "Master thesis, MS in Computer Science, University of Illinois Chicago, defended November 21, 2025", "summary": "Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8c31\u51e0\u4f55\u548c\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u9690\u85cf\u6fc0\u6d3b\u7684\u7279\u5f81\u503c\u7ed3\u6784\u6765\u89e3\u51b3\u5927\u6a21\u578b\u7684\u53ef\u9760\u6027\u95ee\u9898\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u867d\u7136\u6027\u80fd\u5f3a\u5927\uff0c\u4f46\u5b58\u5728\u53ef\u9760\u6027\u95ee\u9898\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u6311\u6218", "method": "\u57fa\u4e8e\u8c31\u51e0\u4f55\u548c\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u8d21\u732e\uff1aEigenTrack\uff08\u4f7f\u7528\u8c31\u7279\u5f81\u53ca\u5176\u65f6\u95f4\u52a8\u6001\u5b9e\u65f6\u68c0\u6d4b\u5e7b\u89c9\u548c\u5206\u5e03\u5916\u884c\u4e3a\uff09\u548cRMT-KD\uff08\u901a\u8fc7\u8bc6\u522b\u4fe1\u606f\u8c31\u5206\u91cf\u5e76\u5e94\u7528\u8fed\u4ee3\u77e5\u8bc6\u84b8\u998f\u8fdb\u884c\u6a21\u578b\u538b\u7f29\uff09", "result": "\u8c31\u7edf\u8ba1\u91cf\u4e3a\u76d1\u63a7\u5927\u5c3a\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u6307\u5bfc\u6a21\u578b\u538b\u7f29\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u4fe1\u53f7", "conclusion": "\u7279\u5f81\u503c\u7ed3\u6784\u5206\u6790\u4e3a\u89e3\u51b3\u5927\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8c31\u7279\u5f81\u5728\u6a21\u578b\u76d1\u63a7\u548c\u538b\u7f29\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c"}}
{"id": "2601.17360", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.17360", "abs": "https://arxiv.org/abs/2601.17360", "authors": ["Jiankai Jin", "Xiangzheng Zhang", "Zhao Liu", "Deyue Zhang", "Quanchen Zou"], "title": "Robust Privacy: Inference-Time Privacy through Certified Robustness", "comment": null, "summary": "Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($\u03c3=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9c81\u68d2\u9690\u79c1\uff08RP\uff09\u6982\u5ff5\uff0c\u901a\u8fc7\u4fdd\u8bc1\u6a21\u578b\u5728\u8f93\u5165\u90bb\u57df\u5185\u7684\u9884\u6d4b\u4e0d\u53d8\u6027\u6765\u63d0\u4f9b\u63a8\u7406\u65f6\u9690\u79c1\u4fdd\u62a4\uff0c\u5e76\u5f00\u53d1\u4e86\u5c5e\u6027\u9690\u79c1\u589e\u5f3a\uff08APE\uff09\u65b9\u6cd5\u5c06\u8f93\u5165\u7ea7\u4e0d\u53d8\u6027\u8f6c\u5316\u4e3a\u5c5e\u6027\u7ea7\u9690\u79c1\u6548\u679c\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u63a8\u7406\u65f6\u53ef\u80fd\u6cc4\u9732\u654f\u611f\u8f93\u5165\u5c5e\u6027\uff0c\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u65b0\u7684\u63a8\u7406\u65f6\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u6765\u9632\u6b62\u6a21\u578b\u53cd\u8f6c\u653b\u51fb\u7b49\u9690\u79c1\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u9c81\u68d2\u9690\u79c1\uff08RP\uff09\u6982\u5ff5\uff0c\u57fa\u4e8e\u8ba4\u8bc1\u9c81\u68d2\u6027\u601d\u60f3\uff1a\u5982\u679c\u6a21\u578b\u9884\u6d4b\u5728\u8f93\u5165x\u7684\u534a\u5f84R\u90bb\u57df\u5185\u4fdd\u6301\u4e0d\u53d8\uff0c\u5219x\u4eab\u6709R-\u9c81\u68d2\u9690\u79c1\u3002\u5f00\u53d1\u5c5e\u6027\u9690\u79c1\u589e\u5f3a\uff08APE\uff09\u65b9\u6cd5\uff0c\u5c06\u8f93\u5165\u7ea7\u4e0d\u53d8\u6027\u8f6c\u5316\u4e3a\u5c5e\u6027\u7ea7\u9690\u79c1\u6548\u679c\u3002", "result": "\u5728\u53d7\u63a7\u63a8\u8350\u4efb\u52a1\u4e2d\uff0cRP\u6269\u5c55\u4e86\u4e0e\u6b63\u63a8\u8350\u517c\u5bb9\u7684\u654f\u611f\u5c5e\u6027\u503c\u96c6\u5408\uff0c\u6269\u5927\u4e86\u63a8\u7406\u533a\u95f4\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u5c0f\u566a\u58f0\u6c34\u5e73\uff08\u03c3=0.1\uff09\u4e0b\uff0cRP\u4e5f\u80fd\u5c06\u6a21\u578b\u53cd\u8f6c\u653b\u51fb\u6210\u529f\u7387\u4ece73%\u964d\u81f34%\uff0c\u4e14\u90e8\u5206\u60c5\u51b5\u4e0b\u53ef\u5b8c\u5168\u907f\u514d\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u9c81\u68d2\u9690\u79c1\uff08RP\uff09\u662f\u4e00\u79cd\u6709\u6548\u7684\u63a8\u7406\u65f6\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u4fdd\u8bc1\u6a21\u578b\u9884\u6d4b\u5728\u8f93\u5165\u90bb\u57df\u5185\u7684\u4e0d\u53d8\u6027\u6765\u9632\u6b62\u654f\u611f\u5c5e\u6027\u6cc4\u9732\uff0c\u663e\u8457\u964d\u4f4e\u6a21\u578b\u53cd\u8f6c\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.17376", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17376", "abs": "https://arxiv.org/abs/2601.17376", "authors": ["Ruijin Hua", "Zichuan Liu", "Kun Zhang", "Yiyuan Yang"], "title": "Diversified Scaling Inference in Time Series Foundation Models", "comment": "23 pages, 16 figures, 9 tables", "summary": "The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u6f5c\u529b\uff0c\u53d1\u73b0\u6807\u51c6\u91c7\u6837\u65b9\u6cd5\u56e0\u63a2\u7d22\u4e0d\u8db3\u800c\u65e0\u6cd5\u9075\u5faa\u7f29\u653e\u5b9a\u5f8b\uff0c\u63d0\u51fa\u901a\u8fc7\u591a\u6837\u5316\u91c7\u6837\u6270\u52a8\u6765\u6269\u5c55\u751f\u6210\u5206\u5e03\u652f\u6301\uff0c\u7406\u8bba\u4e0a\u5206\u6790\u4e86\u591a\u6837\u6027-\u4fdd\u771f\u5ea6\u6743\u8861\uff0c\u5b9e\u9a8c\u8bc1\u660e\u591a\u6837\u5316\u63a8\u7406\u7f29\u653e\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e14\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u53d1\u5c55\uff0c\u4f46\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u6316\u6398\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a1) TSFMs\u5728\u6807\u51c6\u91c7\u6837\u63a8\u7406\u7f29\u653e\u4e0b\u7684\u884c\u4e3a\u7279\u6027\uff1b2) \u53d7\u63a7\u91c7\u6837\u591a\u6837\u6027\u662f\u5426\u80fd\u63d0\u5347\u6027\u80fd\u3002", "method": "\u9996\u5148\u5206\u6790TSFMs\u5728\u6807\u51c6\u91c7\u6837\u4e0b\u7684\u7279\u6027\uff0c\u53d1\u73b0\u5176\u56e0\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u800c\u65e0\u6cd5\u9075\u5faa\u7f29\u653e\u5b9a\u5f8b\u3002\u7136\u540e\u901a\u8fc7\u5b9a\u5236\u5316\u7684\u65f6\u95f4\u5e8f\u5217\u6270\u52a8\u5b9e\u73b0\u591a\u6837\u5316\u63a8\u7406\u7f29\u653e\uff0c\u6269\u5c55\u751f\u6210\u5206\u5e03\u7684\u652f\u6301\u8303\u56f4\u3002\u7406\u8bba\u4e0a\u5206\u6790\u4e86\u591a\u6837\u6027-\u4fdd\u771f\u5ea6\u6743\u8861\uff0c\u63a8\u5bfc\u51fa\u591a\u6837\u5316\u91c7\u6837\u8d85\u8d8a\u6807\u51c6\u91c7\u6837\u7684\u5173\u952e\u6837\u672c\u9608\u503c\u3002", "result": "\u5728\u591a\u79cdTSFMs\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u9002\u5f53\u7684\u591a\u6837\u5316\u63a8\u7406\u7f29\u653e\u80fd\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002\u4f5c\u4e3a\u5e94\u7528\uff0c\u63d0\u51fa\u4e86RobustMSE\u6307\u6807\u6765\u91cf\u5316\u56fa\u5b9a\u9884\u7b97\u4e0bTSFM\u7684\u6027\u80fd\u4e0a\u9650\u3002", "conclusion": "\u7814\u7a76\u9610\u660e\u4e86\u8fd9\u4e9b\u56e0\u7d20\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4f7f\u5f97\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3TSFMs\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5e76\u884c\u73af\u5883\u4e2d\u7684\u591a\u6837\u5316\u5927\u89c4\u6a21\u63a8\u7406\u65f6\u95f4\u5e8f\u5217\u5b9e\u73b0\u53ef\u9760\u6027\u80fd\u6210\u4e3a\u53ef\u80fd\uff0c\u786e\u7acb\u4e86\u63a8\u7406\u8bbe\u8ba1\u4f5c\u4e3aTSFM\u4f18\u5316\u7684\u5173\u952e\u8ba1\u7b97\u9ad8\u6548\u7ef4\u5ea6\u3002"}}
{"id": "2601.17396", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17396", "abs": "https://arxiv.org/abs/2601.17396", "authors": ["Vashista Nobaub"], "title": "GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems", "comment": "21 pages, 5 figures. Includes theoretical analysis, ablation studies, and experiments on synthetic and real vibration datasets. Code available", "summary": "Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.", "AI": {"tldr": "GO-OSC\u662f\u4e00\u4e2a\u51e0\u4f55\u611f\u77e5\u7684\u632f\u8361\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5236\u89c4\u8303\u5316\u7684\u6f5c\u5728\u53c2\u6570\u5316\uff0c\u5b9e\u73b0\u5bf9\u65e9\u671f\u9000\u5316\uff08\u5982\u76f8\u4f4d\u6296\u52a8\u3001\u9891\u7387\u6f02\u79fb\uff09\u7684\u7a33\u5b9a\u68c0\u6d4b\uff0c\u76f8\u6bd4\u4f20\u7edf\u80fd\u91cf\u57fa\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7075\u654f\u5ea6\u3002", "motivation": "\u632f\u8361\u7cfb\u7edf\u7684\u65e9\u671f\u9000\u5316\u901a\u5e38\u8868\u73b0\u4e3a\u52a8\u529b\u5b66\u7684\u51e0\u4f55\u7578\u53d8\uff08\u5982\u76f8\u4f4d\u6296\u52a8\u3001\u9891\u7387\u6f02\u79fb\uff09\uff0c\u5728\u4fe1\u53f7\u80fd\u91cf\u53d8\u5316\u53ef\u68c0\u6d4b\u4e4b\u524d\u5c31\u5df2\u53d1\u751f\u3002\u4f20\u7edf\u7684\u80fd\u91cf\u57fa\u8bca\u65ad\u65b9\u6cd5\u548c\u65e0\u7ea6\u675f\u5b66\u4e60\u8868\u793a\u5bf9\u6b64\u7ed3\u6784\u4e0d\u654f\u611f\uff0c\u5bfc\u81f4\u68c0\u6d4b\u5ef6\u8fdf\u6216\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faGO-OSC\u6846\u67b6\uff1a1\uff09\u5f3a\u5236\u89c4\u8303\u5316\u548c\u53ef\u8bc6\u522b\u7684\u6f5c\u5728\u53c2\u6570\u5316\u8868\u793a\uff0c\u652f\u6301\u8de8\u77ed\u65f6\u3001\u672a\u6807\u8bb0\u7a97\u53e3\u7684\u7a33\u5b9a\u6bd4\u8f83\u548c\u805a\u5408\uff1b2\uff09\u5b9a\u4e49\u4e00\u7cfb\u5217\u4e0d\u53d8\u7ebf\u6027\u51e0\u4f55\u63a2\u9488\uff0c\u9488\u5bf9\u6f5c\u5728\u7a7a\u95f4\u4e2d\u9000\u5316\u76f8\u5173\u7684\u65b9\u5411\uff1b3\uff09\u63d0\u4f9b\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u5728\u65e9\u671f\u76f8\u4f4d\u9000\u5316\u4e0b\u80fd\u91cf\u7edf\u8ba1\u7684\u68c0\u6d4b\u80fd\u529b\u4e3a\u96f6\uff0c\u800c\u51e0\u4f55\u63a2\u9488\u5177\u6709\u4e25\u683c\u6b63\u7075\u654f\u5ea6\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u7ebf\u6027\u63a2\u9488\u5728\u975e\u53ef\u8bc6\u522b\u8868\u793a\u4e0b\u4f1a\u5931\u6548\uff0c\u800c\u89c4\u8303\u5316\u80fd\u6062\u590d\u7edf\u8ba1\u53ef\u68c0\u6d4b\u6027\u3002\u5728\u5408\u6210\u57fa\u51c6\u548c\u771f\u5b9e\u632f\u52a8\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\uff0c\u5c55\u793a\u4e86\u66f4\u65e9\u7684\u68c0\u6d4b\u3001\u6539\u8fdb\u7684\u6570\u636e\u6548\u7387\u4ee5\u53ca\u5bf9\u8fd0\u884c\u6761\u4ef6\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "GO-OSC\u901a\u8fc7\u51e0\u4f55\u611f\u77e5\u8868\u793a\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u632f\u8361\u7cfb\u7edf\u65e9\u671f\u9000\u5316\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u76f8\u6bd4\u4f20\u7edf\u80fd\u91cf\u57fa\u65b9\u6cd5\u5728\u7075\u654f\u5ea6\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u5de5\u4e1a\u76d1\u6d4b\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2601.17407", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17407", "abs": "https://arxiv.org/abs/2601.17407", "authors": ["Prajwal Chauhan", "Salah Eddine Choutri", "Saif Eddin Jabari"], "title": "Efficient Dilated Squeeze and Excitation Neural Operator for Differential Equations", "comment": "Accepted to Transactions on Machine Learning Research (TMLR)", "summary": "Fast and accurate surrogates for physics-driven partial differential equations (PDEs) are essential in fields such as aerodynamics, porous media design, and flow control. However, many transformer-based models and existing neural operators remain parameter-heavy, resulting in costly training and sluggish deployment. We propose D-SENO (Dilated Squeeze-Excitation Neural Operator), a lightweight operator learning framework for efficiently solving a wide range of PDEs, including airfoil potential flow, Darcy flow in porous media, pipe Poiseuille flow, and incompressible Navier Stokes vortical fields. D-SENO combines dilated convolution (DC) blocks with squeeze-and-excitation (SE) modules to jointly capture wide receptive fields and dynamics alongside channel-wise attention, enabling both accurate and efficient PDE inference. Carefully chosen dilation rates allow the receptive field to focus on critical regions, effectively modeling long-range physical dependencies. Meanwhile, the SE modules adaptively recalibrate feature channels to emphasize dynamically relevant scales. Our model achieves training speed of up to approximately $20\\times$ faster than standard transformer-based models and neural operators, while also surpassing (or matching) them in accuracy across multiple PDE benchmarks. Ablation studies show that removing the SE modules leads to a slight drop in performance.", "AI": {"tldr": "D-SENO\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7b97\u5b50\u6846\u67b6\uff0c\u7ed3\u5408\u6269\u5f20\u5377\u79ef\u548c\u6324\u538b-\u6fc0\u52b1\u6a21\u5757\uff0c\u7528\u4e8e\u9ad8\u6548\u6c42\u89e3\u591a\u79cdPDE\uff0c\u8bad\u7ec3\u901f\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb\u7ea620\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u8d85\u8d8a\u5176\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u548c\u795e\u7ecf\u7b97\u5b50\u53c2\u6570\u91cf\u5927\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u90e8\u7f72\u7f13\u6162\uff0c\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u7ea7\u4f46\u51c6\u786e\u7684PDE\u6c42\u89e3\u66ff\u4ee3\u6a21\u578b\u3002", "method": "\u63d0\u51faD-SENO\u6846\u67b6\uff0c\u7ed3\u5408\u6269\u5f20\u5377\u79ef\u5757\uff08\u6355\u83b7\u5bbd\u611f\u53d7\u91ce\u548c\u957f\u7a0b\u7269\u7406\u4f9d\u8d56\uff09\u548c\u6324\u538b-\u6fc0\u52b1\u6a21\u5757\uff08\u901a\u8fc7\u901a\u9053\u6ce8\u610f\u529b\u81ea\u9002\u5e94\u91cd\u65b0\u6821\u51c6\u7279\u5f81\u901a\u9053\uff0c\u5f3a\u8c03\u52a8\u6001\u76f8\u5173\u5c3a\u5ea6\uff09\u3002", "result": "\u8bad\u7ec3\u901f\u5ea6\u6bd4\u6807\u51c6Transformer\u6a21\u578b\u548c\u795e\u7ecf\u7b97\u5b50\u5feb\u7ea620\u500d\uff0c\u5728\u591a\u4e2aPDE\u57fa\u51c6\u6d4b\u8bd5\uff08\u7ffc\u578b\u52bf\u6d41\u3001\u591a\u5b54\u4ecb\u8d28\u8fbe\u897f\u6d41\u3001\u6cca\u8083\u53f6\u7ba1\u6d41\u3001\u4e0d\u53ef\u538b\u7f29\u7eb3\u7ef4-\u65af\u6258\u514b\u65af\u6da1\u573a\uff09\u4e2d\u7cbe\u5ea6\u8fbe\u5230\u6216\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "D-SENO\u901a\u8fc7\u6269\u5f20\u5377\u79ef\u548c\u6324\u538b-\u6fc0\u52b1\u6a21\u5757\u7684\u6709\u6548\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u4e14\u51c6\u786e\u7684PDE\u6c42\u89e3\uff0c\u4e3a\u7269\u7406\u9a71\u52a8PDE\u7684\u5feb\u901f\u66ff\u4ee3\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17430", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17430", "abs": "https://arxiv.org/abs/2601.17430", "authors": ["Zichuan Yang", "Yiming Xing"], "title": "Active Hypothesis Testing for Correlated Combinatorial Anomaly Detection", "comment": "47 pages, 26 figures", "summary": "We study the problem of identifying an anomalous subset of streams under correlated noise, motivated by monitoring and security in cyber-physical systems. This problem can be viewed as a form of combinatorial pure exploration, where each stream plays the role of an arm and measurements must be allocated sequentially under uncertainty. Existing combinatorial bandit and hypothesis testing methods typically assume independent observations and fail to exploit correlation for efficient measurement design. We propose ECC-AHT, an adaptive algorithm that selects continuous, constrained measurements to maximize Chernoff information between competing hypotheses, enabling active noise cancellation through differential sensing. ECC-AHT achieves optimal sample complexity guarantees and significantly outperforms state-of-the-art baselines in both synthetic and real-world correlated environments. The code is available on https://github.com/VincentdeCristo/ECC-AHT", "AI": {"tldr": "\u63d0\u51faECC-AHT\u7b97\u6cd5\uff0c\u7528\u4e8e\u76f8\u5173\u566a\u58f0\u73af\u5883\u4e0b\u5f02\u5e38\u6d41\u8bc6\u522b\uff0c\u901a\u8fc7\u6700\u5927\u5316Chernoff\u4fe1\u606f\u5b9e\u73b0\u4e3b\u52a8\u566a\u58f0\u6d88\u9664\uff0c\u8fbe\u5230\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6", "motivation": "\u76d1\u63a7\u548c\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\uff0c\u73b0\u6709\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u548c\u5047\u8bbe\u68c0\u9a8c\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u72ec\u7acb\u89c2\u6d4b\uff0c\u65e0\u6cd5\u5229\u7528\u76f8\u5173\u6027\u8fdb\u884c\u9ad8\u6548\u6d4b\u91cf\u8bbe\u8ba1", "method": "\u63d0\u51faECC-AHT\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u9009\u62e9\u8fde\u7eed\u7ea6\u675f\u6d4b\u91cf\u4ee5\u6700\u5927\u5316\u7ade\u4e89\u5047\u8bbe\u95f4\u7684Chernoff\u4fe1\u606f\uff0c\u901a\u8fc7\u5dee\u5206\u611f\u77e5\u5b9e\u73b0\u4e3b\u52a8\u566a\u58f0\u6d88\u9664", "result": "\u8fbe\u5230\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\u4fdd\u8bc1\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u76f8\u5173\u73af\u5883\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "ECC-AHT\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u76f8\u5173\u566a\u58f0\u73af\u5883\u4e0b\u7684\u5f02\u5e38\u6d41\u8bc6\u522b\u95ee\u9898\uff0c\u901a\u8fc7\u5229\u7528\u76f8\u5173\u6027\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6d4b\u91cf\u8bbe\u8ba1"}}
{"id": "2601.17441", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17441", "abs": "https://arxiv.org/abs/2601.17441", "authors": ["Ondrej Bohdal", "Taha Ceritli", "Mete Ozay", "Jijoong Moon", "Kyeng-Hun Lee", "Hyeonmok Ko", "Umberto Michieli"], "title": "Data-driven Clustering and Merging of Adapters for On-device Large Language Models", "comment": "Accepted at ICASSP 2026", "summary": "On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.", "AI": {"tldr": "\u63d0\u51faD2C\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c11\u91cf\u4efb\u52a1\u793a\u4f8b\u548c\u8fed\u4ee3\u4f18\u5316\u5bf9\u9002\u914d\u5668\u8fdb\u884c\u805a\u7c7b\uff0c\u5408\u5e76\u540c\u7c07\u9002\u914d\u5668\u521b\u5efa\u591a\u4efb\u52a1\u9002\u914d\u5668\uff0c\u4ee5\u5728\u5b58\u50a8\u53d7\u9650\u8bbe\u5907\u4e0a\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u79fb\u52a8\u8bbe\u5907\u5b58\u50a8\u5bb9\u91cf\u6709\u9650\uff0c\u65e0\u6cd5\u5b58\u50a8\u6240\u6709\u4efb\u52a1\u9002\u914d\u5668\uff0c\u9700\u8981\u9009\u62e9\u4ee3\u8868\u6027\u9002\u914d\u5668\u4ee5\u8de8\u4efb\u52a1\u6cdb\u5316\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faD2C\u65b9\u6cd5\uff1a\u4f7f\u7528\u5c11\u91cf\u4efb\u52a1\u793a\u4f8b\uff08\u5982\u6bcf\u4efb\u52a110\u4e2a\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\u7cbe\u70bc\u805a\u7c7b\u5206\u914d\uff0c\u5408\u5e76\u540c\u7c07\u9002\u914d\u5668\u521b\u5efa\u591a\u4efb\u52a1\u9002\u914d\u5668\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8003\u8651\u5b58\u50a8\u9884\u7b97\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "D2C\u65b9\u6cd5\u89e3\u51b3\u4e86\u79fb\u52a8\u8bbe\u5907\u4e0a\u9002\u914d\u5668\u9009\u62e9\u7684\u6311\u6218\uff0c\u901a\u8fc7\u805a\u7c7b\u548c\u5408\u5e76\u521b\u5efa\u591a\u4efb\u52a1\u9002\u914d\u5668\uff0c\u5728\u6709\u9650\u5b58\u50a8\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.17449", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17449", "abs": "https://arxiv.org/abs/2601.17449", "authors": ["Yusheng Zhao", "Jiaye Xie", "Qixin Zhang", "Weizhi Zhang", "Xiao Luo", "Zhiping Xiao", "Philip S. Yu", "Ming Zhang"], "title": "DREAM: Dual-Standard Semantic Homogeneity with Dynamic Optimization for Graph Learning with Label Noise", "comment": null, "summary": "Graph neural networks (GNNs) have been widely used in various graph machine learning scenarios. Existing literature primarily assumes well-annotated training graphs, while the reliability of labels is not guaranteed in real-world scenarios. Recently, efforts have been made to address the problem of graph learning with label noise. However, existing methods often (i) struggle to distinguish between reliable and unreliable nodes, and (ii) overlook the relational information embedded in the graph topology. To tackle this problem, this paper proposes a novel method, Dual-Standard Semantic Homogeneity with Dynamic Optimization (DREAM), for reliable, relation-informed optimization on graphs with label noise. Specifically, we design a relation-informed dynamic optimization framework that iteratively reevaluates the reliability of each labeled node in the graph during the optimization process according to the relation of the target node and other nodes. To measure this relation comprehensively, we propose a dual-standard selection strategy that selects a set of anchor nodes based on both node proximity and graph topology. Subsequently, we compute the semantic homogeneity between the target node and the anchor nodes, which serves as guidance for optimization. We also provide a rigorous theoretical analysis to justify the design of DREAM. Extensive experiments are performed on six graph datasets across various domains under three types of graph label noise against competing baselines, and the results demonstrate the effectiveness of the proposed DREAM.", "AI": {"tldr": "DREAM\uff1a\u4e00\u79cd\u7528\u4e8e\u6807\u7b7e\u566a\u58f0\u56fe\u5b66\u4e60\u7684\u53cc\u6807\u51c6\u8bed\u4e49\u540c\u8d28\u6027\u52a8\u6001\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5173\u7cfb\u611f\u77e5\u7684\u52a8\u6001\u4f18\u5316\u6846\u67b6\u548c\u53cc\u6807\u51c6\u951a\u70b9\u9009\u62e9\u7b56\u7565\uff0c\u6709\u6548\u5904\u7406\u56fe\u6807\u7b7e\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8bad\u7ec3\u56fe\u6807\u7b7e\u51c6\u786e\uff0c\u4f46\u73b0\u5b9e\u573a\u666f\u4e2d\u6807\u7b7e\u53ef\u9760\u6027\u65e0\u6cd5\u4fdd\u8bc1\u3002\u73b0\u6709\u5904\u7406\u56fe\u6807\u7b7e\u566a\u58f0\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u96be\u4ee5\u533a\u5206\u53ef\u9760\u4e0e\u4e0d\u53ef\u9760\u8282\u70b9\uff0c\u4ee5\u53ca\u5ffd\u7565\u4e86\u56fe\u62d3\u6251\u4e2d\u5d4c\u5165\u7684\u5173\u7cfb\u4fe1\u606f\u3002", "method": "\u63d0\u51faDREAM\u65b9\u6cd5\uff0c\u5305\u542b\uff1a1\uff09\u5173\u7cfb\u611f\u77e5\u7684\u52a8\u6001\u4f18\u5316\u6846\u67b6\uff0c\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u8fed\u4ee3\u91cd\u65b0\u8bc4\u4f30\u6bcf\u4e2a\u6807\u8bb0\u8282\u70b9\u7684\u53ef\u9760\u6027\uff1b2\uff09\u53cc\u6807\u51c6\u9009\u62e9\u7b56\u7565\uff0c\u57fa\u4e8e\u8282\u70b9\u90bb\u8fd1\u6027\u548c\u56fe\u62d3\u6251\u9009\u62e9\u951a\u70b9\u96c6\uff1b3\uff09\u8ba1\u7b97\u76ee\u6807\u8282\u70b9\u4e0e\u951a\u70b9\u4e4b\u95f4\u7684\u8bed\u4e49\u540c\u8d28\u6027\uff0c\u4f5c\u4e3a\u4f18\u5316\u6307\u5bfc\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u56fe\u6570\u636e\u96c6\u4e0a\uff0c\u9488\u5bf9\u4e09\u79cd\u7c7b\u578b\u7684\u56fe\u6807\u7b7e\u566a\u58f0\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u4e0e\u7ade\u4e89\u57fa\u7ebf\u76f8\u6bd4\uff0cDREAM\u8868\u73b0\u51fa\u663e\u8457\u7684\u6709\u6548\u6027\u3002", "conclusion": "DREAM\u901a\u8fc7\u7ed3\u5408\u5173\u7cfb\u4fe1\u606f\u548c\u52a8\u6001\u4f18\u5316\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u56fe\u6807\u7b7e\u566a\u58f0\u95ee\u9898\uff0c\u4e3a\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u73b0\u5b9e\u566a\u58f0\u573a\u666f\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17467", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17467", "abs": "https://arxiv.org/abs/2601.17467", "authors": ["Jianxiong Zhang", "Bing Guo", "Yuming Jiang", "Haobo Wang", "Bo An", "Xuefeng Du"], "title": "Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping", "comment": null, "summary": "Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.", "AI": {"tldr": "\u63d0\u51faARS\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u53cd\u4e8b\u5b9e\u7b54\u6848\u5e76\u5b66\u4e60\u7b54\u6848\u4e00\u81f4\u6027\u8868\u5f81\u6765\u68c0\u6d4b\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u7ecf\u5e38\u751f\u6210\u770b\u4f3c\u8fde\u8d2f\u4f46\u7b54\u6848\u9519\u8bef\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u4f7f\u5f97\u5e7b\u89c9\u68c0\u6d4b\u53d8\u5f97\u56f0\u96be\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u8f68\u8ff9\u6587\u672c\u6216\u9690\u85cf\u72b6\u6001\u7684\u65b9\u6cd5\u5bb9\u6613\u8fc7\u62df\u5408\u8868\u9762\u6a21\u5f0f\u800c\u975e\u7b54\u6848\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u7b54\u6848\u4e00\u81f4\u6027\u8868\u5f81\u5851\u9020(ARS)\u65b9\u6cd5\uff1a\u901a\u8fc7\u5fae\u5c0f\u6f5c\u5728\u5e72\u9884\u751f\u6210\u53cd\u4e8b\u5b9e\u7b54\u6848\uff0c\u6270\u52a8\u8f68\u8ff9\u8fb9\u754c\u5d4c\u5165\uff0c\u6807\u8bb0\u6bcf\u4e2a\u6270\u52a8\u662f\u5426\u4e0e\u539f\u7b54\u6848\u4e00\u81f4\uff0c\u5b66\u4e60\u5c06\u7b54\u6848\u4e00\u81f4\u72b6\u6001\u805a\u5408\u3001\u4e0d\u4e00\u81f4\u72b6\u6001\u5206\u79bb\u7684\u8868\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660eARS\u80fd\u6301\u7eed\u6539\u8fdb\u68c0\u6d4b\u6548\u679c\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u83b7\u5f97\u663e\u8457\u63d0\u5347\u3002\u5851\u9020\u540e\u7684\u5d4c\u5165\u53ef\u4e0e\u73b0\u6709\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u6d4b\u5668\u5373\u63d2\u5373\u7528\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "conclusion": "ARS\u901a\u8fc7\u663e\u5f0f\u7f16\u7801\u7b54\u6848\u7a33\u5b9a\u6027\u5b66\u4e60\u68c0\u6d4b\u53cb\u597d\u7684\u8f68\u8ff9\u6761\u4ef6\u8868\u5f81\uff0c\u6709\u6548\u66b4\u9732\u6307\u793a\u5e7b\u89c9\u98ce\u9669\u7684\u6f5c\u5728\u4e0d\u7a33\u5b9a\u6027\uff0c\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17469", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17469", "abs": "https://arxiv.org/abs/2601.17469", "authors": ["Wei Ju", "Wei Zhang", "Siyu Yi", "Zhengyang Mao", "Yifan Wang", "Jingyang Yuan", "Zhiping Xiao", "Ziyue Qiao", "Ming Zhang"], "title": "Identifying and Correcting Label Noise for Robust GNNs via Influence Contradiction", "comment": null, "summary": "Graph Neural Networks (GNNs) have shown remarkable capabilities in learning from graph-structured data with various applications such as social analysis and bioinformatics. However, the presence of label noise in real scenarios poses a significant challenge in learning robust GNNs, and their effectiveness can be severely impacted when dealing with noisy labels on graphs, often stemming from annotation errors or inconsistencies. To address this, in this paper we propose a novel approach called ICGNN that harnesses the structure information of the graph to effectively alleviate the challenges posed by noisy labels. Specifically, we first design a novel noise indicator that measures the influence contradiction score (ICS) based on the graph diffusion matrix to quantify the credibility of nodes with clean labels, such that nodes with higher ICS values are more likely to be detected as having noisy labels. Then we leverage the Gaussian mixture model to precisely detect whether the label of a node is noisy or not. Additionally, we develop a soft strategy to combine the predictions from neighboring nodes on the graph to correct the detected noisy labels. At last, pseudo-labeling for abundant unlabeled nodes is incorporated to provide auxiliary supervision signals and guide the model optimization. Experiments on benchmark datasets show the superiority of our proposed approach.", "AI": {"tldr": "ICGNN\uff1a\u4e00\u79cd\u5229\u7528\u56fe\u7ed3\u6784\u4fe1\u606f\u5904\u7406\u6807\u7b7e\u566a\u58f0\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f71\u54cd\u529b\u77db\u76fe\u8bc4\u5206\u68c0\u6d4b\u566a\u58f0\u6807\u7b7e\uff0c\u7ed3\u5408\u90bb\u5c45\u9884\u6d4b\u8fdb\u884c\u6821\u6b63\uff0c\u5e76\u5229\u7528\u4f2a\u6807\u7b7e\u589e\u5f3a\u76d1\u7763\u4fe1\u53f7\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u6807\u7b7e\u566a\u58f0\uff08\u5982\u6807\u6ce8\u9519\u8bef\u6216\u4e0d\u4e00\u81f4\uff09\u4f1a\u4e25\u91cd\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u56fe\u6570\u636e\u4e2d\u7684\u6807\u7b7e\u566a\u58f0\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5229\u7528\u56fe\u7ed3\u6784\u4fe1\u606f\u6765\u66f4\u6709\u6548\u5730\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1. \u8bbe\u8ba1\u57fa\u4e8e\u56fe\u6269\u6563\u77e9\u9635\u7684\u5f71\u54cd\u529b\u77db\u76fe\u8bc4\u5206\uff08ICS\uff09\u4f5c\u4e3a\u566a\u58f0\u6307\u793a\u5668\uff0c\u91cf\u5316\u8282\u70b9\u6807\u7b7e\u7684\u53ef\u4fe1\u5ea6\uff1b2. \u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7cbe\u786e\u68c0\u6d4b\u8282\u70b9\u6807\u7b7e\u662f\u5426\u4e3a\u566a\u58f0\uff1b3. \u5f00\u53d1\u8f6f\u7b56\u7565\u7ed3\u5408\u90bb\u5c45\u8282\u70b9\u9884\u6d4b\u6765\u6821\u6b63\u68c0\u6d4b\u5230\u7684\u566a\u58f0\u6807\u7b7e\uff1b4. \u4e3a\u5927\u91cf\u672a\u6807\u8bb0\u8282\u70b9\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u63d0\u4f9b\u8f85\u52a9\u76d1\u7763\u4fe1\u53f7\u6307\u5bfc\u6a21\u578b\u4f18\u5316\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684ICGNN\u65b9\u6cd5\u5728\u5904\u7406\u56fe\u6570\u636e\u4e2d\u7684\u6807\u7b7e\u566a\u58f0\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "ICGNN\u901a\u8fc7\u5145\u5206\u5229\u7528\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6807\u7b7e\u566a\u58f0\u5904\u7406\u6846\u67b6\uff0c\u5305\u62ec\u566a\u58f0\u68c0\u6d4b\u3001\u6807\u7b7e\u6821\u6b63\u548c\u4f2a\u6807\u7b7e\u589e\u5f3a\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff0c\u4e3a\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u73b0\u5b9e\u566a\u58f0\u573a\u666f\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17473", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17473", "abs": "https://arxiv.org/abs/2601.17473", "authors": ["Manooshree Patel", "Rayna Bhattacharyya", "Thomas Lu", "Arnav Mehta", "Niels Voss", "Narges Norouzi", "Gireeja Ranade"], "title": "LeanTutor: Towards a Verified AI Mathematical Proof Tutor", "comment": "arXiv admin note: substantial text overlap with arXiv:2506.08321. substantial text overlap with arXiv:2506.08321. substantial text overlap with arXiv:2506.08321. substantial text overlap with arXiv:2506.08321", "summary": "This paper considers the development of an AI-based provably-correct mathematical proof tutor. While Large Language Models (LLMs) allow seamless communication in natural language, they are error prone. Theorem provers such as Lean allow for provable-correctness, but these are hard for students to learn. We present a proof-of-concept system (LeanTutor) by combining the complementary strengths of LLMs and theorem provers. LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and (iii) a natural language feedback generator. To evaluate the system, we introduce PeanoBench, a dataset of 371 Peano Arithmetic proofs in human-written natural language and formal language, derived from the Natural Numbers Game.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408LLM\u548c\u5b9a\u7406\u8bc1\u660e\u5668\u7684AI\u6570\u5b66\u8bc1\u660e\u8f85\u5bfc\u7cfb\u7edfLeanTutor\uff0c\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff0c\u5e76\u5728PeanoBench\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1", "motivation": "LLM\u867d\u7136\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u6d41\u7545\u4ea4\u6d41\u4f46\u5bb9\u6613\u51fa\u9519\uff0c\u800c\u5b9a\u7406\u8bc1\u660e\u5668\u5982Lean\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\u4f46\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u3002\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\uff0c\u4e3a\u6570\u5b66\u8bc1\u660e\u6559\u5b66\u63d0\u4f9b\u65e2\u6613\u7528\u53c8\u53ef\u9760\u7684\u8f85\u5bfc\u5de5\u5177", "method": "\u5f00\u53d1LeanTutor\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a(1)\u81ea\u52a8\u5f62\u5f0f\u5316/\u8bc1\u660e\u68c0\u67e5\u5668\uff0c(2)\u4e0b\u4e00\u6b65\u751f\u6210\u5668\uff0c(3)\u81ea\u7136\u8bed\u8a00\u53cd\u9988\u751f\u6210\u5668\u3002\u4f7f\u7528\u4ece\u81ea\u7136\u6570\u6e38\u620f\u884d\u751f\u7684PeanoBench\u6570\u636e\u96c6\uff08371\u4e2aPeano\u7b97\u672f\u8bc1\u660e\uff09\u8fdb\u884c\u8bc4\u4f30", "result": "\u63d0\u51fa\u4e86\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edfLeanTutor\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u7ed3\u5408LLM\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\u548c\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u80fd\u529b\uff0c\u4e3a\u6570\u5b66\u8bc1\u660e\u6559\u5b66\u63d0\u4f9b\u65b0\u7684\u89e3\u51b3\u65b9\u6848", "conclusion": "\u901a\u8fc7\u7ed3\u5408LLM\u548c\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u53ef\u4ee5\u521b\u5efa\u65e2\u6613\u4e8e\u4f7f\u7528\u53c8\u5177\u6709\u53ef\u8bc1\u660e\u6b63\u786e\u6027\u7684\u6570\u5b66\u8bc1\u660e\u8f85\u5bfc\u7cfb\u7edf\uff0c\u4e3a\u6570\u5b66\u6559\u80b2\u63d0\u4f9b\u65b0\u7684\u53ef\u80fd\u6027"}}
{"id": "2601.17480", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17480", "abs": "https://arxiv.org/abs/2601.17480", "authors": ["Marton Szep", "Jorge Marin Ruiz", "Georgios Kaissis", "Paulina Seidl", "R\u00fcdiger von Eisenhart-Rothe", "Florian Hinterwimmer", "Daniel Rueckert"], "title": "Unintended Memorization of Sensitive Information in Fine-Tuned Language Models", "comment": "Accepted to EACL 2026. 20 pages", "summary": "Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5728\u5fae\u8c03LLMs\u65f6\uff0c\u5373\u4f7fPII\u4ec5\u51fa\u73b0\u5728\u6a21\u578b\u8f93\u5165\u800c\u975e\u8bad\u7ec3\u76ee\u6807\u4e2d\uff0c\u4e5f\u5b58\u5728\u663e\u8457\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u7684\u6743\u8861\u3002", "motivation": "\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u6570\u636e\u96c6\u4e0a\u5b58\u5728\u610f\u5916\u8bb0\u5fc6\u548c\u6cc4\u9732\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u7684\u91cd\u5927\u98ce\u9669\uff0c\u8fd9\u53ef\u80fd\u8fdd\u53cd\u9690\u79c1\u6cd5\u89c4\u5e76\u5371\u53ca\u4e2a\u4eba\u5b89\u5168\u3002\u5f53\u524d\u7814\u7a76\u5bf9\u4ec5\u51fa\u73b0\u5728\u6a21\u578b\u8f93\u5165\u800c\u975e\u8bad\u7ec3\u76ee\u6807\u4e2d\u7684PII\u66b4\u9732\u8fd9\u4e00\u5173\u952e\u4e14\u672a\u5145\u5206\u63a2\u7d22\u7684\u6f0f\u6d1e\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u8bbe\u8ba1\u53d7\u63a7\u63d0\u53d6\u63a2\u9488\u6765\u91cf\u5316\u610f\u5916PII\u8bb0\u5fc6\uff0c\u7814\u7a76\u8bed\u8a00\u3001PII\u9891\u7387\u3001\u4efb\u52a1\u7c7b\u578b\u548c\u6a21\u578b\u5927\u5c0f\u7b49\u56e0\u7d20\u5bf9\u8bb0\u5fc6\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u540c\u65f6\u57fa\u51c6\u6d4b\u8bd5\u56db\u79cd\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff1a\u5dee\u5206\u9690\u79c1\u3001\u673a\u5668\u9057\u5fd8\u3001\u6b63\u5219\u5316\u548c\u504f\u597d\u5bf9\u9f50\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7fPII\u4ec5\u51fa\u73b0\u5728\u8f93\u5165\u4e2d\uff0c\u6a21\u578b\u4ecd\u4f1a\u610f\u5916\u8bb0\u5fc6\u548c\u6cc4\u9732\u8fd9\u4e9b\u4fe1\u606f\u3002\u540e\u8bad\u7ec3\u65b9\u6cd5\u901a\u5e38\u63d0\u4f9b\u66f4\u4e00\u81f4\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u800c\u5dee\u5206\u9690\u79c1\u5728\u7279\u5b9a\u8bbe\u7f6e\u4e2d\u80fd\u663e\u8457\u51cf\u5c11\u6cc4\u9732\uff0c\u4f46\u53ef\u80fd\u5f15\u5165\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u5fae\u8c03LLMs\u4e2d\u7684\u8bb0\u5fc6\u95ee\u9898\u4ecd\u7136\u662f\u4e00\u4e2a\u6301\u4e45\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5373\u4f7f\u5728PII\u4e0d\u76f4\u63a5\u4f5c\u4e3a\u8bad\u7ec3\u76ee\u6807\u7684\u60c5\u51b5\u4e0b\uff0c\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u4f9d\u7136\u5b58\u5728\uff0c\u5e76\u6307\u51fa\u4e86\u4e0d\u540c\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u7684\u9002\u7528\u573a\u666f\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2601.17483", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17483", "abs": "https://arxiv.org/abs/2601.17483", "authors": ["Barak Or"], "title": "Automatic Stability and Recovery for Neural Network Training", "comment": "Under Review", "summary": "Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8fd0\u884c\u65f6\u7a33\u5b9a\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u9694\u79bb\u521b\u65b0\u4fe1\u53f7\u5b9e\u73b0\u81ea\u52a8\u68c0\u6d4b\u548c\u6062\u590d\uff0c\u4e0d\u4fee\u6539\u5e95\u5c42\u4f18\u5316\u5668\uff0c\u63d0\u4f9b\u7406\u8bba\u5b89\u5168\u4fdd\u8bc1", "motivation": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u8d8a\u6765\u8d8a\u8106\u5f31\uff0c\u7f55\u89c1\u4f46\u4e25\u91cd\u7684\u7834\u574f\u6027\u66f4\u65b0\u5e38\u5bfc\u81f4\u4e0d\u53ef\u9006\u7684\u53d1\u6563\u6216\u6027\u80fd\u9759\u9ed8\u9000\u5316\uff0c\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9884\u9632\u673a\u5236\uff0c\u4e00\u65e6\u53d1\u751f\u4e0d\u7a33\u5b9a\u65f6\u68c0\u6d4b\u548c\u6062\u590d\u80fd\u529b\u6709\u9650", "method": "\u5f15\u5165\u76d1\u7763\u8fd0\u884c\u65f6\u7a33\u5b9a\u6027\u6846\u67b6\uff0c\u5c06\u4f18\u5316\u89c6\u4e3a\u53d7\u63a7\u968f\u673a\u8fc7\u7a0b\uff0c\u901a\u8fc7\u9694\u79bb\u6765\u81ea\u6b21\u7ea7\u6d4b\u91cf\uff08\u5982\u9a8c\u8bc1\u63a2\u9488\uff09\u7684\u521b\u65b0\u4fe1\u53f7\uff0c\u5b9e\u73b0\u81ea\u52a8\u68c0\u6d4b\u548c\u6062\u590d\u7834\u574f\u6027\u66f4\u65b0\uff0c\u4e0d\u4fee\u6539\u5e95\u5c42\u4f18\u5316\u5668", "result": "\u63d0\u4f9b\u7406\u8bba\u8fd0\u884c\u65f6\u5b89\u5168\u4fdd\u8bc1\uff0c\u5f62\u5f0f\u5316\u6709\u754c\u9000\u5316\u548c\u6062\u590d\uff1b\u5b9e\u73b0\u5f00\u9500\u6700\u5c0f\uff0c\u517c\u5bb9\u5185\u5b58\u53d7\u9650\u7684\u8bad\u7ec3\u8bbe\u7f6e", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8fd0\u884c\u65f6\u7a33\u5b9a\u6027\u76d1\u63a7\u548c\u6062\u590d\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u548c\u6062\u590d\u65b9\u9762\u7684\u5c40\u9650\u6027"}}
{"id": "2601.17489", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.17489", "abs": "https://arxiv.org/abs/2601.17489", "authors": ["Ashutosh Bajpai", "Akshat Bhandari", "Akshay Nambi", "Tanmoy Chakraborty"], "title": "SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving", "comment": null, "summary": "Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.", "AI": {"tldr": "SpatialMath\u6846\u67b6\u901a\u8fc7\u5c06\u7a7a\u95f4\u611f\u77e5\u878d\u5165\u7b26\u53f7\u63a8\u7406\u94fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u51e0\u4f55\u95ee\u9898\u4e0a\u7684\u89c6\u89c9\u7406\u89e3\u548c\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u4e2d\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u7406\u89e3\u548c\u6570\u5b66\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u7279\u522b\u662f\u5728\u51e0\u4f55\u95ee\u9898\u4e0a\uff0c\u96be\u4ee5\u51c6\u786e\u5206\u89e3\u590d\u6742\u89c6\u89c9\u8f93\u5165\u5e76\u5c06\u611f\u77e5\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u8fde\u63a5\u8d77\u6765\u3002", "method": "\u63d0\u51faSpatialMath\u6846\u67b6\uff0c\u5305\u542b\u4e13\u95e8\u7684\u611f\u77e5\u6a21\u5757\u63d0\u53d6\u89c6\u89c9\u56fe\u8868\u4e2d\u7684\u7a7a\u95f4\u57fa\u7840\u8868\u793a\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u8868\u793a\u7cfb\u7edf\u5730\u878d\u5165\u7b26\u53f7\u63a8\u7406\u94fe\u4e2d\uff0c\u5b9e\u73b0\u89c6\u89c9\u7406\u89e3\u611f\u77e5\u7684\u7ed3\u6784\u5316\u63a8\u7406\u3002", "result": "SpatialMath\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u89c6\u89c9\u5bc6\u96c6\u578b\u8bbe\u7f6e\u4e2d\u6bd4\u6570\u636e\u589e\u5f3a\u7684\u76d1\u7763\u5fae\u8c03\u63d0\u5347\u4e8610\u4e2a\u767e\u5206\u70b9\u3002\u9c81\u68d2\u6027\u5206\u6790\u663e\u793a\u589e\u5f3a\u7684\u7a7a\u95f4\u8868\u793a\u76f4\u63a5\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u3002", "conclusion": "\u7ed3\u6784\u5316\u611f\u77e5\u5230\u63a8\u7406\u7684\u7ba1\u9053\u5bf9\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u7a7a\u95f4\u8868\u793a\u7684\u6574\u5408\u80fd\u6709\u6548\u63d0\u5347\u89c6\u89c9\u5bc6\u96c6\u578b\u6570\u5b66\u95ee\u9898\u7684\u89e3\u51b3\u80fd\u529b\u3002"}}
{"id": "2601.17495", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.17495", "abs": "https://arxiv.org/abs/2601.17495", "authors": ["Ruiyu Zhang", "Lin Nie", "Wai-Fung Lam", "Qihao Wang", "Xin Zhao"], "title": "PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems", "comment": "15 pages, 1 figure", "summary": "In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.", "AI": {"tldr": "PEARL\u662f\u4e00\u79cd\u6807\u7b7e\u9ad8\u6548\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u539f\u578b\u589e\u5f3a\u5bf9\u9f50\u5d4c\u5165\u8868\u793a\uff0c\u6539\u5584\u5c40\u90e8\u90bb\u57df\u7ed3\u6784\uff0c\u5728\u6807\u7b7e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347\u76f8\u4f3c\u6027\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5b9e\u9645\u90e8\u7f72\u7cfb\u7edf\u4e2d\uff0c\u57fa\u4e8e\u5d4c\u5165\u7684\u6700\u8fd1\u90bb\u68c0\u7d22\u7ecf\u5e38\u5931\u8d25\uff0c\u56e0\u4e3a\u539f\u59cb\u5d4c\u5165\u7684\u51e0\u4f55\u7ed3\u6784\u4e0e\u5c40\u90e8\u90bb\u57df\u9700\u6c42\u4e0d\u5339\u914d\u3002\u6807\u7b7e\u7a00\u7f3a\u3001\u9886\u57df\u6f02\u79fb\u548c\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\u4f7f\u5f97\u4e0b\u6e38\u6027\u80fd\u4e25\u91cd\u4f9d\u8d56\u5d4c\u5165\u51e0\u4f55\u7ed3\u6784\u3002", "method": "PEARL\uff08\u539f\u578b\u589e\u5f3a\u5bf9\u9f50\u8868\u793a\u5b66\u4e60\uff09\u4f7f\u7528\u6709\u9650\u76d1\u7763\u901a\u8fc7\u8f6f\u5bf9\u9f50\u5d4c\u5165\u5230\u7c7b\u522b\u539f\u578b\u6765\u91cd\u5851\u5c40\u90e8\u90bb\u57df\u51e0\u4f55\u7ed3\u6784\uff0c\u4fdd\u6301\u7ef4\u5ea6\u6027\uff0c\u907f\u514d\u6fc0\u8fdb\u6295\u5f71\u6216\u574d\u7f29\u3002", "result": "\u5728\u6807\u7b7e\u7a00\u7f3a\u6761\u4ef6\u4e0b\uff0cPEARL\u663e\u8457\u6539\u5584\u5c40\u90e8\u90bb\u57df\u8d28\u91cf\uff0c\u76f8\u6bd4\u539f\u59cb\u5d4c\u5165\u63d0\u534725.7%\uff0c\u76f8\u6bd4\u5f3a\u65e0\u76d1\u7763\u540e\u5904\u7406\u65b9\u6cd5\u63d0\u534721.1%\u4ee5\u4e0a\u3002", "conclusion": "PEARL\u5728\u6807\u7b7e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u6709\u6548\u6539\u5584\u5d4c\u5165\u51e0\u4f55\u7ed3\u6784\uff0c\u586b\u8865\u4e86\u65e0\u76d1\u7763\u540e\u5904\u7406\uff08\u589e\u76ca\u6709\u9650\uff09\u548c\u5168\u76d1\u7763\u6295\u5f71\uff08\u9700\u8981\u5927\u91cf\u6807\u7b7e\uff09\u4e4b\u95f4\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.17512", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17512", "abs": "https://arxiv.org/abs/2601.17512", "authors": ["Yiqun Zhang", "Shenghong Cai", "Zihua Yang", "Sen Feng", "Yuzhu Ji", "Haijun Zhang"], "title": "One-Shot Federated Clustering of Non-Independent Completely Distributed Data", "comment": "This work has been accepted for publication in IEEE Internet of Things Journal", "summary": "Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGOLD\u6846\u67b6\u89e3\u51b3\u8054\u90a6\u805a\u7c7b\u4e2d\u7684Non-IID\u95ee\u9898\uff0c\u63ed\u793aNon-ICD\u73b0\u8c61\uff0c\u901a\u8fc7\u5168\u5c40\u5bfc\u5411\u7684\u5c40\u90e8\u5206\u5e03\u5b66\u4e60\u63d0\u5347\u805a\u7c7b\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u805a\u7c7b\u5728\u65e0\u6807\u7b7e\u5206\u5e03\u5f0f\u6570\u636e\u4e2d\u9762\u4e34\u4e25\u91cd\u6311\u6218\uff0c\u7279\u522b\u662fNon-IID\u95ee\u9898\u5bfc\u81f4\u4e0d\u540c\u5ba2\u6237\u7aef\u53ef\u80fd\u5206\u5272\u540c\u4e00\u4e2a\u805a\u7c7b\uff0c\u5f62\u6210\u66f4\u590d\u6742\u7684Non-ICD\u73b0\u8c61\uff0c\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u53d7\u9650\u3002", "method": "\u63d0\u51faGOLD\u6846\u67b6\uff1a1) \u7cbe\u7ec6\u63a2\u7d22\u5ba2\u6237\u7aef\u6f5c\u5728\u7684\u4e0d\u5b8c\u6574\u5c40\u90e8\u805a\u7c7b\u5206\u5e03\uff1b2) \u4e0a\u4f20\u5206\u5e03\u6458\u8981\u5230\u670d\u52a1\u5668\u8fdb\u884c\u5168\u5c40\u878d\u5408\uff1b3) \u5728\u5168\u5c40\u5206\u5e03\u6307\u5bfc\u4e0b\u8fdb\u884c\u5c40\u90e8\u805a\u7c7b\u589e\u5f3a\u3002", "result": "\u901a\u8fc7\u663e\u8457\u6027\u68c0\u9a8c\u3001\u6d88\u878d\u7814\u7a76\u3001\u53ef\u6269\u5c55\u6027\u8bc4\u4f30\u548c\u5b9a\u6027\u5206\u6790\u7b49\u5927\u91cf\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86GOLD\u6846\u67b6\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "GOLD\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u805a\u7c7b\u4e2d\u7684Non-ICD\u6311\u6218\uff0c\u901a\u8fc7\u5168\u5c40\u5bfc\u5411\u7684\u5c40\u90e8\u5206\u5e03\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u805a\u7c7b\u6027\u80fd\u3002"}}
{"id": "2601.17563", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17563", "abs": "https://arxiv.org/abs/2601.17563", "authors": ["Nathan Gavenski", "Matteo Leonetti", "Odinaldo Rodrigues"], "title": "Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment", "comment": "The 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026)", "summary": "State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.", "AI": {"tldr": "\u63d0\u51faUfO\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65e0\u76d1\u7763\u5b66\u4e60\u4ece\u89c2\u5bdf\u4e2d\u6a21\u4eff\uff0c\u65e0\u9700\u52a8\u4f5c\u76d1\u7763\uff0c\u4f18\u4e8e\u73b0\u6709ILfO\u65b9\u6cd5\u548c\u6559\u5e08\u7b56\u7565", "motivation": "\u73b0\u6709\u89c2\u5bdf\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u52a8\u4f5c\u76d1\u7763\u3001\u5047\u8bbe\u72b6\u6001\u6709\u5355\u4e00\u6700\u4f18\u52a8\u4f5c\u3001\u4e0d\u8003\u8651\u5b9e\u9645\u73af\u5883\u72b6\u6001\uff0c\u5b58\u5728\u5c40\u9650\u6027", "method": "\u4e24\u9636\u6bb5\u65e0\u76d1\u7763\u5b66\u4e60\uff1a\u7b2c\u4e00\u9636\u6bb5\u8fd1\u4f3c\u6559\u5e08\u771f\u5b9e\u52a8\u4f5c\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8c03\u6574\u667a\u80fd\u4f53\u8f68\u8ff9\u4e0e\u6559\u5e08\u5bf9\u9f50", "result": "\u5728\u4e94\u4e2a\u73af\u5883\u4e2d\u8d85\u8d8a\u6559\u5e08\u548c\u6240\u6709ILfO\u65b9\u6cd5\uff0c\u6807\u51c6\u5dee\u6700\u5c0f\uff0c\u6cdb\u5316\u80fd\u529b\u66f4\u597d", "conclusion": "UfO\u89e3\u51b3\u4e86\u73b0\u6709ILfO\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u65e0\u76d1\u7763\u7684\u89c2\u5bdf\u6a21\u4eff\u5b66\u4e60\uff0c\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd"}}
{"id": "2601.17570", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.17570", "abs": "https://arxiv.org/abs/2601.17570", "authors": ["Hadi Salloum", "Ali Jnadi", "Yaroslav Kholodov", "Alexander Gasnikov"], "title": "Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization", "comment": "Proceedings of Machine Learning Research tbd: 1_13, 2025 International Conference on Computational Optimization", "summary": "Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.", "AI": {"tldr": "MC+QUBO\uff1a\u901a\u8fc7\u5c06\u60c5\u8282\u9009\u62e9\u8f6c\u5316\u4e3aQUBO\u95ee\u9898\u5e76\u4f7f\u7528\u91cf\u5b50\u542f\u53d1\u91c7\u6837\u5668\uff0c\u6539\u8fdb\u8499\u7279\u5361\u6d1b\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u3002", "motivation": "\u8499\u7279\u5361\u6d1b\u5f3a\u5316\u5b66\u4e60\u5728\u7a00\u758f\u5956\u52b1\u3001\u5927\u72b6\u6001\u7a7a\u95f4\u548c\u76f8\u5173\u8f68\u8ff9\u7684\u73af\u5883\u4e2d\u6837\u672c\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6837\u672c\u5229\u7528\u65b9\u6cd5\u3002", "method": "\u5c06\u60c5\u8282\u9009\u62e9\u91cd\u65b0\u8868\u8ff0\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u6a21\u62df\u91cf\u5b50\u9000\u706b\u548c\u6a21\u62df\u5206\u5c94\u4f5c\u4e3a\u9ed1\u76d2\u6c42\u89e3\u5668\uff0c\u4ece\u8f68\u8ff9\u6279\u6b21\u4e2d\u9009\u62e9\u6700\u5927\u5316\u7d2f\u79ef\u5956\u52b1\u540c\u65f6\u4fc3\u8fdb\u72b6\u6001\u7a7a\u95f4\u8986\u76d6\u7684\u5b50\u96c6\u3002", "result": "\u5728\u6709\u9650\u65f6\u57dfGridWorld\u5b9e\u9a8c\u4e2d\uff0cMC+QUBO\u5728\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u7b56\u7565\u8d28\u91cf\u4e0a\u5747\u4f18\u4e8e\u6807\u51c6\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u3002", "conclusion": "\u91cf\u5b50\u542f\u53d1\u4f18\u5316\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u51b3\u7b56\u5b50\u7a0b\u5e8f\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u6837\u672c\u6548\u7387\u548c\u7b56\u7565\u8d28\u91cf\u3002"}}
{"id": "2601.17602", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17602", "abs": "https://arxiv.org/abs/2601.17602", "authors": ["Xuanzhou Chen"], "title": "Understanding Transformer Encoder-Decoder Representations through Bernoulli Dropout", "comment": null, "summary": "We study Transformer overparameterization through the lens of angular similarity in high-dimensional encoder-decoder embeddings. We apply Bernoulli dropout between the encoder and the decoder, varying the keep probability $p$ to identify a sparsity-dependent threshold above which the Top-1 prediction is preserved. Theoretically, we prove that, if the effective sparsity embeddings is sufficiently large, and thus decoder performance, remain stable under moderate coordinate dropout. Empirically, we implement the Bernoulli dropout by constructing a new Transformer model augmented with Binary Erasure Channel (BEC) and test its performance on an English-French translation task. Experimental results visualize the trends for validation accuracies and BLEU scores, both decline sharply at some threshold.", "AI": {"tldr": "\u7814\u7a76Transformer\u8fc7\u53c2\u6570\u5316\uff0c\u901a\u8fc7\u9ad8\u7ef4\u7f16\u7801\u5668-\u89e3\u7801\u5668\u5d4c\u5165\u7684\u89d2\u5ea6\u76f8\u4f3c\u6027\u5206\u6790\uff0c\u4f7f\u7528\u4f2f\u52aa\u5229dropout\u8bc6\u522b\u4fdd\u6301Top-1\u9884\u6d4b\u7684\u7a00\u758f\u6027\u9608\u503c", "motivation": "\u7814\u7a76Transformer\u6a21\u578b\u7684\u8fc7\u53c2\u6570\u5316\u95ee\u9898\uff0c\u63a2\u7d22\u5728\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e4b\u95f4\u5e94\u7528dropout\u65f6\uff0c\u6a21\u578b\u6027\u80fd\u5982\u4f55\u968f\u7a00\u758f\u6027\u53d8\u5316\uff0c\u4ee5\u7406\u89e3\u5d4c\u5165\u8868\u793a\u7684\u9c81\u68d2\u6027", "method": "1. \u4f7f\u7528\u4f2f\u52aa\u5229dropout\u5728\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e4b\u95f4\uff0c\u6539\u53d8\u4fdd\u7559\u6982\u7387p\uff1b2. \u7406\u8bba\u4e0a\u8bc1\u660e\u5f53\u5d4c\u5165\u6709\u6548\u7a00\u758f\u6027\u8db3\u591f\u5927\u65f6\uff0c\u89e3\u7801\u5668\u6027\u80fd\u5728\u9002\u5ea6\u5750\u6807dropout\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff1b3. \u6784\u5efa\u5e26\u6709\u4e8c\u8fdb\u5236\u64e6\u9664\u901a\u9053(BEC)\u7684Transformer\u6a21\u578b\uff0c\u5728\u82f1\u6cd5\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u6d4b\u8bd5", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9a8c\u8bc1\u51c6\u786e\u7387\u548cBLEU\u5206\u6570\u5728\u67d0\u4e2a\u9608\u503c\u5904\u6025\u5267\u4e0b\u964d\uff0c\u53ef\u89c6\u5316\u8d8b\u52bf\u8868\u660e\u5b58\u5728\u4e00\u4e2a\u7a00\u758f\u6027\u4f9d\u8d56\u7684\u9608\u503c\uff0c\u8d85\u8fc7\u8be5\u9608\u503cTop-1\u9884\u6d4b\u5f97\u4ee5\u4fdd\u6301", "conclusion": "Transformer\u6a21\u578b\u5728\u7f16\u7801\u5668-\u89e3\u7801\u5668\u5d4c\u5165\u4e2d\u5b58\u5728\u9c81\u68d2\u6027\u9608\u503c\uff0c\u5f53\u5d4c\u5165\u6709\u6548\u7a00\u758f\u6027\u8db3\u591f\u5927\u65f6\uff0c\u6a21\u578b\u6027\u80fd\u5728\u9002\u5ea6dropout\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff0c\u8fd9\u4e3a\u7406\u89e3Transformer\u8fc7\u53c2\u6570\u5316\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2601.17607", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17607", "abs": "https://arxiv.org/abs/2601.17607", "authors": ["Daisuke Okanohara"], "title": "A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs", "comment": "9 pages. Part I of a planned series entitled \"A Thermodynamic Theory of Learning.\"", "summary": "Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits?\n  We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework.\n  Within this framework, we define the free-energy drop as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This reduction decomposes into a reversible component associated with potential improvement and an irreversible component corresponding to entropy production.\n  We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5b66\u4e60\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e0d\u53ef\u9006\u8fc7\u7a0b\uff0c\u9700\u8981\u71b5\u4ea7\u751f\u6765\u5b9e\u73b0\u8ba4\u77e5\u7ed3\u6784\uff0c\u5e76\u63a8\u5bfc\u51fa\u8ba4\u77e5\u901f\u5ea6\u6781\u9650(ESL)\u4e0d\u7b49\u5f0f\uff0c\u4e3a\u5b66\u4e60\u8fc7\u7a0b\u8bbe\u5b9a\u4e86\u6700\u5c0f\u71b5\u4ea7\u751f\u4e0b\u754c\u3002", "motivation": "\u7ecf\u5178\u4fe1\u606f\u8bba\u8ba4\u4e3a\u786e\u5b9a\u6027\u53d8\u6362\u4e0d\u4f1a\u589e\u52a0\u4fe1\u606f\uff0c\u4f46\u5b66\u4e60\u7cfb\u7edf\u5374\u80fd\u4ece\u6570\u636e\u4e2d\u83b7\u5f97\u7ed3\u6784\u5316\u5185\u90e8\u8868\u793a\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u5b66\u4e60\u5982\u4f55\u5728\u9075\u5b88\u4fe1\u606f\u8bba\u9650\u5236\u7684\u540c\u65f6\u4ea7\u751f\u62bd\u8c61\u548c\u6d1e\u5bdf\uff1f", "method": "\u5c06\u5b66\u4e60\u5efa\u6a21\u4e3a\u6a21\u578b\u914d\u7f6e\u6982\u7387\u5206\u5e03\u7a7a\u95f4\u4e2d\u7684\u4f20\u8f93\u8fc7\u7a0b\uff0c\u5f15\u5165\u8ba4\u77e5\u81ea\u7531\u80fd\u6846\u67b6\uff0c\u5b9a\u4e49\u81ea\u7531\u80fd\u4e0b\u964d\u4f5c\u4e3a\u5b66\u4e60\u8f68\u8ff9\u4e0a\u8ba4\u77e5\u81ea\u7531\u80fd\u603b\u51cf\u5c11\u7684\u8bb0\u8d26\u91cf\uff0c\u5e76\u5c06\u5176\u5206\u89e3\u4e3a\u53ef\u9006\u548c\u4e0d\u53ef\u9006\u5206\u91cf\u3002", "result": "\u63a8\u5bfc\u51fa\u8ba4\u77e5\u901f\u5ea6\u6781\u9650(ESL)\u4e0d\u7b49\u5f0f\uff0c\u8be5\u4e0d\u7b49\u5f0f\u4e3a\u4efb\u4f55\u5b66\u4e60\u8fc7\u7a0b\u5b9e\u73b0\u7ed9\u5b9a\u5206\u5e03\u53d8\u6362\u6240\u9700\u7684\u6700\u5c0f\u71b5\u4ea7\u751f\u8bbe\u5b9a\u4e86\u4e0b\u754c\uff0c\u8be5\u4e0b\u754c\u4ec5\u53d6\u51b3\u4e8e\u521d\u59cb\u548c\u6700\u7ec8\u96c6\u5408\u5206\u5e03\u4e4b\u95f4\u7684Wasserstein\u8ddd\u79bb\uff0c\u4e0e\u5177\u4f53\u5b66\u4e60\u7b97\u6cd5\u65e0\u5173\u3002", "conclusion": "\u5b66\u4e60\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e0d\u53ef\u9006\u8fc7\u7a0b\uff0c\u8ba4\u77e5\u7ed3\u6784\u7684\u5b9e\u73b0\u5fc5\u7136\u4f34\u968f\u71b5\u4ea7\u751f\u3002\u8ba4\u77e5\u901f\u5ea6\u6781\u9650\u4e3a\u5b66\u4e60\u8fc7\u7a0b\u8bbe\u5b9a\u4e86\u57fa\u672c\u9650\u5236\uff0c\u5c06\u5b66\u4e60\u7406\u8bba\u4e0e\u975e\u5e73\u8861\u70ed\u529b\u5b66\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2601.17616", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17616", "abs": "https://arxiv.org/abs/2601.17616", "authors": ["Fatema Siddika", "Md Anwar Hossen", "Tanwi Mallick", "Ali Jannesari"], "title": "Split-on-Share: Mixture of Sparse Experts for Task-Agnostic Continual Learning", "comment": "17 pages, 9 figures, 8 tables", "summary": "Continual learning in Large Language Models (LLMs) is hindered by the plasticity-stability dilemma, where acquiring new capabilities often leads to catastrophic forgetting of previous knowledge. Existing methods typically treat parameters uniformly, failing to distinguish between specific task knowledge and shared capabilities. We introduce Mixture of Sparse Experts for Task-Agnostic Continual Learning, referred to as SETA, a framework that resolves the plasticity-stability conflict by decomposing the model into modular subspaces. Unlike standard updates, where tasks compete for the same parameters, SETA separates knowledge into unique experts, designed to isolate task-specific patterns, and shared experts, responsible for capturing common features. This structure is maintained through elastic weight anchoring, which protects critical shared knowledge and enables a unified gating network to automatically retrieve the correct expert combination for each task during inference. Extensive experiments across diverse domain-specific and general benchmarks demonstrate that SETA consistently outperforms state-of-the-art parameter-efficient fine-tuning-based continual learning methods.", "AI": {"tldr": "SETA\u6846\u67b6\u901a\u8fc7\u5c06LLM\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u5b50\u7a7a\u95f4\u6765\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u53ef\u5851\u6027-\u7a33\u5b9a\u6027\u56f0\u5883\uff0c\u4f7f\u7528\u72ec\u7279\u4e13\u5bb6\u548c\u5171\u4eab\u4e13\u5bb6\u5206\u79bb\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u548c\u901a\u7528\u7279\u5f81\uff0c\u901a\u8fc7\u5f39\u6027\u6743\u91cd\u951a\u5b9a\u4fdd\u62a4\u5173\u952e\u5171\u4eab\u77e5\u8bc6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u9762\u4e34\u53ef\u5851\u6027-\u7a33\u5b9a\u6027\u56f0\u5883\uff1a\u5b66\u4e60\u65b0\u80fd\u529b\u4f1a\u5bfc\u81f4\u5bf9\u5148\u524d\u77e5\u8bc6\u7684\u707e\u96be\u6027\u9057\u5fd8\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u7edf\u4e00\u5904\u7406\u53c2\u6570\uff0c\u65e0\u6cd5\u533a\u5206\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u548c\u5171\u4eab\u80fd\u529b\u3002", "method": "\u63d0\u51faSETA\u6846\u67b6\uff0c\u5c06\u6a21\u578b\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u5b50\u7a7a\u95f4\uff1a\u72ec\u7279\u4e13\u5bb6\u9694\u79bb\u4efb\u52a1\u7279\u5b9a\u6a21\u5f0f\uff0c\u5171\u4eab\u4e13\u5bb6\u6355\u83b7\u901a\u7528\u7279\u5f81\u3002\u901a\u8fc7\u5f39\u6027\u6743\u91cd\u951a\u5b9a\u4fdd\u62a4\u5173\u952e\u5171\u4eab\u77e5\u8bc6\uff0c\u5e76\u4f7f\u7528\u7edf\u4e00\u95e8\u63a7\u7f51\u7edc\u5728\u63a8\u7406\u65f6\u81ea\u52a8\u68c0\u7d22\u6b63\u786e\u7684\u4e13\u5bb6\u7ec4\u5408\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u9886\u57df\u7279\u5b9a\u548c\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSETA\u6301\u7eed\u4f18\u4e8e\u57fa\u4e8e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u6700\u5148\u8fdb\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "SETA\u901a\u8fc7\u6a21\u5757\u5316\u4e13\u5bb6\u5206\u89e3\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u53ef\u5851\u6027-\u7a33\u5b9a\u6027\u56f0\u5883\uff0c\u5b9e\u73b0\u4e86\u4efb\u52a1\u65e0\u5173\u7684\u6301\u7eed\u5b66\u4e60\uff0c\u5728\u4fdd\u62a4\u5148\u524d\u77e5\u8bc6\u7684\u540c\u65f6\u9ad8\u6548\u5b66\u4e60\u65b0\u4efb\u52a1\u3002"}}
{"id": "2601.17625", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17625", "abs": "https://arxiv.org/abs/2601.17625", "authors": ["Yuhan Xie", "Jinhan Liu", "Xiaoyong Ni", "Fei Tan", "Icare Sakr", "Thibault Collin", "Shiqi Sun", "Alejandro Rodriguez Guajardo", "Demon Fanny", "Charles-francois Vincent Latchoumane", "Henri Lorach", "Jocelyne Bloch", "Gregoire Courtine", "Mahsa Shoaran"], "title": "BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation", "comment": "21 pages,7 figures", "summary": "Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.", "AI": {"tldr": "BrainDistill\uff1a\u4e00\u79cd\u7528\u4e8e\u690d\u5165\u5f0fBCI\u7684\u65b0\u578b\u8fd0\u52a8\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u84b8\u998f\u548c\u91cf\u5316\u8bad\u7ec3\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42", "motivation": "Transformer\u89e3\u7801\u5668\u5728BCI\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u53c2\u6570\u591a\u3001\u8ba1\u7b97\u9700\u6c42\u5927\uff0c\u96be\u4ee5\u90e8\u7f72\u5728\u529f\u8017\u53d7\u9650\u7684\u690d\u5165\u5f0f\u7cfb\u7edf\u4e2d\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\u53c8\u9002\u5408\u690d\u5165\u5f0f\u8bbe\u5907\u7ea6\u675f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faBrainDistill\u6846\u67b6\uff0c\u5305\u542b\u690d\u5165\u5f0f\u795e\u7ecf\u89e3\u7801\u5668\uff08IND\uff09\u548c\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u84b8\u998f\uff08TSKD\uff09\u6846\u67b6\u3002TSKD\u901a\u8fc7\u76d1\u7763\u6295\u5f71\u4f18\u5148\u4fdd\u7559\u89e3\u7801\u5173\u952e\u7279\u5f81\uff0c\u4e0d\u540c\u4e8e\u6807\u51c6\u7279\u5f81\u84b8\u998f\u65b9\u6cd5\u3002\u8fd8\u63d0\u51fa\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u65b9\u6848\uff0c\u652f\u6301\u4ec5\u6574\u6570\u63a8\u7406\u3002", "result": "IND\u5728\u591a\u4e2a\u795e\u7ecf\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u795e\u7ecf\u89e3\u7801\u5668\uff1bTSKD\u84b8\u998f\u53d8\u4f53\u5728\u5c11\u6837\u672c\u6821\u51c6\u8bbe\u7f6e\u4e2d\u8d85\u8d8a\u5176\u4ed6\u84b8\u998f\u65b9\u6cd5\uff1b\u91cf\u5316IND\u80fd\u5728\u690d\u5165\u5f0fBCI\u4e25\u683c\u529f\u8017\u7ea6\u675f\u4e0b\u90e8\u7f72\uff0c\u6027\u80fd\u635f\u5931\u6700\u5c0f\u3002", "conclusion": "BrainDistill\u4e3a\u690d\u5165\u5f0fBCI\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8fd0\u52a8\u89e3\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u91cf\u5316\u6280\u672f\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u529f\u8017\u9700\u6c42\uff0c\u6709\u671b\u63a8\u52a8\u690d\u5165\u5f0f\u8111\u673a\u63a5\u53e3\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.17641", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.17641", "abs": "https://arxiv.org/abs/2601.17641", "authors": ["Hao Fang", "Ryan A. Canfield", "Tomohiro Ouchi", "Beatrice Macagno", "Eli Shlizerman", "Amy L. Orsborn"], "title": "RPNT: Robust Pre-trained Neural Transformer -- A Pathway for Generalized Motor Decoding", "comment": null, "summary": "Brain decoding aims to interpret and translate neural activity into behaviors. As such, it is imperative that decoding models are able to generalize across variations, such as recordings from different brain sites, distinct sessions, different types of behavior, and a variety of subjects. Current models can only partially address these challenges and warrant the development of pretrained neural transformer models capable to adapt and generalize. In this work, we propose RPNT - Robust Pretrained Neural Transformer, designed to achieve robust generalization through pretraining, which in turn enables effective finetuning given a downstream task. In particular, RPNT unique components include 1) Multidimensional rotary positional embedding (MRoPE) to aggregate experimental metadata such as site coordinates, session name and behavior types; 2) Context-based attention mechanism via convolution kernels operating on global attention to learn local temporal structures for handling non-stationarity of neural population activity; 3) Robust self-supervised learning (SSL) objective with uniform causal masking strategies and contrastive representations. We pretrained two separate versions of RPNT on distinct datasets a) Multi-session, multi-task, and multi-subject microelectrode benchmark; b) Multi-site recordings using high-density Neuropixel 1.0 probes. The datasets include recordings from the dorsal premotor cortex (PMd) and from the primary motor cortex (M1) regions of nonhuman primates (NHPs) as they performed reaching tasks. After pretraining, we evaluated the generalization of RPNT in cross-session, cross-type, cross-subject, and cross-site downstream behavior decoding tasks. Our results show that RPNT consistently achieves and surpasses the decoding performance of existing decoding models in all tasks.", "AI": {"tldr": "RPNT\u662f\u4e00\u79cd\u9c81\u68d2\u7684\u9884\u8bad\u7ec3\u795e\u7ecfTransformer\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u7ef4\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\u3001\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u9c81\u68d2\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\uff0c\u5b9e\u73b0\u4e86\u8de8\u4f1a\u8bdd\u3001\u8de8\u7c7b\u578b\u3001\u8de8\u88ab\u8bd5\u548c\u8de8\u8111\u533a\u7684\u795e\u7ecf\u89e3\u7801\u6cdb\u5316\u3002", "motivation": "\u8111\u89e3\u7801\u9700\u8981\u6a21\u578b\u80fd\u591f\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u8111\u533a\u8bb0\u5f55\u3001\u4e0d\u540c\u4f1a\u8bdd\u3001\u4e0d\u540c\u884c\u4e3a\u7c7b\u578b\u548c\u4e0d\u540c\u88ab\u8bd5\u3002\u73b0\u6709\u6a21\u578b\u53ea\u80fd\u90e8\u5206\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u548c\u6cdb\u5316\u7684\u9884\u8bad\u7ec3\u795e\u7ecfTransformer\u6a21\u578b\u3002", "method": "\u63d0\u51faRPNT\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u591a\u7ef4\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165(MRoPE)\u805a\u5408\u5b9e\u9a8c\u5143\u6570\u636e\uff1b2) \u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u6ce8\u610f\u529b\u673a\u5236\u901a\u8fc7\u5377\u79ef\u6838\u5904\u7406\u5168\u5c40\u6ce8\u610f\u529b\u4ee5\u5b66\u4e60\u5c40\u90e8\u65f6\u95f4\u7ed3\u6784\uff1b3) \u9c81\u68d2\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\uff0c\u91c7\u7528\u5747\u5300\u56e0\u679c\u63a9\u7801\u7b56\u7565\u548c\u5bf9\u6bd4\u8868\u793a\u3002\u5728\u4e24\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\uff1a\u591a\u4f1a\u8bdd\u591a\u4efb\u52a1\u591a\u88ab\u8bd5\u5fae\u7535\u6781\u57fa\u51c6\u6570\u636e\u96c6\u548cNeuropixel 1.0\u63a2\u9488\u7684\u591a\u8111\u533a\u8bb0\u5f55\u6570\u636e\u96c6\u3002", "result": "RPNT\u5728\u8de8\u4f1a\u8bdd\u3001\u8de8\u7c7b\u578b\u3001\u8de8\u88ab\u8bd5\u548c\u8de8\u8111\u533a\u7684\u4e0b\u6e38\u884c\u4e3a\u89e3\u7801\u4efb\u52a1\u4e2d\uff0c\u59cb\u7ec8\u8fbe\u5230\u5e76\u8d85\u8d8a\u4e86\u73b0\u6709\u89e3\u7801\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "RPNT\u901a\u8fc7\u521b\u65b0\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u8111\u89e3\u7801\u6a21\u578b\u7684\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u795e\u7ecf\u6d3b\u52a8\u5230\u884c\u4e3a\u7684\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2601.17646", "categories": ["cs.LG", "math.FA", "math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.17646", "abs": "https://arxiv.org/abs/2601.17646", "authors": ["Karim Bounja", "Lahcen Laayouni", "Abdeljalil Sakat"], "title": "A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization", "comment": null, "summary": "Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlev\u00e9-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff08ERM\uff09\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u975e\u4e25\u683c\u51f8\u635f\u5931\u51fd\u6570\u5bfc\u81f4\u96c6\u503c\u6700\u5c0f\u5316\u5668\u7684\u60c5\u51b5\u3002\u4f5c\u8005\u63d0\u51faPainlev\u00e9-Kuratowski\u4e0a\u534a\u8fde\u7eed\u6027\u4f5c\u4e3aERM\u89e3\u5bf9\u5e94\u7684\u5185\u5728\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u5e76\u5efa\u7acb\u4e86\u5728Mosco\u4e00\u81f4\u6270\u52a8\u548c\u5c40\u90e8\u6709\u754c\u6700\u5c0f\u5316\u5668\u6761\u4ef6\u4e0b\u7684\u7a33\u5b9a\u6027\u7406\u8bba\u3002", "motivation": "\u4f20\u7edfERM\u7a33\u5b9a\u6027\u7814\u7a76\u901a\u5e38\u9488\u5bf9\u5355\u503c\u8f93\u51fa\uff0c\u4f46\u5b9e\u9645\u4e2d\u51f8\u975e\u4e25\u683c\u635f\u5931\u51fd\u6570\u4f1a\u4ea7\u751f\u96c6\u503c\u6700\u5c0f\u5316\u5668\u3002\u73b0\u6709\u7a33\u5b9a\u6027\u7406\u8bba\u65e0\u6cd5\u5145\u5206\u5904\u7406\u8fd9\u79cd\u96c6\u503c\u60c5\u51b5\uff0c\u9700\u8981\u5efa\u7acb\u66f4\u5408\u9002\u7684\u7a33\u5b9a\u6027\u6846\u67b6\u6765\u7406\u89e3ERM\u89e3\u5bf9\u5e94\u7684\u884c\u4e3a\u3002", "method": "\u91c7\u7528Painlev\u00e9-Kuratowski\u4e0a\u534a\u8fde\u7eed\u6027\u4f5c\u4e3aERM\u89e3\u5bf9\u5e94\u7684\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u7814\u7a76\u5728Mosco\u4e00\u81f4\u6270\u52a8\u548c\u5c40\u90e8\u6709\u754c\u6700\u5c0f\u5316\u5668\u6761\u4ef6\u4e0b\u7684\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u96c6\u503c\u5206\u6790\u5de5\u5177\uff0c\u5efa\u7acb\u4e86\u5b9a\u6027\u7a33\u5b9a\u6027\u7ed3\u679c\uff0c\u5e76\u5728\u4e8c\u6b21\u589e\u957f\u6761\u4ef6\u4e0b\u63a8\u5bfc\u51fa\u5b9a\u91cf\u504f\u5dee\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u5728Mosco\u4e00\u81f4\u6270\u52a8\u548c\u5c40\u90e8\u6709\u754c\u6700\u5c0f\u5316\u5668\u6761\u4ef6\u4e0b\uff0cERM\u89e3\u5bf9\u5e94\u5177\u6709Painlev\u00e9-Kuratowski\u4e0a\u534a\u8fde\u7eed\u6027\u3001\u6700\u5c0f\u503c\u8fde\u7eed\u6027\u548c\u6d88\u5931\u95f4\u9699\u8fd1\u6700\u5c0f\u5316\u5668\u7684\u4e00\u81f4\u6027\u3002\u4e8c\u6b21\u589e\u957f\u6761\u4ef6\u8fdb\u4e00\u6b65\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u5b9a\u91cf\u504f\u5dee\u754c\u3002", "conclusion": "Painlev\u00e9-Kuratowski\u4e0a\u534a\u8fde\u7eed\u6027\u662fERM\u89e3\u5bf9\u5e94\u7684\u5185\u5728\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u4e3a\u7406\u89e3\u96c6\u503c\u6700\u5c0f\u5316\u5668\u7684\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u5408\u9002\u6846\u67b6\u3002\u5728\u9002\u5f53\u7684\u6270\u52a8\u6761\u4ef6\u4e0b\uff0cERM\u8868\u73b0\u51fa\u826f\u597d\u7684\u7a33\u5b9a\u6027\u7279\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7a33\u5b9a\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.17647", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17647", "abs": "https://arxiv.org/abs/2601.17647", "authors": ["Akila Sampath", "Vandana Janeja", "Jianwu Wang"], "title": "Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics", "comment": null, "summary": "Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\\% reduction in estimation error.", "AI": {"tldr": "\u63d0\u51faKGCM-VAE\u6a21\u578b\uff0c\u901a\u8fc7\u77e5\u8bc6\u5f15\u5bfc\u7684\u56e0\u679c\u5efa\u6a21\u91cf\u5316\u6d77\u51b0\u539a\u5ea6\u4e0e\u6d77\u9762\u9ad8\u5ea6\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u548c\u5206\u5e03\u5e73\u8861\u673a\u5236\u63d0\u5347\u5904\u7406\u6548\u679c\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u91cf\u5316\u51b0\u878d\u5316\u548c\u6de1\u6c34\u5206\u5e03\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u5bf9\u7406\u89e3\u6781\u5730\u6c14\u5019\u53d8\u5316\u548c\u5168\u7403\u6d77\u5e73\u9762\u4e0a\u5347\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u65f6\u7a7a\u8bbe\u7f6e\u4e2d\u7531\u4e8e\u672a\u89c2\u6d4b\u7684\u6df7\u6742\u56e0\u7d20\u548c\u7f3a\u4e4f\u7269\u7406\u7ea6\u675f\uff0c\u96be\u4ee5\u53ef\u9760\u4f30\u8ba1\u5904\u7406\u6548\u679c\u3002", "method": "\u63d0\u51fa\u77e5\u8bc6\u5f15\u5bfc\u7684\u56e0\u679c\u6a21\u578b\u53d8\u5206\u81ea\u7f16\u7801\u5668(KGCM-VAE)\uff1a1) \u5f15\u5165\u901f\u5ea6\u8c03\u5236\u65b9\u6848\uff0c\u901a\u8fc7SSH\u8f6c\u6362\u63a7\u5236\u7684sigmoid\u51fd\u6570\u52a8\u6001\u653e\u5927\u5e73\u6ed1\u901f\u5ea6\u4fe1\u53f7\uff0c\u751f\u6210\u7269\u7406\u57fa\u7840\u7684\u56e0\u679c\u5904\u7406\uff1b2) \u4f7f\u7528\u6700\u5927\u5747\u503c\u5dee\u5f02(MMD)\u5728\u6f5c\u5728\u7a7a\u95f4\u5e73\u8861\u5904\u7406\u548c\u5bf9\u7167\u534f\u53d8\u91cf\u5206\u5e03\uff1b3) \u91c7\u7528\u56e0\u679c\u90bb\u63a5\u7ea6\u675f\u89e3\u7801\u5668\u786e\u4fdd\u4e0e\u5df2\u77e5\u7269\u7406\u7ed3\u6784\u5bf9\u9f50\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u5317\u6781\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cKGCM-VAE\u5728PEHE\u6307\u6807\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u51c6\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9eMMD\u548c\u56e0\u679c\u90bb\u63a5\u7ea6\u675f\u7684\u8054\u5408\u5e94\u7528\u4f7f\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e1.88%\u3002", "conclusion": "KGCM-VAE\u901a\u8fc7\u6574\u5408\u7269\u7406\u77e5\u8bc6\u548c\u56e0\u679c\u7ea6\u675f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u7a7a\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u6df7\u6742\u95ee\u9898\uff0c\u4e3a\u91cf\u5316\u6d77\u51b0\u539a\u5ea6\u4e0e\u6d77\u9762\u9ad8\u5ea6\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u63d0\u4f9b\u4e86\u53ef\u9760\u6846\u67b6\u3002"}}
{"id": "2601.17667", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17667", "abs": "https://arxiv.org/abs/2601.17667", "authors": ["Pedro P. Santos", "Jacopo Silvestrin", "Alberto Sardinha", "Francisco S. Melo"], "title": "Entropic Risk-Aware Monte Carlo Tree Search", "comment": null, "summary": "We propose a provably correct Monte Carlo tree search (MCTS) algorithm for solving \\textit{risk-aware} Markov decision processes (MDPs) with \\textit{entropic risk measure} (ERM) objectives. We provide a \\textit{non-asymptotic} analysis of our proposed algorithm, showing that the algorithm: (i) is \\textit{correct} in the sense that the empirical ERM obtained at the root node converges to the optimal ERM; and (ii) enjoys \\textit{polynomial regret concentration}. Our algorithm successfully exploits the dynamic programming formulations for solving risk-aware MDPs with ERM objectives introduced by previous works in the context of an upper confidence bound-based tree search algorithm. Finally, we provide a set of illustrative experiments comparing our risk-aware MCTS method against relevant baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5177\u6709\u71b5\u98ce\u9669\u5ea6\u91cf\u7684\u98ce\u9669\u611f\u77e5\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u63d0\u4f9b\u975e\u6e10\u8fd1\u5206\u6790\u8bc1\u660e\u5176\u6b63\u786e\u6027\u548c\u591a\u9879\u5f0f\u9057\u61be\u96c6\u4e2d\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u71b5\u98ce\u9669\u5ea6\u91cf\u7684\u98ce\u9669\u611f\u77e5MDPs\u65f6\u7f3a\u4e4f\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u8bc1\u7406\u8bba\u6b63\u786e\u6027\u53c8\u5177\u6709\u5b9e\u9645\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7f6e\u4fe1\u4e0a\u754c\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\uff0c\u5229\u7528\u5148\u524d\u5de5\u4f5c\u4e2d\u5f15\u5165\u7684\u71b5\u98ce\u9669\u5ea6\u91cfMDPs\u52a8\u6001\u89c4\u5212\u516c\u5f0f\uff0c\u5728\u6811\u641c\u7d22\u6846\u67b6\u4e2d\u5b9e\u73b0\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u3002", "result": "\u7b97\u6cd5\u5177\u6709\u7406\u8bba\u6b63\u786e\u6027\uff08\u6839\u8282\u70b9\u7ecf\u9a8cERM\u6536\u655b\u5230\u6700\u4f18ERM\uff09\u548c\u591a\u9879\u5f0f\u9057\u61be\u96c6\u4e2d\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u98ce\u9669\u611f\u77e5MCTS\u65b9\u6cd5\u4f18\u4e8e\u76f8\u5173\u57fa\u7ebf\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u9996\u4e2a\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u98ce\u9669\u611f\u77e5MCTS\u7b97\u6cd5\uff0c\u4e3a\u71b5\u98ce\u9669\u5ea6\u91cfMDPs\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2601.17668", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17668", "abs": "https://arxiv.org/abs/2601.17668", "authors": ["Jang-Hyun Kim", "Dongyoon Han", "Sangdoo Yun"], "title": "Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction", "comment": null, "summary": "Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u95e8\u63a7\u7684KV\u7f13\u5b58\u9a71\u9010\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7sink-attention\u95e8\u63a7\u6a21\u5757\u8bc6\u522b\u5173\u952eKV\u5bf9\uff0c\u5b9e\u73b0\u9ad8\u8fbe70%\u7684KV\u7f13\u5b58\u538b\u7f29\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u538b\u7f29\u6280\u672f\u901a\u5e38\u5728\u6027\u80fd\u4e0b\u964d\u548c\u8ba1\u7b97\u5f00\u9500\u4e4b\u95f4\u9700\u8981\u6743\u8861\uff0c\u8fd9\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u6548\u7387\u3002", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7sink-attention\u95e8\u63a7\u6a21\u5757\u6765\u8bc6\u522b\u548c\u4fdd\u7559\u5173\u952eKV\u5bf9\uff0c\u63d0\u51fa\u4ec5\u4f9d\u8d56\u524d\u5411\u4f20\u64ad\u7684\u95e8\u8bad\u7ec3\u7b97\u6cd5\uff0c\u4f7f\u7528\u4efb\u52a1\u65e0\u5173\u7684\u91cd\u5efa\u76ee\u6807\u5b9e\u73b0\u5f3a\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728Qwen2.5-1M\u3001Qwen3\u548cGemma3\u7cfb\u5217\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9a71\u9010\u9ad8\u8fbe70%\u7684KV\u7f13\u5b58\u65f6\u4ecd\u80fd\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7684\u6027\u80fd\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u3001\u4ee3\u7801\u7406\u89e3\u548c\u6570\u5b66\u63a8\u7406\u7b49\u591a\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u4e00\u81f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u51bb\u7ed3\u6743\u91cd\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684KV\u7f13\u5b58\u7ba1\u7406\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.17680", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17680", "abs": "https://arxiv.org/abs/2601.17680", "authors": ["Shota Takashiro", "Takeshi Kojima", "Shohei Taniguchi", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "$\\infty$-MoE: Generalizing Mixture of Experts to Infinite Experts", "comment": "Accepted at EACL 2026 (Main)", "summary": "The Mixture of Experts (MoE) selects a few feed-forward networks (FFNs) per token, achieving an effective trade-off between computational cost and performance. In conventional MoE, each expert is treated as entirely independent, and experts are combined in a discrete space. As a result, when the number of experts increases, it becomes difficult to train each expert effectively. To stabilize training while increasing the number of experts, we propose $\\infty$-MoE that selects a portion of the parameters of large FFNs based on continuous values sampled for each token. By considering experts in a continuous space, this approach allows for an infinite number of experts while maintaining computational efficiency. Experiments show that a GPT-2 Small-based $\\infty$-MoE model, with 129M active and 186M total parameters, achieves comparable performance to a dense GPT-2 Medium with 350M parameters. Adjusting the number of sampled experts at inference time allows for a flexible trade-off between accuracy and speed, with an improvement of up to 2.5\\% in accuracy over conventional MoE.", "AI": {"tldr": "\u221e-MoE\uff1a\u901a\u8fc7\u8fde\u7eed\u7a7a\u95f4\u9009\u62e9\u5927\u578b\u524d\u9988\u7f51\u7edc\u7684\u90e8\u5206\u53c2\u6570\uff0c\u5b9e\u73b0\u65e0\u9650\u4e13\u5bb6\u6570\u91cf\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u63a8\u7406\u65f6\u53ef\u7075\u6d3b\u8c03\u6574\u7cbe\u5ea6\u4e0e\u901f\u5ea6\u7684\u6743\u8861", "motivation": "\u4f20\u7edfMoE\u5c06\u6bcf\u4e2a\u4e13\u5bb6\u89c6\u4e3a\u5b8c\u5168\u72ec\u7acb\u5e76\u5728\u79bb\u6563\u7a7a\u95f4\u7ec4\u5408\uff0c\u5f53\u4e13\u5bb6\u6570\u91cf\u589e\u52a0\u65f6\u96be\u4ee5\u6709\u6548\u8bad\u7ec3\u6bcf\u4e2a\u4e13\u5bb6\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u589e\u52a0\u4e13\u5bb6\u6570\u91cf\u7684\u540c\u65f6\u7a33\u5b9a\u8bad\u7ec3", "method": "\u63d0\u51fa\u221e-MoE\uff0c\u57fa\u4e8e\u6bcf\u4e2atoken\u91c7\u6837\u7684\u8fde\u7eed\u503c\u9009\u62e9\u5927\u578b\u524d\u9988\u7f51\u7edc\u7684\u90e8\u5206\u53c2\u6570\u3002\u901a\u8fc7\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u8003\u8651\u4e13\u5bb6\uff0c\u5141\u8bb8\u65e0\u9650\u6570\u91cf\u7684\u4e13\u5bb6\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387", "result": "\u57fa\u4e8eGPT-2 Small\u7684\u221e-MoE\u6a21\u578b\uff081.29\u4ebf\u6d3b\u8dc3\u53c2\u6570\uff0c1.86\u4ebf\u603b\u53c2\u6570\uff09\u8fbe\u5230\u4e0e3.5\u4ebf\u53c2\u6570\u7684\u5bc6\u96c6GPT-2 Medium\u76f8\u5f53\u7684\u6027\u80fd\u3002\u63a8\u7406\u65f6\u8c03\u6574\u91c7\u6837\u4e13\u5bb6\u6570\u91cf\u53ef\u5728\u7cbe\u5ea6\u4e0e\u901f\u5ea6\u95f4\u7075\u6d3b\u6743\u8861\uff0c\u6bd4\u4f20\u7edfMoE\u7cbe\u5ea6\u63d0\u5347\u8fbe2.5%", "conclusion": "\u221e-MoE\u901a\u8fc7\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u9009\u62e9\u53c2\u6570\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMoE\u5728\u589e\u52a0\u4e13\u5bb6\u6570\u91cf\u65f6\u7684\u8bad\u7ec3\u56f0\u96be\uff0c\u5b9e\u73b0\u4e86\u65e0\u9650\u4e13\u5bb6\u6269\u5c55\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u63d0\u4f9b\u4e86\u7cbe\u5ea6\u4e0e\u901f\u5ea6\u7684\u7075\u6d3b\u6743\u8861"}}
{"id": "2601.17687", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17687", "abs": "https://arxiv.org/abs/2601.17687", "authors": ["Hao Li", "He Cao", "Shenyao Peng", "Zijing Liu", "Bin Feng", "Yu Wang", "Zhiyuan Yan", "Yonghong Tian", "Yu Li", "Li Yuan"], "title": "Agentic reinforcement learning empowers next-generation chemical language models for molecular design and synthesis", "comment": "Working in Progress, 13 pages, 4 figures", "summary": "Language models are revolutionizing the biochemistry domain, assisting scientists in drug design and chemical synthesis with high efficiency. Yet current approaches struggle between small language models prone to hallucination and limited knowledge retention, and large cloud-based language models plagued by privacy risks and high inference costs. To bridge this gap, we introduce ChemCRAFT, a novel framework leveraging agentic reinforcement learning to decouple chemical reasoning from knowledge storage. Instead of forcing the model to memorize vast chemical data, our approach empowers the language model to interact with a sandbox for precise information retrieval. This externalization of knowledge allows a locally deployable small model to achieve superior performance with minimal inference costs. To enable small language models for agent-calling ability, we build an agentic trajectory construction pipeline and a comprehensive chemical-agent sandbox. Based on sandbox interactions, we constructed ChemToolDataset, the first large-scale chemical tool trajectory dataset. Simultaneously, we propose SMILES-GRPO to build a dense chemical reward function, promoting the model's ability to call chemical agents. Evaluations across diverse aspects of drug design show that ChemCRAFT outperforms current cloud-based LLMs in molecular structure analysis, molecular optimization, and synthesis pathway prediction, demonstrating that scientific reasoning is not solely an emergent ability of model scale, but a learnable policy of tool orchestration. This work establishes a cost-effective and privacy-preserving paradigm for AI-aided chemistry, opening new avenues for accelerating molecular discovery with locally deployable agents.", "AI": {"tldr": "ChemCRAFT\u662f\u4e00\u4e2a\u5229\u7528\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5c06\u5316\u5b66\u63a8\u7406\u4e0e\u77e5\u8bc6\u5b58\u50a8\u89e3\u8026\u7684\u6846\u67b6\uff0c\u4f7f\u672c\u5730\u53ef\u90e8\u7f72\u7684\u5c0f\u6a21\u578b\u901a\u8fc7\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u5927\u6a21\u578b\u9690\u79c1\u98ce\u9669\u548c\u5c0f\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u751f\u5316\u9886\u57df\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u4e24\u96be\uff1a\u5c0f\u6a21\u578b\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u4e14\u77e5\u8bc6\u6709\u9650\uff0c\u800c\u5927\u4e91\u6a21\u578b\u5b58\u5728\u9690\u79c1\u98ce\u9669\u548c\u9ad8\u63a8\u7406\u6210\u672c\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u6784\u5efa\u667a\u80fd\u4f53\u8f68\u8ff9\u6784\u5efa\u7ba1\u9053\u548c\u5316\u5b66\u667a\u80fd\u4f53\u6c99\u7bb1\uff1b2) \u521b\u5efaChemToolDataset\u5927\u89c4\u6a21\u5316\u5b66\u5de5\u5177\u8f68\u8ff9\u6570\u636e\u96c6\uff1b3) \u63d0\u51faSMILES-GRPO\u6784\u5efa\u5bc6\u96c6\u5316\u5b66\u5956\u52b1\u51fd\u6570\uff1b4) \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5c0f\u6a21\u578b\u8c03\u7528\u5316\u5b66\u667a\u80fd\u4f53\u3002", "result": "ChemCRAFT\u5728\u836f\u7269\u8bbe\u8ba1\u7684\u591a\u4e2a\u65b9\u9762\uff08\u5206\u5b50\u7ed3\u6784\u5206\u6790\u3001\u5206\u5b50\u4f18\u5316\u3001\u5408\u6210\u8def\u5f84\u9884\u6d4b\uff09\u5747\u4f18\u4e8e\u5f53\u524d\u57fa\u4e8e\u4e91\u7684LLMs\uff0c\u8bc1\u660e\u79d1\u5b66\u63a8\u7406\u4e0d\u662f\u6a21\u578b\u89c4\u6a21\u7684\u6d8c\u73b0\u80fd\u529b\uff0c\u800c\u662f\u53ef\u5b66\u4e60\u7684\u5de5\u5177\u7f16\u6392\u7b56\u7565\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u4fdd\u62a4\u9690\u79c1\u7684AI\u8f85\u52a9\u5316\u5b66\u8303\u5f0f\uff0c\u4e3a\u4f7f\u7528\u672c\u5730\u53ef\u90e8\u7f72\u667a\u80fd\u4f53\u52a0\u901f\u5206\u5b50\u53d1\u73b0\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.17689", "categories": ["cs.LG", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.17689", "abs": "https://arxiv.org/abs/2601.17689", "authors": ["Shanu Saklani", "Tushar M. Athawale", "Nairita Pal", "David Pugmire", "Christopher R. Johnson", "Soumya Dutta"], "title": "REV-INR: Regularized Evidential Implicit Neural Representation for Uncertainty-Aware Volume Visualization", "comment": null, "summary": "Applications of Implicit Neural Representations (INRs) have emerged as a promising deep learning approach for compactly representing large volumetric datasets. These models can act as surrogates for volume data, enabling efficient storage and on-demand reconstruction via model predictions. However, conventional deterministic INRs only provide value predictions without insights into the model's prediction uncertainty or the impact of inherent noisiness in the data. This limitation can lead to unreliable data interpretation and visualization due to prediction inaccuracies in the reconstructed volume. Identifying erroneous results extracted from model-predicted data may be infeasible, as raw data may be unavailable due to its large size. To address this challenge, we introduce REV-INR, Regularized Evidential Implicit Neural Representation, which learns to predict data values accurately along with the associated coordinate-level data uncertainty and model uncertainty using only a single forward pass of the trained REV-INR during inference. By comprehensively comparing and contrasting REV-INR with existing well-established deep uncertainty estimation methods, we show that REV-INR achieves the best volume reconstruction quality with robust data (aleatoric) and model (epistemic) uncertainty estimates using the fastest inference time. Consequently, we demonstrate that REV-INR facilitates assessment of the reliability and trustworthiness of the extracted isosurfaces and volume visualization results, enabling analyses to be solely driven by model-predicted data.", "AI": {"tldr": "REV-INR\u63d0\u51fa\u4e86\u4e00\u79cd\u6b63\u5219\u5316\u8bc1\u636e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u9884\u6d4b\u6570\u636e\u503c\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u89e3\u51b3\u4f20\u7edfINR\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4f53\u79ef\u91cd\u5efa\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u786e\u5b9a\u6027\u9690\u5f0f\u795e\u7ecf\u8868\u793a(INR)\u53ea\u80fd\u9884\u6d4b\u6570\u503c\uff0c\u65e0\u6cd5\u63d0\u4f9b\u6a21\u578b\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6216\u6570\u636e\u56fa\u6709\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4e0d\u53ef\u9760\u7684\u6570\u636e\u89e3\u91ca\u548c\u53ef\u89c6\u5316\u3002\u7531\u4e8e\u539f\u59cb\u6570\u636e\u53ef\u80fd\u56e0\u4f53\u79ef\u8fc7\u5927\u800c\u65e0\u6cd5\u83b7\u53d6\uff0c\u8bc6\u522b\u6a21\u578b\u9884\u6d4b\u6570\u636e\u4e2d\u7684\u9519\u8bef\u7ed3\u679c\u53ef\u80fd\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51faREV-INR\uff08\u6b63\u5219\u5316\u8bc1\u636e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff09\uff0c\u901a\u8fc7\u5355\u6b21\u524d\u5411\u4f20\u64ad\u540c\u65f6\u5b66\u4e60\u51c6\u786e\u9884\u6d4b\u6570\u636e\u503c\u4ee5\u53ca\u76f8\u5173\u7684\u5750\u6807\u7ea7\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u7efc\u5408\u6bd4\u8f83\u4e86\u73b0\u6709\u7684\u6df1\u5ea6\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "REV-INR\u5b9e\u73b0\u4e86\u6700\u4f73\u7684\u4f53\u79ef\u91cd\u5efa\u8d28\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u9c81\u68d2\u7684\u6570\u636e\uff08\u5076\u7136\u6027\uff09\u548c\u6a21\u578b\uff08\u8ba4\u77e5\u6027\uff09\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e14\u5177\u6709\u6700\u5feb\u7684\u63a8\u7406\u65f6\u95f4\u3002\u80fd\u591f\u8bc4\u4f30\u63d0\u53d6\u7684\u7b49\u503c\u9762\u548c\u4f53\u79ef\u53ef\u89c6\u5316\u7ed3\u679c\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "conclusion": "REV-INR\u80fd\u591f\u4fc3\u8fdb\u5bf9\u63d0\u53d6\u7684\u7b49\u503c\u9762\u548c\u4f53\u79ef\u53ef\u89c6\u5316\u7ed3\u679c\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u8bc4\u4f30\uff0c\u4f7f\u5f97\u5206\u6790\u53ef\u4ee5\u5b8c\u5168\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u7684\u6570\u636e\u8fdb\u884c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfINR\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.17713", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17713", "abs": "https://arxiv.org/abs/2601.17713", "authors": ["Kaile Wang", "Jiannong Cao", "Yu Yang", "Xiaoyin Li", "Yinfeng Cao"], "title": "FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices", "comment": "Accepted by IEEE Annual Congress on Artificial Intelligence of Things (IEEE AIoT) 2025", "summary": "With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.", "AI": {"tldr": "FedCCA\u662f\u4e00\u79cd\u9762\u5411\u5f02\u6784\u7269\u8054\u7f51\u6570\u636e\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u4e2d\u5fc3\u5316\u81ea\u9002\u5e94\u673a\u5236\uff0c\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u5b66\u4e60\u72ec\u7279\u6a21\u578b\u4ee5\u89e3\u51b3\u6570\u636e\u5f02\u8d28\u6027\u95ee\u9898\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u4e0a\u7684\u79c1\u6709\u6570\u636e\uff08\u5982\u4eba\u4f53\u611f\u77e5\u6570\u636e\uff09\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u7684AI\u6a21\u578b\u8bad\u7ec3\u3002\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u7269\u8054\u7f51\u8bbe\u5907\u95f4\u7684\u6570\u636e\u5f02\u8d28\u6027\u4f1a\u663e\u8457\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u548c\u6536\u655b\u901f\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u56fa\u5b9a\u5ba2\u6237\u7aef\u9009\u62e9\u548c\u4e91\u7aef\u805a\u5408\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u96be\u4ee5\u5728\u672c\u5730\u8bad\u7ec3\u4e2d\u63d0\u53d6\u5ba2\u6237\u7aef\u7279\u5b9a\u4fe1\u606f\u3002", "method": "\u63d0\u51faFedCCA\u7b97\u6cd5\uff1a1\uff09\u91c7\u7528\u52a8\u6001\u5ba2\u6237\u7aef\u9009\u62e9\uff1b2\uff09\u57fa\u4e8e\u989d\u5916\u7684\u5ba2\u6237\u7aef\u7279\u5b9a\u7f16\u7801\u5668\u8fdb\u884c\u81ea\u9002\u5e94\u805a\u5408\uff1b3\uff09\u4f7f\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5168\u5c40\u805a\u5408\u7b56\u7565\u6765\u589e\u5f3a\u591a\u6e90\u77e5\u8bc6\u8f6c\u79fb\uff1b4\uff09\u901a\u8fc7\u9009\u62e9\u6027\u9002\u5e94\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u5b66\u4e60\u72ec\u7279\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFedCCA\u5728\u5904\u7406\u6570\u636e\u5f02\u8d28\u6027\u95ee\u9898\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "FedCCA\u901a\u8fc7\u5ba2\u6237\u7aef\u4e2d\u5fc3\u5316\u81ea\u9002\u5e94\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7269\u8054\u7f51\u6570\u636e\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5229\u7528\u5ba2\u6237\u7aef\u7279\u5b9a\u77e5\u8bc6\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2601.17716", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17716", "abs": "https://arxiv.org/abs/2601.17716", "authors": ["Daniel M. Pedrozo", "Telma W. de L. Soares", "Bryan L. M. de Oliveira"], "title": "Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games", "comment": "Presented at the NeusymBridge Workshop at AAAI 2026", "summary": "Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u591a\u8f6e\u5bf9\u8bdd\u6846\u67b6\uff0c\u901a\u8fc7\u662f/\u5426\u95ee\u9898\u5728\u5c42\u6b21\u77e5\u8bc6\u56fe\u8c31\u73af\u5883\u4e2d\u5b9a\u91cf\u8bc4\u4f30LLMs\u6536\u96c6\u4fe1\u606f\u7684\u6548\u679c\uff0c\u4f7f\u7528\u4fe1\u606f\u589e\u76ca\u4f5c\u4e3a\u4e3b\u8981\u6307\u6807\uff0c\u5e76\u5728\u5730\u7406\u731c\u57ce\u5e02\u6e38\u620f\u4e2d\u9a8c\u8bc1\u4e86\u5177\u6709\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\u3002", "motivation": "LLMs\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728LLM\u667a\u80fd\u4f53\u7684\u5173\u952e\u80fd\u529b\u2014\u2014\u901a\u8fc7\u63d0\u95ee\u89e3\u51b3\u7528\u6237\u8bf7\u6c42\u4e2d\u7684\u6b67\u4e49\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u7684\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u4e5f\u5f88\u5c11\u7cfb\u7edf\u6bd4\u8f83\u4f7f\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u4e0d\u4f7f\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u591a\u8f6e\u5bf9\u8bdd\u6846\u67b6\uff0c\u91c7\u7528\u4e09\u4e2a\u4ea4\u4e92\u7684LLM\u667a\u80fd\u4f53\uff1a\u63d0\u95ee\u8005\u3001\u56de\u7b54\u8005\u548c\u5047\u8bbe\u7a7a\u95f4\u66f4\u65b0\u8005\u3002\u4f7f\u7528\u57fa\u4e8e\u9999\u519c\u71b5\u7684\u4fe1\u606f\u589e\u76ca\u4f5c\u4e3a\u4e3b\u8981\u6307\u6807\uff0c\u5728\u4e94\u7ea7\u5206\u7c7b\u7684\u5730\u7406\u731c\u57ce\u5e02\u6e38\u620f\u73af\u5883\u4e2d\u5b9e\u4f8b\u5316\u8be5\u6846\u67b6\uff0c\u8bc4\u4f30\u5b8c\u5168\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u6709/\u65e0\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u591a\u4e2aLLM\u53d8\u4f53\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8bc4\u4f30\u7684\u6a21\u578b\u4e2d\uff0c\u5177\u6709\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u6bcf\u8f6e\u83b7\u5f97\u66f4\u9ad8\u7684\u4fe1\u606f\u589e\u76ca\uff0c\u4e14\u4ee5\u66f4\u5c11\u6b65\u9aa4\u8fbe\u5230\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u3002\u63a8\u7406\u8f68\u8ff9\u5206\u6790\u663e\u793a\uff0c\u8f83\u5c0f\u6a21\u578b\u901a\u8fc7\u66f4\u79ef\u6781\u5730\u63a2\u7d22\u5019\u9009\u95ee\u9898\u6765\u5f25\u8865\u80fd\u529b\u9650\u5236\uff0c\u800c\u8f83\u5927\u6a21\u578b\u5728\u9009\u62e9\u6700\u4f18\u67e5\u8be2\u65f6\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u81ea\u4fe1\u5ea6\uff0c\u751f\u6210\u5177\u6709\u66f4\u5927\u6f5c\u5728\u4fe1\u606f\u589e\u76ca\u7684\u5019\u9009\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bc4\u4f30LLMs\u901a\u8fc7\u63d0\u95ee\u89e3\u51b3\u6b67\u4e49\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9a\u91cf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u5728\u4fe1\u606f\u6536\u96c6\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u7406\u89e3\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u4fe1\u606f\u5bfb\u6c42\u7b56\u7565\u63d0\u4f9b\u4e86\u6d1e\u5bdf\u3002"}}
{"id": "2601.17761", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17761", "abs": "https://arxiv.org/abs/2601.17761", "authors": ["Dongjie Cheng", "Ruifeng Yuan", "Yongqi Li", "Runyang You", "Wenjie Wang", "Liqiang Nie", "Lei Zhang", "Wenjie Li"], "title": "AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation", "comment": null, "summary": "Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of \"Omni\" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.", "AI": {"tldr": "AR-Omni\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u81ea\u56de\u5f52\u591a\u6a21\u6001\u6a21\u578b\uff0c\u4f7f\u7528\u5355\u4e00Transformer\u89e3\u7801\u5668\u652f\u6301\u6587\u672c\u3001\u56fe\u50cf\u548c\u6d41\u5f0f\u8bed\u97f3\u7684\u4efb\u610f\u5230\u4efb\u610f\u751f\u6210\uff0c\u65e0\u9700\u4e13\u5bb6\u89e3\u7801\u5668\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u611f\u77e5\u548c\u4ea4\u4e92\u672c\u8d28\u4e0a\u662f\u591a\u6a21\u6001\u7684\uff0c\u9700\u8981\u652f\u6301\u591a\u6a21\u6001\u8f93\u5165\u548c\u8f93\u51fa\u7684\"\u5168\u80fd\"\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002\u73b0\u6709\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u989d\u5916\u7684\u4e13\u5bb6\u7ec4\u4ef6\u6765\u5b9e\u73b0\u591a\u6a21\u6001\u751f\u6210\uff0c\u9650\u5236\u4e86\u7edf\u4e00\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u7b80\u6d01\u6027\u3002\u81ea\u56de\u5f52\u5efa\u6a21\u5728\u6587\u672c\u9886\u57df\u5df2\u88ab\u8bc1\u660e\u662f\u4f18\u96c5\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u56e0\u6b64\u4f5c\u8005\u5e0c\u671b\u5c06\u5176\u6269\u5c55\u5230\u591a\u6a21\u6001\u9886\u57df\u3002", "method": "\u63d0\u51faAR-Omni\u6a21\u578b\uff0c\u91c7\u7528\u5355\u4e00Transformer\u89e3\u7801\u5668\u67b6\u6784\uff0c\u652f\u6301\u6587\u672c\u3001\u56fe\u50cf\u548c\u6d41\u5f0f\u8bed\u97f3\u7684\u81ea\u56de\u5f52\u751f\u6210\u3002\u89e3\u51b3\u4e86\u4e09\u4e2a\u5b9e\u9645\u95ee\u9898\uff1a1) \u901a\u8fc7\u4efb\u52a1\u611f\u77e5\u635f\u5931\u91cd\u52a0\u6743\u5904\u7406\u6a21\u6001\u4e0d\u5e73\u8861\uff1b2) \u901a\u8fc7\u8f7b\u91cf\u7ea7token\u7ea7\u611f\u77e5\u5bf9\u9f50\u635f\u5931\u63d0\u5347\u89c6\u89c9\u4fdd\u771f\u5ea6\uff1b3) \u901a\u8fc7\u6709\u9650\u72b6\u6001\u89e3\u7801\u673a\u5236\u5e73\u8861\u7a33\u5b9a\u6027\u548c\u521b\u9020\u6027\u3002", "result": "AR-Omni\u5728\u4e09\u4e2a\u6a21\u6001\u4e0a\u90fd\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u751f\u6210\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u6027\uff0c\u8bed\u97f3\u751f\u6210\u7684\u5b9e\u65f6\u56e0\u5b50\u8fbe\u52300.88\u3002", "conclusion": "AR-Omni\u5c55\u793a\u4e86\u81ea\u56de\u5f52\u8303\u5f0f\u5728\u591a\u6a21\u6001\u4efb\u610f\u5230\u4efb\u610f\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u5355\u4e00\u89e3\u7801\u5668\u67b6\u6784\u5b9e\u73b0\u4e86\u7b80\u6d01\u7edf\u4e00\u7684\u591a\u6a21\u6001\u751f\u6210\uff0c\u4e3a\u591a\u6a21\u6001\u4ea4\u4e92\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u57fa\u7840\u3002"}}
{"id": "2601.17782", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17782", "abs": "https://arxiv.org/abs/2601.17782", "authors": ["Md Sahidullah", "Hye-jin Shim", "Rosa Gonzalez Hautam\u00e4ki", "Tomi H. Kinnunen"], "title": "Shortcut Learning in Binary Classifier Black Boxes: Applications to Voice Anti-Spoofing and Biometrics", "comment": "Accepted for Publication in IEEE Journal of Selected Topics in Signal Processing", "summary": "The widespread adoption of deep-learning models in data-driven applications has drawn attention to the potential risks associated with biased datasets and models. Neglected or hidden biases within datasets and models can lead to unexpected results. This study addresses the challenges of dataset bias and explores ``shortcut learning'' or ``Clever Hans effect'' in binary classifiers. We propose a novel framework for analyzing the black-box classifiers and for examining the impact of both training and test data on classifier scores. Our framework incorporates intervention and observational perspectives, employing a linear mixed-effects model for post-hoc analysis. By evaluating classifier performance beyond error rates, we aim to provide insights into biased datasets and offer a comprehensive understanding of their influence on classifier behavior. The effectiveness of our approach is demonstrated through experiments on audio anti-spoofing and speaker verification tasks using both statistical models and deep neural networks. The insights gained from this study have broader implications for tackling biases in other domains and advancing the field of explainable artificial intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5206\u6790\u9ed1\u76d2\u5206\u7c7b\u5668\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u5e72\u9884\u548c\u89c2\u6d4b\u89c6\u89d2\uff0c\u4f7f\u7528\u7ebf\u6027\u6df7\u5408\u6548\u5e94\u6a21\u578b\u8fdb\u884c\u540e\u9a8c\u5206\u6790\uff0c\u8bc4\u4f30\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5bf9\u5206\u7c7b\u5668\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u68c0\u6d4b\u6570\u636e\u96c6\u504f\u89c1\u548c\u6377\u5f84\u5b66\u4e60\u95ee\u9898\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u6570\u636e\u9a71\u52a8\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u91c7\u7528\u5f15\u8d77\u4e86\u4eba\u4eec\u5bf9\u6570\u636e\u96c6\u548c\u6a21\u578b\u504f\u89c1\u6f5c\u5728\u98ce\u9669\u7684\u5173\u6ce8\u3002\u88ab\u5ffd\u89c6\u6216\u9690\u85cf\u7684\u504f\u89c1\u53ef\u80fd\u5bfc\u81f4\u610f\u5916\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u4e8c\u8fdb\u5236\u5206\u7c7b\u5668\u4e2d\u51fa\u73b0\u7684\"\u6377\u5f84\u5b66\u4e60\"\u6216\"Clever Hans\u6548\u5e94\"\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u5e72\u9884\u548c\u89c2\u6d4b\u89c6\u89d2\uff0c\u91c7\u7528\u7ebf\u6027\u6df7\u5408\u6548\u5e94\u6a21\u578b\u8fdb\u884c\u540e\u9a8c\u5206\u6790\u3002\u8be5\u6846\u67b6\u80fd\u591f\u5206\u6790\u9ed1\u76d2\u5206\u7c7b\u5668\uff0c\u5e76\u68c0\u67e5\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u5bf9\u5206\u7c7b\u5668\u5206\u6570\u7684\u5f71\u54cd\uff0c\u8d85\u8d8a\u7b80\u5355\u7684\u9519\u8bef\u7387\u8bc4\u4f30\u3002", "result": "\u5728\u97f3\u9891\u53cd\u6b3a\u9a97\u548c\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4f7f\u7528\u4e86\u7edf\u8ba1\u6a21\u578b\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u63d0\u4f9b\u5bf9\u504f\u89c1\u6570\u636e\u96c6\u7684\u6df1\u5165\u89c1\u89e3\uff0c\u5e76\u5168\u9762\u7406\u89e3\u5b83\u4eec\u5bf9\u5206\u7c7b\u5668\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5206\u6790\u5206\u7c7b\u5668\u504f\u89c1\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5176\u89c1\u89e3\u5bf9\u4e8e\u89e3\u51b3\u5176\u4ed6\u9886\u57df\u7684\u504f\u89c1\u95ee\u9898\u548c\u63a8\u8fdb\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u9886\u57df\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u610f\u4e49\u3002"}}
{"id": "2601.17802", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17802", "abs": "https://arxiv.org/abs/2601.17802", "authors": ["A. Brawanski", "Th. Schaffer", "F. Raab", "K. -M. Schebesch", "M. Schrey", "Chr. Doenitz", "A. M. Tom\u00e9", "E. W. Lang"], "title": "Robust Computational Extraction of Non-Enhancing Hypercellular Tumor Regions from Clinical Imaging Data", "comment": null, "summary": "Accurate identification of non-enhancing hypercellular (NEH) tumor regions is an unmet need in neuro-oncological imaging, with significant implications for patient management and treatment planning. We present a robust computational framework that generates probability maps of NEH regions from routine MRI data, leveraging multiple network architectures to address the inherent variability and lack of clear imaging boundaries. Our approach was validated against independent clinical markers -- relative cerebral blood volume (rCBV) and enhancing tumor recurrence location (ETRL) -- demonstrating both methodological robustness and biological relevance. This framework enables reliable, non-invasive mapping of NEH tumor compartments, supporting their integration as imaging biomarkers in clinical workflows and advancing precision oncology for brain tumor patients.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u4ece\u5e38\u89c4MRI\u6570\u636e\u751f\u6210\u975e\u589e\u5f3a\u9ad8\u7ec6\u80de\u6027\u80bf\u7624\u533a\u57df\u7684\u6982\u7387\u56fe\uff0c\u901a\u8fc7\u72ec\u7acb\u4e34\u5e8a\u6807\u5fd7\u7269\u9a8c\u8bc1\u4e86\u5176\u65b9\u6cd5\u7a33\u5065\u6027\u548c\u751f\u7269\u5b66\u76f8\u5173\u6027\u3002", "motivation": "\u795e\u7ecf\u80bf\u7624\u5f71\u50cf\u4e2d\u51c6\u786e\u8bc6\u522b\u975e\u589e\u5f3a\u9ad8\u7ec6\u80de\u6027\u80bf\u7624\u533a\u57df\u662f\u4e00\u4e2a\u672a\u6ee1\u8db3\u7684\u9700\u6c42\uff0c\u5bf9\u60a3\u8005\u7ba1\u7406\u548c\u6cbb\u7597\u89c4\u5212\u6709\u91cd\u8981\u610f\u4e49\u3002\u76ee\u524d\u7f3a\u4e4f\u6e05\u6670\u7684\u5f71\u50cf\u8fb9\u754c\u548c\u5b58\u5728\u56fa\u6709\u53d8\u5f02\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7a33\u5065\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5229\u7528\u591a\u79cd\u7f51\u7edc\u67b6\u6784\u4ece\u5e38\u89c4MRI\u6570\u636e\u751f\u6210NEH\u533a\u57df\u7684\u6982\u7387\u56fe\uff0c\u4ee5\u89e3\u51b3\u5f71\u50cf\u8fb9\u754c\u4e0d\u6e05\u6670\u548c\u53d8\u5f02\u6027\u95ee\u9898\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7\u72ec\u7acb\u4e34\u5e8a\u6807\u5fd7\u7269\uff08\u76f8\u5bf9\u8111\u8840\u5bb9\u91cf\u548c\u589e\u5f3a\u80bf\u7624\u590d\u53d1\u4f4d\u7f6e\uff09\u8fdb\u884c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u7a33\u5065\u6027\u548c\u751f\u7269\u5b66\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u53ef\u9760\u3001\u65e0\u521b\u5730\u6620\u5c04NEH\u80bf\u7624\u533a\u57df\uff0c\u652f\u6301\u5176\u4f5c\u4e3a\u5f71\u50cf\u751f\u7269\u6807\u5fd7\u7269\u6574\u5408\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u63a8\u8fdb\u8111\u80bf\u7624\u60a3\u8005\u7684\u7cbe\u51c6\u80bf\u7624\u5b66\u3002"}}
{"id": "2601.17858", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17858", "abs": "https://arxiv.org/abs/2601.17858", "authors": ["Jiapeng Wang", "Changxin Tian", "Kunlong Chen", "Ziqi Liu", "Jiaxin Mao", "Wayne Xin Zhao", "Zhiqiang Zhang", "Jun Zhou"], "title": "MergeMix: Optimizing Mid-Training Data Mixtures via Learnable Model Merging", "comment": null, "summary": "Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \\textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $\u03c1> 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.", "AI": {"tldr": "MergeMix \u901a\u8fc7\u5c06\u6a21\u578b\u5408\u5e76\u6743\u91cd\u4f5c\u4e3a\u9ad8\u6027\u80fd\u4ee3\u7406\uff0c\u9ad8\u6548\u4f18\u5316\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u5927\u5e45\u964d\u4f4e\u641c\u7d22\u6210\u672c\uff0c\u57288B\u548c16B\u53c2\u6570\u6a21\u578b\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u4f18\u5316\u6570\u636e\u6df7\u5408\u5bf9\u4e8e\u91ca\u653e\u5927\u8bed\u8a00\u6a21\u578b\u6f5c\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f53\u524d\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u8bd5\u9a8c\u6216\u6602\u8d35\u7684\u4ee3\u7406\u8bad\u7ec3\uff0c\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u63d0\u51faMergeMix\u65b9\u6cd5\uff1a\u5728\u5c11\u91cftoken\u4e0a\u8bad\u7ec3\u9886\u57df\u4e13\u5bb6\u6a21\u578b\uff0c\u7136\u540e\u4f18\u5316\u5b83\u4eec\u7684\u5408\u5e76\u6743\u91cd\u4ee5\u5339\u914d\u4e0b\u6e38\u57fa\u51c6\u6027\u80fd\uff0c\u4ee5\u6b64\u4f5c\u4e3a\u9ad8\u6548\u7684\u6570\u636e\u6df7\u5408\u6027\u80fd\u4ee3\u7406\u3002", "result": "\u57288B\u548c16B\u53c2\u6570\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMergeMix\u6027\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u7a77\u4e3e\u624b\u52a8\u8c03\u4f18\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u641c\u7d22\u6210\u672c\uff0c\u5177\u6709\u9ad8\u79e9\u4e00\u81f4\u6027(Spearman \u03c1>0.9)\u548c\u5f3a\u8de8\u5c3a\u5ea6\u53ef\u8fc1\u79fb\u6027\u3002", "conclusion": "MergeMix\u4e3a\u6570\u636e\u6df7\u5408\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6a21\u578b\u5408\u5e76\u6743\u91cd\u4f5c\u4e3a\u4f4e\u6210\u672c\u9ad8\u6027\u80fd\u4ee3\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2601.17883", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.17883", "abs": "https://arxiv.org/abs/2601.17883", "authors": ["Dingkun Liu", "Yuheng Chen", "Zhu Chen", "Zhenyao Cui", "Yaozhi Wen", "Jiayu An", "Jingwei Luo", "Dongrui Wu"], "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems", "comment": null, "summary": "Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u73b0\u6709EEG\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u8bc4\u4f30\uff0c\u6bd4\u8f83\u4e8612\u4e2a\u5f00\u6e90\u6a21\u578b\u572813\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u7ebf\u6027\u63a2\u6d4b\u901a\u5e38\u4e0d\u8db3\u3001\u4e13\u4e1a\u6a21\u578b\u4ecd\u6709\u7ade\u4e89\u529b\u3001\u66f4\u5927\u6a21\u578b\u4e0d\u4e00\u5b9a\u5e26\u6765\u66f4\u597d\u6027\u80fd\u3002", "motivation": "EEG\u57fa\u7840\u6a21\u578b\u5728\u8111\u673a\u63a5\u53e3\u9886\u57df\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u7f3a\u4e4f\u516c\u5e73\u5168\u9762\u7684\u6bd4\u8f83\uff0c\u56e0\u4e3a\u5b58\u5728\u9884\u8bad\u7ec3\u76ee\u6807\u4e0d\u4e00\u81f4\u3001\u9884\u5904\u7406\u9009\u62e9\u4e0d\u540c\u3001\u4e0b\u6e38\u8bc4\u4f30\u534f\u8bae\u4e0d\u7edf\u4e00\u7b49\u95ee\u9898\u3002\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u9886\u57df\u63d0\u4f9b\u53ef\u9760\u7684\u57fa\u51c6\u8bc4\u4f30\u3002", "method": "\u9996\u5148\u56de\u987e50\u4e2a\u4ee3\u8868\u6027\u6a21\u578b\u5e76\u6784\u5efa\u7edf\u4e00\u5206\u7c7b\u6846\u67b6\uff0c\u7136\u540e\u8bc4\u4f3012\u4e2a\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u548c\u7ade\u4e89\u6027\u4e13\u4e1a\u57fa\u7ebf\u6a21\u578b\uff0c\u572813\u4e2aEEG\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd59\u79cdBCI\u8303\u5f0f\u3002\u91c7\u7528\u7559\u4e00\u53d7\u8bd5\u8005\u4ea4\u53c9\u9a8c\u8bc1\u548c\u5c11\u6837\u672c\u5feb\u901f\u6821\u51c6\u4e24\u79cd\u73b0\u5b9e\u90e8\u7f72\u573a\u666f\uff0c\u6bd4\u8f83\u5168\u53c2\u6570\u5fae\u8c03\u4e0e\u7ebf\u6027\u63a2\u6d4b\uff0c\u5e76\u5206\u6790\u6a21\u578b\u89c4\u6a21\u4e0e\u6027\u80fd\u5173\u7cfb\u3002", "result": "1) \u7ebf\u6027\u63a2\u6d4b\u901a\u5e38\u4e0d\u8db3\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff1b2) \u4ece\u5934\u8bad\u7ec3\u7684\u4e13\u4e1a\u6a21\u578b\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u4ecd\u5177\u6709\u7ade\u4e89\u529b\uff1b3) \u5728\u5f53\u524d\u6570\u636e\u89c4\u6a21\u548c\u8bad\u7ec3\u5b9e\u8df5\u4e0b\uff0c\u66f4\u5927\u7684\u57fa\u7840\u6a21\u578b\u4e0d\u4e00\u5b9a\u5e26\u6765\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "EEG\u57fa\u7840\u6a21\u578b\u9886\u57df\u9700\u8981\u66f4\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5f53\u524d\u6a21\u578b\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u4e13\u4e1a\u6a21\u578b\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u4ecd\u662f\u6709\u6548\u9009\u62e9\uff0c\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u9700\u8981\u66f4\u6709\u6548\u7684\u6570\u636e\u548c\u8bad\u7ec3\u7b56\u7565\u652f\u6301\u3002"}}
{"id": "2601.17910", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17910", "abs": "https://arxiv.org/abs/2601.17910", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Adaptive Weighting in Knowledge Distillation: An Axiomatic Framework for Multi-Scale Teacher Ensemble Optimization", "comment": "12 pages, 1 figure, 1 table", "summary": "Knowledge distillation with multiple teachers is increasingly used to improve robustness, efficiency, and safety, yet existing approaches rely largely on heuristic or implementation-specific weighting schemes. This paper develops an operator-agnostic axiomatic framework for adaptive weighting in multi-teacher knowledge distillation across three complementary scales: token, task, and context. We formalize structural conditions under which adaptive weighting operators are well-defined, admit multiple non-equivalent implementations, and can be hierarchically composed via product-structure normalization. Within this framework, we establish existence and non-uniqueness of conforming operators, characterize convergence of gradient-based optimization under standard assumptions, analyze stability and perturbation robustness, and provide an abstract formulation of safety-constrained distillation. The results decouple theoretical guarantees from specific weighting formulas, enabling principled analysis of adaptive distillation methods under heterogeneity, distribution shift, and safety constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b97\u5b50\u65e0\u5173\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6559\u5e08\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u81ea\u9002\u5e94\u6743\u91cd\u5206\u914d\uff0c\u6db5\u76d6token\u3001task\u548ccontext\u4e09\u4e2a\u4e92\u8865\u5c3a\u5ea6\uff0c\u5efa\u7acb\u4e86\u7406\u8bba\u4fdd\u8bc1\u4e0e\u5177\u4f53\u6743\u91cd\u516c\u5f0f\u7684\u89e3\u8026\u3002", "motivation": "\u5f53\u524d\u591a\u6559\u5e08\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u5b9e\u73b0\u7279\u5b9a\u7684\u6743\u91cd\u65b9\u6848\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u7b97\u5b50\u65e0\u5173\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u4e3a\u81ea\u9002\u5e94\u6743\u91cd\u5206\u914d\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7b97\u5b50\u65e0\u5173\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u4e86\u81ea\u9002\u5e94\u6743\u91cd\u7b97\u5b50\u5728token\u3001task\u548ccontext\u4e09\u4e2a\u5c3a\u5ea6\u4e0a\u7684\u7ed3\u6784\u6761\u4ef6\uff0c\u5305\u62ec\u826f\u597d\u5b9a\u4e49\u6027\u3001\u591a\u91cd\u975e\u7b49\u4ef7\u5b9e\u73b0\u53ef\u80fd\u6027\u3001\u4ee5\u53ca\u901a\u8fc7\u4e58\u79ef\u7ed3\u6784\u5f52\u4e00\u5316\u7684\u5c42\u6b21\u7ec4\u5408\u3002", "result": "\u5efa\u7acb\u4e86\u7b26\u5408\u6761\u4ef6\u7b97\u5b50\u7684\u5b58\u5728\u6027\u548c\u975e\u552f\u4e00\u6027\uff0c\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\u5206\u6790\u4e86\u57fa\u4e8e\u68af\u5ea6\u4f18\u5316\u7684\u6536\u655b\u6027\uff0c\u5206\u6790\u4e86\u7a33\u5b9a\u6027\u548c\u6270\u52a8\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b89\u5168\u7ea6\u675f\u84b8\u998f\u7684\u62bd\u8c61\u8868\u8ff0\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u7406\u8bba\u4fdd\u8bc1\u4e0e\u5177\u4f53\u6743\u91cd\u516c\u5f0f\u89e3\u8026\uff0c\u4f7f\u5f97\u5728\u5f02\u6784\u6027\u3001\u5206\u5e03\u504f\u79fb\u548c\u5b89\u5168\u7ea6\u675f\u4e0b\u80fd\u591f\u5bf9\u81ea\u9002\u5e94\u84b8\u998f\u65b9\u6cd5\u8fdb\u884c\u539f\u5219\u6027\u5206\u6790\u3002"}}
{"id": "2601.17912", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17912", "abs": "https://arxiv.org/abs/2601.17912", "authors": ["Qinyi Liu", "Mohammad Khalil", "Naman Goel"], "title": "Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN", "comment": null, "summary": "Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.", "AI": {"tldr": "TabPFN\u7b49\u8868\u683c\u6570\u636e\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u56e0\u679c\u9884\u8bad\u7ec3\u83b7\u5f97\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4f46\u5176\u516c\u5e73\u6027\u8868\u73b0\u6709\u9650\uff0c\u5c24\u5176\u5728MNAR\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\uff0c\u9700\u8981\u989d\u5916\u7684\u516c\u5e73\u6027\u5e72\u9884\u63aa\u65bd\u3002", "motivation": "\u5c3d\u7ba1TabPFN\u7b49\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u9884\u8bad\u7ec3\u7684\u8868\u683c\u6570\u636e\u57fa\u7840\u6a21\u578b\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u7684\u516c\u5e73\u6027\u7279\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u516c\u5e73\u6027\u8868\u73b0\u3002", "method": "\u5bf9TabPFN\u53ca\u5176\u5fae\u8c03\u53d8\u4f53\u8fdb\u884c\u5168\u9762\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5305\u62ec\u9884\u6d4b\u6027\u80fd\u3001\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u6d4b\u8bd5\uff0c\u8003\u5bdf\u4e0d\u540c\u6570\u636e\u96c6\u5927\u5c0f\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u8868\u73b0\u3002", "result": "TabPFN\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u5177\u6709\u66f4\u5f3a\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u516c\u5e73\u6027\u65b9\u9762\u7684\u6539\u8fdb\u6709\u9650\u4e14\u4e0d\u4e00\u81f4\uff0c\u7279\u522b\u662f\u5728MNAR\u534f\u53d8\u91cf\u504f\u79fb\u60c5\u51b5\u4e0b\u3002", "conclusion": "TabPFN\u7684\u56e0\u679c\u9884\u8bad\u7ec3\u6709\u5e2e\u52a9\u4f46\u4e0d\u8db3\u4ee5\u786e\u4fdd\u7b97\u6cd5\u516c\u5e73\u6027\uff0c\u5b9e\u9645\u90e8\u7f72\u9700\u8981\u989d\u5916\u7684\u516c\u5e73\u6027\u5e72\u9884\u63aa\u65bd\uff0c\u7a81\u663e\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u516c\u5e73\u6027\u95ee\u9898\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.17916", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17916", "abs": "https://arxiv.org/abs/2601.17916", "authors": ["Jialu Tang", "Tong Xia", "Yuan Lu", "Aaqib Saeed"], "title": "UniPACT: A Multimodal Framework for Prognostic Question Answering on Raw ECG and Structured EHR", "comment": "Accepted to IEEE ICASSP 2026", "summary": "Accurate clinical prognosis requires synthesizing structured Electronic Health Records (EHRs) with real-time physiological signals like the Electrocardiogram (ECG). Large Language Models (LLMs) offer a powerful reasoning engine for this task but struggle to natively process these heterogeneous, non-textual data types. To address this, we propose UniPACT (Unified Prognostic Question Answering for Clinical Time-series), a unified framework for prognostic question answering that bridges this modality gap. UniPACT's core contribution is a structured prompting mechanism that converts numerical EHR data into semantically rich text. This textualized patient context is then fused with representations learned directly from raw ECG waveforms, enabling an LLM to reason over both modalities holistically. We evaluate UniPACT on the comprehensive MDS-ED benchmark, it achieves a state-of-the-art mean AUROC of 89.37% across a diverse set of prognostic tasks including diagnosis, deterioration, ICU admission, and mortality, outperforming specialized baselines. Further analysis demonstrates that our multimodal, multi-task approach is critical for performance and provides robustness in missing data scenarios.", "AI": {"tldr": "UniPACT\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u5c06\u6570\u503cEHR\u6570\u636e\u8f6c\u6362\u4e3a\u8bed\u4e49\u4e30\u5bcc\u7684\u6587\u672c\uff0c\u5e76\u4e0e\u539f\u59cbECG\u6ce2\u5f62\u8868\u793a\u878d\u5408\uff0c\u4f7fLLM\u80fd\u591f\u5bf9\u4e24\u79cd\u6a21\u6001\u8fdb\u884c\u6574\u4f53\u63a8\u7406\uff0c\u5728MDS-ED\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u9884\u540e\u6027\u80fd\u3002", "motivation": "\u51c6\u786e\u7684\u4e34\u5e8a\u9884\u540e\u9700\u8981\u6574\u5408\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u548c\u5b9e\u65f6\u751f\u7406\u4fe1\u53f7\uff08\u5982\u5fc3\u7535\u56feECG\uff09\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3a\u6b64\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u63a8\u7406\u5f15\u64ce\uff0c\u4f46\u96be\u4ee5\u539f\u751f\u5904\u7406\u8fd9\u4e9b\u5f02\u6784\u7684\u975e\u6587\u672c\u6570\u636e\u7c7b\u578b\u3002", "method": "\u63d0\u51faUniPACT\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u7ed3\u6784\u5316\u63d0\u793a\u673a\u5236\uff0c\u5c06\u6570\u503cEHR\u6570\u636e\u8f6c\u6362\u4e3a\u8bed\u4e49\u4e30\u5bcc\u7684\u6587\u672c\u3002\u7136\u540e\u5c06\u8fd9\u79cd\u6587\u672c\u5316\u7684\u60a3\u8005\u4e0a\u4e0b\u6587\u4e0e\u4ece\u539f\u59cbECG\u6ce2\u5f62\u76f4\u63a5\u5b66\u4e60\u7684\u8868\u793a\u878d\u5408\uff0c\u4f7fLLM\u80fd\u591f\u5bf9\u4e24\u79cd\u6a21\u6001\u8fdb\u884c\u6574\u4f53\u63a8\u7406\u3002", "result": "\u5728\u7efc\u5408MDS-ED\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUniPACT\u5728\u8bca\u65ad\u3001\u6076\u5316\u3001ICU\u5165\u9662\u548c\u6b7b\u4ea1\u7387\u7b49\u591a\u79cd\u9884\u540e\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e8689.37%\u7684\u5e73\u5747AUROC\uff0c\u4f18\u4e8e\u4e13\u95e8\u57fa\u7ebf\u3002\u591a\u6a21\u6001\u591a\u4efb\u52a1\u65b9\u6cd5\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u5728\u7f3a\u5931\u6570\u636e\u573a\u666f\u4e2d\u63d0\u4f9b\u9c81\u68d2\u6027\u3002", "conclusion": "UniPACT\u901a\u8fc7\u5f25\u5408\u6a21\u6001\u5dee\u8ddd\uff0c\u4f7fLLM\u80fd\u591f\u6709\u6548\u5904\u7406\u5f02\u6784\u4e34\u5e8a\u6570\u636e\uff0c\u4e3a\u9884\u540e\u95ee\u7b54\u63d0\u4f9b\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5728\u591a\u79cd\u4e34\u5e8a\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2601.17917", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.17917", "abs": "https://arxiv.org/abs/2601.17917", "authors": ["Zhongyu Xiao", "Zhiwei Hao", "Jianyuan Guo", "Yong Luo", "Jia Liu", "Jie Xu", "Han Hu"], "title": "treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding", "comment": "Tech report. Code is available at https://github.com/xiaoshideta/Streaming-dLLM", "summary": "Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.", "AI": {"tldr": "Streaming-dLLM\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u9ad8\u6548\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u7ef4\u5ea6\u4e0a\u7684\u8870\u51cf\u5f15\u5bfc\u540e\u7f00\u5efa\u6a21\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u52a8\u6001\u7f6e\u4fe1\u611f\u77e5\u7b56\u7565\uff0c\u663e\u8457\u52a0\u901f\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u6700\u9ad8\u53ef\u8fbe68.2\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b(dLLMs)\u63a8\u7406\u52a0\u901f\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u7a7a\u95f4\u5197\u4f59\uff08\u5bf9\u4fe1\u606f\u7a00\u758f\u7684\u540e\u7f00\u533a\u57df\u8fdb\u884c\u7edf\u4e00\u5efa\u6a21\uff09\u548c\u65f6\u95f4\u6548\u7387\u4f4e\u4e0b\uff08\u5728\u6574\u4e2a\u89e3\u7801\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u56fa\u5b9a\u7684\u53bb\u566a\u8c03\u5ea6\uff09\u3002\u8fd9\u4e9b\u5185\u5728\u4f4e\u6548\u6027\u9650\u5236\u4e86dLLMs\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "Streaming-dLLM\u91c7\u7528\u53cc\u7ef4\u5ea6\u4f18\u5316\uff1a1\uff09\u7a7a\u95f4\u4e0a\uff0c\u901a\u8fc7\u8870\u51cf\u5f15\u5bfc\u540e\u7f00\u5efa\u6a21\uff0c\u526a\u679d\u5197\u4f59\u7684\u63a9\u7801\u6807\u8bb0\u6765\u8fd1\u4f3c\u5b8c\u6574\u4e0a\u4e0b\u6587\uff1b2\uff09\u65f6\u95f4\u4e0a\uff0c\u91c7\u7528\u52a8\u6001\u7f6e\u4fe1\u611f\u77e5\u7b56\u7565\u548c\u63d0\u524d\u9000\u51fa\u673a\u5236\uff0c\u8ba9\u6a21\u578b\u8df3\u8fc7\u5df2\u6536\u655b\u6807\u8bb0\u7684\u4e0d\u5fc5\u8981\u8fed\u4ee3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eStreaming-dLLM\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u6700\u9ad8\u53ef\u5b9e\u73b068.2\u500d\u7684\u63a8\u7406\u52a0\u901f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002", "conclusion": "Streaming-dLLM\u901a\u8fc7\u89e3\u51b3\u6269\u6563\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u7a7a\u95f4\u5197\u4f59\u548c\u65f6\u95f4\u4f4e\u6548\u95ee\u9898\uff0c\u4e3a\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u5b9e\u7528\u7684\u63a8\u7406\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u8be5\u8303\u5f0f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.17933", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.17933", "abs": "https://arxiv.org/abs/2601.17933", "authors": ["Laurent Caraffa"], "title": "Dissipative Learning: A Framework for Viable Adaptive Systems", "comment": "68 pages, 14 figures", "summary": "We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.\n  A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.\n  Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faBEDS\u6846\u67b6\uff0c\u5c06\u5b66\u4e60\u89c6\u4e3a\u5185\u5728\u8017\u6563\u8fc7\u7a0b\uff0c\u8bc1\u660eFisher-Rao\u6b63\u5219\u5316\u662f\u70ed\u529b\u5b66\u6700\u4f18\u7b56\u7565\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u9057\u5fd8\u3001\u6b63\u5219\u5316\u548c\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "\u4f20\u7edf\u5b66\u4e60\u7406\u8bba\u5c06\u9057\u5fd8\u548c\u6b63\u5219\u5316\u89c6\u4e3a\u542f\u53d1\u5f0f\u9644\u52a0\u7ec4\u4ef6\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002\u4f5c\u8005\u8ba4\u4e3a\u5b66\u4e60\u672c\u8d28\u4e0a\u662f\u8017\u6563\u8fc7\u7a0b\uff0c\u9700\u8981\u4ece\u4fe1\u606f\u7406\u8bba\u3001\u70ed\u529b\u5b66\u548c\u4fe1\u606f\u51e0\u4f55\u89d2\u5ea6\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u6765\u89e3\u91ca\u8fd9\u4e9b\u73b0\u8c61\u3002", "method": "\u63d0\u51faBEDS\uff08\u8d1d\u53f6\u65af\u6d8c\u73b0\u8017\u6563\u7ed3\u6784\uff09\u6846\u67b6\uff0c\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u3001\u70ed\u529b\u5b66\u548c\u4fe1\u606f\u51e0\u4f55\uff0c\u5c06\u5b66\u4e60\u5efa\u6a21\u4e3a\u5728\u8017\u6563\u7ea6\u675f\u4e0b\u7684\u538b\u7f29\u4fe1\u5ff5\u72b6\u6001\u6f14\u5316\u3002\u6838\u5fc3\u8d21\u732e\u662f\u6761\u4ef6\u6700\u4f18\u6027\u5b9a\u7406\uff0c\u8bc1\u660eFisher-Rao\u6b63\u5219\u5316\u662f\u552f\u4e00\u70ed\u529b\u5b66\u6700\u4f18\u7b56\u7565\u3002", "result": "\u8bc1\u660e\u4e86Fisher-Rao\u6b63\u5219\u5316\u76f8\u6bd4\u6b27\u51e0\u91cc\u5f97\u6b63\u5219\u5316\u5728\u70ed\u529b\u5b66\u4e0a\u66f4\u4f18\uff0c\u7edf\u4e00\u4e86Ridge\u3001SIGReg\u3001EMA\u3001SAC\u7b49\u65b9\u6cd5\u4f5c\u4e3a\u7279\u4f8b\u3002\u533a\u5206\u4e86BEDS\u53ef\u7ed3\u6676\u95ee\u9898\u548cBEDS\u53ef\u7ef4\u6301\u95ee\u9898\uff0c\u4e3a\u6301\u7eed\u5b66\u4e60\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u6807\u51c6\u3002", "conclusion": "\u5b66\u4e60\u5e94\u88ab\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u8017\u6563\u7ea6\u675f\u4e0b\u7ef4\u6301\u53ef\u884c\u4fe1\u5ff5\u72b6\u6001\u7684\u8fc7\u7a0b\u3002\u8be5\u6846\u67b6\u4e3a\u9057\u5fd8\u3001\u6b63\u5219\u5316\u548c\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u89c6\u89d2\uff0c\u5c06\u6e10\u8fd1\u6700\u4f18\u6027\u66ff\u6362\u4e3a\u5728\u6709\u9650\u8d44\u6e90\u4e0b\u7684\u9002\u5e94\u6027\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2601.17935", "categories": ["cs.LG", "cs.CR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.17935", "abs": "https://arxiv.org/abs/2601.17935", "authors": ["Daniel Commey", "Matilda Nkoom", "Yousef Alsenani", "Sena G. Hounsinou", "Garth V. Crosby"], "title": "FedGraph-VASP: Privacy-Preserving Federated Graph Learning with Post-Quantum Security for Cross-Institutional Anti-Money Laundering", "comment": null, "summary": "Virtual Asset Service Providers (VASPs) face a fundamental tension between regulatory compliance and user privacy when detecting cross-institutional money laundering. Current approaches require either sharing sensitive transaction data or operating in isolation, leaving critical cross-chain laundering patterns undetected. We present FedGraph-VASP, a privacy-preserving federated graph learning framework that enables collaborative anti-money laundering (AML) without exposing raw user data. Our key contribution is a Boundary Embedding Exchange protocol that shares only compressed, non-invertible graph neural network representations of boundary accounts. These exchanges are secured using post-quantum cryptography, specifically the NIST-standardized Kyber-512 key encapsulation mechanism combined with AES-256-GCM authenticated encryption. Experiments on the Elliptic Bitcoin dataset with realistic Louvain partitioning show that FedGraph-VASP achieves an F1-score of 0.508, outperforming the state-of-the-art generative baseline FedSage+ (F1 = 0.453) by 12.1 percent on binary fraud detection. We further show robustness under low-connectivity settings where generative imputation degrades performance, while approaching centralized performance (F1 = 0.620) in high-connectivity regimes. We additionally evaluate generalization on an Ethereum fraud detection dataset, where FedGraph-VASP (F1 = 0.635) is less effective under sparse cross-silo connectivity, while FedSage+ excels (F1 = 0.855), outperforming even local training (F1 = 0.785). These results highlight a topology-dependent trade-off: embedding exchange benefits connected transaction graphs, whereas generative imputation can dominate in highly modular sparse graphs. A privacy audit shows embeddings are only partially invertible (R^2 = 0.32), limiting exact feature recovery.", "AI": {"tldr": "FedGraph-VASP\u662f\u4e00\u4e2a\u4fdd\u62a4\u9690\u79c1\u7684\u8054\u90a6\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u673a\u6784\u53cd\u6d17\u94b1\u68c0\u6d4b\uff0c\u901a\u8fc7\u8fb9\u754c\u5d4c\u5165\u4ea4\u6362\u534f\u8bae\u5728\u4e0d\u66b4\u9732\u539f\u59cb\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u534f\u4f5c\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u865a\u62df\u8d44\u4ea7\u670d\u52a1\u63d0\u4f9b\u5546\u5728\u53cd\u6d17\u94b1\u68c0\u6d4b\u4e2d\u9762\u4e34\u76d1\u7ba1\u5408\u89c4\u4e0e\u7528\u6237\u9690\u79c1\u7684\u51b2\u7a81\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u5171\u4eab\u654f\u611f\u4ea4\u6613\u6570\u636e\uff0c\u8981\u4e48\u5b64\u7acb\u64cd\u4f5c\u65e0\u6cd5\u68c0\u6d4b\u8de8\u94fe\u6d17\u94b1\u6a21\u5f0f\u3002", "method": "\u63d0\u51faFedGraph-VASP\u6846\u67b6\uff0c\u91c7\u7528\u8fb9\u754c\u5d4c\u5165\u4ea4\u6362\u534f\u8bae\uff0c\u4ec5\u5171\u4eab\u538b\u7f29\u3001\u4e0d\u53ef\u9006\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u8fb9\u754c\u8d26\u6237\u8868\u793a\uff0c\u5e76\u4f7f\u7528\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff08Kyber-512\u548cAES-256-GCM\uff09\u8fdb\u884c\u5b89\u5168\u4fdd\u62a4\u3002", "result": "\u5728Elliptic\u6bd4\u7279\u5e01\u6570\u636e\u96c6\u4e0a\uff0cFedGraph-VASP\u7684F1\u5206\u6570\u8fbe\u52300.508\uff0c\u6bd4FedSage+\uff080.453\uff09\u63d0\u534712.1%\uff1b\u5728\u4ee5\u592a\u574a\u6b3a\u8bc8\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\uff0c\u6027\u80fd\u53d7\u62d3\u6251\u7ed3\u6784\u5f71\u54cd\uff0c\u5728\u7a00\u758f\u8fde\u63a5\u56fe\u4e2d\u4e0d\u5982FedSage+\u3002", "conclusion": "FedGraph-VASP\u5728\u8fde\u63a5\u826f\u597d\u7684\u4ea4\u6613\u56fe\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u751f\u6210\u5f0f\u63d2\u8865\u5728\u9ad8\u5ea6\u6a21\u5757\u5316\u7684\u7a00\u758f\u56fe\u4e2d\u66f4\u6709\u6548\uff0c\u4f53\u73b0\u4e86\u62d3\u6251\u4f9d\u8d56\u7684\u6743\u8861\uff1b\u5d4c\u5165\u4ec5\u90e8\u5206\u53ef\u9006\uff08R^2=0.32\uff09\uff0c\u9650\u5236\u4e86\u7279\u5f81\u6062\u590d\u3002"}}
{"id": "2601.17954", "categories": ["cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.17954", "abs": "https://arxiv.org/abs/2601.17954", "authors": ["Nikos Georgoudios", "Konstantinos Spiliopoulos", "Justin Sirignano"], "title": "Scaling Effects and Uncertainty Quantification in Neural Actor Critic Algorithms", "comment": "72 pages, 2 figures", "summary": "We investigate the neural Actor Critic algorithm using shallow neural networks for both the Actor and Critic models. The focus of this work is twofold: first, to compare the convergence properties of the network outputs under various scaling schemes as the network width and the number of training steps tend to infinity; and second, to provide precise control of the approximation error associated with each scaling regime. Previous work has shown convergence to ordinary differential equations with random initial conditions under inverse square root scaling in the network width. In this work, we shift the focus from convergence speed alone to a more comprehensive statistical characterization of the algorithm's output, with the goal of quantifying uncertainty in neural Actor Critic methods. Specifically, we study a general inverse polynomial scaling in the network width, with an exponent treated as a tunable hyperparameter taking values strictly between one half and one. We derive an asymptotic expansion of the network outputs, interpreted as statistical estimators, in order to clarify their structure. To leading order, we show that the variance decays as a power of the network width, with an exponent equal to one half minus the scaling parameter, implying improved statistical robustness as the scaling parameter approaches one. Numerical experiments support this behavior and further suggest faster convergence for this choice of scaling. Finally, our analysis yields concrete guidelines for selecting algorithmic hyperparameters, including learning rates and exploration rates, as functions of the network width and the scaling parameter, ensuring provably favorable statistical behavior.", "AI": {"tldr": "\u7814\u7a76\u795e\u7ecfActor-Critic\u7b97\u6cd5\u5728\u4e0d\u540c\u7f51\u7edc\u5bbd\u5ea6\u7f29\u653e\u65b9\u6848\u4e0b\u7684\u6536\u655b\u6027\u548c\u7edf\u8ba1\u7279\u6027\uff0c\u63d0\u51fa\u53ef\u8c03\u8d85\u53c2\u6570\u63a7\u5236\u8fd1\u4f3c\u8bef\u5dee\uff0c\u63a8\u5bfc\u65b9\u5dee\u8870\u51cf\u89c4\u5f8b\u5e76\u63d0\u4f9b\u8d85\u53c2\u6570\u9009\u62e9\u6307\u5357\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6536\u655b\u901f\u5ea6\uff0c\u672c\u6587\u8f6c\u5411\u66f4\u5168\u9762\u7684\u7edf\u8ba1\u7279\u6027\u5206\u6790\uff0c\u65e8\u5728\u91cf\u5316\u795e\u7ecfActor-Critic\u65b9\u6cd5\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u7b97\u6cd5\u63d0\u4f9b\u7edf\u8ba1\u9c81\u68d2\u6027\u4fdd\u8bc1\u3002", "method": "\u4f7f\u7528\u6d45\u5c42\u795e\u7ecf\u7f51\u7edc\u6784\u5efaActor\u548cCritic\u6a21\u578b\uff0c\u7814\u7a76\u7f51\u7edc\u5bbd\u5ea6\u7684\u5e7f\u4e49\u9006\u591a\u9879\u5f0f\u7f29\u653e\uff08\u6307\u6570\u57280.5\u52301\u4e4b\u95f4\u53ef\u8c03\uff09\uff0c\u63a8\u5bfc\u7f51\u7edc\u8f93\u51fa\u7684\u6e10\u8fd1\u5c55\u5f00\uff0c\u5206\u6790\u5176\u7edf\u8ba1\u4f30\u8ba1\u5668\u7ed3\u6784\u3002", "result": "\u65b9\u5dee\u968f\u7f51\u7edc\u5bbd\u5ea6\u4ee5\u5e42\u5f8b\u8870\u51cf\uff0c\u6307\u6570\u4e3a0.5\u51cf\u53bb\u7f29\u653e\u53c2\u6570\uff0c\u5f53\u7f29\u653e\u53c2\u6570\u63a5\u8fd11\u65f6\u7edf\u8ba1\u9c81\u68d2\u6027\u66f4\u597d\uff1b\u6570\u503c\u5b9e\u9a8c\u652f\u6301\u8be5\u884c\u4e3a\u5e76\u663e\u793a\u66f4\u5feb\u6536\u655b\u3002", "conclusion": "\u5206\u6790\u7ed3\u679c\u4e3a\u9009\u62e9\u5b66\u4e60\u7387\u3001\u63a2\u7d22\u7387\u7b49\u8d85\u53c2\u6570\u63d0\u4f9b\u5177\u4f53\u6307\u5bfc\uff0c\u786e\u4fdd\u53ef\u8bc1\u660e\u7684\u6709\u5229\u7edf\u8ba1\u884c\u4e3a\uff0c\u4e3a\u795e\u7ecfActor-Critic\u65b9\u6cd5\u63d0\u4f9b\u7406\u8bba\u652f\u6491\u3002"}}
{"id": "2601.17958", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17958", "abs": "https://arxiv.org/abs/2601.17958", "authors": ["Ido Andrew Atad", "Itamar Zimerman", "Shahar Katz", "Lior Wolf"], "title": "TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors", "comment": "17 pages, 7 figures", "summary": "Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.", "AI": {"tldr": "TensorLens\uff1a\u4e00\u79cd\u5c06\u6574\u4e2atransformer\u8868\u793a\u4e3a\u5355\u4e00\u8f93\u5165\u4f9d\u8d56\u7ebf\u6027\u7b97\u5b50\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u9636\u6ce8\u610f\u529b\u4ea4\u4e92\u5f20\u91cf\u7edf\u4e00\u7f16\u7801\u6ce8\u610f\u529b\u3001FFN\u3001\u6fc0\u6d3b\u3001\u5f52\u4e00\u5316\u548c\u6b8b\u5dee\u8fde\u63a5\u3002", "motivation": "\u73b0\u6709\u6ce8\u610f\u529b\u5206\u6790\u5927\u591a\u5173\u6ce8\u5355\u4e2a\u6ce8\u610f\u529b\u5934\u6216\u5c42\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u5168\u5c40\u884c\u4e3a\u7684\u8003\u8651\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u901a\u8fc7\u5e73\u5747\u548c\u77e9\u9635\u4e58\u6cd5\u6269\u5c55\u6ce8\u610f\u529b\u516c\u5f0f\uff0c\u6216\u7eb3\u5165\u5f52\u4e00\u5316\u3001FFN\u7b49\u7ec4\u4ef6\uff0c\u4f46\u4ecd\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u5b8c\u6574\u7684\u8868\u793a\u6765\u5c01\u88c5\u6240\u6709transformer\u5757\u3002", "method": "\u63d0\u51faTensorLens\u65b9\u6cd5\uff0c\u5c06\u6574\u4e2atransformer\u8868\u793a\u4e3a\u5355\u4e00\u8f93\u5165\u4f9d\u8d56\u7ebf\u6027\u7b97\u5b50\uff0c\u901a\u8fc7\u9ad8\u9636\u6ce8\u610f\u529b\u4ea4\u4e92\u5f20\u91cf\u8054\u5408\u7f16\u7801\u6ce8\u610f\u529b\u673a\u5236\u3001\u524d\u9988\u7f51\u7edc\u3001\u6fc0\u6d3b\u51fd\u6570\u3001\u5f52\u4e00\u5316\u5c42\u548c\u6b8b\u5dee\u8fde\u63a5\u3002", "result": "TensorLens\u5728\u7406\u8bba\u4e0a\u5177\u6709\u4e00\u81f4\u6027\uff0c\u7ecf\u9a8c\u9a8c\u8bc1\u8868\u660e\u5b83\u6bd4\u4e4b\u524d\u7684\u6ce8\u610f\u529b\u805a\u5408\u65b9\u6cd5\u4ea7\u751f\u66f4\u4e30\u5bcc\u7684\u8868\u793a\u3002\u5b9e\u9a8c\u8bc1\u660e\u6ce8\u610f\u529b\u5f20\u91cf\u53ef\u4ee5\u4f5c\u4e3a\u5f00\u53d1\u53ef\u89e3\u91ca\u6027\u548c\u6a21\u578b\u7406\u89e3\u5de5\u5177\u7684\u5f3a\u5927\u57fa\u7840\u3002", "conclusion": "TensorLens\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u4e0a\u8fde\u8d2f\u4e14\u8868\u8fbe\u529b\u5f3a\u7684\u7ebf\u6027\u8868\u793a\uff0c\u80fd\u591f\u6355\u83b7transformer\u7684\u5168\u5c40\u8ba1\u7b97\u884c\u4e3a\uff0c\u4e3a\u6a21\u578b\u7406\u89e3\u548c\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2601.17986", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17986", "abs": "https://arxiv.org/abs/2601.17986", "authors": ["Anders Eklund"], "title": "Federated learning for unpaired multimodal data through a homogeneous transformer model", "comment": null, "summary": "Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.", "AI": {"tldr": "\u63d0\u51fa\u8054\u90a6\u5b66\u4e60\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5206\u6563\u8282\u70b9\u4e0a\u8bad\u7ec3\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff0c\u65e0\u9700\u5bf9\u9f50\u6570\u636e\u5bf9\u6216\u5171\u4eab\u539f\u59cb\u7279\u5f81\uff0c\u901a\u8fc7\u516c\u5171\u951a\u70b9\u96c6\u5bf9\u9f50\u4e0d\u540c\u6a21\u6001\u7684\u79c1\u6709\u6d41\u5f62\u3002", "motivation": "\u73b0\u5b9e\u8054\u90a6\u73af\u5883\u4e2d\u6570\u636e\u901a\u5e38\u4e0d\u5bf9\u9f50\u4e14\u5206\u6563\u5728\u4e0d\u540c\u8282\u70b9\uff08\u5982\u4f20\u611f\u5668\u6570\u636e\u548c\u6587\u672c\u65e5\u5fd7\uff09\uff0c\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5047\u8bbe\u672c\u5730\u5ba2\u6237\u7aef\u62e5\u6709\u5bf9\u9f50\u6570\u636e\u5bf9\u6216\u9700\u8981\u5171\u4eab\u539f\u59cb\u7279\u5f81\uff0c\u8fd9\u8fdd\u53cd\u6570\u636e\u4e3b\u6743\u3002\u9700\u8981\u65b0\u65b9\u6cd5\u5904\u7406\u5206\u6563\u3001\u4e0d\u5bf9\u9f50\u4e14\u79c1\u6709\u7684\u591a\u6a21\u6001\u6570\u636e\u3002", "method": "1) \u4f7f\u7528\u5c0f\u578b\u516c\u5171\u951a\u70b9\u96c6\u5bf9\u9f50\u4e0d\u540c\u6a21\u6001\u7684\u79c1\u6709\u6d41\u5f62\uff1b2) \u901a\u8fc7Gram\u77e9\u9635\u548c\u4e2d\u5fc3\u6838\u5bf9\u9f50\u5b9e\u73b0\u8bed\u4e49\u5bf9\u9f50\uff0c\u4e0d\u4f20\u8f93\u79c1\u6709\u6837\u672c\uff1b3) \u63d0\u51fa\u5b50\u7a7a\u95f4\u7a33\u5b9a\u5fae\u8c03\u65b9\u6cd5\u5904\u7406\u5927\u578btransformer\u6a21\u578b\uff1b4) \u5f15\u5165\u7cbe\u5ea6\u52a0\u6743\u5e73\u5747\uff0c\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u964d\u4f4e\u4e0d\u786e\u5b9a\u8282\u70b9\u7684\u6743\u91cd\u3002", "result": "\u5efa\u7acb\u4e86\u8054\u90a6\u4e0d\u5bf9\u9f50\u57fa\u7840\u6a21\u578b\u7684\u6570\u5b66\u57fa\u7840\uff0c\u4f7f\u5168\u5c40\u6a21\u578b\u80fd\u591f\u4ece\u5206\u6563\u3001\u4e0d\u5bf9\u9f50\u4e14\u79c1\u6709\u7684\u6570\u636e\u5b64\u5c9b\u4e2d\u5b66\u4e60\u7edf\u4e00\u8868\u793a\uff0c\u65e0\u9700\u96c6\u4e2d\u5b58\u50a8\u6216\u914d\u5bf9\u6837\u672c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8054\u90a6\u4e0d\u5bf9\u9f50\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u6570\u636e\u4e3b\u6743\u7684\u524d\u63d0\u4e0b\uff0c\u4ece\u5206\u6563\u3001\u4e0d\u5bf9\u9f50\u4e14\u79c1\u6709\u7684\u591a\u6a21\u6001\u6570\u636e\u4e2d\u8bad\u7ec3\u5168\u5c40\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u4e0d\u5bf9\u9f50\u591a\u6a21\u6001\u6570\u636e\u4e0a\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.17987", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.17987", "abs": "https://arxiv.org/abs/2601.17987", "authors": ["Ziwei Zheng", "Huizhi Liang", "Vaclav Snasel", "Vito Latora", "Panos Pardalos", "Giuseppe Nicosia", "Varun Ojha"], "title": "Systematic Characterization of Minimal Deep Learning Architectures: A Unified Analysis of Convergence, Pruning, and Quantization", "comment": null, "summary": "Deep learning networks excel at classification, yet identifying minimal architectures that reliably solve a task remains challenging. We present a computational methodology for systematically exploring and analyzing the relationships among convergence, pruning, and quantization. The workflow first performs a structured design sweep across a large set of architectures, then evaluates convergence behavior, pruning sensitivity, and quantization robustness on representative models. Focusing on well-known image classification of increasing complexity, and across Deep Neural Networks, Convolutional Neural Networks, and Vision Transformers, our initial results show that, despite architectural diversity, performance is largely invariant and learning dynamics consistently exhibit three regimes: unstable, learning, and overfitting. We further characterize the minimal learnable parameters required for stable learning, uncover distinct convergence and pruning phases, and quantify the effect of reduced numeric precision on trainable parameters. Aligning with intuition, the results confirm that deeper architectures are more resilient to pruning than shallower ones, with parameter redundancy as high as 60%, and quantization impacts models with fewer learnable parameters more severely and has a larger effect on harder image datasets. These findings provide actionable guidance for selecting compact, stable models under pruning and low-precision constraints in image classification.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u63a2\u7d22\u6536\u655b\u6027\u3001\u526a\u679d\u548c\u91cf\u5316\u5173\u7cfb\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u53d1\u73b0\u5c3d\u7ba1\u67b6\u6784\u591a\u6837\uff0c\u6027\u80fd\u57fa\u672c\u4e0d\u53d8\u4e14\u5b66\u4e60\u52a8\u6001\u5448\u73b0\u4e09\u4e2a\u7a33\u5b9a\u9636\u6bb5\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u526a\u679d\u548c\u91cf\u5316\u7684\u9c81\u68d2\u6027\u89c4\u5f8b\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u786e\u5b9a\u80fd\u591f\u53ef\u9760\u5b8c\u6210\u4efb\u52a1\u7684\u6700\u5c0f\u67b6\u6784\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u7814\u7a76\u8005\u5e0c\u671b\u7cfb\u7edf\u63a2\u7d22\u6536\u655b\u6027\u3001\u526a\u679d\u548c\u91cf\u5316\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4e3a\u5728\u526a\u679d\u548c\u4f4e\u7cbe\u5ea6\u7ea6\u675f\u4e0b\u9009\u62e9\u7d27\u51d1\u7a33\u5b9a\u6a21\u578b\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5bf9\u5927\u91cf\u67b6\u6784\u8fdb\u884c\u7ed3\u6784\u5316\u8bbe\u8ba1\u626b\u63cf\uff1b2\uff09\u5728\u4ee3\u8868\u6027\u6a21\u578b\u4e0a\u8bc4\u4f30\u6536\u655b\u884c\u4e3a\u3001\u526a\u679d\u654f\u611f\u6027\u548c\u91cf\u5316\u9c81\u68d2\u6027\uff1b3\uff09\u805a\u7126\u4e8e\u590d\u6742\u5ea6\u9012\u589e\u7684\u77e5\u540d\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff0c\u6db5\u76d6\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u89c6\u89c9\u53d8\u6362\u5668\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u5c3d\u7ba1\u67b6\u6784\u591a\u6837\uff0c\u6027\u80fd\u57fa\u672c\u4e0d\u53d8\uff0c\u5b66\u4e60\u52a8\u6001\u5448\u73b0\u4e0d\u7a33\u5b9a\u3001\u5b66\u4e60\u548c\u8fc7\u62df\u5408\u4e09\u4e2a\u7a33\u5b9a\u9636\u6bb5\uff1b2\uff09\u786e\u5b9a\u4e86\u7a33\u5b9a\u5b66\u4e60\u6240\u9700\u7684\u6700\u5c0f\u53ef\u5b66\u4e60\u53c2\u6570\uff1b3\uff09\u63ed\u793a\u4e86\u4e0d\u540c\u7684\u6536\u655b\u548c\u526a\u679d\u9636\u6bb5\uff1b4\uff09\u91cf\u5316\u4e86\u964d\u4f4e\u6570\u503c\u7cbe\u5ea6\u5bf9\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u5f71\u54cd\uff1b5\uff09\u6df1\u5c42\u67b6\u6784\u6bd4\u6d45\u5c42\u67b6\u6784\u5bf9\u526a\u679d\u66f4\u5177\u97e7\u6027\uff0c\u53c2\u6570\u5197\u4f59\u9ad8\u8fbe60%\uff1b6\uff09\u91cf\u5316\u5bf9\u53c2\u6570\u8f83\u5c11\u7684\u6a21\u578b\u5f71\u54cd\u66f4\u5927\uff0c\u5bf9\u66f4\u96be\u7684\u6570\u636e\u96c6\u5f71\u54cd\u66f4\u663e\u8457\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5728\u526a\u679d\u548c\u4f4e\u7cbe\u5ea6\u7ea6\u675f\u4e0b\u9009\u62e9\u7d27\u51d1\u7a33\u5b9a\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002\u7814\u7a76\u8bc1\u5b9e\u4e86\u6df1\u5c42\u67b6\u6784\u5bf9\u526a\u679d\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u91cf\u5316\u4e86\u91cf\u5316\u5bf9\u4e0d\u540c\u590d\u6742\u5ea6\u6a21\u578b\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.17995", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17995", "abs": "https://arxiv.org/abs/2601.17995", "authors": ["Shudi Weng", "Ming Xiao", "Mikael Skoglund"], "title": "Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning", "comment": null, "summary": "Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees", "AI": {"tldr": "H-SecCoGC\uff1a\u4e00\u79cd\u7ed3\u5408\u7f16\u7801\u7b56\u7565\u7684\u9c81\u68d2\u5206\u5c42\u5b89\u5168\u805a\u5408\u65b9\u6848\uff0c\u5728\u4e0d\u53ef\u9760\u901a\u4fe1\u4e0b\u540c\u65f6\u4fdd\u8bc1\u6a21\u578b\u7cbe\u5ea6\u548c\u9690\u79c1\u4fdd\u62a4", "motivation": "\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff08HFL\uff09\u867d\u7136\u6539\u5584\u4e86\u5ba2\u6237\u7aef\u4e0e\u670d\u52a1\u5668\u4e4b\u95f4\u7684\u94fe\u8def\u8d28\u91cf\uff0c\u4f46\u5728\u4e0d\u53ef\u9760\u901a\u4fe1\u73af\u5883\u4e0b\uff0c\u5982\u4f55\u5728\u4fdd\u8bc1\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u56e0\u4e3a\u9690\u79c1\u566a\u58f0\u7684\u534f\u8c03\u53ef\u80fd\u88ab\u968f\u673a\u7834\u574f\u3002", "method": "\u63d0\u51faH-SecCoGC\u65b9\u6848\uff0c\u5c06\u7f16\u7801\u7b56\u7565\u96c6\u6210\u5230\u5206\u5c42\u5b89\u5168\u805a\u5408\u4e2d\uff0c\u5f3a\u5236\u6267\u884c\u7ed3\u6784\u5316\u805a\u5408\u3002\u8be5\u65b9\u6848\u4e0d\u4ec5\u80fd\u786e\u4fdd\u5728\u4e0d\u540c\u9690\u79c1\u7ea7\u522b\u4e0b\u51c6\u786e\u6784\u5efa\u5168\u5c40\u6a21\u578b\uff0c\u8fd8\u80fd\u907f\u514d\u90e8\u5206\u53c2\u4e0e\u95ee\u9898\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u90fd\u8868\u660e\uff0c\u8be5\u65b9\u6848\u5728\u4e0d\u53ef\u9760\u901a\u4fe1\u73af\u5883\u4e0b\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u80fd\u591f\u9002\u5e94\u4efb\u610f\u5f3a\u5ea6\u7684\u9690\u79c1\u4fdd\u8bc1\u8981\u6c42\u3002", "conclusion": "H-SecCoGC\u65b9\u6848\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u7684\u9c81\u68d2\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u548c\u5b66\u4e60\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u4e0d\u53ef\u9760\u901a\u4fe1\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\u6311\u6218\u3002"}}
{"id": "2601.18030", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18030", "abs": "https://arxiv.org/abs/2601.18030", "authors": ["Markus N. Rabe", "Judith Clymo", "Zheren Dong"], "title": "Spelling Bee Embeddings for Language Modeling", "comment": null, "summary": "We introduce a simple modification to the embedding layer. The key change is to infuse token embeddings with information about their spelling. Models trained with these embeddings improve not only on spelling, but also across standard benchmarks. We conduct scaling studies for models with 40M to 800M parameters, which suggest that the improvements are equivalent to needing about 8% less compute and data to achieve the same test loss.", "AI": {"tldr": "\u901a\u8fc7\u4fee\u6539\u5d4c\u5165\u5c42\uff0c\u5c06\u5355\u8bcd\u62fc\u5199\u4fe1\u606f\u878d\u5165\u8bcd\u5d4c\u5165\u4e2d\uff0c\u63d0\u5347\u6a21\u578b\u5728\u62fc\u5199\u548c\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u76f8\u5f53\u4e8e\u8282\u7701\u7ea68%\u7684\u8ba1\u7b97\u548c\u6570\u636e\u8d44\u6e90", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u5d4c\u5165\u901a\u5e38\u53ea\u5173\u6ce8\u8bed\u4e49\u4fe1\u606f\uff0c\u5ffd\u7565\u4e86\u5355\u8bcd\u7684\u62fc\u5199\u7279\u5f81\u3002\u4f5c\u8005\u8ba4\u4e3a\u5c06\u62fc\u5199\u4fe1\u606f\u878d\u5165\u5d4c\u5165\u5c42\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u62fc\u5199\u4efb\u52a1\u4e0a\uff0c\u540c\u65f6\u4e5f\u80fd\u6539\u5584\u5176\u4ed6\u6807\u51c6\u4efb\u52a1\u7684\u8868\u73b0\u3002", "method": "\u5bf9\u5d4c\u5165\u5c42\u8fdb\u884c\u7b80\u5355\u4fee\u6539\uff0c\u5c06\u8bcd\u5d4c\u5165\u4e0e\u5355\u8bcd\u7684\u62fc\u5199\u4fe1\u606f\u76f8\u878d\u5408\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8ba9\u6a21\u578b\u5b66\u4e60\u5982\u4f55\u5c06\u5355\u8bcd\u7684\u62fc\u5199\u7279\u5f81\u6574\u5408\u5230\u5176\u8868\u793a\u4e2d\u3002", "result": "\u4f7f\u752840M\u5230800M\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u8fdb\u884c\u6269\u5c55\u7814\u7a76\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u4e0d\u4ec5\u62fc\u5199\u80fd\u529b\u5f97\u5230\u63d0\u5347\uff0c\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0\u4e5f\u6709\u6539\u5584\u3002\u6539\u8fdb\u6548\u679c\u76f8\u5f53\u4e8e\u9700\u8981\u7ea68%\u66f4\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u6570\u636e\u6765\u8fbe\u5230\u76f8\u540c\u7684\u6d4b\u8bd5\u635f\u5931\u3002", "conclusion": "\u5728\u8bcd\u5d4c\u5165\u4e2d\u878d\u5165\u62fc\u5199\u4fe1\u606f\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u5e76\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\u3002\u8fd9\u79cd\u6539\u8fdb\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u4e0a\u90fd\u80fd\u5e26\u6765\u663e\u8457\u6548\u76ca\u3002"}}
{"id": "2601.18032", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.18032", "abs": "https://arxiv.org/abs/2601.18032", "authors": ["Brijesh FNU", "Viet Thanh Duy Nguyen", "Ashima Sharma", "Md Harun Rashid Molla", "Chengyi Xu", "Truong-Son Hy"], "title": "Multimodal Machine Learning for Soft High-k Elastomers under Data Scarcity", "comment": null, "summary": "Dielectric materials are critical building blocks for modern electronics such as sensors, actuators, and transistors. With the rapid recent advance in soft and stretchable electronics for emerging human- and robot-interfacing applications, there is a surging need for high-performance dielectric elastomers. However, it remains a grand challenge to develop soft elastomers that simultaneously possess high dielectric constants (k, related to energy storage capacity) and low Young's moduli (E, related to mechanical flexibility). While some new elastomer designs have been reported in individual (mostly one-off) studies, almost no structured dataset is currently available for dielectric elastomers that systematically encompasses their molecular sequence, dielectric, and mechanical properties. Within this context, we curate a compact, high-quality dataset of acrylate-based dielectric elastomers, one of the most widely explored elastomer backbones due to its versatile chemistry and molecular design flexibility, by screening and aggregating experimental results from the literature over the past 10 years. Building on this dataset, we propose a multimodal learning framework that leverages large-scale pretrained polymer representations from graph- and sequence-based encoders. These pretrained embeddings transfer rich chemical and structural knowledge from vast polymer corpora, enabling accurate few-shot prediction of both dielectric and mechanical properties from molecular sequences. Our results represent a new paradigm for transferring knowledge from pretrained multimodal models to overcome severe data scarcity, which can be readily translated to other polymer backbones (e.g., silicones, urethanes) and thus accelerate data-efficient discovery of soft high-k dielectric elastomers. Our source code and dataset are publicly available at https://github.com/HySonLab/Polymers", "AI": {"tldr": "\u5f00\u53d1\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u805a\u5408\u7269\u8868\u793a\u8fdb\u884c\u4ecb\u7535\u5f39\u6027\u4f53\u7684\u5c11\u6837\u672c\u6027\u80fd\u9884\u6d4b\uff0c\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898", "motivation": "\u8f6f\u7535\u5b50\u548c\u53ef\u62c9\u4f38\u7535\u5b50\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u540c\u65f6\u5177\u5907\u9ad8\u4ecb\u7535\u5e38\u6570\u548c\u4f4e\u6768\u6c0f\u6a21\u91cf\u7684\u4ecb\u7535\u5f39\u6027\u4f53\uff0c\u4f46\u73b0\u6709\u6570\u636e\u7a00\u7f3a\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u6027\u6570\u636e\u96c6", "method": "\u6536\u96c610\u5e74\u6587\u732e\u4e2d\u7684\u4e19\u70ef\u9178\u916f\u57fa\u4ecb\u7535\u5f39\u6027\u4f53\u6570\u636e\u96c6\uff0c\u6784\u5efa\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u56fe\u57fa\u548c\u5e8f\u5217\u57fa\u7f16\u7801\u5668\u7684\u9884\u8bad\u7ec3\u805a\u5408\u7269\u8868\u793a\u8fdb\u884c\u5c11\u6837\u672c\u9884\u6d4b", "result": "\u6210\u529f\u5f00\u53d1\u51fa\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u4ecb\u7535\u548c\u673a\u68b0\u6027\u80fd\u7684\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u4ece\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u8f6c\u79fb\u77e5\u8bc6\u4ee5\u514b\u670d\u6570\u636e\u7a00\u7f3a\u95ee\u9898", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u8f6c\u79fb\u8303\u5f0f\uff0c\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u805a\u5408\u7269\u9aa8\u67b6\uff0c\u52a0\u901f\u8f6f\u9ad8\u4ecb\u7535\u5e38\u6570\u5f39\u6027\u4f53\u7684\u6570\u636e\u9ad8\u6548\u53d1\u73b0"}}
{"id": "2601.18064", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.18064", "abs": "https://arxiv.org/abs/2601.18064", "authors": ["Hasi Hays"], "title": "Resonant Sparse Geometry Networks", "comment": null, "summary": "We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse\n  hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with\n  O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength\n  decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two\n  distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow\n  Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous\n  mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k << n represents the average\n  active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks\n  demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer\n  parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8%\n  accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines\n  which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural\n  component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles\n  of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible\n  neural architectures.", "AI": {"tldr": "RSGN\u662f\u4e00\u79cd\u53d7\u5927\u8111\u542f\u53d1\u7684\u7a00\u758f\u51e0\u4f55\u7f51\u7edc\uff0c\u901a\u8fc7\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u5d4c\u5165\u8ba1\u7b97\u8282\u70b9\u5b9e\u73b0\u8f93\u5165\u4f9d\u8d56\u7684\u52a8\u6001\u7a00\u758f\u8fde\u63a5\uff0c\u76f8\u6bd4Transformer\u5177\u6709O(n*k)\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u53c2\u6570\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "Transformer\u67b6\u6784\u4f7f\u7528\u5bc6\u96c6\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3aO(n^2)\uff0c\u53c2\u6570\u9700\u6c42\u5927\u3002\u53d7\u5927\u8111\u7a00\u758f\u8fde\u63a5\u548c\u51e0\u4f55\u7ec4\u7ec7\u7684\u542f\u53d1\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u751f\u7269\u5408\u7406\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3002", "method": "RSGN\u5c06\u8ba1\u7b97\u8282\u70b9\u5d4c\u5165\u5b66\u4e60\u7684\u53cc\u66f2\u7a7a\u95f4\uff0c\u8fde\u63a5\u5f3a\u5ea6\u968f\u6d4b\u5730\u8ddd\u79bb\u8870\u51cf\uff0c\u5b9e\u73b0\u8f93\u5165\u4f9d\u8d56\u7684\u52a8\u6001\u7a00\u758f\u6027\u3002\u91c7\u7528\u53cc\u65f6\u95f4\u5c3a\u5ea6\uff1a\u5feb\u901f\u53ef\u5fae\u5206\u6fc0\u6d3b\u4f20\u64ad\uff08\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\uff09\u548c\u6162\u901fHebbian\u7ed3\u6784\u5b66\u4e60\uff08\u5c40\u90e8\u76f8\u5173\u89c4\u5219\uff09\u3002", "result": "\u5728\u957f\u7a0b\u4f9d\u8d56\u4efb\u52a1\u4e0a\u8fbe\u523096.5%\u51c6\u786e\u7387\uff0c\u53c2\u6570\u6bd4\u6807\u51c6Transformer\u5c11\u7ea615\u500d\u3002\u572820\u7c7b\u5c42\u6b21\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u523023.8%\u51c6\u786e\u7387\uff08\u968f\u673a\u57fa\u7ebf5%\uff09\uff0c\u4ec5\u970041,672\u53c2\u6570\uff0c\u6bd4\u9700\u8981403,348\u53c2\u6570\u8fbe\u523030.1%\u51c6\u786e\u7387\u7684Transformer\u5c11\u8fd110\u500d\u3002", "conclusion": "\u5927\u8111\u542f\u53d1\u7684\u7a00\u758f\u51e0\u4f55\u8ba1\u7b97\u539f\u5219\u4e3a\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u751f\u7269\u5408\u7406\u7684\u795e\u7ecf\u67b6\u6784\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0cHebbian\u5b66\u4e60\u63d0\u4f9b\u4e86\u6301\u7eed\u6539\u8fdb\u3002"}}
{"id": "2601.18076", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18076", "abs": "https://arxiv.org/abs/2601.18076", "authors": ["Alexandra Chouldechova", "A. Feder Cooper", "Solon Barocas", "Abhinav Palia", "Dan Vann", "Hanna Wallach"], "title": "Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming", "comment": null, "summary": "We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\uff0c\u57fa\u4e8e\u653b\u51fb\u6210\u529f\u7387\u6bd4\u8f83\u5f97\u51fa\u7684\u7cfb\u7edf\u5b89\u5168\u6027\u6216\u653b\u51fb\u65b9\u6cd5\u6709\u6548\u6027\u7ed3\u8bba\u5f80\u5f80\u7f3a\u4e4f\u8bc1\u636e\u652f\u6301\uff0c\u56e0\u4e3a\u5b58\u5728\u82f9\u679c\u4e0e\u6a59\u5b50\u7684\u6bd4\u8f83\u548c\u4f4e\u6548\u5ea6\u6d4b\u91cf\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u7ea2\u961f\u8bc4\u4f30\u4e2d\uff0c\u901a\u8fc7\u653b\u51fb\u6210\u529f\u7387\u6bd4\u8f83\u6765\u5f97\u51fa\u7cfb\u7edf\u5b89\u5168\u6027\u6216\u653b\u51fb\u65b9\u6cd5\u6709\u6548\u6027\u7684\u7ed3\u8bba\u5b58\u5728\u65b9\u6cd5\u8bba\u7f3a\u9677\uff0c\u8fd9\u4e9b\u7ed3\u8bba\u5f80\u5f80\u5efa\u7acb\u5728\u65e0\u6548\u7684\u6bd4\u8f83\u548c\u6d4b\u91cf\u57fa\u7840\u4e0a\u3002", "method": "\u7ed3\u5408\u793e\u4f1a\u79d1\u5b66\u6d4b\u91cf\u7406\u8bba\u548c\u63a8\u65ad\u7edf\u8ba1\u5b66\uff0c\u63d0\u51fa\u4e86\u653b\u51fb\u6210\u529f\u7387\u6709\u610f\u4e49\u6bd4\u8f83\u7684\u6761\u4ef6\u6846\u67b6\uff0c\u5e76\u4ee5\u8d8a\u72f1\u653b\u51fb\u4e3a\u4f8b\uff0c\u5206\u6790\u4e86\u82f9\u679c\u4e0e\u6a59\u5b50\u6bd4\u8f83\u95ee\u9898\u548c\u6d4b\u91cf\u6548\u5ea6\u6311\u6218\u3002", "result": "\u901a\u8fc7\u6982\u5ff5\u3001\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5f53\u524dAI\u7ea2\u961f\u8bc4\u4f30\u4e2d\u653b\u51fb\u6210\u529f\u7387\u6bd4\u8f83\u7684\u5c40\u9650\u6027\uff0c\u660e\u786e\u4e86\u54ea\u4e9b\u60c5\u51b5\u4e0bASR\u53ef\u4ee5\u6216\u4e0d\u53ef\u4ee5\u8fdb\u884c\u6709\u610f\u4e49\u7684\u6bd4\u8f83\u3002", "conclusion": "AI\u5b89\u5168\u8bc4\u4f30\u9700\u8981\u66f4\u4e25\u8c28\u7684\u6d4b\u91cf\u548c\u6bd4\u8f83\u65b9\u6cd5\uff0c\u907f\u514d\u57fa\u4e8e\u65e0\u6548\u7684\u653b\u51fb\u6210\u529f\u7387\u6bd4\u8f83\u5f97\u51fa\u8bef\u5bfc\u6027\u7ed3\u8bba\uff0c\u5e94\u5efa\u7acb\u79d1\u5b66\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u652f\u6301\u6709\u610f\u4e49\u7684\u7cfb\u7edf\u5b89\u5168\u6027\u5224\u65ad\u3002"}}
{"id": "2601.18081", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18081", "abs": "https://arxiv.org/abs/2601.18081", "authors": ["Peixuan Han", "Yingjie Yu", "Jingjun Xu", "Jiaxuan You"], "title": "DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal", "comment": null, "summary": "Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.", "AI": {"tldr": "DRPG\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u5b66\u672f\u53cd\u9a73\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u5ba1\u7a3f\u610f\u89c1\u3001\u68c0\u7d22\u8bba\u6587\u8bc1\u636e\u3001\u89c4\u5212\u53cd\u9a73\u7b56\u7565\u548c\u751f\u6210\u56de\u5e94\u56db\u4e2a\u6b65\u9aa4\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u751a\u81f3\u8d85\u8d8a\u4eba\u7c7b\u5e73\u5747\u6c34\u5e73\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u7814\u5de5\u4f5c\u6d41\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5b66\u672f\u53cd\u9a73\u8fd9\u4e00\u5b66\u672f\u4ea4\u6d41\u548c\u540c\u884c\u8bc4\u5ba1\u7684\u5173\u952e\u73af\u8282\u4ecd\u7f3a\u4e4f\u81ea\u52a8\u5316\u652f\u6301\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u73b0\u6210\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6216\u7b80\u5355\u6d41\u7a0b\uff0c\u96be\u4ee5\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u4e14\u65e0\u6cd5\u751f\u6210\u6709\u9488\u5bf9\u6027\u548c\u8bf4\u670d\u529b\u7684\u56de\u5e94\u3002", "method": "DRPG\u91c7\u7528\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u4e2a\u6b65\u9aa4\u81ea\u52a8\u751f\u6210\u5b66\u672f\u53cd\u9a73\uff1a1) \u5c06\u5ba1\u7a3f\u610f\u89c1\u5206\u89e3\u4e3a\u539f\u5b50\u5316\u5173\u6ce8\u70b9\uff1b2) \u4ece\u8bba\u6587\u4e2d\u68c0\u7d22\u76f8\u5173\u8bc1\u636e\uff1b3) \u89c4\u5212\u53cd\u9a73\u7b56\u7565\uff1b4) \u6839\u636e\u7b56\u7565\u751f\u6210\u56de\u5e94\u3002\u5176\u4e2d\u89c4\u5212\u5668\u5728\u8bc6\u522b\u6700\u53ef\u884c\u53cd\u9a73\u65b9\u5411\u65b9\u9762\u51c6\u786e\u7387\u8d85\u8fc798%\u3002", "result": "\u5728\u9876\u7ea7\u4f1a\u8bae\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDRPG\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u53cd\u9a73\u6d41\u7a0b\uff0c\u4ec5\u4f7f\u75288B\u6a21\u578b\u5c31\u5b9e\u73b0\u4e86\u8d85\u8d8a\u4eba\u7c7b\u5e73\u5747\u6c34\u5e73\u7684\u6027\u80fd\u3002\u5206\u6790\u663e\u793a\u89c4\u5212\u5668\u8bbe\u8ba1\u6709\u6548\uff0c\u80fd\u63d0\u4f9b\u591a\u89c6\u89d2\u548c\u53ef\u89e3\u91ca\u7684\u5efa\u8bae\u3002DRPG\u5728\u66f4\u590d\u6742\u7684\u591a\u8f6e\u8bbe\u7f6e\u4e2d\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "DRPG\u6846\u67b6\u6709\u6548\u5c55\u793a\u4e86\u4e3a\u5b66\u672f\u8ba8\u8bba\u63d0\u4f9b\u9ad8\u8d28\u91cf\u53cd\u9a73\u5185\u5bb9\u548c\u6269\u5c55\u652f\u6301\u7684\u6f5c\u529b\uff0c\u5176\u89c4\u5212\u5668\u8bbe\u8ba1\u7279\u522b\u6709\u4ef7\u503c\uff0c\u80fd\u591f\u63d0\u4f9b\u591a\u89c6\u89d2\u548c\u53ef\u89e3\u91ca\u7684\u5efa\u8bae\u3002"}}
{"id": "2601.18089", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18089", "abs": "https://arxiv.org/abs/2601.18089", "authors": ["Venmugil Elango", "Nidhi Bhatia", "Roger Waleffe", "Rasoul Shafipour", "Tomer Asida", "Abhinav Khattar", "Nave Assaf", "Maximilian Golub", "Joey Guman", "Tiyasa Mitra", "Ritchie Zhao", "Ritika Borkar", "Ran Zilberstein", "Mostofa Patwary", "Mohammad Shoeybi", "Bita Rouhani"], "title": "LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts", "comment": null, "summary": "Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).", "AI": {"tldr": "LatentMoE\u662f\u4e00\u79cd\u4ece\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u89d2\u5ea6\u4f18\u5316\u7684\u65b0\u578bMoE\u67b6\u6784\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u53c2\u6570\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u6807\u51c6MoE\uff0c\u5df2\u88abNvidia\u7684Nemotron-3\u6a21\u578b\u91c7\u7528\u3002", "motivation": "\u5c3d\u7ba1MoE\u5df2\u6210\u4e3a\u8bb8\u591a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4f46\u73b0\u6709MoE\u67b6\u6784\u5728\u63a8\u7406\u6210\u672c\uff08\u4ee5\u6bcfFLOP\u548c\u6bcf\u53c2\u6570\u7684\u51c6\u786e\u7387\u8861\u91cf\uff09\u65b9\u9762\u662f\u5426\u63a5\u8fd1\u6700\u4f18\u4ecd\u4e0d\u6e05\u695a\u3002\u9700\u8981\u4ece\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6MoE\u8bbe\u8ba1\u3002", "method": "\u57fa\u4e8e\u7ecf\u9a8c\u548c\u7406\u8bba\u8003\u8651\uff0c\u4ece\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u89d2\u5ea6\u5206\u6790\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u4e0b\u7684\u6027\u80fd\u74f6\u9888\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff08\u6700\u9ad8\u8fbe950\u4ebf\u53c2\u6570\u548c1\u4e07\u4ebftoken\u8bad\u7ec3\uff09\u5f15\u5165LatentMoE\u67b6\u6784\u3002", "result": "LatentMoE\u5728\u6bcfFLOP\u548c\u6bcf\u53c2\u6570\u51c6\u786e\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6807\u51c6MoE\u67b6\u6784\uff0c\u5176\u5f3a\u5927\u6027\u80fd\u4f7f\u5176\u88abNemotron-3 Super\u548cUltra\u6a21\u578b\u91c7\u7528\uff0c\u5e76\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u3002", "conclusion": "\u901a\u8fc7\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u7cfb\u7edf\u5316\u63a2\u7d22\uff0cLatentMoE\u4e3aMoE\u67b6\u6784\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u8ba1\u7b97\u6548\u7387\u548c\u53c2\u6570\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18091", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18091", "abs": "https://arxiv.org/abs/2601.18091", "authors": ["Longwei Ding", "Anhao Zhao", "Fanghua Ye", "Ziyang Chen", "Xiaoyu Shen"], "title": "From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models", "comment": "18 pages, 7 figures", "summary": "Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\\textbf{LLM-instruct}$) and reasoning-augmented ($\\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u6bd4\u4e86\u6307\u4ee4\u9075\u5faa\u578bLLM\u548c\u63a8\u7406\u589e\u5f3a\u578bLLM\u7684\u526a\u679d\u7b56\u7565\uff0c\u53d1\u73b0\u4e0d\u540c\u8303\u5f0f\u9700\u8981\u4e0d\u540c\u7684\u526a\u679d\u65b9\u6cd5\uff1a\u6df1\u5ea6\u526a\u679d\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u5bbd\u5ea6\u526a\u679d\u5728\u751f\u6210\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u66f4\u7a33\u5065\uff0c\u9759\u6001\u526a\u679d\u66f4\u9002\u5408\u4fdd\u7559\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u526a\u679d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6307\u4ee4\u9075\u5faa\u578bLLM\uff0c\u4f46\u4e0d\u786e\u5b9a\u8fd9\u4e9b\u7b56\u7565\u662f\u5426\u9002\u7528\u4e8e\u751f\u6210\u957f\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u7684\u63a8\u7406\u589e\u5f3a\u578b\u6a21\u578b\u3002\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u8303\u5f0fLLM\u7684\u526a\u679d\u6548\u679c\u5dee\u5f02\u3002", "method": "\u5bf9\u6307\u4ee4\u9075\u5faa\u578bLLM\u548c\u63a8\u7406\u589e\u5f3a\u578bLLM\u8fdb\u884c\u5bf9\u7167\u7814\u7a76\uff0c\u91c7\u7528\u4e0e\u539f\u59cb\u8bad\u7ec3\u5206\u5e03\u5bf9\u9f50\u7684\u526a\u679d\u6821\u51c6\u548c\u540e\u526a\u679d\u6062\u590d\u6570\u636e\uff0c\u8bc4\u4f30\u9759\u6001\u6df1\u5ea6\u526a\u679d\u3001\u9759\u6001\u5bbd\u5ea6\u526a\u679d\u548c\u52a8\u6001\u526a\u679d\u572817\u4e2a\u5206\u7c7b\u3001\u751f\u6210\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u660e\u663e\u7684\u8303\u5f0f\u4f9d\u8d56\u5dee\u5f02\uff1a\u6df1\u5ea6\u526a\u679d\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5bbd\u5ea6\u526a\u679d\uff0c\u800c\u5bbd\u5ea6\u526a\u679d\u5728\u751f\u6210\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u66f4\u7a33\u5065\uff1b\u9759\u6001\u526a\u679d\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u63a8\u7406\u6027\u80fd\uff0c\u52a8\u6001\u526a\u679d\u5728\u5206\u7c7b\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u957f\u94fe\u63a8\u7406\u4e0a\u4ecd\u6709\u6311\u6218\u3002", "conclusion": "\u63a8\u7406\u589e\u5f3a\u578bLLM\u9700\u8981\u4e13\u95e8\u8003\u8651\u5176\u7279\u6027\u7684\u526a\u679d\u7b56\u7565\uff0c\u4e0d\u80fd\u7b80\u5355\u5957\u7528\u6307\u4ee4\u9075\u5faa\u578bLLM\u7684\u526a\u679d\u65b9\u6cd5\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u4e3a\u4e0d\u540c\u8303\u5f0fLLM\u8bbe\u8ba1\u9488\u5bf9\u6027\u526a\u679d\u65b9\u6848\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.18107", "categories": ["cs.LG", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.18107", "abs": "https://arxiv.org/abs/2601.18107", "authors": ["Pedram Agand", "Mo Chen"], "title": "Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions", "comment": "11 pages, 2 figures, 2 tables", "summary": "Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.", "AI": {"tldr": "MoReBRAC\u662f\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6f5c\u5728\u5408\u6210\u6765\u7f13\u89e3\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u4f7f\u7528\u5206\u5c42\u4e0d\u786e\u5b9a\u6027\u7ba1\u9053\u786e\u4fdd\u5408\u6210\u6570\u636e\u7684\u53ef\u9760\u6027\uff0c\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u5de5\u4e1a\u673a\u5668\u4eba\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u9759\u6001\u6570\u636e\u96c6\u4e0e\u5b66\u4e60\u7b56\u7565\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u8fd9\u901a\u5e38\u9700\u8981\u9ad8\u5ea6\u4fdd\u5b88\u7684\u65b9\u6cd5\uff0c\u9650\u5236\u4e86\u7b56\u7565\u6539\u8fdb\u7684\u6f5c\u529b\u3002", "method": "MoReBRAC\u91c7\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u53cc\u5faa\u73af\u4e16\u754c\u6a21\u578b\u5408\u6210\u9ad8\u4fdd\u771f\u5ea6\u8f6c\u79fb\u6765\u6269\u5c55\u8bad\u7ec3\u6d41\u5f62\u3002\u901a\u8fc7\u5206\u5c42\u4e0d\u786e\u5b9a\u6027\u7ba1\u9053\uff08\u5305\u62ecVAE\u6d41\u5f62\u68c0\u6d4b\u3001\u6a21\u578b\u654f\u611f\u6027\u5206\u6790\u548cMC dropout\uff09\u786e\u4fdd\u5408\u6210\u6570\u636e\u7684\u53ef\u9760\u6027\uff0c\u53ea\u4f7f\u7528\u5b66\u4e60\u52a8\u6001\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u533a\u57df\u5185\u7684\u8f6c\u79fb\u3002", "result": "\u5728D4RL Gym-MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\"\u968f\u673a\"\u548c\"\u6b21\u4f18\"\u6570\u636e\u673a\u5236\u4e0b\u3002\u7814\u7a76\u8fd8\u6df1\u5165\u5206\u6790\u4e86VAE\u4f5c\u4e3a\u51e0\u4f55\u951a\u70b9\u7684\u4f5c\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u4ece\u63a5\u8fd1\u6700\u4f18\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u65f6\u7684\u5206\u5e03\u6743\u8861\u3002", "conclusion": "MoReBRAC\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6f5c\u5728\u5408\u6210\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5728\u6570\u636e\u8d28\u91cf\u8f83\u5dee\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18110", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18110", "abs": "https://arxiv.org/abs/2601.18110", "authors": ["Pedram Zaree", "Md Abdullah Al Mamun", "Yue Dong", "Ihsen Alouani", "Nael Abu-Ghazaleh"], "title": "AttenMIA: LLM Membership Inference Attack through Attention Signals", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses.", "AI": {"tldr": "AttenMIA\uff1a\u5229\u7528Transformer\u81ea\u6ce8\u610f\u529b\u6a21\u5f0f\u8fdb\u884c\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u65b0\u6846\u67b6\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u6216\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u5728\u4f4e\u8bef\u62a5\u7387\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u80fd\u63d0\u5347\u8bad\u7ec3\u6570\u636e\u63d0\u53d6\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u7684\u9690\u79c1\u548c\u77e5\u8bc6\u4ea7\u6743\u98ce\u9669\uff0c\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e3b\u8981\u4f9d\u8d56\u8f93\u51fa\u7f6e\u4fe1\u5ea6\u6216\u5d4c\u5165\u7279\u5f81\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u53f7\u8106\u5f31\u4e14\u653b\u51fb\u6210\u529f\u7387\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51faAttenMIA\u6846\u67b6\uff0c\u5229\u7528Transformer\u5185\u90e8\u7684\u81ea\u6ce8\u610f\u529b\u6a21\u5f0f\u6765\u63a8\u65ad\u6210\u5458\u8eab\u4efd\u3002\u901a\u8fc7\u8de8\u5c42\u6ce8\u610f\u529b\u5934\u7684\u4fe1\u606f\uff0c\u7ed3\u5408\u57fa\u4e8e\u6270\u52a8\u7684\u53d1\u6563\u5ea6\u6307\u6807\uff0c\u8bad\u7ec3\u6709\u6548\u7684MIA\u5206\u7c7b\u5668\u3002", "result": "\u5728LLaMA-2\u3001Pythia\u3001Opt\u7b49\u5f00\u6e90\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u6ce8\u610f\u529b\u7279\u5f81\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4f4e\u8bef\u62a5\u7387\u6307\u6807\u4e0b\u8868\u73b0\u7a81\u51fa\uff08\u5982Llama2-13b\u5728WikiMIA-32\u4e0a\u8fbe\u52300.996 ROC AUC\u548c87.9% TPR@1%FPR\uff09\u3002\u6ce8\u610f\u529b\u4fe1\u53f7\u80fd\u8de8\u6570\u636e\u96c6\u548c\u67b6\u6784\u6cdb\u5316\uff0c\u5e76\u63ed\u793a\u4e86\u6210\u5458\u6cc4\u6f0f\u6700\u663e\u8457\u7684\u5c42\u548c\u5934\u4f4d\u7f6e\u3002", "conclusion": "\u6ce8\u610f\u529b\u673a\u5236\u867d\u7136\u6700\u521d\u65e8\u5728\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff0c\u5374\u65e0\u610f\u4e2d\u653e\u5927\u4e86LLMs\u7684\u9690\u79c1\u98ce\u9669\uff0c\u7a81\u663e\u4e86\u5f00\u53d1\u65b0\u9632\u5fa1\u63aa\u65bd\u7684\u5fc5\u8981\u6027\u3002AttenMIA\u5728\u6570\u636e\u63d0\u53d6\u6846\u67b6\u4e2d\u66ff\u6362\u5176\u4ed6MIA\u65b9\u6cd5\uff0c\u80fd\u5b9e\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u8bad\u7ec3\u6570\u636e\u63d0\u53d6\u653b\u51fb\u3002"}}
{"id": "2601.18111", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18111", "abs": "https://arxiv.org/abs/2601.18111", "authors": ["Jean Kossaifi", "Nikola Kovachki", "Morteza Mardani", "Daniel Leibovici", "Suman Ravuri", "Ira Shokar", "Edoardo Calvello", "Mohammad Shoaib Abbas", "Peter Harrington", "Ashay Subramaniam", "Noah Brenowitz", "Boris Bonev", "Wonmin Byeon", "Karsten Kreis", "Dale Durran", "Arash Vahdat", "Mike Pritchard", "Jan Kautz"], "title": "Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting", "comment": null, "summary": "The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u591a\u5c3a\u5ea6\u5927\u6c14\u52a8\u529b\u5b66\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u76f4\u63a5\u4e0b\u91c7\u6837\u6f5c\u5728\u7a7a\u95f4\u548c\u5386\u53f2\u6761\u4ef6\u5c40\u90e8\u6295\u5f71\u5668\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u7269\u7406\u5efa\u6a21\uff0c\u65e0\u9700\u590d\u6742\u67b6\u6784\u6216\u4e13\u95e8\u8bad\u7ec3\u7b56\u7565\u5373\u53ef\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6982\u7387\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u9a71\u52a8\u7684\u5929\u6c14\u9884\u62a5\u65b9\u6cd5\u5b58\u5728\u67b6\u6784\u590d\u6742\u3001\u8bad\u7ec3\u7b56\u7565\u788e\u7247\u5316\u7684\u95ee\u9898\uff0c\u63a9\u76d6\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6839\u672c\u9a71\u52a8\u56e0\u7d20\u3002\u4f5c\u8005\u65e8\u5728\u8bc1\u660e\u6700\u5148\u8fdb\u7684\u6982\u7387\u9884\u6d4b\u6280\u80fd\u4e0d\u9700\u8981\u590d\u6742\u7684\u67b6\u6784\u7ea6\u675f\u6216\u4e13\u95e8\u7684\u8bad\u7ec3\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u7ed3\u5408\u76f4\u63a5\u4e0b\u91c7\u6837\u7684\u6f5c\u5728\u7a7a\u95f4\u548c\u5386\u53f2\u6761\u4ef6\u5c40\u90e8\u6295\u5f71\u5668\u6765\u5b66\u4e60\u591a\u5c3a\u5ea6\u5927\u6c14\u52a8\u529b\u5b66\u3002\u8be5\u6846\u67b6\u8bbe\u8ba1\u5bf9\u6982\u7387\u4f30\u8ba1\u5668\u7684\u9009\u62e9\u5177\u6709\u9c81\u68d2\u6027\uff0c\u652f\u6301\u968f\u673a\u63d2\u503c\u3001\u6269\u6563\u6a21\u578b\u548cCRPS-based\u96c6\u6210\u8bad\u7ec3\u3002", "result": "\u4e0e\u96c6\u6210\u9884\u62a5\u7cfb\u7edf(IFS)\u548c\u6df1\u5ea6\u5b66\u4e60\u6982\u7387\u6a21\u578bGenCast\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u5927\u591a\u6570\u53d8\u91cf\u4e0a\u5b9e\u73b0\u4e86\u7edf\u8ba1\u663e\u8457\u7684\u6539\u8fdb\uff0c\u8868\u660e\u6269\u5c55\u901a\u7528\u6a21\u578b\u8db3\u4ee5\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u4e2d\u671f\u9884\u6d4b\u3002", "conclusion": "\u6269\u5c55\u901a\u7528\u6a21\u578b\u8db3\u4ee5\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u4e2d\u671f\u9884\u6d4b\uff0c\u65e0\u9700\u5b9a\u5236\u8bad\u7ec3\u65b9\u6848\uff0c\u4e14\u5728\u5168\u8c31\u6982\u7387\u6846\u67b6\u4e2d\u90fd\u6709\u6548\uff0c\u7b80\u5316\u4e86\u5929\u6c14\u9884\u62a5\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002"}}
{"id": "2601.18115", "categories": ["cs.LG", "cs.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.18115", "abs": "https://arxiv.org/abs/2601.18115", "authors": ["Guyang Cao", "Shuyao Li", "Sushrut Karmalkar", "Jelena Diakonikolas"], "title": "Robust Learning of a Group DRO Neuron", "comment": null, "summary": "We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\\mathcal p_{[1]},\\dots,\\mathcal p_{[K]}$, we seek to approximate $\\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\\boldsymbol\u03bb \\in \u0394_K$, where the objective is $\\sum_{i \\in [K]}\u03bb_{[i]}\\,\\mathbb E_{(\\mathbf x,y)\\sim\\mathcal p_{[i]}}(\u03c3(\\mathbf w\\cdot\\mathbf x)-y)^2 - \u03bdd_f(\\boldsymbol\u03bb,\\frac{1}{K}\\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $\u03bd\\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\\widehat{\\mathbf w}$ that is constant-factor competitive with $\\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5728\u4efb\u610f\u6807\u7b7e\u566a\u58f0\u548c\u7ec4\u7ea7\u5206\u5e03\u504f\u79fb\u4e0b\u5b66\u4e60\u5355\u4e2a\u795e\u7ecf\u5143\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7fa4\u4f53\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u8ba1\u7b97\u9ad8\u6548\u7684\u539f\u59cb-\u5bf9\u5076\u7b97\u6cd5\uff0c\u5728\u5bf9\u6297\u6027\u7fa4\u4f53\u6743\u91cd\u4e0b\u83b7\u5f97\u5e38\u6570\u56e0\u5b50\u7ade\u4e89\u6027\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u5e38\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u548c\u4e0d\u540c\u7fa4\u4f53\u95f4\u7684\u5206\u5e03\u504f\u79fb\uff0c\u4f20\u7edf\u5b66\u4e60\u65b9\u6cd5\u5728\u8fd9\u4e9b\u6311\u6218\u4e0b\u6027\u80fd\u4f1a\u4e0b\u964d\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u4efb\u610f\u6807\u7b7e\u566a\u58f0\u548c\u7fa4\u4f53\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7fa4\u4f53\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u4f7f\u7528f-\u6563\u5ea6\u60e9\u7f5a\u504f\u79bb\u5747\u5300\u7fa4\u4f53\u6743\u91cd\u3002\u5f00\u53d1\u8ba1\u7b97\u9ad8\u6548\u7684\u539f\u59cb-\u5bf9\u5076\u7b97\u6cd5\uff0c\u901a\u8fc7\u53cc\u91cd\u5916\u63a8\u66f4\u65b0\u5904\u7406\u635f\u5931\u51fd\u6570\u7684\u975e\u51f8\u6027\uff0c\u76f4\u63a5\u9762\u5bf9\u5185\u5728\u7684\u975e\u51f8\u4f18\u5316\u6311\u6218\u3002", "result": "\u7b97\u6cd5\u8f93\u51fa\u7684\u53c2\u6570\u5411\u91cf\u5728\u5bf9\u6297\u6027\u7fa4\u4f53\u6743\u91cd\u4e0b\u4e0e\u6700\u4f18\u53c2\u6570\u4fdd\u6301\u5e38\u6570\u56e0\u5b50\u7ade\u4e89\u6027\u3002\u5728LLM\u9884\u8bad\u7ec3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8e\u8be5\u7b97\u6cd5\u6846\u67b6\u7684\u53cc\u91cd\u5916\u63a8\u66f4\u65b0\u663e\u793a\u51fa\u826f\u597d\u524d\u666f\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u4efb\u610f\u6807\u7b7e\u566a\u58f0\u548c\u7fa4\u4f53\u5206\u5e03\u504f\u79fb\u4e0b\u5b66\u4e60\u5355\u4e2a\u795e\u7ecf\u5143\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u7fa4\u4f53\u6743\u91cd\u5206\u5e03\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.18142", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18142", "abs": "https://arxiv.org/abs/2601.18142", "authors": ["Mingxu Zhang", "Huicheng Zhang", "Jiaming Ji", "Yaodong Yang", "Ying Sun"], "title": "Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods", "comment": null, "summary": "Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\\%, establishing superior effectiveness for Safe RL in complex environments.", "AI": {"tldr": "\u63d0\u51faADRC-Lagrangian\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e3b\u52a8\u6297\u6270\u63a7\u5236\u6539\u8fdb\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff0c\u51cf\u5c11\u9707\u8361\u548c\u5b89\u5168\u8fdd\u89c4", "motivation": "\u73b0\u6709\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08\u5305\u62ecPID\u548c\u7ecf\u5178Lagrangian\u65b9\u6cd5\uff09\u5b58\u5728\u9707\u8361\u548c\u9891\u7e41\u5b89\u5168\u8fdd\u89c4\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u53c2\u6570\u654f\u611f\u6027\u548c\u56fa\u6709\u76f8\u4f4d\u6ede\u540e", "method": "\u63d0\u51faADRC-Lagrangian\u65b9\u6cd5\uff0c\u5229\u7528\u4e3b\u52a8\u6297\u6270\u63a7\u5236\uff08ADRC\uff09\u589e\u5f3a\u9c81\u68d2\u6027\u5e76\u51cf\u5c11\u9707\u8361\uff0c\u6784\u5efa\u7edf\u4e00\u6846\u67b6\u5c06\u7ecf\u5178\u548cPID Lagrangian\u65b9\u6cd5\u4f5c\u4e3a\u7279\u4f8b", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a\u5b89\u5168\u8fdd\u89c4\u51cf\u5c1174%\uff0c\u7ea6\u675f\u8fdd\u89c4\u5e45\u5ea6\u964d\u4f4e89%\uff0c\u5e73\u5747\u6210\u672c\u4e0b\u964d67%\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02", "conclusion": "ADRC-Lagrangian\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u51cf\u5c11\u9707\u8361\u548c\u5b89\u5168\u8fdd\u89c4\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b89\u5168\u7ea6\u675f\u4f18\u5316\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18150", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18150", "abs": "https://arxiv.org/abs/2601.18150", "authors": ["Zhaopeng Qiu", "Shuang Yu", "Jingqi Zhang", "Shuai Zhang", "Xue Huang", "Jingyi Yang", "Junjie Lai"], "title": "FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning", "comment": null, "summary": "Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684FP8 rollout\u5806\u6808\uff0c\u901a\u8fc7W8A8\u7ebf\u6027\u5c42\u3001FP8 KV\u7f13\u5b58\u548c\u91cd\u8981\u6027\u91c7\u6837\u6821\u6b63\uff0c\u5b9e\u73b0\u6700\u9ad844%\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eBF16\u57fa\u7ebf\u76f8\u5f53\u7684\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u957f\u8f93\u51fa\u5e8f\u5217\u5bfc\u81f4\u6ce8\u610f\u529b\u673a\u5236\u548cKV\u7f13\u5b58\u5185\u5b58\u6210\u4e3a\u7aef\u5230\u7aef\u6b65\u9aa4\u65f6\u95f4\u7684\u4e3b\u8981\u74f6\u9888\u3002FP8\u63d0\u4f9b\u4e86\u52a0\u901fRL\u7684\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u6743\u91cd\u9891\u7e41\u53d8\u5316\u548c\u8bad\u7ec3-\u63a8\u7406\u4e0d\u5339\u914d\u7684\u6311\u6218\u3002", "method": "1) \u4f7f\u7528\u5206\u5757FP8\u91cf\u5316\u5b9e\u73b0W8A8\u7ebf\u6027\u5c42rollout\uff1b2) \u901a\u8fc7\u6bcf\u6b65QKV\u5c3a\u5ea6\u91cd\u65b0\u6821\u51c6\u5c06FP8\u6269\u5c55\u5230KV\u7f13\u5b58\uff1b3) \u4f7f\u7528\u57fa\u4e8e\u91cd\u8981\u6027\u91c7\u6837\u7684rollout\u6821\u6b63\uff08token\u7ea7TIS/MIS\u53d8\u4f53\uff09\u7f13\u89e3\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u5728\u5bc6\u96c6\u6a21\u578b\u548cMoE\u6a21\u578b\u4e0a\uff0c\u8fd9\u4e9b\u6280\u672f\u5b9e\u73b0\u4e86\u6700\u9ad844%\u7684rollout\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0eBF16\u57fa\u7ebf\u76f8\u5f53\u7684\u5b66\u4e60\u884c\u4e3a\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684FP8 rollout\u5806\u6808\uff0c\u89e3\u51b3\u4e86RL\u4e2dFP8\u5e94\u7528\u7684\u5173\u952e\u5de5\u7a0b\u548c\u7b97\u6cd5\u6311\u6218\uff0c\u663e\u8457\u52a0\u901f\u4e86LLM RL\u7684rollout\u9636\u6bb5\uff0c\u4e3a\u5927\u89c4\u6a21RL\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18171", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18171", "abs": "https://arxiv.org/abs/2601.18171", "authors": ["Yuguang Zhang", "Lijun Sheng", "Jian Liang", "Ran He"], "title": "Learning Fair Domain Adaptation with Virtual Label Distribution", "comment": "ICASSP 2026", "summary": "Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.", "AI": {"tldr": "VILL\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u548cKL\u6563\u5ea6\u518d\u5e73\u8861\u7b56\u7565\uff0c\u89e3\u51b3\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u4e2d\u7684\u7c7b\u522b\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u5347\u6700\u96be\u5206\u7c7b\u522b\u7684\u6027\u80fd\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6574\u4f53\u7cbe\u5ea6\u63d0\u5347\uff0c\u4f46\u5ffd\u7565\u4e86\u4e0d\u540c\u7c7b\u522b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\uff08\u7c7b\u522b\u516c\u5e73\u6027\u95ee\u9898\uff09\u3002\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0UDA\u5206\u7c7b\u5668\u503e\u5411\u4e8e\u504f\u5411\u5bb9\u6613\u5206\u7c7b\u7684\u7c7b\u522b\u800c\u5ffd\u7565\u56f0\u96be\u7c7b\u522b\u3002", "method": "\u63d0\u51faVILL\u6846\u67b6\uff1a1\uff09\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u7b56\u7565\uff0c\u589e\u5f3a\u96be\u4ee5\u5206\u7c7b\u7c7b\u522b\u7684\u5f71\u54cd\uff1b2\uff09\u57fa\u4e8eKL\u6563\u5ea6\u7684\u518d\u5e73\u8861\u7b56\u7565\uff0c\u663e\u5f0f\u8c03\u6574\u51b3\u7b56\u8fb9\u754c\u4ee5\u63d0\u5347\u7c7b\u522b\u516c\u5e73\u6027\u3002", "result": "\u5728\u5e38\u7528\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVILL\u53ef\u4ee5\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709UDA\u65b9\u6cd5\u4e2d\uff0c\u663e\u8457\u6539\u5584\u7c7b\u522b\u516c\u5e73\u6027\u3002", "conclusion": "VILL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86UDA\u4e2d\u7684\u7c7b\u522b\u516c\u5e73\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u548c\u51b3\u7b56\u8fb9\u754c\u8c03\u6574\uff0c\u5728\u4fdd\u6301\u9ad8\u6574\u4f53\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6700\u5dee\u60c5\u51b5\u6027\u80fd\u3002"}}
{"id": "2601.18189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18189", "abs": "https://arxiv.org/abs/2601.18189", "authors": ["Rui Wu", "Yongjun Li"], "title": "Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients", "comment": "20 pages, 8 figures", "summary": "Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.", "AI": {"tldr": "\u63d0\u51faAHOC\u6df7\u5408\u9636\u65e0\u73af\u7ea6\u675f\u548cSPG-AHOC\u7b97\u6cd5\uff0c\u5728\u6709\u9650\u8fed\u4ee3\u5185\u7cbe\u786e\u6062\u590dDAG\u7ed3\u6784\uff0c\u65e0\u9700\u540e\u5904\u7406\u9608\u503c", "motivation": "\u73b0\u6709\u8fde\u7eed\u4f18\u5316\u65b9\u6cd5\uff08\u5982NOTEARS\uff09\u53ea\u80fd\u4fdd\u8bc1\u6e10\u8fd1\u6536\u655b\u5230\u5e73\u7a33\u70b9\uff0c\u901a\u5e38\u4ea7\u751f\u7a20\u5bc6\u6743\u91cd\u77e9\u9635\uff0c\u9700\u8981\u4efb\u610f\u7684\u540e\u5904\u7406\u9608\u503c\u6765\u6062\u590dDAG\u3002\u8fde\u7eed\u4f18\u5316\u4e0e\u79bb\u6563\u56fe\u7ed3\u6784\u4e4b\u95f4\u7684\u5dee\u8ddd\u4ecd\u7136\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u9636\u65e0\u73af\u6027\u7ea6\u675f\uff08AHOC\uff09\uff0c\u5e76\u901a\u8fc7\u5e73\u6ed1\u8fd1\u7aef\u68af\u5ea6\uff08SPG-AHOC\uff09\u8fdb\u884c\u4f18\u5316\u3002\u5229\u7528\u8fd1\u7aef\u7b97\u6cd5\u7684\u6d41\u5f62\u8bc6\u522b\u7279\u6027\uff0c\u63d0\u4f9b\u4e25\u683c\u7684\u7406\u8bba\u4fdd\u8bc1\uff1a\u6709\u9650\u65f6\u95f4\u9884\u8a00\u6027\u8d28\u3002", "result": "\u5728\u6807\u51c6\u53ef\u8bc6\u522b\u6027\u5047\u8bbe\u4e0b\uff0cSPG-AHOC\u5728\u6709\u9650\u8fed\u4ee3\u5185\u6062\u590d\u7cbe\u786e\u7684DAG\u652f\u6491\uff08\u7ed3\u6784\uff09\uff0c\u5373\u4f7f\u4f18\u5316\u7684\u662f\u5e73\u6ed1\u8fd1\u4f3c\u3002\u7b97\u6cd5\u8fd4\u56de\u5177\u6709\u7cbe\u786e\u96f6\u9879\u7684\u56fe\uff0c\u65e0\u9700\u542f\u53d1\u5f0f\u622a\u65ad\u3002\u5b9e\u8bc1\u4e2d\uff0cSPG-AHOC\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u5e76\u5f3a\u70c8\u652f\u6301\u6709\u9650\u65f6\u95f4\u8bc6\u522b\u7406\u8bba\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5f25\u5408\u4e86\u8fde\u7eed\u4f18\u5316\u4e0e\u79bb\u6563\u56fe\u7ed3\u6784\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u6709\u9650\u65f6\u95f4\u7cbe\u786e\u7ed3\u6784\u6062\u590d\uff0c\u6d88\u9664\u4e86\u7ed3\u6784\u6a21\u7cca\u6027\uff0c\u4e3a\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2601.18200", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18200", "abs": "https://arxiv.org/abs/2601.18200", "authors": ["Chenyu Zhang", "Xinchen Lyu", "Chenshan Ren", "Shuhan Liu", "Qimei Cui", "Xiaofeng Tao"], "title": "HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models", "comment": "13 pages, 8 figures", "summary": "Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.", "AI": {"tldr": "HeterCSI\u662f\u4e00\u4e2a\u901a\u9053\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u51b3CSI\u6570\u636e\u7684\u53cc\u91cd\u5f02\u8d28\u6027\uff08\u89c4\u6a21\u548c\u573a\u666f\uff09\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u65e0\u7ebf\u57fa\u7840\u6a21\u578b\u7684\u9ad8\u6548\u8bad\u7ec3\u548c\u8de8\u573a\u666f\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u65e0\u7ebf\u57fa\u7840\u6a21\u578b\u5728\u5904\u7406CSI\u6570\u636e\u65f6\u9762\u4e34\u53cc\u91cd\u5f02\u8d28\u6027\u6311\u6218\uff1aCSI\u5728\u89c4\u6a21\u548c\u573a\u666f\u7ef4\u5ea6\u90fd\u5b58\u5728\u5dee\u5f02\u3002\u73b0\u6709\u9884\u8bad\u7ec3\u65b9\u6cd5\u8981\u4e48\u9650\u5236\u8f93\u5165\u7ef4\u5ea6\u56fa\u5b9a\uff0c\u8981\u4e48\u6309\u89c4\u6a21\u9694\u79bb\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faHeterCSI\u6846\u67b6\uff0c\u5173\u952e\u6d1e\u5bdf\u662f\uff1aCSI\u89c4\u6a21\u5f02\u8d28\u6027\u4e3b\u8981\u5bfc\u81f4\u7834\u574f\u6027\u68af\u5ea6\u5e72\u6270\uff0c\u800c\u573a\u666f\u591a\u6837\u6027\u5728\u9002\u5f53\u7ba1\u7406\u4e0b\u80fd\u4fc3\u8fdb\u5efa\u8bbe\u6027\u68af\u5ea6\u5bf9\u9f50\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1) \u5c06\u5f02\u6784CSI\u6279\u6b21\u6784\u5efa\u516c\u5f0f\u5316\u4e3a\u5206\u533a\u4f18\u5316\u95ee\u9898\uff1b2) \u5f00\u53d1\u89c4\u6a21\u611f\u77e5\u81ea\u9002\u5e94\u6279\u5904\u7406\u7b56\u7565\uff1b3) \u8bbe\u8ba1\u53cc\u91cd\u63a9\u7801\u673a\u5236\u9694\u79bb\u6709\u6548\u4fe1\u53f7\u4e0e\u586b\u5145\u4f2a\u5f71\u3002", "result": "\u572812\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHeterCSI\u65e0\u9700\u573a\u666f\u7279\u5b9a\u5fae\u8c03\u5373\u53ef\u5efa\u7acb\u6cdb\u5316\u57fa\u7840\u6a21\u578b\uff0c\u6027\u80fd\u4f18\u4e8e\u5168\u6837\u672c\u57fa\u7ebf\u3002\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u96f6\u6837\u672c\u57fa\u51c6WiFo\uff0c\u5728CSI\u91cd\u5efa\u3001\u65f6\u57df\u548c\u9891\u57df\u9884\u6d4b\u4e0a\u5206\u522b\u964d\u4f4eNMSE 7.19 dB\u30014.08 dB\u548c5.27 dB\u3002\u8bad\u7ec3\u5ef6\u8fdf\u964d\u4f4e53%\uff0c\u6cdb\u5316\u6027\u80fd\u5e73\u5747\u63d0\u53471.53 dB\u3002", "conclusion": "HeterCSI\u901a\u8fc7\u521b\u65b0\u7684\u68af\u5ea6\u52a8\u6001\u7406\u89e3\u548c\u81ea\u9002\u5e94\u6279\u5904\u7406\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86CSI\u6570\u636e\u7684\u53cc\u91cd\u5f02\u8d28\u6027\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u65e0\u7ebf\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u4e0e\u8de8\u573a\u666f\u6cdb\u5316\u80fd\u529b\u7684\u5e73\u8861\uff0c\u4e3a6G\u7f51\u7edc\u5e94\u7528\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684CSI\u5904\u7406\u57fa\u7840\u6a21\u578b\u3002"}}
{"id": "2601.18207", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.18207", "abs": "https://arxiv.org/abs/2601.18207", "authors": ["James Burgess", "Jan N. Hansen", "Duo Peng", "Yuhui Zhang", "Alejandro Lozano", "Min Woo Sun", "Emma Lundberg", "Serena Yeung-Levy"], "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR", "comment": "EACL 2026", "summary": "Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.", "AI": {"tldr": "\u8bad\u7ec3\u641c\u7d22\u4ee3\u7406\u5728\u751f\u7269\u533b\u5b66\u8bba\u6587\u6458\u8981\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u4ee5\u56de\u7b54\u6280\u672f\u6027\u95ee\u9898\uff0c\u8d85\u8d8a\u4f20\u7edf\u68c0\u7d22\u57fa\u7ebf", "motivation": "\u73b0\u6709RLVR\u641c\u7d22\u4ee3\u7406\u4e3b\u8981\u5904\u7406\u901a\u7528\u9886\u57dfQA\uff0c\u7f3a\u4e4f\u5bf9\u79d1\u5b66\u3001\u5de5\u7a0b\u548c\u533b\u5b66\u7b49\u6280\u672fAI\u7cfb\u7edf\u7684\u9002\u7528\u6027\u3002\u9700\u8981\u8bad\u7ec3\u4ee3\u7406\u5728\u79d1\u5b66\u8bba\u6587\u4e0a\u8fdb\u884c\u641c\u7d22\u548c\u63a8\u7406\uff0c\u8fd9\u5bf9\u6280\u672f\u95ee\u7b54\u81f3\u5173\u91cd\u8981\uff0c\u4e5f\u4e0e\u771f\u5b9e\u79d1\u5b66\u5bb6\u76f8\u5173\uff0c\u662f\u672a\u6765AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u5173\u952e\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b1600\u4e07\u7bc7\u751f\u7269\u533b\u5b66\u8bba\u6587\u6458\u8981\u7684\u641c\u7d22\u8bed\u6599\u5e93\uff0c\u521b\u5efa\u5305\u542b6\u4e07\u4e2a\u6837\u672c\u7684PaperSearchQA\u4e8b\u5b9e\u95ee\u7b54\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002\u4f7f\u7528RLVR\u8bad\u7ec3\u641c\u7d22\u4ee3\u7406\uff0c\u5728Search-R1\u4ee3\u7801\u5e93\u57fa\u7840\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u8bad\u7ec3\u7684\u641c\u7d22\u4ee3\u7406\u5728\u6280\u672f\u95ee\u7b54\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u975e\u5f3a\u5316\u5b66\u4e60\u7684\u68c0\u7d22\u57fa\u7ebf\u3002\u5b9a\u91cf\u5206\u6790\u663e\u793a\u4ee3\u7406\u8868\u73b0\u51fa\u89c4\u5212\u3001\u63a8\u7406\u548c\u81ea\u6211\u9a8c\u8bc1\u7b49\u6709\u8da3\u884c\u4e3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u8bad\u7ec3\u4e86\u5728\u79d1\u5b66\u8bba\u6587\u4e0a\u8fdb\u884c\u6280\u672f\u95ee\u7b54\u7684\u641c\u7d22\u4ee3\u7406\uff0c\u5c55\u793a\u4e86RLVR\u5728\u6280\u672f\u9886\u57df\u7684\u6709\u6548\u6027\u3002\u6570\u636e\u521b\u5efa\u65b9\u6cd5\u53ef\u6269\u5c55\u5e76\u6613\u4e8e\u6269\u5c55\u5230\u5176\u4ed6\u79d1\u5b66\u9886\u57df\uff0c\u4e3a\u672a\u6765AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.18231", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18231", "abs": "https://arxiv.org/abs/2601.18231", "authors": ["Trong Khiem Tran", "Manh Cuong Dao", "Phi Le Nguyen", "Thao Nguyen Truong", "Trong Nghia Hoang"], "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting", "comment": "Accepted AISTATS 20226. Preprint version", "summary": "Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.", "AI": {"tldr": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790\u7279\u5f81\u5bf9\u9f50\u4e0e\u76ee\u6807\u5fae\u8c03\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u901a\u8fc7\u7279\u5f81\u6807\u7b7e\u626d\u66f2\u6982\u5ff5\u5efa\u7acb\u53ef\u8bc1\u660e\u7684\u6cdb\u5316\u8fb9\u754c\uff0c\u6307\u5bfc\u7b97\u6cd5\u8bbe\u8ba1\u5e76\u663e\u8457\u63d0\u5347\u8de8\u6a21\u6001\u9002\u5e94\u6027\u80fd\u3002", "motivation": "\u9884\u8bad\u7ec3\u6a21\u578b\u9002\u5e94\u65b0\u7279\u5f81\u6a21\u6001\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7279\u5f81\u5bf9\u9f50\u4e0e\u76ee\u6807\u5fae\u8c03\u4ea4\u4e92\u4f5c\u7528\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5bfc\u81f4\u672a\u6821\u51c6\u7684\u7ec4\u5408\u53ef\u80fd\u52a0\u5267\u6e90-\u76ee\u6807\u7279\u5f81\u6807\u7b7e\u7ed3\u6784\u9519\u914d\uff0c\u964d\u4f4e\u76ee\u6807\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u539f\u5219\u6027\u6846\u67b6\uff0c\u5efa\u7acb\u76ee\u6807\u8bef\u5dee\u7684\u53ef\u8bc1\u660e\u6cdb\u5316\u8fb9\u754c\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u7279\u5f81\u6807\u7b7e\u626d\u66f2\u6982\u5ff5\u89e3\u91ca\u7279\u5f81\u5bf9\u9f50\u4e0e\u76ee\u6807\u62df\u5408\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u4e3a\u5b9e\u9645\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u4f18\u5316\u6307\u5bfc\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5e7f\u6cdb\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u663e\u8457\u6539\u8fdb\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u6846\u67b6\u6df1\u5165\u7406\u89e3\u7279\u5f81\u5bf9\u9f50\u4e0e\u76ee\u6807\u5fae\u8c03\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u4e3a\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u8bbe\u8ba1\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u9002\u5e94\u65b0\u7279\u5f81\u6a21\u6001\u7684\u6027\u80fd\u3002"}}
{"id": "2601.18245", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18245", "abs": "https://arxiv.org/abs/2601.18245", "authors": ["Santanu Das", "Jatin Batra"], "title": "Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity", "comment": null, "summary": "Phase retrieval is the classical problem of recovering a signal $x^* \\in \\mathbb{R}^n$ from its noisy phaseless measurements $y_i = \\langle a_i, x^* \\rangle^2 + \u03b6_i$ (where $\u03b6_i$ denotes noise, and $a_i$ is the sensing vector) for $i \\in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \\log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5177\u6709\u91cd\u5c3e\u566a\u58f0\u548c\u5bf9\u6297\u6027\u635f\u574f\u7684\u9c81\u68d2\u76f8\u4f4d\u6062\u590d\u95ee\u9898\uff0c\u6837\u672c\u590d\u6742\u5ea6\u63a5\u8fd1\u7ebf\u6027\u3002", "motivation": "\u76f8\u4f4d\u6062\u590d\u662f\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u4f46\u5728\u5b58\u5728\u91cd\u5c3e\u566a\u58f0\u548c\u5bf9\u6297\u6027\u635f\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u7b97\u6cd5\u8981\u4e48\u9700\u8981\u6307\u6570\u65f6\u95f4\uff0c\u8981\u4e48\u7f3a\u4e4f\u6709\u6548\u7684\u9c81\u68d2\u8c31\u521d\u59cb\u5316\u65b9\u6cd5\u3002Buna\u548cRebeschini\u6700\u8fd1\u63d0\u51fa\u4e86\u6307\u6570\u65f6\u95f4\u7b97\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u591a\u9879\u5f0f\u65f6\u95f4\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u9c81\u68d2\u8c31\u521d\u59cb\u5316\u4e0e\u9c81\u68d2\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u6700\u65b0\u7b97\u6cd5\u8fdb\u5c55\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5229\u7528\u9c81\u68d2PCA\u6280\u672f\u5b9e\u73b0\u6709\u6548\u7684\u8c31\u521d\u59cb\u5316\uff0c\u4ece\u800c\u5f00\u53d1\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u5b58\u5728\u91cd\u5c3e\u566a\u58f0\u548c\u5bf9\u6297\u6027\u635f\u574f\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u9c81\u68d2\u76f8\u4f4d\u6062\u590d\uff0c\u6837\u672c\u590d\u6742\u5ea6\u4e3a\u63a5\u8fd1\u7ebf\u6027\u7684O(n log n)\u3002", "conclusion": "\u901a\u8fc7\u8fde\u63a5\u9c81\u68d2\u8c31\u521d\u59cb\u5316\u548c\u9c81\u68d2PCA\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u9c81\u68d2\u76f8\u4f4d\u6062\u590d\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18255", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18255", "abs": "https://arxiv.org/abs/2601.18255", "authors": ["Fei Meng"], "title": "Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs", "comment": null, "summary": "Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \\textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief \"wake-up\" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded \"safety guarantee\" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u7ecf\u9a8c\u56de\u653e\u5728\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u4e8c\u5206\u73b0\u8c61\uff1a\u5bf9\u975e\u7ed3\u6784\u5316\u4efb\u52a1\u4ea7\u751f\u6b63\u5411\u8fc1\u79fb\uff0c\u4f46\u5bf9\u7ed3\u6784\u5316\u4efb\u52a1\uff08\u5982\u4ee3\u7801\u751f\u6210\uff09\u9020\u6210\u4e25\u91cd\u8d1f\u5411\u8fc1\u79fb\uff0c\u5e76\u63d0\u51fa\u6b63\u4ea4\u5b50\u7a7a\u95f4\u5524\u9192\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u56f0\u5883\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u9762\u4e34\u5e73\u8861\u7a33\u5b9a\u6027\uff08\u4fdd\u7559\u65e7\u77e5\u8bc6\uff09\u548c\u53ef\u5851\u6027\uff08\u5b66\u4e60\u65b0\u4efb\u52a1\uff09\u7684\u5173\u952e\u6311\u6218\u3002\u867d\u7136\u7ecf\u9a8c\u56de\u653e\u662f\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u4f46\u5176\u5bf9\u4e0d\u540c\u80fd\u529b\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u6b63\u4ea4\u5b50\u7a7a\u95f4\u5524\u9192\u65b9\u6cd5\uff1a\u901a\u8fc7\u7b80\u77ed\u7684\"\u5524\u9192\"\u9636\u6bb5\u8bc6\u522b\u5148\u524d\u4efb\u52a1\u7684\u5173\u952e\u53c2\u6570\u5b50\u7a7a\u95f4\uff0c\u5e76\u5f3a\u5236\u65b0\u4efb\u52a1\u8fdb\u884c\u6b63\u4ea4\u66f4\u65b0\uff0c\u4e3a\u5df2\u5efa\u7acb\u7684\u77e5\u8bc6\u7ed3\u6784\u63d0\u4f9b\u6570\u5b66\u57fa\u7840\u7684\"\u5b89\u5168\u4fdd\u8bc1\"\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u56db\u4efb\u52a1\u5e8f\u5217\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cOSW\u5728\u4fdd\u6301\u8106\u5f31\u7684\u7f16\u7801\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u72ec\u7279\u6210\u529f\uff08\u800c\u56de\u653e\u65b9\u6cd5\u5931\u8d25\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u65b0\u4efb\u52a1\u7684\u9ad8\u53ef\u5851\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u4e2d\u8bc4\u4f30\u7ed3\u6784\u5b89\u5168\u6027\u4e0e\u5e73\u5747\u4fdd\u7559\u7387\u7684\u5fc5\u8981\u6027\uff0c\u63ed\u793a\u4e86\u7ecf\u9a8c\u56de\u653e\u5b58\u5728\u7528\u7ed3\u6784\u5b8c\u6574\u6027\u6362\u53d6\u5e7f\u6cdb\u5de9\u56fa\u7684\u6743\u8861\u3002"}}
{"id": "2601.18261", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18261", "abs": "https://arxiv.org/abs/2601.18261", "authors": ["Chao-Hong Tan", "Qian Chen", "Wen Wang", "Yukun Ma", "Chong Zhang", "Chong Deng", "Qinglin Zhang", "Xiangang Li", "Jieping Ye"], "title": "FGGM: Fisher-Guided Gradient Masking for Continual Learning", "comment": "Accepted by ICASSP 2026", "summary": "Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.", "AI": {"tldr": "FGGM\u6846\u67b6\u901a\u8fc7Fisher\u4fe1\u606f\u6307\u5bfc\u7684\u68af\u5ea6\u63a9\u7801\uff0c\u9009\u62e9\u6027\u66f4\u65b0\u53c2\u6570\u6765\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u9762\u4e34\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5982MIGU\u57fa\u4e8e\u53c2\u6570\u5e45\u5ea6\u8fdb\u884c\u9009\u62e9\uff0c\u7f3a\u4e4f\u6570\u5b66\u539f\u7406\u57fa\u7840\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u53c2\u6570\u91cd\u8981\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFisher-Guided Gradient Masking\u6846\u67b6\uff0c\u4f7f\u7528\u5bf9\u89d2Fisher\u4fe1\u606f\u77e9\u9635\u52a8\u6001\u751f\u6210\u4e8c\u8fdb\u5236\u63a9\u7801\uff0c\u81ea\u9002\u5e94\u9608\u503c\u9009\u62e9\u8981\u66f4\u65b0\u7684\u53c2\u6570\uff0c\u4fdd\u7559\u5173\u952e\u53c2\u6570\u4ee5\u5e73\u8861\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\uff0c\u65e0\u9700\u5386\u53f2\u6570\u636e\u3002", "result": "\u5728TRACE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFGGM\u76f8\u6bd4\u76d1\u7763\u5fae\u8c03\u5728\u4fdd\u7559\u901a\u7528\u80fd\u529b\u65b9\u9762\u76f8\u5bf9\u63d0\u53479.6%\uff0c\u76f8\u6bd4MIGU\u5728TRACE\u4efb\u52a1\u4e0a\u63d0\u53474.4%\u3002\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u548c\u51cf\u5c11\u9057\u5fd8\u7684\u6548\u679c\u3002", "conclusion": "FGGM\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b66\u539f\u7406\u7684\u53c2\u6570\u91cd\u8981\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6709\u6548\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u95ee\u9898\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.18264", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18264", "abs": "https://arxiv.org/abs/2601.18264", "authors": ["ZeYu Li", "ShiJun Zhang", "TieYong Zeng", "FengLei Fan"], "title": "Neural Network Approximation: A View from Polytope Decomposition", "comment": null, "summary": "Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u9762\u4f53\u5206\u89e3\u7684ReLU\u7f51\u7edc\u901a\u7528\u903c\u8fd1\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u5747\u5300\u5212\u5206\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u5904\u7406\u76ee\u6807\u51fd\u6570\u7684\u5c40\u90e8\u6b63\u5219\u6027\uff0c\u7279\u522b\u662f\u5728\u5947\u5f02\u70b9\u9644\u8fd1\u66f4\u9ad8\u6548\u7075\u6d3b\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u903c\u8fd1\u7406\u8bba\u5927\u591a\u901a\u8fc7\u5747\u5300\u5212\u5206\u8f93\u5165\u7a7a\u95f4\u6765\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u5ffd\u7565\u4e86\u76ee\u6807\u51fd\u6570\u7684\u5c40\u90e8\u6b63\u5219\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u4ece\u591a\u9762\u4f53\u5206\u89e3\u7684\u89d2\u5ea6\u7814\u7a76ReLU\u7f51\u7edc\u7684\u903c\u8fd1\u80fd\u529b\uff0c\u63d0\u4f9b\u66f4\u73b0\u5b9e\u3001\u4efb\u52a1\u5bfc\u5411\u7684\u65b9\u6cd5\u3002", "method": "1. \u5f00\u53d1\u663e\u5f0f\u6838\u591a\u9879\u5f0f\u65b9\u6cd5\u83b7\u5f97\u8fde\u7eed\u51fd\u6570\u7684\u901a\u7528\u903c\u8fd1\uff0c\u7279\u5f81\u5305\u62ec\u7cbe\u7ec6\u7684Totik-Ditzian\u578b\u8fde\u7eed\u6027\u6a21\u548c\u591a\u9762\u4f53\u57df\u5206\u89e3\uff1b2. \u5728\u6bcf\u4e2a\u5b50\u57df\u4e2d\u5206\u522b\u6784\u5efaReLU\u7f51\u7edc\u6765\u903c\u8fd1\u6838\u591a\u9879\u5f0f\uff1b3. \u5c06\u65b9\u6cd5\u6269\u5c55\u5230\u89e3\u6790\u51fd\u6570\u4ee5\u83b7\u5f97\u66f4\u9ad8\u903c\u8fd1\u7387\u3002", "result": "\u591a\u9762\u4f53\u5206\u89e3\u4f7f\u903c\u8fd1\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u7075\u6d3b\uff0c\u7279\u522b\u662f\u5728\u76ee\u6807\u51fd\u6570\u7684\u5947\u5f02\u70b9\u9644\u8fd1\u3002\u901a\u8fc7\u6269\u5c55\u5230\u89e3\u6790\u51fd\u6570\u53ef\u4ee5\u8fbe\u5230\u66f4\u9ad8\u7684\u903c\u8fd1\u7387\u3002", "conclusion": "\u4ece\u591a\u9762\u4f53\u5206\u89e3\u89d2\u5ea6\u7814\u7a76ReLU\u7f51\u7edc\u7684\u901a\u7528\u903c\u8fd1\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u73b0\u5b9e\u3001\u4efb\u52a1\u5bfc\u5411\u7684\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u5904\u7406\u76ee\u6807\u51fd\u6570\u7684\u5c40\u90e8\u7279\u6027\uff0c\u7279\u522b\u662f\u5728\u5947\u5f02\u70b9\u9644\u8fd1\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2601.18278", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18278", "abs": "https://arxiv.org/abs/2601.18278", "authors": ["Indr\u0117 \u017dliobait\u0117"], "title": "What Do Learned Models Measure?", "comment": null, "summary": "In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f5c\u4e3a\u6d4b\u91cf\u5de5\u5177\u4f7f\u7528\u65f6\uff0c\u6807\u51c6\u8bc4\u4f30\u6307\u6807\uff08\u5982\u6cdb\u5316\u8bef\u5dee\u3001\u6821\u51c6\u6027\u3001\u9c81\u68d2\u6027\uff09\u65e0\u6cd5\u4fdd\u8bc1\u6d4b\u91cf\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u7ef4\u5ea6\u3002", "motivation": "\u5728\u79d1\u5b66\u548c\u6570\u636e\u9a71\u52a8\u5e94\u7528\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u6d4b\u91cf\u5de5\u5177\u800c\u975e\u4ec5\u4ec5\u662f\u9884\u6d4b\u5668\u3002\u5f53\u6d4b\u91cf\u51fd\u6570\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u65f6\uff0c\u4ece\u89c2\u5bdf\u5230\u6570\u91cf\u7684\u6620\u5c04\u7531\u8bad\u7ec3\u5206\u5e03\u548c\u5f52\u7eb3\u504f\u7f6e\u9690\u5f0f\u51b3\u5b9a\uff0c\u5bfc\u81f4\u591a\u4e2a\u4e0d\u7b49\u4ef7\u7684\u6620\u5c04\u90fd\u80fd\u6ee1\u8db3\u6807\u51c6\u9884\u6d4b\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u5c06\u5b66\u4e60\u5230\u7684\u6d4b\u91cf\u51fd\u6570\u5f62\u5f0f\u5316\u4e3a\u72ec\u7acb\u7684\u8bc4\u4f30\u7126\u70b9\uff0c\u5f15\u5165\u6d4b\u91cf\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u6355\u6349\u5b66\u4e60\u8fc7\u7a0b\u53ef\u63a5\u53d7\u5b9e\u73b0\u548c\u8de8\u4e0a\u4e0b\u6587\u4e2d\u6d4b\u91cf\u91cf\u7684\u4e0d\u53d8\u6027\u3002\u901a\u8fc7\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u95ee\u9898\u3002", "result": "\u6807\u51c6\u673a\u5668\u5b66\u4e60\u8bc4\u4f30\u6807\u51c6\uff08\u5305\u62ec\u6cdb\u5316\u8bef\u5dee\u3001\u6821\u51c6\u6027\u548c\u9c81\u68d2\u6027\uff09\u4e0d\u80fd\u4fdd\u8bc1\u6d4b\u91cf\u7a33\u5b9a\u6027\u3002\u5177\u6709\u53ef\u6bd4\u9884\u6d4b\u6027\u80fd\u7684\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u7cfb\u7edf\u4e0a\u4e0d\u7b49\u4ef7\u7684\u6d4b\u91cf\u51fd\u6570\uff0c\u5206\u5e03\u504f\u79fb\u5177\u4f53\u8bf4\u660e\u4e86\u8fd9\u79cd\u5931\u8d25\u3002", "conclusion": "\u5728\u5c06\u5b66\u4e60\u5230\u7684\u6a21\u578b\u8f93\u51fa\u8bc6\u522b\u4e3a\u6d4b\u91cf\u7684\u573a\u666f\u4e2d\uff0c\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u989d\u5916\u7684\u8bc4\u4f30\u7ef4\u5ea6\u6765\u786e\u4fdd\u6d4b\u91cf\u7a33\u5b9a\u6027\u3002"}}
{"id": "2601.18292", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18292", "abs": "https://arxiv.org/abs/2601.18292", "authors": ["Zhewen Tan", "Wenhan Yu", "Jianfeng Si", "Tongxin Liu", "Kaiqi Guan", "Huiyan Jin", "Jiawen Tao", "Xiaokun Yuan", "Duohe Ma", "Xiangzheng Zhang", "Tong Yang", "Lin Sun"], "title": "TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment", "comment": null, "summary": "In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.", "AI": {"tldr": "TriPlay-RL\uff1a\u4e00\u4e2a\u4e09\u89d2\u8272\u95ed\u73af\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u653b\u51fb\u8005\u3001\u9632\u5fa1\u8005\u548c\u8bc4\u4f30\u8005\u7684\u534f\u540c\u8fdb\u5316\u5b9e\u73b0LLM\u5b89\u5168\u5bf9\u9f50\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u8fd1\u5e74\u6765\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u98ce\u9669\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u51cf\u8f7b\u6709\u6bd2\u6709\u5bb3\u5185\u5bb9\u7684\u751f\u6210\u3002\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u4e09\u65b9\u534f\u4f5c\u6846\u67b6\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u534f\u540c\u8fdb\u5316\u673a\u5236\u3002", "method": "\u63d0\u51faTriPlay-RL\u95ed\u73af\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u653b\u51fb\u8005\uff08\u751f\u6210\u5bf9\u6297\u63d0\u793a\uff09\u3001\u9632\u5fa1\u8005\uff08\u5b89\u5168\u9632\u5fa1\uff09\u548c\u8bc4\u4f30\u8005\uff08\u54cd\u5e94\u8bc4\u4f30\uff09\u5728\u7edf\u4e00\u5b66\u4e60\u5faa\u73af\u4e2d\u8fed\u4ee3\u534f\u540c\u6539\u8fdb\uff0c\u5b9e\u73b0\u8fd1\u96f6\u4eba\u5de5\u6807\u6ce8\u3002", "result": "\u653b\u51fb\u8005\u5728\u4fdd\u6301\u9ad8\u8f93\u51fa\u591a\u6837\u6027\u7684\u540c\u65f6\uff0c\u5bf9\u6297\u6548\u679c\u63d0\u534720%-50%\uff1b\u9632\u5fa1\u8005\u5b89\u5168\u6027\u80fd\u63d0\u534710%-30%\u4e14\u4e0d\u635f\u5bb3\u4e00\u822c\u63a8\u7406\u80fd\u529b\uff1b\u8bc4\u4f30\u8005\u901a\u8fc7\u8fed\u4ee3\u6301\u7eed\u7ec6\u5316\u5224\u65ad\u80fd\u529b\uff0c\u51c6\u786e\u533a\u5206\u4e0d\u5b89\u5168\u54cd\u5e94\u3001\u7b80\u5355\u62d2\u7edd\u548c\u6709\u7528\u6307\u5bfc\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u5b89\u5168\u5bf9\u9f50\u5efa\u7acb\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u5728\u7edf\u4e00\u5b66\u4e60\u5faa\u73af\u4e2d\u7684\u6301\u7eed\u534f\u540c\u8fdb\u5316\u3002"}}
{"id": "2601.18314", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18314", "abs": "https://arxiv.org/abs/2601.18314", "authors": ["Lina Felsner", "Sevgi G. Kafali", "Hannah Eichhorn", "Agnes A. J. Leth", "Aidas Batvinskas", "Andre Datchev", "Fabian Klemm", "Jan Aulich", "Puntika Leepagorn", "Ruben Klinger", "Daniel Rueckert", "Julia A. Schnabel"], "title": "A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods", "comment": null, "summary": "We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases.", "AI": {"tldr": "\u5b66\u751f\u53ef\u91cd\u590d\u6027\u9ed1\u5ba2\u677e\uff1a\u590d\u73b0\u4e09\u7bc7MRI\u91cd\u5efa\u8bba\u6587\uff08MoDL\u3001HUMUS-Net\u3001\u7269\u7406\u6b63\u5219\u5316\u52a8\u6001MRI\u65b9\u6cd5\uff09\u7684\u8bbe\u8ba1\u3001\u534f\u8bae\u4e0e\u7ed3\u679c\uff0c\u5e76\u5206\u4eab\u6784\u5efa\u53ef\u91cd\u590d\u4ee3\u7801\u5e93\u7684\u6700\u4f73\u5b9e\u8df5\u3002", "motivation": "\u89e3\u51b3MRI\u91cd\u5efa\u9886\u57df\u7814\u7a76\u53ef\u91cd\u590d\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u5b66\u751f\u9ed1\u5ba2\u677e\u5f62\u5f0f\u9a8c\u8bc1\u4e09\u7bc7\u6709\u5f71\u54cd\u529b\u8bba\u6587\u7684\u7ed3\u679c\uff0c\u5e76\u5efa\u7acb\u53ef\u91cd\u590d\u4ee3\u7801\u5e93\u7684\u5b9e\u8df5\u6807\u51c6\u3002", "method": "\u7ec4\u7ec7\u5b66\u751f\u9ed1\u5ba2\u677e\u6d3b\u52a8\uff0c\u53c2\u4e0e\u8005\u5c1d\u8bd5\u590d\u73b0\u4e09\u7bc7MRI\u91cd\u5efa\u8bba\u6587\uff1a1) MoDL\uff08\u57fa\u4e8e\u6a21\u578b\u7684\u5c55\u5f00\u7f51\u7edc+\u5b66\u4e60\u53bb\u566a\uff09\uff1b2) HUMUS-Net\uff08\u6df7\u5408\u5c55\u5f00\u591a\u5c3a\u5ea6CNN+Transformer\u67b6\u6784\uff09\uff1b3) \u57fa\u4e8e\u5b9a\u91cfMR\u6a21\u578b\u8fdb\u884c\u65e9\u505c\u7684\u7269\u7406\u6b63\u5219\u5316\u52a8\u6001MRI\u65b9\u6cd5\u3002\u8bb0\u5f55\u590d\u73b0\u8fc7\u7a0b\u5e76\u5206\u6790\u7ed3\u679c\u3002", "result": "\u62a5\u544a\u4e86\u9ed1\u5ba2\u677e\u7684\u590d\u73b0\u7ed3\u679c\uff0c\u5305\u62ec\u6210\u529f\u590d\u73b0\u7684\u90e8\u5206\u548c\u9047\u5230\u7684\u6311\u6218\uff0c\u540c\u65f6\u8fdb\u884c\u4e86\u989d\u5916\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5e76\u603b\u7ed3\u4e86\u6784\u5efa\u53ef\u91cd\u590d\u4ee3\u7801\u5e93\u7684\u57fa\u672c\u5b9e\u8df5\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5b66\u751f\u9ed1\u5ba2\u677e\u6210\u529f\u9a8c\u8bc1\u4e86MRI\u91cd\u5efa\u8bba\u6587\u7684\u53ef\u91cd\u590d\u6027\uff0c\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u4ee3\u7801\u5e93\u5efa\u8bbe\u7684\u5177\u4f53\u5b9e\u8df5\u6307\u5bfc\uff0c\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u5f00\u653e\u79d1\u5b66\u548c\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2601.18326", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18326", "abs": "https://arxiv.org/abs/2601.18326", "authors": ["Jie Li", "Jing Li", "Lu Lv", "Zhanyu Ju", "Fengkui Gong"], "title": "Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals", "comment": null, "summary": "We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eZC\u5e8f\u5217\u548c\u65f6\u9891\u56fe\u50cf\u8ba4\u77e5\u878d\u5408\u7684\u65e0\u4eba\u673a\u4fe1\u53f7OOD\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5728RID\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u8fdc\u7a0b\u8bc6\u522b\u4e2d\u4fe1\u53f7\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u672a\u77e5\u6216\u975e\u6807\u51c6\u901a\u4fe1\u534f\u8bae\u7684\u65e0\u4eba\u673a\u4fe1\u53f7", "method": "\u7ed3\u5408ZC\u5e8f\u5217\u548c\u65f6\u9891\u56fe\u50cf\u53cc\u6a21\u6001\u7279\u5f81\uff0c\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u3001\u591a\u6a21\u6001\u4ea4\u4e92\u3001\u5355\u6a21\u6001\u878d\u5408\u3001\u591a\u6a21\u6001\u878d\u5408\uff0c\u751f\u6210\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u6743\u91cd\u8fdb\u884c\u5206\u7c7b", "result": "\u5728RID\u548cOODD\u6307\u6807\u4e0a\u5206\u522b\u63d0\u53471.7%\u548c7.5%\uff0c\u5728\u4e0d\u540c\u98de\u884c\u6761\u4ef6\u548c\u65e0\u4eba\u673a\u7c7b\u578b\u4e0b\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027", "conclusion": "\u63d0\u51fa\u7684\u8ba4\u77e5\u878d\u5408\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u65e0\u4eba\u673a\u4fe1\u53f7OOD\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u65e0\u4eba\u673a\u8fdc\u7a0b\u8bc6\u522b\u63d0\u4f9b\u53ef\u9760\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18329", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18329", "abs": "https://arxiv.org/abs/2601.18329", "authors": ["Chuhan Feng", "Jing Li", "Jie Li", "Lu Lv", "Fengkui Gong"], "title": "Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection", "comment": null, "summary": "We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u533a\u5206\u6027\u9a71\u52a8\u7684\u7a7a\u95f4-\u901a\u9053\u9009\u62e9\u548c\u68af\u5ea6\u8303\u6570\u7684\u65e0\u4eba\u673a\u4fe1\u53f7OOD\u68c0\u6d4b\u7b97\u6cd5\uff0c\u901a\u8fc7\u65f6\u9891\u56fe\u50cf\u7279\u5f81\u81ea\u9002\u5e94\u52a0\u6743\u548c\u68af\u5ea6\u8303\u6570\u5ea6\u91cf\u6270\u52a8\u654f\u611f\u6027\uff0c\u5b9e\u73b0\u4f18\u8d8a\u7684OOD\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u65e0\u4eba\u673a\u4fe1\u53f7\u68c0\u6d4b\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u5206\u5e03\u5916(OOD)\u6837\u672c\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u51c6\u786e\u533a\u5206\u5df2\u77e5\u534f\u8bae\u548c\u672a\u77e5\u4fe1\u53f7\u7684\u68c0\u6d4b\u7b97\u6cd5\uff0c\u63d0\u9ad8\u65e0\u4eba\u673a\u76d1\u63a7\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "method": "1) \u57fa\u4e8e\u534f\u8bae\u7279\u5b9a\u65f6\u9891\u7279\u5f81\u91cf\u5316\u7c7b\u95f4\u76f8\u4f3c\u6027\u548c\u65b9\u5dee\uff0c\u81ea\u9002\u5e94\u52a0\u6743\u65f6\u9891\u56fe\u50cf\u7684\u7a7a\u95f4\u548c\u901a\u9053\u7ef4\u5ea6\u7279\u5f81\uff1b2) \u5f15\u5165\u68af\u5ea6\u8303\u6570\u5ea6\u91cf\u6270\u52a8\u654f\u611f\u6027\uff0c\u6355\u6349OOD\u6837\u672c\u7684\u5185\u5728\u4e0d\u7a33\u5b9a\u6027\uff1b3) \u5c06\u68af\u5ea6\u8303\u6570\u4e0e\u57fa\u4e8e\u80fd\u91cf\u7684\u8bc4\u5206\u878d\u5408\u8fdb\u884c\u8054\u5408\u63a8\u7406\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u548c\u591a\u79cd\u65e0\u4eba\u673a\u7c7b\u578b\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u533a\u5206\u80fd\u529b\u548c\u9c81\u68d2\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86OOD\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u53ef\u533a\u5206\u6027\u9a71\u52a8\u7684\u7a7a\u95f4-\u901a\u9053\u9009\u62e9\u548c\u68af\u5ea6\u8303\u6570\u7684\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u65e0\u4eba\u673a\u4fe1\u53f7\u4e2d\u7684OOD\u6837\u672c\uff0c\u4e3a\u65e0\u4eba\u673a\u76d1\u63a7\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684OOD\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18342", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18342", "abs": "https://arxiv.org/abs/2601.18342", "authors": ["Navya SD", "Sreekanth D", "SS Uma Sankari"], "title": "Structural Gender Bias in Credit Scoring: Proxy Leakage", "comment": null, "summary": "As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of \"fairness through blindness.\" Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5ba1\u8ba1\u4e86\u53f0\u6e7e\u4fe1\u7528\u8fdd\u7ea6\u6570\u636e\u96c6\u4e2d\u7684\u7ed3\u6784\u6027\u6027\u522b\u504f\u89c1\uff0c\u6311\u6218\u4e86\"\u901a\u8fc7\u76f2\u89c6\u5b9e\u73b0\u516c\u5e73\"\u7684\u4e3b\u6d41\u89c2\u70b9\uff0c\u53d1\u73b0\u5373\u4f7f\u79fb\u9664\u53d7\u4fdd\u62a4\u5c5e\u6027\u548c\u5e94\u7528\u6807\u51c6\u516c\u5e73\u5e72\u9884\uff0c\u6027\u522b\u9884\u6d4b\u4fe1\u53f7\u4ecd\u901a\u8fc7\u5a5a\u59fb\u72b6\u51b5\u3001\u5e74\u9f84\u3001\u4fe1\u7528\u989d\u5ea6\u7b49\u975e\u654f\u611f\u7279\u5f81\u4f5c\u4e3a\u4ee3\u7406\u53d8\u91cf\u5b58\u5728\u3002", "motivation": "\u968f\u7740\u91d1\u878d\u673a\u6784\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\uff0c\u7b97\u6cd5\u504f\u89c1\u4ecd\u7136\u662f\u5b9e\u73b0\u516c\u5e73\u91d1\u878d\u5305\u5bb9\u6027\u7684\u5173\u952e\u969c\u788d\u3002\u7814\u7a76\u65e8\u5728\u6311\u6218\"\u901a\u8fc7\u76f2\u89c6\u5b9e\u73b0\u516c\u5e73\"\u7684\u4e3b\u6d41\u89c2\u70b9\uff0c\u63ed\u793a\u5373\u4f7f\u79fb\u9664\u663e\u5f0f\u53d7\u4fdd\u62a4\u5c5e\u6027\uff0c\u7ed3\u6784\u6027\u6027\u522b\u504f\u89c1\u4ecd\u7136\u5b58\u5728\u7684\u73b0\u5b9e\u3002", "method": "1) \u4f7f\u7528SHAP\uff08SHapley Additive exPlanations\uff09\u8bc6\u522b\u4f5c\u4e3a\u6027\u522b\u4ee3\u7406\u53d8\u91cf\u7684\u975e\u654f\u611f\u7279\u5f81\uff1b2) \u91c7\u7528\u5bf9\u6297\u6027\u9006\u5efa\u6a21\u6846\u67b6\u4ece\u7eaf\u975e\u654f\u611f\u91d1\u878d\u7279\u5f81\u4e2d\u91cd\u5efa\u53d7\u4fdd\u62a4\u7684\u6027\u522b\u5c5e\u6027\uff1b3) \u901a\u8fc7ROC AUC\u8bc4\u5206\u91cf\u5316\u4fe1\u606f\u6cc4\u6f0f\u7a0b\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5a5a\u59fb\u72b6\u51b5\u3001\u5e74\u9f84\u3001\u4fe1\u7528\u989d\u5ea6\u7b49\u53d8\u91cf\u4f5c\u4e3a\u6027\u522b\u7684\u5f3a\u4ee3\u7406\u53d8\u91cf\uff0c\u4f7f\u6a21\u578b\u5728\u4fdd\u6301\u7edf\u8ba1\u516c\u5e73\u8868\u8c61\u7684\u540c\u65f6\u7ef4\u6301\u6b67\u89c6\u6027\u8def\u5f84\u3002\u901a\u8fc7\u5bf9\u6297\u6027\u9006\u5efa\u6a21\uff0c\u4ec5\u4ece\u975e\u654f\u611f\u91d1\u878d\u7279\u5f81\u5c31\u80fd\u4ee50.65\u7684ROC AUC\u5206\u6570\u91cd\u5efa\u6027\u522b\u5c5e\u6027\uff0c\u8868\u660e\u4f20\u7edf\u516c\u5e73\u5ba1\u8ba1\u65e0\u6cd5\u68c0\u6d4b\u9690\u6027\u7ed3\u6784\u6027\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4f20\u7edf\u516c\u5e73\u5ba1\u8ba1\u4e0d\u8db3\u4ee5\u68c0\u6d4b\u9690\u6027\u7ed3\u6784\u6027\u504f\u89c1\uff0c\u4e3b\u5f20\u4ece\u8868\u9762\u7edf\u8ba1\u5e73\u7b49\u8f6c\u5411\u56e0\u679c\u611f\u77e5\u5efa\u6a21\u548c\u91d1\u878dAI\u4e2d\u7684\u7ed3\u6784\u6027\u95ee\u8d23\u5236\uff0c\u63a8\u52a8\u66f4\u6df1\u5165\u7684\u7cfb\u7edf\u6027\u516c\u5e73\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.18356", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18356", "abs": "https://arxiv.org/abs/2601.18356", "authors": ["Weiqin Yang", "Haowen Xue", "Qingyi Peng", "Hexuan Hu", "Qian Huang", "Tingbo Zhang"], "title": "Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning", "comment": null, "summary": "Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u56e0\u679c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u5c06\u56e0\u679c\u63a8\u7406\u4e0e\u591a\u6a21\u6001\u68c0\u7d22\u7ed3\u5408\uff0c\u63d0\u5347\u533b\u5b66\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027", "motivation": "\u5f53\u524d\u533b\u5b66\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u7edf\u8ba1\u76f8\u5173\u6027\u800c\u975e\u56e0\u679c\u673a\u5236\uff0c\u5bfc\u81f4\u8106\u5f31\u3001\u6613\u4ea7\u751f\u5e7b\u89c9\u4e14\u5bf9\u6570\u636e\u96c6\u504f\u5dee\u654f\u611f\u3002\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4f9d\u8d56\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u4f1a\u5f15\u5165\u65b0\u7684\u865a\u5047\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u56e0\u679c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u4ece\u5916\u90e8\u6e90\u68c0\u7d22\u4e34\u5e8a\u76f8\u5173\u793a\u4f8b\u548c\u56e0\u679c\u56fe\uff0c\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u548c\u5e72\u9884\u8bc1\u636e\u800c\u975e\u5355\u7eaf\u76f8\u5173\u6027\u6765\u8c03\u8282\u6a21\u578b\u63a8\u7406\u3002", "result": "\u5728\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u3001\u8bca\u65ad\u9884\u6d4b\u548c\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u56e0\u679c\u68c0\u7d22\u4e3a\u533b\u5b66\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u4f7f\u5176\u8d85\u8d8a\u6a21\u5f0f\u5339\u914d\uff0c\u5b9e\u73b0\u9ad8\u98ce\u9669\u4e34\u5e8a\u73af\u5883\u4e2d\u53ef\u4fe1\u7684\u591a\u6a21\u6001\u63a8\u7406\u3002"}}
{"id": "2601.18399", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18399", "abs": "https://arxiv.org/abs/2601.18399", "authors": ["Mehmet Velioglu", "Song Zhai", "Alexander Mitsos", "Adel Mhamdi", "Andreas Jupke", "Manuel Dahmen"], "title": "Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach", "comment": "37 pages, 13 figures, 3 tables", "summary": "Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates.", "AI": {"tldr": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u7ed3\u5408\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u6d41\u91cf\u6d4b\u91cf\u4f30\u8ba1\u91cd\u529b\u6c89\u964d\u5668\u4e2d\u6db2-\u6db2\u5206\u6563\u7684\u76f8\u9ad8\u5ea6\uff0c\u51cf\u5c11\u5bf9\u6602\u8d35\u5149\u5b66\u6d4b\u91cf\u7684\u4f9d\u8d56\u3002", "motivation": "\u91cd\u529b\u6c89\u964d\u5668\u4e2d\u6db2-\u6db2\u5206\u6563\u7684\u5206\u79bb\u5728\u5316\u5de5\u3001\u5236\u836f\u548c\u56de\u6536\u8fc7\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u5bc6\u96c6\u5806\u79ef\u533a\u9ad8\u5ea6\u662f\u91cd\u8981\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\u6307\u6807\uff0c\u4f46\u7531\u4e8e\u5149\u5b66\u9650\u5236\uff0c\u6d4b\u91cf\u901a\u5e38\u6602\u8d35\u4e14\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a1\uff09\u9996\u5148\u5728\u5408\u6210\u6570\u636e\u548c\u4f4e\u4fdd\u771f\u673a\u7406\u6a21\u578b\u63a8\u5bfc\u7684\u7269\u7406\u65b9\u7a0b\u4e0a\u9884\u8bad\u7ec3PINN\uff1b2\uff09\u7136\u540e\u7528\u5c11\u91cf\u5b9e\u9a8c\u6570\u636e\u5fae\u8c03\u3002\u5c06\u53ef\u5fae\u5206\u7684PINN\u4f5c\u4e3a\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u72b6\u6001\u4f30\u8ba1\u6846\u67b6\u4e2d\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u4ece\u6d41\u91cf\u6d4b\u91cf\u8ddf\u8e2a\u548c\u66f4\u65b0\u76f8\u9ad8\u5ea6\u3002", "result": "\u5728\u6240\u6709\u8bc4\u4f30\u4e2d\uff0c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7684PINN\u5728\u76f8\u9ad8\u5ea6\u4f30\u8ba1\u65b9\u9762\u8868\u73b0\u6700\u51c6\u786e\uff0c\u4f18\u4e8e\u673a\u7406\u6a21\u578b\u3001\u975e\u9884\u8bad\u7ec3PINN\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7684\u7eaf\u6570\u636e\u9a71\u52a8\u795e\u7ecf\u7f51\u7edc\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u77e5\u8bc6\u548c\u5c11\u91cf\u5b9e\u9a8c\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u4ec5\u4f7f\u7528\u5ec9\u4ef7\u6d41\u91cf\u6d4b\u91cf\u5c31\u80fd\u51c6\u786e\u4f30\u8ba1\u76f8\u9ad8\u5ea6\uff0c\u4e3a\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18401", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18401", "abs": "https://arxiv.org/abs/2601.18401", "authors": ["Yufeng Huang"], "title": "Superlinear Multi-Step Attention", "comment": "30 pages, 6 figures", "summary": "In this paper, we propose \\textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \\textbf{random context access} (a.k.a.\\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.", "AI": {"tldr": "\u63d0\u51faSuperlinear attention\uff0c\u4e00\u79cd\u53ef\u8bad\u7ec3\u7684\u591a\u6b65\u6ce8\u610f\u529b\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u968f\u673a\u4e0a\u4e0b\u6587\u8bbf\u95ee\u7684\u540c\u65f6\u5b9e\u73b0\u957f\u5e8f\u5217\u7684\u6b21\u4e8c\u6b21\u590d\u6742\u5ea6", "motivation": "\u89e3\u51b3\u6807\u51c6\u81ea\u6ce8\u610f\u529b\u5728\u957f\u5e8f\u5217\u4e0a\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u968f\u673a\u4e0a\u4e0b\u6587\u8bbf\u95ee\u80fd\u529b\uff08\u5373\u4e0d\u6392\u9664\u4efb\u4f55\u53ef\u80fd\u76f8\u5173\u7684token\u4f4d\u7f6e\uff09", "method": "\u5c06\u6807\u51c6\u56e0\u679c\u81ea\u6ce8\u610f\u529b\u91cd\u65b0\u8868\u8ff0\u4e3aN\u6b65\u641c\u7d22\u95ee\u9898\uff0c\u590d\u6742\u5ea6\u4e3aO(L^{1+1/N})\u3002\u63d0\u51faN=2\u7684\u57fa\u7ebf\u5b9e\u73b0\uff0c\u7b2c\u4e00\u6b65\u8fdb\u884cO(L^{3/2})\u7684\u8de8\u5ea6\u641c\u7d22\u9009\u62e9\u76f8\u5173\u5e8f\u5217\u6bb5\uff0c\u7b2c\u4e8c\u6b65\u5728\u9009\u5b9a\u6bb5\u5185\u5e94\u7528O(L^{3/2})\u7684\u8de8\u5ea6\u6ce8\u610f\u529b", "result": "\u5728O(L^{1.54})\u914d\u7f6e\u4e0b\uff0c\u5728\u5355B200 GPU\u4e0a\u5b9e\u73b01M\u4e0a\u4e0b\u6587\u957f\u5ea6114 tokens/sec\u548c10M\u4e0a\u4e0b\u658780 tokens/sec\u7684\u89e3\u7801\u541e\u5410\u91cf\u3002\u5728NIAH\u4efb\u52a1\u4e0a\u8fbe\u5230256K\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u826f\u597d\u6027\u80fd", "conclusion": "Superlinear attention\u5728\u4fdd\u6301\u968f\u673a\u4e0a\u4e0b\u6587\u8bbf\u95ee\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6b21\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u5c55\u793a\u4e86\u67b6\u6784\u53ef\u884c\u6027\uff0c\u4f46\u5168\u9762\u8d28\u91cf\u8bc4\u4f30\u9700\u8981\u672a\u6765\u5de5\u4f5c"}}
{"id": "2601.18409", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18409", "abs": "https://arxiv.org/abs/2601.18409", "authors": ["Aniket Sanyal", "Baraah A. M. Sidahmed", "Rebekka Burkholz", "Tatjana Chavdarova"], "title": "Frequency-Based Hyperparameter Selection in Games", "comment": null, "summary": "Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \\emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.", "AI": {"tldr": "\u63d0\u51faMoLA\u65b9\u6cd5\uff0c\u901a\u8fc7\u9891\u7387\u4f30\u8ba1\u81ea\u9002\u5e94\u9009\u62e9LookAhead\u8d85\u53c2\u6570\uff0c\u52a0\u901f\u535a\u5f08\u4f18\u5316\u4e2d\u7684\u8bad\u7ec3\u8fc7\u7a0b", "motivation": "\u5e73\u6ed1\u535a\u5f08\u4e2d\u7684\u5b66\u4e60\u4e0e\u6807\u51c6\u6700\u5c0f\u5316\u95ee\u9898\u4e0d\u540c\uff0c\u5b58\u5728\u65cb\u8f6c\u52a8\u529b\u5b66\uff0c\u4f7f\u7ecf\u5178\u8d85\u53c2\u6570\u8c03\u4f18\u7b56\u7565\u5931\u6548\u3002\u5c3d\u7ba1LookAhead\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5f15\u5165\u4e86\u5173\u952e\u5f71\u54cd\u6027\u80fd\u7684\u989d\u5916\u53c2\u6570\uff0c\u800c\u535a\u5f08\u4e2d\u7684\u6709\u6548\u8c03\u4f18\u65b9\u6cd5\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u9891\u7387\u4f30\u8ba1\u5206\u6790\u632f\u8361\u52a8\u529b\u5b66\uff0c\u5728\u8fde\u7eed\u65f6\u95f4\u8f68\u8ff9\u548c\u79bb\u6563\u52a8\u529b\u5b66\u9891\u8c31\u4e2d\u5206\u6790\u632f\u8361\u3002\u57fa\u4e8e\u6b64\u63d0\u51faModal LookAhead (MoLA)\uff0c\u6269\u5c55LookAhead\u65b9\u6cd5\uff0c\u81ea\u9002\u5e94\u9009\u62e9\u9002\u5408\u7279\u5b9a\u95ee\u9898\u7684\u8d85\u53c2\u6570\u3002", "result": "\u63d0\u4f9b\u4e86\u6536\u655b\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u8bc1\u660eMoLA\u5728\u7eaf\u65cb\u8f6c\u535a\u5f08\u548c\u6df7\u5408\u673a\u5236\u4e2d\u90fd\u80fd\u52a0\u901f\u8bad\u7ec3\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "MoLA\u4e3a\u535a\u5f08\u4e2d\u7684\u8d85\u53c2\u6570\u9009\u62e9\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u9891\u7387\u4f30\u8ba1\u81ea\u9002\u5e94\u8c03\u4f18\uff0c\u6709\u6548\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\u3002"}}
{"id": "2601.18420", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18420", "abs": "https://arxiv.org/abs/2601.18420", "authors": ["Satya Prakash Dash", "Hossein Abdi", "Wei Pan", "Samuel Kaski", "Mingfei Sun"], "title": "Gradient Regularized Natural Gradients", "comment": null, "summary": "Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.", "AI": {"tldr": "\u63d0\u51faGRNG\u4f18\u5316\u5668\uff0c\u5c06\u68af\u5ea6\u6b63\u5219\u5316\u4e0e\u81ea\u7136\u68af\u5ea6\u7ed3\u5408\uff0c\u63d0\u4f9b\u9891\u6b21\u548c\u8d1d\u53f6\u65af\u4e24\u79cd\u53d8\u4f53\uff0c\u5728\u4f18\u5316\u901f\u5ea6\u548c\u6cdb\u5316\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u68af\u5ea6\u6b63\u5219\u5316\u80fd\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u81ea\u7136\u68af\u5ea6\u5728\u8bad\u7ec3\u521d\u671f\u80fd\u52a0\u901f\u4f18\u5316\uff0c\u4f46\u4e8c\u9636\u4f18\u5316\u5668\u7684\u8bad\u7ec3\u52a8\u6001\u5982\u4f55\u4ece\u68af\u5ea6\u6b63\u5219\u5316\u4e2d\u53d7\u76ca\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51faGRNG\u4f18\u5316\u5668\u5bb6\u65cf\uff0c\u96c6\u6210\u663e\u5f0f\u68af\u5ea6\u6b63\u5219\u5316\u4e0e\u81ea\u7136\u68af\u5ea6\u66f4\u65b0\u3002\u63d0\u4f9b\u4e24\u79cd\u7b97\u6cd5\uff1a1) \u9891\u6b21\u53d8\u4f53\u901a\u8fc7\u7ed3\u6784\u5316\u8fd1\u4f3c\u907f\u514dFisher\u4fe1\u606f\u77e9\u9635\u663e\u5f0f\u6c42\u9006\uff1b2) \u8d1d\u53f6\u65af\u53d8\u4f53\u57fa\u4e8e\u6b63\u5219\u5316\u5361\u5c14\u66fc\u516c\u5f0f\u5b8c\u5168\u6d88\u9664FIM\u6c42\u9006\u9700\u6c42\u3002", "result": "\u7406\u8bba\u8bc1\u660eGRNG\u5177\u6709\u6536\u655b\u4fdd\u8bc1\uff0c\u68af\u5ea6\u6b63\u5219\u5316\u63d0\u5347\u7a33\u5b9a\u6027\u5e76\u786e\u4fdd\u6536\u655b\u5230\u5168\u5c40\u6700\u5c0f\u503c\u3002\u5b9e\u9a8c\u8868\u660eGRNG\u5728\u4f18\u5316\u901f\u5ea6\u548c\u6cdb\u5316\u6027\u80fd\u4e0a\u4e00\u81f4\u4f18\u4e8e\u4e00\u9636\u65b9\u6cd5\uff08SGD\u3001AdamW\uff09\u548c\u4e8c\u9636\u57fa\u7ebf\uff08K-FAC\u3001Sophia\uff09\uff0c\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u4e0a\u8868\u73b0\u5f3a\u52b2\u3002", "conclusion": "\u68af\u5ea6\u6b63\u5219\u5316\u662f\u89e3\u9501\u81ea\u7136\u68af\u5ea6\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u9c81\u68d2\u6027\u7684\u539f\u5219\u6027\u548c\u5b9e\u7528\u5de5\u5177\uff0cGRNG\u4e3a\u4e8c\u9636\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2601.18447", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18447", "abs": "https://arxiv.org/abs/2601.18447", "authors": ["Jinlong Hu", "Jiacheng Liu"], "title": "GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level", "comment": null, "summary": "Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.", "AI": {"tldr": "GCFX\uff1a\u57fa\u4e8e\u6df1\u5ea6\u56fe\u751f\u6210\u7684\u6a21\u578b\u7ea7\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u7f16\u7801\u5668\u3001\u7ed3\u6784\u611f\u77e5\u6807\u6ce8\u5668\u548cMPNN\u89e3\u7801\u5668\u751f\u6210\u9ad8\u8d28\u91cf\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u4f7f\u7528\u5168\u5c40\u603b\u7ed3\u7b97\u6cd5\u9009\u62e9\u4ee3\u8868\u6027\u89e3\u91ca\uff0c\u63d0\u5347\u56fe\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6df1\u5ea6\u56fe\u5b66\u4e60\u6a21\u578b\u867d\u7136\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u80fd\u529b\u5f3a\uff0c\u4f46\u5185\u90e8\u67b6\u6784\u590d\u6742\u4e14\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u5bfc\u81f4\u51b3\u7b56\u96be\u4ee5\u89e3\u91ca\uff0c\u7528\u6237\u96be\u4ee5\u7406\u89e3\u548c\u4fe1\u4efb\u8fd9\u4e9b\u9ed1\u76d2\u6a21\u578b\u3002", "method": "\u63d0\u51faGCFX\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u6df1\u5ea6\u56fe\u751f\u6210\u7684\u6a21\u578b\u7ea7\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\uff1b2) \u7ed3\u5408\u53cc\u7f16\u7801\u5668\u3001\u7ed3\u6784\u611f\u77e5\u6807\u6ce8\u5668\u548c\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\u89e3\u7801\u5668\u7684\u67b6\u6784\uff1b3) \u5168\u5c40\u53cd\u4e8b\u5b9e\u603b\u7ed3\u7b97\u6cd5\u4ece\u5019\u9009\u89e3\u91ca\u4e2d\u9009\u62e9\u6700\u5177\u4ee3\u8868\u6027\u7684\u5b50\u96c6\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGCFX\u5728\u53cd\u4e8b\u5b9e\u6709\u6548\u6027\u548c\u8986\u76d6\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u89e3\u91ca\u6210\u672c\u3002", "conclusion": "GCFX\u4e3a\u6df1\u5ea6\u56fe\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u5168\u5c40\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u652f\u6301\u7528\u6237\u5168\u9762\u7406\u89e3\u6a21\u578b\u7684\u6574\u4f53\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2601.18479", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18479", "abs": "https://arxiv.org/abs/2601.18479", "authors": ["Kyoleen Kwak", "Hyoseok Hwang"], "title": "Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States", "comment": "Accepted at AAAI-26. 7 pages (excluding references), 3 figures", "summary": "Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.", "AI": {"tldr": "ASAP\u662f\u4e00\u79cd\u57fa\u4e8e\u635f\u5931\u51fd\u6570\u7684\u52a8\u4f5c\u5e73\u6ed1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u9f50\u8fc7\u6e21\u8bf1\u5bfc\u76f8\u4f3c\u72b6\u6001\u7684\u52a8\u4f5c\u5e76\u60e9\u7f5a\u4e8c\u9636\u5dee\u5f02\u6765\u51cf\u5c11\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9ad8\u9891\u632f\u8361\uff0c\u63d0\u9ad8\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a7\u5236\u5e73\u6ed1\u6027\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u56fa\u6709\u7684\u9ad8\u9891\u632f\u8361\u7279\u6027\u9650\u5236\u4e86\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u5408\u6210\u7684\u72b6\u6001\u76f8\u4f3c\u6027\u5b9a\u4e49\u6765\u4fc3\u8fdb\u52a8\u4f5c\u4e00\u81f4\u6027\uff0c\u4f46\u8fd9\u4e9b\u5b9a\u4e49\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5e95\u5c42\u7cfb\u7edf\u52a8\u6001\u3002", "method": "\u63d0\u51faASAP\u65b9\u6cd5\uff1a1) \u5f15\u5165\u8fc7\u6e21\u8bf1\u5bfc\u76f8\u4f3c\u72b6\u6001\uff0c\u5b9a\u4e49\u4e3a\u4ece\u524d\u4e00\u72b6\u6001\u8f6c\u79fb\u5f97\u5230\u7684\u4e0b\u4e00\u72b6\u6001\u5206\u5e03\uff1b2) \u901a\u8fc7\u5bf9\u9f50\u8fc7\u6e21\u8bf1\u5bfc\u76f8\u4f3c\u72b6\u6001\u4e2d\u7684\u52a8\u4f5c\u6765\u5f3a\u5236\u52a8\u4f5c\u5e73\u6ed1\uff1b3) \u60e9\u7f5a\u4e8c\u9636\u5dee\u5f02\u4ee5\u6291\u5236\u9ad8\u9891\u632f\u8361\u3002\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u7528\u73af\u5883\u53cd\u9988\u548c\u5b9e\u9645\u6536\u96c6\u7684\u6570\u636e\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u7cfb\u7edf\u52a8\u6001\u3002", "result": "\u5728Gymnasium\u548cIsaac-Lab\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cASAP\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u4ea7\u751f\u66f4\u5e73\u6ed1\u7684\u63a7\u5236\u548c\u66f4\u597d\u7684\u7b56\u7565\u6027\u80fd\u3002", "conclusion": "ASAP\u901a\u8fc7\u5229\u7528\u8fc7\u6e21\u8bf1\u5bfc\u76f8\u4f3c\u72b6\u6001\u548c\u4e8c\u9636\u5dee\u5f02\u60e9\u7f5a\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u52a8\u4f5c\u632f\u8361\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5e73\u6ed1\u3001\u66f4\u53ef\u9760\u7684\u63a7\u5236\u7b56\u7565\u3002"}}
{"id": "2601.18500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18500", "abs": "https://arxiv.org/abs/2601.18500", "authors": ["Chen Liang", "Donghua Yang", "Yutong Wang", "Tianle Zhang", "Shenghe Zhou", "Zhiyu Liang", "Hengtong Zhang", "Hongzhi Wang", "Ziqi Li", "Xiyang Zhang", "Zheng Liang", "Yifei Li"], "title": "Nearly Optimal Bayesian Inference for Structural Missingness", "comment": null, "summary": "Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6846\u67b6\u5904\u7406\u7ed3\u6784\u6027\u7f3a\u5931\u6570\u636e\uff0c\u901a\u8fc7\u540e\u9a8c\u9884\u6d4b\u5206\u5e03\u6574\u5408\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u975e\u5355\u70b9\u63d2\u8865\uff0c\u5728\u5206\u7c7b\u548c\u63d2\u8865\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA", "motivation": "\u7ed3\u6784\u6027\u7f3a\u5931\u6570\u636e\u5b58\u5728\u56e0\u679c\u5faa\u73af\u56f0\u5883\uff1a\u9884\u6d4b\u9700\u8981\u7f3a\u5931\u7279\u5f81\uff0c\u4f46\u63a8\u65ad\u5b83\u4eec\u53c8\u4f9d\u8d56\u4e8e\u7f3a\u5931\u673a\u5236\uff1bMNAR\u4e0b\u7f3a\u5931\u90e8\u5206\u53ef\u80fd\u6765\u81ea\u5206\u5e03\u504f\u79fb\uff1b\u5355\u70b9\u63d2\u8865\u4f1a\u9501\u5b9a\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u7684\u51b3\u7b56", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u89c6\u89d2\uff0c\u901a\u8fc7\u540e\u9a8c\u9884\u6d4b\u5206\u5e03\u8fdb\u884c\u9884\u6d4b\uff0c\u6574\u5408\u5b8c\u6574\u6a21\u578b\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\u3002\u6846\u67b6\u89e3\u8026\u4e3a\uff1a(1)\u5b66\u4e60\u6a21\u578b\u5185\u7f3a\u5931\u503c\u540e\u9a8c\u5206\u5e03\uff0c(2)\u901a\u8fc7\u4f18\u5316\u9884\u6d4b\u540e\u9a8c\u5206\u5e03\u8fdb\u884c\u6807\u7b7e\u9884\u6d4b\uff0c\u5b9e\u73b0\u540e\u9a8c\u6574\u5408", "result": "\u572843\u4e2a\u5206\u7c7b\u57fa\u51c6\u548c15\u4e2a\u63d2\u8865\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\uff0c\u5728SCM\u5148\u9a8c\u4e0b\u5177\u6709\u6709\u9650\u6837\u672c\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u6027\u4fdd\u8bc1", "conclusion": "\u8d1d\u53f6\u65af\u6846\u67b6\u63d0\u4f9b\"\u51e0\u4e4e\u514d\u8d39\u5348\u9910\"\uff1a\u4e00\u65e6\u5b66\u4e60\u5230\u540e\u9a8c\u5206\u5e03\uff0c\u9884\u6d4b\u5373\u63d2\u5373\u7528\u540c\u65f6\u4fdd\u6301\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\uff0c\u6709\u6548\u89e3\u51b3\u7ed3\u6784\u6027\u7f3a\u5931\u6570\u636e\u7684\u6311\u6218"}}
{"id": "2601.18509", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18509", "abs": "https://arxiv.org/abs/2601.18509", "authors": ["Andro Sabashvili"], "title": "Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark", "comment": null, "summary": "Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u7684\u5e94\u7528\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u5982\u4f55\u514b\u670d\u65f6\u95f4\u4f9d\u8d56\u6027\u4e0e\u6570\u636e\u53ef\u4ea4\u6362\u6027\u5047\u8bbe\u4e4b\u95f4\u7684\u51b2\u7a81\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9650\u5236\u6027\u5206\u5e03\u5047\u8bbe\u3002\u4fdd\u5f62\u9884\u6d4b\uff08CP\uff09\u4f5c\u4e3a\u4e00\u79cd\u65e0\u5206\u5e03\u6846\u67b6\uff0c\u4e3a\u751f\u6210\u5177\u6709\u4e25\u683c\u7406\u8bba\u4fdd\u8bc1\u7684\u9884\u6d4b\u533a\u95f4\u63d0\u4f9b\u4e86\u5e0c\u671b\u3002\u7136\u800c\uff0c\u5c06CP\u5e94\u7528\u4e8e\u5e8f\u5217\u6570\u636e\u9762\u4e34\u4e3b\u8981\u6311\u6218\uff1a\u65f6\u95f4\u5e8f\u5217\u56fa\u6709\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u4ece\u6839\u672c\u4e0a\u8fdd\u53cd\u4e86\u6807\u51c6CP\u4fdd\u8bc1\u6240\u4f9d\u8d56\u7684\u6570\u636e\u53ef\u4ea4\u6362\u6027\u6838\u5fc3\u5047\u8bbe\u3002", "method": "\u672c\u6587\u6279\u5224\u6027\u5730\u5ba1\u67e5\u4e86\u89e3\u51b3\u8fd9\u4e00\u51b2\u7a81\u7684\u4e3b\u8981\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\u7c7b\u522b\uff1a1\uff09\u653e\u5bbd\u53ef\u4ea4\u6362\u6027\u5047\u8bbe\u7684\u65b9\u6cd5\uff1b2\uff09\u5c06\u6570\u636e\u5355\u4f4d\u91cd\u65b0\u5b9a\u4e49\u4e3a\u72ec\u7acb\u65f6\u95f4\u5e8f\u5217\u96c6\u5408\u7684\u65b9\u6cd5\uff1b3\uff09\u660e\u786e\u5efa\u6a21\u9884\u6d4b\u6b8b\u5dee\u52a8\u6001\u7684\u65b9\u6cd5\uff1b4\uff09\u9002\u5e94\u5206\u5e03\u6f02\u79fb\u4ee5\u7ef4\u6301\u957f\u671f\u8986\u76d6\u7684\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u672c\u6587\u5f3a\u8c03\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u5728\u5b9e\u9645\u6570\u636e\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u5bf9\u4e0d\u540c\u65b9\u6cd5\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u548c\u6bd4\u8f83\u5206\u6790\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u65f6\u95f4\u5e8f\u5217\u4fdd\u5f62\u9884\u6d4b\u7684\u5404\u79cd\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u65f6\u95f4\u4f9d\u8d56\u6027\u4e0e\u53ef\u4ea4\u6362\u6027\u5047\u8bbe\u4e4b\u95f4\u7684\u51b2\u7a81\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u8003\u91cf\u3002"}}
{"id": "2601.18510", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18510", "abs": "https://arxiv.org/abs/2601.18510", "authors": ["Yibo Li", "Zijie Lin", "Ailin Deng", "Xuan Zhang", "Yufei He", "Shuo Ji", "Tri Cao", "Bryan Hooi"], "title": "Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates", "comment": null, "summary": "While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.", "AI": {"tldr": "JitRL\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8bb0\u5fc6\u548c\u8f68\u8ff9\u68c0\u7d22\u5b9e\u73b0\u6d4b\u8bd5\u65f6\u7b56\u7565\u4f18\u5316\uff0c\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\uff0c\u5728WebArena\u548cJericho\u4e0a\u8fbe\u5230\u8bad\u7ec3\u514d\u8d39\u65b9\u6cd5\u7684\u65b0SOTA\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u90e8\u7f72\u540e\u6743\u91cd\u56fa\u5b9a\uff0c\u96be\u4ee5\u6301\u7eed\u9002\u5e94\u65b0\u4efb\u52a1\u3002\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u89e3\u51b3\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u98ce\u9669\u3002", "method": "JitRL\u7ef4\u62a4\u52a8\u6001\u975e\u53c2\u6570\u5316\u7ecf\u9a8c\u8bb0\u5fc6\uff0c\u68c0\u7d22\u76f8\u5173\u8f68\u8ff9\u5b9e\u65f6\u4f30\u8ba1\u52a8\u4f5c\u4f18\u52bf\u503c\uff0c\u7136\u540e\u76f4\u63a5\u8c03\u5236LLM\u7684\u8f93\u51falogits\u3002\u7406\u8bba\u8bc1\u660e\u8fd9\u79cd\u52a0\u6cd5\u66f4\u65b0\u89c4\u5219\u662fKL\u7ea6\u675f\u7b56\u7565\u4f18\u5316\u76ee\u6807\u7684\u7cbe\u786e\u95ed\u5f0f\u89e3\u3002", "result": "\u5728WebArena\u548cJericho\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJitRL\u5728\u8bad\u7ec3\u514d\u8d39\u65b9\u6cd5\u4e2d\u8fbe\u5230\u65b0\u7684SOTA\uff0c\u751a\u81f3\u8d85\u8d8a\u8ba1\u7b97\u6602\u8d35\u7684\u5fae\u8c03\u65b9\u6cd5\uff08\u5982WebRL\uff09\uff0c\u540c\u65f6\u964d\u4f4e30\u500d\u4ee5\u4e0a\u7684\u6210\u672c\u3002", "conclusion": "JitRL\u4e3a\u6301\u7eed\u5b66\u4e60\u4ee3\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\u7684\u6d4b\u8bd5\u65f6\u7b56\u7565\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u6210\u672c\u5f00\u9500\u3002"}}
{"id": "2601.18513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18513", "abs": "https://arxiv.org/abs/2601.18513", "authors": ["Kai Hu", "Haoqi Hu", "Matt Fredrikson"], "title": "LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models", "comment": "ICLR 2026. 17 pages", "summary": "Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \\emph{LipNeXt}, the first \\emph{constraint-free} and \\emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \\emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $\u03b2$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\\%$ at $\\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.", "AI": {"tldr": "LipNeXt\uff1a\u9996\u4e2a\u65e0\u7ea6\u675f\u3001\u65e0\u5377\u79ef\u76841-Lipschitz\u67b6\u6784\uff0c\u901a\u8fc7\u6d41\u5f62\u4f18\u5316\u548c\u7a7a\u95f4\u79fb\u4f4d\u6a21\u5757\u5b9e\u73b0\u9ad8\u6548\u786e\u5b9a\u6027\u9c81\u68d2\u6027\u8ba4\u8bc1\uff0c\u5728ImageNet\u4e0a\u53ef\u6269\u5c55\u523010\u4ebf\u53c2\u6570\u89c4\u6a21\u3002", "motivation": "\u73b0\u6709\u7684Lipschitz\u8ba4\u8bc1\u65b9\u6cd5\u5728\u6a21\u578b\u89c4\u6a21\u3001\u8bad\u7ec3\u6548\u7387\u548cImageNet\u6027\u80fd\u65b9\u9762\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u786e\u5b9a\u6027\u9c81\u68d2\u6027\u4fdd\u8bc1\u53c8\u80fd\u9002\u5e94\u73b0\u4ee3\u5927\u89c4\u6a21\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "method": "1. \u6d41\u5f62\u4f18\u5316\uff1a\u76f4\u63a5\u5728\u6b63\u4ea4\u6d41\u5f62\u4e0a\u66f4\u65b0\u53c2\u6570\uff1b2. \u7a7a\u95f4\u79fb\u4f4d\u6a21\u5757\uff1a\u65e0\u9700\u5377\u79ef\u5efa\u6a21\u7a7a\u95f4\u6a21\u5f0f\uff1b3. \u6b63\u4ea4\u6295\u5f71\u3001\u7a7a\u95f4\u79fb\u4f4d\u3001\u03b2-Abs\u975e\u7ebf\u6027\u51fd\u6570\u548cL2\u7a7a\u95f4\u6c60\u5316\u7ec4\u5408\uff0c\u4fdd\u6301\u4e25\u683c\u7684Lipschitz\u63a7\u5236\u3002", "result": "\u5728CIFAR-10/100\u548cTiny-ImageNet\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u5e72\u51c0\u51c6\u786e\u7387\u548c\u8ba4\u8bc1\u9c81\u68d2\u51c6\u786e\u7387\uff1b\u5728ImageNet\u4e0a\u53ef\u6269\u5c55\u523010-20\u4ebf\u53c2\u6570\u5927\u6a21\u578b\uff0c\u76f8\u6bd4\u5148\u524dLipschitz\u6a21\u578b\u8ba4\u8bc1\u9c81\u68d2\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe8%\uff08\u03b5=1\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u7a33\u5b9a\u7684\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u3002", "conclusion": "Lipschitz\u8ba4\u8bc1\u65b9\u6cd5\u80fd\u591f\u53d7\u76ca\u4e8e\u73b0\u4ee3\u89c4\u6a21\u5316\u8d8b\u52bf\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u786e\u5b9a\u6027\u6216\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u786e\u5b9a\u6027\u9c81\u68d2\u6027\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2601.18521", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18521", "abs": "https://arxiv.org/abs/2601.18521", "authors": ["Emna Boudabbous", "Mohamed Karaa", "Lokman Sboui", "Julio Montecinos", "Omar Alam"], "title": "Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning", "comment": "This manuscript is a preprint of an earlier version. A revised system-oriented version is currently under review", "summary": "Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.\n  We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the \"giant cluster\" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.\n  We compare five model architectures on six months of bus operations from the Soci\u00e9t\u00e9 de transport de Montr\u00e9al (STM) network in Montr\u00e9al. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57ce\u5e02\u7ea7\u516c\u4ea4\u5ef6\u8bef\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u5206\u8fa8\u7387\u7279\u5f81\u5de5\u7a0b\u3001\u964d\u7ef4\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u5728\u8499\u7279\u5229\u5c14\u516c\u4ea4\u7f51\u7edc\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u3001\u53ef\u6269\u5c55\u7684\u5ef6\u8bef\u9884\u6d4b\u3002", "motivation": "\u57ce\u5e02\u516c\u4ea4\u673a\u6784\u9700\u8981\u53ef\u9760\u7684\u7f51\u7edc\u7ea7\u5ef6\u8bef\u9884\u6d4b\u6765\u63d0\u4f9b\u51c6\u786e\u7684\u5230\u7ad9\u4fe1\u606f\u548c\u652f\u6301\u5b9e\u65f6\u8fd0\u8425\u63a7\u5236\u3002\u73b0\u6709\u7cfb\u7edf\u5927\u591a\u53ea\u80fd\u5904\u7406\u5c11\u6570\u7ebf\u8def\uff0c\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u3001\u53ef\u590d\u7528\u7684\u67b6\u6784\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u57ce\u5e02\u7ea7\u9884\u6d4b\u6d41\u6c34\u7ebf\uff1a1) \u901a\u8fc7H3\u7f51\u683c\u3001\u7ebf\u8def\u3001\u8def\u6bb5\u548c\u65f6\u95f4\u6a21\u5f0f\u751f\u62101,683\u4e2a\u65f6\u7a7a\u7279\u5f81\uff1b2) \u4f7f\u7528\u81ea\u9002\u5e94PCA\u964d\u7ef4\u81f383\u4e2a\u6210\u5206\uff1b3) \u5f15\u5165\u6df7\u5408H3+\u62d3\u6251\u805a\u7c7b\u65b9\u6cd5\uff0c\u5f97\u523012\u4e2a\u5e73\u8861\u7ebf\u8def\u7c07\uff1b4) \u6bd4\u8f83\u4e94\u79cd\u6a21\u578b\u67b6\u6784\uff0c\u91c7\u7528\u5168\u5c40LSTM+\u7c07\u611f\u77e5\u7279\u5f81\u3002", "result": "\u5168\u5c40LSTM\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff0c\u6bd4Transformer\u6a21\u578b\u6027\u80fd\u63d0\u534718-52%\uff0c\u53c2\u6570\u91cf\u51cf\u5c11275\u500d\u3002\u901a\u8fc7\u591a\u7ea7\u8bc4\u4f30\u548c\u5ef6\u8fdf\u5206\u6790\uff0c\u8bc1\u660e\u8be5\u6d41\u6c34\u7ebf\u9002\u5408\u5b9e\u65f6\u57ce\u5e02\u7ea7\u90e8\u7f72\uff0c\u4e14\u53ef\u590d\u7528\u4e8e\u5176\u4ed6\u7f51\u7edc\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u590d\u7528\u7684\u57ce\u5e02\u7ea7\u516c\u4ea4\u5ef6\u8bef\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u7279\u5f81\u5de5\u7a0b\u3001\u964d\u7ef4\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u5728\u8499\u7279\u5229\u5c14\u516c\u4ea4\u7f51\u7edc\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e3a\u5176\u4ed6\u57ce\u5e02\u516c\u4ea4\u7f51\u7edc\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18524", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18524", "abs": "https://arxiv.org/abs/2601.18524", "authors": ["Yongqi Jin", "Yecheng Wang", "Jun-jie Wang", "Rong Zhu", "Guolin Ke", "Weinan E"], "title": "From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale", "comment": null, "summary": "Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.", "AI": {"tldr": "\u63d0\u51fa\u534a\u76d1\u7763\u6846\u67b6\uff0c\u4ece\u6570\u767e\u4e07\u6587\u732e\u63d0\u53d6\u7684NMR\u8c31\u4e2d\u5b66\u4e60\u5316\u5b66\u4f4d\u79fb\uff0c\u65e0\u9700\u539f\u5b50\u7ea7\u6807\u6ce8\uff0c\u7ed3\u5408\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u4e0e\u5927\u89c4\u6a21\u672a\u6807\u6ce8\u8c31\u56fe\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u6709\u9650\u3001\u52b3\u52a8\u5bc6\u96c6\u7684\u539f\u5b50\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u96be\u4ee5\u51c6\u786e\u9884\u6d4bNMR\u5316\u5b66\u4f4d\u79fb\u3002\u9700\u8981\u5229\u7528\u5927\u89c4\u6a21\u6587\u732e\u63d0\u53d6\u7684\u8c31\u56fe\u6570\u636e\u6765\u7a81\u7834\u6570\u636e\u74f6\u9888\u3002", "method": "\u5c06\u5316\u5b66\u4f4d\u79fb\u9884\u6d4b\u5efa\u6a21\u4e3a\u7f6e\u6362\u4e0d\u53d8\u96c6\u5408\u76d1\u7763\u95ee\u9898\uff0c\u5728\u635f\u5931\u51fd\u6570\u6ee1\u8db3\u5e38\u89c1\u6761\u4ef6\u4e0b\uff0c\u6700\u4f18\u4e8c\u5206\u5339\u914d\u7b80\u5316\u4e3a\u57fa\u4e8e\u6392\u5e8f\u7684\u635f\u5931\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7684\u5927\u89c4\u6a21\u534a\u76d1\u7763\u8bad\u7ec3\u3002\u6574\u5408\u6eb6\u5242\u4fe1\u606f\u4ee5\u6355\u6349\u7cfb\u7edf\u6027\u6eb6\u5242\u6548\u5e94\u3002", "result": "\u6a21\u578b\u5728\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u66f4\u5927\u66f4\u591a\u6837\u7684\u5206\u5b50\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u9996\u6b21\u5728\u5e38\u89c1NMR\u6eb6\u5242\u4e2d\u6355\u6349\u5230\u7cfb\u7edf\u6027\u6eb6\u5242\u6548\u5e94\u3002", "conclusion": "\u5927\u89c4\u6a21\u6587\u732e\u63d0\u53d6\u7684\u672a\u6807\u6ce8\u8c31\u56fe\u53ef\u4f5c\u4e3a\u8bad\u7ec3NMR\u4f4d\u79fb\u6a21\u578b\u7684\u5b9e\u7528\u6709\u6548\u6570\u636e\u6e90\uff0c\u8868\u660e\u6587\u732e\u884d\u751f\u7684\u5f31\u7ed3\u6784\u5316\u6570\u636e\u5728\u79d1\u5b66\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684AI\u4e2d\u5177\u6709\u66f4\u5e7f\u6cdb\u4f5c\u7528\u3002"}}
{"id": "2601.18525", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18525", "abs": "https://arxiv.org/abs/2601.18525", "authors": ["Eleonora Grassucci", "Giordano Cicchetti", "Emanuele Frasca", "Aurelio Uncini", "Danilo Comminiello"], "title": "Closing the Modality Gap Aligns Group-Wise Semantics", "comment": "ICLR 2026", "summary": "In multimodal learning, CLIP has been recognized as the \\textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u6a21\u6001\u95f4\u9699\uff08modality gap\uff09\u5728\u7fa4\u4f53\u7ea7\u4efb\u52a1\uff08\u5982\u805a\u7c7b\uff09\u4e2d\u5f71\u54cd\u663e\u8457\uff0c\u800c\u4f20\u7edf\u5b9e\u4f8b\u7ea7\u4efb\u52a1\uff08\u5982\u68c0\u7d22\uff09\u5f71\u54cd\u6709\u9650\u3002\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u51cf\u5c11\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6a21\u6001\u95f4\u9699\uff0c\u5e76\u8bc1\u660e\u8fd9\u80fd\u663e\u8457\u63d0\u5347\u7fa4\u4f53\u7ea7\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u867d\u7136CLIP\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u5efa\u7acb\u4e86\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u4f46\u6a21\u6001\u95f4\u9699\uff08\u4e0d\u540c\u6a21\u6001\u8868\u793a\u4e4b\u95f4\u7684\u7ed3\u6784\u4e0d\u5339\u914d\uff09\u95ee\u9898\u4ecd\u7136\u5b58\u5728\u3002\u5f53\u524d\u7814\u7a76\u5bf9\u6a21\u6001\u95f4\u9699\u7684\u5f71\u54cd\u5b58\u5728\u4e89\u8bae\uff0c\u7279\u522b\u662f\u5728\u5b9e\u4f8b\u7ea7\u4efb\u52a1\u4e2d\u5f71\u54cd\u6709\u9650\u3002\u4f5c\u8005\u8ba4\u4e3a\u6a21\u6001\u95f4\u9699\u5728\u7fa4\u4f53\u7ea7\u4efb\u52a1\u4e2d\u5f71\u54cd\u66f4\u4e3a\u663e\u8457\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5176\u5f71\u54cd\u5e76\u5f00\u53d1\u76f8\u5e94\u89e3\u51b3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u6301\u7eed\u51cf\u5c11\u53cc\u6a21\u6001\u8bbe\u7f6e\u4e2d\u7684\u6a21\u6001\u95f4\u9699\uff0c\u5e76\u53ef\u4ee5\u7b80\u5355\u6269\u5c55\u5230n\u6a21\u6001\u60c5\u51b5\u3002\u8be5\u65b9\u6cd5\u4e13\u95e8\u9488\u5bf9\u6a21\u6001\u95f4\u9699\u95ee\u9898\u8bbe\u8ba1\uff0c\u65e8\u5728\u6539\u5584\u591a\u6a21\u6001\u8868\u793a\u7684\u7ed3\u6784\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a\u51cf\u5c11\u6a21\u6001\u95f4\u9699\u5728\u4f20\u7edf\u5b9e\u4f8b\u7ea7\u4efb\u52a1\u4e2d\u4ec5\u5e26\u6765\u8fb9\u9645\u6216\u4e0d\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u4f46\u5728\u7fa4\u4f53\u7ea7\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002\u8fd9\u8bc1\u660e\u4e86\u6a21\u6001\u95f4\u9699\u5bf9\u9700\u8981\u8bed\u4e49\u5206\u7ec4\u7684\u4efb\u52a1\u5177\u6709\u5173\u952e\u5f71\u54cd\u3002", "conclusion": "\u6a21\u6001\u95f4\u9699\u5728\u7fa4\u4f53\u7ea7\u4efb\u52a1\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u51cf\u5c11\u6a21\u6001\u95f4\u9699\u80fd\u663e\u8457\u63d0\u5347\u8bed\u4e49\u5206\u7ec4\u4efb\u52a1\u7684\u6027\u80fd\u3002\u8fd9\u4e00\u53d1\u73b0\u53ef\u80fd\u91cd\u5851\u5bf9\u6a21\u6001\u95f4\u9699\u7684\u7406\u89e3\uff0c\u5f3a\u8c03\u5176\u5728\u6539\u5584\u9700\u8981\u8bed\u4e49\u5206\u7ec4\u7684\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.18546", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18546", "abs": "https://arxiv.org/abs/2601.18546", "authors": ["Arash Jamshidi", "Katsiaryna Haitsiukevich", "Kai Puolam\u00e4ki"], "title": "Information Hidden in Gradients of Regression with Target Noise", "comment": null, "summary": "Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $\u03a3$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $\u03a9(1)$ factor. The proposed method is practical (a \"set target-noise variance to $n$\" rule) and robust (variance $\\mathcal{O}(n)$ suffices to recover $\u03a3$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u68af\u5ea6\u534f\u65b9\u5dee\u4f30\u8ba1Hessian\u77e9\u9635\u7684\u65b9\u6cd5\uff0c\u6838\u5fc3\u662f\u566a\u58f0\u65b9\u5dee\u6821\u51c6\uff1a\u6ce8\u5165\u9ad8\u65af\u566a\u58f0\u4f7f\u76ee\u6807\u566a\u58f0\u65b9\u5dee\u7b49\u4e8e\u6279\u91cf\u5927\u5c0f\uff0c\u4ece\u800c\u68af\u5ea6\u534f\u65b9\u5dee\u80fd\u8fd1\u4f3cHessian\u77e9\u9635\u3002", "motivation": "\u5728\u8bb8\u591a\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u8bbe\u7f6e\u4e2d\uff0c\u53ea\u80fd\u89c2\u5bdf\u5230\u68af\u5ea6\u800c\u65e0\u6cd5\u76f4\u63a5\u83b7\u53d6\u4e8c\u9636\u4fe1\u606f\uff08\u5982Hessian\u77e9\u9635\u6216\u6570\u636e\u534f\u65b9\u5dee\uff09\uff0c\u4f46\u4e8c\u9636\u4fe1\u606f\u5bf9\u4e8e\u4f18\u5316\u3001\u8bca\u65ad\u548c\u9c81\u68d2\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u65b9\u5dee\u6821\u51c6\u65b9\u6cd5\uff1a\u5411\u76ee\u6807\u6ce8\u5165\u9ad8\u65af\u566a\u58f0\uff0c\u4f7f\u603b\u76ee\u6807\u566a\u58f0\u65b9\u5dee\u7b49\u4e8e\u6279\u91cf\u5927\u5c0fn\uff0c\u8fd9\u6837\u7ecf\u9a8c\u68af\u5ea6\u534f\u65b9\u5dee\u5c31\u80fd\u8fd1\u4f3cHessian\u77e9\u9635\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\"\u5c06\u76ee\u6807\u566a\u58f0\u65b9\u5dee\u8bbe\u4e3an\"\u7684\u7b80\u5355\u89c4\u5219\u3002", "result": "\u5728\u6b21\u9ad8\u65af\u8f93\u5165\u4e0b\u63d0\u4f9b\u4e86\u975e\u6e10\u8fd1\u7b97\u5b50\u8303\u6570\u4fdd\u8bc1\uff0c\u8bc1\u660e\u68af\u5ea6\u534f\u65b9\u5dee\u80fd\u51c6\u786e\u6062\u590dHessian\u77e9\u9635\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u90fd\u6709\u6548\uff0c\u4e14\u5177\u6709\u9c81\u68d2\u6027\uff08\u65b9\u5deeO(n)\u5373\u53ef\u6062\u590d\u03a3\u81f3\u5c3a\u5ea6\u56e0\u5b50\uff09\u3002", "conclusion": "\u4ec5\u901a\u8fc7\u68af\u5ea6\u5c31\u80fd\u63ed\u793aHessian\u77e9\u9635\uff0c\u5728\u7ebf\u6027\u56de\u5f52\u4e2d\u7b49\u4e8e\u6570\u636e\u534f\u65b9\u5dee\u03a3\u3002\u63d0\u51fa\u7684\u65b9\u5dee\u6821\u51c6\u65b9\u6cd5\u5b9e\u7528\u4e14\u9c81\u68d2\uff0c\u53ef\u5e94\u7528\u4e8e\u9884\u6761\u4ef6\u52a0\u901f\u4f18\u5316\u3001\u5bf9\u6297\u98ce\u9669\u4f30\u8ba1\u548c\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u4ec5\u68af\u5ea6\u8bad\u7ec3\u7b49\u573a\u666f\u3002"}}
{"id": "2601.18564", "categories": ["cs.LG", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.18564", "abs": "https://arxiv.org/abs/2601.18564", "authors": ["Chong Hyun Lee", "Kibae Lee", "Hyun Hee Yim"], "title": "An Unsupervised Tensor-Based Domain Alignment", "comment": "5 pages, 5 figures", "summary": "We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f20\u91cf\u7684\u57df\u5bf9\u9f50\u7b97\u6cd5\uff0c\u901a\u8fc7\u5bf9\u9f50\u77e9\u9635\u5728\u4e0d\u53d8\u5b50\u7a7a\u95f4\u4e2d\u4f18\u5316\u6e90\u548c\u76ee\u6807\u5f20\u91cf\uff0c\u4f7f\u7528\u659c\u6d41\u5f62\u7ea6\u675f\u63d0\u4f9b\u6bd4\u4f20\u7edfStiefel\u6d41\u5f62\u66f4\u5927\u7684\u7075\u6d3b\u6027\uff0c\u5e76\u52a0\u5165\u65b9\u5dee\u4fdd\u6301\u6b63\u5219\u5316\u9879\uff0c\u663e\u8457\u63d0\u5347\u57df\u9002\u5e94\u6027\u80fd\u548c\u5206\u7c7b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u5f20\u91cf\u57df\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528Stiefel\u6d41\u5f62\u7ea6\u675f\uff0c\u9650\u5236\u4e86\u7b97\u6cd5\u7684\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u57df\u5bf9\u9f50\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u590d\u6742\u7684\u57df\u9002\u5e94\u4efb\u52a1\uff0c\u540c\u65f6\u63d0\u9ad8\u8f6c\u6362\u901f\u5ea6\u548c\u5206\u7c7b\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f20\u91cf\u7684\u57df\u5bf9\u9f50\u7b97\u6cd5\uff1a1\uff09\u4f7f\u7528\u5bf9\u9f50\u77e9\u9635\u5c06\u6e90\u548c\u76ee\u6807\u5f20\u91cf\u5bf9\u9f50\u5230\u4e0d\u53d8\u5b50\u7a7a\u95f4\uff1b2\uff09\u91c7\u7528\u659c\u6d41\u5f62\uff08oblique manifold\uff09\u7ea6\u675f\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u76f8\u6bd4\u4f20\u7edfStiefel\u6d41\u5f62\u63d0\u4f9b\u66f4\u5927\u7075\u6d3b\u6027\uff1b3\uff09\u5f15\u5165\u6b63\u5219\u5316\u9879\u4ee5\u4fdd\u6301\u6e90\u548c\u76ee\u6807\u5f20\u91cf\u7684\u65b9\u5dee\uff0c\u786e\u4fdd\u9c81\u68d2\u6027\u80fd\uff1b4\uff09\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\uff0c\u53ef\u5c06\u73b0\u6709\u5f20\u91cf\u57df\u5bf9\u9f50\u65b9\u6cd5\u4f5c\u4e3a\u7279\u4f8b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u663e\u8457\u63d0\u5347\u57df\u9002\u5e94\u8f6c\u6362\u901f\u5ea6\uff1b2\uff09\u5927\u5e45\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\uff1b3\uff09\u6027\u80fd\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u6280\u672f\uff1b4\uff09\u9002\u7528\u4e8e\u590d\u6742\u7684\u57df\u9002\u5e94\u4efb\u52a1\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f20\u91cf\u57df\u5bf9\u9f50\u7b97\u6cd5\u901a\u8fc7\u659c\u6d41\u5f62\u7ea6\u675f\u548c\u65b9\u5dee\u4fdd\u6301\u6b63\u5219\u5316\uff0c\u5b9e\u73b0\u4e86\u66f4\u7075\u6d3b\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u57df\u5bf9\u9f50\uff0c\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u662f\u590d\u6742\u57df\u9002\u5e94\u4efb\u52a1\u7684\u4f18\u9009\u65b9\u6848\u3002"}}
{"id": "2601.18580", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18580", "abs": "https://arxiv.org/abs/2601.18580", "authors": ["Vincenzo De Paola", "Mirco Mutti", "Riccardo Zamboni", "Marcello Restelli"], "title": "K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents", "comment": null, "summary": "Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.", "AI": {"tldr": "K-Myriad\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u5e76\u884c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u5e76\u884c\u7b56\u7565\u7fa4\u4f53\u8bf1\u5bfc\u7684\u96c6\u4f53\u72b6\u6001\u71b5\uff0c\u57f9\u517b\u591a\u6837\u5316\u7684\u63a2\u7d22\u7b56\u7565\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u5e76\u53d1\u73b0\u5f02\u6784\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4f20\u7edf\u5e76\u884c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u8ba9\u591a\u4e2a\u5de5\u4f5c\u8005\u4ece\u76f8\u540c\u7684\u91c7\u6837\u5206\u5e03\u6536\u96c6\u7ecf\u9a8c\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u9650\u5236\u4e86\u5e76\u884c\u5316\u7684\u6f5c\u529b\uff0c\u5ffd\u89c6\u4e86\u591a\u6837\u5316\u63a2\u7d22\u7b56\u7565\u7684\u4f18\u52bf\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6700\u5927\u5316\u96c6\u4f53\u63a2\u7d22\u591a\u6837\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faK-Myriad\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u5e76\u884c\u7b56\u7565\u7fa4\u4f53\u8bf1\u5bfc\u7684\u96c6\u4f53\u72b6\u6001\u71b5\uff0c\u57f9\u517b\u4e13\u95e8\u5316\u7684\u63a2\u7d22\u7b56\u7565\u7ec4\u5408\u3002\u8be5\u65b9\u6cd5\u662f\u65e0\u76d1\u7763\u7684\u3001\u53ef\u6269\u5c55\u7684\uff0c\u80fd\u591f\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u7a33\u5065\u7684\u521d\u59cb\u5316\u3002", "result": "\u5728\u9ad8\u7ef4\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\u7684\u5927\u89c4\u6a21\u5e76\u884c\u5b9e\u9a8c\u8868\u660e\uff0cK-Myriad\u80fd\u591f\u5b66\u4e60\u5230\u5e7f\u6cdb\u7684\u4e0d\u540c\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u96c6\u4f53\u63a2\u7d22\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u65b0\u578b\u5e76\u884c\u5316\u7b56\u7565\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "K-Myriad\u901a\u8fc7\u6700\u5927\u5316\u96c6\u4f53\u72b6\u6001\u71b5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u6837\u5316\u7684\u63a2\u7d22\u7b56\u7565\u7ec4\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u5e76\u53d1\u73b0\u4e86\u5f02\u6784\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5e76\u884c\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2601.18586", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18586", "abs": "https://arxiv.org/abs/2601.18586", "authors": ["Miguel Costa", "Arthur Vandervoort", "Carolin Schmidt", "Morten W. Petersen", "Martin Drews", "Karyn Morrissey", "Francisco C. Pereira"], "title": "Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning", "comment": null, "summary": "Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u7efc\u5408\u8bc4\u4f30\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u57ce\u5e02\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u5728\u6c14\u5019\u53d8\u5316\u4e0b\u7684\u81ea\u9002\u5e94\u591a\u5341\u5e74\u6295\u8d44\u8def\u5f84", "motivation": "\u6c14\u5019\u53d8\u5316\u52a0\u5267\u964d\u96e8\u7b49\u707e\u5bb3\uff0c\u589e\u52a0\u57ce\u5e02\u4ea4\u901a\u7cfb\u7edf\u4e2d\u65ad\u3002\u8bbe\u8ba1\u6709\u6548\u9002\u5e94\u7b56\u7565\u9762\u4e34\u957f\u671f\u5e8f\u5217\u6295\u8d44\u3001\u6df1\u5ea6\u4e0d\u786e\u5b9a\u6027\u548c\u590d\u6742\u8de8\u90e8\u95e8\u4ea4\u4e92\u7684\u6311\u6218", "method": "\u63d0\u51fa\u901a\u7528\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u5c06\u7efc\u5408\u8bc4\u4f30\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u8026\u5408\uff0c\u7ed3\u5408\u957f\u671f\u6c14\u5019\u9884\u6d4b\u3001\u707e\u5bb3\u6982\u7387\u6620\u5c04\u3001\u57fa\u7840\u8bbe\u65bd\u5f71\u54cd\u4f20\u64ad\u548c\u4ef7\u503c\u8bc4\u4f30\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4e2d\u5b66\u4e60\u81ea\u9002\u5e94\u6c14\u5019\u9002\u5e94\u7b56\u7565", "result": "\u5728\u54e5\u672c\u54c8\u6839\u5e022024-2100\u5e74\u5185\u6d9d\u6848\u4f8b\u4e2d\uff0c\u5b66\u4e60\u5230\u7684\u7b56\u7565\u4ea7\u751f\u534f\u8c03\u7684\u65f6\u7a7a\u8def\u5f84\uff0c\u76f8\u6bd4\u4f20\u7edf\u4f18\u5316\u57fa\u51c6\uff08\u4e0d\u4f5c\u4e3a\u548c\u968f\u673a\u884c\u52a8\uff09\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027", "conclusion": "\u8be5\u6846\u67b6\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u707e\u5bb3\u548c\u57ce\u5e02\uff0c\u4e3a\u6c14\u5019\u53d8\u5316\u4e0b\u7684\u57ce\u5e02\u57fa\u7840\u8bbe\u65bd\u6295\u8d44\u51b3\u7b56\u63d0\u4f9b\u81ea\u9002\u5e94\u3001\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18604", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2601.18604", "abs": "https://arxiv.org/abs/2601.18604", "authors": ["Zhiwei Zheng", "Kevin Bryson"], "title": "LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation", "comment": null, "summary": "Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited.\n  Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis.\n  Availability and implementation: https://github.com/willyzzz/LaCoGSEA", "AI": {"tldr": "\u63d0\u51faLaCoGSEA\u6846\u67b6\uff0c\u5c06\u6df1\u5ea6\u8868\u793a\u5b66\u4e60\u4e0e\u901a\u8def\u5bcc\u96c6\u5206\u6790\u7ed3\u5408\uff0c\u7528\u4e8e\u65e0\u76d1\u7763\u8f6c\u5f55\u7ec4\u6570\u636e\u5206\u6790\uff0c\u65e0\u9700\u8868\u578b\u6807\u7b7e\u5373\u53ef\u8fdb\u884c\u901a\u8def\u5bcc\u96c6\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u901a\u8def\u5bcc\u96c6\u5206\u6790\u65b9\u6cd5\uff08\u5982GSEA\uff09\u4f9d\u8d56\u9884\u5b9a\u4e49\u8868\u578b\u6807\u7b7e\u548c\u6210\u5bf9\u6bd4\u8f83\uff0c\u5728\u65e0\u76d1\u7763\u573a\u666f\u4e0b\u5e94\u7528\u53d7\u9650\u3002\u73b0\u6709\u65e0\u76d1\u7763\u6269\u5c55\u65b9\u6cd5\u4e3b\u8981\u6355\u83b7\u7ebf\u6027\u5173\u7cfb\uff0c\u4e14\u672a\u660e\u786e\u5efa\u6a21\u57fa\u56e0-\u901a\u8def\u5173\u8054\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u80fd\u6355\u83b7\u975e\u7ebf\u6027\u7ed3\u6784\uff0c\u4f46\u5176\u89e3\u91ca\u901a\u5e38\u4f9d\u8d56\u901a\u7528XAI\u6280\u672f\uff0c\u8fd9\u4e9b\u6280\u672f\u5e76\u975e\u4e3a\u65e0\u76d1\u7763\u8f6c\u5f55\u7ec4\u5206\u6790\u4e2d\u7684\u901a\u8def\u7ea7\u89e3\u91ca\u800c\u8bbe\u8ba1\u3002", "method": "\u63d0\u51faLaCoGSEA\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u6355\u83b7\u975e\u7ebf\u6027\u6d41\u5f62\u7ed3\u6784\uff0c\u63d0\u51fa\u5168\u5c40\u57fa\u56e0-\u6f5c\u5728\u53d8\u91cf\u76f8\u5173\u6027\u5ea6\u91cf\u4f5c\u4e3a\u5dee\u5f02\u8868\u8fbe\u4ee3\u7406\uff0c\u65e0\u9700\u5148\u9a8c\u6807\u7b7e\u5373\u53ef\u751f\u6210\u5bc6\u96c6\u57fa\u56e0\u6392\u5e8f\u3002", "result": "LaCoGSEA\u5177\u6709\u4e09\u5927\u4f18\u52bf\uff1a1) \u5728\u533a\u5206\u764c\u75c7\u4e9a\u578b\u65b9\u9762\u6bd4\u73b0\u6709\u65e0\u76d1\u7763\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u597d\u7684\u805a\u7c7b\u6027\u80fd\uff1b2) \u4e0e\u7ebf\u6027\u964d\u7ef4\u548c\u57fa\u4e8e\u68af\u5ea6\u7684XAI\u65b9\u6cd5\u76f8\u6bd4\uff0c\u80fd\u5728\u66f4\u9ad8\u6392\u540d\u6062\u590d\u66f4\u5e7f\u6cdb\u7684\u751f\u7269\u5b66\u610f\u4e49\u901a\u8def\uff1b3) \u5728\u4e0d\u540c\u5b9e\u9a8c\u65b9\u6848\u548c\u6570\u636e\u96c6\u89c4\u6a21\u4e0b\u4fdd\u6301\u9ad8\u9c81\u68d2\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "LaCoGSEA\u5728\u65e0\u76d1\u7763\u901a\u8def\u5bcc\u96c6\u5206\u6790\u4e2d\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u586b\u8865\u4e86\u6df1\u5ea6\u8868\u793a\u5b66\u4e60\u4e0e\u901a\u8def\u7ea7\u89e3\u91ca\u4e4b\u95f4\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.18615", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18615", "abs": "https://arxiv.org/abs/2601.18615", "authors": ["Ramiro Valdes Jara", "Adam Meyers"], "title": "Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem", "comment": null, "summary": "This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u89e3\u51b3\u5fc3\u7535\u56fe\u6210\u50cf\u4e2d\u7684\u9006\u95ee\u9898\uff0c\u65e0\u9700\u51e0\u4f55\u5efa\u6a21\uff0c\u80fd\u751f\u6210\u591a\u4e2a\u6982\u7387\u6027\u91cd\u5efa\u7ed3\u679c\u800c\u975e\u5355\u4e00\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edf\u5fc3\u7535\u56fe\u6210\u50cf\u9006\u95ee\u9898\u5b58\u5728\u975e\u552f\u4e00\u6027\u548c\u6b20\u5b9a\u6027\uff0c\u9700\u8981\u60a3\u8005\u7279\u5b9a\u7684\u7f51\u683c\u6784\u5efa\uff0c\u4e14\u901a\u5e38\u53ea\u80fd\u63d0\u4f9b\u5355\u4e00\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u65e0\u6cd5\u6355\u6349\u89e3\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u91c7\u7528\u6761\u4ef6\u6269\u6563\u6846\u67b6\uff0c\u5b66\u4e60\u4ece\u566a\u58f0\u4f53\u8868\u4fe1\u53f7\u5230\u5fc3\u8868\u7535\u4f4d\u7684\u6982\u7387\u6620\u5c04\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u7279\u6027\u6355\u6349\u9006\u95ee\u9898\u7684\u975e\u552f\u4e00\u6027\uff0c\u5b9e\u73b0\u51e0\u4f55\u65e0\u5173\u7684\u7eaf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "result": "\u5728\u771f\u5b9eECGI\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\u548cTransformer\u7b49\u786e\u5b9a\u6027\u57fa\u7ebf\u6a21\u578b\uff0c\u6269\u6563\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u91cd\u5efa\u7cbe\u5ea6\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u4e3a\u65e0\u521b\u5fc3\u810f\u7535\u751f\u7406\u6210\u50cf\u63d0\u4f9b\u4e86\u9c81\u68d2\u5de5\u5177\uff0c\u80fd\u591f\u5904\u7406\u9006\u95ee\u9898\u7684\u975e\u552f\u4e00\u6027\uff0c\u907f\u514d\u60a3\u8005\u7279\u5b9a\u7f51\u683c\u6784\u5efa\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u91cd\u5efa\u3002"}}
{"id": "2601.18620", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18620", "abs": "https://arxiv.org/abs/2601.18620", "authors": ["Panagiotis Lymperopoulos", "Abhiramon Rajasekharan", "Ian Berlot-Attwell", "St\u00e9phane Aroca-Ouellette", "Kaheer Suleman"], "title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling", "comment": "28 pages, 2 figures", "summary": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.", "AI": {"tldr": "CASSANDRA\uff1a\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u4e16\u754c\u5efa\u6a21\u65b9\u6cd5\uff0c\u5229\u7528LLM\u4f5c\u4e3a\u77e5\u8bc6\u5148\u9a8c\u6784\u5efa\u8f7b\u91cf\u7ea7\u8f6c\u79fb\u6a21\u578b\u7528\u4e8e\u89c4\u5212\uff0c\u5728\u5496\u5561\u5e97\u548c\u4e3b\u9898\u516c\u56ed\u4e1a\u52a1\u6a21\u62df\u5668\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u73b0\u5b9e\u4e16\u754c\u9886\u57df\uff08\u5982\u5546\u4e1a\uff09\u5177\u6709\u4e30\u5bcc\u7684\u8bed\u4e49\uff0c\u53ef\u4ee5\u5229\u7528\u4e16\u754c\u77e5\u8bc6\u4ece\u6709\u9650\u6570\u636e\u4e2d\u6709\u6548\u5efa\u6a21\u590d\u6742\u7684\u52a8\u4f5c\u6548\u679c\u548c\u56e0\u679c\u5173\u7cfb", "method": "CASSANDRA\u6574\u5408\u4e24\u4e2a\u7ec4\u4ef6\uff1a1\uff09LLM\u5408\u6210\u7684\u4ee3\u7801\u5efa\u6a21\u786e\u5b9a\u6027\u7279\u5f81\uff1b2\uff09LLM\u5f15\u5bfc\u7684\u6982\u7387\u56fe\u6a21\u578b\u7ed3\u6784\u5b66\u4e60\u6355\u6349\u968f\u673a\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb", "result": "\u5728\u5496\u5561\u5e97\u6a21\u62df\u5668\u548c\u590d\u6742\u7684\u4e3b\u9898\u516c\u56ed\u4e1a\u52a1\u6a21\u62df\u5668\u4e2d\uff0cCASSANDRA\u5728\u8f6c\u79fb\u9884\u6d4b\u548c\u89c4\u5212\u65b9\u9762\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "CASSANDRA\u901a\u8fc7\u7ed3\u5408LLM\u7684\u77e5\u8bc6\u5148\u9a8c\u548c\u8f7b\u91cf\u7ea7\u8f6c\u79fb\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u5efa\u6a21\u590d\u6742\u9886\u57df\u7684\u4e16\u754c\u6a21\u578b\uff0c\u63d0\u5347\u89c4\u5212\u6027\u80fd"}}
{"id": "2601.18626", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18626", "abs": "https://arxiv.org/abs/2601.18626", "authors": ["Yingxiao Huo", "Satya Prakash Dash", "Radu Stoican", "Samuel Kaski", "Mingfei Sun"], "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning", "comment": null, "summary": "Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u79e9-1\u8fd1\u4f3c\u7684\u81ea\u7136\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u907f\u514d\u8ba1\u7b97\u5b8c\u6574\u7684Fisher\u4fe1\u606f\u77e9\u9635\u9006\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u81ea\u7136\u68af\u5ea6\u8ba1\u7b97", "motivation": "\u81ea\u7136\u68af\u5ea6\u5728\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u5177\u6709\u5feb\u901f\u6536\u655b\u7279\u6027\uff0c\u4f46\u8ba1\u7b97Fisher\u4fe1\u606f\u77e9\u9635\u7684\u9006\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528", "method": "\u4f7f\u7528\u79e9-1\u8fd1\u4f3c\u6765\u903c\u8fd1\u5b8c\u6574\u7684\u9006Fisher\u4fe1\u606f\u77e9\u9635\uff0c\u5f00\u53d1\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u81ea\u7136\u7b56\u7565\u4f18\u5316\u6280\u672f", "result": "\u7406\u8bba\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u79e9-1\u8fd1\u4f3c\u6bd4\u7b56\u7565\u68af\u5ea6\u6536\u655b\u66f4\u5feb\uff0c\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u4e0e\u968f\u673a\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5177\u6709\u76f8\u540c\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002\u5728\u591a\u6837\u5316\u73af\u5883\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6807\u51c6actor-critic\u548c\u4fe1\u4efb\u533a\u57df\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u79e9-1\u8fd1\u4f3c\u81ea\u7136\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u65e2\u4fdd\u6301\u4e86\u81ea\u7136\u68af\u5ea6\u7684\u4f18\u52bf\uff0c\u53c8\u89e3\u51b3\u4e86\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u90fd\u8868\u73b0\u51fa\u8272"}}
{"id": "2601.18638", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.18638", "abs": "https://arxiv.org/abs/2601.18638", "authors": ["Tingkai Xue", "Chin Chun Ooi", "Yang Jiang", "Luu Trung Pham Duong", "Pao-Hsiung Chiu", "Weijiang Zhao", "Nagarajan Raghavan", "My Ha Dao"], "title": "Physics-Informed Uncertainty Enables Reliable AI-driven Design", "comment": null, "summary": "Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u7684\u65b0\u8303\u5f0f\uff0c\u5c06\u6a21\u578b\u9884\u6d4b\u8fdd\u53cd\u7269\u7406\u5b9a\u5f8b\u7684\u7a0b\u5ea6\u4f5c\u4e3a\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u5ec9\u4ef7\u6709\u6548\u4ee3\u7406\uff0c\u7528\u4e8e\u9891\u7387\u9009\u62e9\u8868\u9762\u9006\u8bbe\u8ba1\uff0c\u5927\u5e45\u63d0\u5347\u6210\u529f\u7387\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4ee3\u7406\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5bfc\u81f4\u5728\u6570\u636e\u7a00\u758f\u533a\u57df\u9884\u6d4b\u9519\u8bef\uff0c\u5f71\u54cd\u4f18\u5316\u6027\u80fd\u3002\u9891\u7387\u9009\u62e9\u8868\u9762\u7b49\u9006\u8bbe\u8ba1\u95ee\u9898\u9700\u8981\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "method": "\u5f15\u5165\u7269\u7406\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u8303\u5f0f\uff0c\u5c06\u6a21\u578b\u9884\u6d4b\u8fdd\u53cd\u57fa\u672c\u7269\u7406\u5b9a\u5f8b\u7684\u7a0b\u5ea6\u4f5c\u4e3a\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u4ee3\u7406\u3002\u5c06\u6b64\u65b9\u6cd5\u96c6\u6210\u5230\u591a\u4fdd\u771f\u5ea6\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4f18\u5316\u5de5\u4f5c\u6d41\u4e2d\uff0c\u7528\u4e8e\u8bbe\u8ba120-30 GHz\u8303\u56f4\u7684\u590d\u6742\u9891\u7387\u9009\u62e9\u8868\u9762\u3002", "result": "\u5c06\u5bfb\u627e\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u7684\u6210\u529f\u7387\u4ece\u4e0d\u8db310%\u63d0\u9ad8\u5230\u8d85\u8fc750%\uff0c\u540c\u65f6\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528\u9ad8\u4fdd\u771f\u6c42\u89e3\u5668\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728\u9ad8\u7ef4\u95ee\u9898\u7684\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u9006\u8bbe\u8ba1\u4e2d\u7eb3\u5165\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5fc5\u8981\u6027\uff0c\u786e\u7acb\u4e86\u7269\u7406\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u7269\u7406\u7cfb\u7edf\u4ee3\u7406\u6a21\u578b\u4e2d\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.18640", "categories": ["cs.LG", "q-bio.MN"], "pdf": "https://arxiv.org/pdf/2601.18640", "abs": "https://arxiv.org/abs/2601.18640", "authors": ["Zhiwei Zheng", "Kevin Bryson"], "title": "TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning", "comment": null, "summary": "Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.\n  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as \"background\" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.\n  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.", "AI": {"tldr": "TwinPurify\u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u540c\u4e00\u961f\u5217\u4e2d\u76f8\u90bb\u6b63\u5e38\u7ec4\u7ec7\u4f5c\u4e3a\"\u80cc\u666f\"\u6307\u5bfc\uff0c\u4ece\u6279\u91cf\u8f6c\u5f55\u7ec4\u6570\u636e\u4e2d\u5b66\u4e60\u8fde\u7eed\u7684\u9ad8\u7ef4\u80bf\u7624\u5d4c\u5165\uff0c\u4ece\u800c\u89e3\u8026\u80bf\u7624\u7279\u5f02\u6027\u4fe1\u53f7\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u53c2\u8003\u3002", "motivation": "\u5927\u89c4\u6a21\u60a3\u8005\u961f\u5217\u7814\u7a76\u4ecd\u4f9d\u8d56\u6279\u91cf\u8f6c\u5f55\u7ec4\u6570\u636e\uff0c\u4f46\u80bf\u7624\u7eaf\u5ea6\u53d8\u5316\u4f1a\u63a9\u76d6\u80bf\u7624\u5185\u5728\u8f6c\u5f55\u4fe1\u53f7\u5e76\u9650\u5236\u4e0b\u6e38\u53d1\u73b0\u3002\u73b0\u6709\u7684\u53bb\u5377\u79ef\u65b9\u6cd5\u5728\u5408\u6210\u6df7\u5408\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u672a\u5efa\u6a21\u7684\u751f\u7269\u548c\u6280\u672f\u53d8\u5f02\uff0c\u96be\u4ee5\u63a8\u5e7f\u5230\u771f\u5b9e\u60a3\u8005\u961f\u5217\u3002", "method": "TwinPurify\u91c7\u7528Barlow Twins\u81ea\u76d1\u7763\u76ee\u6807\uff0c\u4ee3\u8868\u4e86\u5bf9\u53bb\u5377\u79ef\u8303\u5f0f\u7684\u6839\u672c\u6027\u8f6c\u53d8\u3002\u5b83\u4e0d\u5c06\u6279\u91cf\u6df7\u5408\u7269\u89e3\u6790\u4e3a\u79bb\u6563\u7684\u7ec6\u80de\u7c7b\u578b\u5206\u6570\uff0c\u800c\u662f\u5229\u7528\u540c\u4e00\u961f\u5217\u4e2d\u76f8\u90bb\u6b63\u5e38\u7ec4\u7ec7\u4f5c\u4e3a\"\u80cc\u666f\"\u6307\u5bfc\uff0c\u5b66\u4e60\u8fde\u7eed\u7684\u9ad8\u7ef4\u80bf\u7624\u5d4c\u5165\uff0c\u4ece\u800c\u89e3\u8026\u80bf\u7624\u7279\u5f02\u6027\u4fe1\u53f7\u3002", "result": "\u5728\u591a\u4e2a\u5927\u578b\u764c\u75c7\u961f\u5217\uff08RNA-seq\u548c\u5fae\u9635\u5217\u5e73\u53f0\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTwinPurify\u5728\u6062\u590d\u80bf\u7624\u5185\u5728\u548c\u514d\u75ab\u4fe1\u53f7\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u81ea\u7f16\u7801\u5668\uff09\u3002\u7eaf\u5316\u7684\u5d4c\u5165\u6539\u5584\u4e86\u5206\u5b50\u4e9a\u578b\u548c\u5206\u7ea7\u5206\u7c7b\uff0c\u589e\u5f3a\u4e86\u751f\u5b58\u6a21\u578b\u4e00\u81f4\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6bd4\u539f\u59cb\u6279\u91cf\u8c31\u66f4\u5bcc\u751f\u7269\u5b66\u610f\u4e49\u7684\u901a\u8def\u6d3b\u6027\u3002", "conclusion": "TwinPurify\u901a\u8fc7\u63d0\u4f9b\u53ef\u8f6c\u79fb\u7684\u6279\u91cf\u8f6c\u5f55\u7ec4\u53bb\u6c61\u67d3\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u4e34\u5e8a\u6570\u636e\u96c6\u5728\u5206\u5b50\u53d1\u73b0\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u80bf\u7624\u751f\u6001\u7cfb\u7edf\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.18650", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18650", "abs": "https://arxiv.org/abs/2601.18650", "authors": ["Liheng Yu", "Zhe Zhao", "Yuxuan Wang", "Pengkun Wang", "Binwu Wang", "Yang Wang"], "title": "FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning", "comment": "camera-ready for iclr2026", "summary": "Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \\textit{Heterogeneous Unlearning Deviation} and \\textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \\textbf{Supplementary Material}.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7814\u7a76\u4e86\u957f\u5c3e\u5206\u5e03\u4e0b\u673a\u5668\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5f02\u8d28\u9057\u5fd8\u504f\u5dee\u548c\u503e\u659c\u9057\u5fd8\u504f\u5dee\uff0c\u63d0\u51fa\u4e86\u52a8\u6001\u635f\u5931\u91cd\u52a0\u6743\u65b9\u6cd5FaLW\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u7814\u7a76\u4e3b\u8981\u8bc4\u4f30\u76f8\u5bf9\u5e73\u8861\u7684\u9057\u5fd8\u96c6\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u6570\u636e\u901a\u5e38\u9075\u5faa\u957f\u5c3e\u5206\u5e03\uff08\u5982\u7528\u6237\u6d3b\u52a8\u8bb0\u5f55\uff09\u7684\u5e38\u89c1\u573a\u666f\u3002\u8fd9\u662f\u9996\u6b21\u7814\u7a76\u8fd9\u4e00\u91cd\u8981\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86FaLW\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u5b9e\u4f8b\u7ea7\u52a8\u6001\u635f\u5931\u91cd\u52a0\u6743\u65b9\u6cd5\u3002\u901a\u8fc7\u6bd4\u8f83\u6bcf\u4e2a\u6837\u672c\u7684\u9884\u6d4b\u6982\u7387\u4e0e\u540c\u7c7b\u522b\u672a\u89c1\u6570\u636e\u7684\u5206\u5e03\u6765\u8bc4\u4f30\u5176\u9057\u5fd8\u72b6\u6001\uff0c\u7136\u540e\u4f7f\u7528\u9057\u5fd8\u611f\u77e5\u7684\u91cd\u52a0\u6743\u65b9\u6848\uff0c\u901a\u8fc7\u5e73\u8861\u56e0\u5b50\u8c03\u8282\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u6bcf\u4e2a\u6837\u672c\u7684\u9057\u5fd8\u5f3a\u5ea6\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFaLW\u5728\u957f\u5c3e\u5206\u5e03\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u8d28\u9057\u5fd8\u504f\u5dee\u548c\u503e\u659c\u9057\u5fd8\u504f\u5dee\u95ee\u9898\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u673a\u5668\u9057\u5fd8\u5728\u957f\u5c3e\u5206\u5e03\u573a\u666f\u4e0b\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63d0\u51fa\u7684FaLW\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u5e38\u89c1\u7684\u957f\u5c3e\u6570\u636e\u9057\u5fd8\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u9690\u79c1\u6cd5\u89c4\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18672", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18672", "abs": "https://arxiv.org/abs/2601.18672", "authors": ["Spyros Rigas", "Thanasis Papaioannou", "Panagiotis Trakadas", "Georgios Alexandridis"], "title": "A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks", "comment": null, "summary": "Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u66f2\u7387\u7684\u91cd\u8981\u6027\u5bc6\u5ea6\u51fd\u6570\u6846\u67b6\uff0c\u7528\u4e8eKAN\u7f51\u7edc\u7f51\u683c\u81ea\u9002\u5e94\uff0c\u76f8\u6bd4\u4f20\u7edf\u8f93\u5165\u5bc6\u5ea6\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u7cbe\u5ea6", "motivation": "\u73b0\u6709KAN\u7f51\u683c\u81ea\u9002\u5e94\u7b56\u7565\u4ec5\u4f9d\u8d56\u8f93\u5165\u6570\u636e\u5bc6\u5ea6\uff0c\u5ffd\u7565\u4e86\u76ee\u6807\u51fd\u6570\u7684\u51e0\u4f55\u590d\u6742\u6027\u548c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5ea6\u91cf\u4fe1\u606f\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u7f51\u683c\u5206\u914d\u65b9\u6cd5", "method": "\u63d0\u51fa\u5e7f\u4e49\u6846\u67b6\uff0c\u5c06\u8282\u70b9\u5206\u914d\u89c6\u4e3a\u91cd\u8981\u6027\u5bc6\u5ea6\u51fd\u6570\uff08IDFs\uff09\u63a7\u5236\u7684\u5bc6\u5ea6\u4f30\u8ba1\u4efb\u52a1\uff0c\u5f15\u5165\u57fa\u4e8e\u66f2\u7387\u7684\u81ea\u9002\u5e94\u7b56\u7565\uff0c\u5229\u7528\u8bad\u7ec3\u52a8\u6001\u786e\u5b9a\u7f51\u683c\u5206\u8fa8\u7387", "result": "\u5728\u5408\u6210\u51fd\u6570\u62df\u5408\u3001Feynman\u6570\u636e\u96c6\u56de\u5f52\u548cHelmholtz PDE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u8f93\u5165\u57fa\u7ebf\uff0c\u76f8\u5bf9\u8bef\u5dee\u5206\u522b\u964d\u4f4e25.3%\u30019.4%\u548c23.3%\uff0c\u7edf\u8ba1\u663e\u8457\u6027\u901a\u8fc7Wilcoxon\u68c0\u9a8c\u786e\u8ba4", "conclusion": "\u57fa\u4e8e\u66f2\u7387\u7684\u81ea\u9002\u5e94\u7b56\u7565\u662fKAN\u8bad\u7ec3\u4e2d\u7a33\u5065\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u51fd\u6570\u51e0\u4f55\u590d\u6742\u6027"}}
{"id": "2601.18675", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18675", "abs": "https://arxiv.org/abs/2601.18675", "authors": ["Aditya Kumar", "Mario A. Cypko", "Oliver Amft"], "title": "Learning temporal embeddings from electronic health records of chronic kidney disease patients", "comment": "7 pages, 3 figures, 3 tables. The paper has been submitted to IEEE EMBC 2026 and copyright might be transferred without notice", "summary": "We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u65f6\u95f4\u5d4c\u5165\u6a21\u578b\u80fd\u5426\u5728\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u5b66\u4e60\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u8868\u793a\uff0c\u4ee5\u53ca\u67b6\u6784\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u5d4c\u5165\u8d28\u91cf\u3002\u4f7f\u7528MIMIC-IV\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e09\u79cd\u5faa\u73af\u67b6\u6784\u5728\u6162\u6027\u80be\u75c5\u548cICU\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u6a21\u578b\u5f15\u5bfc\u7684\u533b\u5b66\u9700\u8981\u80fd\u591f\u6355\u6349\u75be\u75c5\u52a8\u6001\u4e14\u4fdd\u6301\u900f\u660e\u3001\u4efb\u52a1\u65e0\u5173\u7684\u8868\u793a\uff0c\u800c\u5927\u591a\u6570\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u4ec5\u9488\u5bf9\u5355\u4e00\u4efb\u52a1\u4f18\u5316\u3002\u8868\u793a\u5b66\u4e60\u6709\u52a9\u4e8e\u5b66\u4e60\u53ef\u6cdb\u5316\u5230\u4e0b\u6e38\u4efb\u52a1\u7684\u5d4c\u5165\uff0c\u5faa\u73af\u67b6\u6784\u9002\u5408\u5efa\u6a21\u4e34\u5e8a\u6570\u636e\u7684\u65f6\u95f4\u7ed3\u6784\u3002", "method": "\u4f7f\u7528MIMIC-IV\u6570\u636e\u96c6\uff0c\u7814\u7a76\u6162\u6027\u80be\u75c5\u60a3\u8005\uff0c\u6bd4\u8f83\u4e09\u79cd\u5faa\u73af\u67b6\u6784\uff1a\u666e\u901aLSTM\u3001\u6ce8\u610f\u529b\u589e\u5f3aLSTM\u548c\u65f6\u95f4\u611f\u77e5LSTM(T-LSTM)\u3002\u6240\u6709\u6a21\u578b\u65e2\u4f5c\u4e3a\u5d4c\u5165\u6a21\u578b\u8bad\u7ec3\uff0c\u4e5f\u4f5c\u4e3a\u7aef\u5230\u7aef\u9884\u6d4b\u5668\u8bad\u7ec3\u3002\u901a\u8fc7CKD\u9636\u6bb5\u805a\u7c7b\u548cICU\u6b7b\u4ea1\u7387\u9884\u6d4b\u8bc4\u4f30\u5d4c\u5165\u8d28\u91cf\u3002", "result": "T-LSTM\u4ea7\u751f\u66f4\u7ed3\u6784\u5316\u7684\u5d4c\u5165\uff0c\u83b7\u5f97\u66f4\u4f4e\u7684Davies-Bouldin\u6307\u6570(9.91)\u548c\u66f4\u9ad8\u7684CKD\u9636\u6bb5\u5206\u7c7b\u51c6\u786e\u7387(0.74)\uff0c\u4f18\u4e8e\u666e\u901aLSTM(15.85, 0.63)\u548c\u6ce8\u610f\u529b\u589e\u5f3aLSTM(20.72, 0.67)\u3002\u5bf9\u4e8eICU\u6b7b\u4ea1\u7387\u9884\u6d4b\uff0c\u5d4c\u5165\u6a21\u578b\u59cb\u7ec8\u4f18\u4e8e\u7aef\u5230\u7aef\u9884\u6d4b\u5668\uff0c\u51c6\u786e\u7387\u4ece0.72-0.75\u63d0\u5347\u52300.82-0.83\u3002", "conclusion": "\u65f6\u95f4\u611f\u77e5LSTM\u80fd\u5b66\u4e60\u66f4\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u8868\u793a\u800c\u4e0d\u635f\u5bb3\u9884\u6d4b\u6027\u80fd\uff0c\u5d4c\u5165\u6a21\u578b\u4f5c\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6bd4\u76f4\u63a5\u7aef\u5230\u7aef\u5b66\u4e60\u66f4\u6709\u6548\uff0c\u4e3a\u6a21\u578b\u5f15\u5bfc\u533b\u5b66\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2601.18676", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18676", "abs": "https://arxiv.org/abs/2601.18676", "authors": ["Miles Martinez", "Alex H. Williams"], "title": "Quasi Monte Carlo methods enable extremely low-dimensional deep generative models", "comment": null, "summary": "This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.", "AI": {"tldr": "QLVMs\u662f\u4e00\u79cd\u4e13\u95e8\u7528\u4e8e\u5bfb\u627e\u9ad8\u7ef4\u6570\u636e\u6781\u4f4e\u7ef4\u53ef\u89e3\u91ca\u5d4c\u5165\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u51c6\u8499\u7279\u5361\u6d1b\u79ef\u5206\u76f4\u63a5\u8fd1\u4f3c\u8fb9\u7f18\u4f3c\u7136\uff0c\u57281-3\u7ef4\u6f5c\u7a7a\u95f4\u4e0a\u4f18\u4e8e\u4f20\u7edfVAE/IWAE\uff0c\u652f\u6301\u53ef\u89c6\u5316\u5206\u6790\u4f46\u8ba1\u7b97\u5bc6\u96c6\u4e14\u7ec6\u8282\u751f\u6210\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u4f20\u7edf\u53d8\u5206\u81ea\u7f16\u7801\u5668\u4f9d\u8d56\u7f16\u7801\u5668\u548c\u53d8\u5206\u4e0b\u754c\uff0c\u5728\u9ad8\u7ef4\u6f5c\u7a7a\u95f4\u4e2d\u96be\u4ee5\u9a8c\u8bc1\u5d4c\u5165\u7684\u53ef\u89e3\u91ca\u6027\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u6781\u4f4e\u7ef4\uff081-3\u7ef4\uff09\u6f5c\u7a7a\u95f4\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578b\uff0c\u5b9e\u73b0\u900f\u660e\u53ef\u89c6\u5316\u548c\u540e\u9a8c\u5206\u6790\u3002", "method": "\u63d0\u51fa\u51c6\u8499\u7279\u5361\u6d1b\u6f5c\u53d8\u91cf\u6a21\u578b\uff08QLVMs\uff09\uff0c\u4e0d\u4f9d\u8d56\u7f16\u7801\u5668\u6216\u53d8\u5206\u4e0b\u754c\uff0c\u800c\u662f\u901a\u8fc7\u968f\u673a\u5316\u51c6\u8499\u7279\u5361\u6d1b\u79ef\u5206\u76f4\u63a5\u8fd1\u4f3c\u8fb9\u7f18\u4f3c\u7136\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u4f4e\u7ef4\u6f5c\u7a7a\u95f4\u4e2d\u7279\u522b\u6709\u6548\uff0c\u4f46\u8ba1\u7b97\u5bc6\u96c6\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cQLVMs\u57281-3\u7ef4\u6f5c\u7a7a\u95f4\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edf\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u91cd\u8981\u6027\u52a0\u6743\u81ea\u7f16\u7801\u5668\u3002\u751f\u6210\u7684\u5d4c\u5165\u652f\u6301\u900f\u660e\u53ef\u89c6\u5316\u3001\u975e\u53c2\u6570\u5bc6\u5ea6\u4f30\u8ba1\u3001\u805a\u7c7b\u548c\u6d4b\u5730\u7ebf\u8def\u5f84\u8ba1\u7b97\u7b49\u540e\u9a8c\u5206\u6790\u3002", "conclusion": "QLVMs\u4e3a\u4f18\u5148\u8003\u8651\u53ef\u89e3\u91ca\u6027\u548c\u6f5c\u7a7a\u95f4\u5206\u6790\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u5438\u5f15\u529b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u867d\u7136\u5728\u590d\u6742\u6570\u636e\u96c6\u4e0a\u751f\u6210\u7cbe\u7ec6\u7ec6\u8282\u7684\u80fd\u529b\u6709\u9650\u4e14\u8ba1\u7b97\u5bc6\u96c6\uff0c\u4f46\u5728\u4f4e\u7ef4\u5d4c\u5165\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.18678", "categories": ["cs.LG", "cs.CV", "cs.HC", "math.DG"], "pdf": "https://arxiv.org/pdf/2601.18678", "abs": "https://arxiv.org/abs/2601.18678", "authors": ["Eslam Zaher", "Maciej Trzaskowski", "Quan Nguyen", "Fred Roosta"], "title": "Counterfactual Explanations on Robust Perceptual Geodesics", "comment": "Accepted at ICLR 2026", "summary": "Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.", "AI": {"tldr": "PCG\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u611f\u77e5\u9ece\u66fc\u5ea6\u91cf\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ffd\u8e2a\u6d4b\u5730\u7ebf\u751f\u6210\u8bed\u4e49\u6709\u6548\u7684\u53cd\u4e8b\u5b9e\uff0c\u907f\u514d\u5bf9\u6297\u6027\u6270\u52a8\u548c\u79bb\u6d41\u5f62\u4f2a\u5f71\u3002", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5b58\u5728\u8ddd\u79bb\u5ea6\u91cf\u9009\u62e9\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u53cd\u4e8b\u5b9e\u53ef\u80fd\u662f\u5bf9\u6297\u6027\u6270\u52a8\u800c\u975e\u8bed\u4e49\u6709\u6548\u7684\u89e3\u91ca\u3002\u73b0\u6709\u65b9\u6cd5\u91c7\u7528\u5e73\u5766\u6216\u4e0d\u5bf9\u9f50\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u5bfc\u81f4\u79bb\u6d41\u5f62\u4f2a\u5f71\u3001\u8bed\u4e49\u6f02\u79fb\u6216\u5bf9\u6297\u6027\u5d29\u6e83\u3002", "method": "\u63d0\u51fa\u611f\u77e5\u53cd\u4e8b\u5b9e\u6d4b\u5730\u7ebf\uff08PCG\uff09\u65b9\u6cd5\uff0c\u4f7f\u7528\u9c81\u68d2\u89c6\u89c9\u7279\u5f81\u8bf1\u5bfc\u7684\u611f\u77e5\u9ece\u66fc\u5ea6\u91cf\u6784\u9020\u53cd\u4e8b\u5b9e\u3002\u8be5\u65b9\u6cd5\u8ffd\u8e2a\u5728\u8be5\u51e0\u4f55\u4e0b\u7684\u6d4b\u5730\u7ebf\uff0c\u751f\u6210\u5e73\u6ed1\u3001\u5728\u6d41\u5f62\u4e0a\u3001\u8bed\u4e49\u6709\u6548\u7684\u8fc7\u6e21\u3002", "result": "\u5728\u4e09\u4e2a\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPCG\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u6807\u51c6\u5ea6\u91cf\u4e0b\u9690\u85cf\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "PCG\u901a\u8fc7\u611f\u77e5\u5bf9\u9f50\u7684\u9ece\u66fc\u51e0\u4f55\u89e3\u51b3\u4e86\u53cd\u4e8b\u5b9e\u89e3\u91ca\u4e2d\u7684\u5ea6\u91cf\u6a21\u7cca\u95ee\u9898\uff0c\u80fd\u591f\u751f\u6210\u8bed\u4e49\u6709\u6548\u4e14\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002"}}
{"id": "2601.18681", "categories": ["cs.LG", "cs.AI", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.18681", "abs": "https://arxiv.org/abs/2601.18681", "authors": ["Yilie Huang", "Wenpin Tang", "Xunyu Zhou"], "title": "ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule", "comment": "17 pages, 7 figures", "summary": "We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fr\u00e9chet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u91cd\u53c2\u6570\u5316\u65f6\u95f4\uff08ART\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u91cd\u53c2\u6570\u5316\u65f6\u95f4\u53d8\u91cf\u7684\u65f6\u949f\u901f\u5ea6\u6765\u4f18\u5316\u6269\u6563\u6a21\u578b\u7684\u65f6\u95f4\u6b65\u957f\u5206\u914d\uff0c\u51cf\u5c11\u79bb\u6563\u5316\u8bef\u5dee\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08ART-RL\uff09\u5b66\u4e60\u6700\u4f18\u65f6\u95f4\u8c03\u5ea6\u3002", "motivation": "\u4f20\u7edf\u5747\u5300\u6216\u624b\u52a8\u8bbe\u8ba1\u7684\u65f6\u95f4\u7f51\u683c\u5728\u6709\u9650\u65f6\u95f4\u6b65\u9884\u7b97\u4e0b\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u7684\uff0c\u5bfc\u81f4\u91c7\u6837\u8d28\u91cf\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u65f6\u95f4\u8c03\u5ea6\u65b9\u6cd5\u6765\u6700\u5c0f\u5316\u79bb\u6563\u5316\u8bef\u5dee\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u91cd\u53c2\u6570\u5316\u65f6\u95f4\uff08ART\uff09\uff0c\u63a7\u5236\u91cd\u53c2\u6570\u5316\u65f6\u95f4\u53d8\u91cf\u7684\u65f6\u949f\u901f\u5ea6\uff0c\u5b9e\u73b0\u4e0d\u5747\u5300\u7684\u65f6\u95f4\u6b65\u957f\u5206\u914d\u3002\u63d0\u51faART-RL\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u65f6\u95f4\u53d8\u5316\u5efa\u6a21\u4e3a\u8fde\u7eed\u65f6\u95f4RL\u95ee\u9898\uff0c\u4f7f\u7528\u9ad8\u65af\u7b56\u7565\u5e76\u901a\u8fc7actor-critic\u66f4\u65b0\u5b66\u4e60\u6700\u4f18\u65f6\u95f4\u8c03\u5ea6\u3002", "result": "\u57fa\u4e8eEDM\u6846\u67b6\uff0cART-RL\u5728CIFAR-10\u4e0a\u663e\u8457\u6539\u5584\u4e86Fr\u00e9chet Inception Distance\uff08FID\uff09\u5f97\u5206\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u8fc1\u79fb\u5230AFHQv2\u3001FFHQ\u548cImageNet\u7b49\u6570\u636e\u96c6\u3002", "conclusion": "ART\u65b9\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94\u65f6\u95f4\u8c03\u5ea6\u4f18\u5316\u4e86\u6269\u6563\u6a21\u578b\u7684\u91c7\u6837\u6548\u7387\uff0cART-RL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5b66\u4e60\u6700\u4f18\u65f6\u95f4\u53d8\u5316\u7b56\u7565\uff0c\u63d0\u5347\u91c7\u6837\u8d28\u91cf\u5e76\u5177\u6709\u826f\u597d\u7684\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2601.18696", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18696", "abs": "https://arxiv.org/abs/2601.18696", "authors": ["Paul Whitten", "Francis Wolff", "Chris Papachristou"], "title": "Explainability Methods for Hardware Trojan Detection: A Systematic Comparison", "comment": null, "summary": "Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).\n  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like \"high fanin complexity near outputs indicates potential triggers.\" Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.\n  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.\n  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u4e2d\u7684\u4e09\u79cd\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff1a\u57fa\u4e8e\u5c5e\u6027\u7684\u5206\u6790\u3001\u57fa\u4e8e\u6848\u4f8b\u7684\u63a8\u7406\u548c\u6a21\u578b\u65e0\u5173\u7279\u5f81\u5f52\u56e0\uff0c\u53d1\u73b0\u524d\u4e24\u8005\u5728\u9886\u57df\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u540e\u8005\u3002", "motivation": "\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u9700\u8981\u51c6\u786e\u8bc6\u522b\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\uff0c\u4ee5\u4fbf\u5b89\u5168\u5de5\u7a0b\u5e08\u9a8c\u8bc1\u5e76\u91c7\u53d6\u884c\u52a8\u3002\u672c\u6587\u65e8\u5728\u6bd4\u8f83\u4e0d\u540c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u95e8\u7ea7\u6728\u9a6c\u68c0\u6d4b\u4e2d\u7684\u6548\u679c\u3002", "method": "\u6bd4\u8f83\u4e09\u79cd\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff1a1) \u57fa\u4e8e31\u4e2a\u7535\u8def\u7279\u5b9a\u7279\u5f81\u7684\u9886\u57df\u611f\u77e5\u5c5e\u6027\u5206\u6790\uff1b2) \u4f7f\u7528k\u8fd1\u90bb\u7684\u57fa\u4e8e\u6848\u4f8b\u63a8\u7406\uff1b3) \u6a21\u578b\u65e0\u5173\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\uff08LIME\u3001SHAP\u3001\u68af\u5ea6\uff09\u3002\u4f7f\u7528XGBoost\u5206\u7c7b\u5668\u5728Trust-Hub\u57fa\u51c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "XGBoost\u5206\u7c7b\u5668\u572811,392\u4e2a\u6d4b\u8bd5\u6837\u672c\u4e0a\u8fbe\u523046.15%\u7cbe\u786e\u7387\u548c52.17%\u53ec\u56de\u7387\uff0c\u6bd4\u5148\u524d\u5de5\u4f5c\uff08Hasegawa\u7b49\uff1a5.13%\uff09\u63d0\u53479\u500d\u7cbe\u786e\u7387\uff0c\u5047\u9633\u6027\u7387\u4ece5.6%\u964d\u81f30.25%\u3002\u57fa\u4e8e\u5c5e\u6027\u7684\u5206\u6790\u63d0\u4f9b\u7535\u8def\u6982\u5ff5\u89e3\u91ca\uff0c\u57fa\u4e8e\u6848\u4f8b\u7684\u63a8\u7406\u8fbe\u523097.4%\u9884\u6d4b\u4e0e\u8bad\u7ec3\u6837\u672c\u5bf9\u5e94\u6027\uff0cLIME\u548cSHAP\u7279\u5f81\u5f52\u56e0\u76f8\u5173\u6027\u9ad8\u4f46\u7f3a\u4e4f\u7535\u8def\u7ea7\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u57fa\u4e8e\u5c5e\u6027\u7684\u5206\u6790\u548c\u57fa\u4e8e\u6848\u4f8b\u7684\u63a8\u7406\u65b9\u6cd5\u5728\u9886\u57df\u5bf9\u9f50\u548c\u57fa\u4e8e\u5148\u4f8b\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u901a\u7528\u7684\u7279\u5f81\u6392\u540d\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u9700\u8981\u9a8c\u8bc1ML\u9884\u6d4b\u7684\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.18699", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18699", "abs": "https://arxiv.org/abs/2601.18699", "authors": ["Olaf Yunus Laitinen Imanov"], "title": "Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning", "comment": "16 pages, 16 figures (6 main + 10 supplementary)", "summary": "Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u5206\u6790\u4e86Transformer\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fde\u7eed\u5fae\u8c03\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u673a\u5236\uff0c\u8bc6\u522b\u51fa\u6ce8\u610f\u529b\u6743\u91cd\u68af\u5ea6\u5e72\u6270\u3001\u4e2d\u95f4\u5c42\u8868\u5f81\u6f02\u79fb\u548c\u635f\u5931\u666f\u89c2\u5e73\u5766\u5316\u4e09\u4e2a\u4e3b\u8981\u673a\u5236\uff0c\u53d1\u73b0\u9057\u5fd8\u7a0b\u5ea6\u4e0e\u4efb\u52a1\u76f8\u4f3c\u5ea6\u5f3a\u76f8\u5173\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8fde\u7eed\u4efb\u52a1\u5fae\u8c03\u4e2d\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\u73b0\u8c61\uff0c\u65b0\u5b66\u77e5\u8bc6\u4f1a\u5e72\u6270\u5148\u524d\u5b66\u5230\u7684\u80fd\u529b\u3002\u867d\u7136\u8fd9\u79cd\u73b0\u8c61\u88ab\u5e7f\u6cdb\u89c2\u5bdf\u5230\uff0c\u4f46\u5176\u673a\u5236\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002", "method": "\u5bf9\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fde\u7eed\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u5168\u9762\u7684\u673a\u5236\u5206\u6790\uff0c\u901a\u8fc7\u8de8\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\uff08109B\u5230400B\u603b\u53c2\u6570\uff09\u548c\u4efb\u52a1\u5e8f\u5217\u7684\u7cfb\u7edf\u5b9e\u9a8c\uff0c\u8bc6\u522b\u707e\u96be\u6027\u9057\u5fd8\u7684\u4e3b\u8981\u9a71\u52a8\u673a\u5236\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u4e2a\u4e3b\u8981\u9057\u5fd8\u673a\u5236\uff1a\u6ce8\u610f\u529b\u6743\u91cd\u7684\u68af\u5ea6\u5e72\u6270\u3001\u4e2d\u95f4\u5c42\u7684\u8868\u5f81\u6f02\u79fb\u548c\u635f\u5931\u666f\u89c2\u5e73\u5766\u5316\u3002\u9057\u5fd8\u4e25\u91cd\u7a0b\u5ea6\u4e0e\u4efb\u52a1\u76f8\u4f3c\u5ea6\u5f3a\u76f8\u5173\uff08Pearson r = 0.87\uff09\uff0c\u7ea615-23%\u7684\u6ce8\u610f\u529b\u5934\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u53d7\u5230\u4e25\u91cd\u5e72\u6270\uff0c\u8f83\u4f4e\u5c42\u8868\u73b0\u51fa\u66f4\u5927\u7684\u6613\u611f\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5f00\u53d1\u6301\u7eed\u5b66\u4e60\u7cfb\u7edf\u4e2d\u9488\u5bf9\u6027\u7684\u7f13\u89e3\u7b56\u7565\u5efa\u7acb\u4e86\u673a\u5236\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fde\u7eed\u5fae\u8c03\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u73b0\u8c61\u3002"}}
{"id": "2601.18707", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.18707", "abs": "https://arxiv.org/abs/2601.18707", "authors": ["Jan Hagnberger", "Mathias Niepert"], "title": "SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model", "comment": null, "summary": "Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.", "AI": {"tldr": "SMART\u662f\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u51e0\u4f55\u70b9\u4e91\u8868\u793a\uff08\u65e0\u9700\u4eff\u771f\u7f51\u683c\uff09\u5373\u53ef\u9884\u6d4b\u4efb\u610f\u67e5\u8be2\u4f4d\u7f6e\u7684\u7269\u7406\u91cf\uff0c\u6027\u80fd\u4e0e\u4f9d\u8d56\u7f51\u683c\u7684\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7f51\u683c\u7684\u4ee3\u7406\u6a21\u578b\u9700\u8981\u751f\u6210\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u4eff\u771f\u7f51\u683c\uff0c\u800c\u65e0\u9700\u7f51\u683c\u7684\u65b9\u6cd5\u901a\u5e38\u8bef\u5dee\u8f83\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u51c6\u786e\u7684\u7f51\u683c\u65e0\u5173\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u51e0\u4f55\u548c\u4eff\u771f\u53c2\u6570\u7f16\u7801\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u7269\u7406\u89e3\u7801\u5668\u5173\u6ce8\u7f16\u7801\u5668\u7684\u4e2d\u95f4\u6f5c\u5728\u8868\u793a\uff0c\u5b9e\u73b0\u51e0\u4f55\u7279\u5f81\u4e0e\u7269\u7406\u573a\u7684\u8054\u5408\u66f4\u65b0\u3002", "result": "SMART\u5728\u5b9e\u9a8c\u4e2d\u4e0e\u4f9d\u8d56\u7f51\u683c\u8f93\u5165\u7684\u65b9\u6cd5\u7ade\u4e89\u5e76\u7ecf\u5e38\u8d85\u8d8a\u5b83\u4eec\uff0c\u5c55\u793a\u4e86\u5de5\u4e1a\u7ea7\u4eff\u771f\u7684\u80fd\u529b\u3002", "conclusion": "SMART\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4eff\u771f\u7f51\u683c\u7684\u9ad8\u6548\u51c6\u786e\u7269\u7406\u4eff\u771f\u65b9\u6cd5\uff0c\u4e3a\u590d\u6742\u51e0\u4f55\u7684\u5de5\u4e1a\u4eff\u771f\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18728", "categories": ["cs.LG", "math.DG", "math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.18728", "abs": "https://arxiv.org/abs/2601.18728", "authors": ["Willem Diepeveen", "Oscar Leong"], "title": "Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data", "comment": null, "summary": "Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.", "AI": {"tldr": "\u63d0\u51faRiemannian AmbientFlow\u6846\u67b6\uff0c\u4ece\u566a\u58f0\u6216\u7ebf\u6027\u635f\u574f\u7684\u89c2\u6d4b\u4e2d\u540c\u65f6\u5b66\u4e60\u6982\u7387\u751f\u6210\u6a21\u578b\u548c\u5e95\u5c42\u975e\u7ebf\u6027\u6570\u636e\u6d41\u5f62\uff0c\u7ed3\u5408\u53d8\u5206\u63a8\u65ad\u4e0e\u6570\u636e\u9a71\u52a8\u7684\u9ece\u66fc\u51e0\u4f55\u3002", "motivation": "\u5728\u8bb8\u591a\u79d1\u5b66\u548c\u6210\u50cf\u5e94\u7528\u4e2d\uff0c\u65e0\u6cd5\u83b7\u5f97\u5e72\u51c0\u6837\u672c\uff0c\u53ea\u80fd\u89c2\u6d4b\u5230\u566a\u58f0\u6216\u7ebf\u6027\u635f\u574f\u7684\u6d4b\u91cf\u503c\u3002\u6b64\u5916\uff0c\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u7ed3\u6784\uff08\u5982\u6d41\u5f62\u51e0\u4f55\uff09\u5bf9\u4e8e\u4e0b\u6e38\u79d1\u5b66\u5206\u6790\u5f88\u91cd\u8981\uff0c\u9700\u8981\u63d0\u53d6\u8fd9\u4e9b\u7ed3\u6784\u3002", "method": "\u57fa\u4e8eAmbientFlow\u7684\u53d8\u5206\u63a8\u65ad\u6846\u67b6\uff0c\u7ed3\u5408\u7531\u5f52\u4e00\u5316\u6d41\u8bf1\u5bfc\u7684\u6570\u636e\u9a71\u52a8\u9ece\u66fc\u51e0\u4f55\uff0c\u901a\u8fc7\u62c9\u56de\u5ea6\u91cf\u548c\u9ece\u66fc\u81ea\u7f16\u7801\u5668\u63d0\u53d6\u6d41\u5f62\u7ed3\u6784\u3002\u5728\u51e0\u4f55\u6b63\u5219\u5316\u548c\u6d4b\u91cf\u6761\u4ef6\u4e0b\uff0c\u5b66\u4e60\u6a21\u578b\u6062\u590d\u5e95\u5c42\u6570\u636e\u5206\u5e03\u5e76\u83b7\u5f97\u5e73\u6ed1\u7684\u53ccLipschitz\u6d41\u5f62\u53c2\u6570\u5316\u3002", "result": "\u7406\u8bba\u4fdd\u8bc1\u663e\u793a\uff0c\u5728\u9002\u5f53\u7684\u51e0\u4f55\u6b63\u5219\u5316\u548c\u6d4b\u91cf\u6761\u4ef6\u4e0b\uff0c\u5b66\u4e60\u6a21\u578b\u80fd\u4ee5\u53ef\u63a7\u8bef\u5dee\u6062\u590d\u5e95\u5c42\u6570\u636e\u5206\u5e03\uff0c\u5e76\u83b7\u5f97\u5e73\u6ed1\u7684\u53ccLipschitz\u6d41\u5f62\u53c2\u6570\u5316\u3002\u5e73\u6ed1\u89e3\u7801\u5668\u53ef\u4f5c\u4e3a\u9006\u95ee\u9898\u7684\u539f\u5219\u6027\u751f\u6210\u5148\u9a8c\uff0c\u5177\u6709\u6062\u590d\u4fdd\u8bc1\u3002\u5728\u4f4e\u7ef4\u5408\u6210\u6d41\u5f62\u548cMNIST\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "conclusion": "Riemannian AmbientFlow\u4e3a\u4ece\u635f\u574f\u89c2\u6d4b\u4e2d\u540c\u65f6\u5b66\u4e60\u751f\u6210\u6a21\u578b\u548c\u5e95\u5c42\u6570\u636e\u6d41\u5f62\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u9006\u95ee\u9898\u4e2d\u53ef\u4f5c\u4e3a\u539f\u5219\u6027\u751f\u6210\u5148\u9a8c\u3002"}}
{"id": "2601.18734", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18734", "abs": "https://arxiv.org/abs/2601.18734", "authors": ["Siyan Zhao", "Zhihui Xie", "Mengchen Liu", "Jing Huang", "Guan Pang", "Feiyu Chen", "Aditya Grover"], "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models", "comment": "13 pages", "summary": "Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.", "AI": {"tldr": "\u63d0\u51faOPSD\u6846\u67b6\uff0c\u8ba9\u5355\u4e2a\u6a21\u578b\u65e2\u5f53\u8001\u5e08\u53c8\u5f53\u5b66\u751f\uff0c\u901a\u8fc7\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u6761\u4ef6\u4e0b\u751f\u6210\u4e0d\u540c\u7b56\u7565\uff0c\u5b9e\u73b0\u81ea\u6211\u84b8\u998f\uff0c\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u5b58\u5728\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u9700\u8981\u5355\u72ec\u7684\u5927\u6a21\u578b\u4f5c\u4e3a\u6559\u5e08\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528\u63a8\u7406\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u89e3\u4fe1\u606f\u3002", "method": "OPSD\u6846\u67b6\u8ba9\u540c\u4e00\u6a21\u578b\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u5de5\u4f5c\uff1a\u6559\u5e08\u7b56\u7565\u57fa\u4e8e\u7279\u6743\u4fe1\u606f\uff08\u5982\u5df2\u9a8c\u8bc1\u63a8\u7406\u8f68\u8ff9\uff09\uff0c\u5b66\u751f\u7b56\u7565\u4ec5\u57fa\u4e8e\u95ee\u9898\uff1b\u5728\u5b66\u751f\u7684\u81ea\u8eab\u8f68\u8ff9\u4e0a\u6700\u5c0f\u5316\u4e24\u4e2a\u7b56\u7565\u7684\u6bcftoken\u5206\u5e03\u5dee\u5f02\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4GRPO\u7b49\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\u4e864-8\u500d\u7684token\u6548\u7387\uff0c\u6027\u80fd\u4f18\u4e8e\u79bb\u7b56\u7565\u84b8\u998f\u65b9\u6cd5\u3002", "conclusion": "OPSD\u6846\u67b6\u901a\u8fc7\u81ea\u6211\u84b8\u998f\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u5355\u72ec\u6559\u5e08\u6a21\u578b\uff0c\u5145\u5206\u5229\u7528\u6570\u636e\u96c6\u7279\u6743\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2601.18736", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18736", "abs": "https://arxiv.org/abs/2601.18736", "authors": ["Jake Lyon", "Ehsan Saeedizade", "Shamik Sengupta"], "title": "Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift", "comment": null, "summary": "The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u79cd\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u5728IoT\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e0e\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u6a21\u578b\u6027\u80fd\u4f1a\u968f\u65f6\u95f4\u4e0b\u964d\uff0c\u5f3a\u8c03\u4e86\u81ea\u9002\u5e94\u8f7b\u91cf\u7ea7\u6a21\u578b\u5bf9IoT\u5b89\u5168\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u3001\u7269\u7406\u9632\u62a4\u8584\u5f31\u3001\u7f51\u7edc\u73af\u5883\u5f02\u6784\u52a8\u6001\u7684\u60c5\u51b5\u4e0b\uff0c\u5bb9\u6613\u6210\u4e3a\u7f51\u7edc\u653b\u51fb\u548c\u6076\u610f\u8f6f\u4ef6\u7684\u76ee\u6807\u3002\u673a\u5668\u5b66\u4e60\u4e3a\u81ea\u52a8\u5316\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9700\u8981\u65e2\u6709\u6548\u53c8\u8f7b\u91cf\u7ea7\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528IoT-23\u6570\u636e\u96c6\uff0c\u7814\u7a76\u56db\u79cd\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff08\u968f\u673a\u68ee\u6797\u3001LightGBM\u3001\u903b\u8f91\u56de\u5f52\u548c\u591a\u5c42\u611f\u77e5\u5668\uff09\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u548c\u5206\u7c7b\u4e2d\u7684\u6548\u679c\u3002\u8bc4\u4f30\u6a21\u578b\u5728\u4e8c\u5206\u7c7b\u548c\u591a\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5206\u6790\u5bf9\u8bad\u7ec3\u6570\u636e\u91cf\u7684\u654f\u611f\u6027\uff0c\u4ee5\u53ca\u65f6\u95f4\u9c81\u68d2\u6027\u4ee5\u6a21\u62df\u5728\u4e0d\u65ad\u53d8\u5316\u7684\u5a01\u80c1\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002", "result": "\u57fa\u4e8e\u6811\u7684\u6a21\u578b\uff08\u968f\u673a\u68ee\u6797\u548cLightGBM\uff09\u5373\u4f7f\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u548c\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002\u7136\u800c\uff0c\u968f\u7740\u6076\u610f\u8f6f\u4ef6\u591a\u6837\u6027\u7684\u589e\u52a0\uff0c\u6240\u6709\u6a21\u578b\u7684\u6027\u80fd\u90fd\u4f1a\u968f\u65f6\u95f4\u4e0b\u964d\uff0c\u8868\u660e\u6a21\u578b\u9700\u8981\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u5a01\u80c1\u73af\u5883\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u81ea\u9002\u5e94\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u4e8e\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u4fdd\u62a4\u7269\u8054\u7f51\u7cfb\u7edf\u5b89\u5168\u7684\u91cd\u8981\u6027\u3002\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u8981\u6301\u7eed\u66f4\u65b0\u4ee5\u9002\u5e94\u4e0d\u65ad\u6f14\u53d8\u7684\u5a01\u80c1\u73af\u5883\u3002"}}
{"id": "2601.18751", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18751", "abs": "https://arxiv.org/abs/2601.18751", "authors": ["Seyed Amir Hosseini", "Maryam Abdolali", "Amirhosein Tavakkoli", "Fardin Ayar", "Ehsan Javanmardi", "Manabu Tsukada", "Mahdi Javanmardi"], "title": "Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback", "comment": "Equal contribution: Seyed Amir Hosseini and Maryam Abdolali. Corresponding author: Maryam Abdolali (maryam.abdolali@kntu.ac.ir)", "summary": "Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.", "AI": {"tldr": "TTP\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u504f\u597d\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u5171\u4eab\u5956\u52b1\u6a21\u578b\u548c\u4e13\u5bb6\u7279\u5b9a\u4fe1\u4efb\u53c2\u6570\uff0c\u81ea\u52a8\u5904\u7406\u5f02\u6784\u6807\u6ce8\u8005\uff08\u5305\u62ec\u5bf9\u6297\u6027\u6807\u6ce8\u8005\uff09\u7684\u504f\u597d\u53cd\u9988\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u504f\u597d\u6570\u636e\u901a\u5e38\u6765\u81ea\u5177\u6709\u4e0d\u540c\u53ef\u9760\u6027\u7684\u5f02\u6784\u6807\u6ce8\u8005\uff0c\u5305\u62ec\u51c6\u786e\u3001\u5608\u6742\u548c\u7cfb\u7edf\u6027\u5bf9\u6297\u7684\u6807\u6ce8\u8005\u3002\u73b0\u6709\u7684PBRL\u65b9\u6cd5\u8981\u4e48\u5e73\u7b49\u5bf9\u5f85\u6240\u6709\u53cd\u9988\uff0c\u8981\u4e48\u5c1d\u8bd5\u8fc7\u6ee4\u4e0d\u53ef\u9760\u6765\u6e90\uff0c\u4f46\u5728\u9762\u5bf9\u7cfb\u7edf\u6027\u63d0\u4f9b\u9519\u8bef\u504f\u597d\u7684\u5bf9\u6297\u6027\u6807\u6ce8\u8005\u65f6\u90fd\u4f1a\u5931\u8d25\u3002", "method": "TriTrust-PBRL (TTP)\u6846\u67b6\u8054\u5408\u5b66\u4e60\u5171\u4eab\u5956\u52b1\u6a21\u578b\u548c\u4e13\u5bb6\u7279\u5b9a\u4fe1\u4efb\u53c2\u6570\u3002\u5173\u952e\u6d1e\u5bdf\u662f\u4fe1\u4efb\u53c2\u6570\u5728\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u8fc7\u7a0b\u4e2d\u81ea\u7136\u6f14\u53d8\u4e3a\u6b63\u503c\uff08\u4fe1\u4efb\uff09\u3001\u63a5\u8fd1\u96f6\uff08\u5ffd\u7565\uff09\u6216\u8d1f\u503c\uff08\u7ffb\u8f6c\uff09\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u81ea\u52a8\u53cd\u8f6c\u5bf9\u6297\u6027\u504f\u597d\u5e76\u6062\u590d\u6709\u7528\u4fe1\u53f7\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4e22\u5f03\u635f\u574f\u7684\u53cd\u9988\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\uff08MetaWorld\u64cd\u4f5c\u4efb\u52a1\u548cDM Control\u8fd0\u52a8\u4efb\u52a1\uff09\u7684\u5404\u79cd\u8150\u8d25\u573a\u666f\u4e0b\u8bc4\u4f30TTP\u3002TTP\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9c81\u68d2\u6027\uff0c\u5728\u5bf9\u6297\u6027\u8150\u8d25\u4e0b\u4fdd\u6301\u63a5\u8fd1oracle\u7684\u6027\u80fd\uff0c\u800c\u6807\u51c6PBRL\u65b9\u6cd5\u5219\u707e\u96be\u6027\u5730\u5931\u8d25\u3002TTP\u6210\u529f\u5730\u4ece\u5305\u542b\u53ef\u9760\u548c\u5bf9\u6297\u6027\u6807\u6ce8\u8005\u7684\u6df7\u5408\u4e13\u5bb6\u6c60\u4e2d\u5b66\u4e60\uff0c\u4ec5\u9700\u8981\u4e13\u5bb6\u8bc6\u522b\u7d22\u5f15\uff0c\u65e0\u9700\u989d\u5916\u4e13\u5bb6\u7279\u5f81\u3002", "conclusion": "TTP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5f02\u6784\u6807\u6ce8\u8005\u504f\u597d\u6570\u636e\uff0c\u7279\u522b\u662f\u5bf9\u6297\u6027\u6807\u6ce8\u8005\uff0c\u901a\u8fc7\u81ea\u52a8\u5b66\u4e60\u4fe1\u4efb\u53c2\u6570\u6765\u53cd\u8f6c\u5bf9\u6297\u6027\u504f\u597d\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u5730\u4e22\u5f03\u5b83\u4eec\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u4e86PBRL\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.18753", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18753", "abs": "https://arxiv.org/abs/2601.18753", "authors": ["Xinyue Zeng", "Junhong Lin", "Yujun Yan", "Feng Guo", "Liang Shi", "Jun Wu", "Dawei Zhou"], "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs", "comment": "Have been accepted by ICLR'26", "summary": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faHallucination Risk Bound\u7406\u8bba\u6846\u67b6\uff0c\u5c06LLM\u5e7b\u89c9\u98ce\u9669\u5206\u89e3\u4e3a\u6570\u636e\u9a71\u52a8\u548c\u63a8\u7406\u9a71\u52a8\u4e24\u90e8\u5206\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86HalluGuard\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "LLM\u5728\u533b\u7597\u3001\u6cd5\u5f8b\u3001\u79d1\u5b66\u53d1\u73b0\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u53ef\u9760\u6027\u5e38\u56e0\u5e7b\u89c9\u95ee\u9898\u800c\u53d7\u635f\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u53ea\u9488\u5bf9\u5355\u4e00\u5e7b\u89c9\u6765\u6e90\uff0c\u4e14\u4f9d\u8d56\u7279\u5b9a\u4efb\u52a1\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u96be\u4ee5\u63a8\u5e7f\u5230\u590d\u6742\u573a\u666f\u3002", "method": "1. \u63d0\u51faHallucination Risk Bound\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5e7b\u89c9\u98ce\u9669\u6b63\u5f0f\u5206\u89e3\u4e3a\u6570\u636e\u9a71\u52a8\uff08\u8bad\u7ec3\u65f6\u4e0d\u5339\u914d\uff09\u548c\u63a8\u7406\u9a71\u52a8\uff08\u63a8\u7406\u65f6\u4e0d\u7a33\u5b9a\u6027\uff09\u4e24\u90e8\u5206\uff1b2. \u57fa\u4e8e\u6b64\u6846\u67b6\u5f00\u53d1HalluGuard\uff0c\u5229\u7528NTK\uff08\u795e\u7ecf\u6b63\u5207\u6838\uff09\u7684\u51e0\u4f55\u7ed3\u6784\u548c\u6355\u83b7\u7684\u8868\u5f81\u6765\u8054\u5408\u8bc6\u522b\u4e24\u79cd\u5e7b\u89c9\u7c7b\u578b\u3002", "result": "\u572810\u4e2a\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u300111\u4e2a\u7ade\u4e89\u6027\u57fa\u7ebf\u65b9\u6cd5\u548c9\u4e2a\u6d41\u884cLLM\u4e3b\u5e72\u7f51\u7edc\u4e0a\u8bc4\u4f30HalluGuard\uff0c\u5728\u68c0\u6d4b\u591a\u79cd\u5f62\u5f0f\u7684LLM\u5e7b\u89c9\u65b9\u9762\u59cb\u7ec8\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "Hallucination Risk Bound\u4e3a\u5206\u6790\u5e7b\u89c9\u4ea7\u751f\u548c\u6f14\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0cHalluGuard\u4f5c\u4e3a\u5176\u5b9e\u8df5\u5b9e\u73b0\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u6570\u636e\u9a71\u52a8\u548c\u63a8\u7406\u9a71\u52a8\u7684\u5e7b\u89c9\uff0c\u63d0\u5347\u4e86LLM\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.18760", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18760", "abs": "https://arxiv.org/abs/2601.18760", "authors": ["Henry Bell", "Lara Neubauer da Costa Schertel", "Bochu Ding", "Brandon Fain"], "title": "Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values", "comment": null, "summary": "A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.", "AI": {"tldr": "\u63d0\u51faGrounded Constitutional AI (GCAI)\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u7528\u6237\u5bf9AI\u7684\u666e\u904d\u671f\u671b\u548c\u4ea4\u4e92\u65f6\u504f\u597d\uff0c\u751f\u6210\u66f4\u5177\u4ee3\u8868\u6027\u3001\u9053\u5fb7\u57fa\u7840\u66f4\u5f3a\u3001\u66f4\u8fde\u8d2f\u548c\u591a\u5143\u5316\u7684AI\u5baa\u6cd5\u539f\u5219\u3002", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u6846\u67b6\u4e2d\uff0c\u5baa\u6cd5\u539f\u5219\u7684\u786e\u5b9a\u7f3a\u4e4f\u5e7f\u6cdb\u5229\u76ca\u76f8\u5173\u8005\u7684\u516c\u5e73\u53c2\u4e0e\uff0c\u96be\u4ee5\u5e73\u8861\u7528\u6237\u7684\u666e\u904d\u671f\u671b\u548c\u5177\u4f53\u4ea4\u4e92\u504f\u597d\uff0c\u9700\u8981\u66f4\u5168\u9762\u3001\u4ee3\u8868\u6027\u7684\u539f\u5219\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u6269\u5c55Inverse Constitutional AI (ICAI)\u65b9\u6cd5\uff0c\u4ece\u4eba\u7c7b\u504f\u597d\u6807\u6ce8\u6570\u636e\u4e2d\u751f\u6210\u4e0a\u4e0b\u6587\u539f\u5219\uff08\u5229\u7528\u7528\u6237\u63d0\u4f9b\u7684\u504f\u597d\u539f\u56e0\uff09\uff0c\u5e76\u8865\u5145\u4ece\u7528\u6237AI\u4ef7\u503c\u89c2\u9648\u8ff0\u4e2d\u63d0\u53d6\u7684\u666e\u904d\u539f\u5219\uff0c\u5f62\u6210\u7edf\u4e00\u7684\u5baa\u6cd5\u751f\u6210\u6846\u67b6\u3002", "result": "GCAI\u751f\u6210\u7684\u5baa\u6cd5\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u4f18\u4e8eICAI\u751f\u6210\u7684\u5baa\u6cd5\uff0c\u65e2\u5728\u4e2a\u4eba\u504f\u597d\u4e0a\u66f4\u53d7\u6b22\u8fce\uff0c\u4e5f\u66f4\u9002\u5408\u5e7f\u6cdb\u7528\u4e8e\u6cbb\u7406AI\u884c\u4e3a\uff1b\u53c2\u4e0e\u8005\u8ba4\u4e3aGCAI\u5baa\u6cd5\u66f4\u5177\u9053\u5fb7\u57fa\u7840\u3001\u8fde\u8d2f\u6027\u548c\u591a\u5143\u6027\u3002", "conclusion": "GCAI\u6846\u67b6\u80fd\u591f\u751f\u6210\u66f4\u5168\u9762\u3001\u4ee3\u8868\u6027\u66f4\u5f3a\u7684AI\u5baa\u6cd5\u539f\u5219\uff0c\u6709\u6548\u7ed3\u5408\u7528\u6237\u7684\u666e\u904d\u4ef7\u503c\u89c2\u548c\u5177\u4f53\u4ea4\u4e92\u504f\u597d\uff0c\u4e3aAI\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u516c\u5e73\u3001\u591a\u5143\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18777", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18777", "abs": "https://arxiv.org/abs/2601.18777", "authors": ["Abhishek Divekar", "Anirban Majumder"], "title": "PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation", "comment": "Accepted at AAAI 2026 - Innovative Applications of AI (IAAI-26)", "summary": "Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.", "AI": {"tldr": "\u63d0\u51faPRECISE\u6846\u67b6\uff0c\u7ed3\u5408\u5c11\u91cf\u4eba\u5de5\u6807\u6ce8\u548cLLM\u5224\u65ad\u6765\u8bc4\u4f30\u641c\u7d22/\u6392\u5e8f/RAG\u7cfb\u7edf\u8d28\u91cf\uff0c\u663e\u8457\u51cf\u5c11\u6807\u6ce8\u9700\u6c42", "motivation": "\u4f20\u7edf\u641c\u7d22\u3001\u6392\u5e8f\u548cRAG\u7cfb\u7edf\u8bc4\u4f30\u9700\u8981\u5927\u91cf\u4eba\u5de5\u76f8\u5173\u6027\u6807\u6ce8\uff0c\u800cLLM\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u4f30\u5668\u5b58\u5728\u56fa\u6709\u504f\u5dee\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u7edf\u8ba1\u65b9\u6cd5", "method": "\u6269\u5c55\u9884\u6d4b\u9a71\u52a8\u63a8\u7406(PPI)\u6846\u67b6\uff0c\u63d0\u51faPRECISE\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c11\u91cf\u4eba\u5de5\u6807\u6ce8\u67e5\u8be2\uff08100\u4e2a\uff09\u548c\u5927\u91cf\u672a\u6807\u6ce8\u6837\u672c\uff0810,000\u4e2a\uff09\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(2^|C|)\u964d\u4f4e\u5230O(2^K)", "result": "\u5728\u591a\u4e2a\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cPRECISE\u80fd\u51cf\u5c11Precision@K\u6307\u6807\u7684\u4f30\u8ba1\u65b9\u5dee\uff0c\u6709\u6548\u7ea0\u6b63\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u7684LLM\u504f\u5dee\uff0c\u663e\u8457\u964d\u4f4e\u6807\u6ce8\u9700\u6c42", "conclusion": "PRECISE\u6846\u67b6\u4e3a\u641c\u7d22\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u53ef\u9760\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5c11\u91cf\u4eba\u5de5\u6807\u6ce8\u548cLLM\u5224\u65ad\uff0c\u5728\u4fdd\u8bc1\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u6807\u6ce8\u6210\u672c"}}
{"id": "2601.18778", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18778", "abs": "https://arxiv.org/abs/2601.18778", "authors": ["Shobhita Sundaram", "John Quan", "Ariel Kwiatkowski", "Kartik Ahuja", "Yann Ollivier", "Julia Kempe"], "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability", "comment": null, "summary": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.", "AI": {"tldr": "SOAR\uff1a\u4e00\u4e2a\u57fa\u4e8e\u5143\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u6211\u6539\u8fdb\u6846\u67b6\uff0c\u8ba9LLM\u80fd\u591f\u4e3a\u81ea\u8eab\u65e0\u6cd5\u89e3\u51b3\u7684\u96be\u9898\u751f\u6210\u81ea\u52a8\u8bfe\u7a0b\uff0c\u901a\u8fc7\u6559\u5e08-\u5b66\u751f\u4e92\u52a8\u6253\u7834\u5b66\u4e60\u74f6\u9888", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u5fae\u8c03\u65f6\uff0c\u9762\u5bf9\u521d\u59cb\u6210\u529f\u7387\u4f4e\u7684\u56f0\u96be\u6570\u636e\u96c6\u4f1a\u9677\u5165\u5b66\u4e60\u74f6\u9888\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u8db3\u591f\u7684\u8bad\u7ec3\u4fe1\u53f7\u3002\u7814\u7a76\u63a2\u7d22\u9884\u8bad\u7ec3LLM\u662f\u5426\u53ef\u4ee5\u5229\u7528\u6f5c\u5728\u77e5\u8bc6\u4e3a\u81ea\u8eab\u65e0\u6cd5\u89e3\u51b3\u7684\u95ee\u9898\u751f\u6210\u81ea\u52a8\u8bfe\u7a0b\u3002", "method": "SOAR\u6846\u67b6\uff1a\u4f7f\u7528\u5143\u5f3a\u5316\u5b66\u4e60\uff0c\u6559\u5e08\u6a21\u578b\u4e3a\u5b66\u751f\u6a21\u578b\u751f\u6210\u5408\u6210\u95ee\u9898\uff0c\u6839\u636e\u5b66\u751f\u5728\u56f0\u96be\u95ee\u9898\u5b50\u96c6\u4e0a\u7684\u8fdb\u6b65\u83b7\u5f97\u5956\u52b1\u3002\u5173\u952e\u521b\u65b0\u662f\u57fa\u4e8e\u5b9e\u9645\u5b66\u751f\u8fdb\u6b65\u800c\u975e\u5185\u5728\u4ee3\u7406\u5956\u52b1\u6765\u6784\u5efa\u8bfe\u7a0b\u3002", "result": "\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u6700\u56f0\u96be\u5b50\u96c6\uff080/128\u6210\u529f\u7387\uff09\u4e0a\uff1a1\uff09\u5b9e\u73b0\u4e86\u53cc\u5c42\u5143\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u7a00\u758f\u4e8c\u5143\u5956\u52b1\u4e0b\u89e3\u9501\u5b66\u4e60\u80fd\u529b\uff1b2\uff09\u57fa\u4e8e\u5b9e\u9645\u8fdb\u6b65\u7684\u5956\u52b1\u4f18\u4e8e\u5148\u524dLLM\u81ea\u5bf9\u5f08\u7684\u5185\u5728\u5956\u52b1\u65b9\u6848\uff0c\u907f\u514d\u4e0d\u7a33\u5b9a\u6027\u548c\u591a\u6837\u6027\u5d29\u6e83\uff1b3\uff09\u751f\u6210\u95ee\u9898\u7684\u7ed3\u6784\u8d28\u91cf\u548c\u660e\u786e\u6027\u6bd4\u89e3\u51b3\u65b9\u6848\u6b63\u786e\u6027\u5bf9\u5b66\u4e60\u8fdb\u6b65\u66f4\u91cd\u8981\u3002", "conclusion": "\u6a21\u578b\u751f\u6210\u6709\u7528\"\u57ab\u811a\u77f3\"\u7684\u80fd\u529b\u5e76\u4e0d\u9700\u8981\u9884\u5148\u5177\u5907\u89e3\u51b3\u56f0\u96be\u95ee\u9898\u7684\u80fd\u529b\uff0c\u8fd9\u4e3a\u65e0\u9700\u989d\u5916\u7b56\u5212\u6570\u636e\u5373\u53ef\u6253\u7834\u63a8\u7406\u74f6\u9888\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8def\u5f84\u3002"}}
{"id": "2601.18779", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18779", "abs": "https://arxiv.org/abs/2601.18779", "authors": ["Yuxiao Qu", "Amrith Setlur", "Virginia Smith", "Ruslan Salakhutdinov", "Aviral Kumar"], "title": "POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration", "comment": null, "summary": "Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.", "AI": {"tldr": "\u63d0\u51faPOPE\u65b9\u6cd5\uff0c\u5229\u7528\u7279\u6743\u4fe1\u606f\uff08\u5982\u4eba\u5de5\u89e3\u51b3\u65b9\u6848\uff09\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u5728\u56f0\u96be\u63a8\u7406\u95ee\u9898\u4e0a\u7684\u63a2\u7d22\uff0c\u89e3\u51b3\u4f20\u7edfRL\u65b9\u6cd5\u5728\u786c\u95ee\u9898\u4e0a\u63a2\u7d22\u5931\u8d25\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65f6\uff0c\u5728\u56f0\u96be\u95ee\u9898\u4e0a\u7ecf\u5e38\u65e0\u6cd5\u83b7\u5f97\u4efb\u4f55\u6b63\u786e\u8f68\u8ff9\uff0c\u5bfc\u81f4\u96f6\u5956\u52b1\u548c\u7f3a\u4e4f\u5b66\u4e60\u4fe1\u53f7\u3002\u4f20\u7edf\u63a2\u7d22\u65b9\u6cd5\uff08\u5982\u71b5\u5956\u52b1\u3001\u91cd\u8981\u6027\u6bd4\u7387\u8c03\u6574\uff09\u6548\u679c\u6709\u9650\uff0c\u800c\u6df7\u5408\u96be\u6613\u95ee\u9898\u8bad\u7ec3\u53cd\u800c\u4f1a\u4ea7\u751f\"\u5c04\u7ebf\u5e72\u6270\"\u73b0\u8c61\uff0c\u963b\u788d\u786c\u95ee\u9898\u7684\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u7279\u6743\u5728\u7ebf\u63a2\u7d22\uff08POPE\uff09\u65b9\u6cd5\uff1a1\uff09\u5229\u7528\u4eba\u7c7b\u6216\u5176\u4ed6oracle\u89e3\u51b3\u65b9\u6848\u4f5c\u4e3a\u7279\u6743\u4fe1\u606f\uff1b2\uff09\u5728\u786c\u95ee\u9898\u524d\u6dfb\u52a0oracle\u89e3\u51b3\u65b9\u6848\u7684\u524d\u7f00\uff0c\u5f15\u5bfcRL\u83b7\u5f97\u975e\u96f6\u5956\u52b1\uff1b3\uff09\u901a\u8fc7\u6307\u4ee4\u8ddf\u968f\u548c\u63a8\u7406\u7684\u534f\u540c\u4f5c\u7528\uff0c\u5c06\u5b66\u4e60\u5230\u7684\u884c\u4e3a\u8fc1\u79fb\u56de\u539f\u59cb\u672a\u5f15\u5bfc\u7684\u95ee\u9898\u3002", "result": "POPE\u65b9\u6cd5\u663e\u8457\u6269\u5c55\u4e86\u53ef\u89e3\u51b3\u95ee\u9898\u7684\u8303\u56f4\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u5e45\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "POPE\u901a\u8fc7\u7279\u6743\u4fe1\u606f\u5f15\u5bfc\u63a2\u7d22\uff0c\u6709\u6548\u89e3\u51b3\u4e86RL\u5728\u56f0\u96be\u63a8\u7406\u95ee\u9898\u4e0a\u7684\u63a2\u7d22\u5931\u8d25\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u53ef\u89e3\u95ee\u9898\u8303\u56f4\u548c\u6027\u80fd\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2601.18783", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18783", "abs": "https://arxiv.org/abs/2601.18783", "authors": ["Deepthi Pathare", "Leo Laine", "Morteza Haghir Chehreghani"], "title": "Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic", "comment": null, "summary": "Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8ePPO\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u91cd\u578b\u8f66\u8f86\u5b66\u4e60\u8fde\u7eed\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u96c6\uff0c\u5e73\u8861\u5b89\u5168\u3001\u80fd\u6e90\u6548\u7387\u548c\u65f6\u6548\u6027\u4e09\u5927\u51b2\u7a81\u76ee\u6807", "motivation": "\u9ad8\u901f\u516c\u8def\u9a7e\u9a76\u4e2d\uff0c\u91cd\u578b\u8f66\u8f86\u9700\u8981\u5728\u5b89\u5168\u3001\u6548\u7387\u548c\u8fd0\u8425\u6210\u672c\u4e4b\u95f4\u505a\u51fa\u590d\u6742\u51b3\u7b56\u3002\u4f20\u7edf\u7684\u6807\u91cf\u5956\u52b1\u51fd\u6570\u901a\u8fc7\u805a\u5408\u8fd9\u4e9b\u51b2\u7a81\u76ee\u6807\uff0c\u5f80\u5f80\u63a9\u76d6\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u6743\u8861\u7ed3\u6784\uff0c\u9700\u8981\u66f4\u660e\u786e\u7684\u6743\u8861\u8868\u793a\u65b9\u6cd5", "method": "\u57fa\u4e8e\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u5361\u8f66\u6218\u672f\u51b3\u7b56\u7684\u53ef\u6269\u5c55\u4eff\u771f\u5e73\u53f0\u4e0a\u5b66\u4e60\u8fde\u7eed\u7b56\u7565\u96c6\uff0c\u660e\u786e\u8868\u793a\u5b89\u5168\uff08\u78b0\u649e\u548c\u5b8c\u6210\u7387\uff09\u3001\u80fd\u6e90\u6548\u7387\uff08\u80fd\u6e90\u6210\u672c\uff09\u548c\u65f6\u6548\u6027\uff08\u9a7e\u9a76\u5458\u6210\u672c\uff09\u4e4b\u95f4\u7684\u6743\u8861", "result": "\u5b66\u4e60\u5230\u5e73\u6ed1\u4e14\u53ef\u89e3\u91ca\u7684\u8fde\u7eed\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u96c6\uff0c\u80fd\u591f\u6355\u83b7\u4e09\u4e2a\u51b2\u7a81\u76ee\u6807\u4e4b\u95f4\u7684\u6743\u8861\u3002\u751f\u6210\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u5e73\u6ed1\u53ef\u89e3\u91ca\uff0c\u5141\u8bb8\u5728\u4e0d\u540c\u51b2\u7a81\u76ee\u6807\u4e4b\u95f4\u7075\u6d3b\u9009\u62e9\u9a7e\u9a76\u884c\u4e3a", "conclusion": "\u8be5\u6846\u67b6\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5728\u4e0d\u540c\u9a7e\u9a76\u7b56\u7565\u4e4b\u95f4\u65e0\u7f1d\u5207\u6362\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5361\u8f66\u5e94\u7528\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u81ea\u9002\u5e94\u7684\u51b3\u7b56\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u5bf9\u51b2\u7a81\u76ee\u6807\u7684\u660e\u786e\u6743\u8861\u8868\u793a"}}
{"id": "2601.18795", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18795", "abs": "https://arxiv.org/abs/2601.18795", "authors": ["Amrith Setlur", "Zijian Wang", "Andrew Cohen", "Paria Rashidinejad", "Sang Michael Xie"], "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes", "comment": null, "summary": "Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.", "AI": {"tldr": "PrefixRL\uff1a\u4e00\u79cd\u901a\u8fc7\u91cd\u7528\u79bb\u7ebf\u7b56\u7565\u8f68\u8ff9\u524d\u7f00\u6765\u63d0\u5347LLM\u63a8\u7406\u5f3a\u5316\u5b66\u4e60\u6548\u7387\u7684\u65b0\u65b9\u6cd5\uff0c\u907f\u514d\u79bb\u7ebf\u7b56\u7565\u4e0d\u7a33\u5b9a\u6027\uff0c\u5728\u56f0\u96be\u95ee\u9898\u4e0a\u5b9e\u73b02\u500d\u8bad\u7ec3\u52a0\u901f\u548c3\u500d\u6700\u7ec8\u5956\u52b1\u63d0\u5347", "motivation": "\u4f20\u7edfRL\u65b9\u6cd5\u5728LLM\u63a8\u7406\u7684\u56f0\u96be\u95ee\u9898\u4e0a\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u4e3a\u6b63\u786e\u7b56\u7565\u8f68\u8ff9\u7a00\u5c11\u3001\u7b56\u7565\u68af\u5ea6\u6d88\u5931\u5bfc\u81f4\u5b66\u4e60\u505c\u6ede\u3002\u9700\u8981\u91cd\u7528\u5148\u524d\u63a8\u7406\u6216RL\u8bad\u7ec3\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\uff08\u79bb\u7ebf\u7b56\u7565\u8f68\u8ff9\uff09\uff0c\u4f46\u6807\u51c6\u79bb\u7ebf\u7b56\u7565\u65b9\u6cd5\u4f1a\u5bfc\u81f4RL\u4f18\u5316\u4e0d\u7a33\u5b9a", "method": "PrefixRL\u65b9\u6cd5\uff1a\u57fa\u4e8e\u6210\u529f\u79bb\u7ebf\u7b56\u7565\u8f68\u8ff9\u7684\u524d\u7f00\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u7136\u540e\u8fd0\u884c\u5728\u7ebfRL\u6765\u8865\u5168\u8fd9\u4e9b\u8f68\u8ff9\uff0c\u907f\u514d\u79bb\u7ebf\u7b56\u7565\u4e0d\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u8c03\u8282\u524d\u7f00\u957f\u5ea6\u6765\u63a7\u5236\u95ee\u9898\u96be\u5ea6\uff0c\u63d0\u5347\u56f0\u96be\u95ee\u9898\u7684\u5b66\u4e60\u4fe1\u53f7\u3002\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u83b7\u53d6\u79bb\u7ebf\u7b56\u7565\u8f68\u8ff9\uff0c\u5f62\u6210\u81ea\u6211\u6539\u8fdb\u5faa\u73af", "result": "\u5728\u56f0\u96be\u63a8\u7406\u95ee\u9898\u4e0a\uff0cPrefixRL\u8fbe\u5230\u76f8\u540c\u8bad\u7ec3\u5956\u52b1\u7684\u901f\u5ea6\u6bd4\u6700\u5f3a\u57fa\u7ebf\uff08\u79bb\u7ebf\u6570\u636eSFT\u540eRL\uff09\u5feb2\u500d\uff08\u5373\u4f7f\u8003\u8651\u521d\u59cb\u62d2\u7edd\u91c7\u6837\u7684\u8ba1\u7b97\u6210\u672c\uff09\uff0c\u6700\u7ec8\u5956\u52b1\u63d0\u53473\u500d\u3002\u53d1\u73b0\u540e\u5411\u6cdb\u5316\u73b0\u8c61\uff1a\u4ec5\u5728\u524d\u7f00\u95ee\u9898\u4e0a\u8bad\u7ec3\u80fd\u6cdb\u5316\u5230\u975e\u524d\u7f00\u6027\u80fd\u3002\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u65cf\u6765\u6e90\u7684\u79bb\u7ebf\u8f68\u8ff9\u4e0a\u4ecd\u7136\u6709\u6548", "conclusion": "PrefixRL\u901a\u8fc7\u91cd\u7528\u79bb\u7ebf\u7b56\u7565\u8f68\u8ff9\u524d\u7f00\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u63a8\u7406RL\u4e2d\u7684\u6837\u672c\u6548\u7387\u95ee\u9898\uff0c\u907f\u514d\u4e86\u79bb\u7ebf\u7b56\u7565\u4e0d\u7a33\u5b9a\u6027\uff0c\u5728\u56f0\u96be\u95ee\u9898\u4e0a\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6700\u7ec8\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u7684\u7075\u6d3b\u6027"}}
