{"id": "2602.00787", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.00787", "abs": "https://arxiv.org/abs/2602.00787", "authors": ["Ceylin Savas", "Maryam Javed", "Murat Kuscu"], "title": "Hybrid Artificial-Living Cell Collectives for Wetware Computing", "comment": null, "summary": "Living systems continuously sense, integrate, and act on chemical information using multiscale biochemical networks whose dynamics are inherently nonlinear, adaptive, and energy-efficient. Yet, most attempts to harness such \"wetware\" for external computational tasks have centered on neural tissue and electrical interfaces, leaving the information-processing potential of non-neural collectives comparatively underexplored. In this letter, we study a hybrid artificial-living cell network in which programmable artificial cells write time-varying inputs into a biochemical microenvironment, while a living bacterial collective provides the nonlinear spatiotemporal dynamics required for temporal information processing. Specifically, artificial cells transduce an external input sequence into the controlled secretion of attractant and repellent molecules, thereby modulating the \"local biochemical context\" that bacteria naturally sense and respond to. The resulting collective bacterial dynamics, together with the evolving molecular fields, form a high-dimensional reservoir state that is sampled coarsely (voxel-wise) and mapped to outputs through a trained linear readout within a physical reservoir computing framework. Using an agent-based in silico model, we evaluate the proposed hybrid reservoir on the Mackey-Glass chaotic time-series prediction benchmark. The system achieves normalized root mean square error (NRMSE) values of approximately 0.33-0.40 for prediction horizons H=1 to 5, and exhibits measurable short-term memory as encoded in the distributed spatiotemporal patterns of bacteria and biochemicals. These results motivate the future exploration of non-neural hybrid cell networks for in situ temporal signal processing towards novel biomedical applications.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u4eba\u5de5-\u6d3b\u7ec6\u80de\u7f51\u7edc\uff0c\u5229\u7528\u7ec6\u83cc\u96c6\u4f53\u8fdb\u884c\u65f6\u95f4\u4fe1\u606f\u5904\u7406\uff0c\u5728\u6df7\u6c8c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u826f\u597d\u6027\u80fd", "motivation": "\u73b0\u6709\u6e7f\u4ef6\u8ba1\u7b97\u4e3b\u8981\u5173\u6ce8\u795e\u7ecf\u7ec4\u7ec7\u548c\u7535\u63a5\u53e3\uff0c\u975e\u795e\u7ecf\u96c6\u4f53\u7684\u4fe1\u606f\u5904\u7406\u6f5c\u529b\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u5229\u7528\u7ec6\u83cc\u96c6\u4f53\u7684\u975e\u7ebf\u6027\u65f6\u7a7a\u52a8\u529b\u5b66\u8fdb\u884c\u65f6\u95f4\u4fe1\u606f\u5904\u7406", "method": "\u6784\u5efa\u6df7\u5408\u4eba\u5de5-\u6d3b\u7ec6\u80de\u7f51\u7edc\uff1a\u4eba\u5de5\u7ec6\u80de\u5c06\u5916\u90e8\u8f93\u5165\u8f6c\u6362\u4e3a\u5438\u5f15\u5242/\u6392\u65a5\u5242\u5206\u5b50\u7684\u53d7\u63a7\u5206\u6ccc\uff0c\u7ec6\u83cc\u96c6\u4f53\u611f\u77e5\u5e76\u54cd\u5e94\u8fd9\u4e9b\u5206\u5b50\uff0c\u5f62\u6210\u9ad8\u7ef4\u50a8\u5c42\u72b6\u6001\uff0c\u901a\u8fc7\u7269\u7406\u50a8\u5c42\u8ba1\u7b97\u6846\u67b6\u8fdb\u884c\u7ebf\u6027\u8bfb\u51fa", "result": "\u5728Mackey-Glass\u6df7\u6c8c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7cfb\u7edf\u5728\u9884\u6d4b\u8303\u56f4H=1\u52305\u65f6\u8fbe\u5230NRMSE\u7ea60.33-0.40\uff0c\u8868\u73b0\u51fa\u53ef\u6d4b\u91cf\u7684\u77ed\u671f\u8bb0\u5fc6\u80fd\u529b", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u975e\u795e\u7ecf\u6df7\u5408\u7ec6\u80de\u7f51\u7edc\u5728\u751f\u7269\u533b\u5b66\u5e94\u7528\u4e2d\u7684\u539f\u4f4d\u65f6\u95f4\u4fe1\u53f7\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u63a2\u7d22\u65b9\u5411"}}
{"id": "2602.01503", "categories": ["cs.ET", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.01503", "abs": "https://arxiv.org/abs/2602.01503", "authors": ["Afifah Kashif", "Abdul Muhsin Hameed", "Asim Iqbal"], "title": "Governance at the Edge of Architecture: Regulating NeuroAI and Neuromorphic Systems", "comment": "9 pages, 1 table, 1 figure", "summary": "Current AI governance frameworks, including regulatory benchmarks for accuracy, latency, and energy efficiency, are built for static, centrally trained artificial neural networks on von Neumann hardware. NeuroAI systems, embodied in neuromorphic hardware and implemented via spiking neural networks, break these assumptions. This paper examines the limitations of current AI governance frameworks for NeuroAI, arguing that assurance and audit methods must co-evolve with these architectures, aligning traditional regulatory metrics with the physics, learning dynamics, and embodied efficiency of brain-inspired computation to enable technically grounded assurance.", "AI": {"tldr": "\u5f53\u524dAI\u6cbb\u7406\u6846\u67b6\u4e0d\u9002\u7528\u4e8eNeuroAI\u7cfb\u7edf\uff0c\u9700\u8981\u5f00\u53d1\u4e0e\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u548c\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7279\u6027\u76f8\u5339\u914d\u7684\u65b0\u6cbb\u7406\u65b9\u6cd5", "motivation": "\u5f53\u524dAI\u6cbb\u7406\u6846\u67b6\u57fa\u4e8e\u4f20\u7edf\u51af\u00b7\u8bfa\u4f9d\u66fc\u67b6\u6784\u548c\u9759\u6001\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\uff0c\u800cNeuroAI\u7cfb\u7edf\uff08\u795e\u7ecf\u5f62\u6001\u786c\u4ef6+\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff09\u6253\u7834\u4e86\u8fd9\u4e9b\u5047\u8bbe\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u6cbb\u7406\u65b9\u6cd5", "method": "\u5206\u6790\u5f53\u524dAI\u6cbb\u7406\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u8bba\u8bc1\u9700\u8981\u5f00\u53d1\u4e0eNeuroAI\u67b6\u6784\u5171\u540c\u6f14\u8fdb\u7684\u4fdd\u8bc1\u548c\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5c06\u4f20\u7edf\u76d1\u7ba1\u6307\u6807\u4e0e\u8111\u542f\u53d1\u8ba1\u7b97\u7684\u7269\u7406\u7279\u6027\u3001\u5b66\u4e60\u52a8\u6001\u548c\u5177\u8eab\u6548\u7387\u76f8\u7ed3\u5408", "result": "\u8bc6\u522b\u51fa\u73b0\u6709AI\u6cbb\u7406\u6846\u67b6\u5728\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u80fd\u6548\u7b49\u57fa\u51c6\u65b9\u9762\u4e0d\u9002\u7528\u4e8eNeuroAI\u7cfb\u7edf\uff0c\u9700\u8981\u57fa\u4e8e\u6280\u672f\u57fa\u7840\u7684\u4fdd\u8bc1\u65b9\u6cd5", "conclusion": "AI\u6cbb\u7406\u6846\u67b6\u5fc5\u987b\u4e0eNeuroAI\u67b6\u6784\u5171\u540c\u6f14\u8fdb\uff0c\u5c06\u4f20\u7edf\u76d1\u7ba1\u6307\u6807\u4e0e\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u7684\u7269\u7406\u548c\u52a8\u6001\u7279\u6027\u5bf9\u9f50\uff0c\u4ee5\u5b9e\u73b0\u6280\u672f\u57fa\u7840\u7684\u4fdd\u8bc1"}}
{"id": "2602.00087", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.00087", "abs": "https://arxiv.org/abs/2602.00087", "authors": ["Haolin Pan", "Lianghong Huang", "Jinyuan Dong", "Mingjie Xing", "Yanjun Wu"], "title": "ECCO: Evidence-Driven Causal Reasoning for Compiler Optimization", "comment": null, "summary": "Compiler auto-tuning faces a dichotomy between traditional black-box search methods, which lack semantic guidance, and recent Large Language Model (LLM) approaches, which often suffer from superficial pattern matching and causal opacity. In this paper, we introduce ECCO, a framework that bridges interpretable reasoning with combinatorial search. We first propose a reverse engineering methodology to construct a Chain-of-Thought dataset, explicitly mapping static code features to verifiable performance evidence. This enables the model to learn the causal logic governing optimization decisions rather than merely imitating sequences. Leveraging this interpretable prior, we design a collaborative inference mechanism where the LLM functions as a strategist, defining optimization intents that dynamically guide the mutation operations of a genetic algorithm. Experimental results on seven datasets demonstrate that ECCO significantly outperforms the LLVM opt -O3 baseline, achieving an average 24.44% reduction in cycles.", "AI": {"tldr": "ECCO\u6846\u67b6\u7ed3\u5408\u53ef\u89e3\u91ca\u63a8\u7406\u4e0e\u7ec4\u5408\u641c\u7d22\uff0c\u901a\u8fc7\u6784\u5efa\u601d\u7ef4\u94fe\u6570\u636e\u96c6\u8ba9LLM\u5b66\u4e60\u4f18\u5316\u51b3\u7b56\u7684\u56e0\u679c\u903b\u8f91\uff0c\u7136\u540e\u8ba9LLM\u4f5c\u4e3a\u7b56\u7565\u5e08\u6307\u5bfc\u9057\u4f20\u7b97\u6cd5\u7684\u53d8\u5f02\u64cd\u4f5c\uff0c\u5728\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u4e2d\u663e\u8457\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u9762\u4e34\u4f20\u7edf\u9ed1\u76d2\u641c\u7d22\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u6307\u5bfc\u4e0eLLM\u65b9\u6cd5\u5b58\u5728\u8868\u9762\u6a21\u5f0f\u5339\u914d\u548c\u56e0\u679c\u4e0d\u900f\u660e\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u53ef\u89e3\u91ca\u63a8\u7406\u548c\u7ec4\u5408\u641c\u7d22\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u63d0\u51fa\u9006\u5411\u5de5\u7a0b\u65b9\u6cd5\u6784\u5efa\u601d\u7ef4\u94fe\u6570\u636e\u96c6\uff0c\u5c06\u9759\u6001\u4ee3\u7801\u7279\u5f81\u6620\u5c04\u5230\u53ef\u9a8c\u8bc1\u7684\u6027\u80fd\u8bc1\u636e\uff1b\u7136\u540e\u8bbe\u8ba1\u534f\u4f5c\u63a8\u7406\u673a\u5236\uff0c\u8ba9LLM\u4f5c\u4e3a\u7b56\u7565\u5e08\u5b9a\u4e49\u4f18\u5316\u610f\u56fe\uff0c\u52a8\u6001\u6307\u5bfc\u9057\u4f20\u7b97\u6cd5\u7684\u53d8\u5f02\u64cd\u4f5c\u3002", "result": "\u57287\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cECCO\u663e\u8457\u4f18\u4e8eLLVM opt -O3\u57fa\u7ebf\uff0c\u5e73\u5747\u51cf\u5c1124.44%\u7684\u5468\u671f\u6570\u3002", "conclusion": "ECCO\u6210\u529f\u5730\u5c06\u53ef\u89e3\u91ca\u63a8\u7406\u4e0e\u7ec4\u5408\u641c\u7d22\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u4e2d\u8bed\u4e49\u6307\u5bfc\u4e0d\u8db3\u548c\u56e0\u679c\u4e0d\u900f\u660e\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.00330", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.00330", "abs": "https://arxiv.org/abs/2602.00330", "authors": ["Sheldon X. -D. Tan", "Haotian Lu"], "title": "Accelerating Physics-Based Electromigration Analysis via Rational Krylov Subspaces", "comment": null, "summary": "Electromigration (EM) induced stress evolution is a major reliability challenge in nanometer-scale VLSI interconnects. Accurate EM analysis requires solving stress-governing partial differential equations over large interconnect trees, which is computationally expensive using conventional finite-difference methods. This work proposes two fast EM stress analysis techniques based on rational Krylov subspace reduction. Unlike traditional Krylov methods that expand around zero frequency, rational Krylov methods enable expansion at selected time constants, aligning directly with metrics such as nucleation and steady-state times and producing compact reduced models with minimal accuracy loss. Two complementary frameworks are developed: a frequency-domain extended rational Krylov method, ExtRaKrylovEM, and a time-domain rational Krylov exponential integration method, EiRaKrylovEM. We show that the accuracy of both methods depends strongly on the choice of expansion point, or shift time, and demonstrate that effective shift times are typically close to times of interest such as nucleation or post-void steady state. Based on this observation, a coordinate descent optimization strategy is introduced to automatically determine optimal reduction orders and shift times for both nucleation and post-void phases. Experimental results on synthesized structures and industry-scale power grids show that the proposed methods achieve orders-of-magnitude improvements in efficiency and accuracy over finite-difference solutions. Using only 4 to 6 Krylov orders, the methods achieve sub-0.1 percent error in nucleation time and resistance change predictions while delivering 20 to 500 times speedup. In contrast, standard extended Krylov methods require more than 50 orders and still incur 10 to 20 percent nucleation time error, limiting their practicality for EM-aware optimization and stochastic EM analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u6709\u7406Krylov\u5b50\u7a7a\u95f4\u7f29\u51cf\u7684\u5feb\u901f\u7535\u8fc1\u79fb\u5e94\u529b\u5206\u6790\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u6709\u9650\u5dee\u5206\u6cd5\u5b9e\u73b0\u6570\u91cf\u7ea7\u6548\u7387\u63d0\u5347\u548c\u66f4\u9ad8\u7cbe\u5ea6", "motivation": "\u7535\u8fc1\u79fb\u5f15\u8d77\u7684\u5e94\u529b\u6f14\u5316\u662f\u7eb3\u7c73\u7ea7VLSI\u4e92\u8fde\u7684\u4e3b\u8981\u53ef\u9760\u6027\u6311\u6218\uff0c\u4f20\u7edf\u6709\u9650\u5dee\u5206\u6cd5\u6c42\u89e3\u5e94\u529b\u63a7\u5236\u504f\u5fae\u5206\u65b9\u7a0b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5206\u6790\u65b9\u6cd5", "method": "\u5f00\u53d1\u4e24\u79cd\u6709\u7406Krylov\u5b50\u7a7a\u95f4\u7f29\u51cf\u6846\u67b6\uff1a\u9891\u57df\u6269\u5c55\u6709\u7406Krylov\u65b9\u6cd5ExtRaKrylovEM\u548c\u65f6\u57df\u6709\u7406Krylov\u6307\u6570\u79ef\u5206\u65b9\u6cd5EiRaKrylovEM\uff0c\u5f15\u5165\u5750\u6807\u4e0b\u964d\u4f18\u5316\u7b56\u7565\u81ea\u52a8\u786e\u5b9a\u6700\u4f18\u7f29\u51cf\u9636\u6570\u548c\u504f\u79fb\u65f6\u95f4", "result": "\u5728\u5408\u6210\u7ed3\u6784\u548c\u5de5\u4e1a\u7ea7\u7535\u6e90\u7f51\u7edc\u4e0a\uff0c\u4ec5\u97004-6\u9636Krylov\u5c31\u80fd\u5b9e\u73b0\u6210\u6838\u65f6\u95f4\u548c\u7535\u963b\u53d8\u5316\u9884\u6d4b\u7684\u4e9a0.1%\u8bef\u5dee\uff0c\u83b7\u5f9720-500\u500d\u52a0\u901f\uff1b\u800c\u6807\u51c6\u6269\u5c55Krylov\u65b9\u6cd5\u9700\u898150\u591a\u9636\u4e14\u4ecd\u670910-20%\u8bef\u5dee", "conclusion": "\u6709\u7406Krylov\u65b9\u6cd5\u901a\u8fc7\u5728\u4e0e\u5173\u952e\u65f6\u95f4\u5e38\u6570\u5bf9\u9f50\u7684\u504f\u79fb\u70b9\u5c55\u5f00\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7cbe\u786e\u7684\u7535\u8fc1\u79fb\u5e94\u529b\u5206\u6790\uff0c\u4e3a\u7535\u8fc1\u79fb\u611f\u77e5\u4f18\u5316\u548c\u968f\u673a\u7535\u8fc1\u79fb\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00014", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00014", "abs": "https://arxiv.org/abs/2602.00014", "authors": ["Pierrick Pochelu", "Hyacinthe Cartiaux", "Julien Schleich"], "title": "What Artificial Intelligence can do for High-Performance Computing systems?", "comment": null, "summary": "High-performance computing (HPC) centers consume substantial power, incurring environmental and operational costs. This review assesses how artificial intelligence (AI), including machine learning (ML) and optimization, improves the efficiency of operational HPC systems. Approximately 1,800 publications from 2019 to 2025 were manually screened using predefined inclusion/exclusion criteria; 74 \"AI for HPC\" papers were retained and grouped into six application areas: performance estimation, performance optimization, scheduling, surrogate modeling, fault detection, and language-model-based automation.\n  Scheduling is the most active area, spanning research-oriented reinforcement-learning schedulers to production-friendly hybrids that combine ML with heuristics. Supervised performance estimation is foundational for both scheduling and optimization. Graph neural networks and time-series models strengthen anomaly detection by capturing spatio-temporal dependencies in production telemetry. Domain-specialized language models for HPC can outperform general-purpose LLMs on targeted coding and automation tasks. Together, these findings highlight integration opportunities such as LLM-based operating-system concepts and underscore the need for advances in MLOps, standardization of AI components, and benchmarking methodology.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u5206\u6790\u4e862019-2025\u5e74\u95f4AI\u5728HPC\u7cfb\u7edf\u6548\u7387\u63d0\u5347\u4e2d\u7684\u5e94\u7528\uff0c\u7b5b\u9009\u4e8674\u7bc7\u8bba\u6587\uff0c\u8bc6\u522b\u51fa\u516d\u4e2a\u4e3b\u8981\u5e94\u7528\u9886\u57df\uff1a\u6027\u80fd\u4f30\u8ba1\u3001\u6027\u80fd\u4f18\u5316\u3001\u8c03\u5ea6\u3001\u4ee3\u7406\u5efa\u6a21\u3001\u6545\u969c\u68c0\u6d4b\u548c\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u5fc3\u6d88\u8017\u5927\u91cf\u7535\u529b\uff0c\u5e26\u6765\u73af\u5883\u548c\u8fd0\u8425\u6210\u672c\u3002\u9700\u8981\u5229\u7528\u4eba\u5de5\u667a\u80fd\uff08\u5305\u62ec\u673a\u5668\u5b66\u4e60\u548c\u4f18\u5316\uff09\u6765\u63d0\u9ad8HPC\u7cfb\u7edf\u7684\u8fd0\u884c\u6548\u7387\u3002", "method": "\u624b\u52a8\u7b5b\u9009\u4e86\u7ea61800\u7bc72019-2025\u5e74\u7684\u51fa\u7248\u7269\uff0c\u4f7f\u7528\u9884\u5b9a\u4e49\u7684\u7eb3\u5165/\u6392\u9664\u6807\u51c6\uff0c\u4fdd\u7559\u4e8674\u7bc7\"AI for HPC\"\u8bba\u6587\uff0c\u5e76\u5c06\u5176\u5206\u4e3a\u516d\u4e2a\u5e94\u7528\u9886\u57df\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8c03\u5ea6\u662f\u6700\u6d3b\u8dc3\u7684\u7814\u7a76\u9886\u57df\uff0c\u4ece\u7814\u7a76\u5bfc\u5411\u7684\u5f3a\u5316\u5b66\u4e60\u8c03\u5ea6\u5668\u5230\u7ed3\u5408ML\u4e0e\u542f\u53d1\u5f0f\u7684\u751f\u4ea7\u53cb\u597d\u578b\u6df7\u5408\u65b9\u6cd5\u3002\u76d1\u7763\u6027\u80fd\u4f30\u8ba1\u662f\u8c03\u5ea6\u548c\u4f18\u5316\u7684\u57fa\u7840\u3002\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u901a\u8fc7\u6355\u6349\u751f\u4ea7\u9065\u6d4b\u6570\u636e\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u6765\u52a0\u5f3a\u5f02\u5e38\u68c0\u6d4b\u3002\u9488\u5bf9HPC\u9886\u57df\u4e13\u95e8\u5316\u7684\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u7f16\u7801\u548c\u81ea\u52a8\u5316\u4efb\u52a1\u4e0a\u4f18\u4e8e\u901a\u7528LLM\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u51fa\u4e86\u6574\u5408\u673a\u4f1a\uff08\u5982\u57fa\u4e8eLLM\u7684\u64cd\u4f5c\u7cfb\u7edf\u6982\u5ff5\uff09\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u5728MLOps\u3001AI\u7ec4\u4ef6\u6807\u51c6\u5316\u548c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\u3002"}}
{"id": "2602.00012", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00012", "abs": "https://arxiv.org/abs/2602.00012", "authors": ["Michael Siebenmann", "Javier Argota S\u00e1nchez-Vaquerizo", "Stefan Arisona", "Krystian Samp", "Luis Gisler", "Dirk Helbing"], "title": "OGD4All: A Framework for Accessible Interaction with Geospatial Open Government Data Based on Large Language Models", "comment": "This work has been submitted to the IEEE for possible publication. 7 pages, 6 figures", "summary": "We present OGD4All, a transparent, auditable, and reproducible framework based on Large Language Models (LLMs) to enhance citizens' interaction with geospatial Open Government Data (OGD). The system combines semantic data retrieval, agentic reasoning for iterative code generation, and secure sandboxed execution that produces verifiable multimodal outputs. Evaluated on a 199-question benchmark covering both factual and unanswerable questions, across 430 City-of-Zurich datasets and 11 LLMs, OGD4All reaches 98% analytical correctness and 94% recall while reliably rejecting questions unsupported by available data, which minimizes hallucination risks. Statistical robustness tests, as well as expert feedback, show reliability and social relevance. The proposed approach shows how LLMs can provide explainable, multimodal access to public data, advancing trustworthy AI for open governance.", "AI": {"tldr": "OGD4All\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u900f\u660e\u3001\u53ef\u5ba1\u8ba1\u3001\u53ef\u590d\u73b0\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u516c\u6c11\u4e0e\u5730\u7406\u7a7a\u95f4\u5f00\u653e\u653f\u5e9c\u6570\u636e\u7684\u4ea4\u4e92\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u7d22\u3001\u4ee3\u7406\u63a8\u7406\u548c\u6c99\u7bb1\u6267\u884c\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u7684\u591a\u6a21\u6001\u8f93\u51fa\u3002", "motivation": "\u589e\u5f3a\u516c\u6c11\u4e0e\u5730\u7406\u7a7a\u95f4\u5f00\u653e\u653f\u5e9c\u6570\u636e\u7684\u4ea4\u4e92\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u5ba1\u8ba1\u3001\u53ef\u590d\u73b0\u7684\u8bbf\u95ee\u65b9\u5f0f\uff0c\u63a8\u8fdb\u53ef\u4fe1AI\u5728\u5f00\u653e\u6cbb\u7406\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u7ed3\u5408\u8bed\u4e49\u6570\u636e\u68c0\u7d22\u3001\u4ee3\u7406\u63a8\u7406\u8fdb\u884c\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\uff0c\u4ee5\u53ca\u5b89\u5168\u7684\u6c99\u7bb1\u6267\u884c\uff0c\u4ea7\u751f\u53ef\u9a8c\u8bc1\u7684\u591a\u6a21\u6001\u8f93\u51fa\u3002", "result": "\u5728199\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff08\u6db5\u76d6\u4e8b\u5b9e\u6027\u548c\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\uff09\uff0c\u4f7f\u7528430\u4e2a\u82cf\u9ece\u4e16\u5e02\u6570\u636e\u96c6\u548c11\u4e2aLLM\uff0c\u8fbe\u523098%\u7684\u5206\u6790\u6b63\u786e\u7387\u548c94%\u7684\u53ec\u56de\u7387\uff0c\u540c\u65f6\u53ef\u9760\u5730\u62d2\u7edd\u6570\u636e\u4e0d\u652f\u6301\u7684\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u5e7b\u89c9\u98ce\u9669\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86LLM\u5982\u4f55\u4e3a\u516c\u5171\u6570\u636e\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u8bbf\u95ee\uff0c\u63a8\u8fdb\u4e86\u5f00\u653e\u6cbb\u7406\u4e2d\u7684\u53ef\u4fe1AI\u3002"}}
{"id": "2602.00343", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.00343", "abs": "https://arxiv.org/abs/2602.00343", "authors": ["Austin Tapp", "Holger R. Roth", "Ziyue Xu", "Abhijeet Parida", "Hareem Nisar", "Marius George Linguraru"], "title": "Standardized Methods and Recommendations for Green Federated Learning", "comment": "4 sections, 9 pages, 5 figures, 26 references, submission to acm e-energy,", "summary": "Federated learning (FL) enables collaborative model training over privacy-sensitive, distributed data, but its environmental impact is difficult to compare across studies due to inconsistent measurement boundaries and heterogeneous reporting. We present a practical carbon-accounting methodology for FL CO2e tracking using NVIDIA NVFlare and CodeCarbon for explicit, phase-aware tasks (initialization, per-round training, evaluation, and idle/coordination). To capture non-compute effects, we additionally estimate communication emissions from transmitted model-update sizes under a network-configurable energy model. We validate the proposed approach on two representative workloads: CIFAR-10 image classification and retinal optic disk segmentation. In CIFAR-10, controlled client-efficiency scenarios show that system-level slowdowns and coordination effects can contribute meaningfully to carbon footprint under an otherwise fixed FL protocol, increasing total CO2e by 8.34x (medium) and 21.73x (low) relative to the high-efficiency baseline. In retinal segmentation, swapping GPU tiers (H100 vs.\\ V100) yields a consistent 1.7x runtime gap (290 vs. 503 minutes) while producing non-uniform changes in total energy and CO2e across sites, underscoring the need for per-site and per-round reporting. Overall, our results support a standardized carbon accounting method that acts as a prerequisite for reproducible 'green' FL evaluation. Our code is available at https://github.com/Pediatric-Accelerated-Intelligence-Lab/carbon_footprint.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5b9e\u7528\u7684\u8054\u90a6\u5b66\u4e60\u78b3\u6838\u7b97\u65b9\u6cd5\uff0c\u7ed3\u5408NVIDIA NVFlare\u548cCodeCarbon\u8fdb\u884c\u9636\u6bb5\u611f\u77e5\u7684CO\u2082e\u8ffd\u8e2a\uff0c\u5e76\u8003\u8651\u901a\u4fe1\u6392\u653e\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6548\u7387\u5dee\u5f02\u5bf9\u78b3\u8db3\u8ff9\u7684\u663e\u8457\u5f71\u54cd", "motivation": "\u8054\u90a6\u5b66\u4e60\u7684\u73af\u5883\u5f71\u54cd\u96be\u4ee5\u8de8\u7814\u7a76\u6bd4\u8f83\uff0c\u56e0\u4e3a\u6d4b\u91cf\u8fb9\u754c\u4e0d\u4e00\u81f4\u548c\u62a5\u544a\u5f02\u6784\u3002\u9700\u8981\u6807\u51c6\u5316\u7684\u78b3\u6838\u7b97\u65b9\u6cd5\u6765\u652f\u6301\u53ef\u91cd\u590d\u7684\"\u7eff\u8272\"\u8054\u90a6\u5b66\u4e60\u8bc4\u4f30", "method": "\u4f7f\u7528NVIDIA NVFlare\u548cCodeCarbon\u5f00\u53d1\u9636\u6bb5\u611f\u77e5\u7684\u78b3\u6838\u7b97\u65b9\u6cd5\uff0c\u8ffd\u8e2a\u521d\u59cb\u5316\u3001\u6bcf\u8f6e\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u7a7a\u95f2/\u534f\u8c03\u9636\u6bb5\u7684CO\u2082e\uff0c\u5e76\u4f30\u8ba1\u901a\u4fe1\u6392\u653e\u3002\u5728CIFAR-10\u56fe\u50cf\u5206\u7c7b\u548c\u89c6\u7f51\u819c\u89c6\u76d8\u5206\u5272\u4efb\u52a1\u4e0a\u9a8c\u8bc1", "result": "CIFAR-10\u5b9e\u9a8c\u4e2d\uff0c\u7cfb\u7edf\u6548\u7387\u964d\u4f4e\u4f7f\u603bCO\u2082e\u589e\u52a08.34\u500d\uff08\u4e2d\u7b49\u6548\u7387\uff09\u548c21.73\u500d\uff08\u4f4e\u6548\u7387\uff09\u3002\u89c6\u7f51\u819c\u5206\u5272\u4e2d\uff0cGPU\u5c42\u7ea7\u4ea4\u6362\uff08H100 vs V100\uff09\u4ea7\u751f1.7\u500d\u8fd0\u884c\u65f6\u95f4\u5dee\u5f02\uff0c\u4f46\u4e0d\u540c\u7ad9\u70b9\u7684\u603b\u80fd\u8017\u548cCO\u2082e\u53d8\u5316\u4e0d\u5747\u5300", "conclusion": "\u9700\u8981\u6807\u51c6\u5316\u7684\u78b3\u6838\u7b97\u65b9\u6cd5\u4f5c\u4e3a\u53ef\u91cd\u590d\"\u7eff\u8272\"\u8054\u90a6\u5b66\u4e60\u8bc4\u4f30\u7684\u524d\u63d0\uff0c\u652f\u6301\u6309\u7ad9\u70b9\u548c\u6309\u8f6e\u6b21\u62a5\u544a\uff0c\u4ee5\u51c6\u786e\u8bc4\u4f30\u73af\u5883\u5f71\u54cd"}}
{"id": "2602.00342", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.00342", "abs": "https://arxiv.org/abs/2602.00342", "authors": ["Rafi Zahedi", "Amirhossein Ahmadian", "Chen Zhang", "Shashank Narayana Gowda", "Kourosh SedghiSigarchi", "Rajit Gadh"], "title": "Optimal Engagement of Residential Battery Storage to Alleviate Grid Upgrades Caused by EVs and Solar Systems", "comment": "Published at Advances in Science, Technology and Engineering Systems Journal (ASTESJ)- https://www.astesj.com/v09/i02/p01/", "summary": "The integration of distributed energy resources has ushered in a host of complex challenges, significantly impacting power quality in distribution networks. This work studies these challenges, exploring issues such as voltage fluctuations and escalating power losses caused by the integration of solar systems and electric vehicle (EV) chargers. We present a robust methodology focused on mitigating voltage deviations and power losses, emphasizing the allocation of a Permitted Percentage (PP) of battery-based solar systems within residential areas endowed with storage capabilities. A key facet of this research lies in its adaptability to the changing landscape of electric transportation. With the rapid increase of electric trucks on the horizon, our proposed model gains relevance. By tactically deploying PP to oversee the charging and discharging of batteries within residential solar systems, utilities are poised not only to assist with grid resilience but also to cater to the upcoming demands spurred by the advent of new EVs, notably trucks. To validate the efficacy of our proposed model, rigorous simulations were conducted using the IEEE 33-bus distribution network as a designed testbed. Leveraging advanced Particle Swarm Optimization techniques, we have deciphered the optimal charging and discharging commands issued by utilities to energy storage systems. The outcomes of these simulations help us understand the transformative potential of various PP allocations, shedding light on the balance between non-battery-based and battery-based solar residences. This research underscores the need for carefully crafted approaches in navigating the complexities of modern grid dynamics amid the anticipated increase in electric vehicles.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7535\u6c60\u50a8\u80fd\u592a\u9633\u80fd\u7cfb\u7edf\u7684\u5141\u8bb8\u767e\u5206\u6bd4\uff08PP\uff09\u5206\u914d\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f13\u89e3\u5206\u5e03\u5f0f\u80fd\u6e90\u63a5\u5165\u5e26\u6765\u7684\u7535\u538b\u6ce2\u52a8\u548c\u529f\u7387\u635f\u8017\u95ee\u9898\uff0c\u7279\u522b\u9488\u5bf9\u7535\u52a8\u6c7d\u8f66\uff08\u5c24\u5176\u662f\u5361\u8f66\uff09\u589e\u957f\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\uff08\u7279\u522b\u662f\u592a\u9633\u80fd\u7cfb\u7edf\u548c\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u6869\uff09\u7684\u96c6\u6210\u7ed9\u914d\u7535\u7f51\u5e26\u6765\u4e86\u590d\u6742\u7684\u7535\u80fd\u8d28\u91cf\u95ee\u9898\uff0c\u5305\u62ec\u7535\u538b\u6ce2\u52a8\u548c\u529f\u7387\u635f\u8017\u589e\u52a0\u3002\u968f\u7740\u7535\u52a8\u5361\u8f66\u7b49\u65b0\u578b\u7535\u52a8\u6c7d\u8f66\u7684\u5feb\u901f\u589e\u957f\uff0c\u7535\u7f51\u9762\u4e34\u66f4\u5927\u538b\u529b\uff0c\u9700\u8981\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u7ef4\u6301\u7535\u7f51\u7a33\u5b9a\u6027\u548c\u5f39\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9c81\u68d2\u7684\u65b9\u6cd5\u8bba\uff0c\u91cd\u70b9\u662f\u901a\u8fc7\u5728\u5177\u6709\u50a8\u80fd\u80fd\u529b\u7684\u4f4f\u5b85\u533a\u57df\u5206\u914d\u7535\u6c60\u50a8\u80fd\u592a\u9633\u80fd\u7cfb\u7edf\u7684\u5141\u8bb8\u767e\u5206\u6bd4\uff08PP\uff09\u6765\u7f13\u89e3\u7535\u538b\u504f\u5dee\u548c\u529f\u7387\u635f\u8017\u3002\u5229\u7528\u7c92\u5b50\u7fa4\u4f18\u5316\u6280\u672f\u786e\u5b9a\u516c\u7528\u4e8b\u4e1a\u516c\u53f8\u5411\u50a8\u80fd\u7cfb\u7edf\u53d1\u51fa\u7684\u6700\u4f18\u5145\u653e\u7535\u6307\u4ee4\uff0c\u5e76\u5728IEEE 33\u8282\u70b9\u914d\u7535\u7f51\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u4e25\u683c\u4eff\u771f\u9a8c\u8bc1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u7b56\u7565\u6027\u5730\u90e8\u7f72PP\u6765\u7ba1\u7406\u4f4f\u5b85\u592a\u9633\u80fd\u7cfb\u7edf\u4e2d\u7535\u6c60\u7684\u5145\u653e\u7535\uff0c\u4e0d\u4ec5\u6709\u52a9\u4e8e\u589e\u5f3a\u7535\u7f51\u5f39\u6027\uff0c\u8fd8\u80fd\u6ee1\u8db3\u65b0\u578b\u7535\u52a8\u6c7d\u8f66\uff08\u7279\u522b\u662f\u5361\u8f66\uff09\u5e26\u6765\u7684\u9700\u6c42\u589e\u957f\u3002\u7814\u7a76\u63ed\u793a\u4e86\u4e0d\u540cPP\u5206\u914d\u65b9\u6848\u7684\u53d8\u9769\u6f5c\u529b\uff0c\u4ee5\u53ca\u975e\u7535\u6c60\u50a8\u80fd\u548c\u7535\u6c60\u50a8\u80fd\u592a\u9633\u80fd\u4f4f\u5b85\u4e4b\u95f4\u7684\u5e73\u8861\u5173\u7cfb\u3002", "conclusion": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u7684\u9884\u671f\u589e\u957f\uff0c\u73b0\u4ee3\u7535\u7f51\u52a8\u6001\u7684\u590d\u6742\u6027\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u3002\u672c\u7814\u7a76\u63d0\u51fa\u7684PP\u5206\u914d\u6a21\u578b\u4e3a\u516c\u7528\u4e8b\u4e1a\u516c\u53f8\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\uff0c\u65e2\u80fd\u7ba1\u7406\u5f53\u524d\u7684\u7535\u80fd\u8d28\u91cf\u95ee\u9898\uff0c\u53c8\u80fd\u4e3a\u672a\u6765\u7535\u52a8\u6c7d\u8f66\uff08\u7279\u522b\u662f\u5361\u8f66\uff09\u7684\u5927\u89c4\u6a21\u63a5\u5165\u505a\u597d\u51c6\u5907\u3002"}}
{"id": "2602.00272", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.00272", "abs": "https://arxiv.org/abs/2602.00272", "authors": ["Wan Fokkink", "Georgios Karlos", "Andy Tatman"], "title": "A Fault-Tolerant Version of Safra's Termination Detection Algorithm", "comment": null, "summary": "Safra's distributed termination detection algorithm employs a logical token ring structure within a distributed network; only passive nodes forward the token, and a counter in the token keeps track of the number of sent minus the number of received messages. We adapt this classic algorithm to make it fault-tolerant. The counter is split into counters per node, to discard counts from crashed nodes. If a node crashes, the token ring is restored locally and a backup token is sent. Nodes inform each other of detected crashes via the token. Our algorithm imposes no additional message overhead, tolerates any number of crashes as well as simultaneous crashes, and copes with crashes in a decentralized fashion. Correctness proofs are provided of both the original Safra's algorithm and its fault-tolerant variant, as well as a model checking analysis.", "AI": {"tldr": "\u5c06Safra\u7684\u5206\u5e03\u5f0f\u7ec8\u6b62\u68c0\u6d4b\u7b97\u6cd5\u6539\u9020\u4e3a\u5bb9\u9519\u7248\u672c\uff0c\u901a\u8fc7\u8282\u70b9\u7ea7\u8ba1\u6570\u5668\u3001\u672c\u5730\u73af\u6062\u590d\u548c\u5907\u4efd\u4ee4\u724c\u673a\u5236\uff0c\u5b9e\u73b0\u65e0\u989d\u5916\u6d88\u606f\u5f00\u9500\u3001\u5bb9\u5fcd\u4efb\u610f\u6570\u91cf\u540c\u65f6\u5d29\u6e83\u7684\u5bb9\u9519\u80fd\u529b\u3002", "motivation": "\u7ecf\u5178Safra\u7b97\u6cd5\u5728\u5206\u5e03\u5f0f\u7f51\u7edc\u4e2d\u91c7\u7528\u903b\u8f91\u4ee4\u724c\u73af\u7ed3\u6784\u8fdb\u884c\u7ec8\u6b62\u68c0\u6d4b\uff0c\u4f46\u7f3a\u4e4f\u5bb9\u9519\u80fd\u529b\u3002\u5f53\u8282\u70b9\u5d29\u6e83\u65f6\uff0c\u7b97\u6cd5\u65e0\u6cd5\u6b63\u5e38\u5de5\u4f5c\uff0c\u9700\u8981\u8bbe\u8ba1\u5bb9\u9519\u673a\u5236\u6765\u5e94\u5bf9\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u8282\u70b9\u6545\u969c\u3002", "method": "1. \u5c06\u4ee4\u724c\u4e2d\u7684\u5168\u5c40\u8ba1\u6570\u5668\u62c6\u5206\u4e3a\u6bcf\u4e2a\u8282\u70b9\u7684\u72ec\u7acb\u8ba1\u6570\u5668\uff0c\u4ee5\u4fbf\u4e22\u5f03\u5d29\u6e83\u8282\u70b9\u7684\u8ba1\u6570\uff1b2. \u8282\u70b9\u5d29\u6e83\u65f6\uff0c\u5728\u672c\u5730\u6062\u590d\u4ee4\u724c\u73af\u7ed3\u6784\uff1b3. \u53d1\u9001\u5907\u4efd\u4ee4\u724c\uff1b4. \u901a\u8fc7\u4ee4\u724c\u4f20\u9012\u8282\u70b9\u5d29\u6e83\u4fe1\u606f\uff1b5. \u4fdd\u6301\u65e0\u989d\u5916\u6d88\u606f\u5f00\u9500\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "result": "\u7b97\u6cd5\u5b9e\u73b0\u4e86\u5b8c\u5168\u5bb9\u9519\uff1a1. \u5bb9\u5fcd\u4efb\u610f\u6570\u91cf\u7684\u8282\u70b9\u5d29\u6e83\uff1b2. \u5904\u7406\u540c\u65f6\u53d1\u751f\u7684\u591a\u4e2a\u5d29\u6e83\uff1b3. \u4ee5\u53bb\u4e2d\u5fc3\u5316\u65b9\u5f0f\u5e94\u5bf9\u5d29\u6e83\uff1b4. \u4e0d\u589e\u52a0\u989d\u5916\u6d88\u606f\u5f00\u9500\uff1b5. \u63d0\u4f9b\u4e86\u6b63\u786e\u6027\u8bc1\u660e\u548c\u6a21\u578b\u68c0\u67e5\u5206\u6790\u3002", "conclusion": "\u6210\u529f\u5c06\u7ecf\u5178Safra\u7ec8\u6b62\u68c0\u6d4b\u7b97\u6cd5\u6539\u9020\u4e3a\u5bb9\u9519\u7248\u672c\uff0c\u4fdd\u6301\u4e86\u539f\u7b97\u6cd5\u7684\u7b80\u6d01\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u5728\u6545\u969c\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7ec8\u6b62\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00022", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00022", "abs": "https://arxiv.org/abs/2602.00022", "authors": ["Margaret Foster"], "title": "Measurement for Opaque Systems: Multi-source Triangulation with Interpretable Machine Learning", "comment": "16 pages, 6 figures, 3 tables, 9-page appendix", "summary": "We propose a measurement framework for difficult-to-access contexts that uses indirect data traces, interpretable machine-learning models, and theory-guided triangulation to fill inaccessible measurement spaces. Many high-stakes systems of scientific and policy interest are difficult, if not impossible, to reach directly: dynamics of interest are unobservable, data are indirect and fragmented across sources, and ground truth is absent or concealed. In these settings, available data often do not support conventional strategies for analysis, such as statistical inference on a single authoritative data stream or model validation against labeled outcomes. To address this problem, we introduce a general framework for measurement in data regimes characterized by structurally missing or adversarial data. We propose combining multi-source triangulation with interpretable machine learning models. Rather than relying on accuracy against unobservable, unattainable ideal data, our framework seeks consistency across separate, partially informative models. This allows users to draw defensible conclusions about the state of the world based on cross-signal consistency or divergence from an expected state. Our framework provides an analytical workflow tailored to quantitative characterization in the absence of data sufficient for conventional statistical or causal inference. We demonstrate our approach and explicitly surface inferential limits through an empirical analysis of organizational growth and internal pressure dynamics in a clandestine militant organization, drawing on multiple observational signals that individually provide incomplete and biased views of the underlying process. The results show how triangulated, interpretable ML can recover substantively meaningful variation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9488\u5bf9\u96be\u4ee5\u76f4\u63a5\u89c2\u6d4b\u60c5\u5883\u7684\u6d4b\u91cf\u6846\u67b6\uff0c\u7ed3\u5408\u95f4\u63a5\u6570\u636e\u75d5\u8ff9\u3001\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u7406\u8bba\u5f15\u5bfc\u7684\u4e09\u89d2\u9a8c\u8bc1\uff0c\u4ee5\u586b\u8865\u65e0\u6cd5\u8bbf\u95ee\u7684\u6d4b\u91cf\u7a7a\u95f4\u3002", "motivation": "\u8bb8\u591a\u9ad8\u98ce\u9669\u7684\u7cfb\u7edf\u548c\u653f\u7b56\u5173\u6ce8\u5bf9\u8c61\u96be\u4ee5\u76f4\u63a5\u89c2\u6d4b\uff1a\u5173\u952e\u52a8\u6001\u4e0d\u53ef\u89c2\u5bdf\u3001\u6570\u636e\u95f4\u63a5\u4e14\u5206\u6563\u3001\u771f\u5b9e\u60c5\u51b5\u7f3a\u5931\u6216\u88ab\u9690\u85cf\u3002\u5728\u8fd9\u4e9b\u60c5\u5883\u4e0b\uff0c\u73b0\u6709\u6570\u636e\u5f80\u5f80\u4e0d\u652f\u6301\u4f20\u7edf\u7684\u7edf\u8ba1\u5206\u6790\u7b56\u7565\u3002", "method": "\u7ed3\u5408\u591a\u6e90\u4e09\u89d2\u9a8c\u8bc1\u4e0e\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4e0d\u4f9d\u8d56\u65e0\u6cd5\u83b7\u5f97\u7684\u7406\u60f3\u6570\u636e\u51c6\u786e\u6027\uff0c\u800c\u662f\u5bfb\u6c42\u4e0d\u540c\u90e8\u5206\u4fe1\u606f\u6a21\u578b\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u8de8\u4fe1\u53f7\u4e00\u81f4\u6027\u6216\u4e0e\u9884\u671f\u72b6\u6001\u7684\u504f\u79bb\u6765\u5f97\u51fa\u53ef\u9760\u7ed3\u8bba\u3002", "result": "\u901a\u8fc7\u5bf9\u4e00\u4e2a\u79d8\u5bc6\u519b\u4e8b\u7ec4\u7ec7\u7684\u7ec4\u7ec7\u589e\u957f\u548c\u5185\u90e8\u538b\u529b\u52a8\u6001\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5982\u4f55\u6062\u590d\u5177\u6709\u5b9e\u8d28\u610f\u4e49\u7684\u53d8\u5f02\uff0c\u540c\u65f6\u660e\u786e\u63ed\u793a\u4e86\u63a8\u65ad\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u7f3a\u4e4f\u8db3\u591f\u6570\u636e\u8fdb\u884c\u4f20\u7edf\u7edf\u8ba1\u6216\u56e0\u679c\u63a8\u65ad\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9a\u91cf\u7684\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\uff0c\u901a\u8fc7\u4e09\u89d2\u9a8c\u8bc1\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u80fd\u591f\u6062\u590d\u6709\u610f\u4e49\u7684\u53d8\u5f02\u3002"}}
{"id": "2602.00803", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.00803", "abs": "https://arxiv.org/abs/2602.00803", "authors": ["Seungkwan Kang", "Seungjun Lee", "Donghyun Gouk", "Miryeong Kwon", "Hyunkyu Choi", "Junhyeok Jang", "Sangwon Lee", "Huiwon Choi", "Jie Zhang", "Wonil Choi", "Mahmut Taylan Kandemir", "Myoungsoo Jung"], "title": "AutoGNN: End-to-End Hardware-Driven Graph Preprocessing for Enhanced GNN Performance", "comment": null, "summary": "Graph neural network (GNN) inference faces significant bottlenecks in preprocessing, which often dominate overall inference latency. We introduce AutoGNN, an FPGA-based accelerator designed to address these challenges by leveraging FPGA's reconfigurability and specialized components. AutoGNN adapts to diverse graph inputs, efficiently performing computationally intensive tasks such as graph conversion and sampling. By utilizing components like adder trees, AutoGNN executes reduction operations in constant time, overcoming the limitations of serialization and synchronization on GPUs.\n  AutoGNN integrates unified processing elements (UPEs) and single-cycle reducers (SCRs) to streamline GNN preprocessing. UPEs enable scalable parallel processing for edge sorting and unique vertex selection, while SCRs efficiently handle sequential tasks such as pointer array construction and subgraph reindexing. A user-level software framework dynamically profiles graph inputs, determines optimal configurations, and reprograms AutoGNN to handle varying workloads. Implemented on a 7$n$m enterprise FPGA, AutoGNN achieves up to 9.0$\\times$ and 2.1$\\times$ speedup compared to conventional and GPU-accelerated preprocessing systems, respectively, enabling high-performance GNN preprocessing across diverse datasets.", "AI": {"tldr": "AutoGNN\u662f\u4e00\u4e2a\u57fa\u4e8eFPGA\u7684GNN\u63a8\u7406\u52a0\u901f\u5668\uff0c\u4e13\u6ce8\u4e8e\u89e3\u51b3\u9884\u5904\u7406\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u53ef\u91cd\u6784\u67b6\u6784\u548c\u4e13\u7528\u786c\u4ef6\u7ec4\u4ef6\u5b9e\u73b0\u6bd4\u4f20\u7edf\u7cfb\u7edf\u548cGPU\u52a0\u901f\u65b9\u6848\u66f4\u5feb\u7684\u9884\u5904\u7406\u901f\u5ea6\u3002", "motivation": "GNN\u63a8\u7406\u4e2d\u7684\u9884\u5904\u7406\u9636\u6bb5\uff08\u5982\u56fe\u8f6c\u6362\u3001\u91c7\u6837\u7b49\uff09\u901a\u5e38\u5360\u636e\u6574\u4f53\u63a8\u7406\u5ef6\u8fdf\u7684\u4e3b\u8981\u90e8\u5206\uff0c\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u3002\u73b0\u6709GPU\u65b9\u6848\u5728\u5e8f\u5217\u5316\u548c\u540c\u6b65\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eFPGA\u7684AutoGNN\u52a0\u901f\u5668\uff0c\u91c7\u7528\u7edf\u4e00\u5904\u7406\u5355\u5143\uff08UPEs\uff09\u548c\u5355\u5468\u671f\u5f52\u7ea6\u5668\uff08SCRs\uff09\u7b49\u4e13\u7528\u786c\u4ef6\u7ec4\u4ef6\u3002UPEs\u7528\u4e8e\u8fb9\u7f18\u6392\u5e8f\u548c\u9876\u70b9\u9009\u62e9\u7684\u5e76\u884c\u5904\u7406\uff0cSCRs\u5904\u7406\u6307\u9488\u6570\u7ec4\u6784\u5efa\u548c\u5b50\u56fe\u91cd\u7d22\u5f15\u7b49\u987a\u5e8f\u4efb\u52a1\u3002\u901a\u8fc7\u7528\u6237\u7ea7\u8f6f\u4ef6\u6846\u67b6\u52a8\u6001\u5206\u6790\u56fe\u8f93\u5165\uff0c\u786e\u5b9a\u6700\u4f18\u914d\u7f6e\u5e76\u91cd\u65b0\u7f16\u7a0bFPGA\u3002", "result": "\u57287nm\u4f01\u4e1a\u7ea7FPGA\u4e0a\u5b9e\u73b0\uff0c\u76f8\u6bd4\u4f20\u7edf\u9884\u5904\u7406\u7cfb\u7edf\u83b7\u5f979.0\u500d\u52a0\u901f\uff0c\u76f8\u6bd4GPU\u52a0\u901f\u9884\u5904\u7406\u7cfb\u7edf\u83b7\u5f972.1\u500d\u52a0\u901f\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u3002", "conclusion": "AutoGNN\u901a\u8fc7FPGA\u7684\u53ef\u91cd\u6784\u6027\u548c\u4e13\u7528\u786c\u4ef6\u7ec4\u4ef6\uff0c\u6709\u6548\u89e3\u51b3\u4e86GNN\u63a8\u7406\u4e2d\u7684\u9884\u5904\u7406\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u591a\u6837\u5316\u56fe\u6570\u636e\u7684\u9ad8\u6027\u80fd\u9884\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u786c\u4ef6\u52a0\u901f\u65b9\u6848\u3002"}}
{"id": "2602.00277", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00277", "abs": "https://arxiv.org/abs/2602.00277", "authors": ["Omkar Salpekar", "Rohan Varma", "Kenny Yu", "Vladimir Ivanov", "Yang Wang", "Ahmed Sharif", "Min Si", "Shawn Xu", "Feng Tian", "Shengbao Zheng", "Tristan Rice", "Ankush Garg", "Shangfu Peng", "Shreyas Siravara", "Wenyin Fu", "Rodrigo de Castro", "Adithya Gangidi", "Andrey Obraztsov", "Sharan Narang", "Sergey Edunov", "Maxim Naumov", "Chunqiang Tang", "Mathew Oldham"], "title": "Training LLMs with Fault Tolerant HSDP on 100,000 GPUs", "comment": null, "summary": "Large-scale training systems typically use synchronous training, requiring all GPUs to be healthy simultaneously. In our experience training on O(100K) GPUs, synchronous training results in a low efficiency due to frequent failures and long recovery time.\n  To address this problem, we propose a novel training paradigm, Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP). FT-HSDP uses data parallel replicas as units of fault tolerance. When failures occur, only a single data-parallel replica containing the failed GPU or server is taken offline and restarted, while the other replicas continue training. To realize this idea at scale, FT-HSDP incorporates several techniques: 1) We introduce a Fault Tolerant All Reduce (FTAR) protocol for gradient exchange across data parallel replicas. FTAR relies on the CPU to drive the complex control logic for tasks like adding or removing participants dynamically, and relies on GPU to perform data transfer for best performance. 2) We introduce a non-blocking catch-up protocol, allowing a recovering replica to join training with minimal stall.\n  Compared with fully synchronous training at O(100K) GPUs, FT-HSDP can reduce the stall time due to failure recovery from 10 minutes to 3 minutes, increasing effective training time from 44\\% to 80\\%. We further demonstrate that FT-HSDP's asynchronous recovery does not bring any meaning degradation to the accuracy of the result model.", "AI": {"tldr": "FT-HSDP\u662f\u4e00\u79cd\u65b0\u578b\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u6570\u636e\u5e76\u884c\u526f\u672c\u4f5c\u4e3a\u5bb9\u9519\u5355\u5143\uff0c\u5728GPU\u6545\u969c\u65f6\u4ec5\u91cd\u542f\u53d7\u5f71\u54cd\u526f\u672c\uff0c\u5176\u4ed6\u526f\u672c\u7ee7\u7eed\u8bad\u7ec3\uff0c\u663e\u8457\u51cf\u5c11\u6545\u969c\u6062\u590d\u65f6\u95f4\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\uff08O(100K) GPU\uff09\u4e2d\uff0c\u540c\u6b65\u8bad\u7ec3\u56e0\u9891\u7e41\u6545\u969c\u548c\u957f\u6062\u590d\u65f6\u95f4\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5bb9\u9519\u673a\u5236\u3002", "method": "\u63d0\u51faFT-HSDP\u8303\u5f0f\uff1a1) \u4f7f\u7528\u6570\u636e\u5e76\u884c\u526f\u672c\u4f5c\u4e3a\u5bb9\u9519\u5355\u5143\uff1b2) \u5f15\u5165\u5bb9\u9519All Reduce\u534f\u8bae\uff08FTAR\uff09\uff0cCPU\u5904\u7406\u63a7\u5236\u903b\u8f91\uff0cGPU\u8d1f\u8d23\u6570\u636e\u4f20\u8f93\uff1b3) \u975e\u963b\u585e\u8ffd\u8d76\u534f\u8bae\uff0c\u8ba9\u6062\u590d\u526f\u672c\u4ee5\u6700\u5c0f\u5ef6\u8fdf\u52a0\u5165\u8bad\u7ec3\u3002", "result": "\u76f8\u6bd4\u5b8c\u5168\u540c\u6b65\u8bad\u7ec3\uff0cFT-HSDP\u5c06\u6545\u969c\u6062\u590d\u505c\u6ede\u65f6\u95f4\u4ece10\u5206\u949f\u964d\u81f33\u5206\u949f\uff0c\u6709\u6548\u8bad\u7ec3\u65f6\u95f4\u4ece44%\u63d0\u5347\u81f380%\uff0c\u4e14\u5f02\u6b65\u6062\u590d\u4e0d\u4f1a\u5bf9\u6a21\u578b\u7cbe\u5ea6\u4ea7\u751f\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "FT-HSDP\u662f\u4e00\u79cd\u6709\u6548\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u5bb9\u9519\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5bb9\u9519\u5355\u5143\u548c\u667a\u80fd\u6062\u590d\u534f\u8bae\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u7cfb\u7edf\u53ef\u7528\u6027\u3002"}}
{"id": "2602.00027", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00027", "abs": "https://arxiv.org/abs/2602.00027", "authors": ["Zhenyu Pu", "Yu Yang", "Lun Yang", "Qing-Shan Jia", "Xiaohong Guan", "Costas J. Spanos"], "title": "Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems", "comment": "14 pages, 7 figures", "summary": "Hydrogen-based multi-energy systems (HMES) have emerged as a promising low-carbon and energy-efficient solution, as it can enable the coordinated operation of electricity, heating and cooling supply and demand to enhance operational flexibility, improve overall energy efficiency, and increase the share of renewable integration. However, the optimal operation of HMES remains challenging due to the nonlinear and multi-physics coupled dynamics of hydrogen energy storage systems (HESS) (consisting of electrolyters, fuel cells and hydrogen tanks) as well as the presence of multiple uncertainties from supply and demand. To address these challenges, this paper develops a comprehensive operational model for HMES that fully captures the nonlinear dynamics and multi-physics process of HESS. Moreover, we propose an enhanced deep reinforcement learning (DRL) framework by integrating the emerging representation learning techniques, enabling substantially accelerated and improved policy optimization for spatially and temporally coupled complex networked systems, which is not provided by conventional DRL. Experimental studies based on real-world datasets show that the comprehensive model is crucial to ensure the safe and reliable of HESS. In addition, the proposed SR-DRL approaches demonstrate superior convergence rate and performance over conventional DRL counterparts in terms of reducing the operation cost of HMES and handling the system operating constraints. Finally, we provide some insights into the role of representation learning in DRL, speculating that it can reorganize the original state space into a well-structured and cluster-aware geometric representation, thereby smoothing and facilitating the learning process of DRL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8868\u793a\u5b66\u4e60\u6280\u672f\u7684\u589e\u5f3a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u6c22\u57fa\u591a\u80fd\u6e90\u7cfb\u7edf\u7684\u8fd0\u884c\uff0c\u8be5\u6846\u67b6\u80fd\u663e\u8457\u52a0\u901f\u590d\u6742\u7f51\u7edc\u7cfb\u7edf\u7684\u7b56\u7565\u4f18\u5316\u5e76\u964d\u4f4e\u8fd0\u884c\u6210\u672c\u3002", "motivation": "\u6c22\u57fa\u591a\u80fd\u6e90\u7cfb\u7edf\uff08HMES\uff09\u4f5c\u4e3a\u4f4e\u78b3\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u534f\u8c03\u7535\u529b\u3001\u4f9b\u70ed\u548c\u4f9b\u51b7\u7684\u4f9b\u9700\u8fd0\u884c\uff0c\u4f46HESS\u7684\u975e\u7ebf\u6027\u591a\u7269\u7406\u8026\u5408\u52a8\u6001\u4ee5\u53ca\u4f9b\u9700\u4e0d\u786e\u5b9a\u6027\u4f7f\u5f97\u5176\u4f18\u5316\u8fd0\u884c\u9762\u4e34\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u5168\u9762\u6355\u6349HESS\u975e\u7ebf\u6027\u52a8\u6001\u548c\u591a\u7269\u7406\u8fc7\u7a0b\u7684\u8fd0\u884c\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u96c6\u6210\u8868\u793a\u5b66\u4e60\u6280\u672f\u7684\u589e\u5f3a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08SR-DRL\uff09\uff0c\u7528\u4e8e\u52a0\u901f\u590d\u6742\u7f51\u7edc\u7cfb\u7edf\u7684\u7b56\u7565\u4f18\u5316\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7efc\u5408\u6a21\u578b\u5bf9\u786e\u4fddHESS\u5b89\u5168\u53ef\u9760\u8fd0\u884c\u81f3\u5173\u91cd\u8981\uff0cSR-DRL\u65b9\u6cd5\u5728\u964d\u4f4eHMES\u8fd0\u884c\u6210\u672c\u548c\u6ee1\u8db3\u7cfb\u7edf\u7ea6\u675f\u65b9\u9762\u4f18\u4e8e\u4f20\u7edfDRL\u65b9\u6cd5\uff0c\u6536\u655b\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "\u8868\u793a\u5b66\u4e60\u80fd\u591f\u5c06\u539f\u59cb\u72b6\u6001\u7a7a\u95f4\u91cd\u7ec4\u4e3a\u7ed3\u6784\u826f\u597d\u3001\u805a\u7c7b\u611f\u77e5\u7684\u51e0\u4f55\u8868\u793a\uff0c\u4ece\u800c\u5e73\u6ed1\u548c\u4fc3\u8fdbDRL\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4e3a\u590d\u6742\u80fd\u6e90\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00838", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00838", "abs": "https://arxiv.org/abs/2602.00838", "authors": ["Prabhu Vellaisamy", "Harideep Nair", "Di Wu", "Shawn Blanton", "John Paul Shen"], "title": "Exploration of Unary Arithmetic-Based Matrix Multiply Units for Low Precision DL Accelerators", "comment": null, "summary": "General matrix multiplication (GEMM) is a fundamental operation in deep learning (DL). With DL moving increasingly toward low precision, recent works have proposed novel unary GEMM designs as an alternative to conventional binary GEMM hardware. A rigorous evaluation of recent unary and binary GEMM designs is needed to assess the potential of unary hardware for future DL compute. This paper focuses on unary GEMM designs for integer-based DL inference and performs a detailed evaluation of three latest unary design proposals, namely, uGEMM, tuGEMM and tubGEMM, by comparing them to a conventional binary GEMM. Rigorous post-synthesis evaluations beyond prior works are performed across varying bit-widths and matrix sizes to assess the designs' tradeoffs and determine optimal sweetspots. Further, we perform weight sparsity analysis across eight pretrained convolutional neural networks (CNNs) and the LLaMA2 large language model (LLM). In this work, we demonstrate how unary GEMM can be effectively used for energy-efficient compute in future edge AI accelerators.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e09\u79cd\u6700\u65b0\u7684\u5355\u7cbe\u5ea6GEMM\u8bbe\u8ba1\uff08uGEMM\u3001tuGEMM\u3001tubGEMM\uff09\u4e0e\u4f20\u7edf\u4e8c\u8fdb\u5236GEMM\u8fdb\u884c\u4e86\u8be6\u7ec6\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5355\u7cbe\u5ea6GEMM\u5728\u672a\u6765\u8fb9\u7f18AI\u52a0\u901f\u5668\u4e2d\u5b9e\u73b0\u80fd\u6548\u8ba1\u7b97\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u5411\u4f4e\u7cbe\u5ea6\u53d1\u5c55\uff0c\u9700\u8981\u8bc4\u4f30\u5355\u7cbe\u5ea6GEMM\u8bbe\u8ba1\u4f5c\u4e3a\u4f20\u7edf\u4e8c\u8fdb\u5236GEMM\u786c\u4ef6\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765DL\u8ba1\u7b97\u63d0\u4f9b\u80fd\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5bf9\u4e09\u79cd\u6700\u65b0\u5355\u7cbe\u5ea6\u8bbe\u8ba1\uff08uGEMM\u3001tuGEMM\u3001tubGEMM\uff09\u4e0e\u4f20\u7edf\u4e8c\u8fdb\u5236GEMM\u8fdb\u884c\u8be6\u7ec6\u8bc4\u4f30\uff0c\u5305\u62ec\u4e0d\u540c\u4f4d\u5bbd\u548c\u77e9\u9635\u5c3a\u5bf8\u7684\u5408\u6210\u540e\u5206\u6790\uff0c\u5e76\u5bf98\u4e2a\u9884\u8bad\u7ec3CNN\u548cLLaMA2 LLM\u8fdb\u884c\u6743\u91cd\u7a00\u758f\u6027\u5206\u6790\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30\u786e\u5b9a\u4e86\u5404\u8bbe\u8ba1\u7684\u6700\u4f73\u5e94\u7528\u573a\u666f\u548c\u6027\u80fd\u5e73\u8861\u70b9\uff0c\u5c55\u793a\u4e86\u5355\u7cbe\u5ea6GEMM\u5728\u80fd\u6548\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18AI\u52a0\u901f\u5668\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u5355\u7cbe\u5ea6GEMM\u53ef\u4ee5\u6709\u6548\u7528\u4e8e\u672a\u6765\u8fb9\u7f18AI\u52a0\u901f\u5668\u7684\u80fd\u6548\u8ba1\u7b97\uff0c\u4e3a\u4f4e\u7cbe\u5ea6\u6df1\u5ea6\u5b66\u4e60\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2602.00028", "categories": ["cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.00028", "abs": "https://arxiv.org/abs/2602.00028", "authors": ["Zoha Azimi", "Reza Farahani", "Radu Prodan", "Christian Timmerer"], "title": "ELLMPEG: An Edge-based Agentic LLM Video Processing Tool", "comment": "12 pages, 5 tables, 8 Figures, accepted for the MMSys 2026 conference", "summary": "Large language models (LLMs), the foundation of generative AI systems like ChatGPT, are transforming many fields and applications, including multimedia, enabling more advanced content generation, analysis, and interaction. However, cloud-based LLM deployments face three key limitations: high computational and energy demands, privacy and reliability risks from remote processing, and recurring API costs. Recent advances in agentic AI, especially in structured reasoning and tool use, offer a better way to exploit open and locally deployed tools and LLMs. This paper presents ELLMPEG, an edge-enabled agentic LLM framework for the automated generation of video-processing commands. ELLMPEG integrates tool-aware Retrieval-Augmented Generation (RAG) with iterative self-reflection to produce and locally verify executable FFmpeg and VVenC commands directly at the edge, eliminating reliance on external cloud APIs. To evaluate ELLMPEG, we collect a dedicated prompt dataset comprising 480 diverse queries covering different categories of FFmpeg and the Versatile Video Codec (VVC) encoder (VVenC) commands. We validate command generation accuracy and evaluate four open-source LLMs based on command validity, tokens generated per second, inference time, and energy efficiency. We also execute the generated commands to assess their runtime correctness and practical applicability. Experimental results show that Qwen2.5, when augmented with the ELLMPEG framework, achieves an average command-generation accuracy of 78 % with zero recurring API cost, outperforming all other open-source models across both the FFmpeg and VVenC datasets.", "AI": {"tldr": "ELLMPEG\u662f\u4e00\u4e2a\u8fb9\u7f18\u667a\u80fd\u7684\u4ee3\u7406\u5f0fLLM\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u89c6\u9891\u5904\u7406\u547d\u4ee4\uff0c\u901a\u8fc7\u672c\u5730\u90e8\u7f72\u6d88\u9664\u4e91API\u4f9d\u8d56\uff0c\u5728FFmpeg\u548cVVC\u7f16\u7801\u5668\u547d\u4ee4\u751f\u6210\u4e0a\u8fbe\u523078%\u51c6\u786e\u7387\u3002", "motivation": "\u4e91\u57faLLM\u90e8\u7f72\u9762\u4e34\u4e09\u5927\u9650\u5236\uff1a\u9ad8\u8ba1\u7b97\u80fd\u8017\u3001\u8fdc\u7a0b\u5904\u7406\u7684\u9690\u79c1\u53ef\u9760\u6027\u98ce\u9669\u3001\u4ee5\u53ca\u6301\u7eedAPI\u6210\u672c\u3002\u9700\u8981\u5229\u7528\u8fb9\u7f18\u8ba1\u7b97\u548c\u4ee3\u7406\u5f0fAI\u6280\u672f\uff0c\u5728\u672c\u5730\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u89c6\u9891\u5904\u7406\u547d\u4ee4\u751f\u6210\u3002", "method": "\u63d0\u51faELLMPEG\u6846\u67b6\uff0c\u96c6\u6210\u5de5\u5177\u611f\u77e5\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u4e0e\u8fed\u4ee3\u81ea\u53cd\u601d\u673a\u5236\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u751f\u6210\u5e76\u672c\u5730\u9a8c\u8bc1\u53ef\u6267\u884c\u7684FFmpeg\u548cVVenC\u547d\u4ee4\uff0c\u65e0\u9700\u5916\u90e8\u4e91API\u3002", "result": "\u6784\u5efa480\u4e2a\u591a\u6837\u5316\u67e5\u8be2\u7684\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u547d\u4ee4\u751f\u6210\u51c6\u786e\u6027\u3001\u6bcf\u79d2\u751f\u6210token\u6570\u3001\u63a8\u7406\u65f6\u95f4\u3001\u80fd\u6548\u7b49\u6307\u6807\u3002Qwen2.5\u7ed3\u5408ELLMPEG\u6846\u67b6\u5728FFmpeg\u548cVVenC\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u8fbe78%\uff0c\u4f18\u4e8e\u5176\u4ed6\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "ELLMPEG\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u89c6\u9891\u5904\u7406\u547d\u4ee4\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u4e91\u57faLLM\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u96f6API\u6210\u672c\u3001\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u9760\u7684\u8fb9\u7f18\u591a\u5a92\u4f53\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.00909", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.00909", "abs": "https://arxiv.org/abs/2602.00909", "authors": ["Rafael Billig Tonetto", "Marcello Traiola", "Fernando Fernandes dos Santos", "Angeliki Kritikakou"], "title": "ENFOR-SA: End-to-end Cross-layer Transient Fault Injector for Efficient and Accurate DNN Reliability Assessment on Systolic Arrays", "comment": null, "summary": "Recent advances in deep learning have produced highly accurate but increasingly large and complex DNNs, making traditional fault-injection techniques impractical. Accurate fault analysis requires RTL-accurate hardware models. However, this significantly slows evaluation compared with software-only approaches, particularly when combined with expensive HDL instrumentation. In this work, we show that such high-overhead methods are unnecessary for systolic array (SA) architectures and propose ENFOR-SA, an end-to-end framework for DNN transient fault analysis on SAs. Our two-step approach employs cross-layer simulation and uses RTL SA components only during fault injection, with the rest executed at the software level. Experiments on CNNs and Vision Transformers demonstrate that ENFOR-SA achieves RTL-accurate fault injection with only 6% average slowdown compared to software-based injection, while delivering at least two orders of magnitude speedup (average $569\\times$) over full-SoC RTL simulation and a $2.03\\times$ improvement over a state-of-the-art cross-layer RTL injection tool. ENFOR-SA code is publicly available at https://github.com/rafaabt/ENFOR-SA.", "AI": {"tldr": "ENFOR-SA\uff1a\u9488\u5bf9\u8109\u52a8\u9635\u5217\u67b6\u6784\u7684DNN\u77ac\u6001\u6545\u969c\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u5c42\u4eff\u771f\u5b9e\u73b0RTL\u7ea7\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u5168SoC RTL\u4eff\u771f\u52a0\u901f569\u500d", "motivation": "\u4f20\u7edf\u6545\u969c\u6ce8\u5165\u65b9\u6cd5\u5bf9\u4e8e\u5927\u578b\u590d\u6742DNN\u4e0d\u5b9e\u7528\uff0cRTL\u7ea7\u786c\u4ef6\u6a21\u578b\u867d\u7136\u51c6\u786e\u4f46\u901f\u5ea6\u6162\uff0c\u7279\u522b\u662f\u7ed3\u5408\u6602\u8d35\u7684HDL\u5de5\u5177\u65f6\u3002\u9700\u8981\u9488\u5bf9\u8109\u52a8\u9635\u5217\u67b6\u6784\u5f00\u53d1\u9ad8\u6548\u6545\u969c\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u63d0\u51faENFOR-SA\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u8de8\u5c42\u4eff\u771f\uff0c\u4ec5\u5728\u6545\u969c\u6ce8\u5165\u65f6\u4f7f\u7528RTL\u8109\u52a8\u9635\u5217\u7ec4\u4ef6\uff0c\u5176\u4f59\u90e8\u5206\u5728\u8f6f\u4ef6\u5c42\u9762\u6267\u884c\u3002", "result": "\u5728CNN\u548cVision Transformer\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0cENFOR-SA\u5b9e\u73b0RTL\u7ea7\u7cbe\u5ea6\u6545\u969c\u6ce8\u5165\uff0c\u76f8\u6bd4\u8f6f\u4ef6\u6ce8\u5165\u4ec56%\u5e73\u5747\u51cf\u901f\uff0c\u6bd4\u5168SoC RTL\u4eff\u771f\u52a0\u901f569\u500d\uff0c\u6bd4\u73b0\u6709\u8de8\u5c42RTL\u6ce8\u5165\u5de5\u5177\u5feb2.03\u500d\u3002", "conclusion": "\u5bf9\u4e8e\u8109\u52a8\u9635\u5217\u67b6\u6784\uff0c\u9ad8\u5f00\u9500\u7684\u6545\u969c\u6ce8\u5165\u65b9\u6cd5\u4e0d\u5fc5\u8981\uff0cENFOR-SA\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u5b9e\u73b0RTL\u7ea7\u7cbe\u5ea6\u7684DNN\u77ac\u6001\u6545\u969c\u5206\u6790\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.00509", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.00509", "abs": "https://arxiv.org/abs/2602.00509", "authors": ["Qianchao Zhu", "Xucheng Ye", "Yuliang Liu", "Haodong Ouyang", "Chengru Song"], "title": "PROBE: Co-Balancing Computation and Communication in MoE Inference via Real-Time Predictive Prefetching", "comment": null, "summary": "Mixture-of-Experts models have become a dominant architecture for scaling Large Language Models by activating only a sparse subset of experts per token. However, latency-critical MoE inference faces a fundamental tension: while expert parallelism improves memory efficiency, it also amplifies execution stragglers. In real-world serving, continuous batching and diverse concurrent requests induce rapid semantic shifts, causing expert hotspots to migrate abruptly across GPUs and triggering the 'double penalty' of coupled computational skew and network congestion.\n  We propose PROBE, an inference system that co-balances computation and communication in real time. PROBE introduces Continuous Lookahead Pipelining, which proactively predicts, plans, and prefetches for upcoming layers while keeping all control overheads off the critical path. PROBE consists of: (1) a Gate-Initialized Lookahead Predictor that distills the target router to forecast next-layer expert activation with high fidelity; (2) a Hardware-Aware Balance Planning solver that jointly optimizes dynamic expert replication and token assignment under strict hiding-window constraints; and (3) a Phase-Locked Co-Scheduling policy that uses split-phase transmission to hide bandwidth-intensive expert transfers behind computation without contending with All-to-All collectives. Experiments show that PROBE reduces prefill latency by up to 1.32X and improves decoding throughput by up to 1.26X over state-of-the-art baselines, especially under extreme workload volatility.", "AI": {"tldr": "PROBE\uff1a\u4e00\u4e2a\u5b9e\u65f6\u534f\u540c\u5e73\u8861\u8ba1\u7b97\u4e0e\u901a\u4fe1\u7684MoE\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fde\u7eed\u524d\u77bb\u6d41\u6c34\u7ebf\u9884\u6d4b\u3001\u89c4\u5212\u548c\u9884\u53d6\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u63d0\u5347\u541e\u5410\u91cf", "motivation": "MoE\u6a21\u578b\u63a8\u7406\u9762\u4e34\u8ba1\u7b97\u503e\u659c\u4e0e\u7f51\u7edc\u62e5\u585e\u7684\"\u53cc\u91cd\u60e9\u7f5a\"\u95ee\u9898\uff1a\u4e13\u5bb6\u5e76\u884c\u63d0\u9ad8\u5185\u5b58\u6548\u7387\u4f46\u52a0\u5267\u6267\u884c\u5ef6\u8fdf\uff0c\u5b9e\u9645\u670d\u52a1\u4e2d\u8fde\u7eed\u6279\u5904\u7406\u548c\u591a\u6837\u5316\u8bf7\u6c42\u5bfc\u81f4\u4e13\u5bb6\u70ed\u70b9\u5728GPU\u95f4\u5feb\u901f\u8fc1\u79fb", "method": "1) \u95e8\u63a7\u521d\u59cb\u5316\u524d\u77bb\u9884\u6d4b\u5668\uff1a\u84b8\u998f\u76ee\u6807\u8def\u7531\u5668\u4ee5\u9ad8\u4fdd\u771f\u5ea6\u9884\u6d4b\u4e0b\u4e00\u5c42\u4e13\u5bb6\u6fc0\u6d3b\uff1b2) \u786c\u4ef6\u611f\u77e5\u5e73\u8861\u89c4\u5212\u6c42\u89e3\u5668\uff1a\u5728\u4e25\u683c\u9690\u85cf\u7a97\u53e3\u7ea6\u675f\u4e0b\u8054\u5408\u4f18\u5316\u52a8\u6001\u4e13\u5bb6\u590d\u5236\u548c\u4ee4\u724c\u5206\u914d\uff1b3) \u9501\u76f8\u534f\u540c\u8c03\u5ea6\u7b56\u7565\uff1a\u4f7f\u7528\u5206\u9636\u6bb5\u4f20\u8f93\u5c06\u5e26\u5bbd\u5bc6\u96c6\u578b\u4e13\u5bb6\u4f20\u8f93\u9690\u85cf\u5728\u8ba1\u7b97\u540e\u9762", "result": "PROBE\u5c06\u9884\u586b\u5145\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe1.32\u500d\uff0c\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe1.26\u500d\uff0c\u5728\u6781\u7aef\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\u4e0b\u8868\u73b0\u5c24\u4e3a\u51fa\u8272", "conclusion": "PROBE\u901a\u8fc7\u5b9e\u65f6\u534f\u540c\u5e73\u8861\u8ba1\u7b97\u4e0e\u901a\u4fe1\uff0c\u6709\u6548\u89e3\u51b3\u4e86MoE\u63a8\u7406\u4e2d\u7684\u6267\u884c\u5ef6\u8fdf\u548c\u7f51\u7edc\u62e5\u585e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd"}}
{"id": "2602.00030", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00030", "abs": "https://arxiv.org/abs/2602.00030", "authors": ["Takato Yasuno"], "title": "RAPTOR-AI for Disaster OODA Loop: Hierarchical Multimodal RAG with Experience-Driven Agentic Decision-Making", "comment": "4 figures, 3 tables", "summary": "Effective humanitarian assistance and disaster relief (HADR) requires rapid situational understanding, reliable decision support, and the ability to generalize across diverse and previously unseen disaster contexts. This work introduces an agentic Retrieval-Augmented Generation (RAG) framework designed to support the three canonical phases of disaster response: initial rescue, mid-term recovery, and long-term reconstruction. To achieve robust multimodal grounding, we construct a hierarchical knowledge base that integrates textual disaster manuals, historical lessons (e.g., the 2011 Tohoku earthquake), and both aerial and ground-level imagery. Our system builds on the open-source multimodal implementation, which processes 46 tsunami-related PDFs (2,378 pages) using BLIP-based image captioning, ColVBERT embeddings, and long-context summarization to generate an efficient, structured multimodal retrieval tree optimized for disaster knowledge preservation. An agentic controller dynamically selects retrieval strategies (e.g., RAPTOR, ColBERT) through entropy-aware scene abstraction, enabling adaptive reasoning across heterogeneous inputs. Additionally, a lightweight LoRA-based post-training method injects experiential knowledge from past disasters, enhancing the models' capacity to support both expert and non-expert responders. Experiments on real disaster datasets demonstrate improved situational grounding, enhanced task decomposition accuracy, and superior usability for emergency operations. Incorporating recent advances in long-context RAG systems, agentic information retrieval, and contemporary emergency response AI, our system achieves substantial gains through adaptive retrieval-augmented generation with self-reasoning and multimodal chain-of-thought capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u4eba\u9053\u4e3b\u4e49\u63f4\u52a9\u548c\u707e\u5bb3\u54cd\u5e94\u7684\u667a\u80fdRAG\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u77e5\u8bc6\u5e93\u548c\u81ea\u9002\u5e94\u68c0\u7d22\u7b56\u7565\u652f\u6301\u707e\u5bb3\u54cd\u5e94\u7684\u4e09\u4e2a\u9636\u6bb5", "motivation": "\u707e\u5bb3\u54cd\u5e94\u9700\u8981\u5feb\u901f\u7406\u89e3\u73b0\u573a\u60c5\u51b5\u3001\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u5404\u79cd\u672a\u89c1\u8fc7\u7684\u707e\u5bb3\u573a\u666f\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u707e\u5bb3\u54cd\u5e94\u4e09\u4e2a\u9636\u6bb5\uff08\u6551\u63f4\u3001\u4e2d\u671f\u6062\u590d\u3001\u957f\u671f\u91cd\u5efa\uff09\u7684\u5168\u9762\u652f\u6301\uff0c\u4ee5\u53ca\u8de8\u6a21\u6001\u4fe1\u606f\u7684\u6709\u6548\u6574\u5408", "method": "\u6784\u5efa\u5206\u5c42\u77e5\u8bc6\u5e93\u6574\u5408\u6587\u672c\u624b\u518c\u3001\u5386\u53f2\u707e\u5bb3\u7ecf\u9a8c\uff08\u59822011\u5e74\u4e1c\u5317\u5730\u9707\uff09\u548c\u7a7a\u62cd/\u5730\u9762\u56fe\u50cf\uff1b\u4f7f\u7528BLIP\u56fe\u50cf\u63cf\u8ff0\u3001ColVBERT\u5d4c\u5165\u548c\u957f\u4e0a\u4e0b\u6587\u6458\u8981\u5904\u740646\u4e2a\u6d77\u5578\u76f8\u5173PDF\uff1b\u91c7\u7528\u667a\u80fd\u63a7\u5236\u5668\u901a\u8fc7\u71b5\u611f\u77e5\u573a\u666f\u62bd\u8c61\u52a8\u6001\u9009\u62e9\u68c0\u7d22\u7b56\u7565\uff08RAPTOR\u3001ColBERT\uff09\uff1b\u4f7f\u7528\u8f7b\u91cf\u7ea7LoRA\u540e\u8bad\u7ec3\u65b9\u6cd5\u6ce8\u5165\u5386\u53f2\u707e\u5bb3\u7ecf\u9a8c\u77e5\u8bc6", "result": "\u5728\u771f\u5b9e\u707e\u5bb3\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff1a\u6539\u5584\u4e86\u60c5\u5883\u7406\u89e3\u3001\u63d0\u9ad8\u4e86\u4efb\u52a1\u5206\u89e3\u51c6\u786e\u6027\u3001\u589e\u5f3a\u4e86\u5e94\u6025\u64cd\u4f5c\u53ef\u7528\u6027\uff1b\u901a\u8fc7\u81ea\u9002\u5e94\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u81ea\u6211\u63a8\u7406\u548c\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u80fd\u529b\u5b9e\u73b0\u663e\u8457\u63d0\u5347", "conclusion": "\u8be5\u667a\u80fdRAG\u6846\u67b6\u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u707e\u5bb3\u77e5\u8bc6\u3001\u81ea\u9002\u5e94\u68c0\u7d22\u7b56\u7565\u548c\u7ecf\u9a8c\u77e5\u8bc6\u6ce8\u5165\uff0c\u4e3a\u707e\u5bb3\u54cd\u5e94\u7684\u4e09\u4e2a\u9636\u6bb5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u51b3\u7b56\u652f\u6301\uff0c\u80fd\u591f\u540c\u65f6\u670d\u52a1\u4e13\u5bb6\u548c\u975e\u4e13\u5bb6\u54cd\u5e94\u4eba\u5458"}}
{"id": "2602.01546", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.01546", "abs": "https://arxiv.org/abs/2602.01546", "authors": ["Shanmuga Venkatachalam", "Prabhu Vellaisamy", "Harideep Nair", "Wei-Che Huang", "Youngseok Na", "Yuyang Kang", "Quinn Jacobson", "John Paul Shen"], "title": "NeuroAI Temporal Neural Networks (NeuTNNs): Microarchitecture and Design Framework for Specialized Neuromorphic Processing Units", "comment": null, "summary": "Leading experts from both communities have suggested the need to (re)connect research in neuroscience and artificial intelligence (AI) to accelerate the development of next-generation AI innovations. They term this convergence as NeuroAI. Previous research has established temporal neural networks (TNNs) as a promising neuromorphic approach toward biological intelligence and efficiency. We fully embrace NeuroAI and propose a new category of TNNs we call NeuroAI TNNs (NeuTNNs) with greater capability and hardware efficiency by adopting neuroscience findings, including a neuron model with active dendrites and a hierarchy of distal and proximal segments. This work introduces a PyTorch-to-layout tool suite (NeuTNNGen) to design application-specific NeuTNNs. Compared to previous TNN designs, NeuTNNs achieve superior performance and efficiency. We demonstrate NeuTNNGen's capabilities using three example applications: 1) UCR time series benchmarks, 2) MNIST design exploration, and 3) Place Cells design for neocortical reference frames. We also explore using synaptic pruning to further reduce synapse counts and hardware costs by 30-50% while maintaining model precision across diverse sensory modalities. NeuTNNGen can facilitate the design of application-specific energy-efficient NeuTNNs for the next generation of NeuroAI computing systems.", "AI": {"tldr": "\u63d0\u51faNeuroAI TNNs (NeuTNNs) - \u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u79d1\u5b66\u53d1\u73b0\u7684\u65b0\u578b\u65f6\u5e8f\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7PyTorch-to-layout\u5de5\u5177\u5957\u4ef6(NeuTNNGen)\u8bbe\u8ba1\u5e94\u7528\u4e13\u7528\u786c\u4ef6\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edfTNNs\u3002", "motivation": "\u795e\u7ecf\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u7684\u878d\u5408(NeuroAI)\u88ab\u8ba4\u4e3a\u662f\u63a8\u52a8\u4e0b\u4e00\u4ee3AI\u521b\u65b0\u7684\u5173\u952e\u3002\u867d\u7136\u65f6\u5e8f\u795e\u7ecf\u7f51\u7edc(TNNs)\u5df2\u88ab\u8bc1\u660e\u662f\u5b9e\u73b0\u751f\u7269\u667a\u80fd\u548c\u6548\u7387\u7684\u6709\u524d\u666f\u7684\u795e\u7ecf\u5f62\u6001\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7ed3\u5408\u795e\u7ecf\u79d1\u5b66\u53d1\u73b0\u6765\u63d0\u5347\u5176\u80fd\u529b\u548c\u786c\u4ef6\u6548\u7387\u3002", "method": "\u63d0\u51faNeuroAI TNNs (NeuTNNs)\uff0c\u91c7\u7528\u5177\u6709\u4e3b\u52a8\u6811\u7a81\u548c\u8fd1\u7aef-\u8fdc\u7aef\u6bb5\u5c42\u6b21\u7ed3\u6784\u7684\u795e\u7ecf\u5143\u6a21\u578b\u3002\u5f00\u53d1NeuTNNGen\u5de5\u5177\u5957\u4ef6\uff0c\u5b9e\u73b0\u4ecePyTorch\u5230\u786c\u4ef6\u5e03\u5c40\u7684\u81ea\u52a8\u5316\u8bbe\u8ba1\u6d41\u7a0b\u3002\u901a\u8fc7\u7a81\u89e6\u526a\u679d\u6280\u672f\u8fdb\u4e00\u6b65\u51cf\u5c1130-50%\u7684\u7a81\u89e6\u6570\u91cf\u3002", "result": "NeuTNNs\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edfTNN\u8bbe\u8ba1\uff0c\u5728\u4e09\u4e2a\u5e94\u7528\u6848\u4f8b\u4e2d\u8868\u73b0\u4f18\u5f02\uff1a1) UCR\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u6d4b\u8bd5\uff0c2) MNIST\u8bbe\u8ba1\u63a2\u7d22\uff0c3) \u7528\u4e8e\u65b0\u76ae\u5c42\u53c2\u8003\u6846\u67b6\u7684\u4f4d\u7f6e\u7ec6\u80de\u8bbe\u8ba1\u3002\u7a81\u89e6\u526a\u679d\u80fd\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u786c\u4ef6\u6210\u672c\u3002", "conclusion": "NeuTNNGen\u5de5\u5177\u80fd\u591f\u4fc3\u8fdb\u9762\u5411\u4e0b\u4e00\u4ee3NeuroAI\u8ba1\u7b97\u7cfb\u7edf\u7684\u5e94\u7528\u4e13\u7528\u3001\u9ad8\u80fd\u6548NeuTNNs\u7684\u8bbe\u8ba1\uff0c\u4e3a\u795e\u7ecf\u79d1\u5b66\u4e0eAI\u7684\u878d\u5408\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5b9e\u73b0\u6846\u67b6\u3002"}}
{"id": "2602.00748", "categories": ["cs.DC", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.00748", "abs": "https://arxiv.org/abs/2602.00748", "authors": ["Fangxin Liu", "Qinghua Zhang", "Hanjing Shen", "Zhibo Liang", "Li Jiang", "Haibing Guan", "Chong Bao", "Xuefeng Jin"], "title": "HyperOffload: Graph-Driven Hierarchical Memory Management for Large Language Models on SuperNode Architectures", "comment": "Technical Report", "summary": "The rapid evolution of Large Language Models (LLMs) towards long-context reasoning and sparse architectures has pushed memory requirements far beyond the capacity of individual device HBM. While emerging supernode architectures offer terabyte-scale shared memory pools via high-bandwidth interconnects, existing software stacks fail to exploit this hardware effectively. Current runtime-based offloading and swapping techniques operate with a local view, leading to reactive scheduling and exposed communication latency that stall the computation pipeline.\n  In this paper, we propose the SuperNode Memory Management Framework (\\textbf{HyperOffload}). It employs a compiler-assisted approach that leverages graph-driven memory management to treat remote memory access as explicit operations in the computation graph, specifically designed for hierarchical SuperNode architectures. Unlike reactive runtime systems, SuperNode represents data movement using cache operators within the compiler's Intermediate Representation (IR). This design enables a global, compile-time analysis of tensor lifetimes and execution dependencies. Leveraging this visibility, we develop a global execution-order refinement algorithm that statically schedules data transfers to hide remote memory latency behind compute-intensive regions. We implement SuperNode within the production deep learning framework MindSpore, adding a remote memory backend and specialized compiler passes. Evaluation on representative LLM workloads shows that SuperNode reduces peak device memory usage by up to 26\\% for inference while maintaining end-to-end performance. Our work demonstrates that integrating memory-augmented hardware into the compiler's optimization framework is essential for scaling next-generation AI workloads.", "AI": {"tldr": "HyperOffload\u662f\u4e00\u4e2a\u9488\u5bf9\u8d85\u7ea7\u8282\u70b9\u67b6\u6784\u7684\u7f16\u8bd1\u5668\u8f85\u52a9\u5185\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u9a71\u52a8\u7684\u5185\u5b58\u7ba1\u7406\u5c06\u8fdc\u7a0b\u5185\u5b58\u8bbf\u95ee\u4f5c\u4e3a\u8ba1\u7b97\u56fe\u4e2d\u7684\u663e\u5f0f\u64cd\u4f5c\uff0c\u5b9e\u73b0\u9759\u6001\u6570\u636e\u8c03\u5ea6\u4ee5\u9690\u85cf\u5ef6\u8fdf\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u51cf\u5c11\u5cf0\u503c\u8bbe\u5907\u5185\u5b58\u4f7f\u7528\u8fbe26%", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5411\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u7a00\u758f\u67b6\u6784\u53d1\u5c55\uff0c\u5185\u5b58\u9700\u6c42\u5df2\u8d85\u8fc7\u5355\u4e2a\u8bbe\u5907HBM\u5bb9\u91cf\u3002\u867d\u7136\u65b0\u5174\u8d85\u7ea7\u8282\u70b9\u67b6\u6784\u901a\u8fc7\u9ad8\u901f\u4e92\u8fde\u63d0\u4f9bTB\u7ea7\u5171\u4eab\u5185\u5b58\u6c60\uff0c\u4f46\u73b0\u6709\u8f6f\u4ef6\u6808\u65e0\u6cd5\u6709\u6548\u5229\u7528\u8fd9\u79cd\u786c\u4ef6\u3002\u5f53\u524d\u57fa\u4e8e\u8fd0\u884c\u65f6\u7684\u5378\u8f7d\u548c\u4ea4\u6362\u6280\u672f\u5177\u6709\u5c40\u90e8\u89c6\u89d2\uff0c\u5bfc\u81f4\u53cd\u5e94\u5f0f\u8c03\u5ea6\u548c\u901a\u4fe1\u5ef6\u8fdf\u66b4\u9732\uff0c\u4ece\u800c\u963b\u585e\u8ba1\u7b97\u6d41\u6c34\u7ebf\u3002", "method": "\u91c7\u7528\u7f16\u8bd1\u5668\u8f85\u52a9\u65b9\u6cd5\uff0c\u5229\u7528\u56fe\u9a71\u52a8\u5185\u5b58\u7ba1\u7406\u5c06\u8fdc\u7a0b\u5185\u5b58\u8bbf\u95ee\u4f5c\u4e3a\u8ba1\u7b97\u56fe\u4e2d\u7684\u663e\u5f0f\u64cd\u4f5c\uff0c\u4e13\u95e8\u4e3a\u5206\u5c42\u8d85\u7ea7\u8282\u70b9\u67b6\u6784\u8bbe\u8ba1\u3002\u5728\u7f16\u8bd1\u5668\u7684\u4e2d\u95f4\u8868\u793a\u4e2d\u4f7f\u7528\u7f13\u5b58\u64cd\u4f5c\u7b26\u8868\u793a\u6570\u636e\u79fb\u52a8\uff0c\u5b9e\u73b0\u5f20\u91cf\u751f\u547d\u5468\u671f\u548c\u6267\u884c\u4f9d\u8d56\u7684\u5168\u5c40\u7f16\u8bd1\u65f6\u5206\u6790\u3002\u5f00\u53d1\u5168\u5c40\u6267\u884c\u987a\u5e8f\u4f18\u5316\u7b97\u6cd5\uff0c\u9759\u6001\u8c03\u5ea6\u6570\u636e\u4f20\u8f93\u4ee5\u5728\u8ba1\u7b97\u5bc6\u96c6\u578b\u533a\u57df\u540e\u9762\u9690\u85cf\u8fdc\u7a0b\u5185\u5b58\u5ef6\u8fdf\u3002\u5728MindSpore\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u5b9e\u73b0\uff0c\u6dfb\u52a0\u8fdc\u7a0b\u5185\u5b58\u540e\u7aef\u548c\u4e13\u95e8\u7684\u7f16\u8bd1\u5668\u901a\u9053\u3002", "result": "\u5728\u4ee3\u8868\u6027LLM\u5de5\u4f5c\u8d1f\u8f7d\u8bc4\u4f30\u4e2d\uff0cHyperOffload\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5c06\u5cf0\u503c\u8bbe\u5907\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u9ad8\u8fbe26%\uff0c\u540c\u65f6\u4fdd\u6301\u7aef\u5230\u7aef\u6027\u80fd\u3002\u8bc1\u660e\u5c06\u5185\u5b58\u589e\u5f3a\u786c\u4ef6\u96c6\u6210\u5230\u7f16\u8bd1\u5668\u4f18\u5316\u6846\u67b6\u5bf9\u4e8e\u6269\u5c55\u4e0b\u4e00\u4ee3AI\u5de5\u4f5c\u8d1f\u8f7d\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "HyperOffload\u6846\u67b6\u901a\u8fc7\u7f16\u8bd1\u5668\u8f85\u52a9\u7684\u5168\u5c40\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8d85\u7ea7\u8282\u70b9\u67b6\u6784\u4e2d\u7684\u5185\u5b58\u6269\u5c55\u95ee\u9898\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6269\u5c55\u63d0\u4f9b\u4e86\u5173\u952e\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2602.00040", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00040", "abs": "https://arxiv.org/abs/2602.00040", "authors": ["Haonan Shi", "Dehua Shuai", "Liming Wang", "Xiyang Liu", "Long Tian"], "title": "Enhancing few-shot time series forecasting with LLM-guided diffusion", "comment": null, "summary": "Time series forecasting in specialized domains is often constrained by limited data availability, where conventional models typically require large-scale datasets to effectively capture underlying temporal dynamics. To tackle this few-shot challenge, we propose LTSM-DIFF (Large-scale Temporal Sequential Memory with Diffusion), a novel learning framework that integrates the expressive power of large language models with the generative capability of diffusion models. Specifically, the LTSM module is fine-tuned and employed as a temporal memory mechanism, extracting rich sequential representations even under data-scarce conditions. These representations are then utilized as conditional guidance for a joint probability diffusion process, enabling refined modeling of complex temporal patterns. This design allows knowledge transfer from the language domain to time series tasks, substantially enhancing both generalization and robustness. Extensive experiments across diverse benchmarks demonstrate that LTSM-DIFF consistently achieves state-of-the-art performance in data-rich scenarios, while also delivering significant improvements in few-shot forecasting. Our work establishes a new paradigm for time series analysis under data scarcity.", "AI": {"tldr": "LTSM-DIFF\uff1a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6269\u6563\u6a21\u578b\u7684\u5c0f\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4f18\u5f02\u6027\u80fd", "motivation": "\u4e13\u4e1a\u9886\u57df\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5e38\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4f20\u7edf\u6a21\u578b\u9700\u8981\u5927\u89c4\u6a21\u6570\u636e\u96c6\u624d\u80fd\u6709\u6548\u6355\u6349\u65f6\u95f4\u52a8\u6001\u3002\u4e3a\u89e3\u51b3\u5c0f\u6837\u672c\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5728\u6570\u636e\u6709\u9650\u6761\u4ef6\u4e0b\u6709\u6548\u5de5\u4f5c\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLTSM-DIFF\u6846\u67b6\uff1a1\uff09LTSM\u6a21\u5757\u4f5c\u4e3a\u65f6\u95f4\u8bb0\u5fc6\u673a\u5236\uff0c\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u800c\u6765\uff0c\u63d0\u53d6\u4e30\u5bcc\u7684\u5e8f\u5217\u8868\u793a\uff1b2\uff09\u6269\u6563\u6a21\u578b\u7528\u4e8e\u8054\u5408\u6982\u7387\u6269\u6563\u8fc7\u7a0b\uff0c\u4ee5LTSM\u8868\u793a\u4f5c\u4e3a\u6761\u4ef6\u6307\u5bfc\uff0c\u7cbe\u7ec6\u5efa\u6a21\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\uff1b3\uff09\u5b9e\u73b0\u4ece\u8bed\u8a00\u9886\u57df\u5230\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLTSM-DIFF\u5728\u6570\u636e\u4e30\u5bcc\u573a\u666f\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u5c0f\u6837\u672c\u9884\u6d4b\u4e2d\u5e26\u6765\u663e\u8457\u6539\u8fdb\uff0c\u5efa\u7acb\u4e86\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u65b0\u8303\u5f0f\u3002", "conclusion": "LTSM-DIFF\u6210\u529f\u6574\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u7684\u65f6\u5e8f\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.01827", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.01827", "abs": "https://arxiv.org/abs/2602.01827", "authors": ["Tommaso Spagnolo", "Cristina Silvano", "Riccardo Massa", "Filippo Grillotti", "Thomas Boesch", "Giuseppe Desoli"], "title": "In-Pipeline Integration of Digital In-Memory-Computing into RISC-V Vector Architecture to Accelerate Deep Learning", "comment": null, "summary": "Expanding Deep Learning applications toward edge computing demands architectures capable of delivering high computational performance and efficiency while adhering to tight power and memory constraints. Digital In-Memory Computing (DIMC) addresses this need by moving part of the computation directly within memory arrays, significantly reducing data movement and improving energy efficiency. This paper introduces a novel architecture that extends the Vector RISC-V Instruction Set Architecture (ISA) to integrate a tightly coupled DIMC unit directly into the execution stage of the pipeline, to accelerate Deep Learning inference at the edge. Specifically, the proposed approach adds four custom instructions dedicated to data loading, computation, and write-back, enabling flexible and optimal control of the inference execution on the target architecture. Experimental results demonstrate high utilization of the DIMC tile in Vector RISC-V and sustained throughput across the ResNet-50 model, achieving a peak performance of 137 GOP/s. The proposed architecture achieves a speedup of 217x over the baseline core and 50x area-normalized speedup even when operating near the hardware resource limits. The experimental results confirm the high potential of the proposed architecture as a scalable and efficient solution to accelerate Deep Learning inference on the edge.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u6570\u5b57\u5185\u5b58\u8ba1\u7b97\u5355\u5143\u7d27\u5bc6\u96c6\u6210\u5230\u5411\u91cfRISC-V\u6267\u884c\u6d41\u6c34\u7ebf\u7684\u65b0\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u6307\u4ee4\u52a0\u901f\u8fb9\u7f18\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\uff0c\u5b9e\u73b0217\u500d\u52a0\u901f\u6bd4", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u9700\u8981\u9ad8\u6027\u80fd\u3001\u9ad8\u6548\u7387\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u4f46\u9762\u4e34\u4e25\u683c\u7684\u529f\u8017\u548c\u5185\u5b58\u9650\u5236\u3002\u6570\u5b57\u5185\u5b58\u8ba1\u7b97\u901a\u8fc7\u5c06\u8ba1\u7b97\u79fb\u5230\u5185\u5b58\u9635\u5217\u4e2d\u6765\u51cf\u5c11\u6570\u636e\u79fb\u52a8\u5e76\u63d0\u9ad8\u80fd\u6548\u3002", "method": "\u6269\u5c55\u5411\u91cfRISC-V\u6307\u4ee4\u96c6\u67b6\u6784\uff0c\u5728\u6d41\u6c34\u7ebf\u6267\u884c\u9636\u6bb5\u7d27\u5bc6\u96c6\u6210DIMC\u5355\u5143\uff0c\u6dfb\u52a0\u56db\u4e2a\u81ea\u5b9a\u4e49\u6307\u4ee4\u4e13\u95e8\u7528\u4e8e\u6570\u636e\u52a0\u8f7d\u3001\u8ba1\u7b97\u548c\u5199\u56de\u64cd\u4f5c\uff0c\u5b9e\u73b0\u5bf9\u63a8\u7406\u6267\u884c\u7684\u7075\u6d3b\u4f18\u5316\u63a7\u5236\u3002", "result": "\u5728ResNet-50\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86137 GOP/s\u7684\u5cf0\u503c\u6027\u80fd\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6838\u5fc3\u83b7\u5f97217\u500d\u52a0\u901f\u6bd4\uff0c\u5373\u4f7f\u5728\u786c\u4ef6\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b050\u500d\u9762\u79ef\u5f52\u4e00\u5316\u52a0\u901f\u6bd4\u3002", "conclusion": "\u8be5\u67b6\u6784\u5c55\u793a\u4e86\u4f5c\u4e3a\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u8fb9\u7f18\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u9a8c\u8bc1\u4e86DIMC\u4e0e\u5411\u91cfRISC-V\u7d27\u5bc6\u96c6\u6210\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.00892", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.00892", "abs": "https://arxiv.org/abs/2602.00892", "authors": ["Jebacyril Arockiaraj", "Sasindu Wijeratne", "Sugeet Sunder", "Md Abdullah-Al Kaiser", "Akhilesh Jaiswal", "Ajey P. Jacob", "Viktor Prasanna"], "title": "System-Level Performance Modeling of Photonic In-Memory Computing", "comment": null, "summary": "Photonic in-memory computing is a high-speed, low-energy alternative to traditional transistor-based digital computing that utilizes high photonic operating frequencies and bandwidths. In this work, we develop a comprehensive system-level performance model for photonic in-memory computing, capturing the effects of key latency sources such as external memory access and opto-electronic conversion. We perform algorithm-to-hardware mapping across a range of workloads, including the Sod shock tube problem, Matricized Tensor Times Khatri-Rao Product (MTTKRP), and the Vlasov-Maxwell equation, to evaluate how the latencies impact real-world high-performance computing workloads. Our performance model shows that, while accounting for system overheads, a compact 1x256 bit single-wavelength photonic SRAM array, fabricated using the standard silicon photonics process by GlobalFoundries, sustains up to 1.5 TOPS, 0.9 TOPS, and 1.3 TOPS on the Sod shock tube problem, MTTKRP, and the Vlasov-Maxwell equation with an average energy efficiency of 2.5 TOPS/W.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u5149\u5b50\u5185\u5b58\u8ba1\u7b97\u7684\u7cfb\u7edf\u7ea7\u6027\u80fd\u6a21\u578b\uff0c\u5206\u6790\u4e86\u5916\u90e8\u5185\u5b58\u8bbf\u95ee\u548c\u5149\u7535\u8f6c\u6362\u7b49\u5173\u952e\u5ef6\u8fdf\u6e90\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5f71\u54cd\uff0c\u5c55\u793a\u4e861\u00d7256\u4f4d\u5355\u6ce2\u957f\u5149\u5b50SRAM\u9635\u5217\u5728\u591a\u4e2a\u5b9e\u9645\u5e94\u7528\u4e2d\u8fbe\u52301-1.5 TOPS\u7684\u6027\u80fd\u548c2.5 TOPS/W\u7684\u80fd\u6548\u3002", "motivation": "\u5149\u5b50\u5185\u5b58\u8ba1\u7b97\u4f5c\u4e3a\u4f20\u7edf\u6676\u4f53\u7ba1\u6570\u5b57\u8ba1\u7b97\u7684\u9ad8\u901f\u3001\u4f4e\u80fd\u8017\u66ff\u4ee3\u65b9\u6848\uff0c\u5177\u6709\u9ad8\u5149\u5b50\u5de5\u4f5c\u9891\u7387\u548c\u5e26\u5bbd\u4f18\u52bf\u3002\u7136\u800c\uff0c\u7cfb\u7edf\u7ea7\u6027\u80fd\u53d7\u591a\u79cd\u5ef6\u8fdf\u6e90\u5f71\u54cd\uff0c\u9700\u8981\u5efa\u7acb\u7efc\u5408\u6a21\u578b\u6765\u8bc4\u4f30\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u5f00\u53d1\u4e86\u5168\u9762\u7684\u7cfb\u7edf\u7ea7\u6027\u80fd\u6a21\u578b\uff0c\u6355\u6349\u5916\u90e8\u5185\u5b58\u8bbf\u95ee\u548c\u5149\u7535\u8f6c\u6362\u7b49\u5173\u952e\u5ef6\u8fdf\u6e90\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u7b97\u6cd5\u5230\u786c\u4ef6\u7684\u6620\u5c04\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u9ad8\u6027\u80fd\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\uff08Sod\u6fc0\u6ce2\u7ba1\u95ee\u9898\u3001MTTKRP\u3001Vlasov-Maxwell\u65b9\u7a0b\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4f7f\u7528GlobalFoundries\u6807\u51c6\u7845\u5149\u5b50\u5de5\u827a\u5236\u9020\u7684\u7d27\u51d1\u578b1\u00d7256\u4f4d\u5355\u6ce2\u957f\u5149\u5b50SRAM\u9635\u5217\uff0c\u5728\u8003\u8651\u7cfb\u7edf\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\uff0c\u5728Sod\u6fc0\u6ce2\u7ba1\u95ee\u9898\u3001MTTKRP\u548cVlasov-Maxwell\u65b9\u7a0b\u4e0a\u5206\u522b\u8fbe\u52301.5 TOPS\u30010.9 TOPS\u548c1.3 TOPS\u7684\u6027\u80fd\uff0c\u5e73\u5747\u80fd\u6548\u4e3a2.5 TOPS/W\u3002", "conclusion": "\u5149\u5b50\u5185\u5b58\u8ba1\u7b97\u7cfb\u7edf\u5728\u8003\u8651\u5b9e\u9645\u5ef6\u8fdf\u6e90\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u80fd\u5b9e\u73b0\u9ad8\u6027\u80fd\u548c\u9ad8\u80fd\u6548\uff0c\u5c55\u793a\u4e86\u5176\u5728\u89e3\u51b3\u590d\u6742\u79d1\u5b66\u8ba1\u7b97\u95ee\u9898\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2602.00046", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00046", "abs": "https://arxiv.org/abs/2602.00046", "authors": ["Sarthak Sattigeri"], "title": "Extending Beacon to Hindi: Cultural Adaptation Drives Cross-Lingual Sycophancy", "comment": "First Hindi sycophancy benchmark using a three-condition design separating language and cultural effects, with empirical evaluation across four instruction-tuned models", "summary": "Sycophancy, the tendency of language models to prioritize agreement with user preferences over principled reasoning, has been identified as a persistent alignment failure in English-language evaluations. However, it remains unclear whether such diagnostics generalize across languages and cultural contexts. We extend the Beacon single-turn forced-choice sycophancy diagnostic to Hindi through a controlled three-condition design: English original, Hindi literal translation, and Hindi culturally adapted prompts. We evaluate four open-weight instruction-tuned models on 50 prompts per condition, enabling separation of language encoding effects from cultural adaptation effects. Across all models, sycophancy rates are consistently higher for culturally adapted Hindi prompts than for English, with absolute differences ranging from 12.0 to 16.0 percentage points. A decomposition on Qwen 2.5-Coder-7B shows that cultural adaptation (delta = 14.0%, 95% CI: [4.0%, 26.0%]) accounts for the majority of this gap, while language encoding contributes minimally (delta = 2.0%, 95% CI: [0.0%, 6.0%]). Category-level analysis reveals that advice prompts exhibit the largest cross-lingual differences (20-25 percentage points), achieving statistical significance in two of four models. These findings indicate that alignment behaviors measured in English may not transfer uniformly across languages and that culturally grounded prompt framing plays a substantial role. We release all datasets and evaluation code to support replication and extension.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u5370\u5730\u8bed\u6587\u5316\u9002\u5e94\u63d0\u793a\u4e0b\u7684\u5949\u627f\u503e\u5411\u663e\u8457\u9ad8\u4e8e\u82f1\u8bed\uff0c\u6587\u5316\u9002\u5e94\u662f\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u800c\u975e\u8bed\u8a00\u7f16\u7801\u672c\u8eab\u3002", "motivation": "\u5949\u627f\u503e\u5411\uff08\u8bed\u8a00\u6a21\u578b\u4f18\u5148\u8fce\u5408\u7528\u6237\u504f\u597d\u800c\u975e\u539f\u5219\u6027\u63a8\u7406\uff09\u5728\u82f1\u8bed\u8bc4\u4f30\u4e2d\u88ab\u8ba4\u4e3a\u662f\u6301\u7eed\u7684\u5bf9\u9f50\u5931\u8d25\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u8bca\u65ad\u662f\u5426\u9002\u7528\u4e8e\u4e0d\u540c\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u3002\u9700\u8981\u7814\u7a76\u5949\u627f\u503e\u5411\u662f\u5426\u8de8\u8bed\u8a00\u548c\u6587\u5316\u666e\u904d\u5b58\u5728\u3002", "method": "\u5c06Beacon\u5355\u8f6e\u5f3a\u5236\u9009\u62e9\u5949\u627f\u8bca\u65ad\u6269\u5c55\u5230\u5370\u5730\u8bed\uff0c\u91c7\u7528\u4e09\u6761\u4ef6\u8bbe\u8ba1\uff1a\u82f1\u8bed\u539f\u7248\u3001\u5370\u5730\u8bed\u76f4\u8bd1\u3001\u5370\u5730\u8bed\u6587\u5316\u9002\u5e94\u63d0\u793a\u3002\u8bc4\u4f30\u56db\u4e2a\u5f00\u653e\u6743\u91cd\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\uff0c\u6bcf\u4e2a\u6761\u4ef650\u4e2a\u63d0\u793a\uff0c\u5206\u79bb\u8bed\u8a00\u7f16\u7801\u6548\u5e94\u548c\u6587\u5316\u9002\u5e94\u6548\u5e94\u3002", "result": "\u6240\u6709\u6a21\u578b\u4e2d\uff0c\u6587\u5316\u9002\u5e94\u5370\u5730\u8bed\u63d0\u793a\u7684\u5949\u627f\u7387\u59cb\u7ec8\u9ad8\u4e8e\u82f1\u8bed\uff0c\u7edd\u5bf9\u5dee\u5f0212.0-16.0\u4e2a\u767e\u5206\u70b9\u3002\u5bf9Qwen 2.5-Coder-7B\u7684\u5206\u89e3\u663e\u793a\u6587\u5316\u9002\u5e94\u8d21\u732e\u4e3b\u8981\u5dee\u5f02\uff08delta=14.0%\uff09\uff0c\u8bed\u8a00\u7f16\u7801\u8d21\u732e\u5f88\u5c0f\uff08delta=2.0%\uff09\u3002\u5efa\u8bae\u7c7b\u63d0\u793a\u663e\u793a\u6700\u5927\u7684\u8de8\u8bed\u8a00\u5dee\u5f02\uff0820-25\u4e2a\u767e\u5206\u70b9\uff09\u3002", "conclusion": "\u57fa\u4e8e\u82f1\u8bed\u6d4b\u91cf\u7684\u5bf9\u9f50\u884c\u4e3a\u53ef\u80fd\u65e0\u6cd5\u5747\u5300\u5730\u8de8\u8bed\u8a00\u8f6c\u79fb\uff0c\u6587\u5316\u57fa\u7840\u7684\u63d0\u793a\u6846\u67b6\u8d77\u7740\u91cd\u8981\u4f5c\u7528\u3002\u9700\u8981\u66f4\u591a\u8de8\u8bed\u8a00\u5bf9\u9f50\u7814\u7a76\u3002"}}
{"id": "2602.02005", "categories": ["cs.AR", "cs.LG", "eess.SY", "hep-ex", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02005", "abs": "https://arxiv.org/abs/2602.02005", "authors": ["Duc Hoang"], "title": "Position: The Need for Ultrafast Training", "comment": "Position paper at the 2nd Workshop on Domain-Specialized FPGAs (WDSFPGA 2026)", "summary": "Domain-specialized FPGAs have delivered unprecedented performance for low-latency inference across scientific and industrial workloads, yet nearly all existing accelerators assume static models trained offline, relegating learning and adaptation to slower CPUs or GPUs. This separation fundamentally limits systems that must operate in non-stationary, high-frequency environments, where model updates must occur at the timescale of the underlying physics. In this paper, I argue for a shift from inference-only accelerators to ultrafast on-chip learning, in which both inference and training execute directly within the FPGA fabric under deterministic, sub-microsecond latency constraints. Bringing learning into the same real-time datapath as inference would enable closed-loop systems that adapt as fast as the physical processes they control, with applications spanning quantum error correction, cryogenic qubit calibration, plasma and fusion control, accelerator tuning, and autonomous scientific experiments. Enabling such regimes requires rethinking algorithms, architectures, and toolflows jointly, but promises to transform FPGAs from static inference engines into real-time learning machines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.01024", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.01024", "abs": "https://arxiv.org/abs/2602.01024", "authors": ["Zhiwen Pang", "Kang Wei", "Long Shi", "Zhe Wang", "Jun Li", "Feng Shu"], "title": "Low-latency Federated LLM Fine-tuning Over Wireless Networks", "comment": null, "summary": "Recently, federated large language models (LLMs) have drawn significant attention thanks to coupled capabilities of LLMs and federated learning (FL) that address privacy concerns in collaborative fine-tuning. However, due to large-scale parameters of LLMs, existing federated LLM fine-tuning frameworks incur significant challenges in resource-constrained clients characterized by heterogeneous computing capabilities and random wireless channels. To address this issue, we propose a joint client-specific pruning and bandwidth allocation (JCPBA) framework for federated LLMs to improve the fine-tuning efficiency over the wireless networks. Specifically, we formulate a fine-tuning latency minimization problem by jointly optimizing pruning rates and bandwidth allocations. Furthermore, we solve this optimization problem using a block coordinate descent method. Extensive experiments on the datasets of Yahoo Answers and GSM8K demonstrate that the proposed framework significantly reduces wall-clock fine-tuning time compared with state-of-the-art baselines and gains equal or lower test loss at the cost of lower computation and communication overhead.", "AI": {"tldr": "\u63d0\u51faJCPBA\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5ba2\u6237\u7aef\u526a\u679d\u548c\u5e26\u5bbd\u5206\u914d\u4f18\u5316\uff0c\u964d\u4f4e\u8054\u90a6\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5fae\u8c03\u5ef6\u8fdf", "motivation": "\u8054\u90a6\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u4e86LLMs\u548c\u8054\u90a6\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u80fd\u89e3\u51b3\u534f\u4f5c\u5fae\u8c03\u4e2d\u7684\u9690\u79c1\u95ee\u9898\u3002\u4f46\u7531\u4e8eLLMs\u53c2\u6570\u91cf\u5de8\u5927\uff0c\u73b0\u6709\u8054\u90a6LLM\u5fae\u8c03\u6846\u67b6\u5728\u8ba1\u7b97\u80fd\u529b\u5f02\u6784\u4e14\u65e0\u7ebf\u4fe1\u9053\u968f\u673a\u7684\u8d44\u6e90\u53d7\u9650\u5ba2\u6237\u7aef\u4e0a\u9762\u4e34\u663e\u8457\u6311\u6218", "method": "\u63d0\u51fa\u8054\u5408\u5ba2\u6237\u7aef\u526a\u679d\u548c\u5e26\u5bbd\u5206\u914d\uff08JCPBA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u526a\u679d\u7387\u548c\u5e26\u5bbd\u5206\u914d\u6765\u6700\u5c0f\u5316\u5fae\u8c03\u5ef6\u8fdf\uff0c\u4f7f\u7528\u5757\u5750\u6807\u4e0b\u964d\u6cd5\u6c42\u89e3\u4f18\u5316\u95ee\u9898", "result": "\u5728Yahoo Answers\u548cGSM8K\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u663e\u8457\u51cf\u5c11\u4e86\u5fae\u8c03\u65f6\u95f4\uff0c\u4ee5\u66f4\u4f4e\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u83b7\u5f97\u4e86\u76f8\u7b49\u6216\u66f4\u4f4e\u7684\u6d4b\u8bd5\u635f\u5931", "conclusion": "JCPBA\u6846\u67b6\u80fd\u6709\u6548\u63d0\u9ad8\u8054\u90a6LLMs\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5fae\u8c03\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u8d44\u6e90\u53d7\u9650\u5ba2\u6237\u7aef\u7684\u6311\u6218"}}
{"id": "2602.00047", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00047", "abs": "https://arxiv.org/abs/2602.00047", "authors": ["Laha Ale", "Hu Luo", "Mingsheng Cao", "Shichao Li", "Huanlai Xing", "Haifeng Sun"], "title": "Lightweight Edge Learning via Dataset Pruning", "comment": "11 pages, 10 figures", "summary": "Edge learning facilitates ubiquitous intelligence by enabling model training and adaptation directly on data-generating devices, thereby mitigating privacy risks and communication latency. However, the high computational and energy overhead of on-device training hinders its deployment on battery-powered mobile systems with strict thermal and memory budgets. While prior research has extensively optimized model architectures for efficient inference, the training phase remains bottlenecked by the processing of massive, often redundant, local datasets. In this work, we propose a data-centric optimization framework that leverages dataset pruning to achieve resource-efficient edge learning. Unlike standard methods that process all available data, our approach constructs compact, highly informative training subsets via a lightweight, on-device importance evaluation. Specifically, we utilize average loss statistics derived from a truncated warm-up phase to rank sample importance, deterministically retaining only the most critical data points under a dynamic pruning ratio. This mechanism is model-agnostic and operates locally without inter-device communication. Extensive experiments on standard image classification benchmarks demonstrate that our framework achieves a near-linear reduction in training latency and energy consumption proportional to the pruning ratio, with negligible degradation in model accuracy. These results validate dataset pruning as a vital, complementary paradigm for enhancing the sustainability and scalability of learning on resource-constrained mobile edge devices.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u96c6\u526a\u679d\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u7d27\u51d1\u3001\u9ad8\u4fe1\u606f\u91cf\u7684\u8bad\u7ec3\u5b50\u96c6\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u5ef6\u8fdf\u548c\u80fd\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u8fb9\u7f18\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u9690\u79c1\u548c\u964d\u4f4e\u901a\u4fe1\u5ef6\u8fdf\uff0c\u4f46\u5728\u7535\u6c60\u4f9b\u7535\u7684\u79fb\u52a8\u7cfb\u7edf\u4e0a\uff0c\u9ad8\u8ba1\u7b97\u548c\u80fd\u8017\u9650\u5236\u4e86\u90e8\u7f72\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f18\u5316\u6a21\u578b\u67b6\u6784\u8fdb\u884c\u9ad8\u6548\u63a8\u7406\uff0c\u4f46\u8bad\u7ec3\u9636\u6bb5\u4ecd\u53d7\u5927\u91cf\u5197\u4f59\u672c\u5730\u6570\u636e\u5904\u7406\u7684\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u6570\u636e\u4e2d\u5fc3\u5316\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528\u6570\u636e\u96c6\u526a\u679d\u5b9e\u73b0\u8d44\u6e90\u9ad8\u6548\u7684\u8fb9\u7f18\u5b66\u4e60\u3002\u901a\u8fc7\u622a\u65ad\u9884\u70ed\u9636\u6bb5\u5f97\u5230\u7684\u5e73\u5747\u635f\u5931\u7edf\u8ba1\u6765\u8bc4\u4f30\u6837\u672c\u91cd\u8981\u6027\uff0c\u6309\u52a8\u6001\u526a\u679d\u6bd4\u4f8b\u786e\u5b9a\u6027\u5730\u4fdd\u7559\u6700\u5173\u952e\u6570\u636e\u70b9\u3002\u8be5\u65b9\u6cd5\u4e0e\u6a21\u578b\u65e0\u5173\uff0c\u65e0\u9700\u8bbe\u5907\u95f4\u901a\u4fe1\u3002", "result": "\u5728\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u4e0e\u526a\u679d\u6bd4\u4f8b\u6210\u6bd4\u4f8b\u7684\u8fd1\u4e4e\u7ebf\u6027\u7684\u8bad\u7ec3\u5ef6\u8fdf\u548c\u80fd\u8017\u964d\u4f4e\uff0c\u6a21\u578b\u7cbe\u5ea6\u4e0b\u964d\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u6570\u636e\u96c6\u526a\u679d\u662f\u589e\u5f3a\u8d44\u6e90\u53d7\u9650\u79fb\u52a8\u8fb9\u7f18\u8bbe\u5907\u5b66\u4e60\u53ef\u6301\u7eed\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u91cd\u8981\u8865\u5145\u8303\u5f0f\uff0c\u4e3a\u8fb9\u7f18\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2602.02056", "categories": ["cs.AR", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02056", "abs": "https://arxiv.org/abs/2602.02056", "authors": ["Duc Hoang", "Aarush Gupta", "Philip Harris"], "title": "Ultrafast On-chip Online Learning via Spline Locality in Kolmogorov-Arnold Networks", "comment": null, "summary": "Ultrafast online learning is essential for high-frequency systems, such as controls for quantum computing and nuclear fusion, where adaptation must occur on sub-microsecond timescales. Meeting these requirements demands low-latency, fixed-precision computation under strict memory constraints, a regime in which conventional Multi-Layer Perceptrons (MLPs) are both inefficient and numerically unstable. We identify key properties of Kolmogorov-Arnold Networks (KANs) that align with these constraints. Specifically, we show that: (i) KAN updates exploiting B-spline locality are sparse, enabling superior on-chip resource scaling, and (ii) KANs are inherently robust to fixed-point quantization. By implementing fixed-point online training on Field-Programmable Gate Arrays (FPGAs), a representative platform for on-chip computation, we demonstrate that KAN-based online learners are significantly more efficient and expressive than MLPs across a range of low-latency and resource-constrained tasks. To our knowledge, this work is the first to demonstrate model-free online learning at sub-microsecond latencies.", "AI": {"tldr": "KANs\u5728FPGA\u4e0a\u5b9e\u73b0\u4e9a\u5fae\u79d2\u7ea7\u5728\u7ebf\u5b66\u4e60\uff0c\u6bd4MLPs\u66f4\u9ad8\u6548\u7a33\u5b9a\uff0c\u9002\u7528\u4e8e\u91cf\u5b50\u8ba1\u7b97\u7b49\u9ad8\u9891\u7cfb\u7edf", "motivation": "\u9ad8\u9891\u7cfb\u7edf\uff08\u5982\u91cf\u5b50\u8ba1\u7b97\u3001\u6838\u805a\u53d8\u63a7\u5236\uff09\u9700\u8981\u4e9a\u5fae\u79d2\u7ea7\u7684\u5728\u7ebf\u5b66\u4e60\u80fd\u529b\uff0c\u4f20\u7edfMLPs\u5728\u4f4e\u5ef6\u8fdf\u3001\u56fa\u5b9a\u7cbe\u5ea6\u8ba1\u7b97\u548c\u5185\u5b58\u9650\u5236\u4e0b\u6548\u7387\u4f4e\u4e14\u6570\u503c\u4e0d\u7a33\u5b9a", "method": "\u5229\u7528KANs\u7684B\u6837\u6761\u5c40\u90e8\u6027\u5b9e\u73b0\u7a00\u758f\u66f4\u65b0\uff0c\u91c7\u7528\u56fa\u5b9a\u70b9\u91cf\u5316\uff0c\u5728FPGA\u5e73\u53f0\u4e0a\u5b9e\u73b0\u56fa\u5b9a\u70b9\u5728\u7ebf\u8bad\u7ec3", "result": "KANs\u5728\u4f4e\u5ef6\u8fdf\u548c\u8d44\u6e90\u53d7\u9650\u4efb\u52a1\u4e2d\u6bd4MLPs\u66f4\u9ad8\u6548\u548c\u8868\u8fbe\u80fd\u529b\u5f3a\uff0c\u9996\u6b21\u5b9e\u73b0\u4e9a\u5fae\u79d2\u7ea7\u65e0\u6a21\u578b\u5728\u7ebf\u5b66\u4e60", "conclusion": "KANs\u5728\u9ad8\u9891\u7cfb\u7edf\u7684\u5728\u7ebf\u5b66\u4e60\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5176\u7a00\u758f\u66f4\u65b0\u7279\u6027\u548c\u56fa\u5b9a\u70b9\u91cf\u5316\u9c81\u68d2\u6027\u4f7f\u5176\u9002\u5408\u786c\u4ef6\u5b9e\u73b0"}}
{"id": "2602.01404", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.01404", "abs": "https://arxiv.org/abs/2602.01404", "authors": ["Zhouzi Li", "Cindy Zhu", "Arpan Mukhopadhyay", "Mor Harchol-Balter", "Benjamin Berg"], "title": "BOA Constrictor: Squeezing Performance out of GPUs in the Cloud via Budget-Optimal Allocation", "comment": null, "summary": "The past decade has seen a dramatic increase in demand for GPUs to train Machine Learning (ML) models. Because it is prohibitively expensive for most organizations to build and maintain a large GPU cluster, organizations instead choose to rent GPUs from cloud providers. The customer is responsible for devising a policy for (i) deciding how many GPUs to rent at every moment in time to process a stream of ML training jobs and (ii) allocating the rented GPUs among the currently active jobs in the system. Because ML training jobs can be parallelized across different numbers of GPUs, the customer generally has many options for how many GPUs to use for each job. Allocating more GPUs to a single training job will cause the job to complete more quickly. However, the customer pays for each GPU-hour they use, and a training job receives a diminishing marginal benefit from running on additional GPUs. Hence, allocating too many GPUs to a single training job can dramatically increase the overall cost that the customer pays to the cloud provider. This gives rise to a cost-performance tradeoff that customers must balance when running training jobs in the cloud.\n  To balance the cost-performance tradeoff, we develop BOA Constrictor, a new scheduler for ML training jobs which uses a Budget-Optimal Allocation (BOA) policy to squeeze the highest level of performance out of a cloud-deployed GPU cluster given a fixed budget constraint. We explicitly formulate the problem as a budget-constrained scheduling problem and derive the BOA policy which minimizes the average job completion time (JCT) of a stream of arriving jobs subject to the user's budget. For a given budget level, we demonstrate that BOA Constrictor can reduce average JCT by 1.6 times in small-scale implementation experiments and by 2 times in detailed, large-scale simulations compared to state-of-the-art heuristic based schedulers.", "AI": {"tldr": "BOA Constrictor\u662f\u4e00\u79cd\u9488\u5bf9\u4e91\u7aefGPU\u96c6\u7fa4\u7684\u9884\u7b97\u4f18\u5316\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u9884\u7b97\u6700\u4f18\u5206\u914d\u7b56\u7565\u5728\u56fa\u5b9a\u9884\u7b97\u7ea6\u675f\u4e0b\u6700\u5927\u5316ML\u8bad\u7ec3\u4f5c\u4e1a\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u8c03\u5ea6\u5668\u53ef\u5c06\u5e73\u5747\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u51cf\u5c111.6-2\u500d\u3002", "motivation": "\u968f\u7740ML\u8bad\u7ec3\u5bf9GPU\u9700\u6c42\u6fc0\u589e\uff0c\u7ec4\u7ec7\u901a\u5e38\u4ece\u4e91\u63d0\u4f9b\u5546\u79df\u7528GPU\u3002\u7528\u6237\u9700\u8981\u5e73\u8861\u6210\u672c\u4e0e\u6027\u80fd\uff1a\u5206\u914d\u66f4\u591aGPU\u53ef\u4ee5\u52a0\u901f\u4f5c\u4e1a\u5b8c\u6210\uff0c\u4f46GPU\u5c0f\u65f6\u6210\u672c\u589e\u52a0\u4e14\u5b58\u5728\u8fb9\u9645\u6548\u76ca\u9012\u51cf\u3002\u8fd9\u4ea7\u751f\u4e86\u6210\u672c-\u6027\u80fd\u6743\u8861\u95ee\u9898\uff0c\u9700\u8981\u6709\u6548\u8c03\u5ea6\u7b56\u7565\u3002", "method": "\u5f00\u53d1BOA Constrictor\u8c03\u5ea6\u5668\uff0c\u91c7\u7528\u9884\u7b97\u6700\u4f18\u5206\u914d(BOA)\u7b56\u7565\u3002\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u9884\u7b97\u7ea6\u675f\u8c03\u5ea6\u95ee\u9898\uff0c\u63a8\u5bfc\u51fa\u5728\u7528\u6237\u9884\u7b97\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u5e73\u5747\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u7684BOA\u7b56\u7565\u3002", "result": "\u5728\u7ed9\u5b9a\u9884\u7b97\u6c34\u5e73\u4e0b\uff0cBOA Constrictor\u5728\u5c0f\u89c4\u6a21\u5b9e\u73b0\u5b9e\u9a8c\u4e2d\u53ef\u5c06\u5e73\u5747\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u51cf\u5c111.6\u500d\uff0c\u5728\u8be6\u7ec6\u7684\u5927\u89c4\u6a21\u6a21\u62df\u4e2d\u53ef\u51cf\u5c112\u500d\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u8c03\u5ea6\u5668\u3002", "conclusion": "BOA Constrictor\u901a\u8fc7\u9884\u7b97\u6700\u4f18\u5206\u914d\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u4e91\u7aefML\u8bad\u7ec3\u4f5c\u4e1a\u7684\u6210\u672c-\u6027\u80fd\u6743\u8861\u95ee\u9898\uff0c\u5728\u56fa\u5b9a\u9884\u7b97\u7ea6\u675f\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u8c03\u5ea6\u6027\u80fd\u3002"}}
{"id": "2602.00051", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00051", "abs": "https://arxiv.org/abs/2602.00051", "authors": ["Takato Yasuno"], "title": "Distributional Reinforcement Learning for Condition-Based Maintenance of Multi-Pump Equipment", "comment": "15 pages, 15 figures", "summary": "Condition-Based Maintenance (CBM) signifies a paradigm shift from reactive to proactive equipment management strategies in modern industrial systems. Conventional time-based maintenance schedules frequently engender superfluous expenditures and unanticipated equipment failures. In contrast, CBM utilizes real-time equipment condition data to enhance maintenance timing and optimize resource allocation. The present paper proposes a novel distributional reinforcement learning approach for multi-equipment CBM using Quantile Regression Deep Q-Networks (QR-DQN) with aging factor integration. The methodology employed in this study encompasses the concurrent administration of multiple pump units through three strategic scenarios. The implementation of safety-first, balanced, and cost-efficient approaches is imperative. Comprehensive experimental validation over 3,000 training episodes demonstrates significant performance improvements across all strategies. The Safety-First strategy demonstrates superior cost efficiency, with a return on investment (ROI) of 3.91, yielding 152\\% better performance than alternatives while requiring only 31\\% higher investment. The system exhibits 95.66\\% operational stability and immediate applicability to industrial environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u4f4d\u6570\u56de\u5f52\u6df1\u5ea6Q\u7f51\u7edc\uff08QR-DQN\uff09\u5e76\u6574\u5408\u8001\u5316\u56e0\u5b50\u7684\u5206\u5e03\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u8bbe\u5907\u72b6\u6001\u7ef4\u62a4\uff0c\u901a\u8fc7\u4e09\u79cd\u7b56\u7565\u573a\u666f\u9a8c\u8bc1\u4e86\u5b89\u5168\u4f18\u5148\u7b56\u7565\u7684\u6210\u672c\u6548\u76ca\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u65f6\u95f4\u7684\u7ef4\u62a4\u7b56\u7565\u5e38\u5bfc\u81f4\u4e0d\u5fc5\u8981\u7684\u5f00\u652f\u548c\u610f\u5916\u8bbe\u5907\u6545\u969c\uff0c\u800c\u72b6\u6001\u7ef4\u62a4\uff08CBM\uff09\u5229\u7528\u5b9e\u65f6\u8bbe\u5907\u72b6\u6001\u6570\u636e\u53ef\u4ee5\u4f18\u5316\u7ef4\u62a4\u65f6\u673a\u548c\u8d44\u6e90\u914d\u7f6e\uff0c\u4f46\u9700\u8981\u66f4\u667a\u80fd\u7684\u51b3\u7b56\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5206\u4f4d\u6570\u56de\u5f52\u6df1\u5ea6Q\u7f51\u7edc\uff08QR-DQN\uff09\u7ed3\u5408\u8001\u5316\u56e0\u5b50\u7684\u5206\u5e03\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u79cd\u7b56\u7565\u573a\u666f\uff08\u5b89\u5168\u4f18\u5148\u3001\u5e73\u8861\u3001\u6210\u672c\u6548\u76ca\uff09\u5bf9\u591a\u4e2a\u6cf5\u5355\u5143\u8fdb\u884c\u5e76\u53d1\u7ba1\u7406\u3002", "result": "\u7ecf\u8fc73000\u6b21\u8bad\u7ec3\u9a8c\u8bc1\uff0c\u5b89\u5168\u4f18\u5148\u7b56\u7565\u8868\u73b0\u51fa\u6700\u4f73\u6210\u672c\u6548\u76ca\uff0c\u6295\u8d44\u56de\u62a5\u73873.91\uff0c\u6027\u80fd\u6bd4\u66ff\u4ee3\u65b9\u6848\u63d0\u9ad8152%\uff0c\u4ec5\u9700\u589e\u52a031%\u6295\u8d44\uff0c\u7cfb\u7edf\u8fd0\u884c\u7a33\u5b9a\u6027\u8fbe95.66%\uff0c\u5177\u5907\u5de5\u4e1a\u73af\u5883\u5373\u65f6\u5e94\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684QR-DQN\u4e0e\u8001\u5316\u56e0\u5b50\u6574\u5408\u65b9\u6cd5\u5728\u591a\u8bbe\u5907\u72b6\u6001\u7ef4\u62a4\u4e2d\u6709\u6548\uff0c\u5b89\u5168\u4f18\u5148\u7b56\u7565\u5728\u6210\u672c\u6548\u76ca\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f18\uff0c\u4e3a\u5de5\u4e1a\u73af\u5883\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u667a\u80fd\u7ef4\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02119", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.02119", "abs": "https://arxiv.org/abs/2602.02119", "authors": ["Elio Vinciguerra", "Enrico Russo", "Giuseppe Ascia", "Maurizio Palesi"], "title": "CHAOS: Controlled Hardware fAult injectOr System for gem5", "comment": null, "summary": "Fault injectors are essential tools for evaluating the reliability and resilience of computing systems. They enable the simulation of hardware and software faults to analyze system behavior under error conditions and assess its ability to operate correctly despite disruptions. Such analysis is critical for identifying vulnerabilities and improving system robustness. CHAOS is a modular, open-source, and fully configurable fault injection framework designed for the gem5 simulator. It facilitates precise and systematic fault injection across multiple architectural levels, supporting comprehensive evaluations of fault tolerance mechanisms and resilience strategies. Its high configurability and seamless integration with gem5 allow researchers to explore a wide range of fault models and complex scenarios, making CHAOS a valuable tool for advancing research in dependable and high-performance computing systems.", "AI": {"tldr": "CHAOS\u662f\u4e00\u4e2a\u4e3agem5\u6a21\u62df\u5668\u8bbe\u8ba1\u7684\u6a21\u5757\u5316\u3001\u5f00\u6e90\u3001\u53ef\u914d\u7f6e\u7684\u6545\u969c\u6ce8\u5165\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u8ba1\u7b97\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u5f39\u6027\u3002", "motivation": "\u6545\u969c\u6ce8\u5165\u5668\u5bf9\u4e8e\u8bc4\u4f30\u8ba1\u7b97\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u5f39\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5b83\u4eec\u80fd\u591f\u6a21\u62df\u786c\u4ef6\u548c\u8f6f\u4ef6\u6545\u969c\u6765\u5206\u6790\u7cfb\u7edf\u5728\u9519\u8bef\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u5e72\u6270\u4e0b\u6b63\u786e\u8fd0\u884c\u7684\u80fd\u529b\u3002\u8fd9\u79cd\u5206\u6790\u5bf9\u4e8e\u8bc6\u522b\u7cfb\u7edf\u6f0f\u6d1e\u548c\u63d0\u9ad8\u7cfb\u7edf\u9c81\u68d2\u6027\u975e\u5e38\u5173\u952e\u3002", "method": "CHAOS\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u5f00\u6e90\u3001\u5b8c\u5168\u53ef\u914d\u7f6e\u7684\u6545\u969c\u6ce8\u5165\u6846\u67b6\uff0c\u4e13\u4e3agem5\u6a21\u62df\u5668\u8bbe\u8ba1\u3002\u5b83\u652f\u6301\u5728\u591a\u4e2a\u67b6\u6784\u7ea7\u522b\u8fdb\u884c\u7cbe\u786e\u548c\u7cfb\u7edf\u6027\u7684\u6545\u969c\u6ce8\u5165\uff0c\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u5bb9\u9519\u673a\u5236\u548c\u5f39\u6027\u7b56\u7565\u3002\u5176\u9ad8\u53ef\u914d\u7f6e\u6027\u548c\u4e0egem5\u7684\u65e0\u7f1d\u96c6\u6210\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u63a2\u7d22\u5e7f\u6cdb\u7684\u6545\u969c\u6a21\u578b\u548c\u590d\u6742\u573a\u666f\u3002", "result": "CHAOS\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u8fdb\u884c\u5168\u9762\u7684\u6545\u969c\u5bb9\u5fcd\u673a\u5236\u8bc4\u4f30\u548c\u5f39\u6027\u7b56\u7565\u5206\u6790\uff0c\u652f\u6301\u63a2\u7d22\u5404\u79cd\u6545\u969c\u6a21\u578b\u548c\u590d\u6742\u573a\u666f\u3002", "conclusion": "CHAOS\u4f5c\u4e3a\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u80fd\u591f\u63a8\u52a8\u53ef\u9760\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u901a\u8fc7\u5176\u9ad8\u53ef\u914d\u7f6e\u6027\u548c\u4e0egem5\u7684\u96c6\u6210\uff0c\u4e3a\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u5f39\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u652f\u6301\u3002"}}
{"id": "2602.01411", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.01411", "abs": "https://arxiv.org/abs/2602.01411", "authors": ["Zhouzi Li", "Mor Harchol-Balter", "Benjamin Berg"], "title": "Mean field optimal Core Allocation across Malleable jobs", "comment": null, "summary": "Modern data centers and cloud computing clusters are increasingly running workloads composed of malleable jobs. A malleable job can be parallelized across any number of cores, yet the job typically exhibits diminishing marginal returns for each additional core on which it runs. This can be seen in the concavity of a job's speedup function, which describes the job's processing speed as a function of the number of cores on which it runs.\n  Given the prevalence of malleable jobs, several theoretical works have posed the problem of how to allocate a fixed number of cores across a stream of arriving malleable jobs so as to minimize the mean response time across jobs. We refer to this as the Core Allocation to Malleable jobs (CAM) problem. We solve the CAM problem under a highly general setting, allowing for multiple job classes, each with an arbitrary concave speedup function and holding costs (weight). Furthermore, we allow for generally distributed inter-arrival times and job sizes.\n  We analyze the CAM problem in the mean field asymptotic regime and derive two distinct mean field optimal policies, FW-CAM and WHAM. FW-CAM is interesting because it demonstrates a new intuition: in the mean field regime, job sizes are not relevant in finding an optimal policy. WHAM (Whittle Allocation for Malleable jobs) is interesting because it is asymptotically optimal and also serves as a good heuristic even outside of the asymptotic regime. Notably, none of the policies previously proposed in the literature are mean field optimal when jobs may follow different speedup functions.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u9488\u5bf9\u53ef\u5851\u4f5c\u4e1a\u7684\u6838\u5fc3\u5206\u914d\u7b56\u7565FW-CAM\u548cWHAM\uff0c\u5728\u5e73\u5747\u573a\u6e10\u8fd1\u6761\u4ef6\u4e0b\u5b9e\u73b0\u6700\u4f18\u6027\u80fd", "motivation": "\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u548c\u4e91\u8ba1\u7b97\u96c6\u7fa4\u4e2d\u53ef\u5851\u4f5c\u4e1a\u65e5\u76ca\u666e\u904d\uff0c\u8fd9\u4e9b\u4f5c\u4e1a\u53ef\u4ee5\u5728\u4efb\u610f\u6570\u91cf\u6838\u5fc3\u4e0a\u5e76\u884c\u8fd0\u884c\u4f46\u5b58\u5728\u8fb9\u9645\u6536\u76ca\u9012\u51cf\u3002\u73b0\u6709\u7406\u8bba\u5de5\u4f5c\u63d0\u51fa\u4e86\u5982\u4f55\u5728\u56fa\u5b9a\u6838\u5fc3\u6570\u4e0b\u5206\u914d\u8d44\u6e90\u4ee5\u6700\u5c0f\u5316\u4f5c\u4e1a\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u7684\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5728\u9ad8\u5ea6\u901a\u7528\u8bbe\u7f6e\u4e0b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5728\u5e73\u5747\u573a\u6e10\u8fd1\u673a\u5236\u4e0b\u5206\u6790\u6838\u5fc3\u5206\u914d\u95ee\u9898\uff0c\u63a8\u5bfc\u51fa\u4e24\u79cd\u4e0d\u540c\u7684\u5e73\u5747\u573a\u6700\u4f18\u7b56\u7565\uff1aFW-CAM\u548cWHAM\u3002FW-CAM\u57fa\u4e8e\u65b0\u76f4\u89c9\uff0cWHAM\u91c7\u7528Whittle\u5206\u914d\u65b9\u6cd5\uff0c\u4e24\u8005\u90fd\u80fd\u5904\u7406\u591a\u4f5c\u4e1a\u7c7b\u522b\u3001\u4efb\u610f\u51f9\u52a0\u901f\u51fd\u6570\u548c\u4e00\u822c\u5206\u5e03\u3002", "result": "FW-CAM\u7b56\u7565\u8868\u660e\u5728\u5e73\u5747\u573a\u673a\u5236\u4e2d\u4f5c\u4e1a\u5927\u5c0f\u5bf9\u6700\u4f18\u7b56\u7565\u4e0d\u76f8\u5173\uff1bWHAM\u7b56\u7565\u5728\u6e10\u8fd1\u6761\u4ef6\u4e0b\u6700\u4f18\uff0c\u5728\u975e\u6e10\u8fd1\u6761\u4ef6\u4e0b\u4e5f\u80fd\u4f5c\u4e3a\u826f\u597d\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u73b0\u6709\u6587\u732e\u4e2d\u7684\u7b56\u7565\u5728\u591a\u52a0\u901f\u51fd\u6570\u60c5\u51b5\u4e0b\u90fd\u4e0d\u662f\u5e73\u5747\u573a\u6700\u4f18\u7684\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u5ea6\u901a\u7528\u8bbe\u7f6e\u4e0b\u7684\u53ef\u5851\u4f5c\u4e1a\u6838\u5fc3\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5e73\u5747\u573a\u6700\u4f18\u7b56\u7565\uff0c\u4e3a\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u548c\u4e91\u96c6\u7fa4\u7684\u8d44\u6e90\u8c03\u5ea6\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2602.00059", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00059", "abs": "https://arxiv.org/abs/2602.00059", "authors": ["Zizheng Zhang", "Yuyang Liao", "Chen Chen", "Jian He", "Dun Wu", "Qianjin Yu", "Yanqin Gao", "Jin Yang", "Kailai Zhang", "Eng Siong Chng", "Xionghu Zhong"], "title": "TextBFGS: Quasi-Newton Optimization for Discrete Executable Text via Gradient-Operator Retrieval", "comment": null, "summary": "Optimizing discrete executable text such as prompts and code has recently been framed as a gradient-based process, effectively translating backpropagation concepts to the semantic space. However, existing methods predominantly operate as first-order optimizers akin to Stochastic Gradient Descent, which are suffering from slow convergence and instability because they neglect the semantic curvature of the optimization landscape. To bridge this gap, we introduce TextBFGS, a second-order framework to implement a Quasi-Newton optimization method for discrete text. Unlike traditional memory-based approaches that retrieve similar textual instances, TextBFGS approximates the inverse Hessian matrix by retrieving Gradient-Operators from the memory of pre-learned successful trajectories. Specifically, given a textual gradient feedback, TextBFGS identifies historical correction patterns from the optimization knowledge base and tries to apply these abstract operators to the current variable. This mechanism enables a One-Pass Update, combining feedback generation and second-order correction into a single inference step. Empirical evaluations on code optimization across diverse domains (e.g., HumanEval, MBPP) demonstrate that TextBFGS significantly outperforms first-order baselines. It achieves superior pass rates with fewer model calls and exhibits strong cross-task transferability, thus establishes a mathematically grounded paradigm for efficient, memory-aware text optimization.", "AI": {"tldr": "TextBFGS\uff1a\u4e00\u79cd\u7528\u4e8e\u79bb\u6563\u6587\u672c\uff08\u5982\u63d0\u793a\u548c\u4ee3\u7801\uff09\u7684\u4e8c\u9636\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u68af\u5ea6\u7b97\u5b50\u5b9e\u73b0\u62df\u725b\u987f\u6cd5\uff0c\u76f8\u6bd4\u4e00\u9636\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027", "motivation": "\u73b0\u6709\u79bb\u6563\u6587\u672c\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u4e00\u9636\u4f18\u5316\uff08\u7c7b\u4f3cSGD\uff09\uff0c\u6536\u655b\u6162\u4e14\u4e0d\u7a33\u5b9a\uff0c\u56e0\u4e3a\u5b83\u4eec\u5ffd\u7565\u4e86\u4f18\u5316\u666f\u89c2\u7684\u8bed\u4e49\u66f2\u7387\u3002\u9700\u8981\u5f15\u5165\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\u6765\u63d0\u5347\u6548\u7387", "method": "TextBFGS\u901a\u8fc7\u68c0\u7d22\u9884\u5b66\u4e60\u6210\u529f\u8f68\u8ff9\u4e2d\u7684\u68af\u5ea6\u7b97\u5b50\u6765\u8fd1\u4f3c\u9006Hessian\u77e9\u9635\uff0c\u5b9e\u73b0\u62df\u725b\u987f\u4f18\u5316\u3002\u7ed9\u5b9a\u6587\u672c\u68af\u5ea6\u53cd\u9988\uff0c\u7cfb\u7edf\u4ece\u4f18\u5316\u77e5\u8bc6\u5e93\u8bc6\u522b\u5386\u53f2\u4fee\u6b63\u6a21\u5f0f\uff0c\u5e76\u5c06\u8fd9\u4e9b\u62bd\u8c61\u7b97\u5b50\u5e94\u7528\u4e8e\u5f53\u524d\u53d8\u91cf\uff0c\u5b9e\u73b0\u5355\u6b21\u66f4\u65b0", "result": "\u5728\u4ee3\u7801\u4f18\u5316\u4efb\u52a1\uff08HumanEval\u3001MBPP\u7b49\uff09\u4e0a\uff0cTextBFGS\u663e\u8457\u4f18\u4e8e\u4e00\u9636\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4ee5\u66f4\u5c11\u7684\u6a21\u578b\u8c03\u7528\u83b7\u5f97\u66f4\u9ad8\u7684\u901a\u8fc7\u7387\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u4efb\u52a1\u8fc1\u79fb\u80fd\u529b", "conclusion": "TextBFGS\u4e3a\u9ad8\u6548\u3001\u5185\u5b58\u611f\u77e5\u7684\u6587\u672c\u4f18\u5316\u5efa\u7acb\u4e86\u6570\u5b66\u57fa\u7840\u8303\u5f0f\uff0c\u901a\u8fc7\u4e8c\u9636\u4f18\u5316\u6846\u67b6\u89e3\u51b3\u4e86\u79bb\u6563\u6587\u672c\u4f18\u5316\u4e2d\u7684\u6536\u655b\u6162\u548c\u4e0d\u7a33\u5b9a\u95ee\u9898"}}
{"id": "2602.01798", "categories": ["cs.DC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01798", "abs": "https://arxiv.org/abs/2602.01798", "authors": ["Leonardo Pelonero", "Fabio Vitello", "Eva Sciacca", "Mauro Imbrosciano", "Salvatore Scavo", "Ugo Becciani"], "title": "Developing a Portable Solution for Post-Event Analysis Pipelines", "comment": "Preprint of IWSG 2025 Conference Proceeding", "summary": "In recent years, the monitoring and study of natural hazards have gained significant attention, particularly due to climate change, which exacerbates incidents like floods, droughts, storm surges, and landslides. Together with the constant risk of earthquakes, these climate-induced events highlight the critical necessity for enhanced risk assessment and mitigation strategies in susceptible areas such as Italy.\n  In this work, we present a Science Gateway framework for the development of portable and fully automated post-event analysis pipelines integrating Photogrammetry techniques, Data Visualization and Artificial Intelligence technologies, applied on aerial images, to assess extreme natural events and evaluate their impact on risk-exposed assets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u79d1\u5b66\u7f51\u5173\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u53d1\u4fbf\u643a\u5f0f\u3001\u5168\u81ea\u52a8\u7684\u707e\u540e\u5206\u6790\u6d41\u7a0b\uff0c\u7ed3\u5408\u6444\u5f71\u6d4b\u91cf\u3001\u6570\u636e\u53ef\u89c6\u5316\u548c\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u901a\u8fc7\u822a\u7a7a\u5f71\u50cf\u8bc4\u4f30\u6781\u7aef\u81ea\u7136\u707e\u5bb3\u53ca\u5176\u5bf9\u98ce\u9669\u66b4\u9732\u8d44\u4ea7\u7684\u5f71\u54cd\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u52a0\u5267\u4e86\u6d2a\u6c34\u3001\u5e72\u65f1\u3001\u98ce\u66b4\u6f6e\u548c\u6ed1\u5761\u7b49\u81ea\u7136\u707e\u5bb3\uff0c\u52a0\u4e0a\u5730\u9707\u7684\u6301\u7eed\u98ce\u9669\uff0c\u51f8\u663e\u4e86\u5728\u610f\u5927\u5229\u7b49\u6613\u53d7\u5f71\u54cd\u5730\u533a\u52a0\u5f3a\u98ce\u9669\u8bc4\u4f30\u548c\u7f13\u89e3\u7b56\u7565\u7684\u8feb\u5207\u9700\u8981\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u79d1\u5b66\u7f51\u5173\u6846\u67b6\uff0c\u6574\u5408\u6444\u5f71\u6d4b\u91cf\u6280\u672f\u3001\u6570\u636e\u53ef\u89c6\u5316\u548c\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u5e94\u7528\u4e8e\u822a\u7a7a\u5f71\u50cf\uff0c\u521b\u5efa\u4fbf\u643a\u5f0f\u3001\u5168\u81ea\u52a8\u7684\u707e\u540e\u5206\u6790\u6d41\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u591a\u79cd\u6280\u672f\u7684\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u8bc4\u4f30\u6781\u7aef\u81ea\u7136\u707e\u5bb3\u4e8b\u4ef6\uff0c\u5e76\u8bc4\u4f30\u5176\u5bf9\u98ce\u9669\u66b4\u9732\u8d44\u4ea7\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u79d1\u5b66\u7f51\u5173\u6846\u67b6\u4e3a\u81ea\u7136\u707e\u5bb3\u7684\u76d1\u6d4b\u548c\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u98ce\u9669\u66b4\u9732\u5730\u533a\u7684\u707e\u5bb3\u8bc4\u4f30\u548c\u7f13\u89e3\u80fd\u529b\u3002"}}
{"id": "2602.00062", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00062", "abs": "https://arxiv.org/abs/2602.00062", "authors": ["Ming-Yao Ho", "Cheng-Kai Wang", "You-Teng Lin", "Hung-Hsuan Chen"], "title": "SCPL: Enhancing Neural Network Training Throughput with Decoupled Local Losses and Model Parallelism", "comment": null, "summary": "Adopting large-scale AI models in enterprise information systems is often hindered by high training costs and long development cycles, posing a significant managerial challenge. The standard end-to-end backpropagation (BP) algorithm is a primary driver of modern AI, but it is also the source of inefficiency in training deep networks. This paper introduces a new training methodology, Supervised Contrastive Parallel Learning (SCPL), that addresses this issue by decoupling BP and transforming a long gradient flow into multiple short ones. This design enables the simultaneous computation of parameter gradients in different layers, achieving superior model parallelism and enhancing training throughput. Detailed experiments are presented to demonstrate the efficiency and effectiveness of our model compared to BP, Early Exit, GPipe, and Associated Learning (AL), a state-of-the-art method for decoupling backpropagation. By mitigating a fundamental performance bottleneck, SCPL provides a practical pathway for organizations to develop and deploy advanced information systems more cost-effectively and with greater agility. The experimental code is released for reproducibility. https://github.com/minyaho/scpl/", "AI": {"tldr": "SCPL\u662f\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u53cd\u5411\u4f20\u64ad\u5c06\u957f\u68af\u5ea6\u6d41\u5206\u89e3\u4e3a\u591a\u4e2a\u77ed\u68af\u5ea6\u6d41\uff0c\u5b9e\u73b0\u5c42\u95f4\u5e76\u884c\u8ba1\u7b97\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u4f01\u4e1a\u4fe1\u606f\u7cfb\u7edf\u91c7\u7528\u5927\u89c4\u6a21AI\u6a21\u578b\u9762\u4e34\u9ad8\u8bad\u7ec3\u6210\u672c\u548c\u957f\u5f00\u53d1\u5468\u671f\u7684\u6311\u6218\uff0c\u6807\u51c6\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u662f\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\u7684\u4e3b\u8981\u539f\u56e0\u3002", "method": "\u63d0\u51fa\u76d1\u7763\u5bf9\u6bd4\u5e76\u884c\u5b66\u4e60\uff08SCPL\uff09\uff0c\u89e3\u8026\u53cd\u5411\u4f20\u64ad\uff0c\u5c06\u957f\u68af\u5ea6\u6d41\u8f6c\u6362\u4e3a\u591a\u4e2a\u77ed\u68af\u5ea6\u6d41\uff0c\u5b9e\u73b0\u4e0d\u540c\u5c42\u7684\u53c2\u6570\u68af\u5ea6\u540c\u65f6\u8ba1\u7b97\uff0c\u83b7\u5f97\u4f18\u8d8a\u7684\u6a21\u578b\u5e76\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSCPL\u76f8\u6bd4BP\u3001Early Exit\u3001GPipe\u548cAL\uff08\u89e3\u8026\u53cd\u5411\u4f20\u64ad\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff09\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u90fd\u6709\u4f18\u52bf\u3002", "conclusion": "SCPL\u901a\u8fc7\u89e3\u51b3\u57fa\u672c\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u4f01\u4e1a\u66f4\u7ecf\u6d4e\u9ad8\u6548\u5730\u5f00\u53d1\u548c\u90e8\u7f72\u5148\u8fdb\u4fe1\u606f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2602.01410", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.01410", "abs": "https://arxiv.org/abs/2602.01410", "authors": ["Yunjie Pan", "Yongyi Yang", "Hanmei Yang", "Scott Mahlke"], "title": "SNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training", "comment": "Accepted to ASPLOS 2026", "summary": "Training large language models (LLMs) efficiently while preserving model quality poses significant challenges, particularly with subbyte precision supported by state-of-the-art GPUs. Current mixed-precision training approaches either apply uniform precision to all GEMM operations or rely on heuristic-based methods that fail to generalize during training, leading to suboptimal convergence and instability. To address these challenges, this paper introduces SNIP, a fine-grained adaptive mixed-precision training framework for LLM pretraining that supports subbyte precision. SNIP periodically collects statistics on activations, gradients, and optimizer states to assess the precision loss impact on model quality. We define two key metrics: loss divergence in the forward pass, caused by quantization-induced increases in training loss, and weight divergence in the backward pass, which measures error propagation through gradients affecting model updates. These metrics guide an Integer Linear Programming (ILP) problem that systematically optimizes layerwise precision to minimize overall quality loss while meeting efficiency targets. Experiments on 1B, 3B, 7B and 70B Llama-like models demonstrate that SNIP consistently outperforms existing baselines, reducing FLOPs by up to 80% while preserving model quality across different model sizes and training phases with minimal computational overhead.", "AI": {"tldr": "SNIP\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u81ea\u9002\u5e94\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u671f\u6536\u96c6\u7edf\u8ba1\u4fe1\u606f\u5e76\u5b9a\u4e49\u524d\u5411\u635f\u5931\u53d1\u6563\u548c\u540e\u5411\u6743\u91cd\u53d1\u6563\u4e24\u4e2a\u5173\u952e\u6307\u6807\uff0c\u4f7f\u7528\u6574\u6570\u7ebf\u6027\u89c4\u5212\u4f18\u5316\u5c42\u95f4\u7cbe\u5ea6\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5f53\u524d\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u65b9\u6cd5\u8981\u4e48\u5bf9\u6240\u6709GEMM\u64cd\u4f5c\u5e94\u7528\u7edf\u4e00\u7cbe\u5ea6\uff0c\u8981\u4e48\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u6cdb\u5316\uff0c\u5bfc\u81f4\u6536\u655b\u4e0d\u7406\u60f3\u548c\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u652f\u6301\u5b50\u5b57\u8282\u7cbe\u5ea6\u3001\u81ea\u9002\u5e94\u8c03\u6574\u7cbe\u5ea6\u3001\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u8bad\u7ec3\u6846\u67b6\u3002", "method": "SNIP\u6846\u67b6\u5b9a\u671f\u6536\u96c6\u6fc0\u6d3b\u3001\u68af\u5ea6\u548c\u4f18\u5316\u5668\u72b6\u6001\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u5b9a\u4e49\u524d\u5411\u635f\u5931\u53d1\u6563\uff08\u91cf\u5316\u5f15\u8d77\u7684\u8bad\u7ec3\u635f\u5931\u589e\u52a0\uff09\u548c\u540e\u5411\u6743\u91cd\u53d1\u6563\uff08\u68af\u5ea6\u8bef\u5dee\u4f20\u64ad\u5f71\u54cd\u6a21\u578b\u66f4\u65b0\uff09\u4e24\u4e2a\u5173\u952e\u6307\u6807\uff0c\u4f7f\u7528\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7cfb\u7edf\u4f18\u5316\u5c42\u95f4\u7cbe\u5ea6\uff0c\u5728\u6ee1\u8db3\u6548\u7387\u76ee\u6807\u7684\u540c\u65f6\u6700\u5c0f\u5316\u8d28\u91cf\u635f\u5931\u3002", "result": "\u57281B\u30013B\u30017B\u548c70B Llama-like\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSNIP\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u4e0d\u540c\u6a21\u578b\u5927\u5c0f\u548c\u8bad\u7ec3\u9636\u6bb5\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5c06FLOPs\u51cf\u5c11\u9ad8\u8fbe80%\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "SNIP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7ec6\u7c92\u5ea6\u81ea\u9002\u5e94\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u7cbe\u5ea6\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u652f\u6301\u5b50\u5b57\u8282\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.01872", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01872", "abs": "https://arxiv.org/abs/2602.01872", "authors": ["Chongyang Xu", "Christoph Siebenbrunner", "Laurent Bindschaedler"], "title": "Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training", "comment": null, "summary": "Cross-partition edges dominate the cost of distributed GNN training: fetching remote features and activations per iteration overwhelms the network as graphs deepen and partition counts grow. Grappa is a distributed GNN training framework that enforces gradient-only communication: during each iteration, partitions train in isolation and exchange only gradients for the global update. To recover accuracy lost to isolation, Grappa (i) periodically repartitions to expose new neighborhoods and (ii) applies a lightweight coverage-corrected gradient aggregation inspired by importance sampling. We prove the corrected estimator is asymptotically unbiased under standard support and boundedness assumptions, and we derive a batch-level variant for compatibility with common deep-learning packages that minimizes mean-squared deviation from the ideal node-level correction. We also introduce a shrinkage version that improves stability in practice. Empirical results on real and synthetic graphs show that Grappa trains GNNs 4 times faster on average (up to 13 times) than state-of-the-art systems, achieves better accuracy especially for deeper models, and sustains training at the trillion-edge scale on commodity hardware. Grappa is model-agnostic, supports full-graph and mini-batch training, and does not rely on high-bandwidth interconnects or caching.", "AI": {"tldr": "Grappa\u662f\u4e00\u4e2a\u5206\u5e03\u5f0fGNN\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4ec5\u901a\u4fe1\u68af\u5ea6\u800c\u975e\u7279\u5f81/\u6fc0\u6d3b\u6765\u5927\u5e45\u964d\u4f4e\u7f51\u7edc\u5f00\u9500\uff0c\u4f7f\u7528\u91cd\u5206\u533a\u548c\u8986\u76d6\u6821\u6b63\u68af\u5ea6\u805a\u5408\u6765\u4fdd\u6301\u7cbe\u5ea6\uff0c\u5b9e\u73b04-13\u500d\u52a0\u901f\u5e76\u652f\u6301\u4e07\u4ebf\u8fb9\u89c4\u6a21\u8bad\u7ec3\u3002", "motivation": "\u5206\u5e03\u5f0fGNN\u8bad\u7ec3\u4e2d\uff0c\u8de8\u5206\u533a\u8fb9\u7684\u8fdc\u7a0b\u7279\u5f81\u548c\u6fc0\u6d3b\u83b7\u53d6\u6210\u672c\u8fc7\u9ad8\uff0c\u968f\u7740\u56fe\u6df1\u5ea6\u589e\u52a0\u548c\u5206\u533a\u6570\u91cf\u589e\u957f\uff0c\u7f51\u7edc\u901a\u4fe1\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\u3002", "method": "1) \u68af\u5ea6\u552f\u4e00\u901a\u4fe1\uff1a\u6bcf\u4e2a\u8fed\u4ee3\u4e2d\u5206\u533a\u72ec\u7acb\u8bad\u7ec3\uff0c\u4ec5\u4ea4\u6362\u68af\u5ea6\u8fdb\u884c\u5168\u5c40\u66f4\u65b0\uff1b2) \u5b9a\u671f\u91cd\u5206\u533a\u66b4\u9732\u65b0\u90bb\u57df\uff1b3) \u8f7b\u91cf\u7ea7\u8986\u76d6\u6821\u6b63\u68af\u5ea6\u805a\u5408\uff08\u91cd\u8981\u6027\u91c7\u6837\u542f\u53d1\uff09\uff1b4) \u6279\u5904\u7406\u7ea7\u53d8\u4f53\u517c\u5bb9\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff1b5) \u6536\u7f29\u7248\u672c\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002", "result": "\u5e73\u5747\u8bad\u7ec3\u901f\u5ea6\u6bd4\u73b0\u6709\u7cfb\u7edf\u5feb4\u500d\uff08\u6700\u9ad813\u500d\uff09\uff0c\u5bf9\u6df1\u5c42\u6a21\u578b\u7cbe\u5ea6\u66f4\u597d\uff0c\u5728\u5546\u54c1\u786c\u4ef6\u4e0a\u652f\u6301\u4e07\u4ebf\u8fb9\u89c4\u6a21\u8bad\u7ec3\uff0c\u4e0d\u4f9d\u8d56\u9ad8\u5e26\u5bbd\u4e92\u8fde\u6216\u7f13\u5b58\u3002", "conclusion": "Grappa\u901a\u8fc7\u68af\u5ea6\u552f\u4e00\u901a\u4fe1\u3001\u91cd\u5206\u533a\u548c\u6821\u6b63\u68af\u5ea6\u805a\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0fGNN\u8bad\u7ec3\u7684\u7f51\u7edc\u74f6\u9888\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u65b9\u6848\u3002"}}
{"id": "2602.00063", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00063", "abs": "https://arxiv.org/abs/2602.00063", "authors": ["Leonidas Christodoulou", "Chang Sun"], "title": "The Impact of Machine Learning Uncertainty on the Robustness of Counterfactual Explanations", "comment": null, "summary": "Counterfactual explanations are widely used to interpret machine learning predictions by identifying minimal changes to input features that would alter a model's decision. However, most existing counterfactual methods have not been tested when model and data uncertainty change, resulting in explanations that may be unstable or invalid under real-world variability. In this work, we investigate the robustness of common combinations of machine learning models and counterfactual generation algorithms in the presence of both aleatoric and epistemic uncertainty. Through experiments on synthetic and real-world tabular datasets, we show that counterfactual explanations are highly sensitive to model uncertainty. In particular, we find that even small reductions in model accuracy - caused by increased noise or limited data - can lead to large variations in the generated counterfactuals on average and on individual instances. These findings underscore the need for uncertainty-aware explanation methods in domains such as finance and the social sciences.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u9ad8\u5ea6\u654f\u611f\uff0c\u5373\u4f7f\u6a21\u578b\u51c6\u786e\u7387\u5c0f\u5e45\u4e0b\u964d\u4e5f\u4f1a\u5bfc\u81f4\u53cd\u4e8b\u5b9e\u7ed3\u679c\u5927\u5e45\u53d8\u5316\uff0c\u5f3a\u8c03\u4e86\u5728\u91d1\u878d\u548c\u793e\u4f1a\u79d1\u5b66\u7b49\u9886\u57df\u9700\u8981\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u89e3\u91ca\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5927\u591a\u672a\u5728\u6a21\u578b\u548c\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5bfc\u81f4\u5728\u73b0\u5b9e\u4e16\u754c\u53d8\u5f02\u6027\u4e0b\u53ef\u80fd\u4ea7\u751f\u4e0d\u7a33\u5b9a\u6216\u65e0\u6548\u7684\u89e3\u91ca\u3002", "method": "\u901a\u8fc7\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u8868\u683c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\uff0c\u7814\u7a76\u5e38\u89c1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0e\u53cd\u4e8b\u5b9e\u751f\u6210\u7b97\u6cd5\u7ec4\u5408\u5728\u5b58\u5728\u5076\u7136\u6027\u548c\u8ba4\u77e5\u6027\u4e0d\u786e\u5b9a\u6027\u65f6\u7684\u9c81\u68d2\u6027\u3002", "result": "\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u9ad8\u5ea6\u654f\u611f\uff0c\u5373\u4f7f\u7531\u566a\u58f0\u589e\u52a0\u6216\u6570\u636e\u6709\u9650\u5bfc\u81f4\u7684\u6a21\u578b\u51c6\u786e\u7387\u5c0f\u5e45\u4e0b\u964d\uff0c\u4e5f\u4f1a\u5bfc\u81f4\u751f\u6210\u7684\u53cd\u4e8b\u5b9e\u5728\u5e73\u5747\u548c\u4e2a\u4f53\u5b9e\u4f8b\u4e0a\u51fa\u73b0\u5927\u5e45\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u91d1\u878d\u548c\u793e\u4f1a\u79d1\u5b66\u7b49\u9886\u57df\u9700\u8981\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5bf9\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.02204", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02204", "abs": "https://arxiv.org/abs/2602.02204", "authors": ["Peiqi Yin", "Jiangyun Zhu", "Han Gao", "Chenguang Zheng", "Yongxiang Huang", "Taichang Zhou", "Ruirui Yang", "Weizhi Liu", "Weiqing Chen", "Canlin Guo", "Didan Deng", "Zifeng Mo", "Cong Wang", "James Cheng", "Roger Wang", "Hongsheng Liu"], "title": "vLLM-Omni: Fully Disaggregated Serving for Any-to-Any Multimodal Models", "comment": "12 pages, 8 figures", "summary": "Any-to-any multimodal models that jointly handle text, images, video, and audio represent a significant advance in multimodal AI. However, their complex architectures (typically combining multiple autoregressive LLMs, diffusion transformers, and other specialized components) pose substantial challenges for efficient model serving. Existing serving systems are mainly tailored to a single paradigm, such as autoregressive LLMs for text generation or diffusion transformers for visual generation. They lack support for any-to-any pipelines that involve multiple interconnected model components. As a result, developers must manually handle cross-stage interactions, leading to huge performance degradation. We present vLLM-Omni, a fully disaggregated serving system for any-to-any models. vLLM-Omni features a novel stage abstraction that enables users to decompose complex any-to-any architectures into interconnected stages represented as a graph, and a disaggregated stage execution backend that optimizes resource utilization and throughput across stages. Each stage is independently served by an LLM or diffusion engine with per-stage request batching, flexible GPU allocation, and unified inter-stage connectors for data routing. Experimental results demonstrate that vLLM-Omni reduces job completion time (JCT) by up to 91.4% compared to baseline methods. The code is public available at https://github.com/vllm-project/vllm-omni.", "AI": {"tldr": "vLLM-Omni\u662f\u4e00\u4e2a\u7528\u4e8e\u4efb\u610f\u5230\u4efb\u610f\u591a\u6a21\u6001\u6a21\u578b\u7684\u5168\u89e3\u8026\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u9636\u6bb5\u62bd\u8c61\u548c\u4f18\u5316\u540e\u7aef\uff0c\u663e\u8457\u63d0\u5347\u670d\u52a1\u6548\u7387", "motivation": "\u73b0\u6709\u670d\u52a1\u7cfb\u7edf\u4e3b\u8981\u9488\u5bf9\u5355\u4e00\u8303\u5f0f\uff08\u5982\u6587\u672c\u751f\u6210\u6216\u89c6\u89c9\u751f\u6210\uff09\uff0c\u7f3a\u4e4f\u5bf9\u4efb\u610f\u5230\u4efb\u610f\u591a\u6a21\u6001\u6a21\u578b\u590d\u6742\u67b6\u6784\u7684\u652f\u6301\uff0c\u5bfc\u81f4\u5f00\u53d1\u8005\u9700\u8981\u624b\u52a8\u5904\u7406\u8de8\u9636\u6bb5\u4ea4\u4e92\uff0c\u9020\u6210\u5de8\u5927\u6027\u80fd\u635f\u5931", "method": "\u63d0\u51fa\u9636\u6bb5\u62bd\u8c61\u5c06\u590d\u6742\u67b6\u6784\u5206\u89e3\u4e3a\u56fe\u7ed3\u6784\u8fde\u63a5\u7684\u9636\u6bb5\uff0c\u91c7\u7528\u89e3\u8026\u9636\u6bb5\u6267\u884c\u540e\u7aef\uff0c\u6bcf\u4e2a\u9636\u6bb5\u7531LLM\u6216\u6269\u6563\u5f15\u64ce\u72ec\u7acb\u670d\u52a1\uff0c\u652f\u6301\u6bcf\u9636\u6bb5\u8bf7\u6c42\u6279\u5904\u7406\u3001\u7075\u6d3bGPU\u5206\u914d\u548c\u7edf\u4e00\u8de8\u9636\u6bb5\u8fde\u63a5\u5668", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cvLLM-Omni\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5c06\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\uff08JCT\uff09\u51cf\u5c11\u4e86\u9ad8\u8fbe91.4%", "conclusion": "vLLM-Omni\u4e3a\u4efb\u610f\u5230\u4efb\u610f\u591a\u6a21\u6001\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u670d\u52a1\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u5229\u7528\u7387\u548c\u541e\u5410\u91cf\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2602.00064", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00064", "abs": "https://arxiv.org/abs/2602.00064", "authors": ["Hao Deng", "Yingping Li", "Shuiping Gou", "Bo Liu"], "title": "SPGCL: Effective Graph Contrastive Learning via SVD-Guided Structural Perturbation", "comment": null, "summary": "Graph Neural Networks (GNNs) can be highly sensitive to structural noise, including spurious or missing edges caused by adversarial attacks or non-adversarial imperfections. Existing graph contrastive learning methods typically rely on either random perturbations (e.g., edge dropping) to generate diverse views or purely spectral augmentations (e.g., SVD) to preserve global structural priors. However, random perturbations are structure-agnostic and may remove critical edges, while SVD-based views often become dense and lack sufficient diversity. To bridge this gap, we propose SPGCL, a robust graph contrastive learning framework via SVD-guided structural perturbation. SPGCL couples lightweight stochastic edge removal with an SVD-guided refinement step that can recover mistakenly removed informative edges and introduce semantically meaningful missing links while avoiding graph densification through sparse top-ranked edge selection and merging. By balancing edge removal and recovery rates, SPGCL explicitly controls structural discrepancy between views so that contrastive signals reflect semantic structural differences rather than edge-count gaps. We further incorporate a contrastive fusion module regularized by a global similarity constraint to better align the two views. Extensive experiments on ten benchmark datasets demonstrate that SPGCL consistently improves robustness and accuracy of base GNNs, outperforming state-of-the-art graph contrastive learning and structure learning methods.", "AI": {"tldr": "SPGCL\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSVD\u5f15\u5bfc\u7ed3\u6784\u6270\u52a8\u7684\u9c81\u68d2\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u8861\u8fb9\u79fb\u9664\u548c\u6062\u590d\u6765\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u5bf9\u6bd4\u89c6\u56fe\uff0c\u63d0\u9ad8GNN\u5bf9\u7ed3\u6784\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u968f\u673a\u6270\u52a8\uff08\u5982\u8fb9\u4e22\u5f03\uff09\u53ef\u80fd\u79fb\u9664\u5173\u952e\u8fb9\u4e14\u7ed3\u6784\u65e0\u5173\uff0c\u800c\u57fa\u4e8eSVD\u7684\u589e\u5f3a\u65b9\u6cd5\u5f80\u5f80\u751f\u6210\u7a20\u5bc6\u56fe\u4e14\u7f3a\u4e4f\u591a\u6837\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5e73\u8861\u7ed3\u6784\u4fdd\u6301\u548c\u591a\u6837\u6027\u7684\u65b9\u6cd5\u3002", "method": "SPGCL\u7ed3\u5408\u8f7b\u91cf\u7ea7\u968f\u673a\u8fb9\u79fb\u9664\u548cSVD\u5f15\u5bfc\u7684\u7ec6\u5316\u6b65\u9aa4\uff0c\u901a\u8fc7\u7a00\u758f\u7684top-ranked\u8fb9\u9009\u62e9\u548c\u5408\u5e76\u6765\u6062\u590d\u88ab\u9519\u8bef\u79fb\u9664\u7684\u4fe1\u606f\u8fb9\u5e76\u5f15\u5165\u8bed\u4e49\u76f8\u5173\u7684\u7f3a\u5931\u8fde\u63a5\uff0c\u907f\u514d\u56fe\u7a20\u5bc6\u5316\u3002\u8fd8\u5305\u542b\u5bf9\u6bd4\u878d\u5408\u6a21\u5757\u548c\u5168\u5c40\u76f8\u4f3c\u6027\u7ea6\u675f\u3002", "result": "\u572810\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSPGCL\u80fd\u6301\u7eed\u63d0\u9ad8\u57fa\u7840GNN\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u56fe\u5bf9\u6bd4\u5b66\u4e60\u548c\u7ed3\u6784\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "SPGCL\u901a\u8fc7SVD\u5f15\u5bfc\u7684\u7ed3\u6784\u6270\u52a8\u6709\u6548\u5e73\u8861\u4e86\u7ed3\u6784\u4fdd\u6301\u548c\u89c6\u56fe\u591a\u6837\u6027\uff0c\u4e3a\u56fe\u5bf9\u6bd4\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u4e14\u6709\u6548\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u7ed3\u6784\u566a\u58f0\u5e76\u63d0\u9ad8GNN\u6027\u80fd\u3002"}}
{"id": "2602.01996", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.MS"], "pdf": "https://arxiv.org/pdf/2602.01996", "abs": "https://arxiv.org/abs/2602.01996", "authors": ["Theologos Anthimopoulos", "Milad Kokhazadeh", "Vasilios Kelefouras", "Benjamin Himpel", "Georgios Keramidas"], "title": "Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations", "comment": "36 pages, 16 figures, this is the author-accepted version of the article published in ACM Transactions on Embedded Computing Systems (TECS), Vol. 24, No. 6", "summary": "Deep neural networks (DNNs) have become indispensable in many real-life applications like natural language processing, and autonomous systems. However, deploying DNNs on resource-constrained devices, e.g., in RISC-V platforms, remains challenging due to the high computational and memory demands of fully connected (FC) layers, which dominate resource consumption. Low-rank factorization (LRF) offers an effective approach to compressing FC layers, but the vast design space of LRF solutions involves complex trade-offs among FLOPs, memory size, inference time, and accuracy, making the LRF process complex and time-consuming. This paper introduces an end-to-end LRF design space exploration methodology and a specialized design tool for optimizing FC layers on RISC-V processors. Using Tensor Train Decomposition (TTD) offered by TensorFlow T3F library, the proposed work prunes the LRF design space by excluding first, inefficient decomposition shapes and second, solutions with poor inference performance on RISC-V architectures. Compiler optimizations are then applied to enhance custom T3F layer performance, minimizing inference time and boosting computational efficiency. On average, our TT-decomposed layers run 3x faster than IREE and 8x faster than Pluto on the same compressed model. This work provides an efficient solution for deploying DNNs on edge and embedded devices powered by RISC-V architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9RISC-V\u5904\u7406\u5668\u7684\u7aef\u5230\u7aef\u4f4e\u79e9\u5206\u89e3\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7Tensor Train\u5206\u89e3\u538b\u7f29\u5168\u8fde\u63a5\u5c42\uff0c\u7ed3\u5408\u7f16\u8bd1\u5668\u4f18\u5316\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u5728\u538b\u7f29\u6a21\u578b\u4e0a\u6bd4\u73b0\u6709\u65b9\u6848\u5feb3-8\u500d\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\uff08\u5982RISC-V\u5e73\u53f0\uff09\u4e0a\u90e8\u7f72\u56f0\u96be\uff0c\u5168\u8fde\u63a5\u5c42\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u9ad8\u3002\u4f4e\u79e9\u5206\u89e3\u867d\u80fd\u538b\u7f29\u6a21\u578b\uff0c\u4f46\u8bbe\u8ba1\u7a7a\u95f4\u590d\u6742\uff0c\u9700\u8981\u5728FLOPs\u3001\u5185\u5b58\u3001\u63a8\u7406\u65f6\u95f4\u548c\u7cbe\u5ea6\u4e4b\u95f4\u6743\u8861\uff0c\u8fc7\u7a0b\u8017\u65f6\u4e14\u590d\u6742\u3002", "method": "\u4f7f\u7528TensorFlow T3F\u5e93\u7684Tensor Train\u5206\u89e3\uff0c\u901a\u8fc7\u4e24\u6b65\u526a\u679d\u8bbe\u8ba1\u7a7a\u95f4\uff1a1)\u6392\u9664\u4f4e\u6548\u5206\u89e3\u5f62\u72b6\uff1b2)\u6392\u9664\u5728RISC-V\u67b6\u6784\u4e0a\u63a8\u7406\u6027\u80fd\u5dee\u7684\u65b9\u6848\u3002\u5e94\u7528\u7f16\u8bd1\u5668\u4f18\u5316\u63d0\u5347\u81ea\u5b9a\u4e49T3F\u5c42\u6027\u80fd\uff0c\u6700\u5c0f\u5316\u63a8\u7406\u65f6\u95f4\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "TT\u5206\u89e3\u5c42\u5e73\u5747\u6bd4IREE\u5feb3\u500d\uff0c\u6bd4Pluto\u5feb8\u500d\uff08\u76f8\u540c\u538b\u7f29\u6a21\u578b\uff09\u3002\u4e3a\u57fa\u4e8eRISC-V\u67b6\u6784\u7684\u8fb9\u7f18\u548c\u5d4c\u5165\u5f0f\u8bbe\u5907\u90e8\u7f72DNN\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u4f4e\u79e9\u5206\u89e3\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u65b9\u6cd5\u548c\u4e13\u7528\u8bbe\u8ba1\u5de5\u5177\uff0c\u6709\u6548\u4f18\u5316\u4e86RISC-V\u5904\u7406\u5668\u4e0a\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u90e8\u7f72DNN\u7684\u6311\u6218\u3002"}}
{"id": "2602.02234", "categories": ["cs.DC", "physics.chem-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.02234", "abs": "https://arxiv.org/abs/2602.02234", "authors": ["Andong Hu", "Luca Pennati", "Stefano Markidis", "Ivy Peng"], "title": "Enabling AI Deep Potentials for Ab Initio-quality Molecular Dynamics Simulations in GROMACS", "comment": null, "summary": "State-of-the-art AI deep potentials provide ab initio-quality results, but at a fraction of the computational cost of first-principles quantum mechanical calculations, such as density functional theory. In this work, we bring AI deep potentials into GROMACS, a production-level Molecular Dynamics (MD) code, by integrating with DeePMD-kit that provides domain-specific deep learning (DL) models of interatomic potential energy and force fields. In particular, we enable AI deep potentials inference across multiple DP model families and DL backends by coupling GROMACS Neural Network Potentials with the C++/CUDA backend in DeePMD-kit. We evaluate two recent large-atom-model architectures, DPA2 that is based on the attention mechanism and DPA3 that is based on GNN, in GROMACS using four ab initio-quality protein-in-water benchmarks (1YRF, 1UBQ, 3LZM, 2PTC) on NVIDIA A100 and GH200 GPUs. Our results show that DPA2 delivers up to 4.23x and 3.18x higher throughput than DPA3 on A100 and GH200 GPUs, respectively. We also provide a characterization study to further contrast DPA2 and DPA3 in throughput, memory usage, and kernel-level execution on GPUs. Our findings identify kernel-launch overhead and domain-decomposed inference as the main optimization priorities for AI deep potentials in production MD simulations.", "AI": {"tldr": "\u5c06AI\u6df1\u5ea6\u52bf\u80fd\u96c6\u6210\u5230GROMACS\u5206\u5b50\u52a8\u529b\u5b66\u8f6f\u4ef6\u4e2d\uff0c\u901a\u8fc7DeePMD-kit\u652f\u6301\u591a\u79cdDP\u6a21\u578b\uff0c\u8bc4\u4f30\u4e86DPA2\u548cDPA3\u4e24\u79cd\u67b6\u6784\u5728\u86cb\u767d\u8d28-\u6c34\u7cfb\u7edf\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "AI\u6df1\u5ea6\u52bf\u80fd\u80fd\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u4ece\u5934\u7b97\u8d28\u91cf\u7684\u7ed3\u679c\uff0c\u4f46\u9700\u8981\u5c06\u5176\u96c6\u6210\u5230\u751f\u4ea7\u7ea7\u5206\u5b50\u52a8\u529b\u5b66\u8f6f\u4ef6\u4e2d\uff0c\u4ee5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d1\u6325\u4f18\u52bf\u3002", "method": "\u5c06GROMACS\u4e0eDeePMD-kit\u7684C++/CUDA\u540e\u7aef\u8026\u5408\uff0c\u652f\u6301\u591a\u79cdDP\u6a21\u578b\u5bb6\u65cf\u548c\u6df1\u5ea6\u5b66\u4e60\u540e\u7aef\uff0c\u5728NVIDIA A100\u548cGH200 GPU\u4e0a\u8bc4\u4f30DPA2\uff08\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\uff09\u548cDPA3\uff08\u57fa\u4e8eGNN\uff09\u4e24\u79cd\u67b6\u6784\u3002", "result": "DPA2\u5728A100\u548cGH200 GPU\u4e0a\u7684\u541e\u5410\u91cf\u5206\u522b\u6bd4DPA3\u9ad84.23\u500d\u548c3.18\u500d\uff0c\u6027\u80fd\u5dee\u5f02\u4e3b\u8981\u6e90\u4e8e\u5185\u6838\u542f\u52a8\u5f00\u9500\u548c\u57df\u5206\u89e3\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u5185\u6838\u542f\u52a8\u5f00\u9500\u548c\u57df\u5206\u89e3\u63a8\u7406\u662fAI\u6df1\u5ea6\u52bf\u80fd\u5728\u751f\u4ea7\u7ea7MD\u6a21\u62df\u4e2d\u7684\u4e3b\u8981\u4f18\u5316\u65b9\u5411\uff0cDPA2\u67b6\u6784\u5728\u5f53\u524d\u786c\u4ef6\u4e0a\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2602.00067", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00067", "abs": "https://arxiv.org/abs/2602.00067", "authors": ["Yihan Zhang", "Ercan E. Kuruoglu"], "title": "Modality as Heterogeneity: Node Splitting and Graph Rewiring for Multimodal Graph Learning", "comment": null, "summary": "Multimodal graphs are gaining increasing attention due to their rich representational power and wide applicability, yet they introduce substantial challenges arising from severe modality confusion. To address this issue, we propose NSG (Node Splitting Graph)-MoE, a multimodal graph learning framework that integrates a node-splitting and graph-rewiring mechanism with a structured Mixture-of-Experts (MoE) architecture. It explicitly decomposes each node into modality-specific components and assigns relation-aware experts to process heterogeneous message flows, thereby preserving structural information and multimodal semantics while mitigating the undesirable mixing effects commonly observed in general-purpose GNNs. Extensive experiments on three multimodal benchmarks demonstrate that NSG-MoE consistently surpasses strong baselines. Despite incorporating MoE -- which is typically computationally heavy -- our method achieves competitive training efficiency. Beyond empirical results, we provide a spectral analysis revealing that NSG performs adaptive filtering over modality-specific subspaces, thus explaining its disentangling behavior. Furthermore, an information-theoretic analysis shows that the architectural constraints imposed by NSG reduces mutual information between data and parameters and improving generalization capability.", "AI": {"tldr": "NSG-MoE\uff1a\u4e00\u79cd\u901a\u8fc7\u8282\u70b9\u5206\u88c2\u548c\u56fe\u5f62\u91cd\u8fde\u673a\u5236\u7ed3\u5408\u7ed3\u6784\u5316\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u7684\u591a\u6a21\u6001\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u6a21\u6001\u6df7\u6dc6\u95ee\u9898", "motivation": "\u591a\u6a21\u6001\u56fe\u867d\u7136\u5177\u6709\u4e30\u5bcc\u7684\u8868\u793a\u80fd\u529b\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4f46\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u6a21\u6001\u6df7\u6dc6\u95ee\u9898\u3002\u901a\u7528GNN\u5728\u5904\u7406\u591a\u6a21\u6001\u56fe\u65f6\u7ecf\u5e38\u51fa\u73b0\u4e0d\u5e0c\u671b\u7684\u6df7\u5408\u6548\u5e94\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u4fdd\u6301\u7ed3\u6784\u4fe1\u606f\u548c\u591a\u6a21\u6001\u8bed\u4e49", "method": "\u63d0\u51faNSG-MoE\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u8282\u70b9\u5206\u88c2\u548c\u56fe\u5f62\u91cd\u8fde\u673a\u5236\uff0c\u5c06\u6bcf\u4e2a\u8282\u70b9\u663e\u5f0f\u5206\u89e3\u4e3a\u6a21\u6001\u7279\u5b9a\u7ec4\u4ef6\uff1b2\uff09\u7ed3\u6784\u5316MoE\u67b6\u6784\uff0c\u5206\u914d\u5173\u7cfb\u611f\u77e5\u4e13\u5bb6\u5904\u7406\u5f02\u6784\u6d88\u606f\u6d41\uff1b3\uff09\u901a\u8fc7\u67b6\u6784\u7ea6\u675f\u51cf\u5c11\u6570\u636e\u548c\u53c2\u6570\u95f4\u7684\u4e92\u4fe1\u606f", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cNSG-MoE\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002\u5c3d\u7ba1\u5305\u542b\u901a\u5e38\u8ba1\u7b97\u91cf\u5927\u7684MoE\uff0c\u4f46\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6709\u7ade\u4e89\u529b\u7684\u8bad\u7ec3\u6548\u7387\u3002\u8c31\u5206\u6790\u663e\u793aNSG\u5728\u6a21\u6001\u7279\u5b9a\u5b50\u7a7a\u95f4\u4e0a\u6267\u884c\u81ea\u9002\u5e94\u6ee4\u6ce2\uff0c\u4fe1\u606f\u8bba\u5206\u6790\u8868\u660e\u67b6\u6784\u7ea6\u675f\u63d0\u9ad8\u4e86\u6cdb\u5316\u80fd\u529b", "conclusion": "NSG-MoE\u901a\u8fc7\u663e\u5f0f\u5206\u89e3\u8282\u70b9\u4e3a\u6a21\u6001\u7279\u5b9a\u7ec4\u4ef6\u5e76\u5206\u914d\u5173\u7cfb\u611f\u77e5\u4e13\u5bb6\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u591a\u6a21\u6001\u56fe\u4e2d\u7684\u6a21\u6001\u6df7\u6dc6\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ed3\u6784\u4fe1\u606f\u548c\u591a\u6a21\u6001\u8bed\u4e49\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u90fd\u8868\u73b0\u51fa\u8272"}}
{"id": "2602.02335", "categories": ["cs.DC", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.02335", "abs": "https://arxiv.org/abs/2602.02335", "authors": ["Weiming Sheng", "Jinlang Wang", "Manuel Barros", "Aldrin Montana", "Jacopo Tagliabue", "Luca Bigon"], "title": "Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents", "comment": "Pre-print (PaPoC 2026)", "summary": "Lakehouses are the default cloud platform for analytics and AI, but they become unsafe when untrusted actors concurrently operate on production data: upstream-downstream mismatches surface only at runtime, and multi-table pipelines can leak partial effects. Inspired by software engineering, we design Bauplan, a code-first lakehouse that aims to make (most) illegal states unrepresentable using familiar abstractions. Bauplan acts along three axes: typed table contracts to make pipeline boundaries checkable, Git-like data versioning for review and reproducibility, and transactional runs that guarantee pipeline-level atomicity. We report early results from a lightweight formal transaction model and discuss future work motivated by counterexamples.", "AI": {"tldr": "Bauplan\u662f\u4e00\u4e2a\u4ee3\u7801\u4f18\u5148\u7684\u6e56\u4ed3\u5e73\u53f0\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u8868\u5951\u7ea6\u3001Git\u5f0f\u6570\u636e\u7248\u672c\u63a7\u5236\u548c\u4e8b\u52a1\u6027\u8fd0\u884c\u6765\u786e\u4fdd\u6570\u636e\u7ba1\u9053\u5b89\u5168\uff0c\u9632\u6b62\u5e76\u53d1\u64cd\u4f5c\u4e2d\u7684\u4e0d\u5339\u914d\u548c\u6cc4\u6f0f\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u6e56\u4ed3\u5e73\u53f0\u5728\u591a\u4e2a\u4e0d\u53ef\u4fe1\u53c2\u4e0e\u8005\u5e76\u53d1\u64cd\u4f5c\u751f\u4ea7\u6570\u636e\u65f6\u5b58\u5728\u5b89\u5168\u95ee\u9898\uff1a\u4e0a\u4e0b\u6e38\u4e0d\u5339\u914d\u53ea\u80fd\u5728\u8fd0\u884c\u65f6\u53d1\u73b0\uff0c\u591a\u8868\u7ba1\u9053\u53ef\u80fd\u6cc4\u6f0f\u90e8\u5206\u6548\u679c\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u9632\u6b62\u8fd9\u4e9b\u975e\u6cd5\u72b6\u6001\u7684\u51fa\u73b0\u3002", "method": "\u8bbe\u8ba1Bauplan\u4ee3\u7801\u4f18\u5148\u6e56\u4ed3\uff0c\u91c7\u7528\u4e09\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1) \u7c7b\u578b\u5316\u8868\u5951\u7ea6\u4f7f\u7ba1\u9053\u8fb9\u754c\u53ef\u68c0\u67e5\uff1b2) Git\u5f0f\u6570\u636e\u7248\u672c\u63a7\u5236\u7528\u4e8e\u5ba1\u67e5\u548c\u53ef\u91cd\u590d\u6027\uff1b3) \u4e8b\u52a1\u6027\u8fd0\u884c\u4fdd\u8bc1\u7ba1\u9053\u7ea7\u539f\u5b50\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u5f62\u5f0f\u5316\u4e8b\u52a1\u6a21\u578b\u7684\u65e9\u671f\u7ed3\u679c\uff0c\u5e76\u8ba8\u8bba\u4e86\u7531\u53cd\u4f8b\u6fc0\u53d1\u7684\u672a\u6765\u5de5\u4f5c\u65b9\u5411\u3002", "conclusion": "Bauplan\u901a\u8fc7\u8f6f\u4ef6\u5de5\u7a0b\u542f\u53d1\u7684\u8bbe\u8ba1\uff0c\u65e8\u5728\u4f7f\u5927\u591a\u6570\u975e\u6cd5\u72b6\u6001\u65e0\u6cd5\u8868\u793a\uff0c\u4e3a\u5e76\u53d1\u6570\u636e\u64cd\u4f5c\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\uff0c\u662f\u6e56\u4ed3\u5e73\u53f0\u5b89\u5168\u6027\u7684\u91cd\u8981\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2602.00072", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00072", "abs": "https://arxiv.org/abs/2602.00072", "authors": ["Jice Zeng", "David Barajas-Solano", "Hui Chen"], "title": "Generative AI-enhanced Probabilistic Multi-Fidelity Surrogate Modeling Via Transfer Learning", "comment": null, "summary": "The performance of machine learning surrogates is critically dependent on data quality and quantity. This presents a major challenge, as high-fidelity (HF) data is often scarce and computationally expensive to acquire, while low-fidelity (LF) data is abundant but less accurate. To address this data scarcity problem, we develop a probabilistic multi-fidelity surrogate framework based on generative transfer learning. We employ a normalizing flow (NF) generative model as the backbone, which is trained in two phases: (i) the NF is first pretrained on a large LF dataset to learn a probabilistic forward model; (ii) the pretrained model is then fine-tuned on a small HF dataset, allowing it to correct for LF-HF discrepancies via knowledge transfer. To relax the dimension-preserving constraint of standard bijective NFs, we integrate surjective (dimension-reducing) layers with standard coupling blocks. This architecture enables learned dimension reduction while preserving the ability to train with exact likelihoods. The resulting surrogate provides fast probabilistic predictions with quantified uncertainty and significantly outperforms LF-only baselines while using fewer HF evaluations. We validate the approach on a reinforced concrete slab benchmark, combining many coarse-mesh (LF) simulations with a limited set of fine-mesh (HF) simulations. The proposed model achieves probabilistic predictions with HF accuracy, demonstrating a practical path toward data-efficient, generative AI-driven surrogates for complex engineering systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u751f\u6210\u5f0f\u8fc1\u79fb\u5b66\u4e60\u7684\u6982\u7387\u591a\u4fdd\u771f\u5ea6\u4ee3\u7406\u6846\u67b6\uff0c\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\u6a21\u578b\uff0c\u5148\u5728\u5927\u89c4\u6a21\u4f4e\u4fdd\u771f\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\uff0c\u518d\u5728\u5c0f\u89c4\u6a21\u9ad8\u4fdd\u771f\u6570\u636e\u4e0a\u5fae\u8c03\uff0c\u901a\u8fc7\u7ef4\u5ea6\u7f29\u51cf\u5c42\u89e3\u51b3\u6807\u51c6\u5f52\u4e00\u5316\u6d41\u7684\u7ef4\u5ea6\u7ea6\u675f\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6982\u7387\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u4ee3\u7406\u6a21\u578b\u7684\u6027\u80fd\u4e25\u91cd\u4f9d\u8d56\u6570\u636e\u8d28\u91cf\u548c\u6570\u91cf\uff0c\u4f46\u9ad8\u4fdd\u771f\u6570\u636e\u7a00\u7f3a\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4f4e\u4fdd\u771f\u6570\u636e\u4e30\u5bcc\u4f46\u7cbe\u5ea6\u4e0d\u8db3\u3002\u9700\u8981\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5f00\u53d1\u80fd\u591f\u6709\u6548\u5229\u7528\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u7684\u6982\u7387\u4ee3\u7406\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u751f\u6210\u5f0f\u8fc1\u79fb\u5b66\u4e60\u7684\u6982\u7387\u591a\u4fdd\u771f\u5ea6\u4ee3\u7406\u6846\u67b6\uff0c\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u5148\u5728\u5927\u91cf\u4f4e\u4fdd\u771f\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u5b66\u4e60\u6982\u7387\u524d\u5411\u6a21\u578b\uff0c\u7136\u540e\u5728\u5c0f\u89c4\u6a21\u9ad8\u4fdd\u771f\u6570\u636e\u4e0a\u5fae\u8c03\u4ee5\u7ea0\u6b63\u4f4e\u4fdd\u771f-\u9ad8\u4fdd\u771f\u5dee\u5f02\u3002\u5f15\u5165\u7ef4\u5ea6\u7f29\u51cf\u5c42\u4e0e\u6807\u51c6\u8026\u5408\u5757\u7ed3\u5408\uff0c\u653e\u677e\u6807\u51c6\u53cc\u5c04\u5f52\u4e00\u5316\u6d41\u7684\u7ef4\u5ea6\u4fdd\u6301\u7ea6\u675f\uff0c\u5b9e\u73b0\u7cbe\u786e\u4f3c\u7136\u8bad\u7ec3\u3002", "result": "\u5728\u94a2\u7b4b\u6df7\u51dd\u571f\u677f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\uff0c\u7ed3\u5408\u5927\u91cf\u7c97\u7f51\u683c\uff08\u4f4e\u4fdd\u771f\uff09\u6a21\u62df\u548c\u6709\u9650\u7ec6\u7f51\u683c\uff08\u9ad8\u4fdd\u771f\uff09\u6a21\u62df\u3002\u63d0\u51fa\u7684\u6a21\u578b\u5b9e\u73b0\u4e86\u5177\u6709\u9ad8\u4fdd\u771f\u7cbe\u5ea6\u7684\u6982\u7387\u9884\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u4ec5\u4f7f\u7528\u4f4e\u4fdd\u771f\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4f7f\u7528\u66f4\u5c11\u7684\u9ad8\u4fdd\u771f\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u590d\u6742\u5de5\u7a0b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u7684\u6570\u636e\u9ad8\u6548\u3001\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684\u4ee3\u7406\u6a21\u578b\u8def\u5f84\uff0c\u80fd\u591f\u63d0\u4f9b\u5feb\u901f\u6982\u7387\u9884\u6d4b\u548c\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u6709\u6548\u89e3\u51b3\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u5229\u7528\u95ee\u9898\u3002"}}
{"id": "2602.02340", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02340", "abs": "https://arxiv.org/abs/2602.02340", "authors": ["Gustav Schmid"], "title": "LCLs Beyond Bounded Degrees", "comment": null, "summary": "The study of Locally Checkable Labelings (LCLs) has led to a remarkably precise characterization of the distributed time complexities that can occur on bounded-degree trees. A central feature of this complexity landscape is the existence of strong gap results, which rule out large ranges of intermediate complexities. While it was initially hoped that these gaps might extend to more general graph classes, this has turned out not to be the case. In this work, we investigate a different direction: we remain in the class of trees, but allow arbitrarily large degrees.\n  We focus on the polynomial regime ($\u0398(n^{1/k} \\mid k \\in \\mathbb{N})$) and show that whether polynomial gap results persist in the unbounded-degree setting crucially depends on how LCLs are generalized beyond bounded degrees. We first demonstrate that if one allows LCLs to be defined using infinitely many local configurations, then the polynomial gaps disappear entirely: for every real exponent $0 < r \\leq 1$, there exists a locally checkable problem on trees with deterministic LOCAL complexity $\u0398(n^r)$.\n  Rather than stopping at this negative result, we identify a natural class of problems for which polynomial gap results can still be recovered. We introduce Locally Finite Labelings (LFLs), which formalize the intuition that ''every node must fall into one of finitely many local cases'', even in the presence of unbounded degrees.\n  Our main result shows that this restriction is sufficient to restore the polynomial gaps: for any LFL $\u03a0$ on trees with unbounded degrees, the deterministic LOCAL complexity of $\u03a0$ is either\n  - $\u0398(n^{1/k})$ for some integer $k \\geq 1$, or\n  - $O(\\log n)$.\n  Moreover, which case applies, and the corresponding value of $k$, can be determined solely from the description of $\u03a0$.", "AI": {"tldr": "\u7814\u7a76\u65e0\u754c\u5ea6\u6811\u4e0a\u7684LCL\u95ee\u9898\uff0c\u53d1\u73b0\u591a\u9879\u5f0f\u95f4\u9699\u7ed3\u679c\u53d6\u51b3\u4e8e\u95ee\u9898\u5b9a\u4e49\u65b9\u5f0f\uff1a\u82e5\u5141\u8bb8\u65e0\u9650\u591a\u5c40\u90e8\u914d\u7f6e\uff0c\u5219\u95f4\u9699\u6d88\u5931\uff1b\u82e5\u9650\u5236\u4e3a\u5c40\u90e8\u6709\u9650\u6807\u8bb0\uff0c\u5219\u6062\u590d\u591a\u9879\u5f0f\u95f4\u9699\u3002", "motivation": "\u5df2\u6709\u7814\u7a76\u5728\u6709\u9650\u5ea6\u6811\u4e0a\u5bf9LCL\u95ee\u9898\u83b7\u5f97\u4e86\u7cbe\u786e\u7684\u590d\u6742\u5ea6\u7279\u5f81\uff0c\u5305\u62ec\u5f3a\u95f4\u9699\u7ed3\u679c\u3002\u4f46\u5e0c\u671b\u5c06\u8fd9\u4e9b\u7ed3\u679c\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u56fe\u7c7b\u7684\u5c1d\u8bd5\u5931\u8d25\u3002\u672c\u6587\u8f6c\u5411\u7814\u7a76\u65e0\u754c\u5ea6\u6811\uff0c\u63a2\u7d22\u591a\u9879\u5f0f\u95f4\u9699\u7ed3\u679c\u662f\u5426\u80fd\u5728\u65e0\u754c\u5ea6\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u3002", "method": "1. \u9996\u5148\u8bc1\u660e\u82e5\u5141\u8bb8LCL\u4f7f\u7528\u65e0\u9650\u591a\u5c40\u90e8\u914d\u7f6e\u5b9a\u4e49\uff0c\u5219\u591a\u9879\u5f0f\u95f4\u9699\u5b8c\u5168\u6d88\u5931\uff1a\u5bf9\u4efb\u610f\u5b9e\u6570\u6307\u65700<r\u22641\uff0c\u90fd\u5b58\u5728\u786e\u5b9a\u6027LOCAL\u590d\u6742\u5ea6\u4e3a\u0398(n^r)\u7684\u6811\u4e0a\u7684\u5c40\u90e8\u53ef\u68c0\u67e5\u95ee\u9898\u3002\n2. \u5f15\u5165\u5c40\u90e8\u6709\u9650\u6807\u8bb0(LFLs)\u6982\u5ff5\uff0c\u8981\u6c42\"\u6bcf\u4e2a\u8282\u70b9\u5fc5\u987b\u5c5e\u4e8e\u6709\u9650\u591a\u4e2a\u5c40\u90e8\u60c5\u51b5\u4e4b\u4e00\"\uff0c\u5373\u4f7f\u5728\u65e0\u754c\u5ea6\u60c5\u51b5\u4e0b\u3002\n3. \u8bc1\u660e\u5bf9\u4efb\u610f\u65e0\u754c\u5ea6\u6811\u4e0a\u7684LFL\u95ee\u9898\uff0c\u5176\u786e\u5b9a\u6027LOCAL\u590d\u6742\u5ea6\u8981\u4e48\u662f\u0398(n^{1/k})\uff08k\u4e3a\u6574\u6570\uff09\uff0c\u8981\u4e48\u662fO(log n)\uff0c\u4e14\u53ef\u4ece\u95ee\u9898\u63cf\u8ff0\u786e\u5b9a\u5c5e\u4e8e\u54ea\u79cd\u60c5\u51b5\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\uff1a\u5bf9\u4e8e\u65e0\u754c\u5ea6\u6811\u4e0a\u7684LFL\u95ee\u9898\uff0c\u786e\u5b9a\u6027LOCAL\u590d\u6742\u5ea6\u8981\u4e48\u662f\u0398(n^{1/k})\uff08k\u4e3a\u6574\u6570\uff09\uff0c\u8981\u4e48\u662fO(log n)\u3002\u8fd9\u6062\u590d\u4e86\u591a\u9879\u5f0f\u95f4\u9699\u7ed3\u679c\u3002\u540c\u65f6\u8bc1\u660e\u4e86\u82e5\u5141\u8bb8\u65e0\u9650\u591a\u5c40\u90e8\u914d\u7f6e\uff0c\u5219\u95f4\u9699\u6d88\u5931\u3002", "conclusion": "\u5728\u65e0\u754c\u5ea6\u6811\u4e0a\uff0c\u591a\u9879\u5f0f\u95f4\u9699\u7ed3\u679c\u7684\u5b58\u5728\u4e0e\u5426\u53d6\u51b3\u4e8eLCL\u95ee\u9898\u7684\u5b9a\u4e49\u65b9\u5f0f\u3002\u901a\u8fc7\u5f15\u5165\u5c40\u90e8\u6709\u9650\u6807\u8bb0(LFLs)\u8fd9\u4e00\u81ea\u7136\u9650\u5236\uff0c\u53ef\u4ee5\u6062\u590d\u591a\u9879\u5f0f\u95f4\u9699\u7279\u5f81\u3002\u8fd9\u4e3a\u7406\u89e3\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u590d\u6742\u5ea6\u666f\u89c2\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.00075", "categories": ["cs.LG", "cs.MS"], "pdf": "https://arxiv.org/pdf/2602.00075", "abs": "https://arxiv.org/abs/2602.00075", "authors": ["Philipp Andelfinger", "Wentong Cai"], "title": "Dimensional Peeking for Low-Variance Gradients in Zeroth-Order Discrete Optimization via Simulation", "comment": "Accepted at ACM SIGSIM PADS 2026", "summary": "Gradient-based optimization methods are commonly used to identify local optima in high-dimensional spaces. When derivatives cannot be evaluated directly, stochastic estimators can provide approximate gradients. However, these estimators' perturbation-based sampling of the objective function introduces variance that can lead to slow convergence. In this paper, we present dimensional peeking, a variance reduction method for gradient estimation in discrete optimization via simulation. By lifting the sampling granularity from scalar values to classes of values that follow the same control flow path, we increase the information gathered per simulation evaluation. Our derivation from an established smoothed gradient estimator shows that the method does not introduce any bias. We present an implementation via a custom numerical data type to transparently carry out dimensional peeking over C++ programs. Variance reductions by factors of up to 7.9 are observed for three simulation-based optimization problems with high-dimensional input. The optimization progress compared to three meta-heuristics shows that dimensional peeking increases the competitiveness of zeroth-order optimization for discrete and non-convex simulations.", "AI": {"tldr": "\u63d0\u51fa\"\u7ef4\u5ea6\u7aa5\u63a2\"\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u91c7\u6837\u7c92\u5ea6\u4ece\u6807\u91cf\u63d0\u5347\u5230\u9075\u5faa\u76f8\u540c\u63a7\u5236\u6d41\u8def\u5f84\u7684\u503c\u7c7b\uff0c\u51cf\u5c11\u79bb\u6563\u4eff\u771f\u4f18\u5316\u4e2d\u68af\u5ea6\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u5b9e\u73b0\u65e0\u504f\u65b9\u5dee\u964d\u4f4e\u3002", "motivation": "\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u65b9\u6cd5\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5bfb\u627e\u5c40\u90e8\u6700\u4f18\u89e3\u65f6\uff0c\u5f53\u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u5bfc\u6570\u65f6\uff0c\u9700\u8981\u4f7f\u7528\u968f\u673a\u4f30\u8ba1\u5668\u8fd1\u4f3c\u68af\u5ea6\u3002\u4f46\u8fd9\u4e9b\u57fa\u4e8e\u6270\u52a8\u7684\u91c7\u6837\u65b9\u6cd5\u4f1a\u5f15\u5165\u65b9\u5dee\uff0c\u5bfc\u81f4\u6536\u655b\u7f13\u6162\u3002", "method": "\u63d0\u51fa\"\u7ef4\u5ea6\u7aa5\u63a2\"\u65b9\u5dee\u51cf\u5c11\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u5347\u91c7\u6837\u7c92\u5ea6\uff08\u4ece\u6807\u91cf\u503c\u5230\u9075\u5faa\u76f8\u540c\u63a7\u5236\u6d41\u8def\u5f84\u7684\u503c\u7c7b\uff09\uff0c\u589e\u52a0\u6bcf\u6b21\u4eff\u771f\u8bc4\u4f30\u6536\u96c6\u7684\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u4ece\u5df2\u6709\u7684\u5e73\u6ed1\u68af\u5ea6\u4f30\u8ba1\u5668\u63a8\u5bfc\u800c\u6765\uff0c\u4fdd\u8bc1\u65e0\u504f\u6027\uff0c\u5e76\u901a\u8fc7\u81ea\u5b9a\u4e49\u6570\u503c\u6570\u636e\u7c7b\u578b\u5728C++\u7a0b\u5e8f\u4e2d\u900f\u660e\u5b9e\u73b0\u3002", "result": "\u5728\u4e09\u4e2a\u9ad8\u7ef4\u8f93\u5165\u7684\u4eff\u771f\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u89c2\u5bdf\u5230\u65b9\u5dee\u51cf\u5c11\u56e0\u5b50\u6700\u9ad8\u8fbe7.9\u500d\u3002\u4e0e\u4e09\u79cd\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u76f8\u6bd4\uff0c\u7ef4\u5ea6\u7aa5\u63a2\u63d0\u9ad8\u4e86\u96f6\u9636\u4f18\u5316\u5728\u79bb\u6563\u975e\u51f8\u4eff\u771f\u95ee\u9898\u4e2d\u7684\u7ade\u4e89\u529b\u3002", "conclusion": "\u7ef4\u5ea6\u7aa5\u63a2\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u5dee\u51cf\u5c11\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u79bb\u6563\u4eff\u771f\u4f18\u5316\u4e2d\u68af\u5ea6\u4f30\u8ba1\u7684\u6548\u7387\uff0c\u4f7f\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u79bb\u6563\u975e\u51f8\u4eff\u771f\u95ee\u9898\u4e2d\u66f4\u5177\u7ade\u4e89\u529b\u3002"}}
{"id": "2602.02355", "categories": ["cs.DC", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02355", "abs": "https://arxiv.org/abs/2602.02355", "authors": ["Amirreza Kazemi", "Seyed Mohammad Azimi-Abarghouyi", "Gabor Fodor", "Carlo Fischione"], "title": "Hierarchical Federated Learning with SignSGD: A Highly Communication-Efficient Approach", "comment": null, "summary": "Hierarchical federated learning (HFL) has emerged as a key architecture for large-scale wireless and Internet of Things systems, where devices communicate with nearby edge servers before reaching the cloud. In these environments, uplink bandwidth and latency impose strict communication limits, thereby making aggressive gradient compression essential. One-bit methods such as sign-based stochastic gradient descent (SignSGD) offer an attractive solution in flat federated settings, but existing theory and algorithms do not naturally extend to hierarchical settings. In particular, the interaction between majority-vote aggregation at the edge layer and model aggregation at the cloud layer, and its impact on end-to-end performance, remains unknown. To bridge this gap, we propose a highly communication-efficient sign-based HFL framework and develop its corresponding formulation for nonconvex learning, where devices send only signed stochastic gradients, edge servers combine them through majority-vote, and the cloud periodically averages the obtained edge models, while utilizing downlink quantization to broadcast the global model. We introduce the resulting scalable HFL algorithm, HierSignSGD, and provide the convergence analysis for SignSGD in a hierarchical setting. Our core technical contribution is a characterization of how biased sign compression, two-level aggregation intervals, and inter-cluster heterogeneity collectively affect convergence. Numerical experiments under homogeneous and heterogeneous data splits show that HierSignSGD, despite employing extreme compression, achieves accuracy comparable to or better than full-precision stochastic gradient descent while reducing communication cost in the process, and remains robust under aggressive downlink sparsification.", "AI": {"tldr": "\u63d0\u51faHierSignSGD\u7b97\u6cd5\uff0c\u4e00\u79cd\u7528\u4e8e\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u7684\u9ad8\u6548\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7\u68af\u5ea6\u538b\u7f29\u548c\u4e24\u7ea7\u805a\u5408\u673a\u5236\uff0c\u5728\u6781\u7aef\u538b\u7f29\u4e0b\u5b9e\u73b0\u4e0e\u5168\u7cbe\u5ea6SGD\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "motivation": "\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u5728\u5927\u89c4\u6a21\u65e0\u7ebf\u548c\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\u9762\u4e34\u4e25\u683c\u7684\u901a\u4fe1\u9650\u5236\uff0c\u73b0\u6709\u7684\u4e00\u6bd4\u7279\u65b9\u6cd5\uff08\u5982SignSGD\uff09\u5728\u6241\u5e73\u8054\u90a6\u8bbe\u7f6e\u4e2d\u6709\u6548\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5206\u5c42\u67b6\u6784\u7684\u7406\u8bba\u548c\u7b97\u6cd5\u6269\u5c55\uff0c\u7279\u522b\u662f\u8fb9\u7f18\u5c42\u591a\u6570\u6295\u7968\u805a\u5408\u4e0e\u4e91\u5c42\u6a21\u578b\u805a\u5408\u7684\u4ea4\u4e92\u5f71\u54cd\u672a\u77e5\u3002", "method": "\u63d0\u51faHierSignSGD\u7b97\u6cd5\uff1a\u8bbe\u5907\u4ec5\u53d1\u9001\u7b26\u53f7\u5316\u968f\u673a\u68af\u5ea6\uff0c\u8fb9\u7f18\u670d\u52a1\u5668\u901a\u8fc7\u591a\u6570\u6295\u7968\u805a\u5408\uff0c\u4e91\u5c42\u5b9a\u671f\u5e73\u5747\u8fb9\u7f18\u6a21\u578b\uff0c\u540c\u65f6\u4f7f\u7528\u4e0b\u884c\u94fe\u8def\u91cf\u5316\u5e7f\u64ad\u5168\u5c40\u6a21\u578b\u3002\u5efa\u7acb\u4e86\u975e\u51f8\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5206\u6790\u4e86\u6709\u504f\u7b26\u53f7\u538b\u7f29\u3001\u4e24\u7ea7\u805a\u5408\u95f4\u9694\u548c\u96c6\u7fa4\u95f4\u5f02\u8d28\u6027\u5bf9\u6536\u655b\u7684\u5f71\u54cd\u3002", "result": "\u5728\u540c\u8d28\u548c\u5f02\u8d28\u6570\u636e\u5212\u5206\u4e0b\uff0cHierSignSGD\u5c3d\u7ba1\u91c7\u7528\u6781\u7aef\u538b\u7f29\uff0c\u4ecd\u80fd\u8fbe\u5230\u4e0e\u5168\u7cbe\u5ea6\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u76f8\u5f53\u6216\u66f4\u597d\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u5e76\u5728\u6fc0\u8fdb\u7684\u4e0b\u884c\u94fe\u8def\u7a00\u758f\u5316\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "HierSignSGD\u4e3a\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u6781\u7aef\u538b\u7f29\u4e0b\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u65e0\u7ebf\u548c\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.00077", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00077", "abs": "https://arxiv.org/abs/2602.00077", "authors": ["Francisco Mart\u00ednez", "Mar\u00eda P. Fr\u00edas"], "title": "Automated univariate time series forecasting with regression trees", "comment": "23 pages, 17 figures", "summary": "This paper describes a methodology for automated univariate time series forecasting using regression trees and their ensembles: bagging and random forests. The key aspects that are addressed are: the use of an autoregressive approach and recursive forecasts, how to select the autoregressive features, how to deal with trending series and how to cope with seasonal behavior. Experimental results show a forecast accuracy comparable with well-established statistical models such as exponential smoothing or ARIMA. Furthermore, a publicly available software implementing all the proposed strategies has been developed and is described in the paper.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u56de\u5f52\u6811\u53ca\u5176\u96c6\u6210\u65b9\u6cd5\uff08\u88c5\u888b\u548c\u968f\u673a\u68ee\u6797\uff09\u8fdb\u884c\u81ea\u52a8\u5316\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u65b9\u6cd5\u8bba\uff0c\u5b9e\u73b0\u4e86\u4e0e\u6307\u6570\u5e73\u6ed1\u6216ARIMA\u7b49\u4f20\u7edf\u7edf\u8ba1\u6a21\u578b\u76f8\u5f53\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u56de\u5f52\u6811\u548c\u96c6\u6210\u5b66\u4e60\u7684\u81ea\u52a8\u5316\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u5e76\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u5982\u81ea\u56de\u5f52\u7279\u5f81\u9009\u62e9\u3001\u8d8b\u52bf\u5904\u7406\u548c\u5b63\u8282\u6027\u5904\u7406\u3002", "method": "\u91c7\u7528\u81ea\u56de\u5f52\u65b9\u6cd5\u548c\u9012\u5f52\u9884\u6d4b\uff0c\u4f7f\u7528\u56de\u5f52\u6811\u53ca\u5176\u96c6\u6210\u65b9\u6cd5\uff08\u88c5\u888b\u548c\u968f\u673a\u68ee\u6797\uff09\uff0c\u901a\u8fc7\u7279\u5f81\u5de5\u7a0b\u5904\u7406\u81ea\u56de\u5f52\u7279\u5f81\u9009\u62e9\u3001\u8d8b\u52bf\u5e8f\u5217\u548c\u5b63\u8282\u6027\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u4e0e\u6307\u6570\u5e73\u6ed1\u6216ARIMA\u7b49\u6210\u719f\u7edf\u8ba1\u6a21\u578b\u76f8\u5f53\uff0c\u5e76\u5f00\u53d1\u4e86\u516c\u5f00\u53ef\u7528\u7684\u8f6f\u4ef6\u5b9e\u73b0\u6240\u6709\u63d0\u51fa\u7684\u7b56\u7565\u3002", "conclusion": "\u57fa\u4e8e\u56de\u5f52\u6811\u548c\u96c6\u6210\u5b66\u4e60\u7684\u65b9\u6cd5\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4e0e\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u7ade\u4e89\uff0c\u5e76\u901a\u8fc7\u516c\u5f00\u8f6f\u4ef6\u4fc3\u8fdb\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2602.02438", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02438", "abs": "https://arxiv.org/abs/2602.02438", "authors": ["Lican Huang"], "title": "sVIRGO: A Scalable Virtual Tree Hierarchical Framework for Distributed Systems", "comment": "10 pages", "summary": "We propose sVIRGO, a scalable virtual tree hierarchical framework for large-scale distributed systems. sVIRGO constructs virtual hierarchical trees directly on physical nodes, allowing each node to assume multiple hierarchical roles without overlay networks. The hierarchy preserves locality and is organized into configurable layers within regions. Coordination across thousands of regions is achieved via virtual upper-layer roles dynamically mapped onto nodes up to the top layer.\n  Each region maintains multiple active coordinators that monitor local health and perform dynamic re-selection if failures occur. Temporary drops below the minimum threshold do not compromise coordination, ensuring near-zero recovery latency, bounded communication overhead, and exponentially reduced failure probability while maintaining safety, liveness, and robustness under mobile, interference-prone, or adversarial conditions.\n  Communication is decoupled from the hierarchy and may use multi-frequency wireless links. Two message hop strategies are supported: (i) with long-distance infrastructure-assisted channels, coordinators exploit the virtual tree to minimize hops; (ii) without such channels, messages propagate via adjacent regions.\n  sVIRGO also supports Layer-Scoped Command Execution. Commands and coordination actions are executed within the scope of each hierarchical layer, enabling efficient local and regional decision-making while limiting unnecessary global propagation.", "AI": {"tldr": "sVIRGO\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u865a\u62df\u6811\u5c42\u6b21\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u901a\u8fc7\u76f4\u63a5\u5728\u7269\u7406\u8282\u70b9\u4e0a\u6784\u5efa\u865a\u62df\u5c42\u6b21\u6811\uff0c\u652f\u6301\u591a\u89d2\u8272\u5206\u914d\u548c\u533a\u57df\u5316\u534f\u8c03\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u6062\u590d\u548c\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u9700\u8981\u9ad8\u6548\u7684\u534f\u8c03\u673a\u5236\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u6062\u590d\u5ef6\u8fdf\u9ad8\u3001\u901a\u4fe1\u5f00\u9500\u5927\u3001\u6545\u969c\u6982\u7387\u9ad8\u7b49\u95ee\u9898\u3002\u7279\u522b\u662f\u5728\u79fb\u52a8\u3001\u5e72\u6270\u6216\u5bf9\u6297\u6027\u73af\u5883\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u5b89\u5168\u6027\u548c\u6d3b\u6027\uff0c\u53c8\u80fd\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u6062\u590d\u548c\u9ad8\u9c81\u68d2\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u76f4\u63a5\u5728\u7269\u7406\u8282\u70b9\u4e0a\u6784\u5efa\u865a\u62df\u5c42\u6b21\u6811\uff0c\u65e0\u9700\u8986\u76d6\u7f51\u7edc\n2. \u8282\u70b9\u53ef\u627f\u62c5\u591a\u4e2a\u5c42\u6b21\u89d2\u8272\uff0c\u5c42\u6b21\u7ed3\u6784\u6309\u533a\u57df\u7ec4\u7ec7\u4e3a\u53ef\u914d\u7f6e\u5c42\n3. \u901a\u8fc7\u865a\u62df\u4e0a\u5c42\u89d2\u8272\u52a8\u6001\u6620\u5c04\u5b9e\u73b0\u8de8\u533a\u57df\u534f\u8c03\n4. \u6bcf\u4e2a\u533a\u57df\u7ef4\u62a4\u591a\u4e2a\u6d3b\u8dc3\u534f\u8c03\u5668\uff0c\u76d1\u63a7\u672c\u5730\u5065\u5eb7\u72b6\u6001\u5e76\u6267\u884c\u52a8\u6001\u91cd\u9009\n5. \u901a\u4fe1\u4e0e\u5c42\u6b21\u7ed3\u6784\u89e3\u8026\uff0c\u652f\u6301\u591a\u9891\u65e0\u7ebf\u94fe\u8def\u548c\u4e24\u79cd\u6d88\u606f\u8df3\u8f6c\u7b56\u7565\n6. \u652f\u6301\u5c42\u8303\u56f4\u547d\u4ee4\u6267\u884c\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u672c\u5730\u548c\u533a\u57df\u51b3\u7b56", "result": "1. \u5b9e\u73b0\u8fd1\u96f6\u6062\u590d\u5ef6\u8fdf\n2. \u6709\u754c\u901a\u4fe1\u5f00\u9500\n3. \u6307\u6570\u7ea7\u964d\u4f4e\u6545\u969c\u6982\u7387\n4. \u5728\u79fb\u52a8\u3001\u5e72\u6270\u6216\u5bf9\u6297\u6027\u6761\u4ef6\u4e0b\u4fdd\u6301\u5b89\u5168\u6027\u3001\u6d3b\u6027\u548c\u9c81\u68d2\u6027\n5. \u652f\u6301\u5927\u89c4\u6a21\u533a\u57df\u534f\u8c03\uff08\u6570\u5343\u4e2a\u533a\u57df\uff09", "conclusion": "sVIRGO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u534f\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u865a\u62df\u5c42\u6b21\u6811\u7ed3\u6784\u548c\u533a\u57df\u5316\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u7cfb\u7edf\u5b89\u5168\u6027\u548c\u6d3b\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6062\u590d\u5ef6\u8fdf\u548c\u6545\u969c\u6982\u7387\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u590d\u6742\u73af\u5883\u4e0b\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002"}}
{"id": "2602.00079", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00079", "abs": "https://arxiv.org/abs/2602.00079", "authors": ["Han Xiao"], "title": "Lossless Embedding Compression via Spherical Coordinates", "comment": null, "summary": "We present a lossless compression method for unit-norm embeddings that achieves 1.5$\\times$ compression, 25\\% better than the best prior method. The method exploits that spherical coordinates of high-dimensional unit vectors concentrate around $\u03c0/2$, causing IEEE 754 exponents to collapse to a single value and enabling entropy coding. Evaluation across 26 configurations spanning text, image, and multi-vector embeddings confirms consistent improvement. The method requires no training and is fully lossless within float32 precision.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u635f\u538b\u7f29\u5355\u4f4d\u8303\u6570\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b01.5\u500d\u538b\u7f29\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u534725%", "motivation": "\u5355\u4f4d\u8303\u6570\u5d4c\u5165\u5728\u4fe1\u606f\u68c0\u7d22\u3001\u63a8\u8350\u7cfb\u7edf\u7b49\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5b58\u50a8\u548c\u4f20\u8f93\u6210\u672c\u9ad8\uff0c\u9700\u8981\u9ad8\u6548\u7684\u65e0\u635f\u538b\u7f29\u65b9\u6cd5", "method": "\u5229\u7528\u9ad8\u7ef4\u5355\u4f4d\u5411\u91cf\u7403\u5750\u6807\u96c6\u4e2d\u5728\u03c0/2\u9644\u8fd1\u7684\u7279\u6027\uff0c\u4f7fIEEE 754\u6307\u6570\u4f4d\u574d\u7f29\u4e3a\u5355\u4e00\u503c\uff0c\u4ece\u800c\u8fdb\u884c\u71b5\u7f16\u7801", "result": "\u572826\u79cd\u914d\u7f6e\uff08\u6db5\u76d6\u6587\u672c\u3001\u56fe\u50cf\u548c\u591a\u5411\u91cf\u5d4c\u5165\uff09\u7684\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b01.5\u500d\u538b\u7f29", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\uff0c\u5728float32\u7cbe\u5ea6\u5185\u5b8c\u5168\u65e0\u635f\uff0c\u4e3a\u9ad8\u7ef4\u5355\u4f4d\u5411\u91cf\u5d4c\u5165\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u538b\u7f29\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00269", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.00269", "abs": "https://arxiv.org/abs/2602.00269", "authors": ["Keisuke Kamahori", "Wei-Tzu Lee", "Atindra Jha", "Rohan Kadekodi", "Stephanie Wang", "Arvind Krishnamurthy", "Baris Kasikci"], "title": "VoxServe: Streaming-Centric Serving System for Speech Language Models", "comment": "The code is available at https://github.com/vox-serve/vox-serve", "summary": "Deploying modern Speech Language Models (SpeechLMs) in streaming settings requires systems that provide low latency, high throughput, and strong guarantees of streamability. Existing systems fall short of supporting diverse models flexibly and efficiently. We present VoxServe, a unified serving system for SpeechLMs that optimizes streaming performance. VoxServe introduces a model-execution abstraction that decouples model architecture from system-level optimizations, thereby enabling support for diverse SpeechLM architectures within a single framework. Building on this abstraction, VoxServe implements streaming-aware scheduling and an asynchronous inference pipeline to improve end-to-end efficiency. Evaluations across multiple modern SpeechLMs show that VoxServe achieves 10-20x higher throughput than existing implementations at comparable latency while maintaining high streaming viability. The code of VoxServe is available at https://github.com/vox-serve/vox-serve.", "AI": {"tldr": "VoxServe\u662f\u4e00\u4e2a\u7528\u4e8e\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6d41\u5f0f\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u89e3\u8026\u6a21\u578b\u67b6\u6784\u4e0e\u7cfb\u7edf\u4f18\u5316\uff0c\u5b9e\u73b0\u4e8610-20\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u6d41\u5f0f\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u6d41\u5f0f\u90e8\u7f72\u73b0\u4ee3\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u65e0\u6cd5\u7075\u6d3b\u9ad8\u6548\u5730\u652f\u6301\u591a\u6837\u5316\u6a21\u578b\u67b6\u6784\uff0c\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u548c\u6d41\u5f0f\u4fdd\u8bc1\u7684\u8981\u6c42\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u6267\u884c\u62bd\u8c61\u5c42\uff0c\u89e3\u8026\u6a21\u578b\u67b6\u6784\u4e0e\u7cfb\u7edf\u4f18\u5316\uff1b\u5b9e\u73b0\u6d41\u5f0f\u611f\u77e5\u8c03\u5ea6\u548c\u5f02\u6b65\u63a8\u7406\u6d41\u6c34\u7ebf\uff1b\u6784\u5efa\u7edf\u4e00\u6846\u67b6\u652f\u6301\u591a\u79cd\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u3002", "result": "\u5728\u591a\u79cd\u73b0\u4ee3\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cVoxServe\u5728\u53ef\u6bd4\u5ef6\u8fdf\u4e0b\u5b9e\u73b0\u4e8610-20\u500d\u4e8e\u73b0\u6709\u5b9e\u73b0\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6d41\u5f0f\u53ef\u884c\u6027\u3002", "conclusion": "VoxServe\u901a\u8fc7\u521b\u65b0\u7684\u7cfb\u7edf\u8bbe\u8ba1\u4e3a\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u6d41\u5f0f\u670d\u52a1\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u90e8\u7f72\u6027\u80fd\u3002"}}
{"id": "2602.00084", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00084", "abs": "https://arxiv.org/abs/2602.00084", "authors": ["Brady Steele"], "title": "Why LoRA Resists Label Noise: A Theoretical Framework for Noise-Robust Parameter-Efficient Fine-Tuning", "comment": "14 pages, 7 figures, 7 tables", "summary": "Parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA) have become the dominant paradigm for adapting large pretrained models. We present a theoretical framework explaining an underexplored property: LoRA's inherent resistance to label noise. Our analysis reveals three key insights. First, we prove that rank-$r$ LoRA cannot memorize all possible label assignments once the sample size exceeds $O(r(d+k-r))$, limiting its capacity to fit arbitrary noise. Second, we derive an optimal rank balancing approximation bias and noise-induced variance, showing it decreases with noise rate. Third, we establish temporal separation: clean patterns are learned early while noise memorization occurs later. We propose RACT (Rank-Aware Curriculum Training), leveraging rank discrepancy for noise detection. Experiments validate our predictions, with RACT achieving 91.1% F1 for noise detection on AG News while maintaining 91.46% accuracy, competitive with baselines that lack noise detection capability.", "AI": {"tldr": "LoRA\u5177\u6709\u5185\u5728\u7684\u6297\u6807\u7b7e\u566a\u58f0\u80fd\u529b\uff0c\u672c\u6587\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u8fd9\u4e00\u7279\u6027\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86RACT\u65b9\u6cd5\u7528\u4e8e\u566a\u58f0\u68c0\u6d4b\u3002", "motivation": "\u5c3d\u7ba1LoRA\u5df2\u6210\u4e3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u4e3b\u6d41\u65b9\u6cd5\uff0c\u4f46\u5176\u5bf9\u6807\u7b7e\u566a\u58f0\u7684\u5185\u5728\u62b5\u6297\u7279\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u4e0a\u89e3\u91caLoRA\u4e3a\u4f55\u80fd\u62b5\u6297\u6807\u7b7e\u566a\u58f0\uff0c\u5e76\u5229\u7528\u8fd9\u4e00\u7279\u6027\u5f00\u53d1\u5b9e\u7528\u7684\u566a\u58f0\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u5206\u6790LoRA\u7684\u6297\u566a\u58f0\u7279\u6027\uff0c\u5305\u62ec\u8bc1\u660erank-r LoRA\u7684\u8bb0\u5fc6\u5bb9\u91cf\u9650\u5236\u3001\u63a8\u5bfc\u6700\u4f18\u79e9\u5e73\u8861\u8fd1\u4f3c\u504f\u5dee\u548c\u566a\u58f0\u8bf1\u5bfc\u65b9\u5dee\u3001\u5efa\u7acb\u65f6\u95f4\u5206\u79bb\u7406\u8bba\u3002\u7136\u540e\u57fa\u4e8e\u8fd9\u4e9b\u7406\u8bba\u89c1\u89e3\u63d0\u51faRACT\uff08Rank-Aware Curriculum Training\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u79e9\u5dee\u5f02\u8fdb\u884c\u566a\u58f0\u68c0\u6d4b\u3002", "result": "\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86LoRA\u7684\u4e09\u4e2a\u5173\u952e\u7279\u6027\uff1a\u6709\u9650\u8bb0\u5fc6\u5bb9\u91cf\u3001\u6700\u4f18\u79e9\u968f\u566a\u58f0\u7387\u964d\u4f4e\u3001\u65f6\u95f4\u5206\u79bb\u73b0\u8c61\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u9884\u6d4b\uff0cRACT\u5728AG News\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8691.1%\u7684\u566a\u58f0\u68c0\u6d4bF1\u5206\u6570\uff0c\u540c\u65f6\u4fdd\u630191.46%\u7684\u51c6\u786e\u7387\uff0c\u4e0e\u7f3a\u4e4f\u566a\u58f0\u68c0\u6d4b\u80fd\u529b\u7684\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "LoRA\u7684\u5185\u5728\u6297\u566a\u58f0\u7279\u6027\u6e90\u4e8e\u5176\u4f4e\u79e9\u7ed3\u6784\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u8bb0\u5fc6\u4efb\u610f\u566a\u58f0\u7684\u80fd\u529b\u3002\u57fa\u4e8e\u8fd9\u4e00\u7406\u8bba\u7406\u89e3\u5f00\u53d1\u7684RACT\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u6807\u7b7e\u566a\u58f0\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u566a\u58f0\u9c81\u68d2\u5fae\u8c03\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.00294", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.00294", "abs": "https://arxiv.org/abs/2602.00294", "authors": ["Franz A. Heinsen", "Leo Kozachkov"], "title": "Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation", "comment": "For source code and replication instructions, see https://github.com/glassroom/sata_attention. 12 pages, 6 figures (main); 4 pages, 2 figures (appendix)", "summary": "The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u4ee5\u6052\u5b9a\u6210\u672c\u5b9e\u73b0\u4efb\u610f\u7cbe\u5ea6\uff0c\u663e\u8457\u964d\u4f4eTransformer\u6a21\u578b\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u5f53\u524dTransformer\u6a21\u578b\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6210\u672c\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u800c\u589e\u52a0\uff0c\u5bfc\u81f4\u5b58\u50a8\u3001\u8ba1\u7b97\u548c\u80fd\u6e90\u9700\u6c42\u8d85\u8fc7\u793e\u4f1a\u4f9b\u5e94\u80fd\u529b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5c06\u4f20\u7edf\u81ea\u6ce8\u610f\u529b\u516c\u5f0f\u7684\u6cf0\u52d2\u5c55\u5f00\u5206\u89e3\u4e3a\u5bf9\u79f0\u5f20\u91cf\u94fe\u8868\u8fbe\u5f0f\uff0c\u5229\u7528\u5bf9\u79f0\u6027\u83b7\u5f97\u524d\u9988\u53d8\u6362\uff0c\u5c06\u67e5\u8be2\u548c\u952e\u9ad8\u6548\u6620\u5c04\u5230\u6700\u5c0f\u591a\u9879\u5f0f\u6838\u7279\u5f81\u57fa\u7684\u5750\u6807\u4e2d\u3002", "result": "\u5b9e\u73b0\u4e86\u6052\u5b9a\u6210\u672c\u7684\u81ea\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u91cf\u51cf\u5c11\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u591f\u4ee5\u9002\u5ea6\u56fa\u5b9a\u6210\u672c\u5b9e\u73b0\u65e0\u9650\u4ee4\u724c\u751f\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5927\u89c4\u6a21Transformer\u6a21\u578b\u7684\u57fa\u7840\u8bbe\u65bd\u548c\u80fd\u6e90\u9700\u6c42\uff0c\u5f15\u5165\u7684\u6570\u5b66\u6280\u672f\u5177\u6709\u72ec\u7acb\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2602.00085", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00085", "abs": "https://arxiv.org/abs/2602.00085", "authors": ["Shuozhe Li", "Jincheng Cao", "Bodun Hu", "Aryan Mokhtari", "Leqi Liu", "Amy Zhang"], "title": "CARE-RFT: Confidence-Anchored Reinforcement Finetuning for Reliable Reasoning in Large Language Models", "comment": null, "summary": "Reinforcement finetuning (RFT) has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, we identify a critical trade-off: while unconstrained RFT achieves strong reasoning performance, it severely compromises model trustworthiness by amplifying hallucination and worsening calibration; conversely, RKL-constrained RFT preserves trustworthiness but limits reasoning gains due to its unbounded penalty on exploratory deviations. To resolve this tension, we introduce CARE-RFT (Confidence-Anchored Regularized Reinforcement Finetuning), a novel method that replaces standard reverse KL regularization with a skew reverse KL divergence. CARE-RFT provides a confidence-sensitive penalty: it is bounded for confident, consistently rewarded explorations to enable reasoning, while unbounded elsewhere to preserve calibration. Extensive experiments across multiple model scales and RFT algorithms show that CARE-RFT achieves a superior balance, matching the reasoning performance of unconstrained RFT while recovering the trustworthiness and calibration of the base model. Our work establishes that careful, confidence-aware regularization is key to building both capable and trustworthy reasoning models.", "AI": {"tldr": "CARE-RFT\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f6e\u4fe1\u5ea6\u951a\u5b9a\u6b63\u5219\u5316\u5f3a\u5316\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u504f\u659c\u53cd\u5411KL\u6563\u5ea6\u66ff\u4ee3\u6807\u51c6\u53cd\u5411KL\u6b63\u5219\u5316\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u53ef\u4fe1\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5fae\u8c03\u5b58\u5728\u5173\u952e\u6743\u8861\uff1a\u65e0\u7ea6\u675fRFT\u867d\u7136\u80fd\u83b7\u5f97\u5f3a\u5927\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u4e25\u91cd\u635f\u5bb3\u6a21\u578b\u53ef\u4fe1\u5ea6\uff08\u589e\u52a0\u5e7b\u89c9\u3001\u6076\u5316\u6821\u51c6\uff09\uff1b\u800cRKL\u7ea6\u675f\u7684RFT\u867d\u7136\u4fdd\u6301\u53ef\u4fe1\u5ea6\uff0c\u4f46\u7531\u4e8e\u5bf9\u63a2\u7d22\u6027\u504f\u5dee\u7684\u65e0\u754c\u60e9\u7f5a\u9650\u5236\u4e86\u63a8\u7406\u589e\u76ca\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\u3002", "method": "CARE-RFT\uff08\u7f6e\u4fe1\u5ea6\u951a\u5b9a\u6b63\u5219\u5316\u5f3a\u5316\u5fae\u8c03\uff09\u4f7f\u7528\u504f\u659c\u53cd\u5411KL\u6563\u5ea6\u66ff\u4ee3\u6807\u51c6\u53cd\u5411KL\u6b63\u5219\u5316\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u7f6e\u4fe1\u5ea6\u654f\u611f\u7684\u60e9\u7f5a\uff1a\u5bf9\u4e8e\u81ea\u4fe1\u4e14\u6301\u7eed\u83b7\u5f97\u5956\u52b1\u7684\u63a2\u7d22\uff0c\u60e9\u7f5a\u662f\u6709\u754c\u7684\u4ee5\u652f\u6301\u63a8\u7406\uff1b\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u60e9\u7f5a\u662f\u65e0\u754c\u7684\u4ee5\u4fdd\u6301\u6821\u51c6\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u548cRFT\u7b97\u6cd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCARE-RFT\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u5e73\u8861\uff1a\u5339\u914d\u65e0\u7ea6\u675fRFT\u7684\u63a8\u7406\u6027\u80fd\uff0c\u540c\u65f6\u6062\u590d\u57fa\u7840\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u548c\u6821\u51c6\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7f6e\u4fe1\u5ea6\u611f\u77e5\u6b63\u5219\u5316\u662f\u6784\u5efa\u65e2\u5177\u5907\u80fd\u529b\u53c8\u53ef\u4fe1\u8d56\u7684\u63a8\u7406\u6a21\u578b\u7684\u5173\u952e\u3002CARE-RFT\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u654f\u611f\u7684\u60e9\u7f5a\u673a\u5236\u6210\u529f\u89e3\u51b3\u4e86\u63a8\u7406\u6027\u80fd\u4e0e\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2602.00451", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.00451", "abs": "https://arxiv.org/abs/2602.00451", "authors": ["Xiaoyu Wang", "Xiaotian Li", "Zhixiang Zhou", "Chen Li", "Yong Liu"], "title": "Stabilizing Decentralized Federated Fine-Tuning via Topology-Aware Alternating LoRA", "comment": "17 Pages", "summary": "Decentralized federated learning (DFL), a serverless variant of federated learning, poses unique challenges for parameter-efficient fine-tuning due to the factorized structure of low-rank adaptation (LoRA). Unlike linear parameters, decentralized aggregation of LoRA updates introduces topology-dependent cross terms that can destabilize training under dynamic communication graphs. We propose \\texttt{TAD-LoRA}, a Topology-Aware Decentralized Low-Rank Adaptation framework that coordinates the updates and mixing of LoRA factors to control inter-client misalignment. We theoretically prove the convergence of \\texttt{TAD-LoRA} under non-convex objectives, explicitly characterizing the trade-off between topology-induced cross-term error and block-coordinate representation bias governed by the switching interval of alternative training. Experiments under various communication conditions validate our analysis, showing that \\texttt{TAD-LoRA} achieves robust performance across different communication scenarios, remaining competitive in strongly connected topologies and delivering clear gains under moderately and weakly connected topologies, with particularly strong results on the MNLI dataset.", "AI": {"tldr": "TAD-LoRA\uff1a\u4e00\u79cd\u9762\u5411\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u7684\u62d3\u6251\u611f\u77e5\u4f4e\u79e9\u9002\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03LoRA\u56e0\u5b50\u7684\u66f4\u65b0\u4e0e\u6df7\u5408\u6765\u63a7\u5236\u5ba2\u6237\u7aef\u95f4\u9519\u4f4d\uff0c\u5728\u52a8\u6001\u901a\u4fe1\u56fe\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08DFL\uff09\u4f5c\u4e3a\u65e0\u670d\u52a1\u5668\u7684\u8054\u90a6\u5b66\u4e60\u53d8\u4f53\uff0c\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u9762\u9762\u4e34\u72ec\u7279\u6311\u6218\u3002\u7531\u4e8e\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u7684\u56e0\u5b50\u5316\u7ed3\u6784\uff0c\u53bb\u4e2d\u5fc3\u5316\u805a\u5408LoRA\u66f4\u65b0\u4f1a\u5f15\u5165\u62d3\u6251\u4f9d\u8d56\u7684\u4ea4\u53c9\u9879\uff0c\u5728\u52a8\u6001\u901a\u4fe1\u56fe\u4e0b\u53ef\u80fd\u7834\u574f\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faTAD-LoRA\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03LoRA\u56e0\u5b50\u7684\u66f4\u65b0\u548c\u6df7\u5408\u6765\u63a7\u5236\u5ba2\u6237\u7aef\u95f4\u9519\u4f4d\u3002\u7406\u8bba\u8bc1\u660e\u4e86\u5728\u975e\u51f8\u76ee\u6807\u4e0b\u7684\u6536\u655b\u6027\uff0c\u660e\u786e\u523b\u753b\u4e86\u62d3\u6251\u8bf1\u5bfc\u4ea4\u53c9\u9879\u8bef\u5dee\u4e0e\u5757\u5750\u6807\u8868\u793a\u504f\u5dee\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "result": "\u5728\u5404\u79cd\u901a\u4fe1\u6761\u4ef6\u4e0b\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5206\u6790\u7ed3\u679c\uff0cTAD-LoRA\u5728\u4e0d\u540c\u901a\u4fe1\u573a\u666f\u4e0b\u5747\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u80fd\uff1a\u5728\u5f3a\u8fde\u63a5\u62d3\u6251\u4e2d\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5728\u4e2d\u5ea6\u548c\u5f31\u8fde\u63a5\u62d3\u6251\u4e2d\u5e26\u6765\u660e\u663e\u589e\u76ca\uff0c\u5728MNLI\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "TAD-LoRA\u6709\u6548\u89e3\u51b3\u4e86\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2dLoRA\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u7684\u534f\u8c03\u673a\u5236\u5728\u4e0d\u540c\u901a\u4fe1\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u9c81\u68d2\u6027\u80fd\u3002"}}
{"id": "2602.00453", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.00453", "abs": "https://arxiv.org/abs/2602.00453", "authors": ["Ziyao Wang", "Daeun Jung", "Yexiao He", "Guoheng Sun", "Zheyu Shen", "Myungjin Lee", "Ang Li"], "title": "FedMOA: Federated GRPO for Personalized Reasoning LLMs under Heterogeneous Rewards", "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has recently emerged as an effective approach for improving the reasoning capabilities of large language models through online multi-objective reinforcement learning. While personalization on private data is increasingly vital, traditional Reinforcement Learning (RL) alignment is often memory-prohibitive for on-device federated learning due to the overhead of maintaining a separate critic network. GRPO's critic-free architecture enables feasible on-device training, yet transitioning to a federated setting introduces systemic challenges: heterogeneous reward definitions, imbalanced multi-objective optimization, and high training costs. We propose FedMOA, a federated GRPO framework for multi-objective alignment under heterogeneous rewards. FedMOA stabilizes local training through an online adaptive weighting mechanism via hypergradient descent, which prioritizes primary reasoning as auxiliary objectives saturate. On the server side, it utilizes a task- and accuracy-aware aggregation strategy to prioritize high-quality updates. Experiments on mathematical reasoning and code generation benchmarks demonstrate that FedMOA consistently outperforms federated averaging, achieving accuracy gains of up to 2.2% while improving global performance, personalization, and multi-objective balance.", "AI": {"tldr": "FedMOA\uff1a\u4e00\u4e2a\u7528\u4e8e\u5f02\u6784\u5956\u52b1\u4e0b\u591a\u76ee\u6807\u5bf9\u9f50\u7684\u8054\u90a6GRPO\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6743\u91cd\u8c03\u6574\u548c\u4efb\u52a1\u611f\u77e5\u805a\u5408\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u4f18\u4e8e\u8054\u90a6\u5e73\u5747\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfRL\u5bf9\u9f50\u65b9\u6cd5\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\u5185\u5b58\u6d88\u8017\u5927\uff0cGRPO\u7684\u65e0critic\u67b6\u6784\u9002\u5408\u8bbe\u5907\u7aef\u8bad\u7ec3\uff0c\u4f46\u8054\u90a6\u8bbe\u7f6e\u9762\u4e34\u5f02\u6784\u5956\u52b1\u5b9a\u4e49\u3001\u591a\u76ee\u6807\u4f18\u5316\u4e0d\u5e73\u8861\u548c\u9ad8\u8bad\u7ec3\u6210\u672c\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faFedMOA\u6846\u67b6\uff1a1\uff09\u672c\u5730\u8bad\u7ec3\u901a\u8fc7\u8d85\u68af\u5ea6\u4e0b\u964d\u7684\u81ea\u9002\u5e94\u6743\u91cd\u673a\u5236\u7a33\u5b9a\u8bad\u7ec3\uff0c\u4f18\u5148\u8003\u8651\u4e3b\u8981\u63a8\u7406\u76ee\u6807\uff1b2\uff09\u670d\u52a1\u5668\u7aef\u91c7\u7528\u4efb\u52a1\u548c\u51c6\u786e\u7387\u611f\u77e5\u7684\u805a\u5408\u7b56\u7565\uff0c\u4f18\u5148\u9009\u62e9\u9ad8\u8d28\u91cf\u66f4\u65b0\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFedMOA\u59cb\u7ec8\u4f18\u4e8e\u8054\u90a6\u5e73\u5747\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe2.2%\uff0c\u540c\u65f6\u6539\u5584\u4e86\u5168\u5c40\u6027\u80fd\u3001\u4e2a\u6027\u5316\u548c\u591a\u76ee\u6807\u5e73\u8861\u3002", "conclusion": "FedMOA\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6GRPO\u4e2d\u7684\u7cfb\u7edf\u6027\u6311\u6218\uff0c\u4e3a\u5f02\u6784\u5956\u52b1\u4e0b\u7684\u591a\u76ee\u6807\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.00088", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00088", "abs": "https://arxiv.org/abs/2602.00088", "authors": ["Namkyung Yoon", "Hwangnam Kim"], "title": "From Numbers to Prompts: A Cognitive Symbolic Transition Mechanism for Lightweight Time-Series Forecasting", "comment": "16 pages, 5 figures. Submitted to ACM Transactions on Intelligent Systems and Technology", "summary": "Large language models have achieved remarkable success in time series prediction tasks, but their substantial computational and memory requirements limit deployment on lightweight platforms. In this paper, we propose the Symbolic Transition Mechanism (STM) a novel framework that bridges numeric time series data and language models through symbolic abstraction and prompt engineering. STM transforms continuous time series values into symbol tokens with quantization techniques based on human cognitive structures, and captures temporal dynamics through structured transformations of symbols, enabling fast engineering based predictions in which language models focus on critical parts of time series data. STM is a general purpose mechanisms that ensure the integrity of backbone language models, but they significantly improve their efficiency by inferring the dynamic and structured patterns inherent in time series data. We evaluated STM on various time series datasets, paired with four small language models (SLM) with limited computational environments. For all models, STM achieves error reductions of up to 69% in MAE and 90% in MSE compared to the default backbone SLM without STM. These results demonstrate the potential of STM as an efficient, adaptable layer for symbol-driven time series prediction using foundation models. The accuracy improvements were made at negligible resource costs, with maximum GPU memory of the base model increasing by approximately 0.06% and latency overhead increasing by only 0.64%.", "AI": {"tldr": "\u63d0\u51fa\u7b26\u53f7\u8f6c\u6362\u673a\u5236(STM)\uff0c\u901a\u8fc7\u7b26\u53f7\u62bd\u8c61\u548c\u63d0\u793a\u5de5\u7a0b\u5c06\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u4e0e\u8bed\u8a00\u6a21\u578b\u8fde\u63a5\uff0c\u663e\u8457\u63d0\u5347\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u6781\u4f4e\u8d44\u6e90\u5f00\u9500\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u9650\u5236\u4e86\u5728\u8f7b\u91cf\u7ea7\u5e73\u53f0\u4e0a\u7684\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u65e2\u80fd\u5229\u7528\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u53c8\u80fd\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\u3002", "method": "\u63d0\u51fa\u7b26\u53f7\u8f6c\u6362\u673a\u5236(STM)\uff1a1) \u57fa\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u7ed3\u6784\uff0c\u4f7f\u7528\u91cf\u5316\u6280\u672f\u5c06\u8fde\u7eed\u65f6\u95f4\u5e8f\u5217\u503c\u8f6c\u6362\u4e3a\u7b26\u53f7\u6807\u8bb0\uff1b2) \u901a\u8fc7\u7b26\u53f7\u7684\u7ed3\u6784\u5316\u8f6c\u6362\u6355\u6349\u65f6\u95f4\u52a8\u6001\uff1b3) \u4f7f\u8bed\u8a00\u6a21\u578b\u4e13\u6ce8\u4e8e\u65f6\u95f4\u5e8f\u5217\u7684\u5173\u952e\u90e8\u5206\u8fdb\u884c\u5feb\u901f\u5de5\u7a0b\u5316\u9884\u6d4b\u3002STM\u662f\u4e00\u4e2a\u901a\u7528\u673a\u5236\uff0c\u4fdd\u6301\u9aa8\u5e72\u8bed\u8a00\u6a21\u578b\u7684\u5b8c\u6574\u6027\uff0c\u4f46\u901a\u8fc7\u63a8\u65ad\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u52a8\u6001\u548c\u7ed3\u6784\u5316\u6a21\u5f0f\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\uff0c\u914d\u5408\u56db\u79cd\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLM)\u8fdb\u884c\u8bc4\u4f30\u3002STM\u4f7f\u6240\u6709\u6a21\u578b\u7684MAE\u8bef\u5dee\u964d\u4f4e\u9ad8\u8fbe69%\uff0cMSE\u8bef\u5dee\u964d\u4f4e\u9ad8\u8fbe90%\u3002\u8d44\u6e90\u5f00\u9500\u6781\u4f4e\uff1a\u57fa\u7840\u6a21\u578bGPU\u5185\u5b58\u4ec5\u589e\u52a0\u7ea60.06%\uff0c\u5ef6\u8fdf\u5f00\u9500\u4ec5\u589e\u52a00.64%\u3002", "conclusion": "STM\u4f5c\u4e3a\u4e00\u79cd\u9ad8\u6548\u3001\u9002\u5e94\u6027\u5f3a\u7684\u7b26\u53f7\u9a71\u52a8\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5c42\uff0c\u5c55\u793a\u4e86\u5728\u57fa\u7840\u6a21\u578b\u4e0a\u5b9e\u73b0\u663e\u8457\u7cbe\u5ea6\u63d0\u5347\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u5ffd\u7565\u7684\u8d44\u6e90\u6210\u672c\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u5e73\u53f0\u4e0a\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00694", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.00694", "abs": "https://arxiv.org/abs/2602.00694", "authors": ["Fabio Turazza", "Marcello Pietri", "Natalia Selini Hadjidimitriou", "Marco Mamei"], "title": "Forecasting Energy Availability in Local Energy Communities via LSTM Federated Learning", "comment": "Published as a book chapter in the MEDES 2024 proceedings (Springer LNCS)", "summary": "Local Energy Communities are emerging as crucial players in the landscape of sustainable development. A significant challenge for these communities is achieving self-sufficiency through effective management of the balance between energy production and consumption. To meet this challenge, it is essential to develop and implement forecasting models that deliver accurate predictions, which can then be utilized by optimization and planning algorithms. However, the application of forecasting solutions is often hindered by privacy constrains and regulations as the users participating in the Local Energy Community can be (rightfully) reluctant sharing their consumption patterns with others. In this context, the use of Federated Learning (FL) can be a viable solution as it allows to create a forecasting model without the need to share privacy sensitive information among the users. In this study, we demonstrate how FL and long short-term memory (LSTM) networks can be employed to achieve this objective, highlighting the trade-off between data sharing and forecasting accuracy.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e0eLSTM\u7f51\u7edc\u5728\u672c\u5730\u80fd\u6e90\u793e\u533a\u4e2d\u7684\u5e94\u7528\uff0c\u65e8\u5728\u89e3\u51b3\u80fd\u6e90\u4f9b\u9700\u5e73\u8861\u9884\u6d4b\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u6570\u636e\u5171\u4eab\u4e0e\u9884\u6d4b\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u672c\u5730\u80fd\u6e90\u793e\u533a\u5728\u5b9e\u73b0\u80fd\u6e90\u81ea\u7ed9\u81ea\u8db3\u65f6\u9762\u4e34\u6311\u6218\uff1a\u9700\u8981\u51c6\u786e\u9884\u6d4b\u80fd\u6e90\u4f9b\u9700\u5e73\u8861\uff0c\u4f46\u7528\u6237\u56e0\u9690\u79c1\u987e\u8651\u4e0d\u613f\u5171\u4eab\u6d88\u8d39\u6570\u636e\u3002\u4f20\u7edf\u9884\u6d4b\u65b9\u6cd5\u53d7\u9650\u4e8e\u9690\u79c1\u7ea6\u675f\u548c\u6cd5\u89c4\u9650\u5236\u3002", "method": "\u91c7\u7528\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6846\u67b6\u7ed3\u5408\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u7f51\u7edc\u3002FL\u5141\u8bb8\u5728\u4e0d\u5171\u4eab\u539f\u59cb\u9690\u79c1\u654f\u611f\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\uff0c\u5404\u7528\u6237\u672c\u5730\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\uff0c\u4ec5\u4ea4\u6362\u6a21\u578b\u66f4\u65b0\u800c\u975e\u539f\u59cb\u6570\u636e\u3002", "result": "\u7814\u7a76\u8868\u660e\u8054\u90a6\u5b66\u4e60\u4e0eLSTM\u7f51\u7edc\u80fd\u591f\u6709\u6548\u521b\u5efa\u80fd\u6e90\u6d88\u8d39\u9884\u6d4b\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002\u7814\u7a76\u7a81\u51fa\u4e86\u6570\u636e\u5171\u4eab\u7a0b\u5ea6\u4e0e\u9884\u6d4b\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u4e3a\u89e3\u51b3\u672c\u5730\u80fd\u6e90\u793e\u533a\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u9884\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u6709\u6548\u7684\u80fd\u6e90\u4f9b\u9700\u9884\u6d4b\uff0c\u4e3a\u4f18\u5316\u7b97\u6cd5\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2602.00092", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00092", "abs": "https://arxiv.org/abs/2602.00092", "authors": ["Neha Kalibhat", "Zi Wang", "Prasoon Bajpai", "Drew Proud", "Wenjun Zeng", "Been Kim", "Mani Malek"], "title": "Interpreting and Controlling Model Behavior via Constitutions for Atomic Concept Edits", "comment": null, "summary": "We introduce a black-box interpretability framework that learns a verifiable constitution: a natural language summary of how changes to a prompt affect a model's specific behavior, such as its alignment, correctness, or adherence to constraints. Our method leverages atomic concept edits (ACEs), which are targeted operations that add, remove, or replace an interpretable concept in the input prompt. By systematically applying ACEs and observing the resulting effects on model behavior across various tasks, our framework learns a causal mapping from edits to predictable outcomes. This learned constitution provides deep, generalizable insights into the model. Empirically, we validate our approach across diverse tasks, including mathematical reasoning and text-to-image alignment, for controlling and understanding model behavior. We found that for text-to-image generation, GPT-Image tends to focus on grammatical adherence, while Imagen 4 prioritizes atmospheric coherence. In mathematical reasoning, distractor variables confuse GPT-5 but leave Gemini 2.5 models and o4-mini largely unaffected. Moreover, our results show that the learned constitutions are highly effective for controlling model behavior, achieving an average of 1.86 times boost in success rate over methods that do not use constitutions.", "AI": {"tldr": "\u63d0\u51fa\u9ed1\u76d2\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u53ef\u9a8c\u8bc1\u7684\"\u5baa\u6cd5\"\u6765\u603b\u7ed3\u63d0\u793a\u8bcd\u4fee\u6539\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\uff0c\u5229\u7528\u539f\u5b50\u6982\u5ff5\u7f16\u8f91(ACE)\u5efa\u7acb\u56e0\u679c\u6620\u5c04\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u6587\u751f\u56fe\u7b49\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u9700\u8981\u7406\u89e3\u9ed1\u76d2\u6a21\u578b\u7684\u884c\u4e3a\u673a\u5236\uff0c\u7279\u522b\u662f\u63d0\u793a\u8bcd\u4fee\u6539\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u7684\u5bf9\u9f50\u6027\u3001\u6b63\u786e\u6027\u548c\u7ea6\u675f\u9075\u5faa\u7b49\u5177\u4f53\u884c\u4e3a\uff0c\u4e3a\u6a21\u578b\u63a7\u5236\u548c\u7406\u89e3\u63d0\u4f9b\u7cfb\u7edf\u5316\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u539f\u5b50\u6982\u5ff5\u7f16\u8f91(ACE)\u6846\u67b6\uff0c\u901a\u8fc7\u6dfb\u52a0\u3001\u79fb\u9664\u6216\u66ff\u6362\u8f93\u5165\u63d0\u793a\u4e2d\u7684\u53ef\u89e3\u91ca\u6982\u5ff5\uff0c\u7cfb\u7edf\u5e94\u7528\u8fd9\u4e9b\u7f16\u8f91\u5e76\u89c2\u5bdf\u6a21\u578b\u884c\u4e3a\u53d8\u5316\uff0c\u5b66\u4e60\u4ece\u7f16\u8f91\u5230\u53ef\u9884\u6d4b\u7ed3\u679c\u7684\u56e0\u679c\u6620\u5c04\u3002", "result": "\u5728\u6587\u751f\u56fe\u4efb\u52a1\u4e2d\uff0cGPT-Image\u5173\u6ce8\u8bed\u6cd5\u9075\u5faa\uff0cImagen 4\u4f18\u5148\u8003\u8651\u6c1b\u56f4\u4e00\u81f4\u6027\uff1b\u6570\u5b66\u63a8\u7406\u4e2d\uff0c\u5e72\u6270\u53d8\u91cf\u4f1a\u6df7\u6dc6GPT-5\u4f46\u5bf9Gemini 2.5\u548co4-mini\u5f71\u54cd\u8f83\u5c0f\uff1b\u5b66\u4e60\u5230\u7684\u5baa\u6cd5\u5728\u63a7\u5236\u6a21\u578b\u884c\u4e3a\u65b9\u9762\u6bd4\u65e0\u5baa\u6cd5\u65b9\u6cd5\u5e73\u5747\u63d0\u53471.86\u500d\u6210\u529f\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u5b66\u4e60\u53ef\u9a8c\u8bc1\u7684\u6a21\u578b\u884c\u4e3a\u5baa\u6cd5\uff0c\u63d0\u4f9b\u6df1\u5165\u4e14\u53ef\u6cdb\u5316\u7684\u6a21\u578b\u7406\u89e3\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u6210\u529f\u63a7\u5236\u6a21\u578b\u884c\u4e3a\uff0c\u4e3a\u9ed1\u76d2\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.01852", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.01852", "abs": "https://arxiv.org/abs/2602.01852", "authors": ["Zeyan Wang", "Zhengmao Liu", "Yongxin Cai", "Chi Li", "Xiaoying Tang", "Jingchao Chen", "Zibin Pan", "Jing Qiu"], "title": "FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization", "comment": null, "summary": "Federated Unlearning (FU) aims to efficiently remove the influence of specific client data from a federated model while preserving utility for the remaining clients. However, three key challenges remain: (1) existing unlearning objectives often compromise model utility or increase vulnerability to Membership Inference Attacks (MIA); (2) there is a persistent conflict between forgetting and utility, where further unlearning inevitably harms retained performance; and (3) support for concurrent multi-client unlearning is poor, as gradient conflicts among clients degrade the quality of forgetting. To address these issues, we propose FUPareto, an efficient unlearning framework via Pareto-augmented optimization. We first introduce the Minimum Boundary Shift (MBS) Loss, which enforces unlearning by suppressing the target class logit below the highest non-target class logit; this can improve the unlearning efficiency and mitigate MIA risks. During the unlearning process, FUPareto performs Pareto improvement steps to preserve model utility and executes Pareto expansion to guarantee forgetting. Specifically, during Pareto expansion, the framework integrates a Null-Space Projected Multiple Gradient Descent Algorithm (MGDA) to decouple gradient conflicts. This enables effective, fair, and concurrent unlearning for multiple clients while minimizing utility degradation. Extensive experiments across diverse scenarios demonstrate that FUPareto consistently outperforms state-of-the-art FU methods in both unlearning efficacy and retained utility.", "AI": {"tldr": "FUPareto\uff1a\u57fa\u4e8e\u5e15\u7d2f\u6258\u4f18\u5316\u7684\u8054\u90a6\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u8fb9\u754c\u504f\u79fb\u635f\u5931\u548c\u96f6\u7a7a\u95f4\u6295\u5f71\u591a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff0c\u89e3\u51b3\u8054\u90a6\u9057\u5fd8\u4e2d\u7684\u6548\u7528-\u9057\u5fd8\u51b2\u7a81\u548c\u591a\u5ba2\u6237\u7aef\u5e76\u53d1\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u9057\u5fd8\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u9057\u5fd8\u76ee\u6807\u5e38\u635f\u5bb3\u6a21\u578b\u6548\u7528\u6216\u589e\u52a0\u6210\u5458\u63a8\u7406\u653b\u51fb\u98ce\u9669\uff1b2\uff09\u9057\u5fd8\u4e0e\u6548\u7528\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u51b2\u7a81\uff0c\u8fdb\u4e00\u6b65\u9057\u5fd8\u5fc5\u7136\u635f\u5bb3\u4fdd\u7559\u6027\u80fd\uff1b3\uff09\u591a\u5ba2\u6237\u7aef\u5e76\u53d1\u9057\u5fd8\u652f\u6301\u5dee\uff0c\u5ba2\u6237\u7aef\u95f4\u68af\u5ea6\u51b2\u7a81\u4f1a\u964d\u4f4e\u9057\u5fd8\u8d28\u91cf\u3002", "method": "\u63d0\u51faFUPareto\u6846\u67b6\uff1a1\uff09\u5f15\u5165\u6700\u5c0f\u8fb9\u754c\u504f\u79fb\u635f\u5931\uff0c\u901a\u8fc7\u6291\u5236\u76ee\u6807\u7c7blogit\u4f4e\u4e8e\u6700\u9ad8\u975e\u76ee\u6807\u7c7blogit\u6765\u63d0\u5347\u9057\u5fd8\u6548\u7387\u5e76\u964d\u4f4eMIA\u98ce\u9669\uff1b2\uff09\u5728\u9057\u5fd8\u8fc7\u7a0b\u4e2d\u6267\u884c\u5e15\u7d2f\u6258\u6539\u8fdb\u6b65\u9aa4\u4ee5\u4fdd\u6301\u6a21\u578b\u6548\u7528\uff1b3\uff09\u6267\u884c\u5e15\u7d2f\u6258\u6269\u5c55\u4ee5\u4fdd\u8bc1\u9057\u5fd8\uff0c\u5e76\u96c6\u6210\u96f6\u7a7a\u95f4\u6295\u5f71\u591a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u6765\u89e3\u8026\u68af\u5ea6\u51b2\u7a81\uff0c\u652f\u6301\u591a\u5ba2\u6237\u7aef\u5e76\u53d1\u9057\u5fd8\u3002", "result": "\u5728\u591a\u79cd\u573a\u666f\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFUPareto\u5728\u9057\u5fd8\u6548\u679c\u548c\u4fdd\u7559\u6548\u7528\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u8054\u90a6\u9057\u5fd8\u65b9\u6cd5\u3002", "conclusion": "FUPareto\u901a\u8fc7\u5e15\u7d2f\u6258\u589e\u5f3a\u4f18\u5316\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u9057\u5fd8\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u516c\u5e73\u7684\u591a\u5ba2\u6237\u7aef\u5e76\u53d1\u9057\u5fd8\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6548\u7528\u635f\u5931\u3002"}}
{"id": "2602.00094", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.00094", "abs": "https://arxiv.org/abs/2602.00094", "authors": ["Sandra Ben\u00edtez-Pe\u00f1a", "Blas Kolic", "Victoria Menendez", "Bel\u00e9n Pulido"], "title": "Trade-offs Between Individual and Group Fairness in Machine Learning: A Comprehensive Review", "comment": null, "summary": "Algorithmic fairness has become a central concern in computational decision-making systems, where ensuring equitable outcomes is essential for both ethical and legal reasons. Two dominant notions of fairness have emerged in the literature: Group Fairness (GF), which focuses on mitigating disparities across demographic subpopulations, and Individual Fairness (IF), which emphasizes consistent treatment of similar individuals. These notions have traditionally been studied in isolation. In contrast, this survey examines methods that jointly address GF and IF, integrating both perspectives within unified frameworks and explicitly characterizing the trade-offs between them. We provide a systematic and critical review of hybrid fairness approaches, organizing existing methods according to the fairness mechanisms they employ and the algorithmic and mathematical strategies used to reconcile multiple fairness criteria. For each class of methods, we examine their theoretical foundations, optimization mechanisms, and empirical evaluation practices, and discuss their limitations. Additionally, we discuss the challenges and identify open research directions for developing principled, context-aware hybrid fairness methods. By synthesizing insights across the literature, this survey aims to serve as a comprehensive resource for researchers and practitioners seeking to design hybrid algorithms that provide reliable fairness guarantees at both the individual and group levels.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86\u540c\u65f6\u5904\u7406\u7fa4\u4f53\u516c\u5e73\u6027\u548c\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u6df7\u5408\u516c\u5e73\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u7406\u8bba\u57fa\u7840\u3001\u4f18\u5316\u673a\u5236\u548c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e24\u79cd\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u4e0a\u7fa4\u4f53\u516c\u5e73\u6027\u548c\u4e2a\u4f53\u516c\u5e73\u6027\u88ab\u5b64\u7acb\u7814\u7a76\uff0c\u4f46\u5728\u5b9e\u9645\u51b3\u7b56\u7cfb\u7edf\u4e2d\u9700\u8981\u540c\u65f6\u8003\u8651\u8fd9\u4e24\u79cd\u516c\u5e73\u6027\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u8bbe\u8ba1\u65e2\u6ee1\u8db3\u7fa4\u4f53\u5c42\u9762\u53c8\u6ee1\u8db3\u4e2a\u4f53\u5c42\u9762\u516c\u5e73\u4fdd\u8bc1\u7684\u7b97\u6cd5\u63d0\u4f9b\u5168\u9762\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u6309\u7167\u516c\u5e73\u673a\u5236\u548c\u7b97\u6cd5\u7b56\u7565\u5bf9\u73b0\u6709\u6df7\u5408\u516c\u5e73\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\u6574\u7406\u3002\u5206\u6790\u6bcf\u7c7b\u65b9\u6cd5\u7684\u7406\u8bba\u57fa\u7840\u3001\u4f18\u5316\u673a\u5236\u548c\u5b9e\u8bc1\u8bc4\u4f30\u5b9e\u8df5\uff0c\u5e76\u8ba8\u8bba\u5176\u5c40\u9650\u6027\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u6df7\u5408\u516c\u5e73\u65b9\u6cd5\u7684\u5168\u9762\u5206\u7c7b\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728\u8c03\u548c\u7fa4\u4f53\u516c\u5e73\u6027\u4e0e\u4e2a\u4f53\u516c\u5e73\u6027\u65b9\u9762\u7684\u7b56\u7565\u548c\u6743\u8861\u3002\u8bc6\u522b\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u6df7\u5408\u516c\u5e73\u65b9\u6cd5\u662f\u5b9e\u73b0\u5168\u9762\u516c\u5e73\u51b3\u7b56\u7684\u5173\u952e\u65b9\u5411\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5177\u539f\u5219\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u7fa4\u4f53\u548c\u4e2a\u4f53\u516c\u5e73\u6027\u3002\u8fd9\u7bc7\u7efc\u8ff0\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u53ef\u9760\u6df7\u5408\u516c\u5e73\u7b97\u6cd5\u7684\u91cd\u8981\u53c2\u8003\u8d44\u6e90\u3002"}}
{"id": "2602.02192", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02192", "abs": "https://arxiv.org/abs/2602.02192", "authors": ["Jie Xiao", "Meng Chen", "Qingnan Ren", "Song Jingwei", "Jiaqi Huang", "Yangshen Deng", "Chris Tong", "Wanyi Chen", "Suli Wang", "Ziqian Bi", "Shuo Lu", "Yiqun Duan", "Lynn Ai", "Eric Yang", "Bill Shi"], "title": "ECHO-2: A Large Scale Distributed Rollout Framework for Cost-efficient Reinforcement Learning", "comment": "23 pages, 7 figures", "summary": "Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation, reward evaluation, and centralized learning. Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation, dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.", "AI": {"tldr": "ECHO-2\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u7684\u5206\u5e03\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u8fdc\u7a0b\u63a8\u7406\u5de5\u4f5c\u8282\u70b9\u3001\u7b56\u7565\u9648\u65e7\u5ea6\u63a7\u5236\u548c\u91cd\u53e0\u6267\u884c\u6765\u63d0\u5347\u6210\u672c\u6548\u7387", "motivation": "\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u5206\u5e03\u5f0f\u6267\u884c\u53ef\u4ee5\u964d\u4f4e\u6210\u672c\uff0c\u4f46\u9762\u4e34\u5e7f\u57df\u534f\u8c03\u548c\u7b56\u7565\u4f20\u64ad\u5ef6\u8fdf\u7684\u6311\u6218", "method": "\u7ed3\u5408\u96c6\u4e2d\u5f0f\u5b66\u4e60\u4e0e\u5206\u5e03\u5f0frollout\uff0c\u5c06\u7b56\u7565\u9648\u65e7\u5ea6\u4f5c\u4e3a\u53ef\u63a7\u53c2\u6570\uff0c\u91c7\u7528\u91cd\u53e0\u6267\u884c\u3001\u57fa\u4e8e\u91cd\u53e0\u7684\u5bb9\u91cf\u6a21\u578b\u3001\u5bf9\u7b49\u8f85\u52a9\u6d41\u6c34\u7ebf\u5e7f\u64ad\u548c\u6210\u672c\u611f\u77e5\u7684\u5f02\u6784\u5de5\u4f5c\u8282\u70b9\u6fc0\u6d3b", "result": "\u5728\u771f\u5b9e\u5e7f\u57df\u5e26\u5bbd\u73af\u5883\u4e0b\u5bf94B\u548c8B\u6a21\u578b\u8fdb\u884cGRPO\u540e\u8bad\u7ec3\uff0cECHO-2\u663e\u8457\u63d0\u9ad8\u4e86\u6210\u672c\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\u7684RL\u5956\u52b1", "conclusion": "ECHO-2\u901a\u8fc7\u5206\u5e03\u5f0frollout\u3001\u7b56\u7565\u9648\u65e7\u5ea6\u63a7\u5236\u548c\u6210\u672c\u4f18\u5316\u673a\u5236\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00099", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.00099", "abs": "https://arxiv.org/abs/2602.00099", "authors": ["James King", "Arturs Berzins", "Siddhartha Mishra", "Marius Zeinhofer"], "title": "Gauss-Newton Natural Gradient Descent for Shape Learning", "comment": "16 Pages, 9 Figures, submitted to Computer-Aided Design", "summary": "We explore the use of the Gauss-Newton method for optimization in shape learning, including implicit neural surfaces and geometry-informed neural networks. The method addresses key challenges in shape learning, such as the ill-conditioning of the underlying differential constraints and the mismatch between the optimization problem in parameter space and the function space where the problem is naturally posed. This leads to significantly faster and more stable convergence than standard first-order methods, while also requiring far fewer iterations. Experiments across benchmark shape optimization tasks demonstrate that the Gauss-Newton method consistently improves both training speed and final solution accuracy.", "AI": {"tldr": "\u8bba\u6587\u63a2\u7d22\u4e86\u4f7f\u7528\u9ad8\u65af-\u725b\u987f\u6cd5\u4f18\u5316\u5f62\u72b6\u5b66\u4e60\uff0c\u5305\u62ec\u9690\u5f0f\u795e\u7ecf\u8868\u9762\u548c\u51e0\u4f55\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u6bd4\u4e00\u9636\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5f62\u72b6\u5b66\u4e60\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u57fa\u7840\u5fae\u5206\u7ea6\u675f\u7684\u75c5\u6001\u6027\uff1b2\uff09\u53c2\u6570\u7a7a\u95f4\u4f18\u5316\u95ee\u9898\u4e0e\u51fd\u6570\u7a7a\u95f4\u81ea\u7136\u8868\u8ff0\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u3002\u4f20\u7edf\u4e00\u9636\u65b9\u6cd5\u5728\u8fd9\u4e9b\u95ee\u9898\u4e0a\u6536\u655b\u7f13\u6162\u4e14\u4e0d\u7a33\u5b9a\u3002", "method": "\u91c7\u7528\u9ad8\u65af-\u725b\u987f\u6cd5\u8fdb\u884c\u5f62\u72b6\u5b66\u4e60\u4f18\u5316\uff0c\u8be5\u65b9\u6cd5\u7279\u522b\u9002\u7528\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u9762\u548c\u51e0\u4f55\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u66f4\u597d\u5730\u5904\u7406\u5fae\u5206\u7ea6\u675f\u548c\u7a7a\u95f4\u4e0d\u5339\u914d\u95ee\u9898\u6765\u6539\u8fdb\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u57fa\u51c6\u5f62\u72b6\u4f18\u5316\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u9ad8\u65af-\u725b\u987f\u6cd5\u76f8\u6bd4\u6807\u51c6\u4e00\u9636\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u9700\u8981\u66f4\u5c11\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u6700\u7ec8\u89e3\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u9ad8\u65af-\u725b\u987f\u6cd5\u4e3a\u5f62\u72b6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u89e3\u51b3\u8be5\u9886\u57df\u7279\u6709\u7684\u6311\u6218\uff0c\u5728\u8bad\u7ec3\u901f\u5ea6\u548c\u6700\u7ec8\u7cbe\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u4e00\u9636\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2602.00116", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00116", "abs": "https://arxiv.org/abs/2602.00116", "authors": ["Hanne Dejonghe", "Sam Leroux"], "title": "THDC: Training Hyperdimensional Computing Models with Backpropagation", "comment": "Accepted to ESANN 2026", "summary": "Hyperdimensional computing (HDC) offers lightweight learning for energy-constrained devices by encoding data into high-dimensional vectors. However, its reliance on ultra-high dimensionality and static, randomly initialized hypervectors limits memory efficiency and learning capacity. Therefore, we propose Trainable Hyperdimensional Computing (THDC), which enables end-to-end HDC via backpropagation. THDC replaces randomly initialized vectors with trainable embeddings and introduces a one-layer binary neural network to optimize class representations. Evaluated on MNIST, Fashion-MNIST and CIFAR-10, THDC achieves equal or better accuracy than state-of-the-art HDC, with dimensionality reduced from 10.000 to 64.", "AI": {"tldr": "THDC\u63d0\u51fa\u53ef\u8bad\u7ec3\u7684\u8d85\u7ef4\u8ba1\u7b97\uff0c\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u7aef\u5230\u7aef\u5b66\u4e60\uff0c\u5c06\u7ef4\u5ea6\u4ece10000\u964d\u81f364\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8aSOTA HDC\u7cbe\u5ea6", "motivation": "\u4f20\u7edfHDC\u4f9d\u8d56\u8d85\u9ad8\u7ef4\u5ea6\u548c\u968f\u673a\u521d\u59cb\u5316\u7684\u9759\u6001\u8d85\u5411\u91cf\uff0c\u5bfc\u81f4\u5185\u5b58\u6548\u7387\u4f4e\u548c\u5b66\u4e60\u80fd\u529b\u53d7\u9650\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684HDC\u65b9\u6cd5", "method": "\u63d0\u51fa\u53ef\u8bad\u7ec3\u8d85\u7ef4\u8ba1\u7b97(THDC)\uff1a1)\u7528\u53ef\u8bad\u7ec3\u5d4c\u5165\u66ff\u4ee3\u968f\u673a\u521d\u59cb\u5316\u5411\u91cf\uff1b2)\u5f15\u5165\u5355\u5c42\u4e8c\u8fdb\u5236\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u7c7b\u522b\u8868\u793a\uff1b3)\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u5b9e\u73b0\u7aef\u5230\u7aef\u5b66\u4e60", "result": "\u5728MNIST\u3001Fashion-MNIST\u548cCIFAR-10\u4e0a\u8bc4\u4f30\uff0cTHDC\u8fbe\u5230\u6216\u4f18\u4e8eSOTA HDC\u7cbe\u5ea6\uff0c\u540c\u65f6\u5c06\u7ef4\u5ea6\u4ece10000\u5927\u5e45\u51cf\u5c11\u523064", "conclusion": "THDC\u901a\u8fc7\u53ef\u8bad\u7ec3\u5d4c\u5165\u548c\u7aef\u5230\u7aef\u5b66\u4e60\u663e\u8457\u63d0\u5347HDC\u7684\u5185\u5b58\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e3a\u80fd\u91cf\u53d7\u9650\u8bbe\u5907\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u8f7b\u91cf\u7ea7\u5b66\u4e60\u65b9\u6848"}}
{"id": "2602.00120", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00120", "abs": "https://arxiv.org/abs/2602.00120", "authors": ["Xianghong Hu", "Tianning Xu", "Ying Chen", "Shuai Wang"], "title": "Predicting Mortgage Default with Machine Learning: AutoML, Class Imbalance, and Leakage Control", "comment": "12 pages, 4 figures. An extended and pedagogical version will appear as a book chapter", "summary": "Mortgage default prediction is a core task in financial risk management, and machine learning models are increasingly used to estimate default probabilities and provide interpretable signals for downstream decisions. In real-world mortgage datasets, however, three factors frequently undermine evaluation validity and deployment reliability: ambiguity in default labeling, severe class imbalance, and information leakage arising from temporal structure and post-event variables. We compare multiple machine learning approaches for mortgage default prediction using a real-world loan-level dataset, with emphasis on leakage control and imbalance handling. We employ leakage-aware feature selection, a strict temporal split that constrains both origination and reporting periods, and controlled downsampling of the majority class. Across multiple positive-to-negative ratios, performance remains stable, and an AutoML approach (AutoGluon) achieves the strongest AUROC among the models evaluated. An extended and pedagogical version of this work will appear as a book chapter.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u62b5\u62bc\u8d37\u6b3e\u8fdd\u7ea6\u9884\u6d4b\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u6807\u7b7e\u6a21\u7cca\u6027\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u65f6\u95f4\u4fe1\u606f\u6cc4\u9732\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u62b5\u62bc\u8d37\u6b3e\u8fdd\u7ea6\u9884\u6d4b\u662f\u91d1\u878d\u98ce\u9669\u7ba1\u7406\u7684\u6838\u5fc3\u4efb\u52a1\uff0c\u4f46\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u8fdd\u7ea6\u6807\u7b7e\u6a21\u7cca\u6027\u3001\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u4ee5\u53ca\u65f6\u95f4\u7ed3\u6784\u548c\u4e8b\u540e\u53d8\u91cf\u5f15\u8d77\u7684\u4fe1\u606f\u6cc4\u9732\uff0c\u8fd9\u4e9b\u95ee\u9898\u4f1a\u524a\u5f31\u8bc4\u4f30\u6709\u6548\u6027\u548c\u90e8\u7f72\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u6cc4\u6f0f\u611f\u77e5\u7684\u7279\u5f81\u9009\u62e9\u3001\u4e25\u683c\u7684\u65f6\u95f4\u5206\u5272\uff08\u9650\u5236\u8d37\u6b3e\u53d1\u653e\u548c\u62a5\u544a\u5468\u671f\uff09\u3001\u63a7\u5236\u6027\u591a\u6570\u7c7b\u4e0b\u91c7\u6837\uff0c\u5e76\u6bd4\u8f83\u591a\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ecAutoML\uff08AutoGluon\uff09\u3002", "result": "\u5728\u4e0d\u540c\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u4e0b\uff0c\u6a21\u578b\u6027\u80fd\u4fdd\u6301\u7a33\u5b9a\uff0cAutoGluon\u5728\u8bc4\u4f30\u7684\u6a21\u578b\u4e2d\u83b7\u5f97\u4e86\u6700\u5f3a\u7684AUROC\uff08\u53d7\u8bd5\u8005\u5de5\u4f5c\u7279\u5f81\u66f2\u7ebf\u4e0b\u9762\u79ef\uff09\u3002", "conclusion": "\u901a\u8fc7\u6cc4\u6f0f\u63a7\u5236\u548c\u4e0d\u5e73\u8861\u5904\u7406\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u5728\u62b5\u62bc\u8d37\u6b3e\u8fdd\u7ea6\u9884\u6d4b\u4e2d\u5b9e\u73b0\u53ef\u9760\u6027\u80fd\uff0cAutoML\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\u3002\u8be5\u7814\u7a76\u7684\u6269\u5c55\u6559\u5b66\u7248\u672c\u5c06\u4f5c\u4e3a\u4e66\u7c4d\u7ae0\u8282\u51fa\u7248\u3002"}}
{"id": "2602.00125", "categories": ["cs.LG", "cs.AI", "cs.MS"], "pdf": "https://arxiv.org/pdf/2602.00125", "abs": "https://arxiv.org/abs/2602.00125", "authors": ["Soumyadip Sarkar"], "title": "MiniTensor: A Lightweight, High-Performance Tensor Operations Library", "comment": null, "summary": "We present MiniTensor, an open source tensor operations library that focuses on minimalism, correctness, and performance. MiniTensor exposes a familiar PyTorch-like Python API while it executes performance critical code in a Rust engine. The core supports dense $n$ dimensional tensors, broadcasting, reductions, matrix multiplication, reverse mode automatic differentiation, a compact set of neural network layers, and standard optimizers. In this paper, we describe the design of MiniTensor's architecture, including its efficient memory management, dynamic computation graph for gradients, and integration with Python via PyO3. We also compare the install footprint with PyTorch and TensorFlow to demonstrate that MiniTensor achieves a package size of only a few megabytes, several orders of magnitude smaller than mainstream frameworks, while preserving the essentials needed for research and development on CPUs. The repository can be found at https://github.com/neuralsorcerer/minitensor", "AI": {"tldr": "MiniTensor\u662f\u4e00\u4e2a\u5f00\u6e90\u5f20\u91cf\u8fd0\u7b97\u5e93\uff0c\u4e13\u6ce8\u4e8e\u7b80\u6d01\u6027\u3001\u6b63\u786e\u6027\u548c\u6027\u80fd\uff0c\u63d0\u4f9b\u7c7b\u4f3cPyTorch\u7684Python API\uff0c\u5e95\u5c42\u7528Rust\u5b9e\u73b0\uff0c\u5b89\u88c5\u5305\u4ec5\u51e0MB\uff0c\u6bd4\u4e3b\u6d41\u6846\u67b6\u5c0f\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5982PyTorch\u548cTensorFlow\u5b89\u88c5\u5305\u8fc7\u5927\uff08\u6570\u767eMB\u5230GB\u7ea7\u522b\uff09\uff0c\u5bf9\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u6216\u9700\u8981\u8f7b\u91cf\u7ea7\u90e8\u7f72\u7684\u573a\u666f\u4e0d\u591f\u53cb\u597d\u3002MiniTensor\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u6781\u7b80\u4f46\u529f\u80fd\u5b8c\u6574\u7684\u5f20\u91cf\u8fd0\u7b97\u5e93\uff0c\u4fdd\u6301\u6838\u5fc3\u529f\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c0f\u5b89\u88c5\u4f53\u79ef\u3002", "method": "\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff1a1\uff09Python\u5c42\u63d0\u4f9bPyTorch-like API\uff1b2\uff09Rust\u5f15\u64ce\u5c42\u5904\u7406\u6027\u80fd\u5173\u952e\u8fd0\u7b97\uff1b3\uff09\u901a\u8fc7PyO3\u5b9e\u73b0Python-Rust\u96c6\u6210\uff1b4\uff09\u5b9e\u73b0\u9ad8\u6548\u5185\u5b58\u7ba1\u7406\uff1b5\uff09\u52a8\u6001\u8ba1\u7b97\u56fe\u652f\u6301\u53cd\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\uff1b6\uff09\u5305\u542b\u7d27\u51d1\u7684\u795e\u7ecf\u7f51\u7edc\u5c42\u548c\u4f18\u5316\u5668\u3002", "result": "MiniTensor\u5b89\u88c5\u5305\u4ec5\u51e0MB\uff0c\u6bd4PyTorch\u548cTensorFlow\u5c0f\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002\u652f\u6301\u6838\u5fc3\u5f20\u91cf\u64cd\u4f5c\uff08n\u7ef4\u5f20\u91cf\u3001\u5e7f\u64ad\u3001\u5f52\u7ea6\u3001\u77e9\u9635\u4e58\u6cd5\uff09\u3001\u81ea\u52a8\u5fae\u5206\u3001\u795e\u7ecf\u7f51\u7edc\u5c42\u548c\u4f18\u5316\u5668\uff0c\u9002\u5408CPU\u4e0a\u7684\u7814\u7a76\u548c\u5f00\u53d1\u3002", "conclusion": "MiniTensor\u6210\u529f\u5b9e\u73b0\u4e86\u6781\u7b80\u8bbe\u8ba1\u76ee\u6807\uff0c\u5728\u4fdd\u6301\u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u6240\u9700\u6838\u5fc3\u529f\u80fd\u7684\u540c\u65f6\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u6846\u67b6\u4f53\u79ef\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u53ef\u4ee5\u65e2\u5c0f\u5de7\u53c8\u5b9e\u7528\u3002"}}
{"id": "2602.00127", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00127", "abs": "https://arxiv.org/abs/2602.00127", "authors": ["Tong Zhu", "Baiting Chen", "Jin Zhou", "Hua Zhou", "Sriram Sankararaman", "Xiaowu Dai"], "title": "ALIGN: Aligned Delegation with Performance Guarantees for Multi-Agent LLM Reasoning", "comment": null, "summary": "LLMs often underperform on complex reasoning tasks when relying on a single generation-and-selection pipeline. Inference-time ensemble methods can improve performance by sampling diverse reasoning paths or aggregating multiple candidate answers, but they typically treat candidates independently and provide no formal guarantees that ensembling improves reasoning quality. We propose a novel method, Aligned Delegation for Multi-Agent LLM Reasoning (ALIGN), which formulates LLM reasoning as an aligned delegation game. In ALIGN, a principal delegates a task to multiple agents that generate candidate solutions under designed incentives, and then selects among their outputs to produce a final answer. This formulation induces structured interaction among agents while preserving alignment between agent and principal objectives. We establish theoretical guarantees showing that, under a fair comparison with equal access to candidate solutions, ALIGN provably improves expected performance over single-agent generation. Our analysis accommodates correlated candidate answers and relaxes independence assumptions that are commonly used in prior work. Empirical results across a broad range of LLM reasoning benchmarks consistently demonstrate that ALIGN outperforms strong single-agent and ensemble baselines.", "AI": {"tldr": "ALIGN\u65b9\u6cd5\u5c06LLM\u63a8\u7406\u5efa\u6a21\u4e3a\u5bf9\u9f50\u59d4\u6258\u6e38\u620f\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u751f\u6210\u5019\u9009\u65b9\u6848\uff0c\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u6bd4\u5355\u667a\u80fd\u4f53\u63a8\u7406\u6709\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfLLM\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u7684\u63a8\u7406\u65f6\u96c6\u6210\u65b9\u6cd5\u901a\u5e38\u5c06\u5019\u9009\u7b54\u6848\u89c6\u4e3a\u72ec\u7acb\u5904\u7406\uff0c\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u4e14\u65e0\u6cd5\u786e\u4fdd\u96c6\u6210\u80fd\u771f\u6b63\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u3002", "method": "\u63d0\u51faALIGN\u65b9\u6cd5\uff0c\u5c06LLM\u63a8\u7406\u5efa\u6a21\u4e3a\u5bf9\u9f50\u59d4\u6258\u6e38\u620f\uff1a\u59d4\u6258\u4eba\u5c06\u4efb\u52a1\u59d4\u6258\u7ed9\u591a\u4e2a\u667a\u80fd\u4f53\uff0c\u667a\u80fd\u4f53\u5728\u8bbe\u8ba1\u597d\u7684\u6fc0\u52b1\u673a\u5236\u4e0b\u751f\u6210\u5019\u9009\u89e3\u51b3\u65b9\u6848\uff0c\u59d4\u6258\u4eba\u4ece\u4e2d\u9009\u62e9\u6700\u7ec8\u7b54\u6848\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u4fdd\u6301\u667a\u80fd\u4f53\u4e0e\u59d4\u6258\u4eba\u76ee\u6807\u5bf9\u9f50\u7684\u540c\u65f6\uff0c\u4fc3\u8fdb\u667a\u80fd\u4f53\u95f4\u7684\u7ed3\u6784\u5316\u4ea4\u4e92\u3002", "result": "\u5728\u540c\u7b49\u8bbf\u95ee\u5019\u9009\u89e3\u51b3\u65b9\u6848\u7684\u516c\u5e73\u6bd4\u8f83\u4e0b\uff0cALIGN\u5728\u7406\u8bba\u4e0a\u80fd\u8bc1\u660e\u6bd4\u5355\u667a\u80fd\u4f53\u751f\u6210\u6709\u66f4\u597d\u7684\u671f\u671b\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u80fd\u5904\u7406\u76f8\u5173\u7684\u5019\u9009\u7b54\u6848\uff0c\u653e\u5bbd\u4e86\u5148\u524d\u5de5\u4f5c\u4e2d\u5e38\u7528\u7684\u72ec\u7acb\u6027\u5047\u8bbe\u3002\u5728\u5e7f\u6cdb\u7684LLM\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cALIGN\u6301\u7eed\u4f18\u4e8e\u5f3a\u5355\u667a\u80fd\u4f53\u548c\u96c6\u6210\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ALIGN\u901a\u8fc7\u5c06LLM\u63a8\u7406\u5f62\u5f0f\u5316\u4e3a\u5bf9\u9f50\u59d4\u6258\u6e38\u620f\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u5b9e\u8df5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e3a\u591a\u667a\u80fd\u4f53LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u6846\u67b6\u3002"}}
{"id": "2602.00128", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.00128", "abs": "https://arxiv.org/abs/2602.00128", "authors": ["Emine Akpinar", "Murat Oduncuoglu"], "title": "Quantum Model Parallelism for MRI-Based Classification of Alzheimer's Disease Stages", "comment": "Under review at Quantum Machine Intelligence (Springer Nature)", "summary": "With increasing life expectancy, AD has become a major global health concern. While classical AI-based methods have been developed for early diagnosis and stage classification of AD, growing data volumes and limited computational resources necessitate faster, more efficient approaches. Quantum-based AI methods, which leverage superposition and entanglement principles along with high-dimensional Hilbert space, can surpass classical approaches' limitations and offer higher accuracy for high-dimensional, heterogeneous, and noisy data. In this study, a Quantum-Based Parallel Model (QBPM) architecture is proposed for the efficient classification of AD stages using MRI datasets, inspired by the principles of classical model parallelism. The proposed model leverages quantum advantages by employing two distinct quantum circuits, each incorporating rotational and entanglement blocks, running in parallel on the same quantum simulator. The classification performance of the model was evaluated on two different datasets to assess its overall robustness and generalization capability. The proposed model demonstrated high classification accuracy across both datasets, highlighting its overall robustness and generalization capability. Results obtained under high-level Gaussian noise, simulating real-world conditions, further provided experimental evidence for the model's applicability not only in theoretical but also in practical scenarios. Moreover, compared with five different classical transfer learning methods, the proposed model demonstrated its efficiency as an alternative to classical approaches by achieving higher classification accuracy and comparable execution time while utilizing fewer circuit parameters. The results indicate that the proposed QBPM architecture represents an innovative and powerful approach for the classification of stages in complex diseases such as Alzheimer's.", "AI": {"tldr": "\u63d0\u51fa\u91cf\u5b50\u5e76\u884c\u6a21\u578b(QBPM)\u7528\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5206\u671f\u5206\u7c7b\uff0c\u5229\u7528\u91cf\u5b50\u53e0\u52a0\u548c\u7ea0\u7f20\u539f\u7406\uff0c\u5728MRI\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5206\u7c7b\uff0c\u76f8\u6bd4\u7ecf\u5178\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u968f\u7740\u5bff\u547d\u5ef6\u957f\uff0c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u6210\u4e3a\u5168\u7403\u91cd\u5927\u5065\u5eb7\u95ee\u9898\u3002\u4f20\u7edfAI\u65b9\u6cd5\u5728\u6570\u636e\u91cf\u589e\u5927\u548c\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u66f4\u5feb\u901f\u9ad8\u6548\u7684\u65b9\u6cd5\u3002\u91cf\u5b50AI\u5229\u7528\u53e0\u52a0\u3001\u7ea0\u7f20\u548c\u9ad8\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u80fd\u8d85\u8d8a\u7ecf\u5178\u65b9\u6cd5\u9650\u5236\uff0c\u5bf9\u9ad8\u7ef4\u3001\u5f02\u6784\u548c\u566a\u58f0\u6570\u636e\u63d0\u4f9b\u66f4\u9ad8\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u91cf\u5b50\u5e76\u884c\u6a21\u578b(QBPM)\u67b6\u6784\uff0c\u53d7\u7ecf\u5178\u6a21\u578b\u5e76\u884c\u539f\u7406\u542f\u53d1\uff0c\u4f7f\u7528\u4e24\u4e2a\u4e0d\u540c\u7684\u91cf\u5b50\u7535\u8def\uff08\u5305\u542b\u65cb\u8f6c\u548c\u7ea0\u7f20\u5757\uff09\uff0c\u5728\u540c\u4e00\u91cf\u5b50\u6a21\u62df\u5668\u4e0a\u5e76\u884c\u8fd0\u884c\uff0c\u7528\u4e8eMRI\u6570\u636e\u96c6\u7684AD\u5206\u671f\u5206\u7c7b\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u5747\u8868\u73b0\u51fa\u9ad8\u5206\u7c7b\u7cbe\u5ea6\uff0c\u663e\u793a\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u5728\u9ad8\u65af\u566a\u58f0\u6a21\u62df\u771f\u5b9e\u573a\u666f\u4e0b\u4ecd\u8868\u73b0\u826f\u597d\u3002\u4e0e\u4e94\u79cd\u7ecf\u5178\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0cQBPM\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5206\u7c7b\u7cbe\u5ea6\u548c\u76f8\u5f53\u7684\u6267\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u4f7f\u7528\u66f4\u5c11\u7684\u7535\u8def\u53c2\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684QBPM\u67b6\u6784\u4ee3\u8868\u4e86\u590d\u6742\u75be\u75c5\uff08\u5982\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff09\u5206\u671f\u5206\u7c7b\u7684\u521b\u65b0\u4e14\u5f3a\u5927\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.00129", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00129", "abs": "https://arxiv.org/abs/2602.00129", "authors": ["Yixuan Liang"], "title": "Monte Carlo Tree Search for Execution-Guided Program Repair with Large Language Models", "comment": "10 pages, 5 figures. Submitted to a conference workshop", "summary": "Automated program repair with large language models remains challenging at the repository level due to long-horizon reasoning requirements and the limitations of autoregressive decoding. We present CodePilot, a hybrid framework that integrates Monte Carlo Tree Search (MCTS) with large language models to enable execution-guided program repair for real-world GitHub issues. CodePilot performs hierarchical fault localization from repository to file and function level, explores diverse patch trajectories using MCTS, and leverages execution feedback as a reward signal to guide search and refinement. The framework further incorporates confidence-calibrated generation to selectively refine low-confidence outputs. Experiments on SWE-bench Lite demonstrate that CodePilot achieves a 24.67% issue resolution rate using open-weight models, outperforming comparable baselines. These results suggest that combining symbolic search with neural language models is an effective strategy for scalable, execution-aware software engineering automation.", "AI": {"tldr": "CodePilot\uff1a\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u6267\u884c\u5f15\u5bfc\u7684\u4ed3\u5e93\u7ea7\u7a0b\u5e8f\u4fee\u590d\uff0c\u5728SWE-bench Lite\u4e0a\u8fbe\u523024.67%\u7684\u95ee\u9898\u89e3\u51b3\u7387", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u5728\u4ed3\u5e93\u7ea7\u522b\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u957f\u65f6\u7a0b\u63a8\u7406\u9700\u6c42\u548c\u81ea\u56de\u5f52\u89e3\u7801\u7684\u9650\u5236\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6267\u884c\u5f15\u5bfc\u4fee\u590d\u65b9\u6cd5", "method": "\u96c6\u6210\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u8fdb\u884c\u4ece\u4ed3\u5e93\u5230\u6587\u4ef6\u518d\u5230\u51fd\u6570\u7684\u5206\u5c42\u6545\u969c\u5b9a\u4f4d\uff0c\u5229\u7528MCTS\u63a2\u7d22\u591a\u6837\u5316\u8865\u4e01\u8f68\u8ff9\uff0c\u5c06\u6267\u884c\u53cd\u9988\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u6307\u5bfc\u641c\u7d22\u548c\u4f18\u5316\uff0c\u5e76\u52a0\u5165\u7f6e\u4fe1\u5ea6\u6821\u51c6\u751f\u6210\u9009\u62e9\u6027\u5730\u4f18\u5316\u4f4e\u7f6e\u4fe1\u5ea6\u8f93\u51fa", "result": "\u5728SWE-bench Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u5b9e\u73b0\u4e8624.67%\u7684\u95ee\u9898\u89e3\u51b3\u7387\uff0c\u4f18\u4e8e\u53ef\u6bd4\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u5c06\u7b26\u53f7\u641c\u7d22\u4e0e\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\u662f\u6784\u5efa\u53ef\u6269\u5c55\u3001\u6267\u884c\u611f\u77e5\u7684\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u7684\u6709\u6548\u7b56\u7565"}}
{"id": "2602.00130", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00130", "abs": "https://arxiv.org/abs/2602.00130", "authors": ["Sumit Yadav"], "title": "On the Relationship Between Representation Geometry and Generalization in Deep Neural Networks", "comment": "ICML", "summary": "We investigate the relationship between representation geometry and neural network performance. Analyzing 52 pretrained ImageNet models across 13 architecture families, we show that effective dimension -- an unsupervised geometric metric -- strongly predicts accuracy. Output effective dimension achieves partial r=0.75 ($p < 10^(-10)$) after controlling for model capacity, while total compression achieves partial r=-0.72. These findings replicate across ImageNet and CIFAR-10, and generalize to NLP: effective dimension predicts performance for 8 encoder models on SST-2/MNLI and 15 decoder-only LLMs on AG News (r=0.69, p=0.004), while model size does not (r=0.07). We establish bidirectional causality: degrading geometry via noise causes accuracy loss (r=-0.94, $p < 10^(-9)$), while improving geometry via PCA maintains accuracy across architectures (-0.03pp at 95% variance). This relationship is noise-type agnostic -- Gaussian, Uniform, Dropout, and Salt-and-pepper noise all show $|r| > 0.90$. These results establish that effective dimension provides domain-agnostic predictive and causal information about neural network performance, computed entirely without labels.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8868\u793a\u51e0\u4f55\u4e2d\u7684\u6709\u6548\u7ef4\u5ea6\u80fd\u5f3a\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\uff0c\u4e14\u5177\u6709\u56e0\u679c\u6027\uff0c\u8fd9\u4e00\u5173\u7cfb\u5728\u89c6\u89c9\u548cNLP\u4efb\u52a1\u4e2d\u90fd\u6210\u7acb\u3002", "motivation": "\u63a2\u7a76\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u51e0\u4f55\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5bfb\u627e\u65e0\u9700\u6807\u7b7e\u5c31\u80fd\u9884\u6d4b\u6a21\u578b\u8868\u73b0\u7684\u51e0\u4f55\u5ea6\u91cf\u3002", "method": "\u5206\u679052\u4e2a\u9884\u8bad\u7ec3ImageNet\u6a21\u578b\u548c13\u79cd\u67b6\u6784\uff0c\u4f7f\u7528\u6709\u6548\u7ef4\u5ea6\u4f5c\u4e3a\u51e0\u4f55\u5ea6\u91cf\uff0c\u5728ImageNet\u3001CIFAR-10\u4ee5\u53caNLP\u4efb\u52a1\uff08SST-2/MNLI\u3001AG News\uff09\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u6dfb\u52a0\u566a\u58f0\u548cPCA\u8fdb\u884c\u56e0\u679c\u6027\u5b9e\u9a8c\u3002", "result": "\u6709\u6548\u7ef4\u5ea6\u4e0e\u51c6\u786e\u7387\u5f3a\u76f8\u5173\uff08r=0.75\uff09\uff0c\u800c\u6a21\u578b\u5927\u5c0f\u4e0d\u76f8\u5173\uff08r=0.07\uff09\u3002\u6dfb\u52a0\u566a\u58f0\u4f1a\u964d\u4f4e\u51e0\u4f55\u8d28\u91cf\u5e76\u635f\u5bb3\u6027\u80fd\uff08r=-0.94\uff09\uff0cPCA\u6539\u5584\u51e0\u4f55\u80fd\u4fdd\u6301\u6027\u80fd\u3002\u8fd9\u79cd\u5173\u7cfb\u5bf9\u566a\u58f0\u7c7b\u578b\u4e0d\u654f\u611f\uff0c\u5728\u89c6\u89c9\u548cNLP\u4efb\u52a1\u4e2d\u90fd\u6210\u7acb\u3002", "conclusion": "\u6709\u6548\u7ef4\u5ea6\u63d0\u4f9b\u4e86\u8de8\u9886\u57df\u7684\u9884\u6d4b\u6027\u548c\u56e0\u679c\u6027\u4fe1\u606f\uff0c\u65e0\u9700\u6807\u7b7e\u5c31\u80fd\u8bc4\u4f30\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\uff0c\u4e3a\u6a21\u578b\u8bc4\u4f30\u548c\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u89c6\u89d2\u3002"}}
{"id": "2602.00158", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00158", "abs": "https://arxiv.org/abs/2602.00158", "authors": ["Ziqi Gao", "Yaotian Zhu", "Qingcheng Zeng", "Xu Zhao", "Ziqing Wang", "Feng Ruan", "Kaize Ding"], "title": "RAPTOR: Ridge-Adaptive Logistic Probes", "comment": "Preprint", "summary": "Probing studies what information is encoded in a frozen LLM's layer representations by training a lightweight predictor on top of them. Beyond analysis, probes are often used operationally in probe-then-steer pipelines: a learned concept vector is extracted from a probe and injected via additive activation steering by adding it to a layer representation during the forward pass. The effectiveness of this pipeline hinges on estimating concept vectors that are accurate, directionally stable under ablation, and inexpensive to obtain. Motivated by these desiderata, we propose RAPTOR (Ridge-Adaptive Logistic Probe), a simple L2-regularized logistic probe whose validation-tuned ridge strength yields concept vectors from normalized weights. Across extensive experiments on instruction-tuned LLMs and human-written concept datasets, RAPTOR matches or exceeds strong baselines in accuracy while achieving competitive directional stability and substantially lower training cost; these quantitative results are supported by qualitative downstream steering demonstrations. Finally, using the Convex Gaussian Min-max Theorem (CGMT), we provide a mechanistic characterization of ridge logistic regression in an idealized Gaussian teacher-student model in the high-dimensional few-shot regime, explaining how penalty strength mediates probe accuracy and concept-vector stability and yielding structural predictions that qualitatively align with trends observed on real LLM embeddings.", "AI": {"tldr": "RAPTOR\u662f\u4e00\u79cd\u57fa\u4e8eL2\u6b63\u5219\u5316\u903b\u8f91\u56de\u5f52\u7684\u8f7b\u91cf\u7ea7\u63a2\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u51bb\u7ed3LLM\u7684\u5c42\u8868\u793a\u4e2d\u63d0\u53d6\u6982\u5ff5\u5411\u91cf\uff0c\u5728\u51c6\u786e\u6027\u3001\u65b9\u5411\u7a33\u5b9a\u6027\u548c\u8bad\u7ec3\u6210\u672c\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u63a2\u6d4b\u65b9\u6cd5\u5728probe-then-steer\u6d41\u7a0b\u4e2d\u9700\u8981\u51c6\u786e\u3001\u65b9\u5411\u7a33\u5b9a\u4e14\u4f4e\u6210\u672c\u7684\u6982\u5ff5\u5411\u91cf\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u4e9b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRAPTOR\u65b9\u6cd5\uff0c\u4f7f\u7528L2\u6b63\u5219\u5316\u903b\u8f91\u56de\u5f52\u63a2\u6d4b\uff0c\u901a\u8fc7\u9a8c\u8bc1\u96c6\u8c03\u4f18\u6b63\u5219\u5316\u5f3a\u5ea6\uff0c\u4ece\u5f52\u4e00\u5316\u6743\u91cd\u4e2d\u63d0\u53d6\u6982\u5ff5\u5411\u91cf\u3002", "result": "\u5728\u6307\u4ee4\u8c03\u4f18LLM\u548c\u4eba\u5de5\u7f16\u5199\u6982\u5ff5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAPTOR\u5728\u51c6\u786e\u6027\u4e0a\u5339\u914d\u6216\u8d85\u8fc7\u5f3a\u57fa\u7ebf\uff0c\u540c\u65f6\u5177\u6709\u7ade\u4e89\u6027\u7684\u65b9\u5411\u7a33\u5b9a\u6027\u548c\u663e\u8457\u66f4\u4f4e\u7684\u8bad\u7ec3\u6210\u672c\u3002", "conclusion": "RAPTOR\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7a33\u5b9a\u7684\u6982\u5ff5\u5411\u91cf\u63d0\u53d6\u65b9\u6cd5\uff0c\u7406\u8bba\u5206\u6790\u89e3\u91ca\u4e86\u6b63\u5219\u5316\u5f3a\u5ea6\u5982\u4f55\u8c03\u8282\u63a2\u6d4b\u51c6\u786e\u6027\u548c\u6982\u5ff5\u5411\u91cf\u7a33\u5b9a\u6027\uff0c\u4e0e\u771f\u5b9eLLM\u5d4c\u5165\u7684\u89c2\u5bdf\u8d8b\u52bf\u4e00\u81f4\u3002"}}
{"id": "2602.00159", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00159", "abs": "https://arxiv.org/abs/2602.00159", "authors": ["Aneeqa Mehrab", "Jan Willem Van Looy", "Pietro Demurtas", "Stefano Iotti", "Emil Malucelli", "Francesca Rossi", "Ferdinando Zanchetta", "Rita Fioresi"], "title": "Sheaf Neural Networks and biomedical applications", "comment": null, "summary": "The purpose of this paper is to elucidate the theory and mathematical modelling behind the sheaf neural network (SNN) algorithm and then show how SNN can effectively answer to biomedical questions in a concrete case study and outperform the most popular graph neural networks (GNNs) as graph convolutional networks (GCNs), graph attention networks (GAT) and GraphSage.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u7406\u8bba\u7684\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5SNN\uff0c\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u5c55\u793a\u5176\u5728\u751f\u7269\u533b\u5b66\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4e3b\u6d41\u56fe\u795e\u7ecf\u7f51\u7edcGCN\u3001GAT\u548cGraphSage\u3002", "motivation": "\u5f53\u524d\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5728\u751f\u7269\u533b\u5b66\u6570\u636e\u5206\u6790\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u6570\u5b66\u6846\u67b6\u6765\u5904\u7406\u590d\u6742\u7684\u751f\u7269\u533b\u5b66\u7f51\u7edc\u7ed3\u6784\u3002\u5c42\u7406\u8bba\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5f3a\u5927\u7684\u6570\u5b66\u5de5\u5177\u6765\u8868\u793a\u548c\u5206\u6790\u590d\u6742\u5173\u7cfb\uff0c\u56e0\u6b64\u5f00\u53d1\u57fa\u4e8e\u5c42\u7406\u8bba\u7684\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u6709\u671b\u63d0\u5347\u751f\u7269\u533b\u5b66\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u5c42\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u7b97\u6cd5\uff0c\u57fa\u4e8e\u5c42\u7406\u8bba\u8fdb\u884c\u6570\u5b66\u5efa\u6a21\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u5c42\u7ed3\u6784\u6765\u8868\u793a\u548c\u5904\u7406\u590d\u6742\u7684\u5173\u7cfb\u7f51\u7edc\uff0c\u901a\u8fc7\u5177\u4f53\u7684\u751f\u7269\u533b\u5b66\u6848\u4f8b\u7814\u7a76\u6765\u9a8c\u8bc1\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0e\u4e3b\u6d41\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GCN\u3001GAT\u3001GraphSage\uff09\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "SNN\u5728\u751f\u7269\u533b\u5b66\u6848\u4f8b\u7814\u7a76\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u56de\u7b54\u751f\u7269\u533b\u5b66\u95ee\u9898\uff0c\u5e76\u4e14\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u6700\u6d41\u884c\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\uff0c\u5305\u62ec\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u3001\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\u548cGraphSage\u3002", "conclusion": "\u5c42\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u57fa\u4e8e\u575a\u5b9e\u7684\u6570\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u5728\u751f\u7269\u533b\u5b66\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u8d85\u8d8a\u73b0\u6709\u4e3b\u6d41\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u4e3a\u590d\u6742\u751f\u7269\u533b\u5b66\u95ee\u9898\u7684\u89e3\u51b3\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.00161", "categories": ["cs.LG", "cs.AI", "cs.CL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.00161", "abs": "https://arxiv.org/abs/2602.00161", "authors": ["David Jansen", "Roman Rausch", "David Montero", "Roman Orus"], "title": "Block removal for large language models through constrained binary optimization", "comment": "7 pages, 5 figures", "summary": "Compressing resource-intensive large language models by removing whole transformer blocks is a seemingly simple idea, but identifying which blocks to remove constitutes an exponentially difficult combinatorial problem. In this paper, we formulate block removal as a constrained binary optimization problem that can be mapped to a physical system (Ising model), whose energies are a strong proxy for downstream model performance. This formulation enables an efficient ranking of a large number of candidate block-removal configurations and yields many high-quality, non-trivial solutions beyond consecutive regions. We demonstrate that our approach outperforms state-of-the-art block-removal methods across several benchmarks, with performance gains persisting after short retraining, and reaching improvements of up to 6 points on the MMLU benchmark. Our method requires only forward and backward passes for a few active parameters, together with an (at least approximate) Ising solver, and can be readily applied to any architecture. We illustrate this generality on the recent NVIDIA-Nemotron-3-Nano-30B-A3B-FP8 model, which exhibits a highly inhomogeneous and challenging block structure.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4f0a\u8f9b\u6a21\u578b\u7684Transformer\u5757\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5757\u79fb\u9664\u95ee\u9898\u8f6c\u5316\u4e3a\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u9ad8\u6548\u8bc6\u522b\u9ad8\u8d28\u91cf\u7684\u975e\u8fde\u7eed\u5757\u79fb\u9664\u65b9\u6848", "motivation": "\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u79fb\u9664\u6574\u4e2aTransformer\u5757\u770b\u4f3c\u7b80\u5355\uff0c\u4f46\u8bc6\u522b\u8981\u79fb\u9664\u54ea\u4e9b\u5757\u6784\u6210\u6307\u6570\u7ea7\u56f0\u96be\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u627e\u5230\u9ad8\u8d28\u91cf\u7684\u975e\u8fde\u7eed\u5757\u79fb\u9664\u65b9\u6848\u3002", "method": "\u5c06\u5757\u79fb\u9664\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u6620\u5c04\u5230\u7269\u7406\u7cfb\u7edf\uff08\u4f0a\u8f9b\u6a21\u578b\uff09\uff0c\u5176\u80fd\u91cf\u662f\u4e0b\u6e38\u6a21\u578b\u6027\u80fd\u7684\u5f3a\u4ee3\u7406\u3002\u4ec5\u9700\u5c11\u91cf\u6d3b\u52a8\u53c2\u6570\u7684\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad\uff0c\u7ed3\u5408\u4f0a\u8f9b\u6c42\u89e3\u5668\u5373\u53ef\u9ad8\u6548\u8bc4\u4f30\u5927\u91cf\u5019\u9009\u914d\u7f6e\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5757\u79fb\u9664\u65b9\u6cd5\uff0c\u6027\u80fd\u589e\u76ca\u5728\u77ed\u671f\u91cd\u8bad\u7ec3\u540e\u4ecd\u4fdd\u6301\uff0c\u5728MMLU\u57fa\u51c6\u4e0a\u63d0\u5347\u9ad8\u8fbe6\u5206\u3002\u6210\u529f\u5e94\u7528\u4e8e\u5177\u6709\u9ad8\u5ea6\u975e\u5747\u5300\u5757\u7ed3\u6784\u7684NVIDIA-Nemotron-3-Nano-30B-A3B-FP8\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u4f0a\u8f9b\u6a21\u578b\u65b9\u6cd5\u80fd\u9ad8\u6548\u8bc6\u522b\u9ad8\u8d28\u91cf\u7684\u975e\u8fde\u7eedTransformer\u5757\u79fb\u9664\u65b9\u6848\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u901a\u7528\u6027\uff0c\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u67b6\u6784\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u538b\u7f29\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00165", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00165", "abs": "https://arxiv.org/abs/2602.00165", "authors": ["Arthur Negr\u00e3o", "Pedro Silva", "Vander L. S. Freitas", "Gladston Moreira", "Eduardo Luz"], "title": "Benford's Law as a Distributional Prior for Post-Training Quantization of Large Language Models", "comment": null, "summary": "The rapid growth of Large Language Models (LLMs) intensifies the need for effective compression, with weight quantization being the most widely adopted technique. Standard uniform quantizers assume that parameters are evenly distributed, an assumption at odds with the highly skewed distributions observed in practice. We propose Benford-Quant, a simple, data-free non-uniform quantizer inspired by Benford's Law, which predicts that leading digits follow a logarithmic distribution. Benford-Quant replaces the uniform grid with a log-spaced codebook, dedicating more resolution to the frequent small-magnitude weights. We provide both theoretical intuition and empirical evidence: (i) weights in transformer transformational layers adhere closely to Benford statistics, while normalization layers systematically deviate; (ii) on Small Language Models (SLMs), Benford-Quant consistently improves perplexity, reducing 4-bit perplexity on Gemma-270M by more than 10%; and (iii) on larger LLMs, it remains competitive, with differences explained by over-parameterization effects. Our results indicate that incorporating a Benford-inspired prior into quantization grids is a low-cost modification that yields accuracy gains in aggressive few-bit regimes. Although it is not able to surpass the state of the art in tasks such as perplexity and LAMBADA, the Benford-Quant approach can be hybridized with other quantization methods-such as SmoothQuant and Activation-Aware Quantization-without major pipeline modification, potentially improving their performance.", "AI": {"tldr": "Benford-Quant\u662f\u4e00\u79cd\u53d7\u672c\u798f\u7279\u5b9a\u5f8b\u542f\u53d1\u7684\u975e\u5747\u5300\u91cf\u5316\u5668\uff0c\u4f7f\u7528\u5bf9\u6570\u95f4\u9694\u7801\u4e66\uff0c\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u4e2d\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u538b\u7f29\u9700\u6c42\u589e\u957f\uff0c\u4f20\u7edf\u5747\u5300\u91cf\u5316\u5668\u5047\u8bbe\u53c2\u6570\u5747\u5300\u5206\u5e03\uff0c\u4f46\u5b9e\u9645\u6743\u91cd\u5206\u5e03\u9ad8\u5ea6\u504f\u659c\uff0c\u9700\u8981\u66f4\u7b26\u5408\u5b9e\u9645\u5206\u5e03\u7684\u91cf\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faBenford-Quant\uff0c\u53d7\u672c\u798f\u7279\u5b9a\u5f8b\u542f\u53d1\uff0c\u4f7f\u7528\u5bf9\u6570\u95f4\u9694\u7801\u4e66\u66ff\u4ee3\u5747\u5300\u7f51\u683c\uff0c\u4e3a\u9891\u7e41\u51fa\u73b0\u7684\u5c0f\u5e45\u503c\u6743\u91cd\u5206\u914d\u66f4\u591a\u5206\u8fa8\u7387\uff0c\u65e0\u9700\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u975e\u5747\u5300\u91cf\u5316\u3002", "result": "\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\uff0cBenford-Quant\u663e\u8457\u964d\u4f4e\u56f0\u60d1\u5ea6\uff08Gemma-270M 4\u4f4d\u91cf\u5316\u56f0\u60d1\u5ea6\u964d\u4f4e\u8d8510%\uff09\uff1b\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff1b\u53ef\u4e0eSmoothQuant\u7b49\u73b0\u6709\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528\u3002", "conclusion": "\u5c06\u672c\u798f\u7279\u5b9a\u5f8b\u5148\u9a8c\u878d\u5165\u91cf\u5316\u7f51\u683c\u662f\u4f4e\u6210\u672c\u4fee\u6539\uff0c\u5728\u6fc0\u8fdb\u7684\u4f4e\u6bd4\u7279\u91cf\u5316\u4e2d\u80fd\u63d0\u5347\u7cbe\u5ea6\uff0c\u867d\u7136\u4e0d\u80fd\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4f46\u53ef\u4e0e\u5176\u4ed6\u91cf\u5316\u6280\u672f\u7ed3\u5408\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2602.00166", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00166", "abs": "https://arxiv.org/abs/2602.00166", "authors": ["Evan Chen", "Wenzhi Fang", "Shiqiang Wang", "Christopher Brinton"], "title": "Joint Continual Learning of Local Language Models and Cloud Offloading Decisions with Budget Constraints", "comment": null, "summary": "Locally deployed Small Language Models (SLMs) must continually support diverse tasks under strict memory and computation constraints, making selective reliance on cloud Large Language Models (LLMs) unavoidable. Regulating cloud assistance during continual learning is challenging, as naive reward-based reinforcement learning often yields unstable offloading behavior and exacerbates catastrophic forgetting as task distributions shift. We propose DA-GRPO, a dual-advantage extension of Group Relative Policy Optimization that incorporates cloud-usage constraints directly into advantage computation, avoiding fixed reward shaping and external routing models. This design enables the local model to jointly learn task competence and collaboration behavior, allowing cloud requests to emerge naturally during post-training while respecting a prescribed assistance budget. Experiments on mathematical reasoning and code generation benchmarks show that DA-GRPO improves post-switch accuracy, substantially reduces forgetting, and maintains stable cloud usage compared to prior collaborative and routing-based approaches.", "AI": {"tldr": "DA-GRPO\u662f\u4e00\u79cd\u7528\u4e8e\u5c0f\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u7684\u53cc\u4f18\u52bf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4e91\u4f7f\u7528\u7ea6\u675f\u76f4\u63a5\u878d\u5165\u4f18\u52bf\u8ba1\u7b97\uff0c\u4f7f\u672c\u5730\u6a21\u578b\u80fd\u540c\u65f6\u5b66\u4e60\u4efb\u52a1\u80fd\u529b\u548c\u534f\u4f5c\u884c\u4e3a\uff0c\u5728\u9884\u7b97\u5185\u81ea\u7136\u8bf7\u6c42\u4e91\u534f\u52a9\u3002", "motivation": "\u672c\u5730\u90e8\u7f72\u7684\u5c0f\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5728\u4e25\u683c\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u9650\u5236\u4e0b\u6301\u7eed\u652f\u6301\u591a\u6837\u5316\u4efb\u52a1\uff0c\u5fc5\u987b\u9009\u62e9\u6027\u5730\u4f9d\u8d56\u4e91\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u3002\u7136\u800c\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u8c03\u8282\u4e91\u534f\u52a9\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u57fa\u4e8e\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u4f1a\u4ea7\u751f\u4e0d\u7a33\u5b9a\u7684\u5378\u8f7d\u884c\u4e3a\uff0c\u5e76\u5728\u4efb\u52a1\u5206\u5e03\u53d8\u5316\u65f6\u52a0\u5267\u707e\u96be\u6027\u9057\u5fd8\u3002", "method": "\u63d0\u51faDA-GRPO\uff08\u53cc\u4f18\u52bf\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff09\uff0c\u8fd9\u662f\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u6269\u5c55\uff0c\u5c06\u4e91\u4f7f\u7528\u7ea6\u675f\u76f4\u63a5\u7eb3\u5165\u4f18\u52bf\u8ba1\u7b97\uff0c\u907f\u514d\u56fa\u5b9a\u7684\u5956\u52b1\u5851\u9020\u548c\u5916\u90e8\u8def\u7531\u6a21\u578b\u3002\u8be5\u8bbe\u8ba1\u4f7f\u672c\u5730\u6a21\u578b\u80fd\u8054\u5408\u5b66\u4e60\u4efb\u52a1\u80fd\u529b\u548c\u534f\u4f5c\u884c\u4e3a\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDA-GRPO\u63d0\u9ad8\u4e86\u5207\u6362\u540e\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9057\u5fd8\uff0c\u5e76\u76f8\u6bd4\u5148\u524d\u7684\u534f\u4f5c\u548c\u57fa\u4e8e\u8def\u7531\u7684\u65b9\u6cd5\u4fdd\u6301\u4e86\u7a33\u5b9a\u7684\u4e91\u4f7f\u7528\u3002", "conclusion": "DA-GRPO\u901a\u8fc7\u5c06\u4e91\u4f7f\u7528\u7ea6\u675f\u76f4\u63a5\u878d\u5165\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u5c0f\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u9884\u7b97\u5185\u81ea\u7136\u8bf7\u6c42\u4e91\u534f\u52a9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u534f\u4f5c\u8c03\u8282\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u9057\u5fd8\u3002"}}
{"id": "2602.00170", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00170", "abs": "https://arxiv.org/abs/2602.00170", "authors": ["Qiyao Liang", "Jinyeop Song", "Yizhou Liu", "Jeff Gore", "Ila Fiete", "Risto Miikkulainen", "Xin Qiu"], "title": "The Blessing of Dimensionality in LLM Fine-tuning: A Variance-Curvature Perspective", "comment": "8 pages, 6 figures, plus appendices", "summary": "Weight-perturbation evolution strategies (ES) can fine-tune billion-parameter language models with surprisingly small populations (e.g., $N\\!\\approx\\!30$), contradicting classical zeroth-order curse-of-dimensionality intuition. We also observe a second seemingly separate phenomenon: under fixed hyperparameters, the stochastic fine-tuning reward often rises, peaks, and then degrades in both ES and GRPO. We argue that both effects reflect a shared geometric property of fine-tuning landscapes: they are low-dimensional in curvature. A small set of high-curvature dimensions dominates improvement, producing (i) heterogeneous time scales that yield rise-then-decay under fixed stochasticity, as captured by a minimal quadratic stochastic-ascent model, and (ii) degenerate improving updates, where many random perturbations share similar components along these directions. Using ES as a geometric probe on fine-tuning reward landscapes of GSM8K, ARC-C, and WinoGrande across Qwen2.5-Instruct models (0.5B--7B), we show that reward-improving perturbations remain empirically accessible with small populations across scales. Together, these results reconcile ES scalability with non-monotonic training dynamics and suggest that high-dimensional fine-tuning may admit a broader class of viable optimization methods than worst-case theory implies.", "AI": {"tldr": "\u6743\u91cd\u6270\u52a8\u8fdb\u5316\u7b56\u7565(ES)\u80fd\u4ee5\u5c0f\u79cd\u7fa4(\u5982N\u224830)\u5fae\u8c03\u6570\u5341\u4ebf\u53c2\u6570\u8bed\u8a00\u6a21\u578b\uff0c\u8fd9\u4e0e\u7ecf\u5178\u96f6\u9636\u4f18\u5316\u7684\u7ef4\u5ea6\u8bc5\u5492\u76f4\u89c9\u76f8\u6096\u3002\u7814\u7a76\u53d1\u73b0\u5956\u52b1\u5148\u5347\u540e\u964d\u7684\u52a8\u6001\u4e0eES\u53ef\u6269\u5c55\u6027\u90fd\u6e90\u4e8e\u5fae\u8c03\u666f\u89c2\u7684\u4f4e\u7ef4\u66f2\u7387\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u4e24\u4e2a\u770b\u4f3c\u77db\u76fe\u7684\u73b0\u8c61\uff1a1) ES\u80fd\u4ee5\u6781\u5c0f\u79cd\u7fa4\u5fae\u8c03\u8d85\u5927\u6a21\u578b\uff0c\u8fdd\u53cd\u7ef4\u5ea6\u8bc5\u5492\u76f4\u89c9\uff1b2) \u56fa\u5b9a\u8d85\u53c2\u6570\u4e0b\u5956\u52b1\u5148\u5347\u540e\u964d\u7684\u975e\u5355\u8c03\u52a8\u6001\u3002\u63a2\u7d22\u8fd9\u4e9b\u73b0\u8c61\u80cc\u540e\u7684\u5171\u540c\u51e0\u4f55\u539f\u7406\u3002", "method": "\u4f7f\u7528ES\u4f5c\u4e3a\u51e0\u4f55\u63a2\u9488\uff0c\u5728GSM8K\u3001ARC-C\u3001WinoGrande\u6570\u636e\u96c6\u4e0a\u5bf9Qwen2.5-Instruct\u6a21\u578b(0.5B-7B)\u7684\u5fae\u8c03\u5956\u52b1\u666f\u89c2\u8fdb\u884c\u5206\u6790\u3002\u63d0\u51fa\u6700\u5c0f\u4e8c\u6b21\u968f\u673a\u4e0a\u5347\u6a21\u578b\u89e3\u91ca\u52a8\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1) \u5956\u52b1\u6539\u8fdb\u6270\u52a8\u5728\u5c0f\u79cd\u7fa4\u4e0b\u4ecd\u53ef\u8bbf\u95ee\uff1b2) \u5fae\u8c03\u666f\u89c2\u5177\u6709\u4f4e\u7ef4\u66f2\u7387\u7279\u6027\uff0c\u5c11\u6570\u9ad8\u66f2\u7387\u7ef4\u5ea6\u4e3b\u5bfc\u6539\u8fdb\uff1b3) \u5f02\u8d28\u65f6\u95f4\u5c3a\u5ea6\u5bfc\u81f4\u5148\u5347\u540e\u964d\u52a8\u6001\uff1b4) \u9000\u5316\u6539\u8fdb\u66f4\u65b0\u4f7f\u591a\u4e2a\u968f\u673a\u6270\u52a8\u5171\u4eab\u76f8\u4f3c\u65b9\u5411\u5206\u91cf\u3002", "conclusion": "ES\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u975e\u5355\u8c03\u8bad\u7ec3\u52a8\u6001\u90fd\u6e90\u4e8e\u5fae\u8c03\u666f\u89c2\u7684\u4f4e\u7ef4\u66f2\u7387\u7279\u6027\u3002\u9ad8\u7ef4\u5fae\u8c03\u53ef\u80fd\u6bd4\u6700\u574f\u60c5\u51b5\u7406\u8bba\u6697\u793a\u7684\u66f4\u6613\u4f18\u5316\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u4f18\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002"}}
{"id": "2602.00173", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00173", "abs": "https://arxiv.org/abs/2602.00173", "authors": ["Shuozhe Li", "Vaishnav Tadiparthi", "Kwonjoon Lee", "Nakul Agarwal", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi Pari", "Lizhang Chen", "Amy Zhang", "Liu Leqi"], "title": "Learning Robust Reasoning through Guided Adversarial Self-Play", "comment": null, "summary": "Reinforcement learning from verifiable rewards (RLVR) produces strong reasoning models, yet they can fail catastrophically when the conditioning context is fallible (e.g., corrupted chain-of-thought, misleading partial solutions, or mild input perturbations), since standard RLVR optimizes final-answer correctness only under clean conditioning. We introduce GASP (Guided Adversarial Self-Play), a robustification method that explicitly trains detect-and-repair capabilities using only outcome verification. Without human labels or external teachers, GASP forms an adversarial self-play game within a single model: a polluter learns to induce failure via locally coherent corruptions, while an agent learns to diagnose and recover under the same corrupted conditioning. To address the scarcity of successful recoveries early in training, we propose in-distribution repair guidance, an imitation term on self-generated repairs that increases recovery probability while preserving previously acquired capabilities. Across four open-weight models (1.5B--8B), GASP transforms strong-but-brittle reasoners into robust ones that withstand misleading and perturbed context while often improving clean accuracy. Further analysis shows that adversarial corruptions induce an effective curriculum, and in-distribution guidance enables rapid recovery learning with minimal representational drift.", "AI": {"tldr": "GASP\u662f\u4e00\u79cd\u901a\u8fc7\u5bf9\u6297\u6027\u81ea\u6211\u535a\u5f08\u8bad\u7ec3\u63a8\u7406\u6a21\u578b\u68c0\u6d4b\u548c\u4fee\u590d\u80fd\u529b\u7684\u9c81\u68d2\u5316\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u7528\u7ed3\u679c\u9a8c\u8bc1\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u7b7e\u6216\u5916\u90e8\u6559\u5e08\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u6a21\u578b\u5728\u6761\u4ef6\u4e0a\u4e0b\u6587\u6709\u7f3a\u9677\u65f6\uff08\u5982\u88ab\u7834\u574f\u7684\u601d\u7ef4\u94fe\u3001\u8bef\u5bfc\u6027\u90e8\u5206\u89e3\u6216\u8f7b\u5fae\u8f93\u5165\u6270\u52a8\uff09\u4f1a\u707e\u96be\u6027\u5931\u8d25\uff0c\u56e0\u4e3a\u6807\u51c6RLVR\u53ea\u4f18\u5316\u5728\u5e72\u51c0\u6761\u4ef6\u4e0b\u7684\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u3002", "method": "GASP\u5728\u5355\u4e2a\u6a21\u578b\u5185\u5f62\u6210\u5bf9\u6297\u6027\u81ea\u6211\u535a\u5f08\u6e38\u620f\uff1a\u6c61\u67d3\u8005\u5b66\u4e60\u901a\u8fc7\u5c40\u90e8\u8fde\u8d2f\u7684\u7834\u574f\u6765\u8bf1\u5bfc\u5931\u8d25\uff0c\u800c\u667a\u80fd\u4f53\u5b66\u4e60\u5728\u76f8\u540c\u7834\u574f\u6761\u4ef6\u4e0b\u8bca\u65ad\u548c\u6062\u590d\u3002\u4e3a\u4e86\u89e3\u51b3\u8bad\u7ec3\u65e9\u671f\u6210\u529f\u6062\u590d\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5206\u5e03\u5185\u4fee\u590d\u6307\u5bfc\uff0c\u8fd9\u662f\u4e00\u79cd\u5bf9\u81ea\u751f\u6210\u4fee\u590d\u7684\u6a21\u4eff\u9879\uff0c\u53ef\u589e\u52a0\u6062\u590d\u6982\u7387\u540c\u65f6\u4fdd\u7559\u5148\u524d\u83b7\u5f97\u7684\u80fd\u529b\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u653e\u6743\u91cd\u6a21\u578b\uff081.5B-8B\uff09\u4e0a\uff0cGASP\u5c06\u5f3a\u4f46\u8106\u5f31\u7684\u63a8\u7406\u5668\u8f6c\u5316\u4e3a\u9c81\u68d2\u7684\u63a8\u7406\u5668\uff0c\u80fd\u591f\u627f\u53d7\u8bef\u5bfc\u548c\u6270\u52a8\u4e0a\u4e0b\u6587\uff0c\u540c\u65f6\u901a\u5e38\u63d0\u9ad8\u5e72\u51c0\u51c6\u786e\u6027\u3002\u5206\u6790\u663e\u793a\u5bf9\u6297\u6027\u7834\u574f\u8bf1\u5bfc\u4e86\u6709\u6548\u7684\u8bfe\u7a0b\u5b66\u4e60\uff0c\u5206\u5e03\u5185\u6307\u5bfc\u5b9e\u73b0\u4e86\u5feb\u901f\u6062\u590d\u5b66\u4e60\u4e14\u8868\u793a\u6f02\u79fb\u6700\u5c0f\u3002", "conclusion": "GASP\u662f\u4e00\u79cd\u6709\u6548\u7684\u9c81\u68d2\u5316\u65b9\u6cd5\uff0c\u4ec5\u901a\u8fc7\u7ed3\u679c\u9a8c\u8bc1\u5c31\u80fd\u8bad\u7ec3\u68c0\u6d4b\u548c\u4fee\u590d\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u76d1\u7763\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6a21\u578b\u5728\u7f3a\u9677\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.00175", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.00175", "abs": "https://arxiv.org/abs/2602.00175", "authors": ["Manyi Li", "Yufan Liu", "Lai Jiang", "Bing Li", "Yuming Li", "Weiming Hu"], "title": "The Illusion of Forgetting: Attack Unlearned Diffusion via Initial Latent Variable Optimization", "comment": "21 pages, 22 figures, 17 tables", "summary": "Although unlearning-based defenses claim to purge Not-Safe-For-Work (NSFW) concepts from diffusion models (DMs), we reveals that this \"forgetting\" is largely an illusion. Unlearning partially disrupts the mapping between linguistic symbols and the underlying knowledge, which remains intact as dormant memories. We find that the distributional discrepancy in the denoising process serves as a measurable indicator of how much of the mapping is retained, also reflecting the strength of unlearning. Inspired by this, we propose IVO (Initial Latent Variable Optimization), a concise and powerful attack framework that reactivates these dormant memories by reconstructing the broken mappings. Through Image Inversion}, Adversarial Optimization and Reused Attack, IVO optimizes initial latent variables to realign the noise distribution of unlearned models with their original unsafe states. Extensive experiments across 8 widely used unlearning techniques demonstrate that IVO achieves superior attack success rates and strong semantic consistency, exposing fundamental flaws in current defenses. The code is available at anonymous.4open.science/r/IVO/. Warning: This paper has unsafe images that may offend some readers.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u6269\u6563\u6a21\u578b\u53cd\u5b66\u4e60\u9632\u5fa1\u7684\u5c40\u9650\u6027\uff1a\u770b\u4f3c\"\u9057\u5fd8\"NSFW\u6982\u5ff5\u5b9e\u9645\u4e0a\u53ea\u662f\u90e8\u5206\u7834\u574f\u4e86\u8bed\u8a00\u7b26\u53f7\u4e0e\u5e95\u5c42\u77e5\u8bc6\u7684\u6620\u5c04\uff0c\u77e5\u8bc6\u672c\u8eab\u4ecd\u4f5c\u4e3a\u4f11\u7720\u8bb0\u5fc6\u5b58\u5728\u3002\u4f5c\u8005\u63d0\u51faIVO\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u521d\u59cb\u6f5c\u5728\u53d8\u91cf\u91cd\u65b0\u6fc0\u6d3b\u8fd9\u4e9b\u8bb0\u5fc6\uff0c\u66b4\u9732\u4e86\u5f53\u524d\u9632\u5fa1\u7684\u6839\u672c\u7f3a\u9677\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u53cd\u5b66\u4e60\u7684\u9632\u5fa1\u58f0\u79f0\u80fd\u591f\u4ece\u6269\u6563\u6a21\u578b\u4e2d\u6e05\u9664NSFW\u6982\u5ff5\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\"\u9057\u5fd8\"\u5f88\u5927\u7a0b\u5ea6\u4e0a\u662f\u4e00\u79cd\u5047\u8c61\u3002\u53cd\u5b66\u4e60\u53ea\u662f\u90e8\u5206\u7834\u574f\u4e86\u8bed\u8a00\u7b26\u53f7\u4e0e\u5e95\u5c42\u77e5\u8bc6\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u800c\u77e5\u8bc6\u672c\u8eab\u4ecd\u7136\u4f5c\u4e3a\u4f11\u7720\u8bb0\u5fc6\u5b58\u5728\u3002\u8fd9\u79cd\u9632\u5fa1\u7684\u8106\u5f31\u6027\u9700\u8981\u88ab\u63ed\u793a\u548c\u9a8c\u8bc1\u3002", "method": "\u63d0\u51faIVO\uff08\u521d\u59cb\u6f5c\u5728\u53d8\u91cf\u4f18\u5316\uff09\u653b\u51fb\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u56fe\u50cf\u53cd\u6f14\uff1a\u5c06\u76ee\u6807\u56fe\u50cf\u53cd\u6f14\u5230\u6f5c\u5728\u7a7a\u95f4\uff1b2\uff09\u5bf9\u6297\u4f18\u5316\uff1a\u4f18\u5316\u521d\u59cb\u6f5c\u5728\u53d8\u91cf\u4ee5\u91cd\u65b0\u5bf9\u9f50\u566a\u58f0\u5206\u5e03\uff1b3\uff09\u91cd\u7528\u653b\u51fb\uff1a\u5229\u7528\u4f18\u5316\u540e\u7684\u6f5c\u5728\u53d8\u91cf\u8fdb\u884c\u653b\u51fb\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6d4b\u91cf\u53bb\u566a\u8fc7\u7a0b\u4e2d\u7684\u5206\u5e03\u5dee\u5f02\u6765\u8bc4\u4f30\u6620\u5c04\u4fdd\u7559\u7a0b\u5ea6\u3002", "result": "\u57288\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u53cd\u5b66\u4e60\u6280\u672f\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0cIVO\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u548c\u5f3a\u5927\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5f53\u524d\u53cd\u5b66\u4e60\u9632\u5fa1\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u65e0\u6cd5\u771f\u6b63\u6d88\u9664\u6a21\u578b\u4e2d\u7684NSFW\u77e5\u8bc6\u3002", "conclusion": "\u53cd\u5b66\u4e60\u9632\u5fa1\u5bf9NSFW\u6982\u5ff5\u7684\"\u9057\u5fd8\"\u662f\u8868\u9762\u7684\uff0c\u5e95\u5c42\u77e5\u8bc6\u4f5c\u4e3a\u4f11\u7720\u8bb0\u5fc6\u4ecd\u7136\u5b58\u5728\u3002IVO\u653b\u51fb\u6846\u67b6\u80fd\u591f\u6709\u6548\u91cd\u65b0\u6fc0\u6d3b\u8fd9\u4e9b\u8bb0\u5fc6\uff0c\u66b4\u9732\u4e86\u5f53\u524d\u9632\u5fa1\u65b9\u6cd5\u7684\u6839\u672c\u5c40\u9650\u6027\u3002\u8fd9\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u5b89\u5168\u9632\u5fa1\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2602.00179", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00179", "abs": "https://arxiv.org/abs/2602.00179", "authors": ["Joseph L. Breeden"], "title": "How Understanding Forecast Uncertainty Resolves the Explainability Problem in Machine Learning Models", "comment": "22 pages; 2 figures", "summary": "For applications of machine learning in critical decisions, explainability is a primary concern, and often a regulatory requirement. Local linear methods for generating explanations, such as LIME and SHAP, have been criticized for being unstable near decision boundaries. In this paper, we explain that such concerns reflect a misunderstanding of the problem. The forecast uncertainty is high at decision boundaries, so consequently, the explanatory instability is high. The correct approach is to change the sequence of events and questions being asked. Nonlinear models can be highly predictive in some regions while having little or no predictability in others. Therefore, the first question is whether a usable forecast exists. When there is a forecast with low enough uncertainty to be useful, an explanation can be sought via a local linear approximation. In such cases, the explanatory instability is correspondingly low. When no usable forecast exists, the decision must fall to a simpler overall model such as traditional logistic regression. Additionally, these results show that some methods that purport to be explainable everywhere, such as ReLU networks or any piecewise linear model, have only an illusory explainability, because the forecast uncertainty at the segment boundaries is too high to be useful. Explaining an unusable forecast is pointless.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u5c40\u90e8\u7ebf\u6027\u89e3\u91ca\u65b9\u6cd5\uff08\u5982LIME\u3001SHAP\uff09\u5728\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u7684\u4e0d\u7a33\u5b9a\u6027\u53cd\u6620\u4e86\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u9ad8\u7684\u95ee\u9898\uff0c\u800c\u975e\u65b9\u6cd5\u7f3a\u9677\u3002\u6b63\u786e\u7684\u505a\u6cd5\u662f\u5148\u8bc4\u4f30\u9884\u6d4b\u662f\u5426\u53ef\u7528\uff0c\u518d\u5bfb\u6c42\u89e3\u91ca\u3002", "motivation": "\u5728\u5173\u952e\u51b3\u7b56\u5e94\u7528\u4e2d\uff0c\u53ef\u89e3\u91ca\u6027\u662f\u4e3b\u8981\u5173\u6ce8\u70b9\uff0c\u4f46\u73b0\u6709\u5c40\u90e8\u7ebf\u6027\u89e3\u91ca\u65b9\u6cd5\u5728\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u88ab\u6279\u8bc4\u4e3a\u4e0d\u7a33\u5b9a\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u6279\u8bc4\u53cd\u6620\u4e86\u5bf9\u95ee\u9898\u7684\u8bef\u89e3\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u89e3\u91ca\u6027\u8bc4\u4f30\u7684\u987a\u5e8f\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u89e3\u91ca\u6027\u8bc4\u4f30\u6846\u67b6\uff1a\u9996\u5148\u8bc4\u4f30\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u53ea\u6709\u5f53\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u8db3\u591f\u4f4e\u3001\u9884\u6d4b\u53ef\u7528\u65f6\uff0c\u624d\u901a\u8fc7\u5c40\u90e8\u7ebf\u6027\u8fd1\u4f3c\u5bfb\u6c42\u89e3\u91ca\u3002\u5982\u679c\u9884\u6d4b\u4e0d\u53ef\u7528\uff0c\u5219\u5e94\u4f7f\u7528\u66f4\u7b80\u5355\u7684\u6574\u4f53\u6a21\u578b\uff08\u5982\u903b\u8f91\u56de\u5f52\uff09\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4f4e\u7684\u533a\u57df\uff0c\u89e3\u91ca\u4e0d\u7a33\u5b9a\u6027\u4e5f\u76f8\u5e94\u8f83\u4f4e\uff1b\u800c\u5728\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\uff0c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u9ad8\uff0c\u89e3\u91ca\u4e0d\u7a33\u5b9a\u6027\u81ea\u7136\u9ad8\u3002\u67d0\u4e9b\u58f0\u79f0\u5904\u5904\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff08\u5982ReLU\u7f51\u7edc\uff09\u5b9e\u9645\u4e0a\u53ea\u662f\u865a\u5047\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u56e0\u4e3a\u5728\u5206\u6bb5\u8fb9\u754c\u5904\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u592a\u9ad8\u800c\u65e0\u6cd5\u4f7f\u7528\u3002", "conclusion": "\u89e3\u91ca\u6027\u8bc4\u4f30\u7684\u6b63\u786e\u987a\u5e8f\u5e94\u8be5\u662f\uff1a\u5148\u5224\u65ad\u9884\u6d4b\u662f\u5426\u53ef\u7528\uff08\u4e0d\u786e\u5b9a\u6027\u662f\u5426\u8db3\u591f\u4f4e\uff09\uff0c\u518d\u5bfb\u6c42\u89e3\u91ca\u3002\u89e3\u91ca\u4e00\u4e2a\u4e0d\u53ef\u7528\u7684\u9884\u6d4b\u662f\u6ca1\u6709\u610f\u4e49\u7684\u3002\u5f53\u975e\u7ebf\u6027\u6a21\u578b\u5728\u67d0\u4e9b\u533a\u57df\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u9ad8\u65f6\uff0c\u5e94\u56de\u5f52\u5230\u66f4\u7b80\u5355\u7684\u6574\u4f53\u6a21\u578b\u8fdb\u884c\u51b3\u7b56\u3002"}}
{"id": "2602.00191", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00191", "abs": "https://arxiv.org/abs/2602.00191", "authors": ["Yadang Alexis Rouzoumka", "Jean Pinsolle", "Eug\u00e9nie Terreaux", "Christ\u00e8le Morisseau", "Jean-Philippe Ovarlez", "Chengfang Ren"], "title": "GEPC: Group-Equivariant Posterior Consistency for Out-of-Distribution Detection in Diffusion Models", "comment": "preprint", "summary": "Diffusion models learn a time-indexed score field $\\mathbf{s}_\u03b8(\\mathbf{x}_t,t)$ that often inherits approximate equivariances (flips, rotations, circular shifts) from in-distribution (ID) data and convolutional backbones. Most diffusion-based out-of-distribution (OOD) detectors exploit score magnitude or local geometry (energies, curvature, covariance spectra) and largely ignore equivariances. We introduce Group-Equivariant Posterior Consistency (GEPC), a training-free probe that measures how consistently the learned score transforms under a finite group $\\mathcal{G}$, detecting equivariance breaking even when score magnitude remains unchanged. At the population level, we propose the ideal GEPC residual, which averages an equivariance-residual functional over $\\mathcal{G}$, and we derive ID upper bounds and OOD lower bounds under mild assumptions. GEPC requires only score evaluations and produces interpretable equivariance-breaking maps. On OOD image benchmark datasets, we show that GEPC achieves competitive or improved AUROC compared to recent diffusion-based baselines while remaining computationally lightweight. On high-resolution synthetic aperture radar imagery where OOD corresponds to targets or anomalies in clutter, GEPC yields strong target-background separation and visually interpretable equivariance-breaking maps. Code is available at https://github.com/RouzAY/gepc-diffusion/.", "AI": {"tldr": "\u63d0\u51faGEPC\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u6269\u6563\u6a21\u578b\u5206\u6570\u573a\u7684\u7fa4\u7b49\u53d8\u6027\u7834\u574f\u6765\u68c0\u6d4bOOD\u6837\u672c\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u4ec5\u9700\u5206\u6570\u8bc4\u4f30", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5229\u7528\u5206\u6570\u5927\u5c0f\u6216\u5c40\u90e8\u51e0\u4f55\u7279\u6027\uff0c\u5ffd\u7565\u4e86\u5206\u6570\u573a\u7684\u7b49\u53d8\u6027\u7279\u6027\u3002\u6269\u6563\u6a21\u578b\u5b66\u4e60\u7684\u5206\u6570\u573a\u901a\u5e38\u4eceID\u6570\u636e\u548c\u5377\u79ef\u4e3b\u5e72\u4e2d\u7ee7\u627f\u8fd1\u4f3c\u7b49\u53d8\u6027\uff0c\u800cOOD\u6837\u672c\u53ef\u80fd\u7834\u574f\u8fd9\u79cd\u7b49\u53d8\u6027", "method": "\u63d0\u51faGroup-Equivariant Posterior Consistency (GEPC)\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d4b\u91cf\u5b66\u4e60\u5230\u7684\u5206\u6570\u5728\u6709\u9650\u7fa4\u53d8\u6362\u4e0b\u7684\u53d8\u6362\u4e00\u81f4\u6027\u6765\u68c0\u6d4b\u7b49\u53d8\u6027\u7834\u574f\u3002\u8ba1\u7b97\u7406\u60f3\u7684GEPC\u6b8b\u5dee\uff0c\u5e73\u5747\u7fa4\u4e0a\u7684\u7b49\u53d8\u6027\u6b8b\u5dee\u6cdb\u51fd", "result": "\u5728OOD\u56fe\u50cf\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cGEPC\u8fbe\u5230\u4e0e\u73b0\u6709\u6269\u6563\u57fa\u7ebf\u7ade\u4e89\u6216\u6539\u8fdb\u7684AUROC\uff0c\u540c\u65f6\u8ba1\u7b97\u8f7b\u91cf\u3002\u5728\u9ad8\u5206\u8fa8\u7387\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u56fe\u50cf\u4e0a\uff0cGEPC\u5b9e\u73b0\u5f3a\u76ee\u6807-\u80cc\u666f\u5206\u79bb\u548c\u89c6\u89c9\u53ef\u89e3\u91ca\u7684\u7b49\u53d8\u6027\u7834\u574f\u56fe", "conclusion": "GEPC\u901a\u8fc7\u68c0\u6d4b\u6269\u6563\u6a21\u578b\u5206\u6570\u573a\u7684\u7fa4\u7b49\u53d8\u6027\u7834\u574f\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u3001\u8f7b\u91cf\u4e14\u53ef\u89e3\u91ca\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u89c6\u89c9\u53ef\u89e3\u91ca\u6027\u7684\u5e94\u7528\u573a\u666f"}}
{"id": "2602.00199", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00199", "abs": "https://arxiv.org/abs/2602.00199", "authors": ["Johanna Marie Gegenfurtner", "Albert Kj\u00f8ller Jacobsen", "Naima Elosegui Borras", "Alejandro Valverde Mahou", "Georgios Arvanitidis"], "title": "Reducing Memorisation in Generative Models via Riemannian Bayesian Inference", "comment": null, "summary": "Modern generative models can produce realistic samples, however, balancing memorisation and generalisation remains an open problem. We approach this challenge from a Bayesian perspective by focusing on the parameter space of flow matching and diffusion models and constructing a predictive posterior that better captures the variability of the data distribution. In particular, we capture the geometry of the loss using a Riemannian metric and leverage a flexible approximate posterior that adapts to the local structure of the loss landscape. This approach allows us to sample generative models that resemble the original model, but exhibit reduced memorisation. Empirically, we demonstrate that the proposed approach reduces memorisation while preserving generalisation. Further, we provide a theoretical analysis of our method, which explains our findings. Overall, our work illustrates how considering the geometry of the loss enables effective use of the parameter space, even for complex high-dimensional generative models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u635f\u5931\u51fd\u6570\u7684\u9ece\u66fc\u51e0\u4f55\u7ed3\u6784\u6765\u6784\u5efa\u9884\u6d4b\u540e\u9a8c\uff0c\u4ece\u800c\u5728\u6d41\u5339\u914d\u548c\u6269\u6563\u6a21\u578b\u4e2d\u5e73\u8861\u8bb0\u5fc6\u4e0e\u6cdb\u5316", "motivation": "\u73b0\u4ee3\u751f\u6210\u6a21\u578b\u867d\u7136\u80fd\u4ea7\u751f\u903c\u771f\u6837\u672c\uff0c\u4f46\u5e73\u8861\u8bb0\u5fc6\u4e0e\u6cdb\u5316\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002\u4f5c\u8005\u4ece\u8d1d\u53f6\u65af\u89c6\u89d2\u51fa\u53d1\uff0c\u5173\u6ce8\u53c2\u6570\u7a7a\u95f4\uff0c\u5e0c\u671b\u6784\u5efa\u80fd\u66f4\u597d\u6355\u6349\u6570\u636e\u5206\u5e03\u53d8\u5f02\u6027\u7684\u9884\u6d4b\u540e\u9a8c", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u5229\u7528\u9ece\u66fc\u5ea6\u91cf\u6355\u6349\u635f\u5931\u51fd\u6570\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u5e76\u91c7\u7528\u80fd\u9002\u5e94\u635f\u5931\u666f\u89c2\u5c40\u90e8\u7ed3\u6784\u7684\u7075\u6d3b\u8fd1\u4f3c\u540e\u9a8c\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u91c7\u6837\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u4f3c\u4f46\u8bb0\u5fc6\u51cf\u5c11\u7684\u751f\u6210\u6a21\u578b", "result": "\u5b9e\u8bc1\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u4fdd\u6301\u6cdb\u5316\u80fd\u529b\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u8bb0\u5fc6\u3002\u7406\u8bba\u5206\u6790\u4e5f\u89e3\u91ca\u4e86\u8fd9\u4e9b\u53d1\u73b0", "conclusion": "\u8003\u8651\u635f\u5931\u51fd\u6570\u7684\u51e0\u4f55\u7ed3\u6784\u80fd\u591f\u6709\u6548\u5229\u7528\u53c2\u6570\u7a7a\u95f4\uff0c\u5373\u4f7f\u5bf9\u4e8e\u590d\u6742\u7684\u9ad8\u7ef4\u751f\u6210\u6a21\u578b\u4e5f\u662f\u5982\u6b64\u3002\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u51e0\u4f55\u89c6\u89d2\u6539\u5584\u751f\u6210\u6a21\u578b\u7684\u8bb0\u5fc6-\u6cdb\u5316\u5e73\u8861"}}
{"id": "2602.00205", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00205", "abs": "https://arxiv.org/abs/2602.00205", "authors": ["Beier Zhu", "Kesen Zhao", "Jiequan Cui", "Qianru Sun", "Yuan Zhou", "Xun Yang", "Hanwang Zhang"], "title": "Reducing Class-Wise Performance Disparity via Margin Regularization", "comment": "To appear in ICLR 2026", "summary": "Deep neural networks often exhibit substantial disparities in class-wise accuracy, even when trained on class-balanced data, posing concerns for reliable deployment. While prior efforts have explored empirical remedies, a theoretical understanding of such performance disparities in classification remains limited. In this work, we present Margin Regularization for Performance Disparity Reduction (MR$^2$), a theoretically principled regularization for classification by dynamically adjusting margins in both the logit and representation spaces. Our analysis establishes a margin-based, class-sensitive generalization bound that reveals how per-class feature variability contributes to error, motivating the use of larger margins for hard classes. Guided by this insight, MR$^2$ optimizes per-class logit margins proportional to feature spread and penalizes excessive representation margins to enhance intra-class compactness. Experiments on seven datasets, including ImageNet, and diverse pre-trained backbones (MAE, MoCov2, CLIP) demonstrate that MR$^2$ not only improves overall accuracy but also significantly boosts hard class performance without trading off easy classes, thus reducing performance disparity. Code is available at: https://github.com/BeierZhu/MR2", "AI": {"tldr": "\u63d0\u51faMR\u00b2\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574logit\u548c\u8868\u793a\u7a7a\u95f4\u7684\u8fb9\u754c\u6765\u51cf\u5c11\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u63d0\u9ad8\u56f0\u96be\u7c7b\u522b\u7684\u51c6\u786e\u7387\u800c\u4e0d\u727a\u7272\u7b80\u5355\u7c7b\u522b\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5373\u4f7f\u5728\u7c7b\u522b\u5e73\u8861\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u4e5f\u7ecf\u5e38\u8868\u73b0\u51fa\u663e\u8457\u7684\u7c7b\u522b\u95f4\u51c6\u786e\u7387\u5dee\u5f02\uff0c\u8fd9\u5bf9\u53ef\u9760\u90e8\u7f72\u6784\u6210\u6311\u6218\u3002\u867d\u7136\u5df2\u6709\u7ecf\u9a8c\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5bf9\u5206\u7c7b\u4e2d\u8fd9\u79cd\u6027\u80fd\u5dee\u5f02\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002", "method": "\u63d0\u51faMR\u00b2\uff08Margin Regularization for Performance Disparity Reduction\uff09\uff0c\u4e00\u79cd\u7406\u8bba\u4e0a\u6709\u539f\u5219\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574logit\u548c\u8868\u793a\u7a7a\u95f4\u7684\u8fb9\u754c\u3002\u5206\u6790\u5efa\u7acb\u4e86\u57fa\u4e8e\u8fb9\u754c\u7684\u7c7b\u522b\u654f\u611f\u6cdb\u5316\u754c\uff0c\u63ed\u793a\u4e86\u6bcf\u7c7b\u7279\u5f81\u53d8\u5f02\u6027\u5982\u4f55\u5f71\u54cd\u8bef\u5dee\uff0c\u4ece\u800c\u6fc0\u52b1\u5bf9\u56f0\u96be\u7c7b\u522b\u4f7f\u7528\u66f4\u5927\u7684\u8fb9\u754c\u3002MR\u00b2\u6839\u636e\u7279\u5f81\u6269\u6563\u6bd4\u4f8b\u4f18\u5316\u6bcf\u7c7blogit\u8fb9\u754c\uff0c\u5e76\u60e9\u7f5a\u8fc7\u5927\u7684\u8868\u793a\u8fb9\u754c\u4ee5\u589e\u5f3a\u7c7b\u5185\u7d27\u51d1\u6027\u3002", "result": "\u5728\u4e03\u4e2a\u6570\u636e\u96c6\uff08\u5305\u62ecImageNet\uff09\u548c\u591a\u79cd\u9884\u8bad\u7ec3\u9aa8\u5e72\u7f51\u7edc\uff08MAE\u3001MoCov2\u3001CLIP\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMR\u00b2\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6574\u4f53\u51c6\u786e\u7387\uff0c\u8fd8\u663e\u8457\u63d0\u5347\u4e86\u56f0\u96be\u7c7b\u522b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u7b80\u5355\u7c7b\u522b\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "MR\u00b2\u901a\u8fc7\u7406\u8bba\u6307\u5bfc\u7684\u8fb9\u754c\u8c03\u6574\u6709\u6548\u51cf\u5c11\u4e86\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4e3a\u6539\u5584\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u7c7b\u522b\u5e73\u8861\u6570\u636e\u4e0a\u7684\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00208", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00208", "abs": "https://arxiv.org/abs/2602.00208", "authors": ["Jordan Levy", "Paul Saves", "Moncef Garouani", "Nicolas Verstaevel", "Benoit Gaudou"], "title": "Analyzing Shapley Additive Explanations to Understand Anomaly Detection Algorithm Behaviors and Their Complementarity", "comment": "Accepted at Intelligent Data Analysis (IDA), 2026", "summary": "Unsupervised anomaly detection is a challenging problem due to the diversity of data distributions and the lack of labels. Ensemble methods are often adopted to mitigate these challenges by combining multiple detectors, which can reduce individual biases and increase robustness. Yet building an ensemble that is genuinely complementary remains challenging, since many detectors rely on similar decision cues and end up producing redundant anomaly scores. As a result, the potential of ensemble learning is often limited by the difficulty of identifying models that truly capture different types of irregularities. To address this, we propose a methodology for characterizing anomaly detectors through their decision mechanisms. Using SHapley Additive exPlanations, we quantify how each model attributes importance to input features, and we use these attribution profiles to measure similarity between detectors. We show that detectors with similar explanations tend to produce correlated anomaly scores and identify largely overlapping anomalies. Conversely, explanation divergence reliably indicates complementary detection behavior. Our results demonstrate that explanation-driven metrics offer a different criterion than raw outputs for selecting models in an ensemble. However, we also demonstrate that diversity alone is insufficient; high individual model performance remains a prerequisite for effective ensembles. By explicitly targeting explanation diversity while maintaining model quality, we are able to construct ensembles that are more diverse, more complementary, and ultimately more effective for unsupervised anomaly detection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSHAP\u89e3\u91ca\u7684\u5f02\u5e38\u68c0\u6d4b\u5668\u7279\u5f81\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u6a21\u578b\u5bf9\u8f93\u5165\u7279\u5f81\u7684\u91cd\u8981\u6027\u5206\u914d\u6765\u6d4b\u91cf\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u4ece\u800c\u6784\u5efa\u66f4\u4e92\u8865\u3001\u66f4\u6709\u6548\u7684\u96c6\u6210\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u9762\u4e34\u6570\u636e\u5206\u5e03\u591a\u6837\u6027\u548c\u7f3a\u4e4f\u6807\u7b7e\u7684\u6311\u6218\u3002\u96c6\u6210\u65b9\u6cd5\u867d\u7136\u80fd\u51cf\u5c11\u4e2a\u4f53\u504f\u5dee\u5e76\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u4f46\u7531\u4e8e\u8bb8\u591a\u68c0\u6d4b\u5668\u4f9d\u8d56\u76f8\u4f3c\u7684\u51b3\u7b56\u7ebf\u7d22\uff0c\u5bfc\u81f4\u4ea7\u751f\u5197\u4f59\u7684\u5f02\u5e38\u5206\u6570\uff0c\u96be\u4ee5\u6784\u5efa\u771f\u6b63\u4e92\u8865\u7684\u96c6\u6210\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528SHAP\uff08SHapley Additive exPlanations\uff09\u91cf\u5316\u6bcf\u4e2a\u6a21\u578b\u5bf9\u8f93\u5165\u7279\u5f81\u7684\u91cd\u8981\u6027\u5206\u914d\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u5f52\u56e0\u914d\u7f6e\u6587\u4ef6\u6d4b\u91cf\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002\u901a\u8fc7\u89e3\u91ca\u9a71\u52a8\u7684\u6307\u6807\u6765\u9009\u62e9\u6a21\u578b\uff0c\u6784\u5efa\u65e2\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u53c8\u5177\u6709\u89e3\u91ca\u591a\u6837\u6027\u7684\u96c6\u6210\u7cfb\u7edf\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5177\u6709\u76f8\u4f3c\u89e3\u91ca\u7684\u68c0\u6d4b\u5668\u503e\u5411\u4e8e\u4ea7\u751f\u76f8\u5173\u7684\u5f02\u5e38\u5206\u6570\u5e76\u8bc6\u522b\u5927\u91cf\u91cd\u53e0\u7684\u5f02\u5e38\uff0c\u800c\u89e3\u91ca\u5dee\u5f02\u53ef\u9760\u5730\u6307\u793a\u4e86\u4e92\u8865\u7684\u68c0\u6d4b\u884c\u4e3a\u3002\u89e3\u91ca\u9a71\u52a8\u7684\u6307\u6807\u4e3a\u96c6\u6210\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u4e0d\u540c\u4e8e\u539f\u59cb\u8f93\u51fa\u7684\u65b0\u6807\u51c6\u3002", "conclusion": "\u901a\u8fc7\u660e\u786e\u9488\u5bf9\u89e3\u91ca\u591a\u6837\u6027\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\uff0c\u80fd\u591f\u6784\u5efa\u66f4\u591a\u6837\u5316\u3001\u66f4\u4e92\u8865\u4e14\u6700\u7ec8\u66f4\u6709\u6548\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u96c6\u6210\u7cfb\u7edf\u3002\u7136\u800c\uff0c\u591a\u6837\u6027\u672c\u8eab\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u6548\u679c\uff0c\u9ad8\u4e2a\u4f53\u6a21\u578b\u6027\u80fd\u4ecd\u7136\u662f\u6709\u6548\u96c6\u6210\u7684\u524d\u63d0\u6761\u4ef6\u3002"}}
{"id": "2602.00217", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00217", "abs": "https://arxiv.org/abs/2602.00217", "authors": ["Chen Liu", "Xingzhi Sun", "Xi Xiao", "Alexandre Van Tassel", "Ke Xu", "Kristof Reimann", "Danqi Liao", "Mark Gerstein", "Tianyang Wang", "Xiao Wang", "Smita Krishnaswamy"], "title": "Dispersion Loss Counteracts Embedding Condensation and Improves Generalization in Small Language Models", "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance through ever-increasing parameter counts, but scaling incurs steep computational costs. To better understand LLM scaling, we study representational differences between LLMs and their smaller counterparts, with the goal of replicating the representational qualities of larger models in the smaller models. We observe a geometric phenomenon which we term $\\textbf{embedding condensation}$, where token embeddings collapse into a narrow cone-like subspace in some language models. Through systematic analyses across multiple Transformer families, we show that small models such as $\\texttt{GPT2}$ and $\\texttt{Qwen3-0.6B}$ exhibit severe condensation, whereas the larger models such as $\\texttt{GPT2-xl}$ and $\\texttt{Qwen3-32B}$ are more resistant to this phenomenon. Additional observations show that embedding condensation is not reliably mitigated by knowledge distillation from larger models. To fight against it, we formulate a dispersion loss that explicitly encourages embedding dispersion during training. Experiments demonstrate that it mitigates condensation, recovers dispersion patterns seen in larger models, and yields performance gains across 10 benchmarks. We believe this work offers a principled path toward improving smaller Transformers without additional parameters.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\"\u5d4c\u5165\u51dd\u805a\"\u73b0\u8c61\uff0c\u5c0f\u6a21\u578btoken\u5d4c\u5165\u4f1a\u574d\u7f29\u5230\u72ed\u7a84\u5b50\u7a7a\u95f4\uff0c\u5927\u6a21\u578b\u5bf9\u6b64\u66f4\u62b5\u6297\u3002\u63d0\u51fa\u5206\u6563\u635f\u5931\u6765\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u589e\u52a0\u53c2\u6570\u83b7\u5f97\u4f18\u5f02\u6027\u80fd\uff0c\u4f46\u6269\u5c55\u5e26\u6765\u9ad8\u6602\u8ba1\u7b97\u6210\u672c\u3002\u4e3a\u4e86\u7406\u89e3LLM\u7f29\u653e\u673a\u5236\uff0c\u7814\u7a76\u5927\u5c0f\u6a21\u578b\u4e4b\u95f4\u7684\u8868\u793a\u5dee\u5f02\uff0c\u76ee\u6807\u662f\u8ba9\u5c0f\u6a21\u578b\u590d\u5236\u5927\u6a21\u578b\u7684\u8868\u793a\u8d28\u91cf\u3002", "method": "\u901a\u8fc7\u8de8\u591a\u4e2aTransformer\u5bb6\u65cf\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u89c2\u5bdf\"\u5d4c\u5165\u51dd\u805a\"\u73b0\u8c61\u3002\u63d0\u51fa\u5206\u6563\u635f\u5931\uff0c\u5728\u8bad\u7ec3\u4e2d\u663e\u5f0f\u9f13\u52b1\u5d4c\u5165\u5206\u6563\uff0c\u5bf9\u6297\u51dd\u805a\u73b0\u8c61\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5206\u6563\u635f\u5931\u80fd\u7f13\u89e3\u51dd\u805a\u73b0\u8c61\uff0c\u6062\u590d\u5927\u6a21\u578b\u4e2d\u7684\u5206\u6563\u6a21\u5f0f\uff0c\u572810\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u6027\u80fd\u63d0\u5347\u3002\u5c0f\u6a21\u578b\u5982GPT2\u548cQwen3-0.6B\u8868\u73b0\u51fa\u4e25\u91cd\u51dd\u805a\uff0c\u800c\u5927\u6a21\u578b\u5982GPT2-xl\u548cQwen3-32B\u5bf9\u6b64\u66f4\u62b5\u6297\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6539\u8fdb\u5c0f\u578bTransformer\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8def\u5f84\uff0c\u65e0\u9700\u989d\u5916\u53c2\u6570\u3002\u5d4c\u5165\u51dd\u805a\u662f\u7406\u89e3\u6a21\u578b\u7f29\u653e\u7684\u91cd\u8981\u73b0\u8c61\uff0c\u5206\u6563\u635f\u5931\u662f\u6709\u6548\u7684\u7f13\u89e3\u65b9\u6cd5\u3002"}}
{"id": "2602.00218", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00218", "abs": "https://arxiv.org/abs/2602.00218", "authors": ["Bob Junyi Zou", "Lu Tian"], "title": "GRIP2: A Robust and Powerful Deep Knockoff Method for Feature Selection", "comment": null, "summary": "Identifying truly predictive covariates while strictly controlling false discoveries remains a fundamental challenge in nonlinear, highly correlated, and low signal-to-noise regimes, where deep learning based feature selection methods are most attractive. We propose Group Regularization Importance Persistence in 2 Dimensions (GRIP2), a deep knockoff feature importance statistic that integrates first-layer feature activity over a two-dimensional regularization surface controlling both sparsity strength and sparsification geometry. To approximate this surface integral in a single training run, we introduce efficient block-stochastic sampling, which aggregates feature activity magnitudes across diverse regularization regimes along the optimization trajectory. The resulting statistics are antisymmetric by construction, ensuring finite-sample FDR control. In extensive experiments on synthetic and semi-real data, GRIP2 demonstrates improved robustness to feature correlation and noise level: in high correlation and low signal-to-noise ratio regimes where standard deep learning based feature selectors may struggle, our method retains high power and stability. Finally, on real-world HIV drug resistance data, GRIP2 recovers known resistance-associated mutations with power better than established linear baselines, confirming its reliability in practice.", "AI": {"tldr": "GRIP2\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e8c\u7ef4\u6b63\u5219\u5316\u8868\u9762\u79ef\u5206\u548c\u5757\u968f\u673a\u91c7\u6837\uff0c\u5728\u975e\u7ebf\u6027\u3001\u9ad8\u76f8\u5173\u3001\u4f4e\u4fe1\u566a\u6bd4\u573a\u666f\u4e0b\u5b9e\u73b0\u9519\u8bef\u53d1\u73b0\u7387\u63a7\u5236\u548c\u9ad8\u7edf\u8ba1\u529f\u6548\u3002", "motivation": "\u5728\u975e\u7ebf\u6027\u3001\u9ad8\u5ea6\u76f8\u5173\u3001\u4f4e\u4fe1\u566a\u6bd4\u7684\u573a\u666f\u4e2d\uff0c\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u9762\u4e34\u63a7\u5236\u9519\u8bef\u53d1\u73b0\u7387\u7684\u57fa\u672c\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u4e9b\u6700\u5177\u5438\u5f15\u529b\u7684\u5e94\u7528\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faGRIP2\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u4e8c\u7ef4\u6b63\u5219\u5316\u8868\u9762\u63a7\u5236\u7a00\u758f\u5f3a\u5ea6\u548c\u7a00\u758f\u5316\u51e0\u4f55\uff1b2\uff09\u5f15\u5165\u5757\u968f\u673a\u91c7\u6837\u5728\u5355\u6b21\u8bad\u7ec3\u4e2d\u8fd1\u4f3c\u8868\u9762\u79ef\u5206\uff1b3\uff09\u6784\u5efa\u53cd\u5bf9\u79f0\u7edf\u8ba1\u91cf\u786e\u4fdd\u6709\u9650\u6837\u672cFDR\u63a7\u5236\u3002", "result": "\u5728\u5408\u6210\u548c\u534a\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u4e2d\uff0cGRIP2\u5728\u9ad8\u76f8\u5173\u548c\u4f4e\u4fe1\u566a\u6bd4\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3001\u66f4\u9ad8\u7684\u7edf\u8ba1\u529f\u6548\u548c\u7a33\u5b9a\u6027\u3002\u5728HIV\u8010\u836f\u6027\u771f\u5b9e\u6570\u636e\u4e2d\uff0c\u6bd4\u4f20\u7edf\u7ebf\u6027\u65b9\u6cd5\u66f4\u597d\u5730\u8bc6\u522b\u5df2\u77e5\u8010\u836f\u7a81\u53d8\u3002", "conclusion": "GRIP2\u901a\u8fc7\u521b\u65b0\u7684\u4e8c\u7ef4\u6b63\u5219\u5316\u8868\u9762\u79ef\u5206\u548c\u5757\u968f\u673a\u91c7\u6837\u6280\u672f\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u9519\u8bef\u53d1\u73b0\u7387\u63a7\u5236\u65b9\u6848\uff0c\u5728\u590d\u6742\u771f\u5b9e\u573a\u666f\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.00240", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00240", "abs": "https://arxiv.org/abs/2602.00240", "authors": ["Md Muhtasim Munif Fahim", "Soyda Humyra Yesmin", "Saiful Islam", "Md. Palash Bin Faruque", "Md. A. Salam", "Md. Mahfuz Uddin", "Samiul Islam", "Tofayel Ahmed", "Md. Binyamin", "Md. Rezaul Karim"], "title": "Green-NAS: A Global-Scale Multi-Objective Neural Architecture Search for Robust and Efficient Edge-Native Weather Forecasting", "comment": null, "summary": "We introduce Green-NAS, a multi-objective NAS (neural architecture search) framework designed for low-resource environments using weather forecasting as a case study. By adhering to 'Green AI' principles, the framework explicitly minimizes computational energy costs and carbon footprints, prioritizing sustainable deployment over raw computational scale. The Green-NAS architecture search method is optimized for both model accuracy and efficiency to find lightweight models with high accuracy and very few model parameters; this is accomplished through an optimization process that simultaneously optimizes multiple objectives. Our best-performing model, Green-NAS-A, achieved an RMSE of 0.0988 (i.e., within 1.4% of our manually tuned baseline) using only 153k model parameters, which is 239 times fewer than other globally applied weather forecasting models, such as GraphCast. In addition, we also describe how the use of transfer learning will improve the weather forecasting accuracy by approximately 5.2%, in comparison to a naive approach of training a new model for each city, when there is limited historical weather data available for that city.", "AI": {"tldr": "Green-NAS\u662f\u4e00\u4e2a\u9762\u5411\u4f4e\u8d44\u6e90\u73af\u5883\u7684\u591a\u76ee\u6807\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u6846\u67b6\uff0c\u4ee5\u5929\u6c14\u9884\u62a5\u4e3a\u6848\u4f8b\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u548c\u8ba1\u7b97\u80fd\u8017\uff0c\u5b9e\u73b0\u7eff\u8272AI\u90e8\u7f72\u3002", "motivation": "\u9488\u5bf9\u4f20\u7edf\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u78b3\u8db3\u8ff9\u95ee\u9898\uff0c\u9075\u5faa\"\u7eff\u8272AI\"\u539f\u5219\uff0c\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u4fdd\u8bc1\u6a21\u578b\u7cbe\u5ea6\u53c8\u80fd\u6700\u5c0f\u5316\u8ba1\u7b97\u80fd\u8017\u548c\u78b3\u6392\u653e\u7684\u53ef\u6301\u7eedNAS\u6846\u67b6\u3002", "method": "\u91c7\u7528\u591a\u76ee\u6807\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u65b9\u6cd5\uff0c\u540c\u65f6\u4f18\u5316\u6a21\u578b\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5bfb\u627e\u8f7b\u91cf\u7ea7\u9ad8\u7cbe\u5ea6\u6a21\u578b\uff1b\u901a\u8fc7\u4f18\u5316\u8fc7\u7a0b\u540c\u65f6\u5904\u7406\u591a\u4e2a\u76ee\u6807\uff0c\u5e76\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\u63d0\u5347\u6570\u636e\u6709\u9650\u60c5\u51b5\u4e0b\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "result": "\u6700\u4f73\u6a21\u578bGreen-NAS-A\u4ec5\u4f7f\u752815.3\u4e07\u53c2\u6570\u5c31\u8fbe\u5230RMSE 0.0988\uff0c\u7cbe\u5ea6\u4e0e\u4eba\u5de5\u8c03\u4f18\u57fa\u7ebf\u76f8\u5dee\u4ec51.4%\uff0c\u53c2\u6570\u6570\u91cf\u6bd4GraphCast\u7b49\u5168\u7403\u5929\u6c14\u9884\u62a5\u6a21\u578b\u5c11239\u500d\uff1b\u8fc1\u79fb\u5b66\u4e60\u53ef\u5c06\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\u7ea65.2%\u3002", "conclusion": "Green-NAS\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u5e73\u8861\u6a21\u578b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u7684\u76ee\u6807\uff0c\u4e3a\u53ef\u6301\u7eedAI\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5929\u6c14\u9884\u62a5\u7b49\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2602.00250", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00250", "abs": "https://arxiv.org/abs/2602.00250", "authors": ["Shreshth Saini", "Avinab Saha", "Balu Adsumilli", "Neil Birkbeck", "Yilin Wang", "Alan C. Bovik"], "title": "TABES: Trajectory-Aware Backward-on-Entropy Steering for Masked Diffusion Models", "comment": null, "summary": "Masked Diffusion Models (MDMs) have emerged as a promising non-autoregressive paradigm for generative tasks, offering parallel decoding and bidirectional context utilization. However, current sampling methods rely on simple confidence-based heuristics that ignore the long-term impact of local decisions, leading to trajectory lock-in where early hallucinations cascade into global incoherence. While search-based methods mitigate this, they incur prohibitive computational costs ($O(K)$ forward passes per step). In this work, we propose Backward-on-Entropy (BoE) Steering, a gradient-guided inference framework that approximates infinite-horizon lookahead via a single backward pass. We formally derive the Token Influence Score (TIS) from a first-order expansion of the trajectory cost functional, proving that the gradient of future entropy with respect to input embeddings serves as an optimal control signal for minimizing uncertainty. To ensure scalability, we introduce \\texttt{ActiveQueryAttention}, a sparse adjoint primitive that exploits the structure of the masking objective to reduce backward pass complexity. BoE achieves a superior Pareto frontier for inference-time scaling compared to existing unmasking methods, demonstrating that gradient-guided steering offers a mathematically principled and efficient path to robust non-autoregressive generation. We will release the code.", "AI": {"tldr": "\u63d0\u51faBackward-on-Entropy (BoE) Steering\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u6b21\u53cd\u5411\u4f20\u64ad\u8fd1\u4f3c\u65e0\u9650\u89c6\u91ce\u524d\u77bb\uff0c\u89e3\u51b3\u63a9\u7801\u6269\u6563\u6a21\u578b\u4e2d\u8f68\u8ff9\u9501\u5b9a\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u975e\u81ea\u56de\u5f52\u751f\u6210\u3002", "motivation": "\u5f53\u524d\u63a9\u7801\u6269\u6563\u6a21\u578b(MDMs)\u7684\u91c7\u6837\u65b9\u6cd5\u4f9d\u8d56\u7b80\u5355\u7684\u7f6e\u4fe1\u5ea6\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u5ffd\u7565\u4e86\u5c40\u90e8\u51b3\u7b56\u7684\u957f\u671f\u5f71\u54cd\uff0c\u5bfc\u81f4\u65e9\u671f\u5e7b\u89c9\u4f1a\u7ea7\u8054\u6210\u5168\u5c40\u4e0d\u4e00\u81f4\u6027\u3002\u867d\u7136\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff08\u6bcf\u6b65\u9700\u8981O(K)\u6b21\u524d\u5411\u4f20\u64ad\uff09\u3002", "method": "\u63d0\u51faBoE Steering\u6846\u67b6\uff0c\u901a\u8fc7\u8f68\u8ff9\u6210\u672c\u51fd\u6570\u7684\u4e00\u9636\u5c55\u5f00\u5f62\u5f0f\u63a8\u5bfc\u51faToken Influence Score (TIS)\uff0c\u8bc1\u660e\u672a\u6765\u71b5\u5bf9\u8f93\u5165\u5d4c\u5165\u7684\u68af\u5ea6\u53ef\u4ee5\u4f5c\u4e3a\u6700\u5c0f\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u6700\u4f18\u63a7\u5236\u4fe1\u53f7\u3002\u5f15\u5165ActiveQueryAttention\u7a00\u758f\u4f34\u968f\u539f\u8bed\uff0c\u5229\u7528\u63a9\u7801\u76ee\u6807\u7684\u7ed3\u6784\u964d\u4f4e\u53cd\u5411\u4f20\u64ad\u590d\u6742\u5ea6\u3002", "result": "BoE\u5728\u63a8\u7406\u65f6\u95f4\u7f29\u653e\u65b9\u9762\u5b9e\u73b0\u4e86\u4f18\u4e8e\u73b0\u6709\u89e3\u63a9\u7801\u65b9\u6cd5\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u8bc1\u660e\u68af\u5ea6\u5f15\u5bfc\u7684\u8f6c\u5411\u4e3a\u9c81\u68d2\u7684\u975e\u81ea\u56de\u5f52\u751f\u6210\u63d0\u4f9b\u4e86\u6570\u5b66\u539f\u7406\u4e25\u8c28\u4e14\u9ad8\u6548\u7684\u8def\u5f84\u3002", "conclusion": "\u68af\u5ea6\u5f15\u5bfc\u7684\u63a8\u7406\u6846\u67b6\u901a\u8fc7\u5355\u6b21\u53cd\u5411\u4f20\u64ad\u8fd1\u4f3c\u65e0\u9650\u89c6\u91ce\u524d\u77bb\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a9\u7801\u6269\u6563\u6a21\u578b\u4e2d\u7684\u8f68\u8ff9\u9501\u5b9a\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2602.00282", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00282", "abs": "https://arxiv.org/abs/2602.00282", "authors": ["Naman Saxena", "Vaneet Aggarwal"], "title": "Sample Complexity Analysis for Constrained Bilevel Reinforcement Learning", "comment": null, "summary": "Several important problem settings within the literature of reinforcement learning (RL), such as meta-learning, hierarchical learning, and RL from human feedback (RL-HF), can be modelled as bilevel RL problems. A lot has been achieved in these domains empirically; however, the theoretical analysis of bilevel RL algorithms hasn't received a lot of attention. In this work, we analyse the sample complexity of a constrained bilevel RL algorithm, building on the progress in the unconstrained setting. We obtain an iteration complexity of $O(\u03b5^{-2})$ and sample complexity of $\\tilde{O}(\u03b5^{-4})$ for our proposed algorithm, Constrained Bilevel Subgradient Optimization (CBSO). We use a penalty-based objective function to avoid the issue of primal-dual gap and hyper-gradient in the context of a constrained bilevel problem setting. The penalty-based formulation to handle constraints requires analysis of non-smooth optimization. We are the first ones to analyse the generally parameterized policy gradient-based RL algorithm with a non-smooth objective function using the Moreau envelope.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7ea6\u675f\u53cc\u5c42\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u63d0\u51fa\u4e86CBSO\u7b97\u6cd5\uff0c\u83b7\u5f97\u4e86O(\u03b5^{-2})\u7684\u8fed\u4ee3\u590d\u6742\u5ea6\u548c\u00d5(\u03b5^{-4})\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u9996\u6b21\u4f7f\u7528Moreau\u5305\u7edc\u5206\u6790\u975e\u5149\u6ed1\u76ee\u6807\u51fd\u6570\u7684\u53c2\u6570\u5316\u7b56\u7565\u68af\u5ea6RL\u7b97\u6cd5\u3002", "motivation": "\u5143\u5b66\u4e60\u3001\u5206\u5c42\u5b66\u4e60\u548c\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u7b49\u8bb8\u591a\u91cd\u8981RL\u95ee\u9898\u90fd\u53ef\u4ee5\u5efa\u6a21\u4e3a\u53cc\u5c42RL\u95ee\u9898\uff0c\u8fd9\u4e9b\u9886\u57df\u5728\u5b9e\u8bc1\u4e0a\u53d6\u5f97\u4e86\u5f88\u5927\u8fdb\u5c55\uff0c\u4f46\u5bf9\u53cc\u5c42RL\u7b97\u6cd5\u7684\u7406\u8bba\u5206\u6790\u5173\u6ce8\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u7ea6\u675f\u53cc\u5c42RL\u7b97\u6cd5\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "method": "\u63d0\u51fa\u7ea6\u675f\u53cc\u5c42\u6b21\u68af\u5ea6\u4f18\u5316\uff08CBSO\uff09\u7b97\u6cd5\uff0c\u4f7f\u7528\u60e9\u7f5a\u76ee\u6807\u51fd\u6570\u907f\u514d\u7ea6\u675f\u53cc\u5c42\u95ee\u9898\u4e2d\u7684\u539f\u59cb\u5bf9\u5076\u95f4\u9699\u548c\u8d85\u68af\u5ea6\u95ee\u9898\u3002\u91c7\u7528Moreau\u5305\u7edc\u5206\u6790\u975e\u5149\u6ed1\u4f18\u5316\u95ee\u9898\uff0c\u8fd9\u662f\u9996\u6b21\u4f7f\u7528Moreau\u5305\u7edc\u5206\u6790\u5177\u6709\u975e\u5149\u6ed1\u76ee\u6807\u51fd\u6570\u7684\u4e00\u822c\u53c2\u6570\u5316\u7b56\u7565\u68af\u5ea6RL\u7b97\u6cd5\u3002", "result": "\u83b7\u5f97\u4e86O(\u03b5^{-2})\u7684\u8fed\u4ee3\u590d\u6742\u5ea6\u548c\u00d5(\u03b5^{-4})\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5728\u7ea6\u675f\u53cc\u5c42RL\u95ee\u9898\u7684\u7406\u8bba\u5206\u6790\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\u3002", "conclusion": "\u672c\u6587\u4e3a\u7ea6\u675f\u53cc\u5c42RL\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u60e9\u7f5a\u51fd\u6570\u548cMoreau\u5305\u7edc\u6280\u672f\u89e3\u51b3\u4e86\u975e\u5149\u6ed1\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5143\u5b66\u4e60\u3001\u5206\u5c42\u5b66\u4e60\u7b49\u9886\u57df\u7684\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2602.00286", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00286", "abs": "https://arxiv.org/abs/2602.00286", "authors": ["Shaorong Zhang", "Longxuan Yu", "Rob Brekelmans", "Luhan Tang", "Salman Asif", "Greg Ver Steeg"], "title": "Generation Order and Parallel Decoding in Masked Diffusion Models: An Information-Theoretic Perspective", "comment": null, "summary": "Masked Diffusion Models (MDMs) significantly accelerate inference by trading off sequential determinism. However, the theoretical mechanisms governing generation order and the risks inherent in parallelization remain under-explored. In this work, we provide a unified information-theoretic framework to decouple and analyze two fundamental sources of failure: order sensitivity and parallelization bias. Our analysis yields three key insights: (1) The benefits of Easy-First decoding (prioritizing low-entropy tokens) are magnified as model error increases; (2) factorized parallel decoding introduces intrinsic sampling errors that can lead to arbitrary large Reverse KL divergence, capturing \"incoherence\" failures that standard Forward KL metrics overlook; and (3) while verification can eliminate sampling error, it incurs an exponential cost governed by the total correlation within a block. Conversely, heuristics like remasking, though computationally efficient, cannot guarantee distributional correctness. Experiments on a controlled Block-HMM and large-scale MDMs (LLaDA) for arithmetic reasoning validate our theoretical framework.", "AI": {"tldr": "MDMs\u52a0\u901f\u63a8\u7406\u4f46\u727a\u7272\u987a\u5e8f\u786e\u5b9a\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790\u987a\u5e8f\u654f\u611f\u6027\u548c\u5e76\u884c\u5316\u504f\u5dee\u4e24\u79cd\u5931\u8d25\u6765\u6e90\uff0c\u53d1\u73b0\u6613\u5148\u89e3\u7801\u5728\u6a21\u578b\u8bef\u5dee\u5927\u65f6\u66f4\u6709\u6548\uff0c\u56e0\u5b50\u5316\u5e76\u884c\u89e3\u7801\u4f1a\u5f15\u5165\u91c7\u6837\u8bef\u5dee\u5bfc\u81f4\u53cd\u5411KL\u6563\u5ea6\u53d1\u6563\uff0c\u9a8c\u8bc1\u53ef\u6d88\u9664\u8bef\u5dee\u4f46\u6307\u6570\u7ea7\u6602\u8d35\u3002", "motivation": "\u63a9\u7801\u6269\u6563\u6a21\u578b(MDMs)\u901a\u8fc7\u727a\u7272\u987a\u5e8f\u786e\u5b9a\u6027\u6765\u52a0\u901f\u63a8\u7406\uff0c\u4f46\u751f\u6210\u987a\u5e8f\u7684\u7406\u8bba\u673a\u5236\u548c\u5e76\u884c\u5316\u98ce\u9669\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u987a\u5e8f\u654f\u611f\u6027\u548c\u5e76\u884c\u5316\u504f\u5dee\u8fd9\u4e24\u79cd\u6839\u672c\u5931\u8d25\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u89e3\u8026\u548c\u5206\u6790\u987a\u5e8f\u654f\u611f\u6027\u548c\u5e76\u884c\u5316\u504f\u5dee\u3002\u5728\u53d7\u63a7\u7684Block-HMM\u548c\u5927\u89c4\u6a21MDMs\uff08LLaDA\uff09\u4e0a\u8fdb\u884c\u7b97\u672f\u63a8\u7406\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u6846\u67b6\u3002", "result": "\u83b7\u5f97\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\uff1a1)\u6613\u5148\u89e3\u7801\uff08\u4f18\u5148\u5904\u7406\u4f4e\u71b5\u6807\u8bb0\uff09\u5728\u6a21\u578b\u8bef\u5dee\u589e\u52a0\u65f6\u6548\u679c\u66f4\u663e\u8457\uff1b2)\u56e0\u5b50\u5316\u5e76\u884c\u89e3\u7801\u5f15\u5165\u5185\u5728\u91c7\u6837\u8bef\u5dee\uff0c\u53ef\u5bfc\u81f4\u4efb\u610f\u5927\u7684\u53cd\u5411KL\u6563\u5ea6\uff0c\u6355\u6349\u6807\u51c6\u524d\u5411KL\u6307\u6807\u5ffd\u7565\u7684\"\u4e0d\u8fde\u8d2f\"\u5931\u8d25\uff1b3)\u9a8c\u8bc1\u53ef\u6d88\u9664\u91c7\u6837\u8bef\u5dee\u4f46\u9700\u8981\u6307\u6570\u7ea7\u6210\u672c\uff0c\u800c\u91cd\u63a9\u7801\u7b49\u542f\u53d1\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u8bc1\u5206\u5e03\u6b63\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u7684\u4fe1\u606f\u8bba\u6846\u67b6\u4e3a\u7406\u89e3MDMs\u4e2d\u7684\u987a\u5e8f\u654f\u611f\u6027\u548c\u5e76\u884c\u5316\u504f\u5dee\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u6613\u5148\u89e3\u7801\u7684\u4f18\u52bf\u6761\u4ef6\u3001\u5e76\u884c\u89e3\u7801\u7684\u98ce\u9669\u4ee5\u53ca\u9a8c\u8bc1\u4e0e\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e4b\u95f4\u7684\u6743\u8861\u3002"}}
{"id": "2602.00297", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00297", "abs": "https://arxiv.org/abs/2602.00297", "authors": ["Jie Yang", "Yifan Hu", "Yuante Li", "Kexin Zhang", "Kaize Ding", "Philip S. Yu"], "title": "From Observations to States: Latent Time Series Forecasting", "comment": null, "summary": "Deep learning has achieved strong performance in Time Series Forecasting (TSF). However, we identify a critical representation paradox, termed Latent Chaos: models with accurate predictions often learn latent representations that are temporally disordered and lack continuity. We attribute this phenomenon to the dominant observation-space forecasting paradigm. Most TSF models minimize point-wise errors on noisy and partially observed data, which encourages shortcut solutions instead of the recovery of underlying system dynamics. To address this issue, we propose Latent Time Series Forecasting (LatentTSF), a novel paradigm that shifts TSF from observation regression to latent state prediction. Specifically, LatentTSF employs an AutoEncoder to project observations at each time step into a higher-dimensional latent state space. This expanded representation aims to capture underlying system variables and impose a smoother temporal structure. Forecasting is then performed entirely in the latent space, allowing the model to focus on learning structured temporal dynamics. Theoretical analysis demonstrates that our proposed latent objectives implicitly maximize mutual information between predicted latent states and ground-truth states and observations. Extensive experiments on widely-used benchmarks confirm that LatentTSF effectively mitigates latent chaos, achieving superior performance. Our code is available in https://github.com/Muyiiiii/LatentTSF.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLatentTSF\u65b0\u8303\u5f0f\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4ece\u89c2\u6d4b\u7a7a\u95f4\u56de\u5f52\u8f6c\u5411\u6f5c\u5728\u72b6\u6001\u9884\u6d4b\uff0c\u89e3\u51b3\"\u6f5c\u5728\u6df7\u6c8c\"\u95ee\u9898\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5b58\u5728\"\u6f5c\u5728\u6df7\u6c8c\"\u95ee\u9898\uff1a\u9884\u6d4b\u51c6\u786e\u7684\u6a21\u578b\u5b66\u4e60\u7684\u6f5c\u5728\u8868\u5f81\u5f80\u5f80\u662f\u65f6\u95f4\u65e0\u5e8f\u4e14\u7f3a\u4e4f\u8fde\u7eed\u6027\u7684\u3002\u8fd9\u662f\u56e0\u4e3a\u4e3b\u6d41\u89c2\u6d4b\u7a7a\u95f4\u9884\u6d4b\u8303\u5f0f\u6700\u5c0f\u5316\u566a\u58f0\u548c\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u7684\u9010\u70b9\u8bef\u5dee\uff0c\u9f13\u52b1\u6377\u5f84\u89e3\u800c\u975e\u6062\u590d\u5e95\u5c42\u7cfb\u7edf\u52a8\u6001\u3002", "method": "\u63d0\u51faLatentTSF\u65b0\u8303\u5f0f\uff0c\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u5c06\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u89c2\u6d4b\u6295\u5f71\u5230\u9ad8\u7ef4\u6f5c\u5728\u72b6\u6001\u7a7a\u95f4\uff0c\u7136\u540e\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u5c06\u9884\u6d4b\u91cd\u70b9\u4ece\u89c2\u6d4b\u56de\u5f52\u8f6c\u5411\u6f5c\u5728\u72b6\u6001\u9884\u6d4b\uff0c\u65e8\u5728\u6355\u83b7\u5e95\u5c42\u7cfb\u7edf\u53d8\u91cf\u5e76\u65bd\u52a0\u66f4\u5e73\u6ed1\u7684\u65f6\u95f4\u7ed3\u6784\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u63d0\u51fa\u7684\u6f5c\u5728\u76ee\u6807\u51fd\u6570\u9690\u5f0f\u6700\u5927\u5316\u9884\u6d4b\u6f5c\u5728\u72b6\u6001\u4e0e\u771f\u5b9e\u72b6\u6001\u53ca\u89c2\u6d4b\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u3002\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u5b9eLatentTSF\u6709\u6548\u7f13\u89e3\u6f5c\u5728\u6df7\u6c8c\uff0c\u5b9e\u73b0\u66f4\u4f18\u6027\u80fd\u3002", "conclusion": "LatentTSF\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4ece\u89c2\u6d4b\u56de\u5f52\u8f6c\u5411\u6f5c\u5728\u72b6\u6001\u9884\u6d4b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6f5c\u5728\u6df7\u6c8c\u95ee\u9898\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.00299", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00299", "abs": "https://arxiv.org/abs/2602.00299", "authors": ["Rituparna Datta", "Zihan Guan", "Baltazar Espinoza", "Yiqi Su", "Priya Pitre", "Srini Venkatramanan", "Naren Ramakrishnan", "Anil Vullikanti"], "title": "Agentic Framework for Epidemiological Modeling", "comment": null, "summary": "Epidemic modeling is essential for public health planning, yet traditional approaches rely on fixed model classes that require manual redesign as pathogens, policies, and scenario assumptions evolve. We introduce EPIAGENT, an agentic framework that automatically synthesizes, calibrates, verifies, and refines epidemiological simulators by modeling disease progression as an iterative program synthesis problem. A central design choice is an explicit epidemiological flow graph intermediate representation that links scenario specifications to model structure and enables strong, modular correctness checks before code is generated. Verified flow graphs are then compiled into mechanistic models supporting interpretable parameter learning under physical and epidemiological constraints. Evaluation on epidemiological scenario case studies demonstrates that EPIAGENT captures complex growth dynamics and produces epidemiologically consistent counterfactual projections across varying vaccination and immune escape assumptions. Our results show that the agentic feedback loop prevents degeneration and significantly accelerates convergence toward valid models by mimicking professional expert workflows.", "AI": {"tldr": "EPIAGENT\u662f\u4e00\u4e2a\u81ea\u52a8\u5408\u6210\u3001\u6821\u51c6\u3001\u9a8c\u8bc1\u548c\u4f18\u5316\u6d41\u884c\u75c5\u5b66\u6a21\u62df\u5668\u7684\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u4e3a\u8fed\u4ee3\u7a0b\u5e8f\u5408\u6210\u95ee\u9898\uff0c\u663e\u8457\u52a0\u901f\u6709\u6548\u6a21\u578b\u7684\u6536\u655b", "motivation": "\u4f20\u7edf\u6d41\u884c\u75c5\u5efa\u6a21\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u6a21\u578b\u7c7b\u522b\uff0c\u9700\u8981\u968f\u7740\u75c5\u539f\u4f53\u3001\u653f\u7b56\u548c\u573a\u666f\u5047\u8bbe\u7684\u53d8\u5316\u800c\u624b\u52a8\u91cd\u65b0\u8bbe\u8ba1\uff0c\u8fd9\u9650\u5236\u4e86\u5efa\u6a21\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387", "method": "\u91c7\u7528\u667a\u80fd\u6846\u67b6\uff0c\u5c06\u75be\u75c5\u8fdb\u5c55\u5efa\u6a21\u4e3a\u8fed\u4ee3\u7a0b\u5e8f\u5408\u6210\u95ee\u9898\uff0c\u4f7f\u7528\u660e\u786e\u7684\u6d41\u884c\u75c5\u5b66\u6d41\u56fe\u4e2d\u95f4\u8868\u793a\u8fde\u63a5\u573a\u666f\u89c4\u8303\u4e0e\u6a21\u578b\u7ed3\u6784\uff0c\u5728\u4ee3\u7801\u751f\u6210\u524d\u8fdb\u884c\u6a21\u5757\u5316\u6b63\u786e\u6027\u68c0\u67e5\uff0c\u7136\u540e\u5c06\u9a8c\u8bc1\u7684\u6d41\u56fe\u7f16\u8bd1\u4e3a\u652f\u6301\u53ef\u89e3\u91ca\u53c2\u6570\u5b66\u4e60\u7684\u673a\u5236\u6a21\u578b", "result": "\u5728\u6d41\u884c\u75c5\u5b66\u573a\u666f\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cEPIAGENT\u80fd\u591f\u6355\u6349\u590d\u6742\u7684\u589e\u957f\u52a8\u6001\uff0c\u5e76\u5728\u4e0d\u540c\u75ab\u82d7\u63a5\u79cd\u548c\u514d\u75ab\u9003\u9038\u5047\u8bbe\u4e0b\u4ea7\u751f\u6d41\u884c\u75c5\u5b66\u4e00\u81f4\u7684\u53cd\u4e8b\u5b9e\u9884\u6d4b\uff0c\u667a\u80fd\u53cd\u9988\u5faa\u73af\u9632\u6b62\u9000\u5316\u5e76\u663e\u8457\u52a0\u901f\u5411\u6709\u6548\u6a21\u578b\u7684\u6536\u655b", "conclusion": "EPIAGENT\u901a\u8fc7\u6a21\u62df\u4e13\u4e1a\u4e13\u5bb6\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5b9e\u73b0\u4e86\u6d41\u884c\u75c5\u5b66\u6a21\u62df\u5668\u7684\u81ea\u52a8\u5408\u6210\u548c\u4f18\u5316\uff0c\u4e3a\u516c\u5171\u536b\u751f\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u5efa\u6a21\u5de5\u5177"}}
{"id": "2602.00302", "categories": ["cs.LG", "cond-mat.dis-nn", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.00302", "abs": "https://arxiv.org/abs/2602.00302", "authors": ["Sam Reifenstein", "Timothee Leleu"], "title": "Neural Ising Machines via Unrolling and Zeroth-Order Training", "comment": null, "summary": "We propose a data-driven heuristic for NP-hard Ising and Max-Cut optimization that learns the update rule of an iterative dynamical system. The method learns a shared, node-wise update rule that maps local interaction fields to spin updates, parameterized by a compact multilayer perceptron with a small number of parameters. Training is performed using a zeroth-order optimizer, since backpropagation through long, recurrent Ising-machine dynamics leads to unstable and poorly informative gradients. We call this approach a neural network parameterized Ising machine (NPIM). Despite its low parameter count, the learned dynamics recover effective algorithmic structure, including momentum-like behavior and time-varying schedules, enabling efficient search in highly non-convex energy landscapes. Across standard Ising and neural combinatorial optimization benchmarks, NPIM achieves competitive solution quality and time-to-solution relative to recent learning-based methods and strong classical Ising-machine heuristics.", "AI": {"tldr": "\u63d0\u51faNPIM\uff08\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u4f0a\u8f9b\u673a\uff09\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u8fed\u4ee3\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u66f4\u65b0\u89c4\u5219\uff0c\u7528\u4e8e\u89e3\u51b3NP\u96be\u7684\u4f0a\u8f9b\u6a21\u578b\u548c\u6700\u5927\u5272\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u4f0a\u8f9b\u673a\u542f\u53d1\u5f0f\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u7b97\u6cd5\u7ed3\u6784\uff0c\u800c\u5b66\u4e60\u578b\u65b9\u6cd5\u901a\u5e38\u53c2\u6570\u8fc7\u591a\u6216\u68af\u5ea6\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u3001\u8bad\u7ec3\u7a33\u5b9a\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6765\u5b66\u4e60\u4f18\u5316\u52a8\u529b\u5b66\u3002", "method": "\u4f7f\u7528\u7d27\u51d1\u7684\u591a\u5c42\u611f\u77e5\u673a\u53c2\u6570\u5316\u8282\u70b9\u7ea7\u66f4\u65b0\u89c4\u5219\uff0c\u5c06\u5c40\u90e8\u4ea4\u4e92\u573a\u6620\u5c04\u5230\u81ea\u65cb\u66f4\u65b0\u3002\u91c7\u7528\u96f6\u9636\u4f18\u5316\u5668\u8bad\u7ec3\uff0c\u907f\u514d\u957f\u5faa\u73af\u52a8\u529b\u5b66\u4e2d\u7684\u68af\u5ea6\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "result": "NPIM\u5728\u6807\u51c6\u4f0a\u8f9b\u548c\u795e\u7ecf\u7ec4\u5408\u4f18\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e\u6700\u8fd1\u7684\u5b66\u4e60\u65b9\u6cd5\u548c\u7ecf\u5178\u4f0a\u8f9b\u673a\u542f\u53d1\u5f0f\u76f8\u6bd4\uff0c\u83b7\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u89e3\u8d28\u91cf\u548c\u6c42\u89e3\u65f6\u95f4\u3002", "conclusion": "NPIM\u901a\u8fc7\u5c11\u91cf\u53c2\u6570\u5b66\u4e60\u6709\u6548\u7684\u7b97\u6cd5\u7ed3\u6784\uff08\u5305\u62ec\u52a8\u91cf\u884c\u4e3a\u548c\u65f6\u53d8\u8c03\u5ea6\uff09\uff0c\u80fd\u591f\u5728\u9ad8\u5ea6\u975e\u51f8\u7684\u80fd\u91cf\u666f\u89c2\u4e2d\u8fdb\u884c\u9ad8\u6548\u641c\u7d22\uff0c\u4e3a\u7ec4\u5408\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002"}}
{"id": "2602.00315", "categories": ["cs.LG", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.00315", "abs": "https://arxiv.org/abs/2602.00315", "authors": ["Arian Khorasani", "Nathaniel Chen", "Yug D Oswal", "Akshat Santhana Gopalan", "Egemen Kolemen", "Ravid Shwartz-Ziv"], "title": "Beyond the Loss Curve: Scaling Laws, Active Learning, and the Limits of Learning from Exact Posteriors", "comment": null, "summary": "How close are neural networks to the best they could possibly do? Standard benchmarks cannot answer this because they lack access to the true posterior p(y|x). We use class-conditional normalizing flows as oracles that make exact posteriors tractable on realistic images (AFHQ, ImageNet). This enables five lines of investigation. Scaling laws: Prediction error decomposes into irreducible aleatoric uncertainty and reducible epistemic error; the epistemic component follows a power law in dataset size, continuing to shrink even when total loss plateaus. Limits of learning: The aleatoric floor is exactly measurable, and architectures differ markedly in how they approach it: ResNets exhibit clean power-law scaling while Vision Transformers stall in low-data regimes. Soft labels: Oracle posteriors contain learnable structure beyond class labels: training with exact posteriors outperforms hard labels and yields near-perfect calibration. Distribution shift: The oracle computes exact KL divergence of controlled perturbations, revealing that shift type matters more than shift magnitude: class imbalance barely affects accuracy at divergence values where input noise causes catastrophic degradation. Active learning: Exact epistemic uncertainty distinguishes genuinely informative samples from inherently ambiguous ones, improving sample efficiency. Our framework reveals that standard metrics hide ongoing learning, mask architectural differences, and cannot diagnose the nature of distribution shift.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u7c7b\u522b\u6761\u4ef6\u5f52\u4e00\u5316\u6d41\u4f5c\u4e3aoracle\uff0c\u5728\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u4e0a\u83b7\u5f97\u7cbe\u786e\u540e\u9a8c\u5206\u5e03\uff0c\u4ece\u800c\u80fd\u591f\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u6027\u80fd\u6781\u9650\uff0c\u5206\u6790\u7f29\u653e\u89c4\u5f8b\u3001\u5b66\u4e60\u6781\u9650\u3001\u8f6f\u6807\u7b7e\u6548\u679c\u3001\u5206\u5e03\u504f\u79fb\u548c\u4e3b\u52a8\u5b66\u4e60\u3002", "motivation": "\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u8bc4\u4f30\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u4e0e\u7406\u8bba\u6700\u4f18\u7684\u5dee\u8ddd\uff0c\u56e0\u4e3a\u5b83\u4eec\u7f3a\u4e4f\u771f\u5b9e\u540e\u9a8c\u5206\u5e03p(y|x)\u7684\u8bbf\u95ee\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u7cbe\u786e\u6d4b\u91cf\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u6781\u9650\u7684\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u7c7b\u522b\u6761\u4ef6\u5f52\u4e00\u5316\u6d41\u4f5c\u4e3aoracle\uff0c\u5728AFHQ\u548cImageNet\u7b49\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u7cbe\u786e\u53ef\u5904\u7406\u7684\u540e\u9a8c\u5206\u5e03\u3002\u901a\u8fc7\u8fd9\u4e2a\u6846\u67b6\u8fdb\u884c\u4e94\u4e2a\u65b9\u9762\u7684\u7814\u7a76\uff1a\u7f29\u653e\u89c4\u5f8b\u3001\u5b66\u4e60\u6781\u9650\u3001\u8f6f\u6807\u7b7e\u6548\u679c\u3001\u5206\u5e03\u504f\u79fb\u5206\u6790\u548c\u4e3b\u52a8\u5b66\u4e60\u3002", "result": "1) \u9884\u6d4b\u8bef\u5dee\u53ef\u5206\u89e3\u4e3a\u4e0d\u53ef\u7ea6\u7684\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u548c\u53ef\u7ea6\u7684\u8ba4\u77e5\u8bef\u5dee\uff1b\u8ba4\u77e5\u8bef\u5dee\u968f\u6570\u636e\u96c6\u5927\u5c0f\u5448\u5e42\u5f8b\u8870\u51cf\uff0c\u5373\u4f7f\u5728\u603b\u635f\u5931\u5e73\u53f0\u671f\u4ecd\u6301\u7eed\u4e0b\u964d\u30022) \u4e0d\u540c\u67b6\u6784\u63a5\u8fd1\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u5f0f\u4e0d\u540c\uff1aResNets\u5448\u73b0\u6e05\u6670\u7684\u5e42\u5f8b\u7f29\u653e\uff0c\u800cVision Transformers\u5728\u4f4e\u6570\u636e\u533a\u57df\u505c\u6ede\u30023) \u4f7f\u7528\u7cbe\u786e\u540e\u9a8c\u4f5c\u4e3a\u8f6f\u6807\u7b7e\u8bad\u7ec3\u4f18\u4e8e\u786c\u6807\u7b7e\uff0c\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6821\u51c6\u30024) \u5206\u5e03\u504f\u79fb\u7c7b\u578b\u6bd4\u504f\u79fb\u5e45\u5ea6\u66f4\u91cd\u8981\u30025) \u7cbe\u786e\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u53ef\u533a\u5206\u4fe1\u606f\u4e30\u5bcc\u6837\u672c\u548c\u56fa\u6709\u6a21\u7cca\u6837\u672c\uff0c\u63d0\u9ad8\u4e3b\u52a8\u5b66\u4e60\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u63ed\u793a\u4e86\u6807\u51c6\u6307\u6807\u9690\u85cf\u4e86\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u3001\u63a9\u76d6\u4e86\u67b6\u6784\u5dee\u5f02\uff0c\u4e14\u65e0\u6cd5\u8bca\u65ad\u5206\u5e03\u504f\u79fb\u7684\u6027\u8d28\u3002\u901a\u8fc7\u7cbe\u786e\u540e\u9a8c\u5206\u6790\uff0c\u80fd\u591f\u66f4\u6df1\u5165\u5730\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u80fd\u529b\u548c\u6027\u80fd\u6781\u9650\u3002"}}
{"id": "2602.00318", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00318", "abs": "https://arxiv.org/abs/2602.00318", "authors": ["Kunal Mukherjee", "Zulfikar Alom", "Tran Gia Bao Ngo", "Cuneyt Gurcan Akcora", "Murat Kantarcioglu"], "title": "Optimal Transport-Guided Adversarial Attacks on Graph Neural Network-Based Bot Detection", "comment": null, "summary": "The rise of bot accounts on social media poses significant risks to public discourse. To address this threat, modern bot detectors increasingly rely on Graph Neural Networks (GNNs). However, the effectiveness of these GNN-based detectors in real-world settings remains poorly understood. In practice, attackers continuously adapt their strategies as well as must operate under domain-specific and temporal constraints, which can fundamentally limit the applicability of existing attack methods. As a result, there is a critical need for robust GNN-based bot detection methods under realistic, constraint-aware attack scenarios.\n  To address this gap, we introduce BOCLOAK to systematically evaluate the robustness of GNN-based social bot detection via both edge editing and node injection adversarial attacks under realistic constraints. BOCLOAK constructs a probability measure over spatio-temporal neighbor features and learns an optimal transport geometry that separates human and bot behaviors. It then decodes transport plans into sparse, plausible edge edits that evade detection while obeying real-world constraints. We evaluate BOCLOAK across three social bot datasets, five state-of-the-art bot detectors, three adversarial defenses, and compare it against four leading graph adversarial attack baselines. BOCLOAK achieves up to 80.13% higher attack success rates while using 99.80% less GPU memory under realistic real-world constraints. Most importantly, BOCLOAK shows that optimal transport provides a lightweight, principled framework for bridging the gap between adversarial attacks and real-world bot detection.", "AI": {"tldr": "BOCLOAK\uff1a\u4e00\u79cd\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u5bf9\u6297\u653b\u51fb\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u8bc4\u4f30GNN\u793e\u4ea4\u673a\u5668\u4eba\u68c0\u6d4b\u5668\u7684\u9c81\u68d2\u6027\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u653b\u51fb\u6210\u529f\u7387\u63d0\u534780.13%\uff0cGPU\u5185\u5b58\u4f7f\u7528\u51cf\u5c1199.80%\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u673a\u5668\u4eba\u8d26\u6237\u5bf9\u516c\u5171\u8bdd\u8bed\u6784\u6210\u5a01\u80c1\uff0cGNN\u68c0\u6d4b\u5668\u88ab\u5e7f\u6cdb\u4f7f\u7528\u4f46\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u672a\u77e5\u3002\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u672a\u8003\u8651\u73b0\u5b9e\u7ea6\u675f\uff08\u9886\u57df\u7279\u5b9a\u548c\u65f6\u95f4\u9650\u5236\uff09\uff0c\u9700\u8981\u8bc4\u4f30GNN\u68c0\u6d4b\u5668\u5728\u7ea6\u675f\u611f\u77e5\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "BOCLOAK\u901a\u8fc7\u6784\u5efa\u65f6\u7a7a\u90bb\u5c45\u7279\u5f81\u7684\u6982\u7387\u5ea6\u91cf\uff0c\u5b66\u4e60\u5206\u79bb\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u884c\u4e3a\u7684\u6700\u4f18\u4f20\u8f93\u51e0\u4f55\u3002\u5c06\u4f20\u8f93\u8ba1\u5212\u89e3\u7801\u4e3a\u7a00\u758f\u3001\u5408\u7406\u7684\u8fb9\u7f16\u8f91\uff0c\u5728\u9075\u5b88\u73b0\u5b9e\u7ea6\u675f\u7684\u540c\u65f6\u89c4\u907f\u68c0\u6d4b\u3002\u652f\u6301\u8fb9\u7f16\u8f91\u548c\u8282\u70b9\u6ce8\u5165\u4e24\u79cd\u5bf9\u6297\u653b\u51fb\u3002", "result": "\u5728\u4e09\u4e2a\u793e\u4ea4\u673a\u5668\u4eba\u6570\u636e\u96c6\u3001\u4e94\u4e2aSOTA\u68c0\u6d4b\u5668\u3001\u4e09\u4e2a\u5bf9\u6297\u9632\u5fa1\u548c\u56db\u4e2a\u57fa\u7ebf\u653b\u51fb\u4e0a\u8bc4\u4f30\u3002BOCLOAK\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u653b\u51fb\u6210\u529f\u7387\u6700\u9ad8\u63d0\u534780.13%\uff0cGPU\u5185\u5b58\u4f7f\u7528\u51cf\u5c1199.80%\u3002\u6700\u4f18\u4f20\u8f93\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u3001\u539f\u5219\u6027\u7684\u6846\u67b6\u3002", "conclusion": "BOCLOAK\u8868\u660e\u6700\u4f18\u4f20\u8f93\u80fd\u591f\u6709\u6548\u5f25\u5408\u5bf9\u6297\u653b\u51fb\u4e0e\u73b0\u5b9e\u673a\u5668\u4eba\u68c0\u6d4b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u8bc4\u4f30GNN\u68c0\u6d4b\u5668\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u3001\u7ea6\u675f\u611f\u77e5\u7684\u6846\u67b6\u3002"}}
{"id": "2602.00328", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00328", "abs": "https://arxiv.org/abs/2602.00328", "authors": ["Nikhil Gopal", "Kostis Kaffes"], "title": "Harvest: Opportunistic Peer-to-Peer GPU Caching for LLM Inference", "comment": null, "summary": "Large Language Model (LLM) inference is increasingly constrained by GPU memory capacity rather than compute throughput, driven by growing model sizes and the linear growth of the key-value (KV) cache during autoregressive decoding. Existing approaches mitigate memory pressure by offloading model state and KV tensors to host memory, but incur substantial latency due to limited PCIe bandwidth. We present Harvest, an opportunistic GPU cache management framework that exploits high-bandwidth peer-to-peer GPU interconnects to dynamically place model weights and KV cache in unused GPU memory. Harvest treats peer GPU memory as a transient cache tier, preserving correctness while reducing data movement overhead under dynamic memory availability. We demonstrate significant throughput speedup of more than 2 times by using Harvest to accelerate the retrieval of two widely-used inference components: expert layer weights and KV cache entries.", "AI": {"tldr": "Harvest\uff1a\u5229\u7528GPU\u95f4\u9ad8\u901f\u4e92\u8054\uff0c\u5c06\u6a21\u578b\u6743\u91cd\u548cKV\u7f13\u5b58\u52a8\u6001\u653e\u7f6e\u5728\u7a7a\u95f2GPU\u5185\u5b58\u4e2d\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u541e\u5410\u91cf", "motivation": "LLM\u63a8\u7406\u8d8a\u6765\u8d8a\u53d7\u9650\u4e8eGPU\u5185\u5b58\u5bb9\u91cf\u800c\u975e\u8ba1\u7b97\u541e\u5410\u91cf\uff0c\u73b0\u6709\u65b9\u6cd5\u5c06\u6a21\u578b\u72b6\u6001\u548cKV\u5f20\u91cf\u5378\u8f7d\u5230\u4e3b\u673a\u5185\u5b58\uff0c\u4f46\u53d7\u9650\u4e8ePCIe\u5e26\u5bbd\u5bfc\u81f4\u5ef6\u8fdf\u663e\u8457\u589e\u52a0", "method": "\u63d0\u51faHarvest\u6846\u67b6\uff0c\u5229\u7528GPU\u95f4\u9ad8\u901f\u5bf9\u7b49\u4e92\u8054\uff0c\u5c06\u6a21\u578b\u6743\u91cd\u548cKV\u7f13\u5b58\u52a8\u6001\u653e\u7f6e\u5728\u7a7a\u95f2GPU\u5185\u5b58\u4e2d\uff0c\u5c06\u540c\u4f34GPU\u5185\u5b58\u4f5c\u4e3a\u4e34\u65f6\u7f13\u5b58\u5c42", "result": "\u901a\u8fc7\u52a0\u901f\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u63a8\u7406\u7ec4\u4ef6\uff08\u4e13\u5bb6\u5c42\u6743\u91cd\u548cKV\u7f13\u5b58\u6761\u76ee\uff09\u7684\u68c0\u7d22\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc72\u500d\u7684\u541e\u5410\u91cf\u52a0\u901f", "conclusion": "Harvest\u6846\u67b6\u901a\u8fc7\u5229\u7528\u7a7a\u95f2GPU\u5185\u5b58\u4f5c\u4e3a\u7f13\u5b58\u5c42\uff0c\u5728\u4fdd\u6301\u6b63\u786e\u6027\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u6570\u636e\u79fb\u52a8\u5f00\u9500\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u6027\u80fd"}}
{"id": "2602.00329", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00329", "abs": "https://arxiv.org/abs/2602.00329", "authors": ["Meng Ding", "Zeqing Zhang", "Di Wang", "Lijie Hu"], "title": "In-Run Data Shapley for Adam Optimizer", "comment": "16 pages", "summary": "Reliable data attribution is essential for mitigating bias and reducing computational waste in modern machine learning, with the Shapley value serving as the theoretical gold standard. While recent \"In-Run\" methods bypass the prohibitive cost of retraining by estimating contributions dynamically, they heavily rely on the linear structure of Stochastic Gradient Descent (SGD) and fail to capture the complex dynamics of adaptive optimizers like Adam. In this work, we demonstrate that data attribution is inherently optimizer-dependent: we show that SGD-based proxies diverge significantly from true contributions under Adam (Pearson $R \\approx 0.11$), rendering them ineffective for modern training pipelines. To bridge this gap, we propose Adam-Aware In-Run Data Shapley. We derive a closed-form approximation that restores additivity by redefining utility under a fixed-state assumption and enable scalable computation via a novel Linearized Ghost Approximation. This technique linearizes the variance-dependent scaling term, allowing us to compute pairwise gradient dot-products without materializing per-sample gradients. Extensive experiments show that our method achieves near-perfect fidelity to ground-truth marginal contributions ($R > 0.99$) while retaining $\\sim$95\\% of standard training throughput. Furthermore, our Adam-aware attribution significantly outperforms SGD-based baselines in data attribution downstream tasks.", "AI": {"tldr": "\u63d0\u51faAdam-Aware In-Run Data Shapley\u65b9\u6cd5\uff0c\u89e3\u51b3\u73b0\u6709\u57fa\u4e8eSGD\u7684\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u5728Adam\u4f18\u5316\u5668\u4e0b\u5931\u6548\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u6570\u636e\u8d21\u732e\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\"In-Run\"\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56SGD\u7684\u7ebf\u6027\u7ed3\u6784\uff0c\u65e0\u6cd5\u6355\u6349Adam\u7b49\u81ea\u9002\u5e94\u4f18\u5316\u5668\u7684\u590d\u6742\u52a8\u6001\uff0c\u5bfc\u81f4\u5728\u73b0\u4ee3\u5316\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u5931\u6548\u3002\u7814\u7a76\u8868\u660e\u6570\u636e\u5f52\u56e0\u672c\u8d28\u4e0a\u662f\u4f18\u5316\u5668\u4f9d\u8d56\u7684\uff0cSGD\u4ee3\u7406\u5728Adam\u4e0b\u4e0e\u771f\u5b9e\u8d21\u732e\u663e\u8457\u504f\u79bb\u3002", "method": "\u63d0\u51faAdam-Aware In-Run Data Shapley\uff1a1\uff09\u901a\u8fc7\u56fa\u5b9a\u72b6\u6001\u5047\u8bbe\u91cd\u65b0\u5b9a\u4e49\u6548\u7528\u51fd\u6570\uff0c\u6062\u590d\u53ef\u52a0\u6027\uff1b2\uff09\u63d0\u51fa\u7ebf\u6027\u5316\u5e7d\u7075\u8fd1\u4f3c\u6280\u672f\uff0c\u7ebf\u6027\u5316\u65b9\u5dee\u4f9d\u8d56\u7684\u7f29\u653e\u9879\uff0c\u65e0\u9700\u5b9e\u4f8b\u5316\u6bcf\u4e2a\u6837\u672c\u7684\u68af\u5ea6\u5373\u53ef\u8ba1\u7b97\u6210\u5bf9\u68af\u5ea6\u70b9\u79ef\u3002", "result": "\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4e0e\u771f\u5b9e\u8fb9\u9645\u8d21\u732e\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u4fdd\u771f\u5ea6\uff08Pearson R > 0.99\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u7ea695%\u7684\u6807\u51c6\u8bad\u7ec3\u541e\u5410\u91cf\u3002\u5728\u6570\u636e\u5f52\u56e0\u4e0b\u6e38\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eSGD\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6570\u636e\u5f52\u56e0\u662f\u4f18\u5316\u5668\u4f9d\u8d56\u7684\uff0c\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u4f18\u5316\u5668\u8bbe\u8ba1\u5f52\u56e0\u65b9\u6cd5\u3002\u63d0\u51fa\u7684Adam\u611f\u77e5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u9002\u5e94\u4f18\u5316\u5668\u4e0b\u7684\u6570\u636e\u5f52\u56e0\u95ee\u9898\uff0c\u4e3a\u73b0\u4ee3\u5316\u8bad\u7ec3\u6d41\u7a0b\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6570\u636e\u8d21\u732e\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2602.00331", "categories": ["cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.00331", "abs": "https://arxiv.org/abs/2602.00331", "authors": ["Anushka Narayanan", "Karianne J. Bergen"], "title": "Prototype-based Explainable Neural Networks with Channel-specific Reasoning for Geospatial Learning Tasks", "comment": "submitted to Environmental Data Science (preprint)", "summary": "Explainable AI (XAI) is essential for understanding machine learning (ML) decision-making and ensuring model trustworthiness in scientific applications. Prototype-based XAI methods offer an intrinsically interpretable alternative to post-hoc approaches which often yield inconsistent explanations. Prototype-based XAI methods make predictions based on the similarity between inputs and learned prototypes that represent typical characteristics of target classes. However, existing prototype-based models are primarily designed for standard RGB image data and are not optimized for the distinct, variable-specific channels commonly found in geoscientific image and raster datasets. In this study, we develop a prototype-based XAI approach tailored for multi-channel geospatial data, where each channel represents a distinct physical environmental variable or spectral channel. Our approach enables the model to identify separate, channel-specific prototypical characteristics sourced from multiple distinct training examples that inform how these features individually and in combination influence model prediction while achieving comparable performance to standard neural networks. We demonstrate this method through two geoscientific case studies: (1) classification of Madden Julian Oscillation phases using multi-variable climate data and (2) land-use classification from multispectral satellite imagery. This approach produces both local (instance-level) and global (model-level) explanations for providing insights into feature-relevance across channels. By explicitly incorporating channel-prototypes into the prediction process, we discuss how this approach enhances the transparency and trustworthiness of ML models for geoscientific learning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u591a\u901a\u9053\u5730\u7406\u7a7a\u95f4\u6570\u636e\u7684\u539f\u578b\u89e3\u91ca\u6027AI\u65b9\u6cd5\uff0c\u901a\u8fc7\u901a\u9053\u7279\u5b9a\u539f\u578b\u589e\u5f3a\u6a21\u578b\u900f\u660e\u5ea6", "motivation": "\u73b0\u6709\u539f\u578bXAI\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u6807\u51c6RGB\u56fe\u50cf\uff0c\u4e0d\u9002\u7528\u4e8e\u5730\u7406\u79d1\u5b66\u4e2d\u5177\u6709\u4e0d\u540c\u7269\u7406\u53d8\u91cf\u7684\u591a\u901a\u9053\u6570\u636e\uff0c\u9700\u8981\u4e13\u95e8\u65b9\u6cd5\u63d0\u9ad8\u5730\u7406\u79d1\u5b66ML\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6", "method": "\u5f00\u53d1\u9488\u5bf9\u591a\u901a\u9053\u5730\u7406\u7a7a\u95f4\u6570\u636e\u7684\u539f\u578bXAI\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u901a\u9053\u4ee3\u8868\u4e0d\u540c\u7684\u7269\u7406\u73af\u5883\u53d8\u91cf\u6216\u5149\u8c31\u901a\u9053\uff0c\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u6765\u81ea\u591a\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u901a\u9053\u7279\u5b9a\u539f\u578b\u7279\u5f81", "result": "\u65b9\u6cd5\u5728\u4e24\u4e2a\u5730\u7406\u79d1\u5b66\u6848\u4f8b\u4e2d\u9a8c\u8bc1\uff1a(1)\u4f7f\u7528\u591a\u53d8\u91cf\u6c14\u5019\u6570\u636e\u5206\u7c7bMadden Julian\u632f\u8361\u76f8\u4f4d\uff0c(2)\u591a\u5149\u8c31\u536b\u661f\u56fe\u50cf\u7684\u571f\u5730\u5229\u7528\u5206\u7c7b\uff0c\u6027\u80fd\u4e0e\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\uff0c\u540c\u65f6\u63d0\u4f9b\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca", "conclusion": "\u901a\u8fc7\u5c06\u901a\u9053\u539f\u578b\u660e\u786e\u7eb3\u5165\u9884\u6d4b\u8fc7\u7a0b\uff0c\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u5730\u7406\u79d1\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2dML\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u591a\u901a\u9053\u5730\u7406\u7a7a\u95f4\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u91ca\u6027AI\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00333", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00333", "abs": "https://arxiv.org/abs/2602.00333", "authors": ["Parmida Davarmanesh", "Ashia Wilson", "Adityanarayanan Radhakrishnan"], "title": "Efficient and accurate steering of Large Language Models through attention-guided feature learning", "comment": null, "summary": "Steering, or direct manipulation of internal activations to guide LLM responses toward specific semantic concepts, is emerging as a promising avenue for both understanding how semantic concepts are stored within LLMs and advancing LLM capabilities. Yet, existing steering methods are remarkably brittle, with seemingly non-steerable concepts becoming completely steerable based on subtle algorithmic choices in how concept-related features are extracted. In this work, we introduce an attention-guided steering framework that overcomes three core challenges associated with steering: (1) automatic selection of relevant token embeddings for extracting concept-related features; (2) accounting for heterogeneity of concept-related features across LLM activations; and (3) identification of layers most relevant for steering. Across a steering benchmark of 512 semantic concepts, our framework substantially improved steering over previous state-of-the-art (nearly doubling the number of successfully steered concepts) across model architectures and sizes (up to 70 billion parameter models). Furthermore, we use our framework to shed light on the distribution of concept-specific features across LLM layers. Overall, our framework opens further avenues for developing efficient, highly-scalable fine-tuning algorithms for industry-scale LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u5f15\u5bfc\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u9009\u62e9\u76f8\u5173token\u5d4c\u5165\u3001\u8003\u8651\u7279\u5f81\u5f02\u8d28\u6027\u548c\u8bc6\u522b\u5173\u952e\u5c42\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4e2d\u8bed\u4e49\u6982\u5ff5\u7684\u5f15\u5bfc\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5f15\u5bfc\u65b9\u6cd5\u975e\u5e38\u8106\u5f31\uff0c\u5bf9\u6982\u5ff5\u76f8\u5173\u7279\u5f81\u7684\u63d0\u53d6\u65b9\u5f0f\u6781\u5176\u654f\u611f\uff0c\u5bfc\u81f4\u8bb8\u591a\u6982\u5ff5\u770b\u4f3c\u4e0d\u53ef\u5f15\u5bfc\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u6846\u67b6\u6765\u89e3\u51b3\u7279\u5f81\u63d0\u53d6\u3001\u7279\u5f81\u5f02\u8d28\u6027\u548c\u5173\u952e\u5c42\u8bc6\u522b\u8fd9\u4e09\u4e2a\u6838\u5fc3\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u5f15\u5bfc\u6846\u67b6\uff1a1) \u81ea\u52a8\u9009\u62e9\u76f8\u5173token\u5d4c\u5165\u6765\u63d0\u53d6\u6982\u5ff5\u76f8\u5173\u7279\u5f81\uff1b2) \u8003\u8651\u6982\u5ff5\u76f8\u5173\u7279\u5f81\u5728LLM\u6fc0\u6d3b\u4e2d\u7684\u5f02\u8d28\u6027\uff1b3) \u8bc6\u522b\u6700\u9002\u5408\u5f15\u5bfc\u7684\u5c42\u3002\u5728512\u4e2a\u8bed\u4e49\u6982\u5ff5\u7684\u5f15\u5bfc\u57fa\u51c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u6846\u67b6\u663e\u8457\u8d85\u8d8a\u4e86\u5148\u524d\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u6210\u529f\u5f15\u5bfc\u7684\u6982\u5ff5\u6570\u91cf\u51e0\u4e4e\u7ffb\u500d\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u67b6\u6784\u548c\u5927\u5c0f\u7684\u6a21\u578b\uff08\u5305\u62ec\u9ad8\u8fbe700\u4ebf\u53c2\u6570\u7684\u6a21\u578b\uff09\u3002\u540c\u65f6\u63ed\u793a\u4e86\u6982\u5ff5\u7279\u5b9a\u7279\u5f81\u5728LLM\u5c42\u95f4\u7684\u5206\u5e03\u89c4\u5f8b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u9ad8\u6548\u3001\u9ad8\u5ea6\u53ef\u6269\u5c55\u7684\u884c\u4e1a\u7ea7LLM\u5fae\u8c03\u7b97\u6cd5\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u540c\u65f6\u6709\u52a9\u4e8e\u7406\u89e3\u8bed\u4e49\u6982\u5ff5\u5728LLM\u4e2d\u7684\u5b58\u50a8\u673a\u5236\u3002"}}
{"id": "2602.00334", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.00334", "abs": "https://arxiv.org/abs/2602.00334", "authors": ["Aikaterini Karoni", "Rajit Rajpal", "Benedict Leimkuhler", "Gabriel Stoltz"], "title": "Adaptive Momentum and Nonlinear Damping for Neural Network Training", "comment": "29 pages, 11 figures", "summary": "We propose a continuous-time scheme for large-scale optimization that introduces individual, adaptive momentum coefficients regulated by the kinetic energy of each model parameter. This approach automatically adjusts to local landscape curvature to maintain stability without sacrificing convergence speed. We demonstrate that our adaptive friction can be related to cubic damping, a suppression mechanism from structural dynamics. Furthermore, we introduce two specific optimization schemes by augmenting the continuous dynamics of mSGD and Adam with a cubic damping term. Empirically, our methods demonstrate robustness and match or outperform Adam on training ViT, BERT, and GPT2 tasks where mSGD typically struggles. We further provide theoretical results establishing the exponential convergence of the proposed schemes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8fde\u7eed\u65f6\u95f4\u4f18\u5316\u65b9\u6848\uff0c\u4e3a\u6bcf\u4e2a\u6a21\u578b\u53c2\u6570\u5f15\u5165\u7531\u52a8\u80fd\u8c03\u8282\u7684\u81ea\u9002\u5e94\u52a8\u91cf\u7cfb\u6570\uff0c\u81ea\u52a8\u9002\u5e94\u5c40\u90e8\u66f2\u7387\u4ee5\u4fdd\u6301\u7a33\u5b9a\u6027\u800c\u4e0d\u727a\u7272\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5982mSGD\u5728\u8bad\u7ec3\u5927\u578b\u6a21\u578b\uff08\u5982ViT\u3001BERT\u3001GPT2\uff09\u65f6\u5b58\u5728\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u52a8\u9002\u5e94\u5c40\u90e8\u66f2\u7387\u3001\u4fdd\u6301\u7a33\u5b9a\u6027\u7684\u81ea\u9002\u5e94\u4f18\u5316\u65b9\u6848\u3002", "method": "1. \u63d0\u51fa\u8fde\u7eed\u65f6\u95f4\u4f18\u5316\u65b9\u6848\uff0c\u4e3a\u6bcf\u4e2a\u53c2\u6570\u5f15\u5165\u7531\u52a8\u80fd\u8c03\u8282\u7684\u81ea\u9002\u5e94\u52a8\u91cf\u7cfb\u6570\uff1b2. \u5c06\u81ea\u9002\u5e94\u6469\u64e6\u4e0e\u7ed3\u6784\u52a8\u529b\u5b66\u4e2d\u7684\u7acb\u65b9\u963b\u5c3c\u8054\u7cfb\u8d77\u6765\uff1b3. \u901a\u8fc7\u5728mSGD\u548cAdam\u7684\u8fde\u7eed\u52a8\u529b\u5b66\u4e2d\u589e\u52a0\u7acb\u65b9\u963b\u5c3c\u9879\uff0c\u63d0\u51fa\u4e24\u79cd\u5177\u4f53\u4f18\u5316\u65b9\u6848\u3002", "result": "1. \u5728ViT\u3001BERT\u3001GPT2\u8bad\u7ec3\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u5339\u914d\u6216\u4f18\u4e8eAdam\u6027\u80fd\uff1b2. \u5728mSGD\u901a\u5e38\u8868\u73b0\u4e0d\u4f73\u7684\u4efb\u52a1\u4e0a\u53d6\u5f97\u826f\u597d\u6548\u679c\uff1b3. \u7406\u8bba\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6848\u7684\u6307\u6570\u6536\u655b\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u52a8\u80fd\u8c03\u8282\u81ea\u9002\u5e94\u52a8\u91cf\u7684\u8fde\u7eed\u65f6\u95f4\u4f18\u5316\u65b9\u6848\uff0c\u901a\u8fc7\u7acb\u65b9\u963b\u5c3c\u673a\u5236\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6027\u4e0e\u6536\u655b\u901f\u5ea6\u7684\u5e73\u8861\uff0c\u5728\u5927\u578b\u6a21\u578b\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u6709\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u3002"}}
{"id": "2602.00357", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00357", "abs": "https://arxiv.org/abs/2602.00357", "authors": ["Chenyang Yuan", "Xiaoyuan Cheng"], "title": "Planning with Language and Generative Models: Toward General Reward-Guided Wireless Network Design", "comment": null, "summary": "Intelligent access point (AP) deployment remains challenging in next-generation wireless networks due to complex indoor geometries and signal propagation. We firstly benchmark general-purpose large language models (LLMs) as agentic optimizers for AP planning and find that, despite strong wireless domain knowledge, their dependence on external verifiers results in high computational costs and limited scalability. Motivated by these limitations, we study generative inference models guided by a unified reward function capturing core AP deployment objectives across diverse floorplans. We show that diffusion samplers consistently outperform alternative generative approaches. The diffusion process progressively improves sampling by smoothing and sharpening the reward landscape, rather than relying on iterative refinement, which is effective for non-convex and fragmented objectives. Finally, we introduce a large-scale real-world dataset for indoor AP deployment, requiring over $50k$ CPU hours to train general reward functions, and evaluate in- and out-of-distribution generalization and robustness. Our results suggest that diffusion-based generative inference with a unified reward function provides a scalable and domain-agnostic foundation for indoor AP deployment planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u751f\u6210\u63a8\u7406\u65b9\u6cd5\uff0c\u914d\u5408\u7edf\u4e00\u7684\u5956\u52b1\u51fd\u6570\uff0c\u6765\u89e3\u51b3\u5ba4\u5185\u667a\u80fdAP\u90e8\u7f72\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edfLLM\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0c\u590d\u6742\u7684\u5ba4\u5185\u51e0\u4f55\u7ed3\u6784\u548c\u4fe1\u53f7\u4f20\u64ad\u4f7f\u5f97\u667a\u80fdAP\u90e8\u7f72\u5177\u6709\u6311\u6218\u6027\u3002\u4f5c\u8005\u9996\u5148\u6d4b\u8bd5\u4e86\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3aAP\u89c4\u5212\u4f18\u5316\u5668\uff0c\u53d1\u73b0\u5c3d\u7ba1\u5b83\u4eec\u5177\u5907\u5f3a\u5927\u7684\u65e0\u7ebf\u9886\u57df\u77e5\u8bc6\uff0c\u4f46\u5bf9\u5916\u90e8\u9a8c\u8bc1\u5668\u7684\u4f9d\u8d56\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u6709\u9650\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u7814\u7a76\u57fa\u4e8e\u7edf\u4e00\u5956\u52b1\u51fd\u6570\u7684\u751f\u6210\u63a8\u7406\u6a21\u578b\uff0c\u8be5\u51fd\u6570\u6355\u6349\u4e86\u4e0d\u540c\u5e73\u9762\u56fe\u4e2dAP\u90e8\u7f72\u7684\u6838\u5fc3\u76ee\u6807\u3002\u91c7\u7528\u6269\u6563\u91c7\u6837\u5668\uff0c\u901a\u8fc7\u5e73\u6ed1\u548c\u9510\u5316\u5956\u52b1\u666f\u89c2\u9010\u6b65\u6539\u8fdb\u91c7\u6837\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u8fed\u4ee3\u4f18\u5316\u3002\u540c\u65f6\u5f15\u5165\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u5ba4\u5185AP\u90e8\u7f72\u6570\u636e\u96c6\u3002", "result": "\u6269\u6563\u91c7\u6837\u5668\u5728\u66ff\u4ee3\u751f\u6210\u65b9\u6cd5\u4e2d\u8868\u73b0\u4e00\u81f4\u4f18\u5f02\u3002\u6269\u6563\u8fc7\u7a0b\u901a\u8fc7\u5e73\u6ed1\u548c\u9510\u5316\u5956\u52b1\u666f\u89c2\u9010\u6b65\u6539\u8fdb\u91c7\u6837\uff0c\u5bf9\u4e8e\u975e\u51f8\u548c\u788e\u7247\u5316\u7684\u76ee\u6807\u51fd\u6570\u7279\u522b\u6709\u6548\u3002\u8bc4\u4f30\u4e86\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u53ca\u9c81\u68d2\u6027\u3002", "conclusion": "\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u63a8\u7406\u914d\u5408\u7edf\u4e00\u5956\u52b1\u51fd\u6570\uff0c\u4e3a\u5ba4\u5185AP\u90e8\u7f72\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9886\u57df\u65e0\u5173\u7684\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2602.00360", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00360", "abs": "https://arxiv.org/abs/2602.00360", "authors": ["Sumana Biswas", "Karen Young", "Josephine Griffith"], "title": "Leveraging Textual-Cues for Enhancing Multimodal Sentiment Analysis by Object Recognition", "comment": null, "summary": "Multimodal sentiment analysis, which includes both image and text data, presents several challenges due to the dissimilarities in the modalities of text and image, the ambiguity of sentiment, and the complexities of contextual meaning. In this work, we experiment with finding the sentiments of image and text data, individually and in combination, on two datasets. Part of the approach introduces the novel `Textual-Cues for Enhancing Multimodal Sentiment Analysis' (TEMSA) based on object recognition methods to address the difficulties in multimodal sentiment analysis. Specifically, we extract the names of all objects detected in an image and combine them with associated text; we call this combination of text and image data TEMS. Our results demonstrate that only TEMS improves the results when considering all the object names for the overall sentiment of multimodal data compared to individual analysis. This research contributes to advancing multimodal sentiment analysis and offers insights into the efficacy of TEMSA in combining image and text data for multimodal sentiment analysis.", "AI": {"tldr": "\u63d0\u51faTEMSA\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u56fe\u50cf\u4e2d\u6240\u6709\u68c0\u6d4b\u5230\u7684\u7269\u4f53\u540d\u79f0\u5e76\u4e0e\u76f8\u5173\u6587\u672c\u7ed3\u5408\uff0c\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6027\u80fd", "motivation": "\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u9762\u4e34\u6587\u672c\u548c\u56fe\u50cf\u6a21\u6001\u5dee\u5f02\u3001\u60c5\u611f\u6a21\u7cca\u6027\u548c\u4e0a\u4e0b\u6587\u590d\u6742\u6027\u7b49\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7ed3\u5408\u4e24\u79cd\u6a21\u6001\u4fe1\u606f", "method": "\u63d0\u51faTEMSA\u65b9\u6cd5\uff1a\u63d0\u53d6\u56fe\u50cf\u4e2d\u6240\u6709\u68c0\u6d4b\u5230\u7684\u7269\u4f53\u540d\u79f0\uff0c\u5c06\u5176\u4e0e\u76f8\u5173\u6587\u672c\u7ed3\u5408\u5f62\u6210TEMS\u6570\u636e\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u4f7f\u7528TEMS\uff08\u7ed3\u5408\u6240\u6709\u7269\u4f53\u540d\u79f0\uff09\u76f8\u6bd4\u5355\u72ec\u5206\u6790\u80fd\u6539\u5584\u591a\u6a21\u6001\u6570\u636e\u7684\u6574\u4f53\u60c5\u611f\u5206\u6790\u7ed3\u679c", "conclusion": "TEMSA\u65b9\u6cd5\u80fd\u6709\u6548\u7ed3\u5408\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\uff0c\u4e3a\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c55\u793a\u4e86\u7269\u4f53\u8bc6\u522b\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u6f5c\u529b"}}
{"id": "2602.00361", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.00361", "abs": "https://arxiv.org/abs/2602.00361", "authors": ["Philipp Altmann", "Maximilian Mansky", "Maximilian Zorn", "Jonas Stein", "Claudia Linnhoff-Popien"], "title": "Quantum Generator Kernels", "comment": "28 pages, 4 figures, 8 tables, under review", "summary": "Quantum kernel methods offer significant theoretical benefits by rendering classically inseparable features separable in quantum space. Yet, the practical application of Quantum Machine Learning (QML), currently constrained by the limitations of Noisy Intermediate-Scale Quantum (NISQ) hardware, necessitates effective strategies to compress and embed large-scale real-world data like images into the constrained capacities of existing quantum devices or simulators. To this end, we propose Quantum Generator Kernels (QGKs), a generator-based approach to quantum kernels, comprising a set of Variational Generator Groups (VGGs) that merge universal generators into a parameterizable operator, ensuring scalable coverage of the available quantum space. Thereby, we address shortcomings of current leading strategies employing hybrid architectures, which might prevent exploiting quantum computing's full potential due to fixed intermediate embedding processes. To optimize the kernel alignment to the target domain, we train a weight vector to parameterize the projection of the VGGs in the current data context. Our empirical results demonstrate superior projection and classification capabilities of the QGK compared to state-of-the-art quantum and classical kernel approaches and show its potential to serve as a versatile framework for various QML applications.", "AI": {"tldr": "\u63d0\u51fa\u91cf\u5b50\u751f\u6210\u6838\uff08QGKs\uff09\uff0c\u901a\u8fc7\u53d8\u5206\u751f\u6210\u7fa4\uff08VGGs\uff09\u6784\u5efa\u53ef\u53c2\u6570\u5316\u7684\u91cf\u5b50\u6838\uff0c\u89e3\u51b3NISQ\u786c\u4ef6\u9650\u5236\u4e0b\u5927\u89c4\u6a21\u6570\u636e\u5d4c\u5165\u95ee\u9898\uff0c\u5728\u6295\u5f71\u548c\u5206\u7c7b\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u91cf\u5b50\u4e0e\u7ecf\u5178\u6838\u65b9\u6cd5\u3002", "motivation": "\u91cf\u5b50\u6838\u65b9\u6cd5\u7406\u8bba\u4e0a\u80fd\u5c06\u7ecf\u5178\u4e0d\u53ef\u5206\u7279\u5f81\u5728\u91cf\u5b50\u7a7a\u95f4\u53d8\u5f97\u53ef\u5206\uff0c\u4f46\u53d7\u9650\u4e8eNISQ\u786c\u4ef6\u7684\u5b9e\u9645\u5e94\u7528\u9700\u8981\u6709\u6548\u538b\u7f29\u548c\u5d4c\u5165\u5927\u89c4\u6a21\u6570\u636e\uff08\u5982\u56fe\u50cf\uff09\u7684\u7b56\u7565\u3002\u73b0\u6709\u6df7\u5408\u67b6\u6784\u7684\u56fa\u5b9a\u4e2d\u95f4\u5d4c\u5165\u8fc7\u7a0b\u53ef\u80fd\u963b\u788d\u5145\u5206\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u91cf\u5b50\u751f\u6210\u6838\uff08QGKs\uff09\uff0c\u5305\u542b\u4e00\u7ec4\u53d8\u5206\u751f\u6210\u7fa4\uff08VGGs\uff09\uff0c\u5c06\u901a\u7528\u751f\u6210\u5668\u5408\u5e76\u4e3a\u53ef\u53c2\u6570\u5316\u7b97\u5b50\uff0c\u786e\u4fdd\u91cf\u5b50\u7a7a\u95f4\u7684\u6269\u5c55\u8986\u76d6\u3002\u901a\u8fc7\u8bad\u7ec3\u6743\u91cd\u5411\u91cf\u53c2\u6570\u5316VGGs\u5728\u5f53\u524d\u6570\u636e\u4e0a\u4e0b\u6587\u4e2d\u7684\u6295\u5f71\uff0c\u4f18\u5316\u6838\u4e0e\u76ee\u6807\u9886\u57df\u7684\u5bf9\u9f50\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cQGKs\u5728\u6295\u5f71\u548c\u5206\u7c7b\u80fd\u529b\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u91cf\u5b50\u4e0e\u7ecf\u5178\u6838\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u5404\u79cdQML\u5e94\u7528\u7684\u901a\u7528\u6846\u67b6\u6f5c\u529b\u3002", "conclusion": "\u91cf\u5b50\u751f\u6210\u6838\uff08QGKs\uff09\u901a\u8fc7\u53d8\u5206\u751f\u6210\u7fa4\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u6838\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86NISQ\u786c\u4ef6\u9650\u5236\u4e0b\u7684\u6570\u636e\u5d4c\u5165\u95ee\u9898\uff0c\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2602.00372", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00372", "abs": "https://arxiv.org/abs/2602.00372", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Post-Training Probability Manifold Correction via Structured SVD Pruning and Self-Referential Distillation", "comment": "16 pages, 10 tables, 4 figures", "summary": "Large language models are expensive to deploy. We introduce Sparse Knowledge Distillation (SparseKD), a post-training method that compresses transformer models by combining structured SVD pruning with self-referential knowledge distillation. The key insight is simple: instead of using an external teacher, the model teaches itself by matching its own probability distribution from before compression. This self-referential setup enables surprisingly strong quality recovery after aggressive pruning.\n  Our experiments reveal an unexpected finding: self-referential distillation alone, applied post-training under an identical objective and fixed calibration dataset, improves model quality by 39% relative to the original converged checkpoint. When combined with structured pruning, SparseKD achieves 15-65% parameter reduction with acceptable quality trade-offs. Kernel profiling shows that speedups arise entirely from reduced dense matrix multiplication in feed-forward layers while attention remains unchanged, making this approach complementary to attention optimizations.\n  We validate across two model families (0.6B and 3.8B parameters) with multi-seed experiments confirming high reproducibility. SparseKD requires no external super-teacher, no architectural changes, and no custom inference kernels, making it immediately deployable with existing infrastructure.", "AI": {"tldr": "SparseKD\u662f\u4e00\u79cd\u540e\u8bad\u7ec3\u538b\u7f29\u65b9\u6cd5\uff0c\u7ed3\u5408\u7ed3\u6784\u5316SVD\u526a\u679d\u548c\u81ea\u53c2\u8003\u77e5\u8bc6\u84b8\u998f\uff0c\u65e0\u9700\u5916\u90e8\u6559\u5e08\u6a21\u578b\uff0c\u901a\u8fc7\u6a21\u578b\u81ea\u6211\u5339\u914d\u538b\u7f29\u524d\u7684\u6982\u7387\u5206\u5e03\u6765\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6062\u590d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u6709\u6548\u7684\u538b\u7f29\u65b9\u6cd5\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5916\u90e8\u6559\u5e08\u6a21\u578b\u6216\u67b6\u6784\u4fee\u6539\uff0c\u589e\u52a0\u4e86\u90e8\u7f72\u590d\u6742\u6027\u3002", "method": "\u7ed3\u5408\u7ed3\u6784\u5316SVD\u526a\u679d\u548c\u81ea\u53c2\u8003\u77e5\u8bc6\u84b8\u998f\uff1a1\uff09\u4f7f\u7528SVD\u8fdb\u884c\u7ed3\u6784\u5316\u526a\u679d\uff1b2\uff09\u91c7\u7528\u81ea\u53c2\u8003\u84b8\u998f\uff0c\u8ba9\u538b\u7f29\u540e\u7684\u6a21\u578b\u5339\u914d\u81ea\u8eab\u538b\u7f29\u524d\u7684\u6982\u7387\u5206\u5e03\uff1b3\uff09\u4f7f\u7528\u56fa\u5b9a\u6821\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u540e\u8bad\u7ec3\u3002", "result": "1\uff09\u4ec5\u81ea\u53c2\u8003\u84b8\u998f\u5c31\u80fd\u5c06\u6a21\u578b\u8d28\u91cf\u76f8\u5bf9\u539f\u59cb\u68c0\u67e5\u70b9\u63d0\u534739%\uff1b2\uff09\u7ed3\u5408\u526a\u679d\u53ef\u5b9e\u73b015-65%\u53c2\u6570\u51cf\u5c11\uff0c\u8d28\u91cf\u635f\u5931\u53ef\u63a5\u53d7\uff1b3\uff09\u901f\u5ea6\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u524d\u9988\u5c42\u7684\u5bc6\u96c6\u77e9\u9635\u4e58\u6cd5\u51cf\u5c11\uff1b4\uff09\u57280.6B\u548c3.8B\u53c2\u6570\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u91cd\u73b0\u6027\u9ad8\u3002", "conclusion": "SparseKD\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u6559\u5e08\u3001\u65e0\u9700\u67b6\u6784\u4fee\u6539\u3001\u65e0\u9700\u5b9a\u5236\u63a8\u7406\u5185\u6838\u7684\u5373\u65f6\u53ef\u90e8\u7f72\u538b\u7f29\u65b9\u6848\uff0c\u4e0e\u6ce8\u610f\u529b\u4f18\u5316\u65b9\u6cd5\u4e92\u8865\uff0c\u5177\u6709\u9ad8\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.00376", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00376", "abs": "https://arxiv.org/abs/2602.00376", "authors": ["Delia McGrath", "Curtis Chong", "Rohil Kulkarni", "Gerbrand Ceder", "Adeesh Kolluru"], "title": "MATRIX: A Multimodal Benchmark and Post-Training Framework for Materials Science", "comment": "17 pages, 9 Figures, submitted", "summary": "Scientific reasoning in materials science requires integrating multimodal experimental evidence with underlying physical theory. Existing benchmarks make it difficult to assess whether incorporating visual experimental data during post-training improves mechanism-grounded explanation reasoning beyond text-only supervision. We introduce MATRIX, a multimodal benchmark for materials science reasoning that evaluates foundational theory, research-level reasoning, and the interpretation of real experimental artifacts across multiple characterization modalities. Using MATRIX as a controlled diagnostic, we isolate the effect of visual grounding by comparing post-training on structured materials science text alone with post-training that incorporates paired experimental images. Despite using relatively small amounts of multimodal data, visual supervision improves experimental interpretation by 10-25% and yields 5-16% gains on text-only scientific reasoning tasks. Our results demonstrate that these improvements rely on correct image-text alignment during post-training, highlighting cross-modal representational transfer. We also observe consistent improvements on ScienceQA and PubMedQA, demonstrating that the benefits of structured multimodal post-training extend beyond materials science. The MATRIX dataset is available at https://huggingface.co/datasets/radical-ai/MATRIX and the model at https://huggingface.co/radical-ai/MATRIX-PT.", "AI": {"tldr": "MATRIX\u662f\u4e00\u4e2a\u7528\u4e8e\u6750\u6599\u79d1\u5b66\u63a8\u7406\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u7eaf\u6587\u672c\u4e0e\u56fe\u50cf-\u6587\u672c\u5bf9\u9f50\u7684\u540e\u8bad\u7ec3\uff0c\u8bc1\u660e\u89c6\u89c9\u76d1\u7763\u80fd\u663e\u8457\u63d0\u5347\u5b9e\u9a8c\u89e3\u91ca\u548c\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u96be\u4ee5\u8bc4\u4f30\u5728\u6750\u6599\u79d1\u5b66\u4e2d\uff0c\u7ed3\u5408\u89c6\u89c9\u5b9e\u9a8c\u6570\u636e\u662f\u5426\u6bd4\u7eaf\u6587\u672c\u76d1\u7763\u66f4\u80fd\u63d0\u5347\u57fa\u4e8e\u7269\u7406\u673a\u5236\u7684\u89e3\u91ca\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165MATRIX\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u7eaf\u6587\u672c\u540e\u8bad\u7ec3\u4e0e\u5305\u542b\u914d\u5bf9\u5b9e\u9a8c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u540e\u8bad\u7ec3\uff0c\u9694\u79bb\u89c6\u89c9\u57fa\u7840\u7684\u5f71\u54cd\u3002", "result": "\u89c6\u89c9\u76d1\u7763\u4f7f\u5b9e\u9a8c\u89e3\u91ca\u63d0\u534710-25%\uff0c\u7eaf\u6587\u672c\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u63d0\u53475-16%\uff1b\u6539\u8fdb\u4f9d\u8d56\u4e8e\u6b63\u786e\u7684\u56fe\u50cf-\u6587\u672c\u5bf9\u9f50\uff0c\u4e14\u6548\u679c\u53ef\u63a8\u5e7f\u5230ScienceQA\u548cPubMedQA\u3002", "conclusion": "\u7ed3\u6784\u5316\u591a\u6a21\u6001\u540e\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u79d1\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5176\u4f18\u52bf\u4e0d\u4ec5\u9650\u4e8e\u6750\u6599\u79d1\u5b66\u9886\u57df\uff0c\u4e14\u9700\u8981\u6b63\u786e\u7684\u8de8\u6a21\u6001\u8868\u5f81\u5bf9\u9f50\u3002"}}
{"id": "2602.00384", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00384", "abs": "https://arxiv.org/abs/2602.00384", "authors": ["Ke Wang", "Nguyen Gia Hien Vu", "Yifan Tang", "Mostafa Rahmani Dehaghani", "G. Gary Wang"], "title": "RePaint-Enhanced Conditional Diffusion Model for Parametric Engineering Designs under Performance and Parameter Constraints", "comment": null, "summary": "This paper presents a RePaint-enhanced framework that integrates a pre-trained performance-guided denoising diffusion probabilistic model (DDPM) for performance- and parameter-constraint engineering design generation. The proposed method enables the generation of missing design components based on a partial reference design while satisfying performance constraints, without retraining the underlying model. By applying mask-based resampling during inference process, RePaint allows efficient and controllable repainting of partial designs under both performance and parameter constraints, which is not supported by conventional DDPM-base methods. The framework is evaluated on two representative design problems, parametric ship hull design and airfoil design, demonstrating its ability to generate novel designs with expected performance based on a partial reference design. Results show that the method achieves accuracy comparable to or better than pre-trained models while enabling controlled novelty through fixing partial designs. Overall, the proposed approach provides an efficient, training-free solution for parameter-constraint-aware generative design in engineering applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eRePaint\u589e\u5f3a\u7684\u6846\u67b6\uff0c\u96c6\u6210\u9884\u8bad\u7ec3DDPM\u6a21\u578b\uff0c\u7528\u4e8e\u6027\u80fd\u548c\u53c2\u6570\u7ea6\u675f\u7684\u5de5\u7a0b\u8bbe\u8ba1\u751f\u6210\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u57fa\u4e8e\u90e8\u5206\u53c2\u8003\u8bbe\u8ba1\u751f\u6210\u7f3a\u5931\u7ec4\u4ef6\u5e76\u6ee1\u8db3\u7ea6\u675f\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eDDPM\u7684\u65b9\u6cd5\u65e0\u6cd5\u5728\u6027\u80fd\u548c\u53c2\u6570\u7ea6\u675f\u4e0b\u8fdb\u884c\u53ef\u63a7\u7684\u90e8\u5206\u8bbe\u8ba1\u91cd\u7ed8\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3001\u80fd\u57fa\u4e8e\u90e8\u5206\u53c2\u8003\u8bbe\u8ba1\u751f\u6210\u6ee1\u8db3\u7ea6\u675f\u7684\u65b0\u8bbe\u8ba1\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528RePaint\u589e\u5f3a\u6846\u67b6\uff0c\u96c6\u6210\u9884\u8bad\u7ec3\u7684\u6027\u80fd\u5f15\u5bfcDDPM\u6a21\u578b\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5e94\u7528\u57fa\u4e8e\u63a9\u7801\u7684\u91cd\u91c7\u6837\uff0c\u5b9e\u73b0\u5bf9\u90e8\u5206\u8bbe\u8ba1\u5728\u6027\u80fd\u548c\u53c2\u6570\u7ea6\u675f\u4e0b\u7684\u9ad8\u6548\u53ef\u63a7\u91cd\u7ed8\u3002", "result": "\u5728\u53c2\u6570\u5316\u8239\u4f53\u8bbe\u8ba1\u548c\u7ffc\u578b\u8bbe\u8ba1\u4e24\u4e2a\u4ee3\u8868\u6027\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u80fd\u57fa\u4e8e\u90e8\u5206\u53c2\u8003\u8bbe\u8ba1\u751f\u6210\u5177\u6709\u9884\u671f\u6027\u80fd\u7684\u65b0\u8bbe\u8ba1\uff0c\u7cbe\u5ea6\u8fbe\u5230\u6216\u4f18\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u540c\u65f6\u901a\u8fc7\u56fa\u5b9a\u90e8\u5206\u8bbe\u8ba1\u5b9e\u73b0\u53ef\u63a7\u521b\u65b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u53c2\u6570\u7ea6\u675f\u611f\u77e5\u751f\u6210\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u65b9\u6848\uff0c\u652f\u6301\u57fa\u4e8e\u90e8\u5206\u8bbe\u8ba1\u7684\u53ef\u63a7\u521b\u65b0\u751f\u6210\u3002"}}
{"id": "2602.00388", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00388", "abs": "https://arxiv.org/abs/2602.00388", "authors": ["Zeyuan He", "Yupeng Chen", "Lang Lin", "Yihan Wang", "Shenxu Chang", "Eric Sommerlade", "Philip Torr", "Junchi Yu", "Adel Bibi", "Jialin Yu"], "title": "A Fragile Guardrail: Diffusion LLM's Safety Blessing and Its Failure Mode", "comment": null, "summary": "Diffusion large language models (D-LLMs) offer an alternative to autoregressive LLMs (AR-LLMs) and have demonstrated advantages in generation efficiency. Beyond the utility benefits, we argue that D-LLMs exhibit a previously underexplored safety blessing: their diffusion-style generation confers intrinsic robustness against jailbreak attacks originally designed for AR-LLMs. In this work, we provide an initial analysis of the underlying mechanism, showing that the diffusion trajectory induces a stepwise reduction effect that progressively suppresses unsafe generations. This robustness, however, is not absolute. We identify a simple yet effective failure mode, termed context nesting, where harmful requests are embedded within structured benign contexts, effectively bypassing the stepwise reduction mechanism. Empirically, we show that this simple strategy is sufficient to bypass D-LLMs' safety blessing, achieving state-of-the-art attack success rates across models and benchmarks. Most notably, it enables the first successful jailbreak of Gemini Diffusion, to our knowledge, exposing a critical vulnerability in commercial D-LLMs. Together, our results characterize both the origins and the limits of D-LLMs' safety blessing, constituting an early-stage red-teaming of D-LLMs.", "AI": {"tldr": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08D-LLMs\uff09\u76f8\u6bd4\u81ea\u56de\u5f52\u6a21\u578b\u5177\u6709\u5185\u5728\u7684\u5bf9\u6297\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5b58\u5728\u4e0a\u4e0b\u6587\u5d4c\u5957\u7684\u5931\u6548\u6a21\u5f0f\uff0c\u80fd\u6709\u6548\u7ed5\u8fc7\u5176\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u63a2\u7d22\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08D-LLMs\uff09\u76f8\u5bf9\u4e8e\u81ea\u56de\u5f52LLMs\uff08AR-LLMs\uff09\u5728\u5b89\u5168\u6027\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5176\u5bf9\u6297\u8d8a\u72f1\u653b\u51fb\u7684\u5185\u5728\u9c81\u68d2\u6027\u673a\u5236\uff0c\u5e76\u8bc6\u522b\u5176\u6f5c\u5728\u7684\u5931\u6548\u6a21\u5f0f\u3002", "method": "\u5206\u6790\u6269\u6563\u8f68\u8ff9\u7684\u9010\u6b65\u6291\u5236\u673a\u5236\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u5d4c\u5957\u653b\u51fb\u65b9\u6cd5\uff08\u5c06\u6709\u5bb3\u8bf7\u6c42\u5d4c\u5165\u7ed3\u6784\u5316\u826f\u6027\u4e0a\u4e0b\u6587\u4e2d\uff09\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "D-LLMs\u786e\u5b9e\u5177\u6709\u5bf9\u6297\u4f20\u7edf\u8d8a\u72f1\u653b\u51fb\u7684\u5185\u5728\u9c81\u68d2\u6027\uff0c\u4f46\u4e0a\u4e0b\u6587\u5d4c\u5957\u653b\u51fb\u80fd\u6709\u6548\u7ed5\u8fc7\u8fd9\u79cd\u4fdd\u62a4\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u9996\u6b21\u6210\u529f\u8d8a\u72f1Gemini Diffusion\u3002", "conclusion": "D-LLMs\u7684\u5b89\u5168\u4f18\u52bf\u6e90\u4e8e\u5176\u6269\u6563\u751f\u6210\u673a\u5236\uff0c\u4f46\u5e76\u975e\u7edd\u5bf9\u5b89\u5168\uff1b\u4e0a\u4e0b\u6587\u5d4c\u5957\u66b4\u9732\u4e86\u5176\u5173\u952e\u6f0f\u6d1e\uff0c\u8fd9\u6784\u6210\u4e86\u5bf9D-LLMs\u7684\u65e9\u671f\u7ea2\u961f\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u5176\u5b89\u5168\u6027\u7684\u8d77\u6e90\u548c\u5c40\u9650\u3002"}}
{"id": "2602.00392", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00392", "abs": "https://arxiv.org/abs/2602.00392", "authors": ["Arjun Rao", "Ruth Crasto", "Tessa Ooms", "David Rolnick", "Konstantin Klemmer", "Marc Ru\u00dfwurm"], "title": "Localized, High-resolution Geographic Representations with Slepian Functions", "comment": "23 pages, 12 figures, 6 tables", "summary": "Geographic data is fundamentally local. Disease outbreaks cluster in population centers, ecological patterns emerge along coastlines, and economic activity concentrates within country borders. Machine learning models that encode geographic location, however, distribute representational capacity uniformly across the globe, struggling at the fine-grained resolutions that localized applications require. We propose a geographic location encoder built from spherical Slepian functions that concentrate representational capacity inside a region-of-interest and scale to high resolutions without extensive computational demands. For settings requiring global context, we present a hybrid Slepian-Spherical Harmonic encoder that efficiently bridges the tradeoff between local-global performance, while retaining desirable properties such as pole-safety and spherical-surface-distance preservation. Across five tasks spanning classification, regression, and image-augmented prediction, Slepian encodings outperform baselines and retain performance advantages across a wide range of neural network architectures.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7403\u5f62Slepian\u51fd\u6570\u7684\u5730\u7406\u4f4d\u7f6e\u7f16\u7801\u5668\uff0c\u80fd\u591f\u5c06\u8868\u793a\u80fd\u529b\u96c6\u4e2d\u5728\u611f\u5174\u8da3\u533a\u57df\uff0c\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u7f16\u7801\u800c\u65e0\u9700\u5927\u91cf\u8ba1\u7b97\u9700\u6c42", "motivation": "\u5730\u7406\u6570\u636e\u672c\u8d28\u4e0a\u662f\u5c40\u90e8\u7684\uff0c\u4f46\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5730\u7406\u4f4d\u7f6e\u7f16\u7801\u5668\u5c06\u8868\u793a\u80fd\u529b\u5747\u5300\u5206\u5e03\u5728\u5168\u7403\uff0c\u96be\u4ee5\u6ee1\u8db3\u5c40\u90e8\u5e94\u7528\u7684\u9ad8\u5206\u8fa8\u7387\u9700\u6c42", "method": "\u4f7f\u7528\u7403\u5f62Slepian\u51fd\u6570\u6784\u5efa\u5730\u7406\u4f4d\u7f6e\u7f16\u7801\u5668\uff0c\u5c06\u8868\u793a\u80fd\u529b\u96c6\u4e2d\u5728\u611f\u5174\u8da3\u533a\u57df\uff1b\u5bf9\u4e8e\u9700\u8981\u5168\u5c40\u4e0a\u4e0b\u6587\u7684\u60c5\u51b5\uff0c\u63d0\u51fa\u6df7\u5408Slepian-\u7403\u8c10\u51fd\u6570\u7f16\u7801\u5668\uff0c\u5e73\u8861\u5c40\u90e8-\u5168\u5c40\u6027\u80fd", "result": "\u5728\u5206\u7c7b\u3001\u56de\u5f52\u548c\u56fe\u50cf\u589e\u5f3a\u9884\u6d4b\u7b49\u4e94\u4e2a\u4efb\u52a1\u4e2d\uff0cSlepian\u7f16\u7801\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u4fdd\u6301\u6027\u80fd\u4f18\u52bf", "conclusion": "\u7403\u5f62Slepian\u51fd\u6570\u7f16\u7801\u5668\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5730\u7406\u6570\u636e\u5c40\u90e8\u6027\u7279\u5f81\u4e0e\u5168\u5c40\u8868\u793a\u80fd\u529b\u5206\u5e03\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u4e3a\u9ad8\u5206\u8fa8\u7387\u5730\u7406\u5e94\u7528\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00397", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00397", "abs": "https://arxiv.org/abs/2602.00397", "authors": ["Aayush Gautam", "Mukul Gagrani", "Junyoung Park", "Mingu Lee", "Chiris Lott", "Narasimha Reddy"], "title": "Fast Forward: Accelerating LLM Prefill with Predictive FFN Sparsity", "comment": "10 pages, 7 figures", "summary": "The prefill stage of large language model (LLM) inference is a key computational bottleneck for long-context workloads. At short-to-moderate context lengths (1K--16K tokens), Feed-Forward Networks (FFNs) dominate this cost, accounting for most of the total FLOPs. Existing FFN sparsification methods, designed for autoregressive decoding, fail to exploit the prefill stage's parallelism and often degrade accuracy. To address this, we introduce FastForward, a predictive sparsity framework that accelerates LLM prefill through block-wise, context-aware FFN sparsity. FastForward combines (1) a lightweight expert predictor to select high-importance neurons per block, (2) an error compensation network to correct sparsity-induced errors, and (3) a layer-wise sparsity scheduler to allocate compute based on token-mixing importance. Across LLaMA and Qwen models up to 8B parameters, FastForward delivers up to 1.45$\\times$ compute-bound speedup at 50% FFN sparsity with $<$ 6% accuracy loss compared to the dense baseline on LongBench, substantially reducing Time-to-First-Token (TTFT) for efficient, long-context LLM inference on constrained hardware.", "AI": {"tldr": "FastForward\u662f\u4e00\u79cd\u9884\u6d4b\u6027\u7a00\u758f\u6846\u67b6\uff0c\u901a\u8fc7\u5757\u7ea7\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684FFN\u7a00\u758f\u5316\u52a0\u901fLLM\u9884\u586b\u5145\u9636\u6bb5\uff0c\u572850%\u7a00\u758f\u5ea6\u4e0b\u5b9e\u73b01.45\u500d\u8ba1\u7b97\u52a0\u901f\uff0c\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e6%\u3002", "motivation": "LLM\u63a8\u7406\u7684\u9884\u586b\u5145\u9636\u6bb5\u662f\u957f\u4e0a\u4e0b\u6587\u5de5\u4f5c\u8d1f\u8f7d\u7684\u4e3b\u8981\u8ba1\u7b97\u74f6\u9888\uff0cFFN\u5360\u636e\u5927\u90e8\u5206\u8ba1\u7b97\u91cf\u3002\u73b0\u6709FFN\u7a00\u758f\u5316\u65b9\u6cd5\u4e3a\u81ea\u56de\u5f52\u89e3\u7801\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u5229\u7528\u9884\u586b\u5145\u9636\u6bb5\u7684\u5e76\u884c\u6027\u4e14\u5e38\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\u3002", "method": "FastForward\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u8f7b\u91cf\u7ea7\u4e13\u5bb6\u9884\u6d4b\u5668\u9009\u62e9\u6bcf\u4e2a\u5757\u7684\u9ad8\u91cd\u8981\u6027\u795e\u7ecf\u5143\uff1b2) \u8bef\u5dee\u8865\u507f\u7f51\u7edc\u6821\u6b63\u7a00\u758f\u5316\u5f15\u8d77\u7684\u8bef\u5dee\uff1b3) \u5c42\u95f4\u7a00\u758f\u5ea6\u8c03\u5ea6\u5668\u57fa\u4e8etoken\u6df7\u5408\u91cd\u8981\u6027\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u5728LLaMA\u548cQwen\u6a21\u578b\uff08\u6700\u59278B\u53c2\u6570\uff09\u4e0a\uff0cFastForward\u572850% FFN\u7a00\u758f\u5ea6\u4e0b\u5b9e\u73b0\u6700\u9ad81.45\u500d\u8ba1\u7b97\u52a0\u901f\uff0c\u5728LongBench\u57fa\u51c6\u4e0a\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e6%\uff0c\u663e\u8457\u964d\u4f4e\u9996token\u751f\u6210\u65f6\u95f4\u3002", "conclusion": "FastForward\u901a\u8fc7\u9884\u6d4b\u6027\u7a00\u758f\u6846\u67b6\u6709\u6548\u52a0\u901fLLM\u9884\u586b\u5145\u9636\u6bb5\uff0c\u4e3a\u53d7\u9650\u786c\u4ef6\u4e0a\u7684\u9ad8\u6548\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00398", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00398", "abs": "https://arxiv.org/abs/2602.00398", "authors": ["Ajay Jaiswal", "Lauren Hannah", "Han-Byul Kim", "Duc Hoang", "Arnav Kundu", "Mehrdad Farajtabar", "Minsik Cho"], "title": "MemoryLLM: Plug-n-Play Interpretable Feed-Forward Memory for Transformers", "comment": null, "summary": "Understanding how transformer components operate in LLMs is important, as it is at the core of recent technological advances in artificial intelligence. In this work, we revisit the challenges associated with interpretability of feed-forward modules (FFNs) and propose MemoryLLM, which aims to decouple FFNs from self-attention and enables us to study the decoupled FFNs as context-free token-wise neural retrieval memory. In detail, we investigate how input tokens access memory locations within FFN parameters and the importance of FFN memory across different downstream tasks. MemoryLLM achieves context-free FFNs by training them in isolation from self-attention directly using the token embeddings. This approach allows FFNs to be pre-computed as token-wise lookups (ToLs), enabling on-demand transfer between VRAM and storage, additionally enhancing inference efficiency. We also introduce Flex-MemoryLLM, positioning it between a conventional transformer design and MemoryLLM. This architecture bridges the performance gap caused by training FFNs with context-free token-wise embeddings.", "AI": {"tldr": "MemoryLLM\u5c06Transformer\u4e2d\u7684\u524d\u9988\u7f51\u7edc\uff08FFN\uff09\u4e0e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u89e3\u8026\uff0c\u5c06\u5176\u89c6\u4e3a\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u4ee4\u724c\u7ea7\u795e\u7ecf\u68c0\u7d22\u8bb0\u5fc6\uff0c\u901a\u8fc7\u72ec\u7acb\u8bad\u7ec3FFN\u5b9e\u73b0\u9884\u8ba1\u7b97\u4ee4\u724c\u67e5\u627e\u8868\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u7406\u89e3Transformer\u7ec4\u4ef6\u5728LLM\u4e2d\u7684\u8fd0\u4f5c\u673a\u5236\u5bf9AI\u6280\u672f\u8fdb\u6b65\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u524d\u9988\u7f51\u7edc\uff08FFN\uff09\u6a21\u5757\u7684\u53ef\u89e3\u91ca\u6027\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76FFN\u5982\u4f55\u4f5c\u4e3a\u8bb0\u5fc6\u673a\u5236\u8fd0\u4f5c\u4ee5\u53ca\u5728\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51faMemoryLLM\u65b9\u6cd5\uff0c\u5c06FFN\u4e0e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u89e3\u8026\uff0c\u4f7f\u7528\u4ee4\u724c\u5d4c\u5165\u72ec\u7acb\u8bad\u7ec3FFN\uff0c\u4f7f\u5176\u6210\u4e3a\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u4ee4\u724c\u7ea7\u795e\u7ecf\u68c0\u7d22\u8bb0\u5fc6\u3002FFN\u53ef\u9884\u8ba1\u7b97\u4e3a\u4ee4\u724c\u67e5\u627e\u8868\uff08ToLs\uff09\uff0c\u652f\u6301\u6309\u9700\u5728VRAM\u548c\u5b58\u50a8\u95f4\u4f20\u8f93\u3002\u8fd8\u63d0\u51faFlex-MemoryLLM\u4f5c\u4e3a\u4f20\u7edfTransformer\u548cMemoryLLM\u4e4b\u95f4\u7684\u6298\u4e2d\u67b6\u6784\u3002", "result": "MemoryLLM\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u65e0\u5173\u7684FFN\uff0c\u53ef\u9884\u8ba1\u7b97\u4e3a\u4ee4\u724c\u67e5\u627e\u8868\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3002Flex-MemoryLLM\u5f25\u8865\u4e86\u4f7f\u7528\u4e0a\u4e0b\u6587\u65e0\u5173\u4ee4\u724c\u5d4c\u5165\u8bad\u7ec3FFN\u5bfc\u81f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "MemoryLLM\u4e3a\u7814\u7a76FFN\u4f5c\u4e3a\u8bb0\u5fc6\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u901a\u8fc7\u89e3\u8026FFN\u548c\u81ea\u6ce8\u610f\u529b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u8ba1\u7b97\u67b6\u6784\uff0cFlex-MemoryLLM\u5728\u6027\u80fd\u548c\u6548\u7387\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002"}}
{"id": "2602.00403", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00403", "abs": "https://arxiv.org/abs/2602.00403", "authors": ["Hon Tik Tse", "Marlos C. Machado"], "title": "DROGO: Default Representation Objective via Graph Optimization in Reinforcement Learning", "comment": null, "summary": "In computational reinforcement learning, the default representation (DR) and its principal eigenvector have been shown to be effective for a wide variety of applications, including reward shaping, count-based exploration, option discovery, and transfer. However, in prior investigations, the eigenvectors of the DR were computed by first approximating the DR matrix, and then performing an eigendecomposition. This procedure is computationally expensive and does not scale to high-dimensional spaces. In this paper, we derive an objective for directly approximating the principal eigenvector of the DR with a neural network. We empirically demonstrate the effectiveness of the objective in a number of environments, and apply the learned eigenvectors for reward shaping.", "AI": {"tldr": "\u63d0\u51fa\u76f4\u63a5\u8fd1\u4f3c\u9ed8\u8ba4\u8868\u793a\u4e3b\u7279\u5f81\u5411\u91cf\u7684\u76ee\u6807\u51fd\u6570\uff0c\u907f\u514d\u5148\u8ba1\u7b97\u77e9\u9635\u518d\u5206\u89e3\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u5e94\u7528\u4e8e\u5956\u52b1\u5851\u5f62\u7b49\u4efb\u52a1", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5148\u8fd1\u4f3c\u9ed8\u8ba4\u8868\u793a\u77e9\u9635\u518d\u8fdb\u884c\u7279\u5f81\u5206\u89e3\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u9ad8\u7ef4\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u76f4\u63a5\u8fd1\u4f3c\u65b9\u6cd5", "method": "\u63a8\u5bfc\u51fa\u76f4\u63a5\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u9ed8\u8ba4\u8868\u793a\u4e3b\u7279\u5f81\u5411\u91cf\u7684\u76ee\u6807\u51fd\u6570\uff0c\u907f\u514d\u4e2d\u95f4\u77e9\u9635\u8ba1\u7b97\u6b65\u9aa4", "result": "\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u76ee\u6807\u51fd\u6570\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c06\u5b66\u4e60\u5230\u7684\u7279\u5f81\u5411\u91cf\u6210\u529f\u5e94\u7528\u4e8e\u5956\u52b1\u5851\u5f62\u4efb\u52a1", "conclusion": "\u63d0\u51fa\u7684\u76f4\u63a5\u8fd1\u4f3c\u65b9\u6cd5\u6bd4\u4f20\u7edf\u4e24\u6b65\u6cd5\u66f4\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9ed8\u8ba4\u8868\u793a\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00407", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00407", "abs": "https://arxiv.org/abs/2602.00407", "authors": ["Suprim Nakarmi", "Junggab Son", "Yue Zhao", "Zuobin Xiong"], "title": "Fed-Listing: Federated Label Distribution Inference in Graph Neural Networks", "comment": "13 pages, 4 figures, and 5 tables", "summary": "Graph Neural Networks (GNNs) have been intensively studied for their expressive representation and learning performance on graph-structured data, enabling effective modeling of complex relational dependencies among nodes and edges in various domains. However, the standalone GNNs can unleash threat surfaces and privacy implications, as some sensitive graph-structured data is collected and processed in a centralized setting. To solve this issue, Federated Graph Neural Networks (FedGNNs) are proposed to facilitate collaborative learning over decentralized local graph data, aiming to preserve user privacy. Yet, emerging research indicates that even in these settings, shared model updates, particularly gradients, can unintentionally leak sensitive information of local users. Numerous privacy inference attacks have been explored in traditional federated learning and extended to graph settings, but the problem of label distribution inference in FedGNNs remains largely underexplored. In this work, we introduce Fed-Listing (Federated Label Distribution Inference in GNNs), a novel gradient-based attack designed to infer the private label statistics of target clients in FedGNNs without access to raw data or node features. Fed-Listing only leverages the final-layer gradients exchanged during training to uncover statistical patterns that reveal class proportions in a stealthy manner. An auxiliary shadow dataset is used to generate diverse label partitioning strategies, simulating various client distributions, on which the attack model is obtained. Extensive experiments on four benchmark datasets and three GNN architectures show that Fed-Listing significantly outperforms existing baselines, including random guessing and Decaf, even under challenging non-i.i.d. scenarios. Moreover, applying defense mechanisms can barely reduce our attack performance, unless the model's utility is severely degraded.", "AI": {"tldr": "\u63d0\u51faFed-Listing\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u8054\u90a6\u56fe\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f\u63a8\u65ad\u5ba2\u6237\u7aef\u79c1\u6709\u6807\u7b7e\u5206\u5e03\uff0c\u65e0\u9700\u8bbf\u95ee\u539f\u59cb\u6570\u636e\u6216\u8282\u70b9\u7279\u5f81", "motivation": "\u8054\u90a6\u56fe\u795e\u7ecf\u7f51\u7edc(FedGNNs)\u65e8\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u4f46\u5171\u4eab\u7684\u6a21\u578b\u66f4\u65b0\uff08\u7279\u522b\u662f\u68af\u5ea6\uff09\u53ef\u80fd\u65e0\u610f\u4e2d\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7684\u9690\u79c1\u63a8\u7406\u653b\u51fb\uff0c\u800cFedGNNs\u4e2d\u7684\u6807\u7b7e\u5206\u5e03\u63a8\u65ad\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22", "method": "\u63d0\u51faFed-Listing\u653b\u51fb\u65b9\u6cd5\uff0c\u4ec5\u5229\u7528\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ea4\u6362\u7684\u6700\u7ec8\u5c42\u68af\u5ea6\u6765\u63a8\u65ad\u76ee\u6807\u5ba2\u6237\u7aef\u7684\u79c1\u6709\u6807\u7b7e\u7edf\u8ba1\u4fe1\u606f\u3002\u4f7f\u7528\u8f85\u52a9\u5f71\u5b50\u6570\u636e\u96c6\u751f\u6210\u591a\u6837\u5316\u7684\u6807\u7b7e\u5212\u5206\u7b56\u7565\uff0c\u6a21\u62df\u4e0d\u540c\u7684\u5ba2\u6237\u7aef\u5206\u5e03\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bad\u7ec3\u653b\u51fb\u6a21\u578b", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e09\u79cdGNN\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFed-Listing\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff08\u5305\u62ec\u968f\u673a\u731c\u6d4b\u548cDecaf\uff09\uff0c\u5373\u4f7f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\u573a\u666f\u4e0b\u4e5f\u8868\u73b0\u826f\u597d\u3002\u9632\u5fa1\u673a\u5236\u51e0\u4e4e\u65e0\u6cd5\u964d\u4f4e\u653b\u51fb\u6027\u80fd\uff0c\u9664\u975e\u4e25\u91cd\u635f\u5bb3\u6a21\u578b\u6548\u7528", "conclusion": "Fed-Listing\u653b\u51fb\u63ed\u793a\u4e86FedGNNs\u4e2d\u68af\u5ea6\u4fe1\u606f\u6cc4\u9732\u6807\u7b7e\u5206\u5e03\u7684\u98ce\u9669\uff0c\u5373\u4f7f\u5728\u4e0d\u8bbf\u95ee\u539f\u59cb\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6709\u6548\u63a8\u65ad\u79c1\u6709\u6807\u7b7e\u7edf\u8ba1\u4fe1\u606f\uff0c\u8fd9\u5bf9\u8054\u90a6\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218"}}
{"id": "2602.00408", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00408", "abs": "https://arxiv.org/abs/2602.00408", "authors": ["Seung Heon Oh", "Jiwon Baek", "Ki Young Cho", "Hee Chang Yoon", "Jong Hun Woo"], "title": "Variational Approach for Job Shop Scheduling", "comment": null, "summary": "This paper proposes a novel Variational Graph-to-Scheduler (VG2S) framework for solving the Job Shop Scheduling Problem (JSSP), a critical task in manufacturing that directly impacts operational efficiency and resource utilization. Conventional Deep Reinforcement Learning (DRL) approaches often face challenges such as non-stationarity during training and limited generalization to unseen problem instances because they optimize representation learning and policy execution simultaneously. To address these issues, we introduce variational inference to the JSSP domain for the first time and derive a probabilistic objective based on the Evidence of Lower Bound (ELBO) with maximum entropy reinforcement learning. By mathematically decoupling representation learning from policy optimization, the VG2S framework enables the agent to learn robust structural representations of scheduling instances through a variational graph encoder. This approach significantly enhances training stability and robustness against hyperparameter variations. Extensive experiments demonstrate that the proposed method exhibits superior zero-shot generalization compared with state-of-the-art DRL baselines and traditional dispatching rules, particularly on large-scale and challenging benchmark instances such as DMU and SWV.", "AI": {"tldr": "VG2S\u6846\u67b6\u9996\u6b21\u5c06\u53d8\u5206\u63a8\u7406\u5f15\u5165\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u53d8\u5206\u56fe\u7f16\u7801\u5668\u5b66\u4e60\u8c03\u5ea6\u5b9e\u4f8b\u7684\u9c81\u68d2\u7ed3\u6784\u8868\u793a\uff0c\u5c06\u8868\u793a\u5b66\u4e60\u4e0e\u7b56\u7565\u4f18\u5316\u89e3\u8026\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\u4e2d\u9762\u4e34\u8bad\u7ec3\u975e\u5e73\u7a33\u6027\u548c\u5bf9\u672a\u89c1\u95ee\u9898\u5b9e\u4f8b\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u5b83\u4eec\u540c\u65f6\u4f18\u5316\u8868\u793a\u5b66\u4e60\u548c\u7b56\u7565\u6267\u884c\u3002", "method": "\u63d0\u51fa\u53d8\u5206\u56fe\u5230\u8c03\u5ea6\u5668\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u53d8\u5206\u63a8\u7406\u5f15\u5165JSSP\u9886\u57df\uff0c\u57fa\u4e8e\u8bc1\u636e\u4e0b\u754c\u548c\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\u63a8\u5bfc\u6982\u7387\u76ee\u6807\uff0c\u901a\u8fc7\u53d8\u5206\u56fe\u7f16\u7801\u5668\u5b66\u4e60\u8c03\u5ea6\u5b9e\u4f8b\u7684\u7ed3\u6784\u8868\u793a\uff0c\u5c06\u8868\u793a\u5b66\u4e60\u4e0e\u7b56\u7565\u4f18\u5316\u6570\u5b66\u89e3\u8026\u3002", "result": "VG2S\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u5bf9\u8d85\u53c2\u6570\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5728DMU\u548cSWV\u7b49\u5927\u89c4\u6a21\u6311\u6218\u6027\u57fa\u51c6\u5b9e\u4f8b\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e\u6700\u5148\u8fdbDRL\u57fa\u7ebf\u548c\u4f20\u7edf\u8c03\u5ea6\u89c4\u5219\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u53d8\u5206\u63a8\u7406\u5c06\u8868\u793a\u5b66\u4e60\u4e0e\u7b56\u7565\u4f18\u5316\u89e3\u8026\u7684\u65b9\u6cd5\u4e3a\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u5728\u5236\u9020\u8fd0\u8425\u6548\u7387\u4f18\u5316\u65b9\u9762\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.00412", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00412", "abs": "https://arxiv.org/abs/2602.00412", "authors": ["Marcos L. P. Bueno", "Joaquin Vanschoren"], "title": "Robustness of AutoML on Dirty Categorical Data", "comment": null, "summary": "The goal of automated machine learning (AutoML) is to reduce trial and error when doing machine learning (ML). Although AutoML methods for classification are able to deal with data imperfections, such as outliers, multiple scales and missing data, their behavior is less known on dirty categorical datasets. These datasets often have several categorical features with high cardinality arising from issues such as lack of curation and automated collection. Recent research has shown that ML models can benefit from morphological encoders for dirty categorical data, leading to significantly superior predictive performance. However the effects of using such encoders in AutoML methods are not known at the moment. In this paper, we propose a pipeline that transforms categorical data into numerical data so that an AutoML can handle categorical data transformed by more advanced encoding schemes. We benchmark the current robustness of AutoML methods on a set of dirty datasets and compare it with the proposed pipeline. This allows us to get insight on differences in predictive performance. We also look at the ML pipelines built by AutoMLs in order to gain insight beyond the best model as typically returned by these methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5c06\u5206\u7c7b\u6570\u636e\u8f6c\u6362\u4e3a\u6570\u503c\u6570\u636e\u7684\u7ba1\u9053\uff0c\u4f7fAutoML\u65b9\u6cd5\u80fd\u5904\u7406\u7ecf\u8fc7\u9ad8\u7ea7\u7f16\u7801\u65b9\u6848\u5904\u7406\u7684\u810f\u5206\u7c7b\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u5f53\u524dAutoML\u65b9\u6cd5\u5728\u810f\u6570\u636e\u96c6\u4e0a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u867d\u7136AutoML\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u80fd\u5904\u7406\u6570\u636e\u7f3a\u9677\uff0c\u4f46\u5728\u810f\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u5c1a\u4e0d\u6e05\u695a\u3002\u8fd9\u4e9b\u6570\u636e\u96c6\u901a\u5e38\u5177\u6709\u9ad8\u57fa\u6570\u5206\u7c7b\u7279\u5f81\uff0c\u800c\u73b0\u6709\u7814\u7a76\u8868\u660e\u5f62\u6001\u5b66\u7f16\u7801\u5668\u80fd\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u4f46\u8fd9\u7c7b\u7f16\u7801\u5668\u5728AutoML\u4e2d\u7684\u6548\u679c\u672a\u77e5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u5206\u7c7b\u6570\u636e\u8f6c\u6362\u4e3a\u6570\u503c\u6570\u636e\u7684\u7ba1\u9053\uff0c\u4f7fAutoML\u80fd\u5904\u7406\u7ecf\u8fc7\u9ad8\u7ea7\u7f16\u7801\u65b9\u6848\uff08\u5982\u5f62\u6001\u5b66\u7f16\u7801\u5668\uff09\u5904\u7406\u7684\u6570\u636e\u3002\u5728\u810f\u6570\u636e\u96c6\u4e0a\u5bf9\u5f53\u524dAutoML\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u63d0\u51fa\u7684\u7ba1\u9053\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u83b7\u5f97\u4e86\u9884\u6d4b\u6027\u80fd\u5dee\u5f02\u7684\u6d1e\u5bdf\uff0c\u5e76\u6df1\u5165\u7814\u7a76\u4e86AutoML\u6784\u5efa\u7684ML\u7ba1\u9053\uff0c\u8d85\u8d8a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u53ea\u8fd4\u56de\u6700\u4f73\u6a21\u578b\u7684\u5c40\u9650\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ba1\u9053\u4f7fAutoML\u80fd\u66f4\u597d\u5730\u5904\u7406\u810f\u5206\u7c7b\u6570\u636e\uff0c\u901a\u8fc7\u9ad8\u7ea7\u7f16\u7801\u65b9\u6848\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5bf9AutoML\u5185\u90e8\u7ba1\u9053\u6784\u5efa\u7684\u6df1\u5165\u7406\u89e3\u3002"}}
{"id": "2602.00423", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00423", "abs": "https://arxiv.org/abs/2602.00423", "authors": ["Quang-Huy Nguyen", "Zongliang Yue", "Hao Chen", "Wei-Shinn Ku", "Jiaqi Wang"], "title": "Federated-inspired Single-cell Batch Integration in Latent Space", "comment": null, "summary": "Advances in single-cell RNA sequencing enable the rapid generation of massive, high-dimensional datasets, yet the accumulation of data across experiments introduces batch effects that obscure true biological signals. Existing batch correction approaches either insufficiently correct batch effects or require centralized retraining on the complete dataset, limiting their applicability in distributed and continually evolving single-cell data settings. We introduce scBatchProx, a post-hoc optimization method inspired by federated learning principles for refining cell-level embeddings produced by arbitrary upstream methods. Treating each batch as a client, scBatchProx learns batch-conditioned adapters under proximal regularization, correcting batch structure directly in latent space without requiring raw expression data or centralized optimization. The method is lightweight and deployable, optimizing batch-specific adapter parameters only. Extensive experiments show that scBatchProx consistently yields relative gains of approximately 3-8% in overall embedding quality, with batch correction and biological conservation improving in 90% and 85% of data-method pairs, respectively. We envision this work as a step toward the practical refinement of learned representations in dynamic single-cell data systems.", "AI": {"tldr": "scBatchProx\uff1a\u4e00\u79cd\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u539f\u7406\u7684\u540e\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6279\u91cf\u6761\u4ef6\u9002\u914d\u5668\u548c\u8fd1\u7aef\u6b63\u5219\u5316\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u76f4\u63a5\u4fee\u6b63\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u7684\u6279\u6b21\u6548\u5e94\uff0c\u65e0\u9700\u539f\u59cb\u8868\u8fbe\u6570\u636e\u6216\u96c6\u4e2d\u5f0f\u4f18\u5316\u3002", "motivation": "\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u4ea7\u751f\u5927\u91cf\u9ad8\u7ef4\u6570\u636e\uff0c\u4f46\u8de8\u5b9e\u9a8c\u7684\u6570\u636e\u79ef\u7d2f\u4f1a\u5f15\u5165\u6279\u6b21\u6548\u5e94\uff0c\u63a9\u76d6\u771f\u5b9e\u751f\u7269\u4fe1\u53f7\u3002\u73b0\u6709\u6279\u6b21\u6821\u6b63\u65b9\u6cd5\u8981\u4e48\u6821\u6b63\u4e0d\u8db3\uff0c\u8981\u4e48\u9700\u8981\u5728\u5b8c\u6574\u6570\u636e\u96c6\u4e0a\u96c6\u4e2d\u91cd\u65b0\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u5728\u5206\u5e03\u5f0f\u548c\u6301\u7eed\u6f14\u5316\u7684\u5355\u7ec6\u80de\u6570\u636e\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "method": "scBatchProx\u662f\u4e00\u79cd\u540e\u4f18\u5316\u65b9\u6cd5\uff0c\u53d7\u8054\u90a6\u5b66\u4e60\u539f\u7406\u542f\u53d1\uff0c\u7528\u4e8e\u4f18\u5316\u4efb\u610f\u4e0a\u6e38\u65b9\u6cd5\u4ea7\u751f\u7684\u7ec6\u80de\u7ea7\u5d4c\u5165\u3002\u5c06\u6bcf\u4e2a\u6279\u6b21\u89c6\u4e3a\u5ba2\u6237\u7aef\uff0c\u5728\u8fd1\u7aef\u6b63\u5219\u5316\u4e0b\u5b66\u4e60\u6279\u91cf\u6761\u4ef6\u9002\u914d\u5668\uff0c\u76f4\u63a5\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6821\u6b63\u6279\u6b21\u7ed3\u6784\uff0c\u65e0\u9700\u539f\u59cb\u8868\u8fbe\u6570\u636e\u6216\u96c6\u4e2d\u5f0f\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u8f7b\u91cf\u7ea7\u4e14\u53ef\u90e8\u7f72\uff0c\u4ec5\u4f18\u5316\u6279\u91cf\u7279\u5b9a\u7684\u9002\u914d\u5668\u53c2\u6570\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cscBatchProx\u5728\u6574\u4f53\u5d4c\u5165\u8d28\u91cf\u4e0a\u6301\u7eed\u5e26\u6765\u7ea63-8%\u7684\u76f8\u5bf9\u589e\u76ca\uff0c\u572890%\u7684\u6570\u636e-\u65b9\u6cd5\u5bf9\u4e2d\u6539\u5584\u4e86\u6279\u6b21\u6821\u6b63\uff0c\u572885%\u7684\u6570\u636e-\u65b9\u6cd5\u5bf9\u4e2d\u6539\u5584\u4e86\u751f\u7269\u4fdd\u5b88\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u671d\u7740\u5728\u52a8\u6001\u5355\u7ec6\u80de\u6570\u636e\u7cfb\u7edf\u4e2d\u5b9e\u9645\u4f18\u5316\u5b66\u4e60\u8868\u793a\u8fc8\u51fa\u4e86\u4e00\u6b65\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u90e8\u7f72\u7684\u6279\u6b21\u6821\u6b63\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u548c\u6301\u7eed\u6f14\u5316\u7684\u6570\u636e\u73af\u5883\u3002"}}
{"id": "2602.00424", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.00424", "abs": "https://arxiv.org/abs/2602.00424", "authors": ["Philipp Hoellmer", "Stefano Martiniani"], "title": "Open Materials Generation with Inference-Time Reinforcement Learning", "comment": "16 pages, 8 figures, 1 table", "summary": "Continuous-time generative models for crystalline materials enable inverse materials design by learning to predict stable crystal structures, but incorporating explicit target properties into the generative process remains challenging. Policy-gradient reinforcement learning (RL) provides a principled mechanism for aligning generative models with downstream objectives but typically requires access to the score, which has prevented its application to flow-based models that learn only velocity fields. We introduce Open Materials Generation with Inference-time Reinforcement Learning (OMatG-IRL), a policy-gradient RL framework that operates directly on the learned velocity fields and eliminates the need for the explicit computation of the score. OMatG-IRL leverages stochastic perturbations of the underlying generation dynamics preserving the baseline performance of the pretrained generative model while enabling exploration and policy-gradient estimation at inference time. Using OMatG-IRL, we present the first application of RL to crystal structure prediction (CSP). Our method enables effective reinforcement of an energy-based objective while preserving diversity through composition conditioning, and it achieves performance competitive with score-based RL approaches. Finally, we show that OMatG-IRL can learn time-dependent velocity-annealing schedules, enabling accurate CSP with order-of-magnitude improvements in sampling efficiency and, correspondingly, reduction in generation time.", "AI": {"tldr": "OMatG-IRL\uff1a\u4e00\u79cd\u57fa\u4e8e\u7b56\u7565\u68af\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u76f4\u63a5\u5728\u5b66\u4e60\u7684\u901f\u5ea6\u573a\u4e0a\u64cd\u4f5c\uff0c\u65e0\u9700\u663e\u5f0f\u8ba1\u7b97\u5206\u6570\uff0c\u7528\u4e8e\u6676\u4f53\u6750\u6599\u751f\u6210\u548c\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u3002", "motivation": "\u8fde\u7eed\u65f6\u95f4\u751f\u6210\u6a21\u578b\u80fd\u591f\u9884\u6d4b\u7a33\u5b9a\u6676\u4f53\u7ed3\u6784\uff0c\u4f46\u96be\u4ee5\u5c06\u663e\u5f0f\u76ee\u6807\u5c5e\u6027\u6574\u5408\u5230\u751f\u6210\u8fc7\u7a0b\u4e2d\u3002\u7b56\u7565\u68af\u5ea6\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u5bf9\u9f50\u751f\u6210\u6a21\u578b\u4e0e\u4e0b\u6e38\u76ee\u6807\u7684\u673a\u5236\uff0c\u4f46\u901a\u5e38\u9700\u8981\u8bbf\u95ee\u5206\u6570\uff0c\u8fd9\u963b\u788d\u4e86\u5176\u5728\u4ec5\u5b66\u4e60\u901f\u5ea6\u573a\u7684\u57fa\u4e8e\u6d41\u7684\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faOMatG-IRL\u6846\u67b6\uff0c\u76f4\u63a5\u5728\u5b66\u4e60\u7684\u901f\u5ea6\u573a\u4e0a\u64cd\u4f5c\uff0c\u6d88\u9664\u5bf9\u663e\u5f0f\u5206\u6570\u8ba1\u7b97\u7684\u9700\u6c42\u3002\u5229\u7528\u5e95\u5c42\u751f\u6210\u52a8\u529b\u5b66\u7684\u968f\u673a\u6270\u52a8\uff0c\u4fdd\u6301\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u7684\u57fa\u7ebf\u6027\u80fd\uff0c\u540c\u65f6\u5728\u63a8\u7406\u65f6\u5b9e\u73b0\u63a2\u7d22\u548c\u7b56\u7565\u68af\u5ea6\u4f30\u8ba1\u3002", "result": "\u8be5\u65b9\u6cd5\u9996\u6b21\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\uff0c\u80fd\u591f\u6709\u6548\u5f3a\u5316\u57fa\u4e8e\u80fd\u91cf\u7684\u76ee\u6807\uff0c\u540c\u65f6\u901a\u8fc7\u7ec4\u6210\u6761\u4ef6\u4fdd\u6301\u591a\u6837\u6027\uff0c\u6027\u80fd\u4e0e\u57fa\u4e8e\u5206\u6570\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53\u3002\u80fd\u591f\u5b66\u4e60\u65f6\u95f4\u4f9d\u8d56\u7684\u901f\u5ea6\u9000\u706b\u8ba1\u5212\uff0c\u5b9e\u73b0\u91c7\u6837\u6548\u7387\u6570\u91cf\u7ea7\u63d0\u5347\u548c\u751f\u6210\u65f6\u95f4\u76f8\u5e94\u51cf\u5c11\u3002", "conclusion": "OMatG-IRL\u4e3a\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u663e\u5f0f\u5206\u6570\u8ba1\u7b97\uff0c\u5728\u6676\u4f53\u6750\u6599\u8bbe\u8ba1\u548c\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u5305\u62ec\u91c7\u6837\u6548\u7387\u7684\u5927\u5e45\u63d0\u5347\u3002"}}
{"id": "2602.00426", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00426", "abs": "https://arxiv.org/abs/2602.00426", "authors": ["Vikram Krishnamurthy"], "title": "LLMs as High-Dimensional Nonlinear Autoregressive Models with Attention: Training, Alignment and Inference", "comment": "27 pages, 12 figures. Mathematical survey framing LLMs as high-dimensional nonlinear autoregressive models with attention, covering training, alignment, and inference, with nanoGPT/nanochat-style code examples. Feedback welcome", "summary": "Large language models (LLMs) based on transformer architectures are typically described through collections of architectural components and training procedures, obscuring their underlying computational structure. This review article provides a concise mathematical reference for researchers seeking an explicit, equation-level description of LLM training, alignment, and generation. We formulate LLMs as high-dimensional nonlinear autoregressive models with attention-based dependencies. The framework encompasses pretraining via next-token prediction, alignment methods such as reinforcement learning from human feedback (RLHF), direct preference optimization (DPO), rejection sampling fine-tuning (RSFT), and reinforcement learning from verifiable rewards (RLVR), as well as autoregressive generation during inference. Self-attention emerges naturally as a repeated bilinear--softmax--linear composition, yielding highly expressive sequence models. This formulation enables principled analysis of alignment-induced behaviors (including sycophancy), inference-time phenomena (such as hallucination, in-context learning, chain-of-thought prompting, and retrieval-augmented generation), and extensions like continual learning, while serving as a concise reference for interpretation and further theoretical development.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c06\u5176\u8868\u8ff0\u4e3a\u5177\u6709\u6ce8\u610f\u529b\u4f9d\u8d56\u7684\u9ad8\u7ef4\u975e\u7ebf\u6027\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u6db5\u76d6\u9884\u8bad\u7ec3\u3001\u5bf9\u9f50\u548c\u751f\u6210\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63cf\u8ff0\u901a\u5e38\u4fa7\u91cd\u4e8e\u67b6\u6784\u7ec4\u4ef6\u548c\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u7f3a\u4e4f\u5bf9\u5176\u5e95\u5c42\u8ba1\u7b97\u7ed3\u6784\u7684\u6e05\u6670\u6570\u5b66\u8868\u8ff0\u3002\u672c\u6587\u65e8\u5728\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e00\u4e2a\u7b80\u6d01\u7684\u6570\u5b66\u53c2\u8003\uff0c\u660e\u786e\u63cf\u8ff0LLM\u8bad\u7ec3\u3001\u5bf9\u9f50\u548c\u751f\u6210\u7684\u65b9\u7a0b\u7ea7\u7ec6\u8282\u3002", "method": "\u5c06LLMs\u8868\u8ff0\u4e3a\u5177\u6709\u6ce8\u610f\u529b\u4f9d\u8d56\u7684\u9ad8\u7ef4\u975e\u7ebf\u6027\u81ea\u56de\u5f52\u6a21\u578b\u3002\u81ea\u6ce8\u610f\u529b\u88ab\u8868\u8ff0\u4e3a\u91cd\u590d\u7684\u53cc\u7ebf\u6027-softmax-\u7ebf\u6027\u7ec4\u5408\u3002\u6846\u67b6\u6db5\u76d6\uff1a1\uff09\u901a\u8fc7\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u8fdb\u884c\u9884\u8bad\u7ec3\uff1b2\uff09\u5bf9\u9f50\u65b9\u6cd5\u5305\u62ecRLHF\u3001DPO\u3001RSFT\u548cRLVR\uff1b3\uff09\u63a8\u7406\u65f6\u7684\u81ea\u56de\u5f52\u751f\u6210\u3002", "result": "\u8be5\u6570\u5b66\u6846\u67b6\u80fd\u591f\u5bf9\u5bf9\u9f50\u8bf1\u5bfc\u7684\u884c\u4e3a\uff08\u5982\u5949\u627f\uff09\u3001\u63a8\u7406\u65f6\u73b0\u8c61\uff08\u5982\u5e7b\u89c9\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u601d\u7ef4\u94fe\u63d0\u793a\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u4ee5\u53ca\u6269\u5c55\uff08\u5982\u6301\u7eed\u5b66\u4e60\uff09\u8fdb\u884c\u539f\u7406\u6027\u5206\u6790\uff0c\u540c\u65f6\u4f5c\u4e3a\u89e3\u91ca\u548c\u8fdb\u4e00\u6b65\u7406\u8bba\u53d1\u5c55\u7684\u7b80\u6d01\u53c2\u8003\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c06LLMs\u8868\u8ff0\u4e3a\u5177\u6709\u6ce8\u610f\u529b\u673a\u5236\u7684\u9ad8\u7ef4\u975e\u7ebf\u6027\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u4e3a\u7406\u89e3\u3001\u5206\u6790\u548c\u6269\u5c55\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2602.00446", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00446", "abs": "https://arxiv.org/abs/2602.00446", "authors": ["Ziyao Wang", "Nizhang Li", "Pingzhi Li", "Guoheng Sun", "Tianlong Chen", "Ang Li"], "title": "Towards Building Non-Fine-Tunable Foundation Models", "comment": null, "summary": "Open-sourcing foundation models (FMs) enables broad reuse but also exposes model trainers to economic and safety risks from unrestricted downstream fine-tuning. We address this problem by building non-fine-tunable foundation models: models that remain broadly usable in their released form while yielding limited adaptation gains under task-agnostic unauthorized fine-tuning. We propose Private Mask Pre-Training (PMP), a pre-training framework that concentrates representation learning into a sparse subnetwork identified early in training. The binary mask defining this subnetwork is kept private, and only the final dense weights are released. This forces unauthorized fine-tuning without access to the mask to update parameters misaligned with pretraining subspace, inducing an intrinsic mismatch between the fine-tuning objective and the pre-training geometry. We provide theoretical analysis showing that this mismatch destabilizes gradient-based adaptation and bounds fine-tuning gains. Empirical results on large language models demonstrating that PMP preserves base model performance while consistently degrading unauthorized fine-tuning across a wide range of downstream tasks, with the strength of non-fine-tunability controlled by the mask ratio.", "AI": {"tldr": "\u63d0\u51faPrivate Mask Pre-Training (PMP)\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u65f6\u5c06\u8868\u5f81\u5b66\u4e60\u96c6\u4e2d\u5728\u7a00\u758f\u5b50\u7f51\u7edc\u4e2d\uff0c\u5e76\u4fdd\u5bc6\u8be5\u5b50\u7f51\u7edc\u7684\u4e8c\u8fdb\u5236\u63a9\u7801\uff0c\u4f7f\u672a\u7ecf\u6388\u6743\u7684\u4e0b\u6e38\u5fae\u8c03\u96be\u4ee5\u83b7\u5f97\u6027\u80fd\u63d0\u5347\uff0c\u4ece\u800c\u4fdd\u62a4\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u7684\u7ecf\u6d4e\u548c\u5b89\u5168\u5229\u76ca\u3002", "motivation": "\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u867d\u7136\u4fc3\u8fdb\u4e86\u5e7f\u6cdb\u91cd\u7528\uff0c\u4f46\u4e5f\u4f7f\u6a21\u578b\u8bad\u7ec3\u8005\u9762\u4e34\u672a\u7ecf\u6388\u6743\u7684\u4e0b\u6e38\u5fae\u8c03\u5e26\u6765\u7684\u7ecf\u6d4e\u548c\u5b89\u5168\u98ce\u9669\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u6a21\u578b\u5e7f\u6cdb\u53ef\u7528\u6027\uff0c\u53c8\u80fd\u9650\u5236\u672a\u7ecf\u6388\u6743\u5fae\u8c03\u6027\u80fd\u63d0\u5347\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPrivate Mask Pre-Training (PMP)\u9884\u8bad\u7ec3\u6846\u67b6\uff1a\u5728\u8bad\u7ec3\u65e9\u671f\u8bc6\u522b\u7a00\u758f\u5b50\u7f51\u7edc\uff0c\u5c06\u8868\u5f81\u5b66\u4e60\u96c6\u4e2d\u5728\u8be5\u5b50\u7f51\u7edc\u4e2d\uff1b\u4fdd\u5bc6\u5b9a\u4e49\u8be5\u5b50\u7f51\u7edc\u7684\u4e8c\u8fdb\u5236\u63a9\u7801\uff0c\u4ec5\u53d1\u5e03\u6700\u7ec8\u5bc6\u96c6\u6743\u91cd\uff1b\u8fd9\u4f7f\u5f97\u672a\u7ecf\u6388\u6743\u7684\u5fae\u8c03\u65e0\u6cd5\u8bbf\u95ee\u63a9\u7801\uff0c\u5bfc\u81f4\u53c2\u6570\u66f4\u65b0\u4e0e\u9884\u8bad\u7ec3\u5b50\u7a7a\u95f4\u4e0d\u5339\u914d\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u8fd9\u79cd\u4e0d\u5339\u914d\u4f1a\u7834\u574f\u57fa\u4e8e\u68af\u5ea6\u7684\u9002\u5e94\u8fc7\u7a0b\u5e76\u9650\u5236\u5fae\u8c03\u6536\u76ca\uff1b\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cPMP\u80fd\u4fdd\u6301\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5e7f\u6cdb\u4e0b\u6e38\u4efb\u52a1\u4e2d\u6301\u7eed\u964d\u4f4e\u672a\u7ecf\u6388\u6743\u5fae\u8c03\u7684\u6548\u679c\uff0c\u4e14\u975e\u5fae\u8c03\u80fd\u529b\u5f3a\u5ea6\u53ef\u901a\u8fc7\u63a9\u7801\u6bd4\u4f8b\u63a7\u5236\u3002", "conclusion": "PMP\u6846\u67b6\u4e3a\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4fdd\u62a4\u673a\u5236\uff0c\u901a\u8fc7\u63a7\u5236\u8868\u5f81\u5b66\u4e60\u7684\u7a00\u758f\u5b50\u7f51\u7edc\u5e76\u4fdd\u5bc6\u63a9\u7801\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u5728\u4fdd\u6301\u5e7f\u6cdb\u53ef\u7528\u6027\u7684\u540c\u65f6\u9650\u5236\u672a\u7ecf\u6388\u6743\u5fae\u8c03\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e73\u8861\u4e86\u5f00\u6e90\u5171\u4eab\u4e0e\u98ce\u9669\u63a7\u5236\u7684\u9700\u6c42\u3002"}}
{"id": "2602.00458", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00458", "abs": "https://arxiv.org/abs/2602.00458", "authors": ["Omer Haq"], "title": "LatentTrack: Sequential Weight Generation via Latent Filtering", "comment": null, "summary": "We introduce LatentTrack (LT), a sequential neural architecture for online probabilistic prediction under nonstationary dynamics. LT performs causal Bayesian filtering in a low-dimensional latent space and uses a lightweight hypernetwork to generate predictive model parameters at each time step, enabling constant-time online adaptation without per-step gradient updates.\n  At each time step, a learned latent model predicts the next latent distribution, which is updated via amortized inference using new observations, yielding a predict--generate--update filtering framework in function space. The formulation supports both structured (Markovian) and unstructured latent dynamics within a unified objective, while Monte Carlo inference over latent trajectories produces calibrated predictive mixtures with fixed per-step cost. Evaluated on long-horizon online regression using the Jena Climate benchmark, LT consistently achieves lower negative log-likelihood and mean squared error than stateful sequential and static uncertainty-aware baselines, with competitive calibration, demonstrating that latent-conditioned function evolution is an effective alternative to traditional latent-state modeling under distribution shift.", "AI": {"tldr": "LatentTrack (LT) \u662f\u4e00\u79cd\u7528\u4e8e\u975e\u5e73\u7a33\u52a8\u6001\u4e0b\u5728\u7ebf\u6982\u7387\u9884\u6d4b\u7684\u5e8f\u5217\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u56e0\u679c\u8d1d\u53f6\u65af\u6ee4\u6ce2\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8d85\u7f51\u7edc\u751f\u6210\u9884\u6d4b\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u6052\u5b9a\u65f6\u95f4\u7684\u5728\u7ebf\u81ea\u9002\u5e94\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u975e\u5e73\u7a33\u52a8\u6001\u7684\u5728\u7ebf\u9884\u6d4b\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7684\u5728\u7ebf\u81ea\u9002\u5e94\u673a\u5236\u6765\u5e94\u5bf9\u5206\u5e03\u6f02\u79fb\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "method": "LT\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u6267\u884c\u56e0\u679c\u8d1d\u53f6\u65af\u6ee4\u6ce2\uff0c\u4f7f\u7528\u8d85\u7f51\u7edc\u751f\u6210\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u9884\u6d4b\u6a21\u578b\u53c2\u6570\uff0c\u5f62\u6210\"\u9884\u6d4b-\u751f\u6210-\u66f4\u65b0\"\u7684\u51fd\u6570\u7a7a\u95f4\u6ee4\u6ce2\u6846\u67b6\uff0c\u652f\u6301\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6f5c\u5728\u52a8\u6001\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u63a8\u7406\u4ea7\u751f\u6821\u51c6\u7684\u9884\u6d4b\u6df7\u5408\u3002", "result": "\u5728Jena Climate\u57fa\u51c6\u6d4b\u8bd5\u7684\u957f\u65f6\u57df\u5728\u7ebf\u56de\u5f52\u4e2d\uff0cLT\u5728\u8d1f\u5bf9\u6570\u4f3c\u7136\u548c\u5747\u65b9\u8bef\u5dee\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u72b6\u6001\u5e8f\u5217\u548c\u9759\u6001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u57fa\u7ebf\uff0c\u5177\u6709\u7ade\u4e89\u529b\u7684\u6821\u51c6\u6027\u80fd\u3002", "conclusion": "\u6f5c\u5728\u6761\u4ef6\u51fd\u6570\u6f14\u5316\u662f\u4f20\u7edf\u6f5c\u5728\u72b6\u6001\u5efa\u6a21\u5728\u5206\u5e03\u6f02\u79fb\u4e0b\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u5728\u7ebf\u6982\u7387\u9884\u6d4b\u3002"}}
{"id": "2602.00460", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00460", "abs": "https://arxiv.org/abs/2602.00460", "authors": ["Georgios Sotirchos", "Zlatan Ajanovi\u0107", "Jens Kober"], "title": "Search Inspired Exploration in Reinforcement Learning", "comment": null, "summary": "Exploration in environments with sparse rewards remains a fundamental challenge in reinforcement learning (RL). Existing approaches such as curriculum learning and Go-Explore often rely on hand-crafted heuristics, while curiosity-driven methods risk converging to suboptimal policies. We propose Search-Inspired Exploration in Reinforcement Learning (SIERL), a novel method that actively guides exploration by setting sub-goals based on the agent's learning progress. At the beginning of each episode, SIERL chooses a sub-goal from the \\textit{frontier} (the boundary of the agent's known state space), before the agent continues exploring toward the main task objective. The key contribution of our method is the sub-goal selection mechanism, which provides state-action pairs that are neither overly familiar nor completely novel. Thus, it assures that the frontier is expanded systematically and that the agent is capable of reaching any state within it. Inspired by search, sub-goals are prioritized from the frontier based on estimates of cost-to-come and cost-to-go, effectively steering exploration towards the most informative regions. In experiments on challenging sparse-reward environments, SIERL outperforms dominant baselines in both achieving the main task goal and generalizing to reach arbitrary states in the environment.", "AI": {"tldr": "SIERL\u662f\u4e00\u79cd\u53d7\u641c\u7d22\u542f\u53d1\u7684\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u5b66\u4e60\u8fdb\u5ea6\u8bbe\u7f6e\u5b50\u76ee\u6807\u6765\u4e3b\u52a8\u5f15\u5bfc\u63a2\u7d22\uff0c\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u7684\u63a2\u7d22\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u8bfe\u7a0b\u5b66\u4e60\u548cGo-Explore\u4f9d\u8d56\u624b\u5de5\u542f\u53d1\u5f0f\uff0c\u800c\u597d\u5947\u5fc3\u9a71\u52a8\u65b9\u6cd5\u53ef\u80fd\u6536\u655b\u5230\u6b21\u4f18\u7b56\u7565\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u63a2\u7d22\u65b9\u6cd5\u3002", "method": "SIERL\u5728\u6bcf\u8f6e\u5f00\u59cb\u65f6\u4ece\u8fb9\u754c\uff08\u5df2\u77e5\u72b6\u6001\u7a7a\u95f4\u7684\u8fb9\u754c\uff09\u4e2d\u9009\u62e9\u5b50\u76ee\u6807\uff0c\u7136\u540e\u4ee3\u7406\u7ee7\u7eed\u5411\u4e3b\u8981\u4efb\u52a1\u76ee\u6807\u63a2\u7d22\u3002\u5b50\u76ee\u6807\u9009\u62e9\u673a\u5236\u63d0\u4f9b\u65e2\u4e0d\u8fc7\u4e8e\u719f\u6089\u4e5f\u4e0d\u5b8c\u5168\u65b0\u9896\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u786e\u4fdd\u8fb9\u754c\u88ab\u7cfb\u7edf\u6269\u5c55\u3002\u53d7\u641c\u7d22\u542f\u53d1\uff0c\u57fa\u4e8e\u6210\u672c\u4f30\u8ba1\uff08\u5230\u8fbe\u6210\u672c\u548c\u524d\u5f80\u6210\u672c\uff09\u5bf9\u8fb9\u754c\u5b50\u76ee\u6807\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u5f15\u5bfc\u63a2\u7d22\u5230\u4fe1\u606f\u6700\u4e30\u5bcc\u7684\u533a\u57df\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u7a00\u758f\u5956\u52b1\u73af\u5883\u5b9e\u9a8c\u4e2d\uff0cSIERL\u5728\u5b9e\u73b0\u4e3b\u8981\u4efb\u52a1\u76ee\u6807\u548c\u6cdb\u5316\u5230\u73af\u5883\u4e2d\u4efb\u610f\u72b6\u6001\u65b9\u9762\u90fd\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SIERL\u901a\u8fc7\u53d7\u641c\u7d22\u542f\u53d1\u7684\u5b50\u76ee\u6807\u9009\u62e9\u673a\u5236\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u63a2\u7d22\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u7684\u63a2\u7d22\u6311\u6218\uff0c\u5e76\u5728\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.00465", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00465", "abs": "https://arxiv.org/abs/2602.00465", "authors": ["Jiaqi Yin", "Baiming Chen", "Jia Fei", "Mingjun Yang"], "title": "PAIR-Former: Budgeted Relational MIL for miRNA Target Prediction", "comment": "Preprint. Under review. During the preprint stage, inquiries and feedback can be directed to Jiaqi Yin (yjqhit@gmail.com)", "summary": "Functional miRNA--mRNA targeting is a large-bag prediction problem: each transcript yields a heavy-tailed pool of candidate target sites (CTSs), yet only a pair-level label is observed. We formalize this regime as \\emph{Budgeted Relational Multi-Instance Learning (BR-MIL)}, where at most $K$ instances per bag may receive expensive encoding and relational processing under a hard compute budget. We propose \\textbf{PAIR-Former} (Pool-Aware Instance-Relational Transformer), a BR-MIL pipeline that performs a cheap full-pool scan, selects up to $K$ diverse CTSs on CPU, and applies a permutation-invariant Set Transformer aggregator on the selected tokens. On miRAW, PAIR-Former outperforms strong pooling baselines at a practical operating budget ($K^\\star{=}64$) while providing a controllable accuracy--compute trade-off as $K$ varies. We further provide theory linking budgeted selection to (i) approximation error decreasing with $K$ and (ii) generalization terms governed by $K$ in the expensive relational component.", "AI": {"tldr": "PAIR-Former\uff1a\u4e00\u79cd\u9884\u7b97\u611f\u77e5\u7684\u5173\u7cfb\u591a\u793a\u4f8b\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8emiRNA-mRNA\u9776\u5411\u9884\u6d4b\uff0c\u901a\u8fc7\u5ec9\u4ef7\u5168\u6c60\u626b\u63cf\u548c\u591a\u6837\u5316\u5b9e\u4f8b\u9009\u62e9\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u9884\u6d4b\u3002", "motivation": "miRNA-mRNA\u9776\u5411\u9884\u6d4b\u9762\u4e34\u5927\u89c4\u6a21\u5019\u9009\u9776\u70b9\u6c60\u95ee\u9898\uff0c\u6bcf\u4e2a\u8f6c\u5f55\u672c\u4ea7\u751f\u5927\u91cf\u5019\u9009\u9776\u70b9\uff0c\u4f46\u53ea\u6709\u6210\u5bf9\u6807\u7b7e\u53ef\u89c2\u5bdf\u3002\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u5019\u9009\u6c60\u3002", "method": "\u63d0\u51faBR-MIL\u6846\u67b6\u548cPAIR-Former\u6a21\u578b\uff1a1\uff09\u5ec9\u4ef7\u5168\u6c60\u626b\u63cf\uff1b2\uff09\u5728CPU\u4e0a\u9009\u62e9\u6700\u591aK\u4e2a\u591a\u6837\u5316\u5019\u9009\u9776\u70b9\uff1b3\uff09\u4f7f\u7528\u7f6e\u6362\u4e0d\u53d8Set Transformer\u805a\u5408\u5668\u5904\u7406\u9009\u5b9a\u6807\u8bb0\u3002", "result": "\u5728miRAW\u6570\u636e\u96c6\u4e0a\uff0cPAIR-Former\u5728\u5b9e\u7528\u64cd\u4f5c\u9884\u7b97\uff08K*=64\uff09\u4e0b\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u53ef\u63a7\u7684\u51c6\u786e\u7387-\u8ba1\u7b97\u6743\u8861\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u9009\u62e9\u8bef\u5dee\u968fK\u51cf\u5c0f\uff0c\u6cdb\u5316\u9879\u7531K\u63a7\u5236\u3002", "conclusion": "PAIR-Former\u4e3a\u5927\u89c4\u6a21\u5019\u9009\u6c60\u7684miRNA-mRNA\u9776\u5411\u9884\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u9884\u7b97\u611f\u77e5\u7684\u5b9e\u4f8b\u9009\u62e9\u548c\u5173\u7cfb\u5904\u7406\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u9ad8\u6027\u80fd\u9884\u6d4b\u3002"}}
{"id": "2602.00475", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00475", "abs": "https://arxiv.org/abs/2602.00475", "authors": ["Michael Psenka", "Michael Rabbat", "Aditi Krishnapriyan", "Yann LeCun", "Amir Bar"], "title": "Parallel Stochastic Gradient-Based Planning for World Models", "comment": "23 pages, 7 figures", "summary": "World models simulate environment dynamics from raw sensory inputs like video. However, using them for planning can be challenging due to the vast and unstructured search space. We propose a robust and highly parallelizable planner that leverages the differentiability of the learned world model for efficient optimization, solving long-horizon control tasks from visual input. Our method treats states as optimization variables (\"virtual states\") with soft dynamics constraints, enabling parallel computation and easier optimization. To facilitate exploration and avoid local optima, we introduce stochasticity into the states. To mitigate sensitive gradients through high-dimensional vision-based world models, we modify the gradient structure to descend towards valid plans while only requiring action-input gradients. Our planner, which we call GRASP (Gradient RelAxed Stochastic Planner), can be viewed as a stochastic version of a non-condensed or collocation-based optimal controller. We provide theoretical justification and experiments on video-based world models, where our resulting planner outperforms existing planning algorithms like the cross-entropy method (CEM) and vanilla gradient-based optimization (GD) on long-horizon experiments, both in success rate and time to convergence.", "AI": {"tldr": "GRASP\uff1a\u4e00\u79cd\u5229\u7528\u53ef\u5fae\u5206\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u9ad8\u6548\u4f18\u5316\u7684\u5e76\u884c\u5316\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u865a\u62df\u72b6\u6001\u548c\u8f6f\u52a8\u529b\u5b66\u7ea6\u675f\u89e3\u51b3\u89c6\u89c9\u8f93\u5165\u7684\u957f\u65f6\u57df\u63a7\u5236\u4efb\u52a1", "motivation": "\u4e16\u754c\u6a21\u578b\u53ef\u4ee5\u4ece\u539f\u59cb\u611f\u5b98\u8f93\u5165\uff08\u5982\u89c6\u9891\uff09\u6a21\u62df\u73af\u5883\u52a8\u6001\uff0c\u4f46\u7528\u4e8e\u89c4\u5212\u65f6\u9762\u4e34\u641c\u7d22\u7a7a\u95f4\u5e9e\u5927\u4e14\u975e\u7ed3\u6784\u5316\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89c4\u5212\u65b9\u6cd5", "method": "1) \u5c06\u72b6\u6001\u89c6\u4e3a\u4f18\u5316\u53d8\u91cf\uff08\u865a\u62df\u72b6\u6001\uff09\u5e76\u65bd\u52a0\u8f6f\u52a8\u529b\u5b66\u7ea6\u675f\uff1b2) \u5728\u72b6\u6001\u4e2d\u5f15\u5165\u968f\u673a\u6027\u4ee5\u4fc3\u8fdb\u63a2\u7d22\uff1b3) \u4fee\u6539\u68af\u5ea6\u7ed3\u6784\u4ee5\u7f13\u89e3\u9ad8\u7ef4\u89c6\u89c9\u4e16\u754c\u6a21\u578b\u7684\u654f\u611f\u68af\u5ea6\u95ee\u9898\uff0c\u4ec5\u9700\u52a8\u4f5c\u8f93\u5165\u68af\u5ea6", "result": "\u5728\u57fa\u4e8e\u89c6\u9891\u7684\u4e16\u754c\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0cGRASP\u5728\u957f\u65f6\u57df\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4ea4\u53c9\u71b5\u65b9\u6cd5\uff08CEM\uff09\u548c\u666e\u901a\u68af\u5ea6\u4f18\u5316\uff08GD\uff09\uff0c\u5728\u6210\u529f\u7387\u548c\u6536\u655b\u65f6\u95f4\u65b9\u9762\u8868\u73b0\u66f4\u597d", "conclusion": "GRASP\u4f5c\u4e3a\u4e00\u79cd\u968f\u673a\u5316\u7684\u975e\u51dd\u805a\u6216\u914d\u70b9\u6700\u4f18\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u6548\u5e76\u884c\u89c4\u5212\uff0c\u4e3a\u89c6\u89c9\u8f93\u5165\u7684\u957f\u65f6\u57df\u63a7\u5236\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00476", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00476", "abs": "https://arxiv.org/abs/2602.00476", "authors": ["Hengchang Liu", "Zhao Yang", "Bing Su"], "title": "Diffusion LMs Can Approximate Optimal Infilling Lengths Implicitly", "comment": null, "summary": "Diffusion language models (DLMs) provide a bidirectional generation framework naturally suited for infilling, yet their performance is constrained by the pre-specified infilling length. In this paper, we reveal that DLMs possess an inherent ability to discover the correct infilling length. We identify two key statistical phenomena in the first-step denoising confidence: a local \\textit{Oracle Peak} that emerges near the ground-truth length and a systematic \\textit{Length Bias} that often obscures this signal. By leveraging this signal and calibrating the bias, our training-free method \\textbf{CAL} (\\textbf{C}alibrated \\textbf{A}daptive \\textbf{L}ength) enables DLMs to approximate the optimal length through an efficient search before formal decoding. Empirical evaluations demonstrate that CAL improves Pass@1 by up to 47.7\\% over fixed-length baselines and 40.5\\% over chat-based adaptive methods in code infilling, while boosting BLEU-2 and ROUGE-L by up to 8.5\\% and 9.9\\% in text infilling. These results demonstrate that CAL paves the way for robust DLM infilling without requiring any specialized training. Code is available at https://github.com/NiuHechang/Calibrated_Adaptive_Length.", "AI": {"tldr": "CAL\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u7b2c\u4e00\u6b65\u53bb\u566a\u4e2d\u7684\u7edf\u8ba1\u4fe1\u53f7\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u81ea\u9002\u5e94\u786e\u5b9a\u6700\u4f73\u586b\u5145\u957f\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u548c\u6587\u672c\u586b\u5145\u6027\u80fd\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5929\u751f\u9002\u5408\u586b\u5145\u4efb\u52a1\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u9650\u4e8e\u9884\u8bbe\u7684\u586b\u5145\u957f\u5ea6\u3002\u7814\u7a76\u53d1\u73b0DLMs\u5177\u6709\u53d1\u73b0\u6b63\u786e\u586b\u5145\u957f\u5ea6\u7684\u5185\u5728\u80fd\u529b\uff0c\u4f46\u8fd9\u4e00\u4fe1\u53f7\u88ab\u957f\u5ea6\u504f\u5dee\u6240\u63a9\u76d6\u3002", "method": "\u63d0\u51faCAL\u65b9\u6cd5\uff1a\u5229\u7528\u7b2c\u4e00\u6b65\u53bb\u566a\u7f6e\u4fe1\u5ea6\u4e2d\u7684Oracle Peak\u7edf\u8ba1\u4fe1\u53f7\uff0c\u901a\u8fc7\u6821\u51c6\u957f\u5ea6\u504f\u5dee\uff0c\u5728\u6b63\u5f0f\u89e3\u7801\u524d\u901a\u8fc7\u9ad8\u6548\u641c\u7d22\u8fd1\u4f3c\u6700\u4f18\u957f\u5ea6\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\u3002", "result": "\u5728\u4ee3\u7801\u586b\u5145\u4e2d\uff0cCAL\u6bd4\u56fa\u5b9a\u957f\u5ea6\u57fa\u7ebf\u63d0\u5347Pass@1\u8fbe47.7%\uff0c\u6bd4\u57fa\u4e8e\u804a\u5929\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u63d0\u534740.5%\uff1b\u5728\u6587\u672c\u586b\u5145\u4e2d\uff0cBLEU-2\u548cROUGE-L\u5206\u522b\u63d0\u53478.5%\u548c9.9%\u3002", "conclusion": "CAL\u8bc1\u660e\u4e86DLMs\u5177\u6709\u53d1\u73b0\u6b63\u786e\u586b\u5145\u957f\u5ea6\u7684\u5185\u5728\u80fd\u529b\uff0c\u901a\u8fc7\u5229\u7528\u7edf\u8ba1\u4fe1\u53f7\u548c\u6821\u51c6\u504f\u5dee\uff0c\u65e0\u9700\u4e13\u95e8\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9c81\u68d2\u7684\u586b\u5145\uff0c\u4e3aDLM\u586b\u5145\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.00478", "categories": ["cs.LG", "cs.AI", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.00478", "abs": "https://arxiv.org/abs/2602.00478", "authors": ["Xi Lin", "Ping Guo", "Yilu Liu", "Qingfu Zhang", "Jianyong Sun"], "title": "Quality-Diversity Optimization as Multi-Objective Optimization", "comment": null, "summary": "The Quality-Diversity (QD) optimization aims to discover a collection of high-performing solutions that simultaneously exhibit diverse behaviors within a user-defined behavior space. This paradigm has stimulated significant research interest and demonstrated practical utility in domains including robot control, creative design, and adversarial sample generation. A variety of QD algorithms with distinct design principles have been proposed in recent years. Instead of proposing a new QD algorithm, this work introduces a novel reformulation by casting the QD optimization as a multi-objective optimization (MOO) problem with a huge number of optimization objectives. By establishing this connection, we enable the direct adoption of well-established MOO methods, particularly set-based scalarization techniques, to solve QD problems through a collaborative search process. We further provide a theoretical analysis demonstrating that our approach inherits theoretical guarantees from MOO while providing desirable properties for the QD optimization. Experimental studies across several QD applications confirm that our method achieves performance competitive with state-of-the-art QD algorithms.", "AI": {"tldr": "\u5c06\u8d28\u91cf\u591a\u6837\u6027\u4f18\u5316\u91cd\u65b0\u8868\u8ff0\u4e3a\u5177\u6709\u5927\u91cf\u76ee\u6807\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u4ece\u800c\u53ef\u4ee5\u76f4\u63a5\u5e94\u7528\u6210\u719f\u7684MOO\u65b9\u6cd5\u89e3\u51b3QD\u95ee\u9898", "motivation": "\u73b0\u6709QD\u7b97\u6cd5\u8bbe\u8ba1\u539f\u5219\u5404\u5f02\uff0c\u672c\u6587\u4e0d\u63d0\u51fa\u65b0\u7b97\u6cd5\uff0c\u800c\u662f\u5efa\u7acbQD\u4e0eMOO\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u4f7f\u6210\u719f\u7684MOO\u65b9\u6cd5\u80fd\u591f\u76f4\u63a5\u5e94\u7528\u4e8eQD\u95ee\u9898", "method": "\u5c06QD\u4f18\u5316\u91cd\u65b0\u8868\u8ff0\u4e3a\u5177\u6709\u5927\u91cf\u4f18\u5316\u76ee\u6807\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u91c7\u7528\u57fa\u4e8e\u96c6\u5408\u7684\u6807\u91cf\u5316\u6280\u672f\uff0c\u901a\u8fc7\u534f\u4f5c\u641c\u7d22\u8fc7\u7a0b\u89e3\u51b3QD\u95ee\u9898", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u8be5\u65b9\u6cd5\u7ee7\u627f\u4e86MOO\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u540c\u65f6\u4e3aQD\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u60f3\u7279\u6027\uff1b\u5b9e\u9a8c\u7814\u7a76\u8868\u660e\u5728\u591a\u4e2aQD\u5e94\u7528\u4e2d\u8fbe\u5230\u4e86\u4e0e\u6700\u5148\u8fdbQD\u7b97\u6cd5\u7ade\u4e89\u7684\u6027\u80fd", "conclusion": "\u901a\u8fc7\u5efa\u7acbQD\u4e0eMOO\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u4e3aQD\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u6846\u67b6\uff0c\u53ef\u4ee5\u76f4\u63a5\u5229\u7528\u6210\u719f\u7684MOO\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u6027\u80fd"}}
{"id": "2602.00482", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00482", "abs": "https://arxiv.org/abs/2602.00482", "authors": ["Jiarui Zhang", "Yuchen Yang", "Ran Yan", "Zhiyu Mei", "Liyuan Zhang", "Daifeng Li", "Wei Fu", "Jiaxuan Gao", "Shusheng Xu", "Yi Wu", "Binhang Yuan"], "title": "AREAL-DTA: Dynamic Tree Attention for Efficient Reinforcement Learning of Large Language Models", "comment": null, "summary": "Reinforcement learning (RL) based post-training for large language models (LLMs) is computationally expensive, as it generates many rollout sequences that could frequently share long token prefixes. Existing RL frameworks usually process these sequences independently, repeatedly recomputing identical prefixes during forward and backward passes during policy model training, leading to substantial inefficiencies in computation and memory usage. Although prefix sharing naturally induces a tree structure over rollouts, prior tree-attention-based solutions rely on fully materialized attention masks and scale poorly in RL settings. In this paper, we introduce AREAL-DTA to efficiently exploit prefix sharing in RL training. AREAL-DTA employs a depth-first-search (DFS)-based execution strategy that dynamically traverses the rollout prefix tree during both forward and backward computation, materializing only a single root-to-leaf path at a time. To further improve scalability, AREAL-DTA incorporates a load-balanced distributed batching mechanism that dynamically constructs and processes prefix trees across multiple GPUs. Across the popular RL post-training workload, AREAL-DTA achieves up to $8.31\\times$ in $\u03c4^2$-bench higher training throughput.", "AI": {"tldr": "AREAL-DTA\uff1a\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7684\u5206\u5e03\u5f0f\u6811\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u9ad8\u6548\u5229\u7528RL\u8bad\u7ec3\u4e2d\u7684\u524d\u7f00\u5171\u4eab\uff0c\u63d0\u5347LLM\u540e\u8bad\u7ec3\u7684\u8ba1\u7b97\u6548\u7387", "motivation": "\u73b0\u6709RL\u6846\u67b6\u5728\u5904\u7406LLM\u540e\u8bad\u7ec3\u65f6\uff0c\u5bf9\u5171\u4eab\u957f\u524d\u7f00\u7684rollout\u5e8f\u5217\u8fdb\u884c\u72ec\u7acb\u5904\u7406\uff0c\u5bfc\u81f4\u5927\u91cf\u91cd\u590d\u8ba1\u7b97\u548c\u5185\u5b58\u6d6a\u8d39\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b", "method": "\u91c7\u7528\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7b56\u7565\u52a8\u6001\u904d\u5386rollout\u524d\u7f00\u6811\uff0c\u6bcf\u6b21\u53ea\u5b9e\u4f8b\u5316\u5355\u4e2a\u6839\u5230\u53f6\u8def\u5f84\uff1b\u7ed3\u5408\u8d1f\u8f7d\u5747\u8861\u7684\u5206\u5e03\u5f0f\u6279\u5904\u7406\u673a\u5236\u5728\u591aGPU\u4e0a\u52a8\u6001\u6784\u5efa\u548c\u5904\u7406\u524d\u7f00\u6811", "result": "\u5728\u6d41\u884c\u7684RL\u540e\u8bad\u7ec3\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0cAREAL-DTA\u5b9e\u73b0\u4e86\u9ad8\u8fbe8.31\u500d\u7684\u03c4\u00b2-bench\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347", "conclusion": "AREAL-DTA\u901a\u8fc7\u9ad8\u6548\u7684\u6811\u7ed3\u6784\u5904\u7406\u548c\u5206\u5e03\u5f0f\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86RL\u8bad\u7ec3\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21LLM\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00488", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00488", "abs": "https://arxiv.org/abs/2602.00488", "authors": ["Dongbin Jiao", "Zisheng Chen", "Xianyi Wang", "Jintao Shi", "Shengcai Liu", "Shi Yan"], "title": "OD-DEAL: Dynamic Expert-Guided Adversarial Learning with Online Decomposition for Scalable Capacitated Vehicle Routing", "comment": null, "summary": "Solving large-scale capacitated vehicle routing problems (CVRP) is hindered by the high complexity of heuristics and the limited generalization of neural solvers on massive graphs. We propose OD-DEAL, an adversarial learning framework that tightly integrates hybrid genetic search (HGS) and online barycenter clustering (BCC) decomposition, and leverages high-fidelity knowledge distillation to transfer expert heuristic behavior. OD-DEAL trains a graph attention network (GAT)-based generative policy through a minimax game, in which divide-and-conquer strategies from a hybrid expert are distilled into dense surrogate rewards. This enables high-quality, clustering-free inference on large-scale instances. Empirical results demonstrate that OD-DEAL achieves state-of-the-art (SOTA) real-time CVRP performance, solving 10000-node instances with near-constant neural scaling. This uniquely enables the sub-second, heuristic-quality inference required for dynamic large-scale deployment.", "AI": {"tldr": "OD-DEAL\u662f\u4e00\u4e2a\u5bf9\u6297\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u9057\u4f20\u641c\u7d22\u548c\u5728\u7ebf\u91cd\u5fc3\u805a\u7c7b\u5206\u89e3\uff0c\u7ed3\u5408\u77e5\u8bc6\u84b8\u998f\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21CVRP\u95ee\u9898\u7684\u5b9e\u65f6\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21CVRP\u95ee\u9898\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u4f20\u7edf\u542f\u53d1\u5f0f\u7b97\u6cd5\u590d\u6742\u5ea6\u9ad8\uff0c\u800c\u795e\u7ecf\u6c42\u89e3\u5668\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u542f\u53d1\u5f0f\u7b97\u6cd5\u8d28\u91cf\uff0c\u53c8\u80fd\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faOD-DEAL\u5bf9\u6297\u5b66\u4e60\u6846\u67b6\uff1a1\uff09\u7d27\u5bc6\u96c6\u6210\u6df7\u5408\u9057\u4f20\u641c\u7d22(HGS)\u548c\u5728\u7ebf\u91cd\u5fc3\u805a\u7c7b(BCC)\u5206\u89e3\uff1b2\uff09\u901a\u8fc7\u9ad8\u4fdd\u771f\u77e5\u8bc6\u84b8\u998f\u5c06\u4e13\u5bb6\u542f\u53d1\u5f0f\u884c\u4e3a\u8f6c\u79fb\u5230\u795e\u7ecf\u7f51\u7edc\uff1b3\uff09\u8bad\u7ec3\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u7f51\u7edc(GAT)\u7684\u751f\u6210\u7b56\u7565\uff0c\u901a\u8fc7\u6781\u5c0f\u6781\u5927\u535a\u5f08\u5c06\u5206\u6cbb\u7b56\u7565\u84b8\u998f\u4e3a\u5bc6\u96c6\u4ee3\u7406\u5956\u52b1\uff1b4\uff09\u5b9e\u73b0\u65e0\u9700\u805a\u7c7b\u7684\u5927\u89c4\u6a21\u5b9e\u4f8b\u63a8\u7406\u3002", "result": "OD-DEAL\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5b9e\u65f6CVRP\u6027\u80fd\uff0c\u80fd\u591f\u89e3\u51b310000\u8282\u70b9\u7684\u5927\u89c4\u6a21\u5b9e\u4f8b\uff0c\u5177\u6709\u63a5\u8fd1\u6052\u5b9a\u7684\u795e\u7ecf\u7f29\u653e\u7279\u6027\u3002\u5b9e\u73b0\u4e86\u4e9a\u79d2\u7ea7\u7684\u542f\u53d1\u5f0f\u8d28\u91cf\u63a8\u7406\uff0c\u6ee1\u8db3\u52a8\u6001\u5927\u89c4\u6a21\u90e8\u7f72\u9700\u6c42\u3002", "conclusion": "OD-DEAL\u901a\u8fc7\u5bf9\u6297\u5b66\u4e60\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21CVRP\u95ee\u9898\u4e2d\u542f\u53d1\u5f0f\u7b97\u6cd5\u590d\u6742\u5ea6\u9ad8\u548c\u795e\u7ecf\u6c42\u89e3\u5668\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u53cc\u91cd\u6311\u6218\uff0c\u4e3a\u52a8\u6001\u5927\u89c4\u6a21\u7269\u6d41\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00511", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.00511", "abs": "https://arxiv.org/abs/2602.00511", "authors": ["Akram Aldroubi"], "title": "Partition of Unity Neural Networks for Interpretable Classification with Explicit Class Regions", "comment": null, "summary": "Despite their empirical success, neural network classifiers remain difficult to interpret. In softmax-based models, class regions are defined implicitly as solutions to systems of inequalities among logits, making them difficult to extract and visualize. We introduce Partition of Unity Neural Networks (PUNN), an architecture in which class probabilities arise directly from a learned partition of unity, without requiring a softmax layer.\n  PUNN constructs $k$ nonnegative functions $h_1, \\ldots, h_k$ satisfying $\\sum_i h_i(x) = 1$, where each $h_i(x)$ directly represents $P(\\text{class } i \\mid x)$. Unlike softmax, where class regions are defined implicitly through coupled inequalities among logits, each PUNN partition function $h_i$ directly defines the probability of class $i$ as a standalone function of $x$.\n  We prove that PUNN is dense in the space of continuous probability maps on compact domains. The gate functions $g_i$ that define the partition can use various activation functions (sigmoid, Gaussian, bump) and parameterizations ranging from flexible MLPs to parameter-efficient shape-informed designs (spherical shells, ellipsoids, spherical harmonics).\n  Experiments on synthetic data, UCI benchmarks, and MNIST show that PUNN with MLP-based gates achieves accuracy within 0.3--0.6\\% of standard multilayer perceptrons. When geometric priors match the data structure, shape-informed gates achieve comparable accuracy with up to 300$\\times$ fewer parameters. These results demonstrate that interpretable-by-design architectures can be competitive with black-box models while providing transparent class probability assignments.", "AI": {"tldr": "\u63d0\u51faPUNN\u67b6\u6784\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u5355\u4f4d\u5206\u89e3\u76f4\u63a5\u751f\u6210\u7c7b\u522b\u6982\u7387\uff0c\u65e0\u9700softmax\u5c42\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\u867d\u7136\u7ecf\u9a8c\u4e0a\u6210\u529f\u4f46\u96be\u4ee5\u89e3\u91ca\u3002softmax\u6a21\u578b\u4e2d\u7c7b\u522b\u533a\u57df\u901a\u8fc7logits\u7684\u4e0d\u7b49\u5f0f\u7cfb\u7edf\u9690\u5f0f\u5b9a\u4e49\uff0c\u96be\u4ee5\u63d0\u53d6\u548c\u53ef\u89c6\u5316", "method": "\u5f15\u5165PUNN\u67b6\u6784\uff0c\u5b66\u4e60k\u4e2a\u975e\u8d1f\u51fd\u6570h\u2081,...,h\u2096\u6ee1\u8db3\u2211h\u1d62(x)=1\uff0c\u6bcf\u4e2ah\u1d62(x)\u76f4\u63a5\u8868\u793aP(class i|x)\u3002\u4f7f\u7528\u5404\u79cd\u6fc0\u6d3b\u51fd\u6570\u548c\u53c2\u6570\u5316\u8bbe\u8ba1", "result": "\u5728\u5408\u6210\u6570\u636e\u3001UCI\u57fa\u51c6\u548cMNIST\u4e0a\uff0c\u57fa\u4e8eMLP\u7684PUNN\u51c6\u786e\u7387\u6bd4\u6807\u51c6\u591a\u5c42\u611f\u77e5\u673a\u4f4e0.3-0.6%\u3002\u5f53\u51e0\u4f55\u5148\u9a8c\u5339\u914d\u6570\u636e\u7ed3\u6784\u65f6\uff0c\u5f62\u72b6\u611f\u77e5\u95e8\u51fd\u6570\u7528\u5c11300\u500d\u7684\u53c2\u6570\u8fbe\u5230\u53ef\u6bd4\u51c6\u786e\u7387", "conclusion": "PUNN\u8bc1\u660e\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\u7684\u67b6\u6784\u53ef\u4ee5\u4e0e\u9ed1\u76d2\u6a21\u578b\u7ade\u4e89\uff0c\u540c\u65f6\u63d0\u4f9b\u900f\u660e\u7684\u7c7b\u522b\u6982\u7387\u5206\u914d"}}
{"id": "2602.00513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00513", "abs": "https://arxiv.org/abs/2602.00513", "authors": ["Md Tanvirul Alam", "Aritran Piplai", "Ionut Cardei", "Nidhi Rastogi", "Peter J Worth"], "title": "Minerva: Reinforcement Learning with Verifiable Rewards for Cyber Threat Intelligence LLMs", "comment": null, "summary": "Cyber threat intelligence (CTI) analysts routinely convert noisy, unstructured security artifacts into standardized, automation-ready representations. Although large language models (LLMs) show promise for this task, existing approaches remain brittle when producing structured CTI outputs and have largely relied on supervised fine-tuning (SFT). In contrast, CTI standards and community-maintained resources define canonical identifiers and schemas that enable deterministic verification of model outputs. We leverage this structure to study reinforcement learning with verifiable rewards (RLVR) for CTI tasks. We introduce \\textit{Minerva}, a unified dataset and training pipeline spanning multiple CTI subtasks, each paired with task-specific verifiers that score structured outputs and identifier predictions. To address reward sparsity during rollout, we propose a lightweight self-training mechanism that generates additional verified trajectories and distills them back into the model. Experiments across LLM backbones show consistent improvements in accuracy and robustness over SFT across multiple benchmarks.", "AI": {"tldr": "\u63d0\u51faMinerva\u6846\u67b6\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u60c5\u62a5\u7ed3\u6784\u5316\u63d0\u53d6\u4efb\u52a1\uff0c\u76f8\u6bd4\u76d1\u7763\u5fae\u8c03\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u6709\u63d0\u5347", "motivation": "\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u60c5\u62a5\u5206\u6790\u5e08\u9700\u8981\u5c06\u975e\u7ed3\u6784\u5316\u5b89\u5168\u6570\u636e\u8f6c\u6362\u4e3a\u6807\u51c6\u5316\u3001\u53ef\u81ea\u52a8\u5316\u7684\u8868\u793a\u5f62\u5f0f\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\u65f6\u4ecd\u663e\u8106\u5f31\uff0c\u4e14\u4e3b\u8981\u4f9d\u8d56\u76d1\u7763\u5fae\u8c03\u3002CTI\u6807\u51c6\u548c\u793e\u533a\u7ef4\u62a4\u7684\u8d44\u6e90\u5b9a\u4e49\u4e86\u89c4\u8303\u7684\u6807\u8bc6\u7b26\u548c\u6a21\u5f0f\uff0c\u80fd\u591f\u5bf9\u6a21\u578b\u8f93\u51fa\u8fdb\u884c\u786e\u5b9a\u6027\u9a8c\u8bc1\u3002", "method": "\u63d0\u51faMinerva\u6846\u67b6\uff0c\u5305\u542b\u7edf\u4e00\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6d41\u7a0b\uff0c\u6db5\u76d6\u591a\u4e2aCTI\u5b50\u4efb\u52a1\u3002\u6bcf\u4e2a\u4efb\u52a1\u90fd\u914d\u6709\u7279\u5b9a\u9a8c\u8bc1\u5668\uff0c\u7528\u4e8e\u5bf9\u7ed3\u6784\u5316\u8f93\u51fa\u548c\u6807\u8bc6\u7b26\u9884\u6d4b\u8fdb\u884c\u8bc4\u5206\u3002\u9488\u5bf9\u5956\u52b1\u7a00\u758f\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u81ea\u8bad\u7ec3\u673a\u5236\uff0c\u751f\u6210\u989d\u5916\u7684\u5df2\u9a8c\u8bc1\u8f68\u8ff9\u5e76\u5c06\u5176\u84b8\u998f\u56de\u6a21\u578b\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u9aa8\u5e72\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u76d1\u7763\u5fae\u8c03\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\u3002", "conclusion": "\u5229\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u6709\u6548\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u60c5\u62a5\u7ed3\u6784\u5316\u63d0\u53d6\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u7ed3\u5408\u786e\u5b9a\u6027\u9a8c\u8bc1\u548c\u81ea\u8bad\u7ec3\u673a\u5236\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.00515", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00515", "abs": "https://arxiv.org/abs/2602.00515", "authors": ["Lin Liu", "Rita Machacy", "Simi Kuniyilh"], "title": "Contrastive Learning for Privacy Enhancements in Industrial Internet of Things", "comment": null, "summary": "The Industrial Internet of Things (IIoT) integrates intelligent sensing, communication, and analytics into industrial environments, including manufacturing, energy, and critical infrastructure. While IIoT enables predictive maintenance and cross-site optimization of modern industrial control systems, such as those in manufacturing and energy, it also introduces significant privacy and confidentiality risks due to the sensitivity of operational data. Contrastive learning, a self-supervised representation learning paradigm, has recently emerged as a promising approach for privacy-preserving analytics by reducing reliance on labeled data and raw data sharing. Although contrastive learning-based privacy-preserving techniques have been explored in the Internet of Things (IoT) domain, this paper offers a comprehensive review of these techniques specifically for privacy preservation in Industrial Internet of Things (IIoT) systems. It emphasizes the unique characteristics of industrial data, system architectures, and various application scenarios. Additionally, the paper discusses solutions and open challenges and outlines future research directions.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5de5\u4e1a\u7269\u8054\u7f51(IIoT)\u4e2d\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u5de5\u4e1a\u6570\u636e\u7684\u72ec\u7279\u7279\u6027\u3001\u7cfb\u7edf\u67b6\u6784\u548c\u5e94\u7528\u573a\u666f\uff0c\u5e76\u8ba8\u8bba\u4e86\u89e3\u51b3\u65b9\u6848\u3001\u5f00\u653e\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51(IIoT)\u5728\u5236\u9020\u4e1a\u3001\u80fd\u6e90\u548c\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u4e2d\u96c6\u6210\u4e86\u667a\u80fd\u611f\u77e5\u3001\u901a\u4fe1\u548c\u5206\u6790\u529f\u80fd\uff0c\u867d\u7136\u5b9e\u73b0\u4e86\u9884\u6d4b\u6027\u7ef4\u62a4\u548c\u8de8\u7ad9\u70b9\u4f18\u5316\uff0c\u4f46\u4e5f\u56e0\u64cd\u4f5c\u6570\u636e\u7684\u654f\u611f\u6027\u5e26\u6765\u4e86\u663e\u8457\u7684\u9690\u79c1\u548c\u4fdd\u5bc6\u98ce\u9669\u3002\u5bf9\u6bd4\u5b66\u4e60\u4f5c\u4e3a\u4e00\u79cd\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u51cf\u5c11\u5bf9\u6807\u8bb0\u6570\u636e\u548c\u539f\u59cb\u6570\u636e\u5171\u4eab\u7684\u4f9d\u8d56\uff0c\u6210\u4e3a\u9690\u79c1\u4fdd\u62a4\u5206\u6790\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u56de\u987e\u548c\u5206\u6790\u5de5\u4e1a\u7269\u8054\u7f51(IIoT)\u9886\u57df\u4e2d\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u3002\u91cd\u70b9\u5173\u6ce8\u5de5\u4e1a\u6570\u636e\u7684\u72ec\u7279\u7279\u6027\u3001\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u4ee5\u53ca\u5404\u79cd\u5e94\u7528\u573a\u666f\uff0c\u5e76\u5bf9\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u5f52\u7eb3\u603b\u7ed3\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u5de5\u4e1a\u7269\u8054\u7f51\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u7684\u5168\u9762\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5e94\u7528\u6f5c\u529b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u8be5\u9886\u57df\u9762\u4e34\u7684\u7279\u5b9a\u6311\u6218\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5728\u5de5\u4e1a\u7269\u8054\u7f51\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u5de5\u4e1a\u6570\u636e\u7684\u72ec\u7279\u7279\u6027\u548c\u7cfb\u7edf\u67b6\u6784\u8fdb\u884c\u4e13\u95e8\u7814\u7a76\u3002\u8bba\u6587\u6307\u51fa\u4e86\u5f53\u524d\u5b58\u5728\u7684\u5f00\u653e\u6311\u6218\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u6027\u6307\u5bfc\u3002"}}
{"id": "2602.00520", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00520", "abs": "https://arxiv.org/abs/2602.00520", "authors": ["Minghui Sun", "Haoyu Gong", "Xingyu You", "Jillian Hurst", "Benjamin Goldstein", "Matthew Engelhard"], "title": "NEST: Nested Event Stream Transformer for Sequences of Multisets", "comment": "11 pages", "summary": "Event stream data often exhibit hierarchical structure in which multiple events co-occur, resulting in a sequence of multisets (i.e., bags of events). In electronic health records (EHRs), for example, medical events are grouped into a sequence of clinical encounters with well-defined temporal structure, but the order and timing of events within each encounter may be unknown or unreliable. Most existing foundation models (FMs) for event stream data flatten this hierarchy into a one-dimensional sequence, leading to (i) computational inefficiency associated with dense attention and learning spurious within-set relationships, and (ii) lower-quality set-level representations from heuristic post-training pooling for downstream tasks. Here, we show that preserving the original hierarchy in the FM architecture provides a useful inductive bias that improves both computational efficiency and representation quality. We then introduce Nested Event Stream Transformer (NEST), a FM for event streams comprised of sequences of multisets. Building on this architecture, we formulate Masked Set Modeling (MSM), an efficient paradigm that promotes improved set-level representation learning. Experiments on real-world multiset sequence data show that NEST captures real-world dynamics while improving both pretraining efficiency and downstream performance.", "AI": {"tldr": "NEST\uff1a\u4e00\u79cd\u7528\u4e8e\u591a\u96c6\u5408\u5e8f\u5217\u4e8b\u4ef6\u6d41\u7684\u5c42\u6b21\u5316Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u4fdd\u7559\u539f\u59cb\u5c42\u6b21\u7ed3\u6784\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u8868\u793a\u8d28\u91cf", "motivation": "\u73b0\u6709\u4e8b\u4ef6\u6d41\u57fa\u7840\u6a21\u578b\u5c06\u5c42\u6b21\u7ed3\u6784\u6241\u5e73\u5316\u4e3a\u4e00\u7ef4\u5e8f\u5217\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff08\u5bc6\u96c6\u6ce8\u610f\u529b\uff09\u3001\u5b66\u4e60\u865a\u5047\u7684\u96c6\u5408\u5185\u5173\u7cfb\uff0c\u4ee5\u53ca\u4e0b\u6e38\u4efb\u52a1\u4e2d\u96c6\u5408\u7ea7\u8868\u793a\u8d28\u91cf\u8f83\u4f4e\uff08\u9700\u8981\u542f\u53d1\u5f0f\u540e\u8bad\u7ec3\u6c60\u5316\uff09", "method": "\u63d0\u51faNEST\uff08Nested Event Stream Transformer\uff09\uff0c\u4e00\u79cd\u7528\u4e8e\u591a\u96c6\u5408\u5e8f\u5217\u4e8b\u4ef6\u6d41\u7684\u57fa\u7840\u6a21\u578b\uff0c\u4fdd\u7559\u539f\u59cb\u5c42\u6b21\u7ed3\u6784\uff1b\u5e76\u5236\u5b9aMasked Set Modeling\uff08MSM\uff09\u8303\u5f0f\uff0c\u4fc3\u8fdb\u66f4\u597d\u7684\u96c6\u5408\u7ea7\u8868\u793a\u5b66\u4e60", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u591a\u96c6\u5408\u5e8f\u5217\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNEST\u80fd\u591f\u6355\u6349\u771f\u5b9e\u4e16\u754c\u52a8\u6001\uff0c\u540c\u65f6\u63d0\u9ad8\u9884\u8bad\u7ec3\u6548\u7387\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd", "conclusion": "\u5728\u57fa\u7840\u6a21\u578b\u67b6\u6784\u4e2d\u4fdd\u7559\u4e8b\u4ef6\u6d41\u7684\u539f\u59cb\u5c42\u6b21\u7ed3\u6784\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u65e2\u80fd\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u53c8\u80fd\u6539\u5584\u8868\u793a\u8d28\u91cf"}}
{"id": "2602.00526", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00526", "abs": "https://arxiv.org/abs/2602.00526", "authors": ["Kaiwen Zha", "Chao Li", "Hao He", "Peng Cao", "Tianhong Li", "Ali Mirzazadeh", "Ellen Zhang", "Jong Woo Lee", "Yoon Kim", "Dina Katabi"], "title": "Physiology as Language: Translating Respiration to Sleep EEG", "comment": "Tech report", "summary": "This paper introduces a novel cross-physiology translation task: synthesizing sleep electroencephalography (EEG) from respiration signals. To address the significant complexity gap between the two modalities, we propose a waveform-conditional generative framework that preserves fine-grained respiratory dynamics while constraining the EEG target space through discrete tokenization. Trained on over 28,000 individuals, our model achieves a 7% Mean Absolute Error in EEG spectrogram reconstruction. Beyond reconstruction, the synthesized EEG supports downstream tasks with performance comparable to ground truth EEG on age estimation (MAE 5.0 vs. 5.1 years), sex detection (AUROC 0.81 vs. 0.82), and sleep staging (Accuracy 0.84 vs. 0.88), significantly outperforming baselines trained directly on breathing. Finally, we demonstrate that the framework generalizes to contactless sensing by synthesizing EEG from wireless radio-frequency reflections, highlighting the feasibility of remote, non-contact neurological assessment during sleep.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u547c\u5438\u4fe1\u53f7\u5408\u6210\u7761\u7720\u8111\u7535\u56fe\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce2\u5f62\u6761\u4ef6\u751f\u6210\u6846\u67b6\u548c\u79bb\u6563\u6807\u8bb0\u5316\u6280\u672f\uff0c\u572828,000\u4eba\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5b9e\u73b07%\u7684MAE\uff0c\u5e76\u80fd\u652f\u6301\u5e74\u9f84\u4f30\u8ba1\u3001\u6027\u522b\u68c0\u6d4b\u548c\u7761\u7720\u5206\u671f\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u8de8\u751f\u7406\u4fe1\u53f7\u7ffb\u8bd1\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u4ece\u547c\u5438\u4fe1\u53f7\u5408\u6210\u8111\u7535\u56fe\uff0c\u4ee5\u63a2\u7d22\u975e\u63a5\u89e6\u5f0f\u8fdc\u7a0b\u795e\u7ecf\u8bc4\u4f30\u7684\u53ef\u80fd\u6027\uff0c\u586b\u8865\u4e24\u79cd\u6a21\u6001\u4e4b\u95f4\u7684\u590d\u6742\u6027\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u6ce2\u5f62\u6761\u4ef6\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u6563\u6807\u8bb0\u5316\u6280\u672f\u7ea6\u675f\u8111\u7535\u56fe\u76ee\u6807\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u7559\u547c\u5438\u4fe1\u53f7\u7684\u7ec6\u7c92\u5ea6\u52a8\u6001\u7279\u5f81\u3002\u4f7f\u7528\u8d85\u8fc728,000\u540d\u4e2a\u4f53\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u8111\u7535\u56fe\u9891\u8c31\u56fe\u91cd\u5efa\u4e0a\u8fbe\u52307%\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u3002\u5408\u6210\u8111\u7535\u56fe\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u771f\u5b9e\u8111\u7535\u56fe\uff1a\u5e74\u9f84\u4f30\u8ba1\uff08MAE 5.0 vs 5.1\u5e74\uff09\u3001\u6027\u522b\u68c0\u6d4b\uff08AUROC 0.81 vs 0.82\uff09\u3001\u7761\u7720\u5206\u671f\uff08\u51c6\u786e\u73870.84 vs 0.88\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u5728\u547c\u5438\u4fe1\u53f7\u4e0a\u8bad\u7ec3\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u547c\u5438\u4fe1\u53f7\u5230\u8111\u7535\u56fe\u7684\u8de8\u751f\u7406\u7ffb\u8bd1\uff0c\u5e76\u80fd\u63a8\u5e7f\u5230\u65e0\u7ebf\u5c04\u9891\u53cd\u5c04\u7684\u975e\u63a5\u89e6\u5f0f\u4f20\u611f\uff0c\u5c55\u793a\u4e86\u7761\u7720\u671f\u95f4\u8fdc\u7a0b\u975e\u63a5\u89e6\u795e\u7ecf\u8bc4\u4f30\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.00533", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00533", "abs": "https://arxiv.org/abs/2602.00533", "authors": ["Core Francisco Park"], "title": "Convergent World Representations and Divergent Tasks", "comment": null, "summary": "While neural representations are central to modern deep learning, the conditions governing their geometry and their roles in downstream adaptability remain poorly understood. We develop a framework clearly separating the underlying world, the data generation process and the resulting model representations to study these questions in a controlled setup. 5,075 city coordinates define the world and 7 geometric tasks generate the training data for autoregressive training. We find that different tasks give rise to qualitatively and quantitatively distinct world representation geometries. However, multi-task training drives convergence of world representations: models trained on non-overlapping tasks develop aligned geometric representations, providing controlled evidence for the Multitask Scaling Hypothesis of the Platonic Representation Hypothesis. To study adaptation, we pretrain models on all tasks, then test whether new entities (cities) can be consistently integrated into the representation space via fine-tuning. Surprisingly, we find that despite multi-task pretraining, some tasks, which we call divergent, actively harm the representational integration of new entities and harm generalization. Our results show that training on multiple relational tasks reliably produces convergent world representations, but lurking divergent tasks can catastrophically harm new entity integration via fine-tuning.", "AI": {"tldr": "\u591a\u4efb\u52a1\u8bad\u7ec3\u80fd\u4ea7\u751f\u6536\u655b\u7684\u4e16\u754c\u8868\u793a\uff0c\u4f46\u67d0\u4e9b\"\u53d1\u6563\u6027\u4efb\u52a1\"\u4f1a\u901a\u8fc7\u5fae\u8c03\u7834\u574f\u65b0\u5b9e\u4f53\u7684\u8868\u793a\u6574\u5408\u548c\u6cdb\u5316\u80fd\u529b", "motivation": "\u7814\u7a76\u795e\u7ecf\u8868\u793a\u7684\u51e0\u4f55\u7279\u6027\u53ca\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\u9002\u5e94\u6027\u4e2d\u7684\u4f5c\u7528\uff0c\u76ee\u524d\u5bf9\u8fd9\u4e9b\u8868\u793a\u7684\u6761\u4ef6\u548c\u89d2\u8272\u7406\u89e3\u4e0d\u8db3", "method": "\u5efa\u7acb\u5206\u79bb\u4e16\u754c\u3001\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u548c\u6a21\u578b\u8868\u793a\u7684\u6846\u67b6\uff0c\u4f7f\u75285,075\u4e2a\u57ce\u5e02\u5750\u6807\u4f5c\u4e3a\u4e16\u754c\uff0c7\u4e2a\u51e0\u4f55\u4efb\u52a1\u751f\u6210\u81ea\u56de\u5f52\u8bad\u7ec3\u6570\u636e\uff0c\u7814\u7a76\u591a\u4efb\u52a1\u8bad\u7ec3\u548c\u5fae\u8c03\u6548\u679c", "result": "\u4e0d\u540c\u4efb\u52a1\u4ea7\u751f\u4e0d\u540c\u7684\u4e16\u754c\u8868\u793a\u51e0\u4f55\uff1b\u591a\u4efb\u52a1\u8bad\u7ec3\u4f7f\u8868\u793a\u6536\u655b\u5bf9\u9f50\uff1b\u4f46\u67d0\u4e9b\u53d1\u6563\u6027\u4efb\u52a1\u4f1a\u901a\u8fc7\u5fae\u8c03\u7834\u574f\u65b0\u5b9e\u4f53\u7684\u8868\u793a\u6574\u5408\uff0c\u635f\u5bb3\u6cdb\u5316\u80fd\u529b", "conclusion": "\u591a\u4efb\u52a1\u5173\u7cfb\u8bad\u7ec3\u80fd\u53ef\u9760\u4ea7\u751f\u6536\u655b\u7684\u4e16\u754c\u8868\u793a\uff0c\u4f46\u9690\u85cf\u7684\u53d1\u6563\u6027\u4efb\u52a1\u53ef\u80fd\u901a\u8fc7\u5fae\u8c03\u707e\u96be\u6027\u5730\u7834\u574f\u65b0\u5b9e\u4f53\u7684\u8868\u793a\u6574\u5408"}}
{"id": "2602.00534", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00534", "abs": "https://arxiv.org/abs/2602.00534", "authors": ["Apurba Prasad Padhy", "Fernando Camacho", "Saibal Mukhopadhyay"], "title": "AIRE-Prune: Asymptotic Impulse-Response Energy for State Pruning in State Space Models", "comment": null, "summary": "State space models (SSMs) often sacrifice capacity, search space, or stability to offset the memory and compute costs of large state dimensions. We introduce a structured post-training pruning method for SSMs -- AIRE-Prune (Asymptotic Impulse-Response Energy for State PRUN(E)) -- that reduces each layer's state dimension by directly minimizing long-run output-energy distortion. AIRE-Prune assigns every state a closed-form asymptotic impulse-response energy-based score, i.e., the total impulse-response energy it contributes over an infinite horizon (time), and normalizes these scores layer-wise to enable global cross-layer comparison and selection. This extends modal truncation from single systems to deep stacks and aligns pruning with asymptotic response energy rather than worst-case gain. Across diverse sequence benchmarks, AIRE-Prune reveals substantial redundancy in SISO and MIMO SSMs with average pruning of 60.8%, with average accuracy drop of 0.29% without retraining, while significantly lowering compute. Code: https://github.com/falcon-arrow/AIRE-Prune.", "AI": {"tldr": "\u63d0\u51faAIRE-Prune\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fd1\u8109\u51b2\u54cd\u5e94\u80fd\u91cf\u8bc4\u5206\u5bf9\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5316\u540e\u8bad\u7ec3\u526a\u679d\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u540c\u65f6\u4fdd\u6301\u7cbe\u5ea6", "motivation": "\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(SSMs)\u901a\u5e38\u9700\u8981\u5728\u5927\u72b6\u6001\u7ef4\u5ea6\u4e0b\u5e73\u8861\u5bb9\u91cf\u3001\u641c\u7d22\u7a7a\u95f4\u6216\u7a33\u5b9a\u6027\u4e0e\u5185\u5b58\u8ba1\u7b97\u6210\u672c\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u9700\u8981\u727a\u7272\u67d0\u4e9b\u6027\u80fd", "method": "AIRE-Prune\u65b9\u6cd5\u4e3a\u6bcf\u4e2a\u72b6\u6001\u5206\u914d\u57fa\u4e8e\u6e10\u8fd1\u8109\u51b2\u54cd\u5e94\u80fd\u91cf\u7684\u95ed\u5f0f\u8bc4\u5206\uff0c\u901a\u8fc7\u5c42\u95f4\u5f52\u4e00\u5316\u5b9e\u73b0\u5168\u5c40\u8de8\u5c42\u6bd4\u8f83\u548c\u9009\u62e9\uff0c\u5c06\u6a21\u6001\u622a\u65ad\u4ece\u5355\u7cfb\u7edf\u6269\u5c55\u5230\u6df1\u5ea6\u5806\u6808", "result": "\u5728\u591a\u6837\u5316\u5e8f\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5bf9SISO\u548cMIMO SSMs\u5b9e\u73b0\u5e73\u574760.8%\u7684\u526a\u679d\u7387\uff0c\u7cbe\u5ea6\u5e73\u5747\u4ec5\u4e0b\u964d0.29%\uff08\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff09\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "conclusion": "AIRE-Prune\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7ed3\u6784\u5316\u540e\u8bad\u7ec3\u526a\u679d\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4e3aSSMs\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00535", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00535", "abs": "https://arxiv.org/abs/2602.00535", "authors": ["Liyu Zerihun", "Alexandr Plashchinsky"], "title": "Invertible Memory Flow Networks", "comment": null, "summary": "Long sequence neural memory remains a challenging problem. RNNs and their variants suffer from vanishing gradients, and Transformers suffer from quadratic scaling. Furthermore, compressing long sequences into a finite fixed representation remains an intractable problem due to the difficult optimization landscape. Invertible Memory Flow Networks (IMFN) make long sequence compression tractable through factorization: instead of learning end-to-end compression, we decompose the problem into pairwise merges using a binary tree of \"sweeper\" modules. Rather than learning to compress long sequences, each sweeper learns a much simpler 2-to-1 compression task, achieving O(log N) depth with sublinear error accumulation in sequence length. For online inference, we distilled into a constant-cost recurrent student achieving O(1) sequential steps. Empirical results validate IMFN on long MNIST sequences and UCF-101 videos, demonstrating compression of high-dimensional data over long sequences.", "AI": {"tldr": "IMFN\u901a\u8fc7\u4e8c\u53c9\u6811\u5206\u89e3\u5c06\u957f\u5e8f\u5217\u538b\u7f29\u95ee\u9898\u7b80\u5316\u4e3a\u6210\u5bf9\u5408\u5e76\uff0c\u5b9e\u73b0O(log N)\u6df1\u5ea6\u548c\u4e9a\u7ebf\u6027\u8bef\u5dee\u7d2f\u79ef\uff0c\u5e76\u53ef\u901a\u8fc7\u84b8\u998f\u5b9e\u73b0O(1)\u5728\u7ebf\u63a8\u7406", "motivation": "\u89e3\u51b3\u957f\u5e8f\u5217\u795e\u7ecf\u8bb0\u5fc6\u7684\u6311\u6218\uff1aRNN\u5b58\u5728\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0cTransformer\u6709\u4e8c\u6b21\u65b9\u590d\u6742\u5ea6\uff0c\u800c\u5c06\u957f\u5e8f\u5217\u538b\u7f29\u4e3a\u56fa\u5b9a\u8868\u793a\u56e0\u4f18\u5316\u56f0\u96be\u800c\u96be\u4ee5\u5b9e\u73b0", "method": "\u4f7f\u7528\u53ef\u9006\u8bb0\u5fc6\u6d41\u7f51\u7edc\uff08IMFN\uff09\uff0c\u901a\u8fc7\u4e8c\u53c9\u6811\u7ed3\u6784\u7684\"sweeper\"\u6a21\u5757\u5c06\u957f\u5e8f\u5217\u538b\u7f29\u5206\u89e3\u4e3a\u6210\u5bf9\u76842\u5bf91\u538b\u7f29\u4efb\u52a1\uff0c\u6bcf\u4e2asweeper\u5b66\u4e60\u66f4\u7b80\u5355\u7684\u538b\u7f29", "result": "\u5728\u957fMNIST\u5e8f\u5217\u548cUCF-101\u89c6\u9891\u4e0a\u9a8c\u8bc1\u4e86IMFN\u80fd\u591f\u538b\u7f29\u957f\u5e8f\u5217\u4e2d\u7684\u9ad8\u7ef4\u6570\u636e\uff0c\u5b9e\u73b0O(log N)\u6df1\u5ea6\u548c\u4e9a\u7ebf\u6027\u8bef\u5dee\u7d2f\u79ef", "conclusion": "IMFN\u901a\u8fc7\u5206\u89e3\u7b56\u7565\u4f7f\u957f\u5e8f\u5217\u538b\u7f29\u53d8\u5f97\u53ef\u884c\uff0c\u5e76\u901a\u8fc7\u84b8\u998f\u5b9e\u73b0\u9ad8\u6548\u7684\u5728\u7ebf\u63a8\u7406\uff0c\u4e3a\u957f\u5e8f\u5217\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2602.00539", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00539", "abs": "https://arxiv.org/abs/2602.00539", "authors": ["Xinmo Jin", "Bowen Fan", "Xunkai Li", "Henan Sun", "YuXin Zeng", "Zekai Chen", "Yuxuan Sun", "Jia Li", "Qiangqiang Dai", "Hongchao Qin", "Rong-Hua Li", "Guoren Wang"], "title": "OpenDDI: A Comprehensive Benchmark for DDI Prediction", "comment": null, "summary": "Drug-Drug Interactions (DDIs) significantly influence therapeutic efficacy and patient safety. As experimental discovery is resource-intensive and time-consuming, efficient computational methodologies have become essential. The predominant paradigm formulates DDI prediction as a drug graph-based link prediction task. However, further progress is hindered by two fundamental challenges: (1) lack of high-quality data: most studies rely on small-scale DDI datasets and single-modal drug representations; (2) lack of standardized evaluation: inconsistent scenarios, varied metrics, and diverse baselines. To address the above issues, we propose OpenDDI, a comprehensive benchmark for DDI prediction. Specifically, (1) from the data perspective, OpenDDI unifies 6 widely used DDI datasets and 2 existing forms of drug representation, while additionally contributing 3 new large-scale LLM-augmented datasets and a new multimodal drug representation covering 5 modalities. (2) From the evaluation perspective, OpenDDI unifies 20 SOTA model baselines across 3 downstream tasks, with standardized protocols for data quality, effectiveness, generalization, robustness, and efficiency. Based on OpenDDI, we conduct a comprehensive evaluation and derive 10 valuable insights for DDI prediction while exposing current limitations to provide critical guidance for this rapidly evolving field. Our code is available at https://github.com/xiaoriwuguang/OpenDDI", "AI": {"tldr": "OpenDDI\u662f\u4e00\u4e2a\u5168\u9762\u7684\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u57fa\u51c6\uff0c\u7edf\u4e00\u4e86\u591a\u4e2a\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u63d0\u4f9b\u4e86\u65b0\u7684LLM\u589e\u5f3a\u6570\u636e\u96c6\u548c\u591a\u6a21\u6001\u836f\u7269\u8868\u793a\uff0c\u5e76\u5bf920\u4e2aSOTA\u6a21\u578b\u8fdb\u884c\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "motivation": "\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1) \u7f3a\u4e4f\u9ad8\u8d28\u91cf\u6570\u636e\uff08\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u548c\u5355\u6a21\u6001\u836f\u7269\u8868\u793a\uff09\uff1b2) \u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\uff08\u4e0d\u4e00\u81f4\u7684\u573a\u666f\u3001\u6307\u6807\u548c\u57fa\u7ebf\uff09\u3002\u8fd9\u4e9b\u9650\u5236\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "OpenDDI\u4ece\u4e24\u4e2a\u89d2\u5ea6\u6784\u5efa\u57fa\u51c6\uff1a1) \u6570\u636e\u89d2\u5ea6\uff1a\u7edf\u4e006\u4e2a\u5e38\u7528DDI\u6570\u636e\u96c6\u548c2\u79cd\u73b0\u6709\u836f\u7269\u8868\u793a\uff0c\u65b0\u589e3\u4e2a\u5927\u89c4\u6a21LLM\u589e\u5f3a\u6570\u636e\u96c6\u548c\u8986\u76d65\u79cd\u6a21\u6001\u7684\u591a\u6a21\u6001\u836f\u7269\u8868\u793a\uff1b2) \u8bc4\u4f30\u89d2\u5ea6\uff1a\u7edf\u4e0020\u4e2aSOTA\u6a21\u578b\u57fa\u7ebf\uff0c\u6db5\u76d63\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff0c\u63d0\u4f9b\u6570\u636e\u8d28\u91cf\u3001\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u7684\u6807\u51c6\u5316\u534f\u8bae\u3002", "result": "\u57fa\u4e8eOpenDDI\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5f97\u51fa\u4e8610\u4e2a\u6709\u4ef7\u503c\u7684DDI\u9884\u6d4b\u89c1\u89e3\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5f53\u524d\u5c40\u9650\u6027\uff0c\u4e3a\u8fd9\u4e00\u5feb\u901f\u53d1\u5c55\u9886\u57df\u63d0\u4f9b\u4e86\u5173\u952e\u6307\u5bfc\u3002", "conclusion": "OpenDDI\u4e3a\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u6570\u636e\u548c\u8bc4\u4f30\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2602.00541", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00541", "abs": "https://arxiv.org/abs/2602.00541", "authors": ["Zilin Jing", "Vincent Jeanselme", "Yuta Kobayashi", "Simon A. Lee", "Chao Pang", "Aparajita Kashyap", "Yanwei Li", "Xinzhuo Jiang", "Shalmali Joshi"], "title": "One Loss to Rule Them All: Marked Time-to-Event for Structured EHR Foundation Models", "comment": null, "summary": "Clinical events captured in Electronic Health Records (EHR) are irregularly sampled and may consist of a mixture of discrete events and numerical measurements, such as laboratory values or treatment dosages. The sequential nature of EHR, analogous to natural language, has motivated the use of next-token prediction to train prior EHR Foundation Models (FMs) over events. However, this training fails to capture the full structure of EHR. We propose ORA, a marked time-to-event pretraining objective that jointly models event timing and associated measurements. Across multiple datasets, downstream tasks, and model architectures, this objective consistently yields more generalizable representations than next-token prediction and pretraining losses that ignore continuous measurements. Importantly, the proposed objective yields improvements beyond traditional classification evaluation, including better regression and time-to-event prediction. Beyond introducing a new family of FMs, our results suggest a broader takeaway: pretraining objectives that account for EHR structure are critical for expanding downstream capabilities and generalizability", "AI": {"tldr": "ORA\uff1a\u4e00\u79cd\u65b0\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u57fa\u7840\u6a21\u578b\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u8054\u5408\u5efa\u6a21\u4e8b\u4ef6\u65f6\u95f4\u548c\u76f8\u5173\u6d4b\u91cf\u503c\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u65b9\u6cd5\u80fd\u4ea7\u751f\u66f4\u5177\u6cdb\u5316\u80fd\u529b\u7684\u8868\u793a", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\u5177\u6709\u4e0d\u89c4\u5219\u91c7\u6837\u3001\u6df7\u5408\u79bb\u6563\u4e8b\u4ef6\u548c\u6570\u503c\u6d4b\u91cf\u7684\u7279\u70b9\uff0c\u73b0\u6709\u57fa\u4e8e\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u6355\u6349EHR\u7684\u5b8c\u6574\u7ed3\u6784", "method": "\u63d0\u51faORA\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u8fd9\u662f\u4e00\u79cd\u5e26\u6807\u8bb0\u7684\u65f6\u95f4\u5230\u4e8b\u4ef6\u5efa\u6a21\u65b9\u6cd5\uff0c\u8054\u5408\u5efa\u6a21\u4e8b\u4ef6\u53d1\u751f\u65f6\u95f4\u548c\u76f8\u5173\u7684\u8fde\u7eed\u6d4b\u91cf\u503c", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u3001\u4e0b\u6e38\u4efb\u52a1\u548c\u6a21\u578b\u67b6\u6784\u4e0a\uff0cORA\u76f8\u6bd4\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u548c\u5ffd\u7565\u8fde\u7eed\u6d4b\u91cf\u7684\u9884\u8bad\u7ec3\u635f\u5931\uff0c\u80fd\u4ea7\u751f\u66f4\u5177\u6cdb\u5316\u80fd\u529b\u7684\u8868\u793a\uff0c\u5728\u56de\u5f52\u548c\u65f6\u95f4\u5230\u4e8b\u4ef6\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18", "conclusion": "ORA\u4e0d\u4ec5\u5f15\u5165\u4e86\u65b0\u7684\u57fa\u7840\u6a21\u578b\u5bb6\u65cf\uff0c\u66f4\u91cd\u8981\u7684\u662f\u8868\u660e\uff1a\u8003\u8651EHR\u7ed3\u6784\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u5bf9\u4e8e\u6269\u5c55\u4e0b\u6e38\u80fd\u529b\u548c\u63d0\u9ad8\u6cdb\u5316\u6027\u81f3\u5173\u91cd\u8981"}}
{"id": "2602.00545", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00545", "abs": "https://arxiv.org/abs/2602.00545", "authors": ["Shenyang Deng", "Boyao Liao", "Zhuoli Ouyang", "Tianyu Pang", "Yaoqing Yang"], "title": "Depth, Not Data: An Analysis of Hessian Spectral Bifurcation", "comment": null, "summary": "The eigenvalue distribution of the Hessian matrix plays a crucial role in understanding the optimization landscape of deep neural networks. Prior work has attributed the well-documented ``bulk-and-spike'' spectral structure, where a few dominant eigenvalues are separated from a bulk of smaller ones, to the imbalance in the data covariance matrix. In this work, we challenge this view by demonstrating that such spectral Bifurcation can arise purely from the network architecture, independent of data imbalance.\n  Specifically, we analyze a deep linear network setup and prove that, even when the data covariance is perfectly balanced, the Hessian still exhibits a Bifurcation eigenvalue structure: a dominant cluster and a bulk cluster. Crucially, we establish that the ratio between dominant and bulk eigenvalues scales linearly with the network depth. This reveals that the spectral gap is strongly affected by the network architecture rather than solely by data distribution. Our results suggest that both model architecture and data characteristics should be considered when designing optimization algorithms for deep networks.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u4e86\u4f20\u7edf\u89c2\u70b9\uff0c\u8bc1\u660e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edcHessian\u77e9\u9635\u7684\"bulk-and-spike\"\u8c31\u7ed3\u6784\u4e0d\u4ec5\u6e90\u4e8e\u6570\u636e\u534f\u65b9\u5dee\u4e0d\u5e73\u8861\uff0c\u4e5f\u53ef\u7eaf\u7cb9\u7531\u7f51\u7edc\u67b6\u6784\u4ea7\u751f\uff0c\u4e14\u8c31\u95f4\u9699\u968f\u7f51\u7edc\u6df1\u5ea6\u7ebf\u6027\u589e\u957f\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u5c06\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edcHessian\u77e9\u9635\u7684\"bulk-and-spike\"\u8c31\u7ed3\u6784\u5f52\u56e0\u4e8e\u6570\u636e\u534f\u65b9\u5dee\u77e9\u9635\u7684\u4e0d\u5e73\u8861\u3002\u672c\u6587\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u89c2\u70b9\uff0c\u63a2\u7a76\u7f51\u7edc\u67b6\u6784\u672c\u8eab\u662f\u5426\u4e5f\u80fd\u4ea7\u751f\u8fd9\u79cd\u8c31\u5206\u5c94\u7ed3\u6784\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\u8bbe\u7f6e\uff0c\u5728\u6570\u636e\u534f\u65b9\u5dee\u5b8c\u5168\u5e73\u8861\u7684\u6761\u4ef6\u4e0b\uff0c\u5206\u6790Hessian\u77e9\u9635\u7684\u7279\u5f81\u503c\u5206\u5e03\u3002\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\uff0c\u5373\u4f7f\u6570\u636e\u5e73\u8861\uff0cHessian\u4ecd\u4f1a\u5448\u73b0\u5206\u5c94\u7279\u5f81\u503c\u7ed3\u6784\u3002", "result": "\u8bc1\u660e\u5728\u6570\u636e\u534f\u65b9\u5dee\u5e73\u8861\u65f6\uff0cHessian\u4ecd\u8868\u73b0\u51fa\u5206\u5c94\u7279\u5f81\u503c\u7ed3\u6784\uff1a\u4e00\u4e2a\u4e3b\u5bfc\u7c07\u548c\u4e00\u4e2a\u4e3b\u4f53\u7c07\u3002\u5173\u952e\u53d1\u73b0\u662f\u4e3b\u5bfc\u7279\u5f81\u503c\u4e0e\u4e3b\u4f53\u7279\u5f81\u503c\u4e4b\u6bd4\u968f\u7f51\u7edc\u6df1\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u8868\u660e\u8c31\u95f4\u9699\u53d7\u7f51\u7edc\u67b6\u6784\u5f3a\u70c8\u5f71\u54cd\u3002", "conclusion": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8c31\u5206\u5c94\u7ed3\u6784\u4e0d\u4ec5\u6e90\u4e8e\u6570\u636e\u5206\u5e03\uff0c\u4e5f\u7531\u7f51\u7edc\u67b6\u6784\u672c\u8eab\u4ea7\u751f\u3002\u8bbe\u8ba1\u6df1\u5ea6\u7f51\u7edc\u4f18\u5316\u7b97\u6cd5\u65f6\uff0c\u5e94\u540c\u65f6\u8003\u8651\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u7279\u6027\u3002"}}
{"id": "2602.00547", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00547", "abs": "https://arxiv.org/abs/2602.00547", "authors": ["Seunghyun Yoo", "Sanghong Kim", "Namkyung Yoon", "Hwangnam Kim"], "title": "Contrastive Domain Generalization for Cross-Instrument Molecular Identification in Mass Spectrometry", "comment": "8 pages, 2 figures", "summary": "Identifying molecules from mass spectrometry (MS) data remains a fundamental challenge due to the semantic gap between physical spectral peaks and underlying chemical structures. Existing deep learning approaches often treat spectral matching as a closed-set recognition task, limiting their ability to generalize to unseen molecular scaffolds. To overcome this limitation, we propose a cross-modal alignment framework that directly maps mass spectra into the chemically meaningful molecular structure embedding space of a pretrained chemical language model. On a strict scaffold-disjoint benchmark, our model achieves a Top-1 accuracy of 42.2% in fixed 256-way zero-shot retrieval and demonstrates strong generalization under a global retrieval setting. Moreover, the learned embedding space demonstrates strong chemical coherence, reaching 95.4% accuracy in 5-way 5-shot molecular re-identification. These results suggest that explicitly integrating physical spectral resolution with molecular structure embedding is key to solving the generalization bottleneck in molecular identification from MS data.", "AI": {"tldr": "\u63d0\u51fa\u8de8\u6a21\u6001\u5bf9\u9f50\u6846\u67b6\uff0c\u5c06\u8d28\u8c31\u6570\u636e\u6620\u5c04\u5230\u9884\u8bad\u7ec3\u5316\u5b66\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u7ed3\u6784\u5d4c\u5165\u7a7a\u95f4\uff0c\u89e3\u51b3\u8d28\u8c31\u5206\u5b50\u8bc6\u522b\u4e2d\u7684\u6cdb\u5316\u74f6\u9888", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5c06\u8d28\u8c31\u5339\u914d\u89c6\u4e3a\u5c01\u95ed\u96c6\u8bc6\u522b\u4efb\u52a1\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u5206\u5b50\u9aa8\u67b6\u7ed3\u6784\uff0c\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898", "method": "\u8de8\u6a21\u6001\u5bf9\u9f50\u6846\u67b6\uff0c\u76f4\u63a5\u5c06\u8d28\u8c31\u6620\u5c04\u5230\u9884\u8bad\u7ec3\u5316\u5b66\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u7ed3\u6784\u5d4c\u5165\u7a7a\u95f4\uff0c\u6574\u5408\u7269\u7406\u8c31\u5206\u8fa8\u7387\u548c\u5206\u5b50\u7ed3\u6784\u5d4c\u5165", "result": "\u5728\u4e25\u683c\u9aa8\u67b6\u4e0d\u76f8\u4ea4\u57fa\u51c6\u4e0a\uff0cTop-1\u51c6\u786e\u7387\u8fbe42.2%\uff08256\u8def\u96f6\u6837\u672c\u68c0\u7d22\uff09\uff0c\u5168\u5c40\u68c0\u7d22\u4e0b\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c5\u8def5\u6837\u672c\u5206\u5b50\u91cd\u8bc6\u522b\u51c6\u786e\u7387\u8fbe95.4%", "conclusion": "\u663e\u5f0f\u6574\u5408\u7269\u7406\u8c31\u5206\u8fa8\u7387\u548c\u5206\u5b50\u7ed3\u6784\u5d4c\u5165\u662f\u89e3\u51b3\u8d28\u8c31\u5206\u5b50\u8bc6\u522b\u6cdb\u5316\u74f6\u9888\u7684\u5173\u952e\uff0c\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u7a7a\u95f4\u5177\u6709\u5f3a\u5316\u5b66\u4e00\u81f4\u6027"}}
{"id": "2602.00549", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00549", "abs": "https://arxiv.org/abs/2602.00549", "authors": ["Kezhao Lai", "Yutao Lai", "Hai-Lin Liu"], "title": "Beyond the Node: Clade-level Selection for Efficient MCTS in Automatic Heuristic Design", "comment": null, "summary": "While Monte Carlo Tree Search (MCTS) shows promise in Large Language Model (LLM) based Automatic Heuristic Design (AHD), it suffers from a critical over-exploitation tendency under the limited computational budgets required for heuristic evaluation. To address this limitation, we propose Clade-AHD, an efficient framework that replaces node-level point estimates with clade-level Bayesian beliefs. By aggregating descendant evaluations into Beta distributions and performing Thompson Sampling over these beliefs, Clade-AHD explicitly models uncertainty to guide exploration, enabling more reliable decision-making under sparse and noisy evaluations. Extensive experiments on complex combinatorial optimization problems demonstrate that Clade-AHD consistently outperforms state-of-the-art methods while significantly reducing computational cost. The source code is publicly available at: https://github.com/Mriya0306/Clade-AHD.", "AI": {"tldr": "Clade-AHD\uff1a\u7528\u57fa\u4e8e\u7c07\u7684\u8d1d\u53f6\u65af\u4fe1\u5ff5\u66ff\u4ee3\u8282\u70b9\u7ea7\u70b9\u4f30\u8ba1\uff0c\u89e3\u51b3MCTS\u5728LLM\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u8fc7\u5ea6\u5229\u7528\u95ee\u9898\uff0c\u901a\u8fc7Thompson\u91c7\u6837\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u63a2\u7d22", "motivation": "MCTS\u5728\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u5b58\u5728\u8fc7\u5ea6\u5229\u7528\u503e\u5411\uff0c\u7279\u522b\u662f\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u8fdb\u884c\u542f\u53d1\u5f0f\u8bc4\u4f30\u65f6\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u6027\u80fd\u8868\u73b0", "method": "\u63d0\u51faClade-AHD\u6846\u67b6\uff0c\u5c06\u8282\u70b9\u7ea7\u70b9\u4f30\u8ba1\u66ff\u6362\u4e3a\u7c07\u7ea7\u8d1d\u53f6\u65af\u4fe1\u5ff5\uff0c\u901a\u8fc7\u5c06\u540e\u4ee3\u8bc4\u4f30\u805a\u5408\u4e3aBeta\u5206\u5e03\uff0c\u5e76\u5bf9\u8fd9\u4e9b\u4fe1\u5ff5\u6267\u884cThompson\u91c7\u6837\u6765\u663e\u5f0f\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027", "result": "\u5728\u590d\u6742\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cClade-AHD\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "conclusion": "Clade-AHD\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u6765\u6307\u5bfc\u63a2\u7d22\uff0c\u5728\u7a00\u758f\u548c\u566a\u58f0\u8bc4\u4f30\u4e0b\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u51b3\u7b56\uff0c\u6709\u6548\u89e3\u51b3\u4e86MCTS\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u8fc7\u5ea6\u5229\u7528\u95ee\u9898"}}
{"id": "2602.00567", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00567", "abs": "https://arxiv.org/abs/2602.00567", "authors": ["Tian Zhang", "Yujia Tong", "Junhao Dong", "Ke Xu", "Yuze Wang", "Jingling Yuan"], "title": "Forget by Uncertainty: Orthogonal Entropy Unlearning for Quantized Neural Networks", "comment": null, "summary": "The deployment of quantized neural networks on edge devices, combined with privacy regulations like GDPR, creates an urgent need for machine unlearning in quantized models. However, existing methods face critical challenges: they induce forgetting by training models to memorize incorrect labels, conflating forgetting with misremembering, and employ scalar gradient reweighting that cannot resolve directional conflicts between gradients. We propose OEU, a novel Orthogonal Entropy Unlearning framework with two key innovations: 1) Entropy-guided unlearning maximizes prediction uncertainty on forgotten data, achieving genuine forgetting rather than confident misprediction, and 2) Gradient orthogonal projection eliminates interference by projecting forgetting gradients onto the orthogonal complement of retain gradients, providing theoretical guarantees for utility preservation under first-order approximation. Extensive experiments demonstrate that OEU outperforms existing methods in both forgetting effectiveness and retain accuracy.", "AI": {"tldr": "OEU\u662f\u4e00\u4e2a\u7528\u4e8e\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u673a\u5668\u9057\u5fd8\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u71b5\u5f15\u5bfc\u9057\u5fd8\u548c\u68af\u5ea6\u6b63\u4ea4\u6295\u5f71\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5728\u9057\u5fd8\u6548\u679c\u548c\u4fdd\u7559\u7cbe\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u4e0eGDPR\u7b49\u9690\u79c1\u6cd5\u89c4\u7684\u7ed3\u5408\uff0c\u8feb\u5207\u9700\u8981\u91cf\u5316\u6a21\u578b\u7684\u673a\u5668\u9057\u5fd8\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5173\u952e\u95ee\u9898\uff1a\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u8bb0\u5fc6\u9519\u8bef\u6807\u7b7e\u6765\u8bf1\u5bfc\u9057\u5fd8\uff0c\u6df7\u6dc6\u4e86\u9057\u5fd8\u4e0e\u9519\u8bef\u8bb0\u5fc6\uff1b\u4f7f\u7528\u6807\u91cf\u68af\u5ea6\u91cd\u52a0\u6743\u65e0\u6cd5\u89e3\u51b3\u68af\u5ea6\u95f4\u7684\u65b9\u5411\u51b2\u7a81\u3002", "method": "\u63d0\u51faOEU\u6b63\u4ea4\u71b5\u9057\u5fd8\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u71b5\u5f15\u5bfc\u9057\u5fd8\uff1a\u6700\u5927\u5316\u9057\u5fd8\u6570\u636e\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u9057\u5fd8\u800c\u975e\u81ea\u4fe1\u7684\u9519\u8bef\u9884\u6d4b\uff1b2) \u68af\u5ea6\u6b63\u4ea4\u6295\u5f71\uff1a\u5c06\u9057\u5fd8\u68af\u5ea6\u6295\u5f71\u5230\u4fdd\u7559\u68af\u5ea6\u7684\u6b63\u4ea4\u8865\u7a7a\u95f4\uff0c\u5728\u4e00\u9636\u8fd1\u4f3c\u4e0b\u4e3a\u6548\u7528\u4fdd\u6301\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cOEU\u5728\u9057\u5fd8\u6548\u679c\u548c\u4fdd\u7559\u7cbe\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "OEU\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u673a\u5668\u9057\u5fd8\u95ee\u9898\uff0c\u901a\u8fc7\u71b5\u5f15\u5bfc\u9057\u5fd8\u548c\u68af\u5ea6\u6b63\u4ea4\u6295\u5f71\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u9057\u5fd8\u548c\u6548\u7528\u4fdd\u6301\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9690\u79c1\u5408\u89c4\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00573", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00573", "abs": "https://arxiv.org/abs/2602.00573", "authors": ["Zheng Zhang", "Tao Hu", "Xueheng Li", "Yang Wang", "Rui Li", "Jie Zhang", "Chengjun Xie"], "title": "When Classes Evolve: A Benchmark and Framework for Stage-Aware Class-Incremental Learning", "comment": null, "summary": "Class-Incremental Learning (CIL) aims to sequentially learn new classes while mitigating catastrophic forgetting of previously learned knowledge. Conventional CIL approaches implicitly assume that classes are morphologically static, focusing primarily on preserving previously learned representations as new classes are introduced. However, this assumption neglects intra-class evolution: a phenomenon wherein instances of the same semantic class undergo significant morphological transformations, such as a larva turning into a butterfly. Consequently, a model must both discriminate between classes and adapt to evolving appearances within a single class. To systematically address this challenge, we formalize Stage-Aware CIL (Stage-CIL), a paradigm in which each class is learned progressively through distinct morphological stages. To facilitate rigorous evaluation within this paradigm, we introduce the Stage-Bench, a 10-domain, 2-stages dataset and protocol that jointly measure inter- and intra-class forgetting. We further propose STAGE, a novel method that explicitly learns abstract and transferable evolution patterns within a fixed-size memory pool. By decoupling semantic identity from transformation dynamics, STAGE enables accurate prediction of future morphologies based on earlier representations. Extensive empirical evaluation demonstrates that STAGE consistently and substantially outperforms existing state-of-the-art approaches, highlighting its effectiveness in simultaneously addressing inter-class discrimination and intra-class morphological adaptation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faStage-CIL\u65b0\u8303\u5f0f\uff0c\u89e3\u51b3\u4f20\u7edf\u7c7b\u589e\u91cf\u5b66\u4e60\u4e2d\u5ffd\u7565\u7c7b\u5185\u5f62\u6001\u6f14\u5316\u7684\u95ee\u9898\uff0c\u5e76\u5f15\u5165Stage-Bench\u6570\u636e\u96c6\u548cSTAGE\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u8bed\u4e49\u8eab\u4efd\u4e0e\u8f6c\u6362\u52a8\u6001\u6765\u540c\u65f6\u5904\u7406\u7c7b\u95f4\u533a\u5206\u548c\u7c7b\u5185\u5f62\u6001\u9002\u5e94\u3002", "motivation": "\u4f20\u7edf\u7c7b\u589e\u91cf\u5b66\u4e60\u5047\u8bbe\u7c7b\u522b\u5f62\u6001\u9759\u6001\uff0c\u5ffd\u7565\u4e86\u7c7b\u5185\u6f14\u5316\u73b0\u8c61\uff08\u5982\u5e7c\u866b\u53d8\u8774\u8776\uff09\uff0c\u5bfc\u81f4\u6a21\u578b\u9700\u8981\u540c\u65f6\u5904\u7406\u7c7b\u95f4\u533a\u5206\u548c\u7c7b\u5185\u5f62\u6001\u9002\u5e94\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u8fd9\u79cd\u53cc\u91cd\u6311\u6218\u3002", "method": "\u63d0\u51faStage-CIL\u8303\u5f0f\uff0c\u5c06\u7c7b\u522b\u5b66\u4e60\u5206\u89e3\u4e3a\u4e0d\u540c\u5f62\u6001\u9636\u6bb5\uff1b\u5f15\u5165Stage-Bench\u6570\u636e\u96c6\uff0810\u4e2a\u9886\u57df\uff0c2\u9636\u6bb5\uff09\u8bc4\u4f30\u534f\u8bae\uff1b\u63d0\u51faSTAGE\u65b9\u6cd5\uff0c\u5728\u56fa\u5b9a\u5185\u5b58\u6c60\u4e2d\u5b66\u4e60\u62bd\u8c61\u53ef\u8f6c\u79fb\u7684\u6f14\u5316\u6a21\u5f0f\uff0c\u89e3\u8026\u8bed\u4e49\u8eab\u4efd\u4e0e\u8f6c\u6362\u52a8\u6001\u3002", "result": "STAGE\u65b9\u6cd5\u5728Stage-Bench\u4e0a\u6301\u7eed\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u6709\u6548\u540c\u65f6\u89e3\u51b3\u7c7b\u95f4\u533a\u5206\u548c\u7c7b\u5185\u5f62\u6001\u9002\u5e94\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u65b0\u8303\u5f0f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7c7b\u589e\u91cf\u5b66\u4e60\u9700\u8981\u8003\u8651\u7c7b\u5185\u5f62\u6001\u6f14\u5316\uff0cStage-CIL\u8303\u5f0f\u3001Stage-Bench\u6570\u636e\u96c6\u548cSTAGE\u65b9\u6cd5\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u5728\u540c\u65f6\u5904\u7406\u7c7b\u95f4\u533a\u5206\u548c\u7c7b\u5185\u9002\u5e94\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.00576", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00576", "abs": "https://arxiv.org/abs/2602.00576", "authors": ["Tushaar Gangavarapu", "Jiping Li", "Christopher Vattheuer", "Zhangyang Wang", "Baharan Mirzasoleiman"], "title": "Data Distribution as a Lever for Guiding Optimizers Toward Superior Generalization in LLMs", "comment": null, "summary": "Can modifying the training data distribution guide optimizers toward solutions with improved generalization when training large language models (LLMs)? In this work, we theoretically analyze an in-context linear regression model with multi-head linear self-attention, and compare the training dynamics of two gradient based optimizers, namely gradient descent (GD) and sharpness-aware minimization (SAM), the latter exhibiting superior generalization properties but is prohibitively expensive for training even medium-sized LLMs. We show, for the first time, that SAM induces a lower simplicity bias (SB)-the tendency of an optimizer to preferentially learn simpler features earlier in training-and identify this reduction as a key factor underlying its improved generalization performance. Motivated by this insight, we demonstrate that altering the training data distribution by upsampling or augmenting examples learned later in training similarly reduces SB and leads to improved generalization. Our extensive experiments show that our strategy improves the performance of multiple LLMs-including Phi2-2.7B , Llama3.2-1B, Gemma3-1B-PT, and Qwen3-0.6B-Base-achieving relative accuracy gains up to 18% when fine-tuned with AdamW and Muon on mathematical reasoning tasks.", "AI": {"tldr": "\u901a\u8fc7\u4fee\u6539\u8bad\u7ec3\u6570\u636e\u5206\u5e03\uff08\u4e0a\u91c7\u6837\u6216\u589e\u5f3a\u540e\u671f\u5b66\u4e60\u7684\u6837\u672c\uff09\u53ef\u4ee5\u964d\u4f4e\u4f18\u5316\u5668\u7684\u7b80\u5355\u6027\u504f\u7f6e\uff0c\u4ece\u800c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u9ad8\u8fbe18%\u7684\u76f8\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4fee\u6539\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u6765\u5f15\u5bfc\u4f18\u5316\u5668\u83b7\u5f97\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002SAM\u4f18\u5316\u5668\u867d\u7136\u6cdb\u5316\u6027\u80fd\u597d\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u627e\u5230\u66f4\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u7406\u8bba\u5206\u6790\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u591a\u5934\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\uff0c\u6bd4\u8f83GD\u548cSAM\u7684\u8bad\u7ec3\u52a8\u6001\u3002\u53d1\u73b0SAM\u964d\u4f4e\u7b80\u5355\u6027\u504f\u7f6e\uff0c\u8fdb\u800c\u63d0\u51fa\u901a\u8fc7\u4e0a\u91c7\u6837\u6216\u589e\u5f3a\u540e\u671f\u5b66\u4e60\u6837\u672c\u6765\u4fee\u6539\u8bad\u7ec3\u6570\u636e\u5206\u5e03\uff0c\u4ee5\u7c7b\u4f3c\u65b9\u5f0f\u964d\u4f4e\u7b80\u5355\u6027\u504f\u7f6e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7b56\u7565\u663e\u8457\u63d0\u5347\u591a\u4e2aLLM\uff08Phi2-2.7B\u3001Llama3.2-1B\u3001Gemma3-1B-PT\u3001Qwen3-0.6B-Base\uff09\u7684\u6027\u80fd\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u4f7f\u7528AdamW\u548cMuon\u5fae\u8c03\u65f6\u83b7\u5f97\u9ad8\u8fbe18%\u7684\u76f8\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u4fee\u6539\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u6765\u964d\u4f4e\u7b80\u5355\u6027\u504f\u7f6e\u662f\u63d0\u5347LLM\u6cdb\u5316\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e3a\u8bad\u7ec3\u5927\u6a21\u578b\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2602.00577", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00577", "abs": "https://arxiv.org/abs/2602.00577", "authors": ["Yuze Wang", "Yujia Tong", "Ke Xu", "Jingling Yuan", "Jiawei Jiang", "Chuang Hu"], "title": "Sparsity-Aware Unlearning for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) inevitably memorize sensitive information during training, posing significant privacy risks. Machine unlearning has emerged as a promising solution to selectively remove such information without full retraining. However, existing methods are designed for dense models and overlook model sparsification-an essential technique for efficient LLM deployment. We find that unlearning effectiveness degrades substantially on sparse models. Through empirical analysis, we reveal that this degradation occurs because existing unlearning methods require updating all parameters, yet sparsification prunes substantial weights to zero, fundamentally limiting the model's forgetting capacity. To address this challenge, we propose Sparsity-Aware Unlearning (SAU), which decouples unlearning from sparsification objectives through gradient masking that redirects updates to surviving weights, combined with importance-aware redistribution to compensate for pruned parameters. Extensive experiments demonstrate that SAU significantly outperforms existing methods on sparse LLMs, achieving effective forgetting while preserving model utility.", "AI": {"tldr": "\u63d0\u51faSAU\u65b9\u6cd5\u89e3\u51b3\u7a00\u758f\u5316\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u6548\u679c\u4e0b\u964d\u95ee\u9898\uff0c\u901a\u8fc7\u68af\u5ea6\u63a9\u7801\u548c\u91cd\u8981\u6027\u611f\u77e5\u91cd\u5206\u5e03\u5b9e\u73b0\u6709\u6548\u9057\u5fd8", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65f6\u4f1a\u8bb0\u5fc6\u654f\u611f\u4fe1\u606f\uff0c\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u9488\u5bf9\u5bc6\u96c6\u6a21\u578b\u8bbe\u8ba1\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u7a00\u758f\u5316\u8fd9\u4e00\u9ad8\u6548\u90e8\u7f72\u6280\u672f\uff0c\u5bfc\u81f4\u5728\u7a00\u758f\u6a21\u578b\u4e0a\u9057\u5fd8\u6548\u679c\u663e\u8457\u4e0b\u964d", "method": "\u63d0\u51fa\u7a00\u758f\u611f\u77e5\u9057\u5fd8(SAU)\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u68af\u5ea6\u63a9\u7801\u5c06\u66f4\u65b0\u91cd\u5b9a\u5411\u5230\u5b58\u6d3b\u6743\u91cd\uff0c\u89e3\u8026\u9057\u5fd8\u4e0e\u7a00\u758f\u5316\u76ee\u6807\uff1b2) \u91cd\u8981\u6027\u611f\u77e5\u91cd\u5206\u5e03\u8865\u507f\u88ab\u526a\u679d\u53c2\u6570", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eSAU\u5728\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u6709\u6548\u9057\u5fd8\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5b9e\u7528\u6027", "conclusion": "SAU\u89e3\u51b3\u4e86\u7a00\u758f\u5316\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u6548\u679c\u4e0b\u964d\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548\u90e8\u7f72\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00582", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00582", "abs": "https://arxiv.org/abs/2602.00582", "authors": ["Xiangfei Qiu", "Kangjia Yan", "Xvyuan Liu", "Xingjian Wu", "Jilin Hu"], "title": "Bridging Time and Frequency: A Joint Modeling Framework for Irregular Multivariate Time Series Forecasting", "comment": null, "summary": "Irregular multivariate time series forecasting (IMTSF) is challenging due to non-uniform sampling and variable asynchronicity. These irregularities violate the equidistant assumptions of standard models, hindering local temporal modeling and rendering classical frequency-domain methods ineffective for capturing global periodic structures. To address this challenge, we propose TFMixer, a joint time-frequency modeling framework for IMTS forecasting. Specifically, TFMixer incorporates a Global Frequency Module that employs a learnable Non-Uniform Discrete Fourier Transform (NUDFT) to directly extract spectral representations from irregular timestamps. In parallel, the Local Time Module introduces a query-based patch mixing mechanism to adaptively aggregate informative temporal patches and alleviate information density imbalance. Finally, TFMixer fuses the time-domain and frequency-domain representations to generate forecasts and further leverages inverse NUDFT for explicit seasonal extrapolation. Extensive experiments on real-world datasets demonstrate the state--of-the-art performance of TFMixer.", "AI": {"tldr": "TFMixer\u662f\u4e00\u4e2a\u7528\u4e8e\u4e0d\u89c4\u5219\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u8054\u5408\u65f6\u9891\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u975e\u5747\u5300\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u63d0\u53d6\u9891\u57df\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u67e5\u8be2\u7684\u8865\u4e01\u6df7\u5408\u673a\u5236\u8fdb\u884c\u65f6\u57df\u5efa\u6a21\uff0c\u5b9e\u73b0\u72b6\u6001-of-the-art\u6027\u80fd\u3002", "motivation": "\u4e0d\u89c4\u5219\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9762\u4e34\u975e\u5747\u5300\u91c7\u6837\u548c\u53d8\u91cf\u5f02\u6b65\u6027\u7684\u6311\u6218\uff0c\u8fd9\u4e9b\u4e0d\u89c4\u5219\u6027\u8fdd\u53cd\u4e86\u6807\u51c6\u6a21\u578b\u7684\u7b49\u8ddd\u5047\u8bbe\uff0c\u963b\u788d\u4e86\u5c40\u90e8\u65f6\u95f4\u5efa\u6a21\uff0c\u5e76\u4f7f\u7ecf\u5178\u7684\u9891\u57df\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u6355\u6349\u5168\u5c40\u5468\u671f\u6027\u7ed3\u6784\u3002", "method": "\u63d0\u51faTFMixer\u6846\u67b6\uff0c\u5305\u542b\uff1a1) \u5168\u5c40\u9891\u7387\u6a21\u5757\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u975e\u5747\u5300\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u76f4\u63a5\u4ece\u4e0d\u89c4\u5219\u65f6\u95f4\u6233\u63d0\u53d6\u9891\u8c31\u8868\u793a\uff1b2) \u5c40\u90e8\u65f6\u95f4\u6a21\u5757\uff0c\u5f15\u5165\u57fa\u4e8e\u67e5\u8be2\u7684\u8865\u4e01\u6df7\u5408\u673a\u5236\u81ea\u9002\u5e94\u805a\u5408\u4fe1\u606f\u6027\u65f6\u95f4\u8865\u4e01\uff1b3) \u878d\u5408\u65f6\u57df\u548c\u9891\u57df\u8868\u793a\u751f\u6210\u9884\u6d4b\uff0c\u5e76\u5229\u7528\u9006NUDFT\u8fdb\u884c\u663e\u5f0f\u5b63\u8282\u6027\u5916\u63a8\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660eTFMixer\u8fbe\u5230\u4e86state-of-the-art\u6027\u80fd\u3002", "conclusion": "TFMixer\u901a\u8fc7\u8054\u5408\u65f6\u9891\u5efa\u6a21\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u89c4\u5219\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6311\u6218\uff0c\u4e3a\u5904\u7406\u975e\u5747\u5300\u91c7\u6837\u548c\u53d8\u91cf\u5f02\u6b65\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00587", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00587", "abs": "https://arxiv.org/abs/2602.00587", "authors": ["Mahesh Keswani", "Samyak Jain", "Raunak P. Bhattacharyya"], "title": "Safe Langevin Soft Actor Critic", "comment": "20 pages, 12 figures", "summary": "Balancing reward and safety in constrained reinforcement learning remains challenging due to poor generalization from sharp value minima and inadequate handling of heavy-tailed risk distribution. We introduce Safe Langevin Soft Actor-Critic (SL-SAC), a principled algorithm that addresses both issues through parameter-space exploration and distributional risk control. Our approach combines three key mechanisms: (1) Adaptive Stochastic Gradient Langevin Dynamics (aSGLD) for reward critics, promoting ensemble diversity and escape from poor optima; (2) distributional cost estimation via Implicit Quantile Networks (IQN) with Conditional Value-at-Risk (CVaR) optimization for tail-risk mitigation; and (3) a reactive Lagrangian relaxation scheme that adapts constraint enforcement based on the empirical CVaR of episodic costs. We provide theoretical guarantees on CVaR estimation error and demonstrate that CVaR-based Lagrange updates yield stronger constraint violation signals than expected-cost updates. On Safety-Gymnasium benchmarks, SL-SAC achieves the lowest cost in 7 out of 10 tasks while maintaining competitive returns, with cost reductions of 19-63% in velocity tasks compared to state-of-the-art baselines.", "AI": {"tldr": "SL-SAC\u662f\u4e00\u79cd\u5b89\u5168\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u53c2\u6570\u7a7a\u95f4\u63a2\u7d22\u548c\u5206\u5e03\u98ce\u9669\u63a7\u5236\u89e3\u51b3\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u4e0e\u5b89\u5168\u7684\u5e73\u8861\u95ee\u9898\uff0c\u5728Safety-Gymnasium\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u4e0e\u5b89\u5168\u7684\u5e73\u8861\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u4e3b\u8981\u95ee\u9898\u5305\u62ec\uff1a\u4ece\u5c16\u9510\u4ef7\u503c\u6700\u5c0f\u503c\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u4ee5\u53ca\u5bf9\u91cd\u5c3e\u98ce\u9669\u5206\u5e03\u5904\u7406\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u4e09\u79cd\u5173\u952e\u673a\u5236\uff1a1) \u4f7f\u7528\u81ea\u9002\u5e94\u968f\u673a\u68af\u5ea6\u6717\u4e4b\u4e07\u52a8\u529b\u5b66(aSGLD)\u8fdb\u884c\u5956\u52b1\u6279\u8bc4\u5668\u8bad\u7ec3\uff0c\u4fc3\u8fdb\u96c6\u6210\u591a\u6837\u6027\u5e76\u9003\u79bb\u4e0d\u826f\u6700\u4f18\u89e3\uff1b2) \u901a\u8fc7\u9690\u5f0f\u5206\u4f4d\u6570\u7f51\u7edc(IQN)\u8fdb\u884c\u5206\u5e03\u6210\u672c\u4f30\u8ba1\uff0c\u7ed3\u5408\u6761\u4ef6\u98ce\u9669\u4ef7\u503c(CVaR)\u4f18\u5316\u6765\u51cf\u8f7b\u5c3e\u90e8\u98ce\u9669\uff1b3) \u57fa\u4e8e\u7ecf\u9a8cCVaR\u7684\u53cd\u5e94\u6027\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u65b9\u6848\uff0c\u81ea\u9002\u5e94\u5730\u6267\u884c\u7ea6\u675f\u3002", "result": "\u5728Safety-Gymnasium\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSL-SAC\u572810\u4e2a\u4efb\u52a1\u4e2d\u76847\u4e2a\u5b9e\u73b0\u4e86\u6700\u4f4e\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u56de\u62a5\uff0c\u5728\u901f\u5ea6\u4efb\u52a1\u4e2d\u6210\u672c\u964d\u4f4e\u4e8619-63%\u3002", "conclusion": "SL-SAC\u901a\u8fc7\u53c2\u6570\u7a7a\u95f4\u63a2\u7d22\u548c\u5206\u5e03\u98ce\u9669\u63a7\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\u548c\u5c3e\u90e8\u98ce\u9669\u5904\u7406\u95ee\u9898\uff0c\u5728\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.00589", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00589", "abs": "https://arxiv.org/abs/2602.00589", "authors": ["Xiangfei Qiu", "Xvyuan Liu", "Tianen Shen", "Xingjian Wu", "Hanyin Cheng", "Bin Yang", "Jilin Hu"], "title": "SEER: Transformer-based Robust Time Series Forecasting via Automated Patch Enhancement and Replacement", "comment": null, "summary": "Time series forecasting is important in many fields that require accurate predictions for decision-making. Patching techniques, commonly used and effective in time series modeling, help capture temporal dependencies by dividing the data into patches. However, existing patch-based methods fail to dynamically select patches and typically use all patches during the prediction process. In real-world time series, there are often low-quality issues during data collection, such as missing values, distribution shifts, anomalies and white noise, which may cause some patches to contain low-quality information, negatively impacting the prediction results. To address this issue, this study proposes a robust time series forecasting framework called SEER. Firstly, we propose an Augmented Embedding Module, which improves patch-wise representations using a Mixture-of-Experts (MoE) architecture and obtains series-wise token representations through a channel-adaptive perception mechanism. Secondly, we introduce a Learnable Patch Replacement Module, which enhances forecasting robustness and model accuracy through a two-stage process: 1) a dynamic filtering mechanism eliminates negative patch-wise tokens; 2) a replaced attention module substitutes the identified low-quality patches with global series-wise token, further refining their representations through a causal attention mechanism. Comprehensive experimental results demonstrate the SOTA performance of SEER.", "AI": {"tldr": "SEER\u662f\u4e00\u4e2a\u9c81\u68d2\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u8865\u4e01\u66ff\u6362\u673a\u5236\u52a8\u6001\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u8865\u4e01\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8865\u4e01\u7684\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u65e0\u6cd5\u52a8\u6001\u9009\u62e9\u8865\u4e01\uff0c\u800c\u771f\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u5e38\u5b58\u5728\u7f3a\u5931\u503c\u3001\u5206\u5e03\u504f\u79fb\u3001\u5f02\u5e38\u548c\u566a\u58f0\u7b49\u4f4e\u8d28\u91cf\u95ee\u9898\uff0c\u5bfc\u81f4\u67d0\u4e9b\u8865\u4e01\u5305\u542b\u4f4e\u8d28\u91cf\u4fe1\u606f\uff0c\u5f71\u54cd\u9884\u6d4b\u7ed3\u679c\u3002", "method": "1) \u63d0\u51fa\u589e\u5f3a\u5d4c\u5165\u6a21\u5757\uff0c\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u6539\u8fdb\u8865\u4e01\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u901a\u9053\u81ea\u9002\u5e94\u611f\u77e5\u673a\u5236\u83b7\u5f97\u5e8f\u5217\u7ea7\u6807\u8bb0\u8868\u793a\uff1b2) \u5f15\u5165\u53ef\u5b66\u4e60\u8865\u4e01\u66ff\u6362\u6a21\u5757\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8fc7\u7a0b\uff1a\u52a8\u6001\u8fc7\u6ee4\u673a\u5236\u6d88\u9664\u8d1f\u9762\u8865\u4e01\u6807\u8bb0\uff0c\u66ff\u6362\u6ce8\u610f\u529b\u6a21\u5757\u7528\u5168\u5c40\u5e8f\u5217\u7ea7\u6807\u8bb0\u66ff\u4ee3\u4f4e\u8d28\u91cf\u8865\u4e01\uff0c\u5e76\u901a\u8fc7\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u4e00\u6b65\u7cbe\u5316\u8868\u793a\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eSEER\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "SEER\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8865\u4e01\u9009\u62e9\u548c\u66ff\u6362\u673a\u5236\uff0c\u6709\u6548\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u4f4e\u8d28\u91cf\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2602.00596", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00596", "abs": "https://arxiv.org/abs/2602.00596", "authors": ["Govind Waghmare", "Srini Rohan Gujulla Leel", "Nikhil Tumbde", "Sumedh B G", "Sonia Gupta", "Srikanta Bedathur"], "title": "Kernelized Edge Attention: Addressing Semantic Attention Blurring in Temporal Graph Neural Networks", "comment": "Accepted at AAAI 2026", "summary": "Temporal Graph Neural Networks (TGNNs) aim to capture the evolving structure and timing of interactions in dynamic graphs. Although many models incorporate time through encodings or architectural design, they often compute attention over entangled node and edge representations, failing to reflect their distinct temporal behaviors. Node embeddings evolve slowly as they aggregate long-term structural context, while edge features reflect transient, timestamped interactions (e.g. messages, trades, or transactions). This mismatch results in semantic attention blurring, where attention weights cannot distinguish between slowly drifting node states and rapidly changing, information-rich edge interactions. As a result, models struggle to capture fine-grained temporal dependencies and provide limited transparency into how temporal relevance is computed. This paper introduces KEAT (Kernelized Edge Attention for Temporal Graphs), a novel attention formulation that modulates edge features using a family of continuous-time kernels, including Laplacian, RBF, and learnable MLP variant. KEAT preserves the distinct roles of nodes and edges, and integrates seamlessly with both Transformer-style (e.g., DyGFormer) and message-passing (e.g., TGN) architectures. It achieves up to 18% MRR improvement over the recent DyGFormer and 7% over TGN on link prediction tasks, enabling more accurate, interpretable and temporally aware message passing in TGNNs.", "AI": {"tldr": "KEAT\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u8fde\u7eed\u65f6\u95f4\u6838\u51fd\u6570\u8c03\u5236\u8fb9\u7279\u5f81\uff0c\u89e3\u51b3TGNN\u4e2d\u8282\u70b9\u548c\u8fb9\u7279\u5f81\u6df7\u6dc6\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u56fe\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709TGNN\u6a21\u578b\u5728\u8ba1\u7b97\u6ce8\u610f\u529b\u65f6\u901a\u5e38\u5c06\u8282\u70b9\u548c\u8fb9\u8868\u793a\u7ea0\u7f20\u5728\u4e00\u8d77\uff0c\u5ffd\u7565\u4e86\u5b83\u4eec\u4e0d\u540c\u7684\u65f6\u95f4\u884c\u4e3a\u6a21\u5f0f\u3002\u8282\u70b9\u5d4c\u5165\u7f13\u6162\u6f14\u5316\u4ee5\u805a\u5408\u957f\u671f\u7ed3\u6784\u4e0a\u4e0b\u6587\uff0c\u800c\u8fb9\u7279\u5f81\u53cd\u6620\u77ac\u65f6\u7684\u5e26\u65f6\u95f4\u6233\u4ea4\u4e92\u3002\u8fd9\u79cd\u4e0d\u5339\u914d\u5bfc\u81f4\u8bed\u4e49\u6ce8\u610f\u529b\u6a21\u7cca\uff0c\u4f7f\u6a21\u578b\u96be\u4ee5\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "KEAT\uff08Kernelized Edge Attention for Temporal Graphs\uff09\u4f7f\u7528\u8fde\u7eed\u65f6\u95f4\u6838\u51fd\u6570\uff08\u5305\u62ec\u62c9\u666e\u62c9\u65af\u6838\u3001RBF\u6838\u548c\u53ef\u5b66\u4e60\u7684MLP\u53d8\u4f53\uff09\u6765\u8c03\u5236\u8fb9\u7279\u5f81\uff0c\u4fdd\u6301\u8282\u70b9\u548c\u8fb9\u7684\u4e0d\u540c\u89d2\u8272\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230Transformer\u98ce\u683c\uff08\u5982DyGFormer\uff09\u548c\u6d88\u606f\u4f20\u9012\uff08\u5982TGN\uff09\u67b6\u6784\u4e2d\u3002", "result": "\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e0a\uff0cKEAT\u76f8\u6bd4\u6700\u8fd1\u7684DyGFormer\u5b9e\u73b0\u4e86\u9ad8\u8fbe18%\u7684MRR\u6539\u8fdb\uff0c\u76f8\u6bd4TGN\u5b9e\u73b0\u4e867%\u7684\u6539\u8fdb\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u548c\u5177\u6709\u65f6\u95f4\u611f\u77e5\u80fd\u529b\u7684\u6d88\u606f\u4f20\u9012\u3002", "conclusion": "KEAT\u901a\u8fc7\u89e3\u8026\u8282\u70b9\u548c\u8fb9\u7684\u65f6\u95f4\u884c\u4e3a\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u548c\u53ef\u89e3\u91ca\u7684TGNN\u6ce8\u610f\u529b\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u56fe\u5efa\u6a21\u7684\u6027\u80fd\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2602.00603", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00603", "abs": "https://arxiv.org/abs/2602.00603", "authors": ["Luca Viano", "Ruida Zhou", "Yifan Sun", "Mahdi Namazifar", "Volkan Cevher", "Shoham Sabach", "Mohammad Ghavamzadeh"], "title": "Direct Preference Optimization with Rating Information: Practical Algorithms and Provable Gains", "comment": null, "summary": "The class of direct preference optimization (DPO) algorithms has emerged as a promising approach for solving the alignment problem in foundation models. These algorithms work with very limited feedback in the form of pairwise preferences and fine-tune models to align with these preferences without explicitly learning a reward model. While the form of feedback used by these algorithms makes the data collection process easy and relatively more accurate, its ambiguity in terms of the quality of responses could have negative implications. For example, it is not clear if a decrease (increase) in the likelihood of preferred (dispreferred) responses during the execution of these algorithms could be interpreted as a positive or negative phenomenon. In this paper, we study how to design algorithms that can leverage additional information in the form of rating gap, which informs the learner how much the chosen response is better than the rejected one. We present new algorithms that can achieve faster statistical rates than DPO in presence of accurate rating gap information. Moreover, we theoretically prove and empirically show that the performance of our algorithms is robust to inaccuracy in rating gaps. Finally, we demonstrate the solid performance of our methods in comparison to a number of DPO-style algorithms across a wide range of LLMs and evaluation benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u504f\u597d\u4f18\u5316\u7b97\u6cd5\uff0c\u5229\u7528\u8bc4\u5206\u5dee\u8ddd\u4fe1\u606f\u6765\u63d0\u5347\u5bf9\u9f50\u6548\u679c\uff0c\u76f8\u6bd4\u4f20\u7edfDPO\u7b97\u6cd5\u5177\u6709\u66f4\u5feb\u7684\u7edf\u8ba1\u6536\u655b\u901f\u5ea6\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfDPO\u7b97\u6cd5\u4ec5\u4f7f\u7528\u6210\u5bf9\u504f\u597d\u53cd\u9988\uff0c\u5b58\u5728\u4fe1\u606f\u6a21\u7cca\u6027\u95ee\u9898\u3002\u867d\u7136\u6570\u636e\u6536\u96c6\u5bb9\u6613\uff0c\u4f46\u65e0\u6cd5\u533a\u5206\u504f\u597d\u7684\u7a0b\u5ea6\u5dee\u5f02\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff08\u4f8b\u5982\u504f\u597d\u54cd\u5e94\u6982\u7387\u4e0b\u964d\u662f\u5426\u8868\u793a\u8d1f\u9762\u73b0\u8c61\uff09\u3002\u9700\u8981\u5229\u7528\u8bc4\u5206\u5dee\u8ddd\u8fd9\u4e00\u989d\u5916\u4fe1\u606f\u6765\u6539\u8fdb\u7b97\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u65b0\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u80fd\u591f\u5229\u7528\u8bc4\u5206\u5dee\u8ddd\u4fe1\u606f\uff08\u5373\u88ab\u9009\u54cd\u5e94\u6bd4\u88ab\u62d2\u7edd\u54cd\u5e94\u597d\u591a\u5c11\u7684\u7a0b\u5ea6\uff09\u3002\u7b97\u6cd5\u5728\u51c6\u786e\u8bc4\u5206\u5dee\u8ddd\u4fe1\u606f\u4e0b\u80fd\u83b7\u5f97\u6bd4DPO\u66f4\u5feb\u7684\u7edf\u8ba1\u6536\u655b\u901f\u5ea6\uff0c\u540c\u65f6\u5bf9\u8bc4\u5206\u5dee\u8ddd\u7684\u4e0d\u51c6\u786e\u6027\u5177\u6709\u9c81\u68d2\u6027\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u65b0\u7b97\u6cd5\u5728\u51c6\u786e\u8bc4\u5206\u5dee\u8ddd\u4fe1\u606f\u4e0b\u7edf\u8ba1\u6536\u655b\u901f\u5ea6\u4f18\u4e8eDPO\uff0c\u4e14\u5bf9\u8bc4\u5206\u5dee\u8ddd\u4e0d\u51c6\u786e\u6027\u5177\u6709\u9c81\u68d2\u6027\u3002\u5728\u591a\u79cdLLM\u548c\u8bc4\u4f30\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u591a\u79cdDPO\u98ce\u683c\u7b97\u6cd5\u90fd\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "conclusion": "\u5229\u7528\u8bc4\u5206\u5dee\u8ddd\u4fe1\u606f\u53ef\u4ee5\u663e\u8457\u6539\u8fdb\u504f\u597d\u4f18\u5316\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u65b0\u7b97\u6cd5\u5728\u7edf\u8ba1\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u90fd\u4f18\u4e8e\u4f20\u7edfDPO\u65b9\u6cd5\uff0c\u4e3a\u6a21\u578b\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00606", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.00606", "abs": "https://arxiv.org/abs/2602.00606", "authors": ["Ahmed Said Donmez", "Yuksel Arslantas", "Muhammed O. Sayin"], "title": "Actor-Dual-Critic Dynamics for Zero-sum and Identical-Interest Stochastic Games", "comment": null, "summary": "We propose a novel independent and payoff-based learning framework for stochastic games that is model-free, game-agnostic, and gradient-free. The learning dynamics follow a best-response-type actor-critic architecture, where agents update their strategies (actors) using feedback from two distinct critics: a fast critic that intuitively responds to observed payoffs under limited information, and a slow critic that deliberatively approximates the solution to the underlying dynamic programming problem. Crucially, the learning process relies on non-equilibrium adaptation through smoothed best responses to observed payoffs. We establish convergence to (approximate) equilibria in two-agent zero-sum and multi-agent identical-interest stochastic games over an infinite horizon. This provides one of the first payoff-based and fully decentralized learning algorithms with theoretical guarantees in both settings. Empirical results further validate the robustness and effectiveness of the proposed approach across both classes of games.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u72ec\u7acb\u3001\u57fa\u4e8e\u6536\u76ca\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u968f\u673a\u535a\u5f08\uff0c\u8be5\u6846\u67b6\u65e0\u9700\u6a21\u578b\u3001\u4e0e\u6e38\u620f\u65e0\u5173\u4e14\u65e0\u9700\u68af\u5ea6\u3002\u91c7\u7528\u6700\u4f73\u54cd\u5e94\u578b\u6f14\u5458-\u8bc4\u8bba\u5bb6\u67b6\u6784\uff0c\u901a\u8fc7\u5feb\u901f\u8bc4\u8bba\u5bb6\u548c\u6162\u901f\u8bc4\u8bba\u5bb6\u66f4\u65b0\u7b56\u7565\uff0c\u8bc1\u660e\u5728\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u4e0e\u591a\u4eba\u540c\u5229\u76ca\u968f\u673a\u535a\u5f08\u4e2d\u6536\u655b\u5230\uff08\u8fd1\u4f3c\uff09\u5747\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u968f\u673a\u535a\u5f08\u5b66\u4e60\u7b97\u6cd5\u901a\u5e38\u9700\u8981\u6a21\u578b\u77e5\u8bc6\u3001\u68af\u5ea6\u4fe1\u606f\u6216\u96c6\u4e2d\u5f0f\u534f\u8c03\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u3001\u57fa\u4e8e\u6536\u76ca\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u6709\u9650\u4fe1\u606f\u4e0b\u6709\u6548\u5b66\u4e60\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u535a\u5f08\u7c7b\u578b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6700\u4f73\u54cd\u5e94\u7684\u6f14\u5458-\u8bc4\u8bba\u5bb6\u67b6\u6784\uff1a\u6f14\u5458\uff08\u7b56\u7565\uff09\u6839\u636e\u4e24\u4e2a\u8bc4\u8bba\u5bb6\u7684\u53cd\u9988\u66f4\u65b0\uff1a1\uff09\u5feb\u901f\u8bc4\u8bba\u5bb6\u76f4\u89c2\u54cd\u5e94\u89c2\u5bdf\u5230\u7684\u6536\u76ca\uff1b2\uff09\u6162\u901f\u8bc4\u8bba\u5bb6\u5ba1\u614e\u8fd1\u4f3c\u5e95\u5c42\u52a8\u6001\u89c4\u5212\u95ee\u9898\u3002\u5b66\u4e60\u8fc7\u7a0b\u901a\u8fc7\u5e73\u6ed1\u6700\u4f73\u54cd\u5e94\u8fdb\u884c\u975e\u5747\u8861\u9002\u5e94\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5728\u65e0\u9650\u65f6\u57df\u4e0b\uff0c\u7b97\u6cd5\u80fd\u6536\u655b\u5230\uff08\u8fd1\u4f3c\uff09\u5747\u8861\uff0c\u9002\u7528\u4e8e\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u548c\u591a\u4eba\u540c\u5229\u76ca\u968f\u673a\u535a\u5f08\u3002\u8fd9\u662f\u9996\u4e2a\u5728\u8fd9\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u90fd\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u3001\u57fa\u4e8e\u6536\u76ca\u7684\u5b66\u4e60\u7b97\u6cd5\u3002\u5b9e\u8bc1\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u72ec\u7acb\u3001\u57fa\u4e8e\u6536\u76ca\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u6a21\u578b\u3001\u68af\u5ea6\u6216\u96c6\u4e2d\u534f\u8c03\uff0c\u5728\u591a\u79cd\u968f\u673a\u535a\u5f08\u7c7b\u578b\u4e2d\u5177\u6709\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u548c\u5b9e\u8bc1\u6709\u6548\u6027\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00620", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00620", "abs": "https://arxiv.org/abs/2602.00620", "authors": ["Juntao Fang", "Shifeng Xie", "Shengbin Nie", "Yuhui Ling", "Yuming Liu", "Zijian Li", "Keli Zhang", "Lujia Pan", "Themis Palpanas", "Ruichu Cai"], "title": "Rethinking Zero-Shot Time Series Classification: From Task-specific Classifiers to In-Context Inference", "comment": null, "summary": "The zero-shot evaluation of time series foundation models (TSFMs) for classification typically uses a frozen encoder followed by a task-specific classifier. However, this practice violates the training-free premise of zero-shot deployment and introduces evaluation bias due to classifier-dependent training choices. To address this issue, we propose TIC-FM, an in-context learning framework that treats the labeled training set as context and predicts labels for all test instances in a single forward pass, without parameter updates. TIC-FM pairs a time series encoder and a lightweight projection adapter with a split-masked latent memory Transformer. We further provide theoretical justification that in-context inference can subsume trained classifiers and can emulate gradient-based classifier training within a single forward pass. Experiments on 128 UCR datasets show strong accuracy, with consistent gains in the extreme low-label situation, highlighting training-free transfer", "AI": {"tldr": "\u63d0\u51faTIC-FM\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b9e\u73b0\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u771f\u6b63\u96f6\u6837\u672c\u5206\u7c7b\uff0c\u65e0\u9700\u5fae\u8c03\u5206\u7c7b\u5668\uff0c\u907f\u514d\u8bc4\u4f30\u504f\u5dee\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u95ee\u9898\uff1a\u4f7f\u7528\u51bb\u7ed3\u7f16\u7801\u5668\u540e\u63a5\u4efb\u52a1\u7279\u5b9a\u5206\u7c7b\u5668\uff0c\u8fd9\u8fdd\u53cd\u4e86\u96f6\u6837\u672c\u90e8\u7f72\u7684\u8bad\u7ec3\u514d\u8d39\u524d\u63d0\uff0c\u4e14\u5206\u7c7b\u5668\u4f9d\u8d56\u7684\u8bad\u7ec3\u9009\u62e9\u4f1a\u5f15\u5165\u8bc4\u4f30\u504f\u5dee\u3002", "method": "\u63d0\u51faTIC-FM\u6846\u67b6\uff0c\u5c06\u6807\u8bb0\u8bad\u7ec3\u96c6\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u5355\u6b21\u524d\u5411\u4f20\u64ad\u9884\u6d4b\u6240\u6709\u6d4b\u8bd5\u5b9e\u4f8b\u6807\u7b7e\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002\u7ed3\u5408\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u5668\u3001\u8f7b\u91cf\u6295\u5f71\u9002\u914d\u5668\u548c\u5206\u5272\u63a9\u7801\u6f5c\u5728\u8bb0\u5fc6Transformer\u3002", "result": "\u5728128\u4e2aUCR\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\u5f3a\u51c6\u786e\u6027\uff0c\u5728\u6781\u7aef\u4f4e\u6807\u7b7e\u60c5\u51b5\u4e0b\u8868\u73b0\u5c24\u5176\u7a81\u51fa\uff0c\u5c55\u793a\u4e86\u8bad\u7ec3\u514d\u8d39\u8fc1\u79fb\u7684\u6709\u6548\u6027\u3002", "conclusion": "TIC-FM\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u96f6\u6837\u672c\u5206\u7c7b\uff0c\u7406\u8bba\u8bc1\u660e\u4e0a\u4e0b\u6587\u63a8\u7406\u53ef\u4ee5\u66ff\u4ee3\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u5e76\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u6a21\u62df\u57fa\u4e8e\u68af\u5ea6\u7684\u5206\u7c7b\u5668\u8bad\u7ec3\u3002"}}
{"id": "2602.00624", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00624", "abs": "https://arxiv.org/abs/2602.00624", "authors": ["Hyekyung Yoon", "Minhyuk Lee", "Imseung Park", "Myungjoo Kang"], "title": "MoDEx: Mixture of Depth-specific Experts for Multivariate Long-term Time Series Forecasting", "comment": null, "summary": "Multivariate long-term time series forecasting (LTSF) supports critical applications such as traffic-flow management, solar-power scheduling, and electricity-transformer monitoring. The existing LTSF paradigms follow a three-stage pipeline of embedding, backbone refinement, and long-horizon prediction. However, the behaviors of individual backbone layers remain underexplored. We introduce layer sensitivity, a gradient-based metric inspired by GradCAM and effective receptive field theory, which quantifies both positive and negative contributions of each time point to a layer's latent features. Applying this metric to a three-layer MLP backbone reveals depth-specific specialization in modeling temporal dynamics in the input sequence. Motivated by these insights, we propose MoDEx, a lightweight Mixture of Depth-specific Experts, which replaces complex backbones with depth-specific MLP experts. MoDEx achieves state-of-the-art accuracy on seven real-world benchmarks, ranking first in 78 percent of cases, while using significantly fewer parameters and computational resources. It also integrates seamlessly into transformer variants, consistently boosting their performance and demonstrating robust generalizability as an efficient and high-performance LTSF framework.", "AI": {"tldr": "MoDEx\uff1a\u57fa\u4e8e\u5c42\u654f\u611f\u5ea6\u5206\u6790\u7684\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u591a\u53d8\u91cf\u957f\u65f6\u5e8f\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u957f\u65f6\u5e8f\u9884\u6d4b\uff08LTSF\uff09\u65b9\u6cd5\u91c7\u7528\u5d4c\u5165-\u9aa8\u5e72\u7f51\u7edc-\u9884\u6d4b\u7684\u4e09\u9636\u6bb5\u6d41\u7a0b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u9aa8\u5e72\u7f51\u7edc\u5404\u5c42\u884c\u4e3a\u7684\u6df1\u5165\u7406\u89e3\u3002\u4f5c\u8005\u53d1\u73b0\u4e0d\u540c\u6df1\u5ea6\u5c42\u5728\u5efa\u6a21\u65f6\u5e8f\u52a8\u6001\u65b9\u9762\u5177\u6709\u4e13\u95e8\u5316\u7279\u6027\uff0c\u8fd9\u542f\u53d1\u4ed6\u4eec\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684\u9884\u6d4b\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u5c42\u654f\u611f\u5ea6\u6307\u6807\uff08\u53d7GradCAM\u548c\u6709\u6548\u611f\u53d7\u91ce\u7406\u8bba\u542f\u53d1\uff09\uff0c\u91cf\u5316\u6bcf\u4e2a\u65f6\u95f4\u70b9\u5bf9\u5c42\u7279\u5f81\u7684\u8d21\u732e\u3002\u57fa\u4e8e\u6b64\u53d1\u73b0\uff0c\u63d0\u51faMoDEx\uff08\u6df1\u5ea6\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff09\uff0c\u7528\u6df1\u5ea6\u7279\u5b9a\u7684MLP\u4e13\u5bb6\u66ff\u4ee3\u590d\u6742\u9aa8\u5e72\u7f51\u7edc\uff0c\u5e76\u53ef\u4e0eTransformer\u53d8\u4f53\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u57287\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u572878%\u7684\u60c5\u51b5\u4e0b\u6392\u540d\u7b2c\u4e00\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\u8d44\u6e90\u3002\u96c6\u6210\u5230Transformer\u53d8\u4f53\u540e\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MoDEx\u4f5c\u4e3a\u4e00\u4e2a\u9ad8\u6548\u9ad8\u6027\u80fd\u7684LTSF\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u4e13\u5bb6\u6df7\u5408\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u957f\u65f6\u5e8f\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00628", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00628", "abs": "https://arxiv.org/abs/2602.00628", "authors": ["Louis Schiekiera", "Max Zimmer", "Christophe Roux", "Sebastian Pokutta", "Fritz G\u00fcnther"], "title": "From Associations to Activations: Comparing Behavioral and Hidden-State Semantic Geometry in LLMs", "comment": "25 pages including references, 15 figures, 6 tables", "summary": "We investigate the extent to which an LLM's hidden-state geometry can be recovered from its behavior in psycholinguistic experiments. Across eight instruction-tuned transformer models, we run two experimental paradigms -- similarity-based forced choice and free association -- over a shared 5,000-word vocabulary, collecting 17.5M+ trials to build behavior-based similarity matrices. Using representational similarity analysis, we compare behavioral geometries to layerwise hidden-state similarity and benchmark against FastText, BERT, and cross-model consensus. We find that forced-choice behavior aligns substantially more with hidden-state geometry than free association. In a held-out-words regression, behavioral similarity (especially forced choice) predicts unseen hidden-state similarities beyond lexical baselines and cross-model consensus, indicating that behavior-only measurements retain recoverable information about internal semantic geometry. Finally, we discuss implications for the ability of behavioral tasks to uncover hidden cognitive states.", "AI": {"tldr": "\u901a\u8fc7\u5fc3\u7406\u8bed\u8a00\u5b66\u5b9e\u9a8c\u7684\u884c\u4e3a\u6570\u636e\u53ef\u4ee5\u6062\u590dLLM\u9690\u85cf\u72b6\u6001\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u5176\u4e2d\u5f3a\u5236\u9009\u62e9\u4efb\u52a1\u6bd4\u81ea\u7531\u8054\u60f3\u4efb\u52a1\u66f4\u80fd\u53cd\u6620\u5185\u90e8\u8bed\u4e49\u51e0\u4f55", "motivation": "\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u901a\u8fc7LLM\u5728\u5fc3\u7406\u8bed\u8a00\u5b66\u5b9e\u9a8c\u4e2d\u7684\u884c\u4e3a\u6570\u636e\u6765\u6062\u590d\u5176\u9690\u85cf\u72b6\u6001\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u63a2\u7d22\u884c\u4e3a\u6d4b\u91cf\u80fd\u5426\u63ed\u793a\u5185\u90e8\u8ba4\u77e5\u72b6\u6001", "method": "\u57288\u4e2a\u6307\u4ee4\u8c03\u4f18\u7684transformer\u6a21\u578b\u4e0a\u8fd0\u884c\u4e24\u79cd\u5b9e\u9a8c\u8303\u5f0f\uff08\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u5f3a\u5236\u9009\u62e9\u548c\u81ea\u7531\u8054\u60f3\uff09\uff0c\u4f7f\u75285000\u4e2a\u5171\u4eab\u8bcd\u6c47\uff0c\u6536\u96c61750\u4e07+\u6b21\u8bd5\u9a8c\u6784\u5efa\u57fa\u4e8e\u884c\u4e3a\u7684\u76f8\u4f3c\u6027\u77e9\u9635\uff0c\u901a\u8fc7\u8868\u5f81\u76f8\u4f3c\u6027\u5206\u6790\u6bd4\u8f83\u884c\u4e3a\u51e0\u4f55\u4e0e\u5c42\u95f4\u9690\u85cf\u72b6\u6001\u76f8\u4f3c\u6027\uff0c\u5e76\u4e0eFastText\u3001BERT\u548c\u8de8\u6a21\u578b\u5171\u8bc6\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5", "result": "\u5f3a\u5236\u9009\u62e9\u884c\u4e3a\u4e0e\u9690\u85cf\u72b6\u6001\u51e0\u4f55\u7684\u5bf9\u9f50\u7a0b\u5ea6\u663e\u8457\u9ad8\u4e8e\u81ea\u7531\u8054\u60f3\uff1b\u5728\u4fdd\u7559\u8bcd\u6c47\u56de\u5f52\u4e2d\uff0c\u884c\u4e3a\u76f8\u4f3c\u6027\uff08\u7279\u522b\u662f\u5f3a\u5236\u9009\u62e9\uff09\u80fd\u591f\u9884\u6d4b\u672a\u89c1\u8fc7\u7684\u9690\u85cf\u72b6\u6001\u76f8\u4f3c\u6027\uff0c\u8d85\u8d8a\u4e86\u8bcd\u6c47\u57fa\u7ebf\u548c\u8de8\u6a21\u578b\u5171\u8bc6\uff0c\u8868\u660e\u4ec5\u57fa\u4e8e\u884c\u4e3a\u7684\u6d4b\u91cf\u4fdd\u7559\u4e86\u5173\u4e8e\u5185\u90e8\u8bed\u4e49\u51e0\u4f55\u7684\u53ef\u6062\u590d\u4fe1\u606f", "conclusion": "\u884c\u4e3a\u4efb\u52a1\u80fd\u591f\u63ed\u793aLLM\u7684\u9690\u85cf\u8ba4\u77e5\u72b6\u6001\uff0c\u5f3a\u5236\u9009\u62e9\u8303\u5f0f\u7279\u522b\u9002\u5408\u7528\u4e8e\u6062\u590d\u5185\u90e8\u8bed\u4e49\u51e0\u4f55\uff0c\u4e3a\u901a\u8fc7\u884c\u4e3a\u5b9e\u9a8c\u7406\u89e3\u6a21\u578b\u5185\u90e8\u8868\u793a\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301"}}
{"id": "2602.00636", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00636", "abs": "https://arxiv.org/abs/2602.00636", "authors": ["Yujie Yang", "Zhilong Zheng", "Shengbo Eben Li"], "title": "Equilibrium of Feasible Zone and Uncertain Model in Safe Exploration", "comment": null, "summary": "Ensuring the safety of environmental exploration is a critical problem in reinforcement learning (RL). While limiting exploration to a feasible zone has become widely accepted as a way to ensure safety, key questions remain unresolved: what is the maximum feasible zone achievable through exploration, and how can it be identified? This paper, for the first time, answers these questions by revealing that the goal of safe exploration is to find the equilibrium between the feasible zone and the environment model. This conclusion is based on the understanding that these two components are interdependent: a larger feasible zone leads to a more accurate environment model, and a more accurate model, in turn, enables exploring a larger zone. We propose the first equilibrium-oriented safe exploration framework called safe equilibrium exploration (SEE), which alternates between finding the maximum feasible zone and the least uncertain model. Using a graph formulation of the uncertain model, we prove that the uncertain model obtained by SEE is monotonically refined, the feasible zones monotonically expand, and both converge to the equilibrium of safe exploration. Experiments on classic control tasks show that our algorithm successfully expands the feasible zones with zero constraint violation, and achieves the equilibrium of safe exploration within a few iterations.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63ed\u793a\u4e86\u5b89\u5168\u63a2\u7d22\u7684\u76ee\u6807\u662f\u5728\u53ef\u884c\u533a\u57df\u4e0e\u73af\u5883\u6a21\u578b\u4e4b\u95f4\u627e\u5230\u5e73\u8861\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u9762\u5411\u5e73\u8861\u7684\u5b89\u5168\u63a2\u7d22\u6846\u67b6SEE\uff0c\u901a\u8fc7\u4ea4\u66ff\u5bfb\u627e\u6700\u5927\u53ef\u884c\u533a\u57df\u548c\u6700\u4e0d\u786e\u5b9a\u6a21\u578b\uff0c\u5b9e\u73b0\u96f6\u7ea6\u675f\u8fdd\u89c4\u7684\u5b89\u5168\u63a2\u7d22\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u63a2\u7d22\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002\u867d\u7136\u5c06\u63a2\u7d22\u9650\u5236\u5728\u53ef\u884c\u533a\u57df\u5df2\u6210\u4e3a\u786e\u4fdd\u5b89\u5168\u7684\u5e7f\u6cdb\u63a5\u53d7\u65b9\u6cd5\uff0c\u4f46\u5173\u952e\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\uff1a\u901a\u8fc7\u63a2\u7d22\u53ef\u5b9e\u73b0\u7684\u6700\u5927\u53ef\u884c\u533a\u57df\u662f\u4ec0\u4e48\uff1f\u5982\u4f55\u8bc6\u522b\u5b83\uff1f\u672c\u6587\u9996\u6b21\u56de\u7b54\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9762\u5411\u5e73\u8861\u7684\u5b89\u5168\u63a2\u7d22\u6846\u67b6SEE\uff08\u5b89\u5168\u5e73\u8861\u63a2\u7d22\uff09\uff0c\u8be5\u6846\u67b6\u4ea4\u66ff\u6267\u884c\u4e24\u4e2a\u6b65\u9aa4\uff1a1\uff09\u5bfb\u627e\u6700\u5927\u53ef\u884c\u533a\u57df\uff1b2\uff09\u5bfb\u627e\u6700\u4e0d\u786e\u5b9a\u7684\u6a21\u578b\u3002\u4f7f\u7528\u4e0d\u786e\u5b9a\u6a21\u578b\u7684\u56fe\u8868\u793a\uff0c\u8bc1\u660eSEE\u83b7\u5f97\u7684\u4e0d\u786e\u5b9a\u6a21\u578b\u5355\u8c03\u7ec6\u5316\uff0c\u53ef\u884c\u533a\u57df\u5355\u8c03\u6269\u5c55\uff0c\u4e24\u8005\u90fd\u6536\u655b\u5230\u5b89\u5168\u63a2\u7d22\u7684\u5e73\u8861\u70b9\u3002", "result": "\u5728\u7ecf\u5178\u63a7\u5236\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSEE\u7b97\u6cd5\u6210\u529f\u6269\u5c55\u4e86\u53ef\u884c\u533a\u57df\u4e14\u96f6\u7ea6\u675f\u8fdd\u89c4\uff0c\u5e76\u5728\u51e0\u6b21\u8fed\u4ee3\u5185\u5b9e\u73b0\u4e86\u5b89\u5168\u63a2\u7d22\u7684\u5e73\u8861\u3002\u8bc1\u660e\u4e0d\u786e\u5b9a\u6a21\u578b\u5355\u8c03\u7ec6\u5316\uff0c\u53ef\u884c\u533a\u57df\u5355\u8c03\u6269\u5c55\uff0c\u4e24\u8005\u90fd\u6536\u655b\u5230\u5e73\u8861\u70b9\u3002", "conclusion": "\u5b89\u5168\u63a2\u7d22\u7684\u76ee\u6807\u662f\u5728\u53ef\u884c\u533a\u57df\u4e0e\u73af\u5883\u6a21\u578b\u4e4b\u95f4\u627e\u5230\u5e73\u8861\uff0c\u4e24\u8005\u76f8\u4e92\u4f9d\u8d56\uff1a\u66f4\u5927\u7684\u53ef\u884c\u533a\u57df\u5e26\u6765\u66f4\u51c6\u786e\u7684\u73af\u5883\u6a21\u578b\uff0c\u66f4\u51c6\u786e\u7684\u6a21\u578b\u53c8\u80fd\u63a2\u7d22\u66f4\u5927\u7684\u533a\u57df\u3002SEE\u6846\u67b6\u9996\u6b21\u5b9e\u73b0\u4e86\u8fd9\u79cd\u5e73\u8861\u5bfc\u5411\u7684\u5b89\u5168\u63a2\u7d22\u3002"}}
{"id": "2602.00640", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00640", "abs": "https://arxiv.org/abs/2602.00640", "authors": ["Jingru Huang", "Haijie Xu", "Jie Guo", "Manrui Jiang", "Chen Zhang"], "title": "Combinatorial Bandit Bayesian Optimization for Tensor Outputs", "comment": null, "summary": "Bayesian optimization (BO) has been widely used to optimize expensive and black-box functions across various domains. Existing BO methods have not addressed tensor-output functions. To fill this gap, we propose a novel tensor-output BO method. Specifically, we first introduce a tensor-output Gaussian process (TOGP) with two classes of tensor-output kernels as a surrogate model of the tensor-output function, which can effectively capture the structural dependencies within the tensor. Based on it, we develop an upper confidence bound (UCB) acquisition function to select the queried points. Furthermore, we introduce a more complex and practical problem setting, named combinatorial bandit Bayesian optimization (CBBO), where only a subset of the outputs can be selected to contribute to the objective function. To tackle this, we propose a tensor-output CBBO method, which extends TOGP to handle partially observed outputs, and accordingly design a novel combinatorial multi-arm bandit-UCB2 (CMAB-UCB2) criterion to sequentially select both the queried points and the optimal output subset. Theoretical regret bounds for the two methods are established, ensuring their sublinear performance. Extensive synthetic and real-world experiments demonstrate their superiority.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u5f20\u91cf\u8f93\u51fa\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff1aTOGP\u7528\u4e8e\u5b8c\u6574\u5f20\u91cf\u8f93\u51fa\u4f18\u5316\uff0cCBBO\u7528\u4e8e\u7ec4\u5408\u9009\u62e9\u90e8\u5206\u8f93\u51fa\u7684\u4f18\u5316\uff0c\u5747\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u672a\u5904\u7406\u5f20\u91cf\u8f93\u51fa\u51fd\u6570\uff0c\u4e14\u5b9e\u9645\u5e94\u7528\u4e2d\u5e38\u9700\u9009\u62e9\u90e8\u5206\u8f93\u51fa\u8d21\u732e\u76ee\u6807\u51fd\u6570\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "1) \u63d0\u51fa\u5f20\u91cf\u8f93\u51fa\u9ad8\u65af\u8fc7\u7a0b(TOGP)\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\uff0c\u5305\u542b\u4e24\u7c7b\u5f20\u91cf\u8f93\u51fa\u6838\u51fd\u6570\u6355\u6349\u7ed3\u6784\u4f9d\u8d56\uff1b2) \u5f00\u53d1UCB\u91c7\u96c6\u51fd\u6570\u9009\u62e9\u67e5\u8be2\u70b9\uff1b3) \u9488\u5bf9\u7ec4\u5408\u9009\u62e9\u95ee\u9898\u63d0\u51faCBBO\u65b9\u6cd5\uff0c\u6269\u5c55TOGP\u5904\u7406\u90e8\u5206\u89c2\u6d4b\uff0c\u8bbe\u8ba1CMAB-UCB2\u51c6\u5219\u540c\u65f6\u9009\u62e9\u67e5\u8be2\u70b9\u548c\u6700\u4f18\u8f93\u51fa\u5b50\u96c6\u3002", "result": "\u5efa\u7acb\u4e86\u4e24\u79cd\u65b9\u6cd5\u7684\u7406\u8bba\u9057\u61be\u754c\uff0c\u786e\u4fdd\u6b21\u7ebf\u6027\u6027\u80fd\u3002\u5927\u91cf\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6210\u529f\u586b\u8865\u4e86\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u5f20\u91cf\u8f93\u51fa\u51fd\u6570\u4f18\u5316\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684TOGP\u548cCBBO\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u590d\u6742\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00647", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00647", "abs": "https://arxiv.org/abs/2602.00647", "authors": ["Noorain Mukhtiar", "Adnan Mahmood", "Quan Z. Sheng"], "title": "CoRe-Fed: Bridging Collaborative and Representation Fairness via Federated Embedding Distillation", "comment": "7 pages (main content), 2 pages (references), Accepted in AAAI 2026", "summary": "With the proliferation of distributed data sources, Federated Learning (FL) has emerged as a key approach to enable collaborative intelligence through decentralized model training while preserving data privacy. However, conventional FL algorithms often suffer from performance disparities across clients caused by heterogeneous data distributions and unequal participation, which leads to unfair outcomes. Specifically, we focus on two core fairness challenges, i.e., representation bias, arising from misaligned client representations, and collaborative bias, stemming from inequitable contribution during aggregation, both of which degrade model performance and generalizability. To mitigate these disparities, we propose CoRe-Fed, a unified optimization framework that bridges collaborative and representation fairness via embedding-level regularization and fairness-aware aggregation. Initially, an alignment-driven mechanism promotes semantic consistency between local and global embeddings to reduce representational divergence. Subsequently, a dynamic reward-penalty-based aggregation strategy adjusts each client's weight based on participation history and embedding alignment to ensure contribution-aware aggregation. Extensive experiments across diverse models and datasets demonstrate that CoRe-Fed improves both fairness and model performance over the state-of-the-art baseline algorithms.", "AI": {"tldr": "CoRe-Fed\u662f\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u516c\u5e73\u6027\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5165\u5bf9\u9f50\u548c\u516c\u5e73\u805a\u5408\u89e3\u51b3\u8868\u793a\u504f\u5dee\u548c\u534f\u4f5c\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u5b58\u5728\u6570\u636e\u5206\u5e03\u5f02\u6784\u548c\u53c2\u4e0e\u4e0d\u5e73\u7b49\u5bfc\u81f4\u7684\u6027\u80fd\u5dee\u5f02\u95ee\u9898\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\u8868\u793a\u504f\u5dee\uff08\u5ba2\u6237\u7aef\u8868\u793a\u4e0d\u4e00\u81f4\uff09\u548c\u534f\u4f5c\u504f\u5dee\uff08\u805a\u5408\u8d21\u732e\u4e0d\u516c\u5e73\uff09\uff0c\u8fd9\u5f71\u54cd\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faCoRe-Fed\u6846\u67b6\uff1a1\uff09\u5d4c\u5165\u5bf9\u9f50\u673a\u5236\u4fc3\u8fdb\u672c\u5730\u4e0e\u5168\u5c40\u5d4c\u5165\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u4ee5\u51cf\u5c11\u8868\u793a\u504f\u5dee\uff1b2\uff09\u57fa\u4e8e\u52a8\u6001\u5956\u52b1-\u60e9\u7f5a\u7684\u805a\u5408\u7b56\u7565\u6839\u636e\u53c2\u4e0e\u5386\u53f2\u548c\u5d4c\u5165\u5bf9\u9f50\u8c03\u6574\u5ba2\u6237\u7aef\u6743\u91cd\uff0c\u5b9e\u73b0\u8d21\u732e\u611f\u77e5\u7684\u516c\u5e73\u805a\u5408\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCoRe-Fed\u5728\u516c\u5e73\u6027\u548c\u6a21\u578b\u6027\u80fd\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b97\u6cd5\u3002", "conclusion": "CoRe-Fed\u901a\u8fc7\u7edf\u4e00\u4f18\u5316\u6846\u67b6\u6709\u6548\u7f13\u89e3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u8868\u793a\u504f\u5dee\u548c\u534f\u4f5c\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u548c\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2602.00654", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00654", "abs": "https://arxiv.org/abs/2602.00654", "authors": ["Jiaming Ma", "Guanjun Wang", "Qihe Huang", "Sheng Huang", "Haofeng Ma", "Zhengyang Zhou", "Pengkun Wang", "Binwu Wang", "Yang Wang"], "title": "PHAT: Modeling Period Heterogeneity for Multivariate Time Series Forecasting", "comment": null, "summary": "While existing multivariate time series forecasting models have advanced significantly in modeling periodicity, they largely neglect the periodic heterogeneity common in real-world data, where variates exhibit distinct and dynamically changing periods. To effectively capture this periodic heterogeneity, we propose PHAT (Period Heterogeneity-Aware Transformer). Specifically, PHAT arranges multivariate inputs into a three-dimensional \"periodic bucket\" tensor, where the dimensions correspond to variate group characteristics with similar periodicity, time steps aligned by phase, and offsets within the period. By restricting interactions within buckets and masking cross-bucket connections, PHAT effectively avoids interference from inconsistent periods. We also propose a positive-negative attention mechanism, which captures periodic dependencies from two perspectives: periodic alignment and periodic deviation. Additionally, the periodic alignment attention scores are decomposed into positive and negative components, with a modulation term encoding periodic priors. This modulation constrains the attention mechanism to more faithfully reflect the underlying periodic trends. A mathematical explanation is provided to support this property. We evaluate PHAT comprehensively on 14 real-world datasets against 18 baselines, and the results show that it significantly outperforms existing methods, achieving highly competitive forecasting performance. Our sources is available at GitHub.", "AI": {"tldr": "PHAT\u662f\u4e00\u79cd\u65b0\u578b\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\"\u5468\u671f\u6876\"\u5f20\u91cf\u7ed3\u6784\u548c\u6b63\u8d1f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u6355\u6349\u73b0\u5b9e\u6570\u636e\u4e2d\u7684\u5468\u671f\u5f02\u8d28\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u867d\u7136\u80fd\u5f88\u597d\u5efa\u6a21\u5468\u671f\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u73b0\u5b9e\u6570\u636e\u4e2d\u5e38\u89c1\u7684\u5468\u671f\u5f02\u8d28\u6027\u2014\u2014\u4e0d\u540c\u53d8\u91cf\u5177\u6709\u4e0d\u540c\u4e14\u52a8\u6001\u53d8\u5316\u7684\u5468\u671f\u3002\u8fd9\u79cd\u5468\u671f\u5f02\u8d28\u6027\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faPHAT\u6a21\u578b\uff1a1) \u5c06\u591a\u5143\u8f93\u5165\u7ec4\u7ec7\u6210\u4e09\u7ef4\"\u5468\u671f\u6876\"\u5f20\u91cf\uff0c\u7ef4\u5ea6\u5206\u522b\u5bf9\u5e94\u76f8\u4f3c\u5468\u671f\u6027\u7684\u53d8\u91cf\u7ec4\u3001\u76f8\u4f4d\u5bf9\u9f50\u7684\u65f6\u95f4\u6b65\u548c\u5468\u671f\u5185\u504f\u79fb\uff1b2) \u9650\u5236\u6876\u5185\u4ea4\u4e92\u5e76\u5c4f\u853d\u8de8\u6876\u8fde\u63a5\uff0c\u907f\u514d\u4e0d\u4e00\u81f4\u5468\u671f\u7684\u5e72\u6270\uff1b3) \u63d0\u51fa\u6b63\u8d1f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ece\u5468\u671f\u5bf9\u9f50\u548c\u5468\u671f\u504f\u5dee\u4e24\u4e2a\u89d2\u5ea6\u6355\u6349\u5468\u671f\u6027\u4f9d\u8d56\uff1b4) \u5c06\u5468\u671f\u5bf9\u9f50\u6ce8\u610f\u529b\u5206\u6570\u5206\u89e3\u4e3a\u6b63\u8d1f\u5206\u91cf\uff0c\u5e76\u7528\u7f16\u7801\u5468\u671f\u5148\u9a8c\u7684\u8c03\u5236\u9879\u7ea6\u675f\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u572814\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4e0e18\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u5bf9\u6bd4\uff0cPHAT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6781\u5177\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u6027\u80fd\u3002\u63d0\u4f9b\u4e86\u6570\u5b66\u89e3\u91ca\u652f\u6301\u5176\u7279\u6027\u3002", "conclusion": "PHAT\u901a\u8fc7\u6709\u6548\u5efa\u6a21\u5468\u671f\u5f02\u8d28\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\u3002\u6a21\u578b\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90\u3002"}}
{"id": "2602.00656", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00656", "abs": "https://arxiv.org/abs/2602.00656", "authors": ["Yingxu Wang", "Xinwang Liu", "Mengzhu Wang", "Siyang Gao", "Nan Yin"], "title": "Riemannian Flow Matching for Disentangled Graph Domain Adaptation", "comment": null, "summary": "Graph Domain Adaptation (GDA) typically uses adversarial learning to align graph embeddings in Euclidean space. However, this paradigm suffers from two critical challenges: Structural Degeneration, where hierarchical and semantic representations are entangled, and Optimization Instability, which arises from oscillatory dynamics of minimax adversarial training. To tackle these issues, we propose DisRFM, a geometry-aware GDA framework that unifies Riemannian embedding and flow-based transport. First, to overcome structural degeneration, we embed graphs into a Riemannian manifold. By adopting polar coordinates, we explicitly disentangle structure (radius) from semantics (angle). Then, we enforce topology preservation through radial Wasserstein alignment and semantic discrimination via angular clustering, thereby preventing feature entanglement and collapse. Second, we address the instability of adversarial alignment by using Riemannian flow matching. This method learns a smooth vector field to guide source features toward the target along geodesic paths, guaranteeing stable convergence. The geometric constraints further guide the flow to maintain the disentangled structure during transport. Theoretically, we prove the asymptotic stability of the flow matching and derive a tighter bound for the target risk. Extensive experiments demonstrate that DisRFM consistently outperforms state-of-the-art methods.", "AI": {"tldr": "DisRFM\uff1a\u4e00\u79cd\u51e0\u4f55\u611f\u77e5\u7684\u56fe\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u9ece\u66fc\u6d41\u5f62\u5d4c\u5165\u548c\u57fa\u4e8e\u6d41\u7684\u4f20\u8f93\u89e3\u51b3\u7ed3\u6784\u9000\u5316\u548c\u4f18\u5316\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898", "motivation": "\u4f20\u7edf\u56fe\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u5bf9\u9f50\u56fe\u5d4c\u5165\u65f6\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u7ed3\u6784\u9000\u5316\u95ee\u9898\u2014\u2014\u5c42\u6b21\u548c\u8bed\u4e49\u8868\u793a\u7ea0\u7f20\u5728\u4e00\u8d77\uff1b2\uff09\u4f18\u5316\u4e0d\u7a33\u5b9a\u6027\u2014\u2014\u6700\u5c0f\u6700\u5927\u5bf9\u6297\u8bad\u7ec3\u5e26\u6765\u7684\u632f\u8361\u52a8\u6001", "method": "1\uff09\u5c06\u56fe\u5d4c\u5165\u5230\u9ece\u66fc\u6d41\u5f62\u4e2d\uff0c\u91c7\u7528\u6781\u5750\u6807\u663e\u5f0f\u89e3\u8026\u7ed3\u6784\uff08\u534a\u5f84\uff09\u548c\u8bed\u4e49\uff08\u89d2\u5ea6\uff09\uff1b2\uff09\u901a\u8fc7\u5f84\u5411Wasserstein\u5bf9\u9f50\u4fdd\u6301\u62d3\u6251\u7ed3\u6784\uff0c\u901a\u8fc7\u89d2\u5ea6\u805a\u7c7b\u5b9e\u73b0\u8bed\u4e49\u533a\u5206\uff1b3\uff09\u4f7f\u7528\u9ece\u66fc\u6d41\u5339\u914d\u5b66\u4e60\u5e73\u6ed1\u5411\u91cf\u573a\uff0c\u5f15\u5bfc\u6e90\u7279\u5f81\u6cbf\u6d4b\u5730\u7ebf\u8def\u5f84\u5411\u76ee\u6807\u79fb\u52a8", "result": "DisRFM\u5728\u5b9e\u9a8c\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027", "conclusion": "DisRFM\u901a\u8fc7\u51e0\u4f55\u611f\u77e5\u7684\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u57df\u81ea\u9002\u5e94\u4e2d\u7684\u7ed3\u6784\u9000\u5316\u548c\u4f18\u5316\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3aGDA\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u548c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00670", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00670", "abs": "https://arxiv.org/abs/2602.00670", "authors": ["Ashna Purwar", "Gaurav Simkar", "Madhumita", "Sachin Kadam"], "title": "Three-Way Emotion Classification of EEG-based Signals using Machine Learning", "comment": "6 pages, 8 figures, and 3 tables. Submitted to a conference, under review", "summary": "Electroencephalography (EEG) is a widely used technique for measuring brain activity. EEG-based signals can reveal a persons emotional state, as they directly reflect activity in different brain regions. Emotion-aware systems and EEG-based emotion recognition are a growing research area. This paper presents how machine learning (ML) models categorize a limited dataset of EEG signals into three different classes, namely Negative, Neutral, or Positive. It also presents the complete workflow, including data preprocessing and comparison of ML models. To understand which ML classification model works best for this kind of problem, we train and test the following three commonly used models: logistic regression (LR), support vector machine (SVM), and random forest (RF). The performance of each is evaluated with respect to accuracy and F1-score. The results indicate that ML models can be effectively utilized for three-way emotion classification of EEG signals. Among the three ML models trained on the available dataset, the RF model gave the best results. Its higher accuracy and F1-score suggest that it is able to capture the emotional patterns more accurately and effectively than the other two models. The RF model also outperformed the existing state-of-the-art classification models in terms of the accuracy parameter.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9EEG\u4fe1\u53f7\u8fdb\u884c\u4e09\u5206\u7c7b\u60c5\u611f\u8bc6\u522b\uff08\u6d88\u6781\u3001\u4e2d\u6027\u3001\u79ef\u6781\uff09\uff0c\u6bd4\u8f83\u4e86\u903b\u8f91\u56de\u5f52\u3001\u652f\u6301\u5411\u91cf\u673a\u548c\u968f\u673a\u68ee\u6797\u4e09\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u968f\u673a\u68ee\u6797\u8868\u73b0\u6700\u4f73\u3002", "motivation": "EEG\u4fe1\u53f7\u80fd\u591f\u76f4\u63a5\u53cd\u6620\u5927\u8111\u6d3b\u52a8\uff0c\u53ef\u7528\u4e8e\u8bc6\u522b\u4eba\u7684\u60c5\u7eea\u72b6\u6001\u3002\u968f\u7740\u60c5\u611f\u611f\u77e5\u7cfb\u7edf\u548cEEG\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u7684\u589e\u957f\uff0c\u9700\u8981\u63a2\u7d22\u54ea\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6700\u9002\u5408\u5904\u7406\u6709\u9650\u7684EEG\u6570\u636e\u96c6\u8fdb\u884c\u4e09\u5206\u7c7b\u60c5\u611f\u8bc6\u522b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5b8c\u6574\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u9884\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6bd4\u8f83\u3002\u8bad\u7ec3\u548c\u6d4b\u8bd5\u4e86\u4e09\u79cd\u5e38\u7528\u6a21\u578b\uff1a\u903b\u8f91\u56de\u5f52(LR)\u3001\u652f\u6301\u5411\u91cf\u673a(SVM)\u548c\u968f\u673a\u68ee\u6797(RF)\u3002\u4f7f\u7528\u51c6\u786e\u7387\u548cF1\u5206\u6570\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u7528\u4e8eEEG\u4fe1\u53f7\u7684\u4e09\u5206\u7c7b\u60c5\u611f\u8bc6\u522b\u3002\u5728\u4e09\u79cd\u6a21\u578b\u4e2d\uff0c\u968f\u673a\u68ee\u6797(RF)\u8868\u73b0\u6700\u4f73\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548cF1\u5206\u6570\uff0c\u8868\u660e\u5b83\u80fd\u66f4\u51c6\u786e\u6709\u6548\u5730\u6355\u6349\u60c5\u7eea\u6a21\u5f0f\u3002RF\u6a21\u578b\u5728\u51c6\u786e\u7387\u53c2\u6570\u4e0a\u4e5f\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u5206\u7c7b\u6a21\u578b\u3002", "conclusion": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u662f\u5904\u7406\u6709\u9650EEG\u6570\u636e\u96c6\u8fdb\u884c\u4e09\u5206\u7c7b\u60c5\u611f\u8bc6\u522b\u7684\u6700\u4f73\u9009\u62e9\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u903b\u8f91\u56de\u5f52\u548c\u652f\u6301\u5411\u91cf\u673a\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u7387\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u3002"}}
{"id": "2602.00672", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00672", "abs": "https://arxiv.org/abs/2602.00672", "authors": ["Aleksandr Yugay", "Hang Cui", "Changhua Pei", "Alexey Zaytsev"], "title": "Strong Linear Baselines Strike Back: Closed-Form Linear Models as Gaussian Process Conditional Density Estimators for TSAD", "comment": null, "summary": "Research in time series anomaly detection (TSAD) has largely focused on developing increasingly sophisticated, hard-to-train, and expensive-to-infer neural architectures. We revisit this paradigm and show that a simple linear autoregressive anomaly score with the closed-form solution provided by ordinary least squares (OLS) regression consistently matches or outperforms state-of-the-art deep detectors. From a theoretical perspective, we show that linear models capture a broad class of anomaly types, estimating a finite-history Gaussian process conditional density. From a practical side, across extensive univariate and multivariate benchmarks, the proposed approach achieves superior accuracy while requiring orders of magnitude fewer computational resources. Thus, future research should consistently include strong linear baselines and, more importantly, develop new benchmarks with richer temporal structures pinpointing the advantages of deep learning models.", "AI": {"tldr": "\u7ebf\u6027\u81ea\u56de\u5f52\u5f02\u5e38\u8bc4\u5206\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u590d\u6742\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u51e0\u4e2a\u6570\u91cf\u7ea7", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7814\u7a76\u8fc7\u5ea6\u5173\u6ce8\u590d\u6742\u3001\u96be\u4ee5\u8bad\u7ec3\u4e14\u63a8\u7406\u6602\u8d35\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u8303\u5f0f", "method": "\u4f7f\u7528\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff08OLS\uff09\u56de\u5f52\u7684\u95ed\u5f0f\u89e3\u6784\u5efa\u7b80\u5355\u7ebf\u6027\u81ea\u56de\u5f52\u5f02\u5e38\u8bc4\u5206\u6a21\u578b", "result": "\u5728\u5e7f\u6cdb\u7684\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u68c0\u6d4b\u5668\u7cbe\u5ea6\uff0c\u540c\u65f6\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u51cf\u5c11\u51e0\u4e2a\u6570\u91cf\u7ea7", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u5305\u542b\u5f3a\u5927\u7684\u7ebf\u6027\u57fa\u7ebf\uff0c\u5e76\u5f00\u53d1\u5177\u6709\u66f4\u4e30\u5bcc\u65f6\u95f4\u7ed3\u6784\u7684\u65b0\u57fa\u51c6\u6765\u51f8\u663e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u4f18\u52bf"}}
{"id": "2602.00688", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00688", "abs": "https://arxiv.org/abs/2602.00688", "authors": ["Tom Segal", "Asaf Shabtai", "Yuval Elovici"], "title": "Provably Protecting Fine-Tuned LLMs from Training Data Extraction", "comment": "20 pages, 5 figures", "summary": "Fine-tuning large language models (LLMs) on sensitive datasets raises privacy concerns, as training data extraction (TDE) attacks can expose highly confidential information. Existing defenses against such attacks either lack formal privacy guarantees or incur substantial utility degradation. We observe that fine-tuning induces widespread probability shifts, yet preserving only a small subset of influential token-level deviations is sufficient; the remaining shifts can be aggressively smoothed with minimal impact on utility. Motivated by this insight, we propose SCP-$\u0394_r$, a Near Access Freeness (NAF)-based algorithm that operates on relative probabilities and explicitly smooths low-impact tokens using a base model. SCP-$\u0394_r$ achieves orders-of-magnitude better theoretical bounds than existing NAF based methods and provides strong empirical protection against TDE attacks with minimal performance loss.", "AI": {"tldr": "\u63d0\u51faSCP-\u0394r\u7b97\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5e73\u6ed1\u4f4e\u5f71\u54cdtoken\u6765\u9632\u5fa1\u8bad\u7ec3\u6570\u636e\u63d0\u53d6\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u62a4", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u6570\u636e\u4e0a\u5fae\u8c03\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9690\u79c1\u4fdd\u8bc1\uff0c\u8981\u4e48\u5bfc\u81f4\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\u3002\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u53ea\u5f15\u8d77\u5c11\u6570\u5173\u952etoken\u7684\u6982\u7387\u504f\u79fb\uff0c\u5927\u90e8\u5206\u504f\u79fb\u53ef\u4ee5\u5b89\u5168\u5e73\u6ed1\u800c\u4e0d\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u57fa\u4e8eNear Access Freeness (NAF)\u6846\u67b6\uff0c\u63d0\u51faSCP-\u0394r\u7b97\u6cd5\uff0c\u5728\u76f8\u5bf9\u6982\u7387\u7a7a\u95f4\u64cd\u4f5c\uff0c\u663e\u5f0f\u5730\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u5e73\u6ed1\u4f4e\u5f71\u54cdtoken\uff0c\u4ec5\u4fdd\u7559\u9ad8\u5f71\u54cd\u529b\u7684token\u7ea7\u504f\u5dee\u3002", "result": "SCP-\u0394r\u76f8\u6bd4\u73b0\u6709NAF\u65b9\u6cd5\u83b7\u5f97\u6570\u91cf\u7ea7\u66f4\u597d\u7684\u7406\u8bba\u8fb9\u754c\uff0c\u5728\u5bf9\u6297\u8bad\u7ec3\u6570\u636e\u63d0\u53d6\u653b\u51fb\u65f6\u63d0\u4f9b\u5f3a\u5b9e\u8bc1\u4fdd\u62a4\uff0c\u540c\u65f6\u6027\u80fd\u635f\u5931\u6700\u5c0f\u3002", "conclusion": "\u901a\u8fc7\u9009\u62e9\u6027\u5e73\u6ed1\u4f4e\u5f71\u54cdtoken\u7684\u65b9\u6cd5\uff0cSCP-\u0394r\u5728\u4fdd\u62a4\u9690\u79c1\u548c\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u9690\u79c1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.00693", "categories": ["cs.LG", "math.AG", "math.AT"], "pdf": "https://arxiv.org/pdf/2602.00693", "abs": "https://arxiv.org/abs/2602.00693", "authors": ["Marco Nurisso", "Pierrick Leroy", "Giovanni Petri", "Francesco Vaccarino"], "title": "Topology and Geometry of the Learning Space of ReLU Networks: Connectivity and Singularities", "comment": "Accepted to ICLR 2026. 32 pages, 13 figures", "summary": "Understanding the properties of the parameter space in feed-forward ReLU networks is critical for effectively analyzing and guiding training dynamics. After initialization, training under gradient flow decisively restricts the parameter space to an algebraic variety that emerges from the homogeneous nature of the ReLU activation function. In this study, we examine two key challenges associated with feed-forward ReLU networks built on general directed acyclic graph (DAG) architectures: the (dis)connectedness of the parameter space and the existence of singularities within it. We extend previous results by providing a thorough characterization of connectedness, highlighting the roles of bottleneck nodes and balance conditions associated with specific subsets of the network. Our findings clearly demonstrate that singularities are intricately connected to the topology of the underlying DAG and its induced sub-networks. We discuss the reachability of these singularities and establish a principled connection with differentiable pruning. We validate our theory with simple numerical experiments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u524d\u9988ReLU\u7f51\u7edc\u53c2\u6570\u7a7a\u95f4\u7684\u8fde\u901a\u6027\u548c\u5947\u5f02\u6027\uff0c\u53d1\u73b0\u8bad\u7ec3\u5c06\u53c2\u6570\u9650\u5236\u5728\u4ee3\u6570\u7c07\u4e0a\uff0c\u8fde\u901a\u6027\u53d7\u74f6\u9888\u8282\u70b9\u548c\u5e73\u8861\u6761\u4ef6\u5f71\u54cd\uff0c\u5947\u5f02\u6027\u4e0eDAG\u62d3\u6251\u7ed3\u6784\u76f8\u5173\uff0c\u5e76\u4e0e\u53ef\u5fae\u526a\u679d\u6709\u8054\u7cfb\u3002", "motivation": "\u7406\u89e3\u524d\u9988ReLU\u7f51\u7edc\u53c2\u6570\u7a7a\u95f4\u7684\u6027\u8d28\u5bf9\u4e8e\u5206\u6790\u548c\u6307\u5bfc\u8bad\u7ec3\u52a8\u6001\u81f3\u5173\u91cd\u8981\u3002\u521d\u59cb\u5316\u540e\uff0c\u68af\u5ea6\u6d41\u8bad\u7ec3\u5c06\u53c2\u6570\u7a7a\u95f4\u9650\u5236\u5728\u7531ReLU\u6fc0\u6d3b\u51fd\u6570\u7684\u9f50\u6b21\u6027\u4ea7\u751f\u7684\u4ee3\u6570\u7c07\u4e0a\uff0c\u9700\u8981\u7814\u7a76\u8be5\u7a7a\u95f4\u7684\u8fde\u901a\u6027\u548c\u5947\u5f02\u6027\u95ee\u9898\u3002", "method": "\u7814\u7a76\u57fa\u4e8e\u4e00\u822c\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u67b6\u6784\u7684\u524d\u9988ReLU\u7f51\u7edc\uff0c\u6269\u5c55\u5148\u524d\u7ed3\u679c\uff0c\u5168\u9762\u8868\u5f81\u53c2\u6570\u7a7a\u95f4\u7684\u8fde\u901a\u6027\uff0c\u5206\u6790\u74f6\u9888\u8282\u70b9\u548c\u5e73\u8861\u6761\u4ef6\u7684\u4f5c\u7528\uff0c\u63a2\u8ba8\u5947\u5f02\u6027\u4e0eDAG\u62d3\u6251\u7ed3\u6784\u7684\u5173\u7cfb\uff0c\u5e76\u5efa\u7acb\u4e0e\u53ef\u5fae\u526a\u679d\u7684\u7406\u8bba\u8054\u7cfb\u3002", "result": "\u53d1\u73b0\u53c2\u6570\u7a7a\u95f4\u7684\u8fde\u901a\u6027\u53d7\u74f6\u9888\u8282\u70b9\u548c\u7279\u5b9a\u5b50\u7f51\u7edc\u5e73\u8861\u6761\u4ef6\u7684\u5f71\u54cd\uff1b\u5947\u5f02\u6027\u4e0e\u5e95\u5c42DAG\u53ca\u5176\u8bf1\u5bfc\u5b50\u7f51\u7edc\u7684\u62d3\u6251\u7ed3\u6784\u5bc6\u5207\u76f8\u5173\uff1b\u5efa\u7acb\u4e86\u5947\u5f02\u6027\u53ef\u8fbe\u6027\u4e0e\u53ef\u5fae\u526a\u679d\u7684\u539f\u5219\u6027\u8054\u7cfb\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u3002", "conclusion": "\u524d\u9988ReLU\u7f51\u7edc\u7684\u53c2\u6570\u7a7a\u95f4\u6027\u8d28\uff08\u8fde\u901a\u6027\u548c\u5947\u5f02\u6027\uff09\u4e0e\u7f51\u7edc\u67b6\u6784\u7684\u62d3\u6251\u7ed3\u6784\u5bc6\u5207\u76f8\u5173\uff0c\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u7406\u89e3\u8bad\u7ec3\u52a8\u6001\u548c\u7f51\u7edc\u526a\u679d\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u66f4\u6709\u6548\u5730\u5206\u6790\u548c\u6307\u5bfc\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u8fc7\u7a0b\u3002"}}
{"id": "2602.00704", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00704", "abs": "https://arxiv.org/abs/2602.00704", "authors": ["Hanqi Lyu", "Di Huang", "Yaoyu Zhu", "Kangcheng Liu", "Bohan Dou", "Chongxiao Li", "Pengwei Jin", "Shuyao Cheng", "Rui Zhang", "Zidong Du", "Qi Guo", "Xing Hu", "Yunji Chen"], "title": "LocalV: Exploiting Information Locality for IP-level Verilog Generation", "comment": null, "summary": "The generation of Register-Transfer Level (RTL) code is a crucial yet labor-intensive step in digital hardware design, traditionally requiring engineers to manually translate complex specifications into thousands of lines of synthesizable Hardware Description Language (HDL) code. While Large Language Models (LLMs) have shown promise in automating this process, existing approaches-including fine-tuned domain-specific models and advanced agent-based systems-struggle to scale to industrial IP-level design tasks. We identify three key challenges: (1) handling long, highly detailed documents, where critical interface constraints become buried in unrelated submodule descriptions; (2) generating long RTL code, where both syntactic and semantic correctness degrade sharply with increasing output length; and (3) navigating the complex debugging cycles required for functional verification through simulation and waveform analysis. To overcome these challenges, we propose LocalV, a multi-agent framework that leverages information locality in modular hardware design. LocalV decomposes the long-document to long-code generation problem into a set of short-document, short-code tasks, enabling scalable generation and debugging. Specifically, LocalV integrates hierarchical document partitioning, task planning, localized code generation, interface-consistent merging, and AST-guided locality-aware debugging. Experiments on RealBench, an IP-level Verilog generation benchmark, demonstrate that LocalV substantially outperforms state-of-the-art (SOTA) LLMs and agents, achieving a pass rate of 45.0% compared to 21.6%.", "AI": {"tldr": "LocalV\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u6a21\u5757\u5316\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u4fe1\u606f\u5c40\u90e8\u6027\uff0c\u5c06\u957f\u6587\u6863\u5230\u957f\u4ee3\u7801\u751f\u6210\u95ee\u9898\u5206\u89e3\u4e3a\u77ed\u6587\u6863\u3001\u77ed\u4ee3\u7801\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86RTL\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4f20\u7edfRTL\u4ee3\u7801\u751f\u6210\u9700\u8981\u5de5\u7a0b\u5e08\u624b\u52a8\u5c06\u590d\u6742\u89c4\u8303\u8f6c\u6362\u4e3a\u6570\u5343\u884c\u53ef\u7efc\u5408HDL\u4ee3\u7801\uff0c\u52b3\u52a8\u5bc6\u96c6\u578b\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u73b0\u6709LLM\u65b9\u6cd5\u5728\u5904\u7406\u5de5\u4e1a\u7ea7IP\u8bbe\u8ba1\u4efb\u52a1\u65f6\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u5904\u7406\u957f\u800c\u8be6\u7ec6\u7684\u6587\u6863\u3001\u751f\u6210\u957fRTL\u4ee3\u7801\u65f6\u6b63\u786e\u6027\u4e0b\u964d\u3001\u4ee5\u53ca\u590d\u6742\u7684\u8c03\u8bd5\u5468\u671f\u3002", "method": "LocalV\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528\u6a21\u5757\u5316\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u4fe1\u606f\u5c40\u90e8\u6027\u3002\u5177\u4f53\u5305\u62ec\uff1a\u5206\u5c42\u6587\u6863\u5206\u533a\u3001\u4efb\u52a1\u89c4\u5212\u3001\u5c40\u90e8\u5316\u4ee3\u7801\u751f\u6210\u3001\u63a5\u53e3\u4e00\u81f4\u6027\u5408\u5e76\u3001\u4ee5\u53caAST\u5f15\u5bfc\u7684\u5c40\u90e8\u611f\u77e5\u8c03\u8bd5\u3002", "result": "\u5728RealBench\uff08IP\u7ea7Verilog\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\uff09\u4e0a\uff0cLocalV\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684LLM\u548c\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u901a\u8fc7\u7387\u8fbe\u523045.0%\uff0c\u800c\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u4ec5\u4e3a21.6%\u3002", "conclusion": "LocalV\u901a\u8fc7\u5206\u89e3\u957f\u6587\u6863\u5230\u957f\u4ee3\u7801\u751f\u6210\u95ee\u9898\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4e1a\u7ea7IP\u8bbe\u8ba1\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00717", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00717", "abs": "https://arxiv.org/abs/2602.00717", "authors": ["Licheng Pan", "Hao Wang", "Haocheng Yang", "Yuqi Li", "Qingsong Wen", "Xiaoxi Li", "Zhichao Chen", "Haoxuan Li", "Zhixuan Chu", "Yuan Lu"], "title": "Deep Time-series Forecasting Needs Kernelized Moment Balancing", "comment": null, "summary": "Deep time-series forecasting can be formulated as a distribution balancing problem aimed at aligning the distribution of the forecasts and ground truths. According to Imbens' criterion, true distribution balance requires matching the first moments with respect to any balancing function. We demonstrate that existing objectives fail to meet this criterion, as they enforce moment matching only for one or two predefined balancing functions, thus failing to achieve full distribution balance. To address this limitation, we propose direct forecasting with kernelized moment balancing (KMB-DF). Unlike existing objectives, KMB-DF adaptively selects the most informative balancing functions from a reproducing kernel hilbert space (RKHS) to enforce sufficient distribution balancing. We derive a tractable and differentiable objective that enables efficient estimation from empirical samples and seamless integration into gradient-based training pipelines. Extensive experiments across multiple models and datasets show that KMB-DF consistently improves forecasting accuracy and achieves state-of-the-art performance. Code is available at https://anonymous.4open.science/r/KMB-DF-403C.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faKMB-DF\u65b9\u6cd5\uff0c\u901a\u8fc7\u6838\u5316\u77e9\u5e73\u8861\u5b9e\u73b0\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u5206\u5e03\u5bf9\u9f50\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3Imbens\u51c6\u5219\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5c06\u95ee\u9898\u89c6\u4e3a\u5206\u5e03\u5e73\u8861\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u76ee\u6807\u51fd\u6570\u53ea\u80fd\u5339\u914d\u4e00\u4e2a\u6216\u4e24\u4e2a\u9884\u5b9a\u4e49\u7684\u5e73\u8861\u51fd\u6570\uff0c\u65e0\u6cd5\u6ee1\u8db3Imbens\u51c6\u5219\u8981\u6c42\u7684\u4e0e\u4efb\u4f55\u5e73\u8861\u51fd\u6570\u7684\u4e00\u9636\u77e9\u5339\u914d\uff0c\u56e0\u6b64\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u5206\u5e03\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u6838\u5316\u77e9\u5e73\u8861\u76f4\u63a5\u9884\u6d4b(KMB-DF)\uff0c\u4ece\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4(RKHS)\u81ea\u9002\u5e94\u9009\u62e9\u6700\u5177\u4fe1\u606f\u91cf\u7684\u5e73\u8861\u51fd\u6570\u6765\u5f3a\u5236\u5145\u5206\u7684\u5206\u5e03\u5e73\u8861\uff0c\u63a8\u5bfc\u51fa\u53ef\u5904\u7406\u4e14\u53ef\u5fae\u7684\u76ee\u6807\u51fd\u6570\uff0c\u652f\u6301\u4ece\u7ecf\u9a8c\u6837\u672c\u9ad8\u6548\u4f30\u8ba1\u5e76\u96c6\u6210\u5230\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cKMB-DF\u80fd\u6301\u7eed\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "KMB-DF\u901a\u8fc7\u6838\u5316\u77e9\u5e73\u8861\u89e3\u51b3\u4e86\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5206\u5e03\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.00718", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00718", "abs": "https://arxiv.org/abs/2602.00718", "authors": ["Noorain Mukhtiar", "Adnan Mahmood", "Yipeng Zhou", "Jian Yang", "Jing Teng", "Quan Z. Sheng"], "title": "Federated Learning at the Forefront of Fairness: A Multifaceted Perspective", "comment": "7 pages (main content), 2 pages (references), Accepted and Published Proceedings of the 34th International Joint Conference on Artificial Intelligence (IJCAI). 2025", "summary": "Fairness in Federated Learning (FL) is emerging as a critical factor driven by heterogeneous clients' constraints and balanced model performance across various scenarios. In this survey, we delineate a comprehensive classification of the state-of-the-art fairness-aware approaches from a multifaceted perspective, i.e., model performance-oriented and capability-oriented. Moreover, we provide a framework to categorize and address various fairness concerns and associated technical aspects, examining their effectiveness in balancing equity and performance within FL frameworks. We further examine several significant evaluation metrics leveraged to measure fairness quantitatively. Finally, we explore exciting open research directions and propose prospective solutions that could drive future advancements in this important area, laying a solid foundation for researchers working toward fairness in FL.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u5206\u7c7b\u548c\u5206\u6790\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u516c\u5e73\u6027\u65b9\u6cd5\uff0c\u4ece\u6a21\u578b\u6027\u80fd\u5bfc\u5411\u548c\u80fd\u529b\u5bfc\u5411\u4e24\u4e2a\u89d2\u5ea6\u68b3\u7406\u73b0\u6709\u6280\u672f\uff0c\u63d0\u4f9b\u4e86\u516c\u5e73\u6027\u8bc4\u4f30\u6846\u67b6\u548c\u5ea6\u91cf\u6307\u6807\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u65e5\u76ca\u91cd\u8981\uff0c\u4e3b\u8981\u52a8\u673a\u6e90\u4e8e\uff1a1\uff09\u5f02\u6784\u5ba2\u6237\u7aef\u5177\u6709\u4e0d\u540c\u7684\u7ea6\u675f\u6761\u4ef6\uff1b2\uff09\u9700\u8981\u5728\u5404\u79cd\u573a\u666f\u4e0b\u5b9e\u73b0\u5e73\u8861\u7684\u6a21\u578b\u6027\u80fd\uff1b3\uff09\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u516c\u5e73\u6027\u5206\u7c7b\u548c\u5206\u6790\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff1a1\uff09\u4ece\u591a\u89d2\u5ea6\uff08\u6a21\u578b\u6027\u80fd\u5bfc\u5411\u548c\u80fd\u529b\u5bfc\u5411\uff09\u5bf9\u73b0\u6709\u516c\u5e73\u6027\u611f\u77e5\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u5206\u7c7b\uff1b2\uff09\u63d0\u4f9b\u6846\u67b6\u6765\u5206\u7c7b\u548c\u89e3\u51b3\u5404\u79cd\u516c\u5e73\u6027\u5173\u5207\u53ca\u76f8\u5173\u6280\u672f\u65b9\u9762\uff1b3\uff09\u5206\u6790\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u6027\u80fd\u7684\u6709\u6548\u6027\uff1b4\uff09\u8003\u5bdf\u7528\u4e8e\u91cf\u5316\u6d4b\u91cf\u516c\u5e73\u6027\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5efa\u7acb\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u516c\u5e73\u6027\u7814\u7a76\u7684\u7cfb\u7edf\u6027\u5206\u7c7b\u6846\u67b6\uff0c\u660e\u786e\u4e86\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\u5bfc\u5411\uff08\u6027\u80fd\u5bfc\u5411\u548c\u80fd\u529b\u5bfc\u5411\uff09\uff0c\u63d0\u4f9b\u4e86\u516c\u5e73\u6027\u8bc4\u4f30\u7684\u6280\u672f\u5de5\u5177\uff0c\u5e76\u8bc6\u522b\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u516c\u5e73\u6027\u662f\u4e00\u4e2a\u91cd\u8981\u4e14\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u9886\u57df\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u5206\u7c7b\u548c\u8bc4\u4f30\u6846\u67b6\u3002\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u5f00\u653e\u7814\u7a76\u65b9\u5411\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2602.00722", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00722", "abs": "https://arxiv.org/abs/2602.00722", "authors": ["Hao Gu", "Mao-Lin Luo", "Zi-Hao Zhou", "Han-Chen Zhang", "Min-Ling Zhang", "Tong Wei"], "title": "Spectral Imbalance Causes Forgetting in Low-Rank Continual Adaptation", "comment": "19 pages, 6 figures", "summary": "Parameter-efficient continual learning aims to adapt pre-trained models to sequential tasks without forgetting previously acquired knowledge. Most existing approaches treat continual learning as avoiding interference with past updates, rather than considering what properties make the current task-specific update naturally preserve previously acquired knowledge. From a knowledge-decomposition perspective, we observe that low-rank adaptations exhibit highly imbalanced singular value spectra: a few dominant components absorb most of the adaptation energy, thereby (i) more likely to disrupt previously acquired knowledge and (ii) making the update more vulnerable to interference from subsequent tasks. To enable explicit balance among components, we decouple the magnitude of the task update from its directional structure and formulate it as a constrained optimization problem on a restricted Stiefel manifold. We address this problem using a projected first-order method compatible with standard deep-learning optimizers used in vision-language models. Our method mitigates both backward and forward forgetting, consistently outperforming continual learning baselines. The implementation code is available at https://github.com/haodotgu/EBLoRA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEBLoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u4efb\u52a1\u66f4\u65b0\u7684\u5e45\u5ea6\u4e0e\u65b9\u5411\u7ed3\u6784\uff0c\u5728\u53d7\u9650Stiefel\u6d41\u5f62\u4e0a\u4f18\u5316\uff0c\u5e73\u8861\u5947\u5f02\u503c\u8c31\uff0c\u51cf\u8f7b\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u524d\u5411\u548c\u540e\u5411\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u907f\u514d\u4e0e\u8fc7\u53bb\u66f4\u65b0\u7684\u5e72\u6270\uff0c\u800c\u975e\u8003\u8651\u5f53\u524d\u4efb\u52a1\u7279\u5b9a\u66f4\u65b0\u5982\u4f55\u81ea\u7136\u4fdd\u7559\u5148\u524d\u77e5\u8bc6\u3002\u4ece\u77e5\u8bc6\u5206\u89e3\u89c6\u89d2\u53d1\u73b0\uff0c\u4f4e\u79e9\u9002\u5e94\u8868\u73b0\u51fa\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u5947\u5f02\u503c\u8c31\uff1a\u5c11\u6570\u4e3b\u5bfc\u5206\u91cf\u5438\u6536\u5927\u90e8\u5206\u9002\u5e94\u80fd\u91cf\uff0c\u65e2\u5bb9\u6613\u7834\u574f\u5148\u524d\u77e5\u8bc6\uff0c\u53c8\u4f7f\u66f4\u65b0\u6613\u53d7\u540e\u7eed\u4efb\u52a1\u5e72\u6270\u3002", "method": "\u63d0\u51faEBLoRA\u65b9\u6cd5\uff1a1) \u89e3\u8026\u4efb\u52a1\u66f4\u65b0\u7684\u5e45\u5ea6\u4e0e\u65b9\u5411\u7ed3\u6784\uff1b2) \u5c06\u5176\u8868\u8ff0\u4e3a\u53d7\u9650Stiefel\u6d41\u5f62\u4e0a\u7684\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff1b3) \u4f7f\u7528\u4e0e\u6807\u51c6\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u5668\u517c\u5bb9\u7684\u6295\u5f71\u4e00\u9636\u65b9\u6cd5\u6c42\u89e3\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u540c\u65f6\u51cf\u8f7b\u540e\u5411\u9057\u5fd8\u548c\u524d\u5411\u9057\u5fd8\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5e73\u8861\u5947\u5f02\u503c\u8c31\u5206\u91cf\uff0cEBLoRA\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u4fdd\u7559\u5148\u524d\u77e5\u8bc6\u5e76\u51cf\u5c11\u4efb\u52a1\u95f4\u5e72\u6270\uff0c\u4e3a\u53c2\u6570\u9ad8\u6548\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.00723", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00723", "abs": "https://arxiv.org/abs/2602.00723", "authors": ["Prakhar Ganesh", "Reza Shokri", "Golnoosh Farnadi"], "title": "Rethinking Hallucinations: Correctness, Consistency, and Prompt Multiplicity", "comment": "To appear at EACL 2026", "summary": "Large language models (LLMs) are known to \"hallucinate\" by generating false or misleading outputs. Hallucinations pose various harms, from erosion of trust to widespread misinformation. Existing hallucination evaluation, however, focuses only on correctness and often overlooks consistency, necessary to distinguish and address these harms. To bridge this gap, we introduce prompt multiplicity, a framework for quantifying consistency in LLM evaluations. Our analysis reveals significant multiplicity (over 50% inconsistency in benchmarks like Med-HALT), suggesting that hallucination-related harms have been severely misunderstood. Furthermore, we study the role of consistency in hallucination detection and mitigation. We find that: (a) detection techniques detect consistency, not correctness, and (b) mitigation techniques like RAG, while beneficial, can introduce additional inconsistencies. By integrating prompt multiplicity into hallucination evaluation, we provide an improved framework of potential harms and uncover critical limitations in current detection and mitigation strategies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u63d0\u793a\u591a\u6837\u6027\"\u6846\u67b6\u6765\u91cf\u5316LLM\u8bc4\u4f30\u4e2d\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u5e7b\u89c9\u8bc4\u4f30\u8fc7\u5ea6\u5173\u6ce8\u6b63\u786e\u6027\u800c\u5ffd\u89c6\u4e00\u81f4\u6027\uff0c\u5bfc\u81f4\u5bf9\u5e7b\u89c9\u5371\u5bb3\u7684\u4e25\u91cd\u8bef\u89e3\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6b63\u786e\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u3002\u8fd9\u79cd\u5c40\u9650\u6027\u5bfc\u81f4\u65e0\u6cd5\u51c6\u786e\u533a\u5206\u548c\u89e3\u51b3\u5e7b\u89c9\u5e26\u6765\u7684\u5404\u79cd\u5371\u5bb3\uff0c\u5982\u4fe1\u4efb\u4fb5\u8680\u548c\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u3002", "method": "\u5f15\u5165\"\u63d0\u793a\u591a\u6837\u6027\"\u6846\u67b6\u6765\u91cf\u5316LLM\u8bc4\u4f30\u4e2d\u7684\u4e00\u81f4\u6027\uff0c\u5206\u6790\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982Med-HALT\uff09\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u7814\u7a76\u4e00\u81f4\u6027\u5728\u5e7b\u89c9\u68c0\u6d4b\u548c\u7f13\u89e3\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b58\u5728\u663e\u8457\u7684\u4e0d\u4e00\u81f4\u6027\uff08\u8d85\u8fc750%\uff09\uff1b2\uff09\u73b0\u6709\u68c0\u6d4b\u6280\u672f\u68c0\u6d4b\u7684\u662f\u6a21\u578b\u8f93\u51fa\u7684\u4e00\u81f4\u6027\u800c\u975e\u6b63\u786e\u6027\uff1b3\uff09\u7f13\u89e3\u6280\u672f\u5982RAG\u867d\u7136\u6709\u76ca\uff0c\u4f46\u53ef\u80fd\u5f15\u5165\u989d\u5916\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u63d0\u793a\u591a\u6837\u6027\u6846\u67b6\u6574\u5408\u5230\u5e7b\u89c9\u8bc4\u4f30\u4e2d\uff0c\u53ef\u4ee5\u63d0\u4f9b\u66f4\u5b8c\u5584\u7684\u5371\u5bb3\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u63ed\u793a\u5f53\u524d\u68c0\u6d4b\u548c\u7f13\u89e3\u7b56\u7565\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e00\u81f4\u6027\u8bc4\u4f30\u5bf9\u4e8e\u51c6\u786e\u7406\u89e3\u5e7b\u89c9\u5371\u5bb3\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.00737", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00737", "abs": "https://arxiv.org/abs/2602.00737", "authors": ["Jatan Shrestha", "Santeri Heiskanen", "Kari Hepola", "Severi Rissanen", "Pekka J\u00e4\u00e4skel\u00e4inen", "Joni Pajarinen"], "title": "Pareto-Conditioned Diffusion Models for Offline Multi-Objective Optimization", "comment": "Accepted by ICLR 2026. Project page: https://sites.google.com/view/pcd-iclr26", "summary": "Multi-objective optimization (MOO) arises in many real-world applications where trade-offs between competing objectives must be carefully balanced. In the offline setting, where only a static dataset is available, the main challenge is generalizing beyond observed data. We introduce Pareto-Conditioned Diffusion (PCD), a novel framework that formulates offline MOO as a conditional sampling problem. By conditioning directly on desired trade-offs, PCD avoids the need for explicit surrogate models. To effectively explore the Pareto front, PCD employs a reweighting strategy that focuses on high-performing samples and a reference-direction mechanism to guide sampling towards novel, promising regions beyond the training data. Experiments on standard offline MOO benchmarks show that PCD achieves highly competitive performance and, importantly, demonstrates greater consistency across diverse tasks than existing offline MOO approaches.", "AI": {"tldr": "PCD\u5c06\u79bb\u7ebf\u591a\u76ee\u6807\u4f18\u5316\u8f6c\u5316\u4e3a\u6761\u4ef6\u91c7\u6837\u95ee\u9898\uff0c\u901a\u8fc7\u76f4\u63a5\u6761\u4ef6\u5316\u4e8e\u671f\u671b\u6743\u8861\u6765\u907f\u514d\u663e\u5f0f\u4ee3\u7406\u6a21\u578b\uff0c\u91c7\u7528\u91cd\u52a0\u6743\u7b56\u7565\u805a\u7126\u9ad8\u6027\u80fd\u6837\u672c\uff0c\u5e76\u4f7f\u7528\u53c2\u8003\u65b9\u5411\u673a\u5236\u5f15\u5bfc\u91c7\u6837\u5230\u8bad\u7ec3\u6570\u636e\u4e4b\u5916\u7684\u65b0\u9896\u533a\u57df\u3002", "motivation": "\u79bb\u7ebf\u591a\u76ee\u6807\u4f18\u5316\u4e2d\uff0c\u4ec5\u4f7f\u7528\u9759\u6001\u6570\u636e\u96c6\u65f6\u7684\u4e3b\u8981\u6311\u6218\u662f\u5982\u4f55\u6cdb\u5316\u5230\u89c2\u6d4b\u6570\u636e\u4e4b\u5916\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u663e\u5f0f\u4ee3\u7406\u6a21\u578b\uff0c\u53ef\u80fd\u9650\u5236\u5176\u6cdb\u5316\u80fd\u529b\u548c\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51faPareto-Conditioned Diffusion (PCD)\u6846\u67b6\uff0c\u5c06\u79bb\u7ebfMOO\u5efa\u6a21\u4e3a\u6761\u4ef6\u91c7\u6837\u95ee\u9898\u3002\u901a\u8fc7\u76f4\u63a5\u6761\u4ef6\u5316\u4e8e\u671f\u671b\u6743\u8861\u6765\u907f\u514d\u663e\u5f0f\u4ee3\u7406\u6a21\u578b\u3002\u91c7\u7528\u91cd\u52a0\u6743\u7b56\u7565\u805a\u7126\u9ad8\u6027\u80fd\u6837\u672c\uff0c\u5e76\u4f7f\u7528\u53c2\u8003\u65b9\u5411\u673a\u5236\u5f15\u5bfc\u91c7\u6837\u5230\u8bad\u7ec3\u6570\u636e\u4e4b\u5916\u7684\u65b0\u9896\u533a\u57df\u3002", "result": "\u5728\u6807\u51c6\u79bb\u7ebfMOO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPCD\u5b9e\u73b0\u4e86\u9ad8\u5ea6\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u6bd4\u73b0\u6709\u79bb\u7ebfMOO\u65b9\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u8868\u73b0\u51fa\u66f4\u597d\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "PCD\u901a\u8fc7\u5c06\u79bb\u7ebf\u591a\u76ee\u6807\u4f18\u5316\u91cd\u65b0\u8868\u8ff0\u4e3a\u6761\u4ef6\u91c7\u6837\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u907f\u514d\u663e\u5f0f\u4ee3\u7406\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5728\u6cdb\u5316\u80fd\u529b\u548c\u4efb\u52a1\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.00753", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00753", "abs": "https://arxiv.org/abs/2602.00753", "authors": ["Zeljko Bolevic", "Milos Brajovic", "Isidora Stankovic", "Ljubisa Stankovic"], "title": "GraphNNK -- Graph Classification and Interpretability", "comment": "4 pages, 3 figures, IEEE conference paper", "summary": "Graph Neural Networks (GNNs) have become a standard approach for learning from graph-structured data. However, their reliance on parametric classifiers (most often linear softmax layers) limits interpretability and sometimes hinders generalization. Recent work on interpolation-based methods, particularly Non-Negative Kernel regression (NNK), has demonstrated that predictions can be expressed as convex combinations of similar training examples in the embedding space, yielding both theoretical results and interpretable explanations.", "AI": {"tldr": "GNNs\u4f9d\u8d56\u53c2\u6570\u5316\u5206\u7c7b\u5668\u9650\u5236\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u57fa\u4e8e\u63d2\u503c\u7684\u65b9\u6cd5\uff08\u5982NNK\uff09\u901a\u8fc7\u8bad\u7ec3\u6837\u672c\u7684\u51f8\u7ec4\u5408\u8fdb\u884c\u9884\u6d4b\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "GNNs\u5df2\u6210\u4e3a\u56fe\u7ed3\u6784\u6570\u636e\u5b66\u4e60\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u4f46\u5176\u4f9d\u8d56\u53c2\u6570\u5316\u5206\u7c7b\u5668\uff08\u901a\u5e38\u662f\u7ebf\u6027softmax\u5c42\uff09\u9650\u5236\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u65f6\u4e5f\u963b\u788d\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u63d2\u503c\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u975e\u8d1f\u6838\u56de\u5f52\uff08NNK\uff09\uff0c\u5c06\u9884\u6d4b\u8868\u793a\u4e3a\u5d4c\u5165\u7a7a\u95f4\u4e2d\u76f8\u4f3c\u8bad\u7ec3\u6837\u672c\u7684\u51f8\u7ec4\u5408\u3002", "result": "\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u8fd8\u4ea7\u751f\u4e86\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\u89e3\u91ca\u3002", "conclusion": "\u57fa\u4e8e\u63d2\u503c\u7684\u975e\u53c2\u6570\u65b9\u6cd5\u53ef\u4ee5\u514b\u670d\u4f20\u7edfGNNs\u53c2\u6570\u5316\u5206\u7c7b\u5668\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.00767", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00767", "abs": "https://arxiv.org/abs/2602.00767", "authors": ["Muhammed Ustaomeroglu", "Guannan Qu"], "title": "BLOCK-EM: Preventing Emergent Misalignment by Blocking Causal Features", "comment": "41 pages, 32 figures. Code available", "summary": "Emergent misalignment can arise when a language model is fine-tuned on a narrowly scoped supervised objective: the model learns the target behavior, yet also develops undesirable out-of-domain behaviors. We investigate a mechanistic approach to preventing emergent misalignment by identifying a small set of internal features that reliably control the misaligned behavior and then discouraging the model from strengthening these features during fine-tuning. Across six fine-tuning domains, blocking (i.e., constraining) a fixed set of features achieves up to 95\\% relative reduction in emergent misalignment with no degradation in model quality or target-task performance. We strengthen validity with disjoint selection/evaluation splits, multiple independent judges, multiple random seeds for key settings, quality metrics, and extensive ablations demonstrating that the reduction in misalignment is specific to the identified mechanism. We also characterize a limiting regime in which misalignment re-emerges under prolonged fine-tuning, present evidence consistent with rerouting through alternative features or layers, and evaluate modifications that partially restore the misalignment-blocking effect. Overall, our results show that targeted training-time constraints on internal mechanisms can mitigate emergent misalignment without degrading target-task performance.", "AI": {"tldr": "\u901a\u8fc7\u8bc6\u522b\u63a7\u5236\u6a21\u578b\u4e0d\u826f\u884c\u4e3a\u7684\u5185\u90e8\u7279\u5f81\uff0c\u5e76\u5728\u5fae\u8c03\u65f6\u963b\u6b62\u8fd9\u4e9b\u7279\u5f81\u7684\u5f3a\u5316\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u51fa\u73b0\u7684\u9519\u4f4d\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u548c\u76ee\u6807\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u5f53\u8bed\u8a00\u6a21\u578b\u5728\u8303\u56f4\u72ed\u7a84\u7684\u76d1\u7763\u76ee\u6807\u4e0a\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u4f1a\u51fa\u73b0\"\u6d8c\u73b0\u6027\u9519\u4f4d\"\u95ee\u9898\uff1a\u6a21\u578b\u5b66\u4f1a\u4e86\u76ee\u6807\u884c\u4e3a\uff0c\u4f46\u4e5f\u53d1\u5c55\u51fa\u4e0d\u826f\u7684\u57df\u5916\u884c\u4e3a\u3002\u9700\u8981\u627e\u5230\u4e00\u79cd\u673a\u5236\u6027\u65b9\u6cd5\u6765\u9884\u9632\u8fd9\u79cd\u9519\u4f4d\u3002", "method": "\u8bc6\u522b\u4e00\u5c0f\u90e8\u5206\u53ef\u9760\u63a7\u5236\u9519\u4f4d\u884c\u4e3a\u7684\u5185\u90e8\u7279\u5f81\uff0c\u7136\u540e\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u963b\u6b62\u6a21\u578b\u5f3a\u5316\u8fd9\u4e9b\u7279\u5f81\u3002\u901a\u8fc7\u7279\u5f81\u963b\u65ad\uff08\u7ea6\u675f\uff09\u7684\u65b9\u6cd5\uff0c\u5728\u516d\u4e2a\u5fae\u8c03\u9886\u57df\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u963b\u65ad\u56fa\u5b9a\u7279\u5f81\u96c6\u53ef\u5b9e\u73b0\u9ad8\u8fbe95%\u7684\u76f8\u5bf9\u9519\u4f4d\u51cf\u5c11\uff0c\u4e14\u4e0d\u964d\u4f4e\u6a21\u578b\u8d28\u91cf\u6216\u76ee\u6807\u4efb\u52a1\u6027\u80fd\u3002\u901a\u8fc7\u591a\u79cd\u9a8c\u8bc1\u65b9\u6cd5\u786e\u8ba4\u4e86\u6548\u679c\u7684\u7279\u5f02\u6027\uff0c\u4f46\u4e5f\u53d1\u73b0\u4e86\u5728\u957f\u65f6\u95f4\u5fae\u8c03\u4e0b\u9519\u4f4d\u4f1a\u91cd\u65b0\u51fa\u73b0\u7684\u9650\u5236\u60c5\u51b5\u3002", "conclusion": "\u9488\u5bf9\u5185\u90e8\u673a\u5236\u7684\u6709\u9488\u5bf9\u6027\u7684\u8bad\u7ec3\u65f6\u7ea6\u675f\u53ef\u4ee5\u6709\u6548\u51cf\u8f7b\u6d8c\u73b0\u6027\u9519\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u76ee\u6807\u4efb\u52a1\u6027\u80fd\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u9884\u9632\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u4e0d\u826f\u884c\u4e3a\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00772", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00772", "abs": "https://arxiv.org/abs/2602.00772", "authors": ["Xiaoqi Qiu", "Hao Zeng", "Zhiyu Hou", "Hongxin Wei"], "title": "Provable Model Provenance Set for Large Language Models", "comment": null, "summary": "The growing prevalence of unauthorized model usage and misattribution has increased the need for reliable model provenance analysis. However, existing methods largely rely on heuristic fingerprint-matching rules that lack provable error control and often overlook the existence of multiple sources, leaving the reliability of their provenance claims unverified. In this work, we first formalize the model provenance problem with provable guarantees, requiring rigorous coverage of all true provenances at a prescribed confidence level. Then, we propose the Model Provenance Set (MPS), which employs a sequential test-and-exclusion procedure to adaptively construct a small set satisfying the guarantee. The key idea of MPS is to test the significance of provenance existence within a candidate pool, thereby establishing a provable asymptotic guarantee at a user-specific confidence level. Extensive experiments demonstrate that MPS effectively achieves target provenance coverage while strictly limiting the inclusion of unrelated models, and further reveal its potential for practical provenance analysis in attribution and auditing tasks.", "AI": {"tldr": "\u63d0\u51faMPS\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e8f\u5217\u5316\u6d4b\u8bd5\u4e0e\u6392\u9664\u8fc7\u7a0b\u6784\u5efa\u53ef\u8bc1\u660e\u4fdd\u8bc1\u7684\u6a21\u578b\u6eaf\u6e90\u96c6\u5408\uff0c\u5728\u6307\u5b9a\u7f6e\u4fe1\u6c34\u5e73\u4e0b\u8986\u76d6\u6240\u6709\u771f\u5b9e\u6765\u6e90", "motivation": "\u73b0\u6709\u6a21\u578b\u6eaf\u6e90\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u6307\u7eb9\u5339\u914d\u89c4\u5219\uff0c\u7f3a\u4e4f\u53ef\u8bc1\u660e\u7684\u9519\u8bef\u63a7\u5236\uff0c\u4e14\u5e38\u5ffd\u7565\u591a\u6e90\u60c5\u51b5\uff0c\u5bfc\u81f4\u6eaf\u6e90\u58f0\u660e\u7684\u53ef\u9760\u6027\u65e0\u6cd5\u9a8c\u8bc1", "method": "\u63d0\u51fa\u6a21\u578b\u6eaf\u6e90\u96c6\u5408(MPS)\u65b9\u6cd5\uff0c\u91c7\u7528\u5e8f\u5217\u5316\u6d4b\u8bd5\u4e0e\u6392\u9664\u8fc7\u7a0b\uff0c\u5728\u5019\u9009\u6c60\u4e2d\u6d4b\u8bd5\u6eaf\u6e90\u5b58\u5728\u7684\u663e\u8457\u6027\uff0c\u81ea\u9002\u5e94\u6784\u5efa\u6ee1\u8db3\u4fdd\u8bc1\u7684\u5c0f\u96c6\u5408", "result": "MPS\u80fd\u6709\u6548\u8fbe\u5230\u76ee\u6807\u6eaf\u6e90\u8986\u76d6\u7387\uff0c\u540c\u65f6\u4e25\u683c\u9650\u5236\u65e0\u5173\u6a21\u578b\u7684\u5305\u542b\uff0c\u5728\u5f52\u56e0\u548c\u5ba1\u8ba1\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5b9e\u9645\u6eaf\u6e90\u5206\u6790\u6f5c\u529b", "conclusion": "MPS\u4e3a\u6a21\u578b\u6eaf\u6e90\u95ee\u9898\u63d0\u4f9b\u4e86\u5177\u6709\u53ef\u8bc1\u660e\u4fdd\u8bc1\u7684\u5f62\u5f0f\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u7684\u95ee\u9898"}}
{"id": "2602.00774", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00774", "abs": "https://arxiv.org/abs/2602.00774", "authors": ["Yuxin Lu", "Zhen Peng", "Xiqiang Xia", "Jie Wang"], "title": "A novel VAE-DML fusion framework for casual analysis of greenwashing in the mining industry", "comment": null, "summary": "Against the backdrop of the global green transition and \"dual carbon\" goals, mining industry chain enterprises are pivotal entities in terms of resource consumption and environmental impact. Their environmental performance directly affects regional ecological security and is closely tied to national resource strategies and green transformation outcomes. Ensuring the authenticity and reliability of their environmental disclosure is thus a core and urgent issue for sustainable development and national strategic objectives.From a corporate governance perspective, this study examines equity balance as a fundamental governance mechanism, investigating its inhibitory effect on greenwashing behavior among these enterprises and the underlying pathways involved. Methodologically, the paper innovatively employs a Variational Autoencoder (VAE) and a Double Machine Learning (DML) model to construct counterfactual scenarios, mitigating endogeneity concerns and precisely identifying the causal relationship between equity balance and greenwashing. The findings indicate, first, a significant negative causal relationship between equity balance and corporate greenwashing, confirming its substantive governance effect. Second, this inhibitory effect exhibits notable heterogeneity, manifesting more strongly in western regions, upstream segments of the industrial chain, and industries with high environmental sensitivity. Third, the governance effect demonstrates clear temporal dynamics, with the strongest impact occurring in the current period, followed by a diminishing yet statistically significant lagged effect, and ultimately a stable long-term cumulative influence. Finally, mechanism analysis reveals that equity balance operates through three distinct channels to curb greenwashing: alleviating management performance pressure, enhancing the stability of the executive team, and intensifying media scrutiny.", "AI": {"tldr": "\u80a1\u6743\u5236\u8861\u80fd\u6709\u6548\u6291\u5236\u77ff\u4e1a\u4f01\u4e1a\u7eff\u8272\u6f02\u6d17\u884c\u4e3a\uff0c\u901a\u8fc7\u7f13\u89e3\u7ba1\u7406\u5c42\u4e1a\u7ee9\u538b\u529b\u3001\u589e\u5f3a\u9ad8\u7ba1\u56e2\u961f\u7a33\u5b9a\u6027\u3001\u5f3a\u5316\u5a92\u4f53\u76d1\u7763\u4e09\u6761\u8def\u5f84\u5b9e\u73b0\uff0c\u4e14\u6548\u679c\u5b58\u5728\u533a\u57df\u3001\u4ea7\u4e1a\u94fe\u73af\u8282\u548c\u884c\u4e1a\u5f02\u8d28\u6027\u3002", "motivation": "\u5728\u5168\u7403\u7eff\u8272\u8f6c\u578b\u548c\"\u53cc\u78b3\"\u76ee\u6807\u80cc\u666f\u4e0b\uff0c\u77ff\u4e1a\u4ea7\u4e1a\u94fe\u4f01\u4e1a\u4f5c\u4e3a\u8d44\u6e90\u6d88\u8017\u548c\u73af\u5883\u5f71\u54cd\u7684\u91cd\u70b9\u5b9e\u4f53\uff0c\u5176\u73af\u5883\u4fe1\u606f\u62ab\u9732\u7684\u771f\u5b9e\u6027\u5bf9\u533a\u57df\u751f\u6001\u5b89\u5168\u548c\u56fd\u5bb6\u6218\u7565\u81f3\u5173\u91cd\u8981\u3002\u4ece\u516c\u53f8\u6cbb\u7406\u89d2\u5ea6\u7814\u7a76\u80a1\u6743\u5236\u8861\u8fd9\u4e00\u57fa\u7840\u6cbb\u7406\u673a\u5236\u5982\u4f55\u6291\u5236\u4f01\u4e1a\u7684\u7eff\u8272\u6f02\u6d17\u884c\u4e3a\u3002", "method": "\u521b\u65b0\u6027\u5730\u91c7\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u548c\u53cc\u91cd\u673a\u5668\u5b66\u4e60(DML)\u6a21\u578b\u6784\u5efa\u53cd\u4e8b\u5b9e\u573a\u666f\uff0c\u89e3\u51b3\u5185\u751f\u6027\u95ee\u9898\uff0c\u7cbe\u786e\u8bc6\u522b\u80a1\u6743\u5236\u8861\u4e0e\u7eff\u8272\u6f02\u6d17\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "1) \u80a1\u6743\u5236\u8861\u4e0e\u4f01\u4e1a\u7eff\u8272\u6f02\u6d17\u5b58\u5728\u663e\u8457\u8d1f\u5411\u56e0\u679c\u5173\u7cfb\uff1b2) \u6291\u5236\u6548\u5e94\u5b58\u5728\u5f02\u8d28\u6027\uff1a\u897f\u90e8\u5730\u533a\u3001\u4ea7\u4e1a\u94fe\u4e0a\u6e38\u3001\u9ad8\u73af\u5883\u654f\u611f\u6027\u884c\u4e1a\u6548\u679c\u66f4\u5f3a\uff1b3) \u6cbb\u7406\u6548\u5e94\u5177\u6709\u65f6\u95f4\u52a8\u6001\u6027\uff1a\u5f53\u671f\u6700\u5f3a\uff0c\u6ede\u540e\u6548\u5e94\u9012\u51cf\u4f46\u663e\u8457\uff0c\u6700\u7ec8\u5f62\u6210\u7a33\u5b9a\u957f\u671f\u7d2f\u79ef\u5f71\u54cd\u3002", "conclusion": "\u80a1\u6743\u5236\u8861\u4f5c\u4e3a\u516c\u53f8\u6cbb\u7406\u57fa\u7840\u673a\u5236\uff0c\u901a\u8fc7\u7f13\u89e3\u7ba1\u7406\u5c42\u4e1a\u7ee9\u538b\u529b\u3001\u589e\u5f3a\u9ad8\u7ba1\u56e2\u961f\u7a33\u5b9a\u6027\u3001\u5f3a\u5316\u5a92\u4f53\u76d1\u7763\u4e09\u6761\u8def\u5f84\u6709\u6548\u6291\u5236\u77ff\u4e1a\u4f01\u4e1a\u7eff\u8272\u6f02\u6d17\u884c\u4e3a\uff0c\u4e3a\u4fc3\u8fdb\u4f01\u4e1a\u771f\u5b9e\u73af\u5883\u4fe1\u606f\u62ab\u9732\u63d0\u4f9b\u4e86\u6cbb\u7406\u5c42\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00775", "categories": ["cs.LG", "econ.EM"], "pdf": "https://arxiv.org/pdf/2602.00775", "abs": "https://arxiv.org/abs/2602.00775", "authors": ["Zitao Hong", "Zhen Peng", "Xueping Liu"], "title": "Stable Time Series Prediction of Enterprise Carbon Emissions Based on Causal Inference", "comment": null, "summary": "Against the backdrop of ongoing carbon peaking and carbon neutrality goals, accurate prediction of enterprise carbon emission trends constitutes an essential foundation for energy structure optimization and low-carbon transformation decision-making. Nevertheless, significant heterogeneity persists across regions, industries and individual enterprises regarding energy structure, production scale, policy intensity and governance efficacy, resulting in pronounced distribution shifts and non-stationarity in carbon emission data across both temporal and spatial dimensions. Such cross-regional and cross-enterprise data drift not only compromises the accuracy of carbon emission reporting but substantially undermines the guidance value of predictive models for production planning and carbon quota trading decisions. To address this critical challenge, we integrate causal inference perspectives with stable learning methodologies and time-series modelling, proposing a stable temporal prediction mechanism tailored to distribution shift environments. This mechanism incorporates enterprise-level energy inputs, capital investment, labour deployment, carbon pricing, governmental interventions and policy implementation intensity, constructing a risk consistency-constrained stable learning framework that extracts causal stable features (robust against external perturbations yet demonstrating long-term stable effects on carbon dioxide emissions) from multi-environment samples across diverse policies, regions and industrial sectors. Furthermore, through adaptive normalization and sample reweighting strategies, the approach dynamically rectifies temporal non-stationarity induced by economic fluctuations and policy transitions, ultimately enhancing model generalization capability and explainability in complex environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4f01\u4e1a\u78b3\u6392\u653e\u9884\u6d4b\u7684\u7a33\u5b9a\u65f6\u95f4\u9884\u6d4b\u673a\u5236\uff0c\u7ed3\u5408\u56e0\u679c\u63a8\u65ad\u548c\u7a33\u5b9a\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u8de8\u533a\u57df\u3001\u8de8\u4f01\u4e1a\u7684\u6570\u636e\u5206\u5e03\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u5728\u78b3\u8fbe\u5cf0\u548c\u78b3\u4e2d\u548c\u76ee\u6807\u80cc\u666f\u4e0b\uff0c\u51c6\u786e\u9884\u6d4b\u4f01\u4e1a\u78b3\u6392\u653e\u8d8b\u52bf\u5bf9\u80fd\u6e90\u7ed3\u6784\u4f18\u5316\u548c\u4f4e\u78b3\u8f6c\u578b\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u4e0d\u540c\u5730\u533a\u3001\u884c\u4e1a\u548c\u4f01\u4e1a\u5728\u80fd\u6e90\u7ed3\u6784\u3001\u751f\u4ea7\u89c4\u6a21\u3001\u653f\u7b56\u5f3a\u5ea6\u7b49\u65b9\u9762\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u78b3\u6392\u653e\u6570\u636e\u5728\u65f6\u7a7a\u7ef4\u5ea6\u4e0a\u5448\u73b0\u660e\u663e\u7684\u5206\u5e03\u6f02\u79fb\u548c\u975e\u5e73\u7a33\u6027\uff0c\u8fd9\u5f71\u54cd\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u5bf9\u751f\u4ea7\u89c4\u5212\u3001\u78b3\u914d\u989d\u4ea4\u6613\u51b3\u7b56\u7684\u6307\u5bfc\u4ef7\u503c\u3002", "method": "\u6574\u5408\u56e0\u679c\u63a8\u65ad\u89c6\u89d2\u4e0e\u7a33\u5b9a\u5b66\u4e60\u65b9\u6cd5\u53ca\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\uff0c\u63d0\u51fa\u9002\u7528\u4e8e\u5206\u5e03\u6f02\u79fb\u73af\u5883\u7684\u7a33\u5b9a\u65f6\u95f4\u9884\u6d4b\u673a\u5236\u3002\u8be5\u673a\u5236\u5305\u542b\u4f01\u4e1a\u7ea7\u80fd\u6e90\u6295\u5165\u3001\u8d44\u672c\u6295\u8d44\u3001\u52b3\u52a8\u529b\u914d\u7f6e\u3001\u78b3\u5b9a\u4ef7\u3001\u653f\u5e9c\u5e72\u9884\u548c\u653f\u7b56\u5b9e\u65bd\u5f3a\u5ea6\u7b49\u56e0\u7d20\uff0c\u6784\u5efa\u98ce\u9669\u4e00\u81f4\u6027\u7ea6\u675f\u7684\u7a33\u5b9a\u5b66\u4e60\u6846\u67b6\uff0c\u4ece\u4e0d\u540c\u653f\u7b56\u3001\u5730\u533a\u548c\u5de5\u4e1a\u90e8\u95e8\u7684\u591a\u73af\u5883\u6837\u672c\u4e2d\u63d0\u53d6\u56e0\u679c\u7a33\u5b9a\u7279\u5f81\u3002\u901a\u8fc7\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u548c\u6837\u672c\u91cd\u52a0\u6743\u7b56\u7565\uff0c\u52a8\u6001\u4fee\u6b63\u7ecf\u6d4e\u6ce2\u52a8\u548c\u653f\u7b56\u8f6c\u53d8\u5f15\u8d77\u7684\u65f6\u95f4\u975e\u5e73\u7a33\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u53d6\u5bf9\u5916\u90e8\u6270\u52a8\u5177\u6709\u9c81\u68d2\u6027\u4e14\u5bf9\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u5177\u6709\u957f\u671f\u7a33\u5b9a\u5f71\u54cd\u7684\u56e0\u679c\u7a33\u5b9a\u7279\u5f81\uff0c\u589e\u5f3a\u6a21\u578b\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7a33\u5b9a\u65f6\u95f4\u9884\u6d4b\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u4f01\u4e1a\u78b3\u6392\u653e\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u5206\u5e03\u6f02\u79fb\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u5bf9\u4f4e\u78b3\u8f6c\u578b\u51b3\u7b56\u7684\u6307\u5bfc\u4ef7\u503c\uff0c\u4e3a\u78b3\u8fbe\u5cf0\u548c\u78b3\u4e2d\u548c\u76ee\u6807\u7684\u5b9e\u73b0\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2602.00781", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00781", "abs": "https://arxiv.org/abs/2602.00781", "authors": ["Jiamin Xu", "Kyra Gan"], "title": "Fast Non-Episodic Finite-Horizon RL with K-Step Lookahead Thresholding", "comment": null, "summary": "Online reinforcement learning in non-episodic, finite-horizon MDPs remains underexplored and is challenged by the need to estimate returns to a fixed terminal time. Existing infinite-horizon methods, which often rely on discounted contraction, do not naturally account for this fixed-horizon structure. We introduce a modified Q-function: rather than targeting the full-horizon, we learn a K-step lookahead Q-function that truncates planning to the next K steps. To further improve sample efficiency, we introduce a thresholding mechanism: actions are selected only when their estimated K-step lookahead value exceeds a time-varying threshold. We provide an efficient tabular learning algorithm for this novel objective, proving it achieves fast finite-sample convergence: it achieves minimax optimal constant regret for $K=1$ and $\\mathcal{O}(\\max((K-1),C_{K-1})\\sqrt{SAT\\log(T)})$ regret for any $K \\geq 2$. We numerically evaluate the performance of our algorithm under the objective of maximizing reward. Our implementation adaptively increases K over time, balancing lookahead depth against estimation variance. Empirical results demonstrate superior cumulative rewards over state-of-the-art tabular RL methods across synthetic MDPs and RL environments: JumpRiverswim, FrozenLake and AnyTrading.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6709\u9650\u65f6\u57dfMDP\u4e2d\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528K\u6b65\u524d\u77bbQ\u51fd\u6570\u548c\u9608\u503c\u673a\u5236\uff0c\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u5b66\u4e60", "motivation": "\u73b0\u6709\u65e0\u9650\u65f6\u57df\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6298\u6263\u6536\u7f29\uff0c\u4e0d\u9002\u7528\u4e8e\u5177\u6709\u56fa\u5b9a\u65f6\u57df\u7ed3\u6784\u7684\u975e\u7247\u6bb5\u5f0f\u6709\u9650\u65f6\u57dfMDP\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u56fa\u5b9a\u7ec8\u6b62\u65f6\u95f4\u7684\u56de\u62a5", "method": "\u5f15\u5165K\u6b65\u524d\u77bbQ\u51fd\u6570\uff0c\u5c06\u89c4\u5212\u622a\u65ad\u5230\u672a\u6765K\u6b65\uff1b\u91c7\u7528\u9608\u503c\u673a\u5236\uff0c\u4ec5\u5f53\u4f30\u8ba1\u7684K\u6b65\u524d\u77bb\u503c\u8d85\u8fc7\u65f6\u53d8\u9608\u503c\u65f6\u624d\u9009\u62e9\u52a8\u4f5c\uff1b\u63d0\u51fa\u9ad8\u6548\u7684\u8868\u683c\u5b66\u4e60\u7b97\u6cd5\uff0c\u968f\u65f6\u95f4\u81ea\u9002\u5e94\u589e\u52a0K\u503c\u4ee5\u5e73\u8861\u524d\u77bb\u6df1\u5ea6\u548c\u4f30\u8ba1\u65b9\u5dee", "result": "\u7b97\u6cd5\u5728K=1\u65f6\u8fbe\u5230\u6781\u5c0f\u6781\u5927\u6700\u4f18\u5e38\u6570\u9057\u61be\uff0cK\u22652\u65f6\u9057\u61be\u4e3aO(max((K-1),C_{K-1})\u221a(SATlog(T)))\uff1b\u5728JumpRiverswim\u3001FrozenLake\u548cAnyTrading\u7b49\u73af\u5883\u4e2d\u4f18\u4e8e\u73b0\u6709\u8868\u683cRL\u65b9\u6cd5", "conclusion": "K\u6b65\u524d\u77bbQ\u51fd\u6570\u548c\u9608\u503c\u673a\u5236\u4e3a\u6709\u9650\u65f6\u57dfMDP\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2602.00788", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00788", "abs": "https://arxiv.org/abs/2602.00788", "authors": ["Md Abir Hossen", "Mohammad Ali Javidian", "Vignesh Narayanan", "Jason M. O'Kane", "Pooyan Jamshidi"], "title": "Multi-Objective Multi-Fidelity Bayesian Optimization with Causal Priors", "comment": null, "summary": "Multi-fidelity Bayesian optimization (MFBO) accelerates the search for the global optimum of black-box functions by integrating inexpensive, low-fidelity approximations. The central task of an MFBO policy is to balance the cost-efficiency of low-fidelity proxies against their reduced accuracy to ensure effective progression toward the high-fidelity optimum. Existing MFBO methods primarily capture associational dependencies between inputs, fidelities, and objectives, rather than causal mechanisms, and can perform poorly when lower-fidelity proxies are poorly aligned with the target fidelity. We propose RESCUE (REducing Sampling cost with Causal Understanding and Estimation), a multi-objective MFBO method that incorporates causal calculus to systematically address this challenge. RESCUE learns a structural causal model capturing causal relationships between inputs, fidelities, and objectives, and uses it to construct a probabilistic multi-fidelity (MF) surrogate that encodes intervention effects. Exploiting the causal structure, we introduce a causal hypervolume knowledge-gradient acquisition strategy to select input-fidelity pairs that balance expected multi-objective improvement and cost. We show that RESCUE improves sample efficiency over state-of-the-art MF optimization methods on synthetic and real-world problems in robotics, machine learning (AutoML), and healthcare.", "AI": {"tldr": "RESCUE\u662f\u4e00\u79cd\u591a\u4fdd\u771f\u5ea6\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u6765\u63d0\u5347\u6837\u672c\u6548\u7387\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u4f4e\u4fdd\u771f\u5ea6\u4ee3\u7406\u4e0e\u76ee\u6807\u4fdd\u771f\u5ea6\u4e0d\u4e00\u81f4\u65f6\u7684\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u591a\u4fdd\u771f\u5ea6\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u6355\u6349\u8f93\u5165\u3001\u4fdd\u771f\u5ea6\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u5173\u8054\u6027\u4f9d\u8d56\uff0c\u800c\u975e\u56e0\u679c\u673a\u5236\uff0c\u5f53\u4f4e\u4fdd\u771f\u5ea6\u4ee3\u7406\u4e0e\u76ee\u6807\u4fdd\u771f\u5ea6\u5bf9\u9f50\u4e0d\u4f73\u65f6\u6027\u80fd\u4f1a\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7cfb\u7edf\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u7684\u65b9\u6cd5\u3002", "method": "RESCUE\u5b66\u4e60\u4e00\u4e2a\u6355\u6349\u8f93\u5165\u3001\u4fdd\u771f\u5ea6\u548c\u76ee\u6807\u4e4b\u95f4\u56e0\u679c\u5173\u7cfb\u7684\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff0c\u5e76\u5229\u7528\u5b83\u6784\u5efa\u7f16\u7801\u5e72\u9884\u6548\u5e94\u7684\u6982\u7387\u591a\u4fdd\u771f\u5ea6\u4ee3\u7406\u6a21\u578b\u3002\u57fa\u4e8e\u56e0\u679c\u7ed3\u6784\uff0c\u5f15\u5165\u56e0\u679c\u8d85\u4f53\u79ef\u77e5\u8bc6\u68af\u5ea6\u91c7\u96c6\u7b56\u7565\u6765\u9009\u62e9\u5e73\u8861\u9884\u671f\u591a\u76ee\u6807\u6539\u8fdb\u548c\u6210\u672c\u7684\u8f93\u5165-\u4fdd\u771f\u5ea6\u5bf9\u3002", "result": "\u5728\u673a\u5668\u4eba\u3001\u673a\u5668\u5b66\u4e60\uff08AutoML\uff09\u548c\u533b\u7597\u4fdd\u5065\u7b49\u9886\u57df\u7684\u5408\u6210\u548c\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u4e0a\uff0cRESCUE\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u591a\u4fdd\u771f\u5ea6\u4f18\u5316\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u56e0\u679c\u6f14\u7b97\uff0cRESCUE\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u4f4e\u4fdd\u771f\u5ea6\u8fd1\u4f3c\uff0c\u5728\u591a\u4fdd\u771f\u5ea6\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4f4e\u4fdd\u771f\u5ea6\u4ee3\u7406\u4e0e\u76ee\u6807\u4fdd\u771f\u5ea6\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2602.00791", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.00791", "abs": "https://arxiv.org/abs/2602.00791", "authors": ["Shahryar Zehtabi", "Dong-Jun Han", "Seyyedali Hosseinalipour", "Christopher Brinton"], "title": "Sporadic Gradient Tracking over Directed Graphs: A Theoretical Perspective on Decentralized Federated Learning", "comment": "32 pages, 5 figures", "summary": "Decentralized Federated Learning (DFL) enables clients with local data to collaborate in a peer-to-peer manner to train a generalized model. In this paper, we unify two branches of work that have separately solved important challenges in DFL: (i) gradient tracking techniques for mitigating data heterogeneity and (ii) accounting for diverse availability of resources across clients. We propose $\\textit{Sporadic Gradient Tracking}$ ($\\texttt{Spod-GT}$), the first DFL algorithm that incorporates these factors over general directed graphs by allowing (i) client-specific gradient computation frequencies and (ii) heterogeneous and asymmetric communication frequencies. We conduct a rigorous convergence analysis of our methodology with relaxed assumptions on gradient estimation variance and gradient diversity of clients, providing consensus and optimality guarantees for GT over directed graphs despite intermittent client participation. Through numerical experiments on image classification datasets, we demonstrate the efficacy of $\\texttt{Spod-GT}$ compared to well-known GT baselines.", "AI": {"tldr": "\u63d0\u51faSpod-GT\u7b97\u6cd5\uff0c\u9996\u6b21\u5728\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7edf\u4e00\u5904\u7406\u6570\u636e\u5f02\u6784\u6027\u548c\u8d44\u6e90\u591a\u6837\u6027\u95ee\u9898\uff0c\u652f\u6301\u5ba2\u6237\u7aef\u7279\u5b9a\u7684\u68af\u5ea6\u8ba1\u7b97\u9891\u7387\u548c\u5f02\u6784\u4e0d\u5bf9\u79f0\u901a\u4fe1\u9891\u7387\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60(DFL)\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u6570\u636e\u5f02\u6784\u6027\u5bfc\u81f4\u6536\u655b\u56f0\u96be\uff0c\u4ee5\u53ca\u5ba2\u6237\u7aef\u8d44\u6e90\u591a\u6837\u6027\uff08\u8ba1\u7b97\u548c\u901a\u4fe1\u80fd\u529b\u5dee\u5f02\uff09\u3002\u73b0\u6709\u7814\u7a76\u5206\u522b\u89e3\u51b3\u4e86\u8fd9\u4e24\u4e2a\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faSporadic Gradient Tracking (Spod-GT)\u7b97\u6cd5\uff0c\u5728\u901a\u7528\u6709\u5411\u56fe\u4e0a\u5b9e\u73b0\uff1a1) \u5ba2\u6237\u7aef\u7279\u5b9a\u7684\u68af\u5ea6\u8ba1\u7b97\u9891\u7387\uff1b2) \u5f02\u6784\u4e14\u4e0d\u5bf9\u79f0\u7684\u901a\u4fe1\u9891\u7387\uff1b3) \u653e\u5bbd\u68af\u5ea6\u4f30\u8ba1\u65b9\u5dee\u548c\u68af\u5ea6\u591a\u6837\u6027\u5047\u8bbe\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u7b97\u6cd5\u5728\u6709\u5411\u56fe\u4e0a\u5177\u6709\u5171\u8bc6\u548c\u6700\u4f18\u6027\u4fdd\u8bc1\uff0c\u5373\u4f7f\u5ba2\u6237\u7aef\u95f4\u6b47\u53c2\u4e0e\u3002\u56fe\u50cf\u5206\u7c7b\u5b9e\u9a8c\u663e\u793aSpod-GT\u4f18\u4e8e\u73b0\u6709\u68af\u5ea6\u8ddf\u8e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Spod-GT\u662f\u9996\u4e2a\u7edf\u4e00\u5904\u7406DFL\u4e2d\u6570\u636e\u5f02\u6784\u6027\u548c\u8d44\u6e90\u591a\u6837\u6027\u7684\u7b97\u6cd5\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u5ba2\u6237\u7aef\u8d44\u6e90\u5dee\u5f02\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00792", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00792", "abs": "https://arxiv.org/abs/2602.00792", "authors": ["Guinan Chen", "Xunpeng Huang", "Ying Sun", "Shijin Wang", "Yanyong Zhang", "Chao Wang"], "title": "Latent Shadows: The Gaussian-Discrete Duality in Masked Diffusion", "comment": "10 pages", "summary": "Masked discrete diffusion is a dominant paradigm for high-quality language modeling where tokens are iteratively corrupted to a mask state, yet its inference efficiency is bottlenecked by the lack of deterministic sampling tools. While diffusion duality enables deterministic distillation for uniform models, these approaches generally underperform masked models and rely on complex integral operators. Conversely, in the masked domain, prior methods typically assume the absence of deterministic trajectories, forcing a reliance on stochastic distillation. To bridge this gap, we establish explicit Masked Diffusion Duality, proving that the masked process arises as the projection of a continuous Gaussian process via a novel maximum-value index preservation mechanism. Furthermore, we introduce Masked Consistency Distillation (MCD), a principled framework that leverages this duality to analytically construct the deterministic coupled trajectories required for consistency distillation, bypassing numerical ODE solvers. This result strictly improves upon prior stochastic distillation methods, achieving a 16$\\times$ inference speedup without compromising generation quality. Our findings not only provide a solid theoretical foundation connecting masked and continuous diffusion, but also unlock the full potential of consistency distillation for high-performance discrete generation. Our code is available at https://anonymous.4open.science/r/MCD-70FD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u63a9\u7801\u4e00\u81f4\u6027\u84b8\u998f\uff08MCD\uff09\uff0c\u901a\u8fc7\u5efa\u7acb\u63a9\u7801\u6269\u6563\u5bf9\u5076\u6027\uff0c\u4e3a\u63a9\u7801\u79bb\u6563\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u786e\u5b9a\u6027\u91c7\u6837\u65b9\u6cd5\uff0c\u5b9e\u73b016\u500d\u63a8\u7406\u52a0\u901f\u4e14\u4e0d\u635f\u5931\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u63a9\u7801\u79bb\u6563\u6269\u6563\u662f\u9ad8\u8d28\u91cf\u8bed\u8a00\u5efa\u6a21\u7684\u4e3b\u6d41\u65b9\u6cd5\uff0c\u4f46\u5176\u63a8\u7406\u6548\u7387\u53d7\u9650\u4e8e\u7f3a\u4e4f\u786e\u5b9a\u6027\u91c7\u6837\u5de5\u5177\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u6027\u80fd\u8f83\u5dee\uff0c\u8981\u4e48\u4f9d\u8d56\u590d\u6742\u79ef\u5206\u7b97\u5b50\uff0c\u8981\u4e48\u53ea\u80fd\u4f7f\u7528\u968f\u673a\u84b8\u998f\u3002", "method": "\u5efa\u7acb\u663e\u5f0f\u7684\u63a9\u7801\u6269\u6563\u5bf9\u5076\u6027\uff0c\u8bc1\u660e\u63a9\u7801\u8fc7\u7a0b\u662f\u8fde\u7eed\u9ad8\u65af\u8fc7\u7a0b\u901a\u8fc7\u6700\u5927\u7d22\u5f15\u4fdd\u6301\u673a\u5236\u7684\u6295\u5f71\u3002\u57fa\u4e8e\u6b64\u63d0\u51fa\u63a9\u7801\u4e00\u81f4\u6027\u84b8\u998f\uff08MCD\uff09\uff0c\u5229\u7528\u5bf9\u5076\u6027\u89e3\u6790\u6784\u5efa\u786e\u5b9a\u6027\u8026\u5408\u8f68\u8ff9\uff0c\u7ed5\u8fc7\u6570\u503cODE\u6c42\u89e3\u5668\u3002", "result": "MCD\u4e25\u683c\u4f18\u4e8e\u5148\u524d\u7684\u968f\u673a\u84b8\u998f\u65b9\u6cd5\uff0c\u5b9e\u73b016\u500d\u63a8\u7406\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u4e0d\u53d8\u3002\u4e3a\u63a9\u7801\u548c\u8fde\u7eed\u6269\u6563\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u8fde\u63a5\u3002", "conclusion": "\u672c\u6587\u4e0d\u4ec5\u5efa\u7acb\u4e86\u63a9\u7801\u4e0e\u8fde\u7eed\u6269\u6563\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8fd8\u89e3\u9501\u4e86\u4e00\u81f4\u6027\u84b8\u998f\u5728\u9ad8\u6027\u80fd\u79bb\u6563\u751f\u6210\u4e2d\u7684\u5168\u90e8\u6f5c\u529b\uff0c\u4e3a\u9ad8\u6548\u8bed\u8a00\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.00800", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00800", "abs": "https://arxiv.org/abs/2602.00800", "authors": ["Yebin Yang", "Huaijin Wu", "Fu Guo", "Lin Yao", "Xiaohan Qin", "Jingzhi Wang", "Debing Zhang", "Junchi Yan"], "title": "JTok: On Token Embedding as another Axis of Scaling Law via Joint Token Self-modulation", "comment": null, "summary": "LLMs have traditionally scaled along dense dimensions, where performance is coupled with near-linear increases in computational cost. While MoE decouples capacity from compute, it introduces large memory overhead and hardware efficiency challenges. To overcome these, we propose token-indexed parameters as a novel, orthogonal scaling axis that decouple model capacity from FLOPs. Specifically, we introduce Joint-Token (JTok) and Mixture of Joint-Token (JTok-M), which augment Transformer layers with modulation vectors retrieved from auxiliary embedding tables. These vectors modulate the backbone via lightweight, element-wise operations, incurring negligible FLOPs overhead. Extensive experiments on both dense and MoE backbones, spanning from 650M (190M + 460M embedding) to 61B (17B + 44B embedding) total parameters, demonstrate that our approach consistently reduces validation loss and significantly improves downstream task performance (e.g., +4.1 on MMLU, +8.3 on ARC, +8.9 on CEval). Rigorous isoFLOPs analysis further confirms that JTok-M fundamentally shifts the quality-compute Pareto frontier, achieving comparable model quality with 35% less compute relative to vanilla MoE architectures, and we validate that token-indexed parameters exhibit a predictable power-law scaling behavior. Moreover, our efficient implementation ensures that the overhead introduced by JTok and JTok-M remains marginal.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f29\u653e\u7ef4\u5ea6\u2014\u2014token\u7d22\u5f15\u53c2\u6570\uff0c\u901a\u8fc7JTok\u548cJTok-M\u65b9\u6cd5\u5728Transformer\u5c42\u4e2d\u6dfb\u52a0\u8c03\u5236\u5411\u91cf\uff0c\u4ee5\u6781\u5c0f\u7684\u8ba1\u7b97\u5f00\u9500\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfLLM\u901a\u8fc7\u5bc6\u96c6\u7ef4\u5ea6\u6269\u5c55\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u7ebf\u6027\u589e\u957f\uff0c\u800cMoE\u65b9\u6cd5\u867d\u7136\u89e3\u8026\u4e86\u5bb9\u91cf\u4e0e\u8ba1\u7b97\uff0c\u4f46\u5e26\u6765\u4e86\u5185\u5b58\u5f00\u9500\u548c\u786c\u4ef6\u6548\u7387\u95ee\u9898\u3002\u9700\u8981\u627e\u5230\u4e00\u79cd\u65e2\u80fd\u89e3\u8026\u6a21\u578b\u5bb9\u91cf\u4e0e\u8ba1\u7b97\u5f00\u9500\uff0c\u53c8\u4e0d\u4f1a\u5f15\u5165\u663e\u8457\u989d\u5916\u6210\u672c\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fatoken\u7d22\u5f15\u53c2\u6570\u4f5c\u4e3a\u65b0\u7684\u6b63\u4ea4\u7f29\u653e\u8f74\uff0c\u5f15\u5165Joint-Token (JTok)\u548cMixture of Joint-Token (JTok-M)\u3002\u901a\u8fc7\u5728Transformer\u5c42\u4e2d\u6dfb\u52a0\u4ece\u8f85\u52a9\u5d4c\u5165\u8868\u4e2d\u68c0\u7d22\u7684\u8c03\u5236\u5411\u91cf\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u9010\u5143\u7d20\u64cd\u4f5c\u6765\u8c03\u5236\u4e3b\u5e72\u7f51\u7edc\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002", "result": "\u5728650M\u523061B\u53c2\u6570\u7684\u5bc6\u96c6\u548cMoE\u4e3b\u5e72\u7f51\u7edc\u4e0a\u5b9e\u9a8c\u8868\u660e\uff1a\u9a8c\u8bc1\u635f\u5931\u6301\u7eed\u964d\u4f4e\uff0c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u663e\u8457\u63d0\u5347\uff08MMLU +4.1\uff0cARC +8.3\uff0cCEval +8.9\uff09\u3002isoFLOPs\u5206\u6790\u663e\u793aJTok-M\u5c06\u8d28\u91cf-\u8ba1\u7b97Pareto\u524d\u6cbf\u663e\u8457\u63d0\u5347\uff0c\u76f8\u6bd4\u666e\u901aMoE\u67b6\u6784\u5728\u76f8\u540c\u8d28\u91cf\u4e0b\u51cf\u5c1135%\u8ba1\u7b97\u91cf\u3002token\u7d22\u5f15\u53c2\u6570\u5c55\u73b0\u51fa\u53ef\u9884\u6d4b\u7684\u5e42\u5f8b\u7f29\u653e\u884c\u4e3a\u3002", "conclusion": "token\u7d22\u5f15\u53c2\u6570\u662f\u4e00\u79cd\u6709\u6548\u7684\u6a21\u578b\u7f29\u653e\u65b0\u7ef4\u5ea6\uff0c\u80fd\u591f\u5728\u6781\u5c0f\u8ba1\u7b97\u5f00\u9500\u4e0b\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u8d28\u91cf-\u8ba1\u7b97\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e3aLLM\u6269\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2602.00809", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00809", "abs": "https://arxiv.org/abs/2602.00809", "authors": ["David Craveiro", "Hugo Silva"], "title": "Mobile Exergames: Activity Recognition Based on Smartphone Sensors", "comment": null, "summary": "Smartphone sensors can be extremely useful in providing information on the activities and behaviors of persons. Human activity recognition is increasingly used for games, medical, or surveillance. In this paper, we propose a proof-of-concept 2D endless game called Duck Catch & Fit, which implements a detailed activity recognition system that uses a smartphone accelerometer, gyroscope, and magnetometer sensors. The system applies feature extraction and learning mechanism to detect human activities like staying, side movements, and fake side movements. In addition, a voice recognition system is combined to recognize the word \"fire\" and raise the game's complexity. The results show that it is possible to use machine learning techniques to recognize human activity with high recognition levels. Also, the combination of movement-based and voice-based integrations contributes to a more immersive gameplay.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u6b3e\u7ed3\u5408\u667a\u80fd\u624b\u673a\u4f20\u611f\u5668\u548c\u8bed\u97f3\u8bc6\u522b\u76842D\u65e0\u5c3d\u6e38\u620fDuck Catch & Fit\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6280\u672f\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b", "motivation": "\u667a\u80fd\u624b\u673a\u4f20\u611f\u5668\u80fd\u63d0\u4f9b\u4e30\u5bcc\u7684\u7528\u6237\u6d3b\u52a8\u548c\u884c\u4e3a\u4fe1\u606f\uff0c\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u5728\u6e38\u620f\u3001\u533b\u7597\u548c\u76d1\u63a7\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5982\u4f55\u6709\u6548\u7ed3\u5408\u591a\u79cd\u4f20\u611f\u5668\u6570\u636e\u63d0\u5347\u6e38\u620f\u6c89\u6d78\u611f\u503c\u5f97\u63a2\u7d22", "method": "\u5f00\u53d1\u6982\u5ff5\u9a8c\u8bc1\u6e38\u620fDuck Catch & Fit\uff0c\u4f7f\u7528\u667a\u80fd\u624b\u673a\u52a0\u901f\u5ea6\u8ba1\u3001\u9640\u87ba\u4eea\u548c\u78c1\u529b\u8ba1\u4f20\u611f\u5668\uff0c\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u548c\u5b66\u4e60\u673a\u5236\u8bc6\u522b\u9759\u6b62\u3001\u4fa7\u5411\u79fb\u52a8\u548c\u865a\u5047\u4fa7\u5411\u79fb\u52a8\u7b49\u6d3b\u52a8\uff0c\u5e76\u6574\u5408\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u8bc6\u522b\"fire\"\u6307\u4ee4", "result": "\u673a\u5668\u5b66\u4e60\u6280\u672f\u80fd\u591f\u5b9e\u73b0\u9ad8\u6c34\u5e73\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\uff0c\u8fd0\u52a8\u8bc6\u522b\u548c\u8bed\u97f3\u8bc6\u522b\u7684\u7ed3\u5408\u4e3a\u6e38\u620f\u521b\u9020\u4e86\u66f4\u6c89\u6d78\u5f0f\u7684\u4f53\u9a8c", "conclusion": "\u667a\u80fd\u624b\u673a\u4f20\u611f\u5668\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6280\u672f\u53ef\u4ee5\u6709\u6548\u8bc6\u522b\u4eba\u4f53\u6d3b\u52a8\uff0c\u591a\u6a21\u6001\u8bc6\u522b\u7cfb\u7edf\uff08\u8fd0\u52a8+\u8bed\u97f3\uff09\u80fd\u591f\u663e\u8457\u63d0\u5347\u6e38\u620f\u7684\u590d\u6742\u6027\u548c\u6c89\u6d78\u611f"}}
{"id": "2602.00827", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00827", "abs": "https://arxiv.org/abs/2602.00827", "authors": ["Taesun Yeom", "Taehyeok Ha", "Jaeho Lee"], "title": "Over-Alignment vs Over-Fitting: The Role of Feature Learning Strength in Generalization", "comment": null, "summary": "Feature learning strength (FLS), i.e., the inverse of the effective output scaling of a model, plays a critical role in shaping the optimization dynamics of neural nets. While its impact has been extensively studied under the asymptotic regimes -- both in training time and FLS -- existing theory offers limited insight into how FLS affects generalization in practical settings, such as when training is stopped upon reaching a target training risk. In this work, we investigate the impact of FLS on generalization in deep networks under such practical conditions. Through empirical studies, we first uncover the emergence of an $\\textit{optimal FLS}$ -- neither too small nor too large -- that yields substantial generalization gains. This finding runs counter to the prevailing intuition that stronger feature learning universally improves generalization. To explain this phenomenon, we develop a theoretical analysis of gradient flow dynamics in two-layer ReLU nets trained with logistic loss, where FLS is controlled via initialization scale. Our main theoretical result establishes the existence of an optimal FLS arising from a trade-off between two competing effects: An excessively large FLS induces an $\\textit{over-alignment}$ phenomenon that degrades generalization, while an overly small FLS leads to $\\textit{over-fitting}$.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u7279\u5f81\u5b66\u4e60\u5f3a\u5ea6\uff08FLS\uff09\u5b58\u5728\u6700\u4f18\u503c\uff0c\u65e2\u4e0d\u80fd\u592a\u5c0f\u4e5f\u4e0d\u80fd\u592a\u5927\uff0c\u8fd9\u4e0e\"\u7279\u5f81\u5b66\u4e60\u8d8a\u5f3a\u6cdb\u5316\u8d8a\u597d\"\u7684\u76f4\u89c9\u76f8\u53cd\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u4e3b\u8981\u7814\u7a76FLS\u5728\u6e10\u8fd1\u60c5\u51b5\u4e0b\u7684\u5f71\u54cd\uff0c\u4f46\u5bf9\u5b9e\u9645\u8bad\u7ec3\u4e2d\uff08\u5982\u8fbe\u5230\u76ee\u6807\u8bad\u7ec3\u98ce\u9669\u65f6\u505c\u6b62\uff09FLS\u5982\u4f55\u5f71\u54cd\u6cdb\u5316\u7684\u7406\u89e3\u6709\u9650\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u89c2\u5bdfFLS\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\uff0c\u7136\u540e\u5bf9\u4e24\u5c42ReLU\u7f51\u7edc\u5728\u903b\u8f91\u635f\u5931\u4e0b\u7684\u68af\u5ea6\u6d41\u52a8\u529b\u5b66\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u901a\u8fc7\u521d\u59cb\u5316\u89c4\u6a21\u63a7\u5236FLS\u3002", "result": "\u53d1\u73b0\u5b58\u5728\u6700\u4f18FLS\u503c\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6cdb\u5316\u6027\u80fd\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u6700\u4f18FLS\u6e90\u4e8e\u4e24\u4e2a\u7ade\u4e89\u6548\u5e94\u7684\u6743\u8861\uff1a\u8fc7\u5927\u7684FLS\u5bfc\u81f4\"\u8fc7\u5bf9\u9f50\"\u73b0\u8c61\u635f\u5bb3\u6cdb\u5316\uff0c\u8fc7\u5c0f\u7684FLS\u5bfc\u81f4\u8fc7\u62df\u5408\u3002", "conclusion": "\u7279\u5f81\u5b66\u4e60\u5f3a\u5ea6\u5b58\u5728\u6700\u4f18\u503c\uff0c\u9700\u8981\u5728\"\u8fc7\u5bf9\u9f50\"\u548c\u8fc7\u62df\u5408\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u8fd9\u5bf9\u6df1\u5ea6\u7f51\u7edc\u7684\u5b9e\u9645\u8bad\u7ec3\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2602.00834", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00834", "abs": "https://arxiv.org/abs/2602.00834", "authors": ["Wei Chen", "Jiacheng Li", "Shigui Li", "Zhiqi Lin", "Junmei Yang", "John Paisley", "Delu Zeng"], "title": "Don't Forget Its Variance! The Minimum Path Variance Principle for Accurate and Stable Score-Based Density Ratio Estimation", "comment": null, "summary": "Score-based methods have emerged as a powerful framework for density ratio estimation (DRE), but they face an important paradox in that, while theoretically path-independent, their practical performance depends critically on the chosen path schedule. We resolve this issue by proving that tractable training objectives differ from the ideal, ground-truth objective by a crucial, overlooked term: the path variance of the time score. To address this, we propose MinPV (\\textbf{Min}imum \\textbf{P}ath \\textbf{V}ariance) Principle, which introduces a principled heuristic to minimize the overlooked path variance. Our key contribution is the derivation of a closed-form expression for the variance, turning an intractable problem into a tractable optimization. By parameterizing the path with a flexible Kumaraswamy Mixture Model, our method learns a data-adaptive, low-variance path without heuristic selection. This principled optimization of the complete objective yields more accurate and stable estimators, establishing new state-of-the-art results on challenging benchmarks.", "AI": {"tldr": "\u57fa\u4e8e\u5206\u6570\u7684\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u65b9\u6cd5\u5b58\u5728\u8def\u5f84\u4f9d\u8d56\u6096\u8bba\uff0c\u672c\u6587\u63d0\u51fa\u6700\u5c0f\u8def\u5f84\u65b9\u5dee\u539f\u5219\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u8def\u5f84\u5b66\u4e60\u6570\u636e\u81ea\u9002\u5e94\u4f4e\u65b9\u5dee\u8def\u5f84\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\u3002", "motivation": "\u57fa\u4e8e\u5206\u6570\u7684\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u65b9\u6cd5\u9762\u4e34\u4e00\u4e2a\u91cd\u8981\u6096\u8bba\uff1a\u867d\u7136\u7406\u8bba\u4e0a\u8def\u5f84\u72ec\u7acb\uff0c\u4f46\u5b9e\u9645\u6027\u80fd\u5374\u4e25\u91cd\u4f9d\u8d56\u4e8e\u9009\u62e9\u7684\u8def\u5f84\u8c03\u5ea6\u3002\u8fd9\u662f\u56e0\u4e3a\u53ef\u8bad\u7ec3\u7684\u4f18\u5316\u76ee\u6807\u4e0e\u7406\u60f3\u76ee\u6807\u4e4b\u95f4\u5b58\u5728\u88ab\u5ffd\u89c6\u7684\u5173\u952e\u5dee\u5f02\u2014\u2014\u65f6\u95f4\u5206\u6570\u7684\u8def\u5f84\u65b9\u5dee\u3002", "method": "\u63d0\u51fa\u6700\u5c0f\u8def\u5f84\u65b9\u5dee\u539f\u5219\uff0c\u63a8\u5bfc\u51fa\u8def\u5f84\u65b9\u5dee\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5c06\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u4f18\u5316\u7684\u5f62\u5f0f\u3002\u4f7f\u7528\u7075\u6d3b\u7684Kumaraswamy\u6df7\u5408\u6a21\u578b\u53c2\u6570\u5316\u8def\u5f84\uff0c\u5b66\u4e60\u6570\u636e\u81ea\u9002\u5e94\u7684\u4f4e\u65b9\u5dee\u8def\u5f84\uff0c\u65e0\u9700\u542f\u53d1\u5f0f\u9009\u62e9\u3002", "result": "\u901a\u8fc7\u4f18\u5316\u5b8c\u6574\u76ee\u6807\u83b7\u5f97\u66f4\u51c6\u786e\u548c\u7a33\u5b9a\u7684\u4f30\u8ba1\u5668\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "\u6700\u5c0f\u8def\u5f84\u65b9\u5dee\u539f\u5219\u89e3\u51b3\u4e86\u57fa\u4e8e\u5206\u6570\u7684\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u4e2d\u7684\u8def\u5f84\u4f9d\u8d56\u6096\u8bba\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u88ab\u5ffd\u89c6\u7684\u8def\u5f84\u65b9\u5dee\u9879\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u4f30\u8ba1\u6027\u80fd\uff0c\u4e3a\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u548c\u51c6\u786e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.00849", "categories": ["cs.LG", "cs.AI", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.00849", "abs": "https://arxiv.org/abs/2602.00849", "authors": ["Yuhao Huang", "Shih-Hsin Wang", "Andrea L. Bertozzi", "Bao Wang"], "title": "RMFlow: Refined Mean Flow by a Noise-Injection Step for Multimodal Generation", "comment": "Accepted to ICLR 2026", "summary": "Mean flow (MeanFlow) enables efficient, high-fidelity image generation, yet its single-function evaluation (1-NFE) generation often cannot yield compelling results. We address this issue by introducing RMFlow, an efficient multimodal generative model that integrates a coarse 1-NFE MeanFlow transport with a subsequent tailored noise-injection refinement step. RMFlow approximates the average velocity of the flow path using a neural network trained with a new loss function that balances minimizing the Wasserstein distance between probability paths and maximizing sample likelihood. RMFlow achieves near state-of-the-art results on text-to-image, context-to-molecule, and time-series generation using only 1-NFE, at a computational cost comparable to the baseline MeanFlows.", "AI": {"tldr": "RMFlow\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u6a21\u6001\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u7c97\u7c92\u5ea61-NFE MeanFlow\u4f20\u8f93\u548c\u5b9a\u5236\u5316\u7684\u566a\u58f0\u6ce8\u5165\u7ec6\u5316\u6b65\u9aa4\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u751f\u6210\u8d28\u91cf\u3002", "motivation": "MeanFlow\u867d\u7136\u80fd\u5b9e\u73b0\u9ad8\u6548\u7684\u9ad8\u4fdd\u771f\u56fe\u50cf\u751f\u6210\uff0c\u4f46\u5176\u5355\u6b21\u51fd\u6570\u8bc4\u4f30\uff081-NFE\uff09\u751f\u6210\u7684\u7ed3\u679c\u5f80\u5f80\u4e0d\u591f\u7406\u60f3\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u4fdd\u6301MeanFlow\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u53471-NFE\u751f\u6210\u8d28\u91cf\u3002", "method": "RMFlow\u6574\u5408\u4e86\u7c97\u7c92\u5ea61-NFE MeanFlow\u4f20\u8f93\u548c\u540e\u7eed\u7684\u5b9a\u5236\u5316\u566a\u58f0\u6ce8\u5165\u7ec6\u5316\u6b65\u9aa4\u3002\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u6d41\u8def\u5f84\u7684\u5e73\u5747\u901f\u5ea6\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u635f\u5931\u51fd\u6570\u8bad\u7ec3\uff0c\u8be5\u51fd\u6570\u5e73\u8861\u4e86\u6982\u7387\u8def\u5f84\u95f4Wasserstein\u8ddd\u79bb\u7684\u6700\u5c0f\u5316\u548c\u6837\u672c\u4f3c\u7136\u7684\u6700\u5927\u5316\u3002", "result": "RMFlow\u5728\u6587\u672c\u5230\u56fe\u50cf\u3001\u4e0a\u4e0b\u6587\u5230\u5206\u5b50\u548c\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u4e0a\uff0c\u4ec5\u4f7f\u75281-NFE\u5c31\u8fbe\u5230\u4e86\u63a5\u8fd1\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u7ed3\u679c\uff0c\u8ba1\u7b97\u6210\u672c\u4e0e\u57fa\u7ebfMeanFlow\u76f8\u5f53\u3002", "conclusion": "RMFlow\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86MeanFlow\u57281-NFE\u6a21\u5f0f\u4e0b\u751f\u6210\u8d28\u91cf\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u751f\u6210\u7ed3\u679c\uff0c\u4e3a\u9ad8\u6548\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00852", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00852", "abs": "https://arxiv.org/abs/2602.00852", "authors": ["Pattarawat Chormai", "Klaus-Robert M\u00fcller", "Gr\u00e9goire Montavon"], "title": "Investigating the Robustness of Subtask Distillation under Spurious Correlation", "comment": "7 pages, 3 figures", "summary": "Subtask distillation is an emerging paradigm in which compact, specialized models are extracted from large, general-purpose 'foundation models' for deployment in environments with limited resources or in standalone computer systems. Although distillation uses a teacher model, it still relies on a dataset that is often limited in size and may lack representativeness or exhibit spurious correlations. In this paper, we evaluate established distillation methods, as well as the recent SubDistill method, when using data with spurious correlations for distillation. As the strength of the correlations increases, we observe a widening gap between advanced methods, such as SubDistill, which remain fairly robust, and some baseline methods, which degrade to near-random performance. Overall, our study underscores the challenges of knowledge distillation when applied to imperfect, real-world datasets, particularly those with spurious correlations.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5728\u5b58\u5728\u865a\u5047\u76f8\u5173\u6027\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0SubDistill\u7b49\u5148\u8fdb\u65b9\u6cd5\u76f8\u5bf9\u7a33\u5065\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u5b50\u4efb\u52a1\u84b8\u998f\u867d\u7136\u4f7f\u7528\u6559\u5e08\u6a21\u578b\uff0c\u4f46\u4ecd\u4f9d\u8d56\u6570\u636e\u96c6\uff0c\u800c\u73b0\u5b9e\u6570\u636e\u96c6\u5f80\u5f80\u5b58\u5728\u865a\u5047\u76f8\u5173\u6027\u3001\u4ee3\u8868\u6027\u4e0d\u8db3\u7b49\u95ee\u9898\u3002\u9700\u8981\u8bc4\u4f30\u84b8\u998f\u65b9\u6cd5\u5728\u8fd9\u79cd\u4e0d\u5b8c\u7f8e\u6570\u636e\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u8bc4\u4f30\u4e86\u4f20\u7edf\u84b8\u998f\u65b9\u6cd5\u548c\u6700\u65b0\u7684SubDistill\u65b9\u6cd5\uff0c\u5728\u5177\u6709\u865a\u5047\u76f8\u5173\u6027\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u84b8\u998f\u5b9e\u9a8c\u3002\u901a\u8fc7\u589e\u52a0\u76f8\u5173\u6027\u5f3a\u5ea6\u6765\u89c2\u5bdf\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\u53d8\u5316\u3002", "result": "\u968f\u7740\u865a\u5047\u76f8\u5173\u6027\u589e\u5f3a\uff0cSubDistill\u7b49\u5148\u8fdb\u65b9\u6cd5\u4fdd\u6301\u76f8\u5bf9\u7a33\u5065\uff0c\u800c\u4e00\u4e9b\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u5230\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u4e24\u8005\u5dee\u8ddd\u663e\u8457\u6269\u5927\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5177\u6709\u865a\u5047\u76f8\u5173\u6027\u7684\u4e0d\u5b8c\u7f8e\u73b0\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7a33\u5065\u7684\u84b8\u998f\u65b9\u6cd5\u3002"}}
{"id": "2602.00862", "categories": ["cs.LG", "cs.AI", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.00862", "abs": "https://arxiv.org/abs/2602.00862", "authors": ["Shih-Hsin Wang", "Yuhao Huang", "Taos Transue", "Justin Baker", "Jonathan Forstater", "Thomas Strohmer", "Bao Wang"], "title": "Towards Multiscale Graph-based Protein Learning with Geometric Secondary Structural Motifs", "comment": "Published in NeurIPS 2025", "summary": "Graph neural networks (GNNs) have emerged as powerful tools for learning protein structures by capturing spatial relationships at the residue level. However, existing GNN-based methods often face challenges in learning multiscale representations and modeling long-range dependencies efficiently. In this work, we propose an efficient multiscale graph-based learning framework tailored to proteins. Our proposed framework contains two crucial components: (1) It constructs a hierarchical graph representation comprising a collection of fine-grained subgraphs, each corresponding to a secondary structure motif (e.g., $\u03b1$-helices, $\u03b2$-strands, loops), and a single coarse-grained graph that connects these motifs based on their spatial arrangement and relative orientation. (2) It employs two GNNs for feature learning: the first operates within individual secondary motifs to capture local interactions, and the second models higher-level structural relationships across motifs. Our modular framework allows a flexible choice of GNN in each stage. Theoretically, we show that our hierarchical framework preserves the desired maximal expressiveness, ensuring no loss of critical structural information. Empirically, we demonstrate that integrating baseline GNNs into our multiscale framework remarkably improves prediction accuracy and reduces computational cost across various benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u86cb\u767d\u8d28\u7ed3\u6784\u5b66\u4e60\u7684\u9ad8\u6548\u591a\u5c3a\u5ea6\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5c42\u6b21\u5316\u56fe\u8868\u793a\uff08\u7ec6\u7c92\u5ea6\u4e8c\u7ea7\u7ed3\u6784\u5b50\u56fe\u548c\u7c97\u7c92\u5ea6\u8fde\u63a5\u56fe\uff09\u6765\u6355\u83b7\u5c40\u90e8\u548c\u5168\u5c40\u7ed3\u6784\u4fe1\u606f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eGNN\u7684\u86cb\u767d\u8d28\u7ed3\u6784\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u5c3a\u5ea6\u8868\u793a\u5b66\u4e60\u548c\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\u65b9\u9762\u5b58\u5728\u6548\u7387\u6311\u6218\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6846\u67b6\u6765\u540c\u65f6\u6355\u83b7\u5c40\u90e8\u548c\u5168\u5c40\u7ed3\u6784\u4fe1\u606f\u3002", "method": "\u6784\u5efa\u5305\u542b\u7ec6\u7c92\u5ea6\u4e8c\u7ea7\u7ed3\u6784\u5b50\u56fe\uff08\u03b1-\u87ba\u65cb\u3001\u03b2-\u6298\u53e0\u3001\u73af\u7b49\uff09\u548c\u8fde\u63a5\u8fd9\u4e9b\u57fa\u5e8f\u7684\u7c97\u7c92\u5ea6\u56fe\u7684\u5c42\u6b21\u5316\u56fe\u8868\u793a\uff1b\u4f7f\u7528\u4e24\u4e2aGNN\u5206\u522b\u5b66\u4e60\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u548c\u8de8\u57fa\u5e8f\u7684\u9ad8\u5c42\u7ed3\u6784\u5173\u7cfb\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u8be5\u5c42\u6b21\u5316\u6846\u67b6\u4fdd\u6301\u6700\u5927\u8868\u8fbe\u80fd\u529b\uff0c\u4e0d\u635f\u5931\u5173\u952e\u7ed3\u6784\u4fe1\u606f\uff1b\u5b9e\u8bc1\u8868\u660e\u5c06\u57fa\u7ebfGNN\u96c6\u6210\u5230\u8be5\u591a\u5c3a\u5ea6\u6846\u67b6\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u5c3a\u5ea6\u56fe\u5b66\u4e60\u6846\u67b6\u4e3a\u86cb\u767d\u8d28\u7ed3\u6784\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u8868\u8fbe\u80fd\u529b\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u8868\u793a\u6709\u6548\u5e73\u8861\u4e86\u5c40\u90e8\u7ec6\u8282\u548c\u5168\u5c40\u7ed3\u6784\u5efa\u6a21\u3002"}}
{"id": "2602.00869", "categories": ["cs.LG", "cs.AI", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.00869", "abs": "https://arxiv.org/abs/2602.00869", "authors": ["Yuhao Huang", "Taos Transue", "Shih-Hsin Wang", "William Feldman", "Hong Zhang", "Bao Wang"], "title": "Improving Flow Matching by Aligning Flow Divergence", "comment": "Published in ICML 2025", "summary": "Conditional flow matching (CFM) stands out as an efficient, simulation-free approach for training flow-based generative models, achieving remarkable performance for data generation. However, CFM is insufficient to ensure accuracy in learning probability paths. In this paper, we introduce a new partial differential equation characterization for the error between the learned and exact probability paths, along with its solution. We show that the total variation gap between the two probability paths is bounded above by a combination of the CFM loss and an associated divergence loss. This theoretical insight leads to the design of a new objective function that simultaneously matches the flow and its divergence. Our new approach improves the performance of the flow-based generative model by a noticeable margin without sacrificing generation efficiency. We showcase the advantages of this enhanced training approach over CFM on several important benchmark tasks, including generative modeling for dynamical systems, DNA sequences, and videos. Code is available at \\href{https://github.com/Utah-Math-Data-Science/Flow_Div_Matching}{Utah-Math-Data-Science}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u6761\u4ef6\u6d41\u5339\u914d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u65f6\u5339\u914d\u6d41\u548c\u5176\u6563\u5ea6\u6765\u51cf\u5c11\u5b66\u4e60\u6982\u7387\u8def\u5f84\u7684\u8bef\u5dee\uff0c\u4ece\u800c\u63d0\u9ad8\u6d41\u57fa\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u800c\u4e0d\u727a\u7272\u751f\u6210\u6548\u7387\u3002", "motivation": "\u6761\u4ef6\u6d41\u5339\u914d\uff08CFM\uff09\u867d\u7136\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u6a21\u62df\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f46\u5728\u5b66\u4e60\u6982\u7387\u8def\u5f84\u7684\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u4f5c\u8005\u53d1\u73b0CFM\u4e0d\u80fd\u5b8c\u5168\u786e\u4fdd\u6982\u7387\u8def\u5f84\u7684\u51c6\u786e\u5b66\u4e60\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u5b66\u4e60\u8def\u5f84\u4e0e\u771f\u5b9e\u8def\u5f84\u4e4b\u95f4\u7684\u8bef\u5dee\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u6765\u63cf\u8ff0\u5b66\u4e60\u8def\u5f84\u4e0e\u771f\u5b9e\u8def\u5f84\u4e4b\u95f4\u7684\u8bef\u5dee\uff0c\u5e76\u7ed9\u51fa\u4e86\u5176\u89e3\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4e24\u4e2a\u6982\u7387\u8def\u5f84\u4e4b\u95f4\u7684\u603b\u53d8\u5dee\u5dee\u8ddd\u53d7\u5230CFM\u635f\u5931\u548c\u5173\u8054\u6563\u5ea6\u635f\u5931\u7684\u4e0a\u754c\u7ea6\u675f\u3002\u57fa\u4e8e\u8fd9\u4e00\u7406\u8bba\u6d1e\u5bdf\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7684\u76ee\u6807\u51fd\u6570\uff0c\u540c\u65f6\u5339\u914d\u6d41\u548c\u5176\u6563\u5ea6\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u591a\u4e2a\u91cd\u8981\u57fa\u51c6\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edfCFM\uff0c\u5305\u62ec\u52a8\u6001\u7cfb\u7edf\u751f\u6210\u5efa\u6a21\u3001DNA\u5e8f\u5217\u751f\u6210\u548c\u89c6\u9891\u751f\u6210\u3002\u6539\u8fdb\u540e\u7684\u8bad\u7ec3\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u751f\u6210\u6548\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d41\u57fa\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u540c\u65f6\u5339\u914d\u6d41\u548c\u5176\u6563\u5ea6\uff0c\u53ef\u4ee5\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u6982\u7387\u8def\u5f84\uff0c\u4ece\u800c\u63d0\u9ad8\u6d41\u57fa\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e3a\u6761\u4ef6\u6d41\u5339\u914d\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u6539\u8fdb\uff0c\u5728\u591a\u4e2a\u5e94\u7528\u9886\u57df\u5c55\u73b0\u51fa\u4f18\u52bf\u3002"}}
{"id": "2602.00872", "categories": ["cs.LG", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.00872", "abs": "https://arxiv.org/abs/2602.00872", "authors": ["Shihao Wang", "Qipeng Qian", "Jingquan Wang"], "title": "Learning Heat-based Equations in Self-similar variables", "comment": null, "summary": "We study solution learning for heat-based equations in self-similar variables (SSV). We develop an SSV training framework compatible with standard neural-operator training. We instantiate this framework on the two-dimensional incompressible Navier-Stokes equations and the one-dimensional viscous Burgers equation, and perform controlled comparisons between models trained in physical coordinates and in the corresponding self-similar coordinates using two simple fully connected architectures (standard multilayer perceptrons and a factorized fully connected network). Across both systems and both architectures, SSV-trained networks consistently deliver substantially more accurate and stable extrapolation beyond the training window and better capture qualitative long-time trends. These results suggest that self-similar coordinates provide a mathematically motivated inductive bias for learning the long-time dynamics of heat-based equations.", "AI": {"tldr": "\u7814\u7a76\u70ed\u57fa\u65b9\u7a0b\u5728\u81ea\u76f8\u4f3c\u53d8\u91cf\u4e2d\u7684\u89e3\u5b66\u4e60\uff0c\u5f00\u53d1\u4e0e\u6807\u51c6\u795e\u7ecf\u7b97\u5b50\u8bad\u7ec3\u517c\u5bb9\u7684\u81ea\u76f8\u4f3c\u53d8\u91cf\u8bad\u7ec3\u6846\u67b6\uff0c\u5728\u4e8c\u7ef4\u4e0d\u53ef\u538b\u7f29Navier-Stokes\u65b9\u7a0b\u548c\u4e00\u7ef4\u7c98\u6027Burgers\u65b9\u7a0b\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u7269\u7406\u5750\u6807\u8bad\u7ec3\uff0c\u81ea\u76f8\u4f3c\u5750\u6807\u8bad\u7ec3\u7684\u7f51\u7edc\u5728\u8bad\u7ec3\u7a97\u53e3\u5916\u5177\u6709\u66f4\u51c6\u786e\u7a33\u5b9a\u7684\u5916\u63a8\u80fd\u529b\u548c\u66f4\u597d\u7684\u957f\u671f\u8d8b\u52bf\u6355\u6349\u80fd\u529b\u3002", "motivation": "\u70ed\u57fa\u65b9\u7a0b\u5728\u957f\u65f6\u95f4\u6f14\u5316\u4e2d\u5e38\u8868\u73b0\u51fa\u81ea\u76f8\u4f3c\u884c\u4e3a\uff0c\u4f20\u7edf\u7269\u7406\u5750\u6807\u4e0b\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u5728\u957f\u671f\u5916\u63a8\u65f6\u53ef\u80fd\u4e0d\u591f\u51c6\u786e\u7a33\u5b9a\uff0c\u9700\u8981\u63a2\u7d22\u57fa\u4e8e\u6570\u5b66\u7ed3\u6784\u5148\u9a8c\u7684\u8bad\u7ec3\u6846\u67b6\u6765\u63d0\u5347\u5b66\u4e60\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u81ea\u76f8\u4f3c\u53d8\u91cf\u8bad\u7ec3\u6846\u67b6\uff0c\u4e0e\u6807\u51c6\u795e\u7ecf\u7b97\u5b50\u8bad\u7ec3\u517c\u5bb9\uff1b\u5728\u4e8c\u7ef4\u4e0d\u53ef\u538b\u7f29Navier-Stokes\u65b9\u7a0b\u548c\u4e00\u7ef4\u7c98\u6027Burgers\u65b9\u7a0b\u4e0a\u5b9e\u4f8b\u5316\uff1b\u4f7f\u7528\u4e24\u79cd\u7b80\u5355\u5168\u8fde\u63a5\u67b6\u6784\uff08\u6807\u51c6\u591a\u5c42\u611f\u77e5\u673a\u548c\u56e0\u5b50\u5316\u5168\u8fde\u63a5\u7f51\u7edc\uff09\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff1b\u6bd4\u8f83\u7269\u7406\u5750\u6807\u548c\u81ea\u76f8\u4f3c\u5750\u6807\u4e0b\u7684\u8bad\u7ec3\u6548\u679c\u3002", "result": "\u5728\u4e24\u79cd\u7cfb\u7edf\u548c\u4e24\u79cd\u67b6\u6784\u4e2d\uff0c\u81ea\u76f8\u4f3c\u53d8\u91cf\u8bad\u7ec3\u7684\u7f51\u7edc\u4e00\u81f4\u5730\u63d0\u4f9b\uff1a1\uff09\u8bad\u7ec3\u7a97\u53e3\u5916\u66f4\u51c6\u786e\u7a33\u5b9a\u7684\u5916\u63a8\u6027\u80fd\uff1b2\uff09\u66f4\u597d\u7684\u5b9a\u6027\u957f\u671f\u8d8b\u52bf\u6355\u6349\u80fd\u529b\uff1b3\uff09\u76f8\u6bd4\u7269\u7406\u5750\u6807\u8bad\u7ec3\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u81ea\u76f8\u4f3c\u5750\u6807\u4e3a\u5b66\u4e60\u70ed\u57fa\u65b9\u7a0b\u7684\u957f\u671f\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u6570\u5b66\u52a8\u673a\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u80fd\u663e\u8457\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u5728\u957f\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u5916\u63a8\u80fd\u529b\u548c\u5b9a\u6027\u884c\u4e3a\u6355\u6349\u3002"}}
{"id": "2602.00879", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00879", "abs": "https://arxiv.org/abs/2602.00879", "authors": ["Hao Mark Chen", "Zhiwen Mo", "Royson Lee", "Qianzhou Wang", "Da Li", "Shell Xu Hu", "Wayne Luk", "Timothy Hospedales", "Hongxiang Fan"], "title": "Dynamic Expert Sharing: Decoupling Memory from Parallelism in Mixture-of-Experts Diffusion LLMs", "comment": null, "summary": "Among parallel decoding paradigms, diffusion large language models (dLLMs) have emerged as a promising candidate that balances generation quality and throughput. However, their integration with Mixture-of-Experts (MoE) architectures is constrained by an expert explosion: as the number of tokens generated in parallel increases, the number of distinct experts activated grows nearly linearly. This results in substantial memory traffic that pushes inference into a memory-bound regime, negating the efficiency gains of both MoE and parallel decoding. To address this challenge, we propose Dynamic Expert Sharing (DES), a novel technique that shifts MoE optimization from token-centric pruning and conventional expert skipping methods to sequence-level coreset selection. To maximize expert reuse, DES identifies a compact, high-utility set of experts to satisfy the requirements of an entire parallel decoding block. We introduce two innovative selection strategies: (1) Intra-Sequence Sharing (DES-Seq), which adapts optimal allocation to the sequence level, and (2) Saliency-Aware Voting (DES-Vote), a novel mechanism that allows tokens to collectively elect a coreset based on aggregated router weights. Extensive experiments on MoE dLLMs demonstrate that DES reduces unique expert activations by over 55% and latency by up to 38%, while retaining 99% of vanilla accuracy, effectively decoupling memory overhead from the degree of parallelism.", "AI": {"tldr": "\u63d0\u51faDynamic Expert Sharing (DES)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e8f\u5217\u7ea7\u4e13\u5bb6\u5171\u4eab\u89e3\u51b3MoE\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e13\u5bb6\u7206\u70b8\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5f00\u9500\u5e76\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "MoE\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e76\u884c\u89e3\u7801\u65f6\u9762\u4e34\u4e13\u5bb6\u7206\u70b8\u95ee\u9898\uff1a\u968f\u7740\u5e76\u884c\u751f\u6210token\u6570\u91cf\u589e\u52a0\uff0c\u6fc0\u6d3b\u7684\u4e13\u5bb6\u6570\u91cf\u7ebf\u6027\u589e\u957f\uff0c\u5bfc\u81f4\u5185\u5b58\u6d41\u91cf\u6fc0\u589e\uff0c\u4f7f\u63a8\u7406\u8fdb\u5165\u5185\u5b58\u53d7\u9650\u72b6\u6001\uff0c\u62b5\u6d88\u4e86MoE\u548c\u5e76\u884c\u89e3\u7801\u7684\u6548\u7387\u4f18\u52bf\u3002", "method": "\u63d0\u51faDynamic Expert Sharing (DES)\u6280\u672f\uff0c\u5c06MoE\u4f18\u5316\u4ecetoken\u7ea7\u526a\u679d\u8f6c\u5411\u5e8f\u5217\u7ea7\u6838\u5fc3\u96c6\u9009\u62e9\u3002\u5305\u542b\u4e24\u79cd\u7b56\u7565\uff1a1) DES-Seq\uff1a\u5728\u5e8f\u5217\u7ea7\u522b\u81ea\u9002\u5e94\u6700\u4f18\u5206\u914d\uff1b2) DES-Vote\uff1a\u57fa\u4e8e\u805a\u5408\u8def\u7531\u5668\u6743\u91cd\u7684\u663e\u8457\u6027\u611f\u77e5\u6295\u7968\u673a\u5236\uff0c\u8ba9token\u96c6\u4f53\u9009\u4e3e\u6838\u5fc3\u4e13\u5bb6\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDES\u80fd\u51cf\u5c11\u8d85\u8fc755%\u7684\u552f\u4e00\u4e13\u5bb6\u6fc0\u6d3b\uff0c\u5ef6\u8fdf\u964d\u4f4e\u8fbe38%\uff0c\u540c\u65f6\u4fdd\u630199%\u7684\u539f\u59cb\u6a21\u578b\u7cbe\u5ea6\uff0c\u6709\u6548\u89e3\u8026\u5185\u5b58\u5f00\u9500\u4e0e\u5e76\u884c\u5ea6\u3002", "conclusion": "DES\u901a\u8fc7\u5e8f\u5217\u7ea7\u4e13\u5bb6\u5171\u4eab\u6709\u6548\u89e3\u51b3\u4e86MoE\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e13\u5bb6\u7206\u70b8\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u5e76\u884c\u89e3\u7801\u7684MoE\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2602.00884", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00884", "abs": "https://arxiv.org/abs/2602.00884", "authors": ["Louis Serrano", "Jiequn Han", "Edouard Oyallon", "Shirley Ho", "Rudy Morel"], "title": "Test-time Generalization for Physics through Neural Operator Splitting", "comment": null, "summary": "Neural operators have shown promise in learning solution maps of partial differential equations (PDEs), but they often struggle to generalize when test inputs lie outside the training distribution, such as novel initial conditions, unseen PDE coefficients or unseen physics. Prior works address this limitation with large-scale multiple physics pretraining followed by fine-tuning, but this still requires examples from the new dynamics, falling short of true zero-shot generalization. In this work, we propose a method to enhance generalization at test time, i.e., without modifying pretrained weights. Building on DISCO, which provides a dictionary of neural operators trained across different dynamics, we introduce a neural operator splitting strategy that, at test time, searches over compositions of training operators to approximate unseen dynamics. On challenging out-of-distribution tasks including parameter extrapolation and novel combinations of physics phenomena, our approach achieves state-of-the-art zero-shot generalization results, while being able to recover the underlying PDE parameters. These results underscore test-time computation as a key avenue for building flexible, compositional, and generalizable neural operators.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u795e\u7ecf\u7b97\u5b50\u5206\u88c2\u7b56\u7565\uff0c\u5728\u6d4b\u8bd5\u65f6\u901a\u8fc7\u7ec4\u5408\u8bad\u7ec3\u7b97\u5b50\u6765\u8fd1\u4f3c\u672a\u89c1\u8fc7\u7684\u52a8\u529b\u5b66\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316", "motivation": "\u795e\u7ecf\u7b97\u5b50\u5728\u5904\u7406\u8bad\u7ec3\u5206\u5e03\u5916\u7684\u6d4b\u8bd5\u8f93\u5165\uff08\u5982\u65b0\u7684\u521d\u59cb\u6761\u4ef6\u3001\u672a\u89c1\u8fc7\u7684PDE\u7cfb\u6570\u6216\u7269\u7406\u73b0\u8c61\uff09\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u65b0\u52a8\u6001\u7684\u793a\u4f8b\u8fdb\u884c\u5fae\u8c03\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u96f6\u6837\u672c\u6cdb\u5316", "method": "\u57fa\u4e8eDISCO\uff08\u5728\u4e0d\u540c\u52a8\u529b\u5b66\u4e0a\u8bad\u7ec3\u7684\u795e\u7ecf\u7b97\u5b50\u5b57\u5178\uff09\uff0c\u63d0\u51fa\u795e\u7ecf\u7b97\u5b50\u5206\u88c2\u7b56\u7565\uff0c\u5728\u6d4b\u8bd5\u65f6\u641c\u7d22\u8bad\u7ec3\u7b97\u5b50\u7684\u7ec4\u5408\u6765\u8fd1\u4f3c\u672a\u89c1\u8fc7\u7684\u52a8\u529b\u5b66", "result": "\u5728\u53c2\u6570\u5916\u63a8\u548c\u7269\u7406\u73b0\u8c61\u65b0\u7ec4\u5408\u7b49\u6311\u6218\u6027\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u96f6\u6837\u672c\u6cdb\u5316\u7ed3\u679c\uff0c\u5e76\u80fd\u6062\u590d\u5e95\u5c42PDE\u53c2\u6570", "conclusion": "\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u662f\u6784\u5efa\u7075\u6d3b\u3001\u7ec4\u5408\u5316\u548c\u53ef\u6cdb\u5316\u795e\u7ecf\u7b97\u5b50\u7684\u5173\u952e\u9014\u5f84"}}
{"id": "2602.00885", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00885", "abs": "https://arxiv.org/abs/2602.00885", "authors": ["Ahmad Sarlak", "Abolfazl Razi"], "title": "Reliability-Aware Determinantal Point Processes for Robust Informative Data Selection in Large Language Models", "comment": null, "summary": "Informative data selection is a key requirement for large language models (LLMs) to minimize the amount of data required for fine-tuning, network distillation, and token pruning, enabling fast and efficient deployment, especially under computational and communication constraints. Traditional subset selection methods, including those based on Determinantal Point Processes (DPP), focus on maximizing diversity but assume that selected data batches are always available error-free. This presumption prohibits their use under partial storage outage, imperfect communication, and stochastic access failures. Furthermore, we show that the original formulation collapses under such conditions. To address this gap, we introduce ProbDPP, a novel reliability-aware implementation of k-DPP that accounts for probabilistic data access by recasting the objective function with a regularization term that remains well-posed and decomposes into a geometric diversity term and unreliability cost. The resulting objective facilitates robust selection of diverse data batches under uncertainty. Furthermore, we frame this reliability-aware diversity maximization as a combinatorial semi-bandit problem and propose a UCB-style algorithm to efficiently learn the unknown reliability online. Theoretical analysis provides regret bounds for the proposed approach, ensuring performance guarantees.", "AI": {"tldr": "\u63d0\u51faProbDPP\u65b9\u6cd5\uff0c\u5728\u4f20\u7edfDPP\u6570\u636e\u9009\u62e9\u57fa\u7840\u4e0a\u8003\u8651\u6570\u636e\u8bbf\u95ee\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u9879\u5904\u7406\u6982\u7387\u6027\u6570\u636e\u8bbf\u95ee\uff0c\u5e76\u8bbe\u8ba1\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u4f18\u5316\u9009\u62e9\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff08\u5982DPP\uff09\u5047\u8bbe\u6570\u636e\u603b\u662f\u53ef\u9760\u53ef\u7528\uff0c\u4f46\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5e38\u9047\u5230\u5b58\u50a8\u6545\u969c\u3001\u901a\u4fe1\u4e0d\u5b8c\u7f8e\u548c\u968f\u673a\u8bbf\u95ee\u5931\u8d25\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u539f\u6709\u65b9\u6cd5\u5931\u6548\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u9760\u6027\u611f\u77e5\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u63d0\u51faProbDPP\u65b9\u6cd5\uff0c\u5c06k-DPP\u91cd\u65b0\u8868\u8ff0\u4e3a\u5305\u542b\u6b63\u5219\u5316\u9879\u7684\u76ee\u6807\u51fd\u6570\uff0c\u5206\u89e3\u4e3a\u51e0\u4f55\u591a\u6837\u6027\u9879\u548c\u4e0d\u53ef\u9760\u6027\u6210\u672c\uff1b\u5c06\u53ef\u9760\u6027\u611f\u77e5\u7684\u591a\u6837\u6027\u6700\u5927\u5316\u5efa\u6a21\u4e3a\u7ec4\u5408\u534a\u8d4c\u535a\u95ee\u9898\uff0c\u8bbe\u8ba1UCB\u98ce\u683c\u7b97\u6cd5\u5728\u7ebf\u5b66\u4e60\u672a\u77e5\u53ef\u9760\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e3a\u6240\u63d0\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9057\u61be\u754c\u9650\uff0c\u786e\u4fdd\u6027\u80fd\u4fdd\u8bc1\uff1bProbDPP\u80fd\u591f\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u9c81\u68d2\u5730\u9009\u62e9\u591a\u6837\u5316\u7684\u6570\u636e\u6279\u6b21\u3002", "conclusion": "ProbDPP\u89e3\u51b3\u4e86\u4f20\u7edf\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5728\u8ba1\u7b97\u548c\u901a\u4fe1\u7ea6\u675f\u4e0b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u9760\u6027\u611f\u77e5\u7684\u6570\u636e\u9009\u62e9\u65b9\u6848\u3002"}}
{"id": "2602.00888", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00888", "abs": "https://arxiv.org/abs/2602.00888", "authors": ["Yingjie Niu", "Lanxin Lu", "Changhong Jin", "Ruihai Dong"], "title": "GAPNet: Plug-in Jointly Learning Task-Specific Graph for Dynamic Stock Relation", "comment": null, "summary": "The advent of the web has led to a paradigm shift in the financial relations, with the real-time dissemination of news, social discourse, and financial filings contributing significantly to the reshaping of financial forecasting. The existing methods rely on establishing relations a priori, i.e. predefining graphs to capture inter-stock relationships. However, the stock-related web signals are characterised by high levels of noise, asynchrony, and challenging to obtain, resulting in poor generalisability and non-alignment between the predefined graphs and the downstream tasks. To address this, we propose GAPNet, a Graph Adaptation Plug-in Network that jointly learns task-specific topology and representations in an end-to-end manner. GAPNet attaches to existing pairwise graph or hypergraph backbone models, enabling the dynamic adaptation and rewiring of edge topologies via two complementary components: a Spatial Perception Layer that captures short-term co-movements across assets, and a Temporal Perception Layer that maintains long-term dependency under distribution shift. Across two real-world stock datasets, GAPNet has been shown to consistently enhance the profitability and stability in comparision to the state-of-the-art models, yielding annualised cumulative returns of up to 0.47 for RT-GCN and 0.63 for CI-STHPAN, with peak Sharpe Ratio of 2.20 and 2.12 respectively. The plug-and-play design of GAPNet ensures its broad applicability to diverse GNN-based architectures. Our results underscore that jointly learning graph structures and representations is essential for task-specific relational modeling.", "AI": {"tldr": "GAPNet\u662f\u4e00\u4e2a\u56fe\u81ea\u9002\u5e94\u63d2\u4ef6\u7f51\u7edc\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u4efb\u52a1\u7279\u5b9a\u7684\u62d3\u6251\u548c\u8868\u793a\u6765\u89e3\u51b3\u9884\u5b9a\u4e49\u56fe\u4e0e\u4e0b\u6e38\u4efb\u52a1\u4e0d\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u80a1\u7968\u9884\u6d4b\u7684\u76c8\u5229\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u56fe\u6765\u6355\u6349\u80a1\u7968\u95f4\u5173\u7cfb\uff0c\u4f46\u7f51\u7edc\u4fe1\u53f7\u566a\u58f0\u5927\u3001\u5f02\u6b65\u4e14\u96be\u4ee5\u83b7\u53d6\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u5dee\u4e14\u9884\u5b9a\u4e49\u56fe\u4e0e\u4e0b\u6e38\u4efb\u52a1\u4e0d\u5bf9\u9f50\u3002\u9700\u8981\u4e00\u79cd\u80fd\u52a8\u6001\u9002\u5e94\u4efb\u52a1\u7279\u5b9a\u5173\u7cfb\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGAPNet\u56fe\u81ea\u9002\u5e94\u63d2\u4ef6\u7f51\u7edc\uff0c\u53ef\u9644\u52a0\u5230\u73b0\u6709\u6210\u5bf9\u56fe\u6216\u8d85\u56fe\u9aa8\u5e72\u6a21\u578b\u4e0a\uff0c\u901a\u8fc7\u7a7a\u95f4\u611f\u77e5\u5c42\u6355\u6349\u77ed\u671f\u8d44\u4ea7\u5171\u52a8\u548c\u65f6\u95f4\u611f\u77e5\u5c42\u7ef4\u6301\u5206\u5e03\u6f02\u79fb\u4e0b\u7684\u957f\u671f\u4f9d\u8d56\uff0c\u7aef\u5230\u7aef\u8054\u5408\u5b66\u4e60\u4efb\u52a1\u7279\u5b9a\u62d3\u6251\u548c\u8868\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u80a1\u7968\u6570\u636e\u96c6\u4e0a\uff0cGAPNet\u76f8\u6bd4SOTA\u6a21\u578b\u6301\u7eed\u63d0\u5347\u76c8\u5229\u6027\u548c\u7a33\u5b9a\u6027\uff0cRT-GCN\u5e74\u5316\u7d2f\u8ba1\u6536\u76ca\u8fbe0.47\uff0cCI-STHPAN\u8fbe0.63\uff0c\u5cf0\u503c\u590f\u666e\u6bd4\u7387\u5206\u522b\u4e3a2.20\u548c2.12\u3002", "conclusion": "\u8054\u5408\u5b66\u4e60\u56fe\u7ed3\u6784\u548c\u8868\u793a\u5bf9\u4e8e\u4efb\u52a1\u7279\u5b9a\u5173\u7cfb\u5efa\u6a21\u81f3\u5173\u91cd\u8981\uff0cGAPNet\u7684\u5373\u63d2\u5373\u7528\u8bbe\u8ba1\u786e\u4fdd\u5176\u5e7f\u6cdb\u9002\u7528\u4e8e\u5404\u79cd\u57fa\u4e8eGNN\u7684\u67b6\u6784\u3002"}}
{"id": "2602.00899", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00899", "abs": "https://arxiv.org/abs/2602.00899", "authors": ["Mritunjay Pandey"], "title": "Domain-Adaptive and Scalable Dense Retrieval for Content-Based Recommendation", "comment": "13 pages, 4 figures. Semantic dense retrieval for content-based recommendation on Amazon Reviews 2023 (Category - Fashion). Dataset statistics: 2.0M users; 825.9K items; 2.5M ratings; 94.9M review tokens; 510.5M metadata tokens. Timespan: May 1996 to September 2023. Metadata includes: user reviews (ratings, text, helpfulness votes, etc.); item metadata (descriptions, price, raw images, etc.)", "summary": "E-commerce recommendation and search commonly rely on sparse keyword matching (e.g., BM25), which breaks down under vocabulary mismatch when user intent has limited lexical overlap with product metadata. We cast content-based recommendation as recommendation-as-retrieval: given a natural-language intent signal (a query or review), retrieve the top-K most relevant items from a large catalog via semantic similarity.\n  We present a scalable dense retrieval system based on a two-tower bi-encoder, fine-tuned on the Amazon Reviews 2023 (Fashion) subset using supervised contrastive learning with Multiple Negatives Ranking Loss. We construct training pairs from review text (as a query proxy) and item metadata (as the positive document) and fine-tune on 50,000 sampled interactions with a maximum sequence length of 500 tokens.\n  For efficient serving, we combine FAISS HNSW indexing with an ONNX Runtime inference pipeline using INT8 dynamic quantization. On a review-to-title benchmark over 826,402 catalog items, our approach improves Recall@10 from 0.26 (BM25) to 0.66, while meeting practical latency and model-size constraints: 6.1 ms median CPU inference latency (batch size 1) and a 4x reduction in model size.\n  Overall, we provide an end-to-end, reproducible blueprint for taking domain-adapted dense retrieval from offline training to CPU-efficient serving at catalog scale.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53cc\u5854\u7f16\u7801\u5668\u7684\u7a20\u5bc6\u68c0\u7d22\u7cfb\u7edf\uff0c\u7528\u4e8e\u7535\u5546\u63a8\u8350\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u6027\u89e3\u51b3\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edfBM25\u65b9\u6cd5Recall@10\u4ece0.26\u63d0\u5347\u52300.66\u3002", "motivation": "\u7535\u5546\u63a8\u8350\u548c\u641c\u7d22\u901a\u5e38\u4f9d\u8d56\u7a00\u758f\u5173\u952e\u8bcd\u5339\u914d\uff08\u5982BM25\uff09\uff0c\u5f53\u7528\u6237\u610f\u56fe\u4e0e\u4ea7\u54c1\u5143\u6570\u636e\u8bcd\u6c47\u91cd\u53e0\u6709\u9650\u65f6\u6548\u679c\u4e0d\u4f73\u3002\u9700\u8981\u89e3\u51b3\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u5185\u5bb9\u63a8\u8350\u3002", "method": "\u91c7\u7528\u53cc\u5854\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5728Amazon Reviews 2023\uff08\u65f6\u5c1a\uff09\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u548c\u591a\u91cd\u8d1f\u6837\u672c\u6392\u5e8f\u635f\u5931\u8fdb\u884c\u5fae\u8c03\u3002\u6784\u5efa\u8bad\u7ec3\u5bf9\uff1a\u8bc4\u8bba\u6587\u672c\u4f5c\u4e3a\u67e5\u8be2\u4ee3\u7406\uff0c\u7269\u54c1\u5143\u6570\u636e\u4f5c\u4e3a\u6b63\u6587\u6863\u3002\u4f7f\u7528FAISS HNSW\u7d22\u5f15\u548cONNX Runtime\u63a8\u7406\u7ba1\u9053\uff0c\u7ed3\u5408INT8\u52a8\u6001\u91cf\u5316\u5b9e\u73b0\u9ad8\u6548\u670d\u52a1\u3002", "result": "\u5728\u5305\u542b826,402\u4e2a\u76ee\u5f55\u7269\u54c1\u7684\u8bc4\u8bba\u5230\u6807\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRecall@10\u4eceBM25\u76840.26\u63d0\u5347\u52300.66\u3002\u6ee1\u8db3\u5b9e\u9645\u5ef6\u8fdf\u548c\u6a21\u578b\u5927\u5c0f\u7ea6\u675f\uff1a\u4e2d\u4f4dCPU\u63a8\u7406\u5ef6\u8fdf6.1\u6beb\u79d2\uff08\u6279\u91cf\u5927\u5c0f1\uff09\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c114\u500d\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u3001\u53ef\u590d\u73b0\u7684\u84dd\u56fe\uff0c\u5c06\u9886\u57df\u9002\u5e94\u7684\u7a20\u5bc6\u68c0\u7d22\u4ece\u79bb\u7ebf\u8bad\u7ec3\u6269\u5c55\u5230CPU\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u76ee\u5f55\u670d\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7535\u5546\u63a8\u8350\u7684\u8bed\u4e49\u5339\u914d\u80fd\u529b\u3002"}}
{"id": "2602.00906", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DS", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.00906", "abs": "https://arxiv.org/abs/2602.00906", "authors": ["Anxin Guo", "Jingwei Li"], "title": "Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing", "comment": null, "summary": "Large language models often hallucinate with high confidence on \"random facts\" that lack inferable patterns. We formalize the memorization of such facts as a membership testing problem, unifying the discrete error metrics of Bloom filters with the continuous log-loss of LLMs. By analyzing this problem in the regime where facts are sparse in the universe of plausible claims, we establish a rate-distortion theorem: the optimal memory efficiency is characterized by the minimum KL divergence between score distributions on facts and non-facts. This theoretical framework provides a distinctive explanation for hallucination: even with optimal training, perfect data, and a simplified \"closed world\" setting, the information-theoretically optimal strategy under limited capacity is not to abstain or forget, but to assign high confidence to some non-facts, resulting in hallucination. We validate this theory empirically on synthetic data, showing that hallucinations persist as a natural consequence of lossy compression.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u5c06LLM\u7684\u8bb0\u5fc6\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6210\u5458\u6d4b\u8bd5\u95ee\u9898\uff0c\u8bc1\u660e\u5728\u6709\u9650\u5bb9\u91cf\u4e0b\uff0c\u6700\u4f18\u7b56\u7565\u4f1a\u5bfc\u81f4\u5e7b\u89c9\uff0c\u8fd9\u662f\u6709\u635f\u538b\u7f29\u7684\u81ea\u7136\u7ed3\u679c\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u5bf9\u7f3a\u4e4f\u53ef\u63a8\u65ad\u6a21\u5f0f\u7684\"\u968f\u673a\u4e8b\u5b9e\"\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u5e7b\u89c9\u3002\u672c\u6587\u65e8\u5728\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u7406\u89e3\u8fd9\u79cd\u73b0\u8c61\u7684\u6839\u672c\u539f\u56e0\uff0c\u89e3\u91ca\u4e3a\u4ec0\u4e48\u5373\u4f7f\u6709\u6700\u4f18\u8bad\u7ec3\u3001\u5b8c\u7f8e\u6570\u636e\u548c\u7b80\u5316\u8bbe\u7f6e\uff0c\u5e7b\u89c9\u4ecd\u7136\u4f1a\u53d1\u751f\u3002", "method": "\u5c06\u4e8b\u5b9e\u8bb0\u5fc6\u5f62\u5f0f\u5316\u4e3a\u6210\u5458\u6d4b\u8bd5\u95ee\u9898\uff0c\u7edf\u4e00Bloom\u8fc7\u6ee4\u5668\u7684\u79bb\u6563\u8bef\u5dee\u5ea6\u91cf\u548cLLM\u7684\u8fde\u7eed\u5bf9\u6570\u635f\u5931\u3002\u5728\u4e8b\u5b9e\u7a00\u758f\u7684\u5047\u8bbe\u4e0b\uff0c\u5efa\u7acb\u7387\u5931\u771f\u5b9a\u7406\uff0c\u901a\u8fc7\u4e8b\u5b9e\u4e0e\u975e\u4e8b\u5b9e\u5f97\u5206\u5206\u5e03\u4e4b\u95f4\u7684\u6700\u5c0fKL\u6563\u5ea6\u6765\u8868\u5f81\u6700\u4f18\u8bb0\u5fc6\u6548\u7387\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u6709\u9650\u5bb9\u91cf\u4e0b\uff0c\u4fe1\u606f\u8bba\u6700\u4f18\u7b56\u7565\u4e0d\u662f\u5f03\u6743\u6216\u9057\u5fd8\uff0c\u800c\u662f\u5bf9\u67d0\u4e9b\u975e\u4e8b\u5b9e\u5206\u914d\u9ad8\u7f6e\u4fe1\u5ea6\uff0c\u4ece\u800c\u5bfc\u81f4\u5e7b\u89c9\u3002\u5728\u5408\u6210\u6570\u636e\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u663e\u793a\uff0c\u5e7b\u89c9\u4f5c\u4e3a\u6709\u635f\u538b\u7f29\u7684\u81ea\u7136\u7ed3\u679c\u6301\u7eed\u5b58\u5728\u3002", "conclusion": "\u5e7b\u89c9\u4e0d\u662f\u8bad\u7ec3\u7f3a\u9677\u6216\u6570\u636e\u95ee\u9898\u7684\u7ed3\u679c\uff0c\u800c\u662f\u4fe1\u606f\u8bba\u7ea6\u675f\u4e0b\u6700\u4f18\u538b\u7f29\u7b56\u7565\u7684\u5fc5\u7136\u4ea7\u7269\u3002\u5373\u4f7f\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\uff0c\u6709\u9650\u5bb9\u91cf\u6a21\u578b\u4e5f\u5fc5\u987b\u901a\u8fc7\u4ea7\u751f\u5e7b\u89c9\u6765\u6709\u6548\u8bb0\u5fc6\u7a00\u758f\u4e8b\u5b9e\u3002"}}
{"id": "2602.00907", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00907", "abs": "https://arxiv.org/abs/2602.00907", "authors": ["Pingping Wang", "Yihong Yuan", "Lingcheng Li", "Yongmei Lu"], "title": "PyGALAX: An Open-Source Python Toolkit for Advanced Explainable Geospatial Machine Learning", "comment": null, "summary": "PyGALAX is a Python package for geospatial analysis that integrates automated machine learning (AutoML) and explainable artificial intelligence (XAI) techniques to analyze spatial heterogeneity in both regression and classification tasks. It automatically selects and optimizes machine learning models for different geographic locations and contexts while maintaining interpretability through SHAP (SHapley Additive exPlanations) analysis. PyGALAX builds upon and improves the GALAX framework (Geospatial Analysis Leveraging AutoML and eXplainable AI), which has proven to outperform traditional geographically weighted regression (GWR) methods. Critical enhancements in PyGALAX from the original GALAX framework include automatic bandwidth selection and flexible kernel function selection, providing greater flexibility and robustness for spatial modeling across diverse datasets and research questions. PyGALAX not only inherits all the functionalities of the original GALAX framework but also packages them into an accessible, reproducible, and easily deployable Python toolkit while providing additional options for spatial modeling. It effectively addresses spatial non-stationarity and generates transparent insights into complex spatial relationships at both global and local scales, making advanced geospatial machine learning methods accessible to researchers and practitioners in geography, urban planning, environmental science, and related fields.", "AI": {"tldr": "PyGALAX\u662f\u4e00\u4e2a\u96c6\u6210\u4e86AutoML\u548cXAI\u7684Python\u5730\u7406\u7a7a\u95f4\u5206\u6790\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5904\u7406\u7a7a\u95f4\u5f02\u8d28\u6027\u7684\u56de\u5f52\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u76f8\u6bd4\u4f20\u7edfGWR\u65b9\u6cd5\u6709\u66f4\u597d\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5730\u7406\u52a0\u6743\u56de\u5f52(GWR)\u65b9\u6cd5\u5728\u5904\u7406\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u3001\u81ea\u52a8\u5316\u7684\u5de5\u5177\u6765\u5206\u6790\u548c\u89e3\u91ca\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\uff0c\u4f7f\u9ad8\u7ea7\u5730\u7406\u7a7a\u95f4\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u66f4\u6613\u4e8e\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u4f7f\u7528\u3002", "method": "\u57fa\u4e8eGALAX\u6846\u67b6\u6539\u8fdb\uff0c\u96c6\u6210AutoML\u81ea\u52a8\u9009\u62e9\u548c\u4f18\u5316\u4e0d\u540c\u5730\u7406\u4f4d\u7f6e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4f7f\u7528SHAP\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u65b0\u589e\u81ea\u52a8\u5e26\u5bbd\u9009\u62e9\u548c\u7075\u6d3b\u6838\u51fd\u6570\u9009\u62e9\u529f\u80fd\u3002", "result": "PyGALAX\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edfGWR\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u7a33\u5065\u7684\u7a7a\u95f4\u5efa\u6a21\u80fd\u529b\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\uff0c\u5e76\u5728\u5168\u5c40\u548c\u5c40\u90e8\u5c3a\u5ea6\u4e0a\u751f\u6210\u900f\u660e\u6d1e\u5bdf\u3002", "conclusion": "PyGALAX\u5c06\u9ad8\u7ea7\u5730\u7406\u7a7a\u95f4\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6253\u5305\u6210\u53ef\u8bbf\u95ee\u3001\u53ef\u590d\u73b0\u3001\u6613\u4e8e\u90e8\u7f72\u7684Python\u5de5\u5177\u5305\uff0c\u4e3a\u5730\u7406\u5b66\u3001\u57ce\u5e02\u89c4\u5212\u3001\u73af\u5883\u79d1\u5b66\u7b49\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2602.00910", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00910", "abs": "https://arxiv.org/abs/2602.00910", "authors": ["Cuong Manh Nguyen", "Truong-Son Hy"], "title": "Efficient Deep Learning for Medical Imaging: Bridging the Gap Between High-Performance AI and Clinical Deployment", "comment": null, "summary": "Deep learning has revolutionized medical image analysis, playing a vital role in modern clinical applications. However, the deployment of large-scale models in real-world clinical settings remains challenging due to high computational costs, latency constraints, and patient data privacy concerns associated with cloud-based processing. To address these bottlenecks, this review provides a comprehensive synthesis of efficient and lightweight deep learning architectures specifically tailored for the medical domain. We categorize the landscape of modern efficient models into three primary streams: Convolutional Neural Networks (CNNs), Lightweight Transformers, and emerging Linear Complexity Models. Furthermore, we examine key model compression strategies (including pruning, quantization, knowledge distillation, and low-rank factorization) and evaluate their efficacy in maintaining diagnostic performance while reducing hardware requirements. By identifying current limitations and discussing the transition toward on-device intelligence, this review serves as a roadmap for researchers and practitioners aiming to bridge the gap between high-performance AI and resource-constrained clinical environments.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u7cfb\u7edf\u68b3\u7406\u4e86\u9762\u5411\u533b\u7597\u9886\u57df\u7684\u9ad8\u6548\u8f7b\u91cf\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u5c06\u73b0\u4ee3\u9ad8\u6548\u6a21\u578b\u5206\u4e3aCNN\u3001\u8f7b\u91cfTransformer\u548c\u7ebf\u6027\u590d\u6742\u5ea6\u6a21\u578b\u4e09\u5927\u7c7b\uff0c\u5e76\u8bc4\u4f30\u4e86\u6a21\u578b\u538b\u7f29\u7b56\u7565\u5728\u4fdd\u6301\u8bca\u65ad\u6027\u80fd\u540c\u65f6\u964d\u4f4e\u786c\u4ef6\u9700\u6c42\u7684\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u6311\u6218\uff0c\u5305\u62ec\u9ad8\u8ba1\u7b97\u6210\u672c\u3001\u5ef6\u8fdf\u9650\u5236\u548c\u4e91\u7aef\u5904\u7406\u5e26\u6765\u7684\u60a3\u8005\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u65e8\u5728\u5f25\u5408\u9ad8\u6027\u80fdAI\u4e0e\u8d44\u6e90\u53d7\u9650\u4e34\u5e8a\u73af\u5883\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf9\u533b\u7597\u9886\u57df\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u8fdb\u884c\u5168\u9762\u7efc\u5408\uff0c\u5c06\u73b0\u4ee3\u9ad8\u6548\u6a21\u578b\u5206\u4e3a\u4e09\u5927\u7c7b\uff1a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u8f7b\u91cfTransformer\u548c\u65b0\u5174\u7ebf\u6027\u590d\u6742\u5ea6\u6a21\u578b\uff0c\u5e76\u6df1\u5165\u5206\u6790\u6a21\u578b\u538b\u7f29\u7b56\u7565\uff08\u526a\u679d\u3001\u91cf\u5316\u3001\u77e5\u8bc6\u84b8\u998f\u3001\u4f4e\u79e9\u5206\u89e3\uff09\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u533b\u7597\u9886\u57df\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u63d0\u4f9b\u4e86\u6a21\u578b\u5206\u7c7b\u6846\u67b6\u548c\u538b\u7f29\u7b56\u7565\u8bc4\u4f30\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u4e34\u5e8a\u73af\u5883\u4e2d\u90e8\u7f72AI\u7684\u8def\u7ebf\u56fe\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u533b\u7597\u9886\u57df\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u6307\u5bfc\uff0c\u901a\u8fc7\u5206\u6790\u5f53\u524d\u5c40\u9650\u6027\u548c\u8ba8\u8bba\u5411\u8bbe\u5907\u7aef\u667a\u80fd\u7684\u8fc7\u6e21\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u9ad8\u6027\u80fdAI\u5728\u8d44\u6e90\u53d7\u9650\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2602.00918", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00918", "abs": "https://arxiv.org/abs/2602.00918", "authors": ["Aur\u00e9lien Renault", "Alexis Bondu", "Antoine Cornu\u00e9jols", "Vincent Lemaire"], "title": "Early Classification of Time Series in Non-Stationary Cost Regimes", "comment": null, "summary": "Early Classification of Time Series (ECTS) addresses decision-making problems in which predictions must be made as early as possible while maintaining high accuracy. Most existing ECTS methods assume that the time-dependent decision costs governing the learning objective are known, fixed, and correctly specified. In practice, however, these costs are often uncertain and may change over time, leading to mismatches between training-time and deployment-time objectives. In this paper, we study ECTS under two practically relevant forms of cost non-stationarity: drift in the balance between misclassification and decision delay costs, and stochastic realizations of decision costs that deviate from the nominal training-time model. To address these challenges, we revisit representative ECTS approaches and adapt them to an online learning setting. Focusing on separable methods, we update only the triggering model during deployment, while keeping the classifier fixed. We propose several online adaptations and baselines, including bandit-based and RL-based approaches, and conduct controlled experiments on synthetic data to systematically evaluate robustness under cost non-stationarity. Our results demonstrate that online learning can effectively improve the robustness of ECTS methods to cost drift, with RL-based strategies exhibiting strong and stable performance across varying cost regimes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u65f6\u95f4\u5e8f\u5217\u65e9\u671f\u5206\u7c7b\u5728\u6210\u672c\u975e\u5e73\u7a33\u6027\u4e0b\u7684\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u5e94\u5bf9\u6210\u672c\u6f02\u79fb\u548c\u968f\u673a\u53d8\u5316", "motivation": "\u73b0\u6709ECTS\u65b9\u6cd5\u5047\u8bbe\u51b3\u7b56\u6210\u672c\u56fa\u5b9a\u4e14\u5df2\u77e5\uff0c\u4f46\u5b9e\u9645\u4e2d\u6210\u672c\u7ecf\u5e38\u4e0d\u786e\u5b9a\u4e14\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u5bfc\u81f4\u8bad\u7ec3\u76ee\u6807\u4e0e\u90e8\u7f72\u76ee\u6807\u4e0d\u5339\u914d", "method": "\u5c06ECTS\u65b9\u6cd5\u9002\u914d\u5230\u5728\u7ebf\u5b66\u4e60\u8bbe\u7f6e\uff0c\u9488\u5bf9\u53ef\u5206\u79bb\u65b9\u6cd5\u4ec5\u66f4\u65b0\u89e6\u53d1\u6a21\u578b\u800c\u4fdd\u6301\u5206\u7c7b\u5668\u56fa\u5b9a\uff0c\u63d0\u51fa\u57fa\u4e8ebandit\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u5728\u7ebf\u9002\u5e94\u65b9\u6cd5", "result": "\u5728\u7ebf\u5b66\u4e60\u80fd\u6709\u6548\u63d0\u9ad8ECTS\u65b9\u6cd5\u5bf9\u6210\u672c\u6f02\u79fb\u7684\u9c81\u68d2\u6027\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7b56\u7565\u5728\u4e0d\u540c\u6210\u672c\u673a\u5236\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u4e14\u7a33\u5b9a\u7684\u6027\u80fd", "conclusion": "\u5728\u7ebf\u5b66\u4e60\u662f\u5e94\u5bf9ECTS\u4e2d\u6210\u672c\u975e\u5e73\u7a33\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0cRL-based\u7b56\u7565\u5728\u6210\u672c\u6f02\u79fb\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.00927", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00927", "abs": "https://arxiv.org/abs/2602.00927", "authors": ["Yihao Xue", "Allan Zhang", "Jianhao Huang", "Amit Sahai", "Baharan Mirzasoleiman"], "title": "Beyond What Seems Necessary: Hidden Gains from Scaling Training-Time Reasoning Length under Outcome Supervision", "comment": null, "summary": "Training LLMs to think and reason for longer has become a key ingredient in building state-of-the-art models that can solve complex problems previously out of reach. Recent efforts pursue this in different ways, such as RL fine-tuning to elicit long CoT or scaling latent reasoning through architectural recurrence. This makes reasoning length an important scaling knob. In this work, we identify a novel phenomenon (both theoretically and experimentally): under outcome-only supervision, out-of-distribution (OOD) performance can continue improving as training-time reasoning length (e.g., the token budget in RL, or the loop count in looped Transformers) increases, even after in-distribution (ID) performance has saturated. This suggests that robustness may require a larger budget than ID validation alone would indicate. We provide theoretical explanations via two mechanisms: (i) self-iteration can induce a stronger inductive bias in the hypothesis class, reshaping ID-optimal solutions in ways that improve OOD generalization; and (ii) when shortcut solutions that work for ID samples but not for OOD samples persist in the hypothesis class, regularization can reduce the learned solution's reliance on these shortcuts as the number of self-iterations increases. We complement the theory with empirical evidence from two realizations of scaling training-time reasoning length: increasing the number of loops in looped Transformers on a synthetic task, and increasing token budgets during RL fine-tuning of LLMs on mathematical reasoning.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff1a\u5728\u4ec5\u7ed3\u679c\u76d1\u7763\u4e0b\uff0c\u589e\u52a0\u8bad\u7ec3\u65f6\u63a8\u7406\u957f\u5ea6\uff08\u5982RL\u7684token\u9884\u7b97\u6216\u5faa\u73afTransformer\u7684\u5faa\u73af\u6b21\u6570\uff09\u53ef\u63d0\u5347OOD\u6027\u80fd\uff0c\u5373\u4f7fID\u6027\u80fd\u5df2\u9971\u548c\uff0c\u8868\u660e\u9c81\u68d2\u6027\u9700\u8981\u6bd4ID\u9a8c\u8bc1\u66f4\u5927\u7684\u9884\u7b97\u3002", "motivation": "\u8bad\u7ec3LLMs\u8fdb\u884c\u66f4\u957f\u63a8\u7406\u5df2\u6210\u4e3a\u6784\u5efa\u80fd\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u6700\u5148\u8fdb\u6a21\u578b\u7684\u5173\u952e\u8981\u7d20\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u4e0d\u540c\u65b9\u5f0f\u5b9e\u73b0\uff0c\u5982RL\u5fae\u8c03\u4ee5\u5f15\u51fa\u957f\u94fe\u5f0f\u601d\u7ef4\u6216\u901a\u8fc7\u67b6\u6784\u5faa\u73af\u6269\u5c55\u6f5c\u5728\u63a8\u7406\u3002\u8fd9\u4f7f\u5f97\u63a8\u7406\u957f\u5ea6\u6210\u4e3a\u91cd\u8981\u7684\u6269\u5c55\u53c2\u6570\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e24\u79cd\u673a\u5236\uff1a1\uff09\u81ea\u8fed\u4ee3\u53ef\u5728\u5047\u8bbe\u7c7b\u4e2d\u5f15\u5165\u66f4\u5f3a\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u91cd\u5851ID\u6700\u4f18\u89e3\u4ee5\u6539\u5584OOD\u6cdb\u5316\uff1b2\uff09\u5f53\u4ec5\u9002\u7528\u4e8eID\u6837\u672c\u7684\u6377\u5f84\u89e3\u5728\u5047\u8bbe\u7c7b\u4e2d\u6301\u7eed\u5b58\u5728\u65f6\uff0c\u6b63\u5219\u5316\u53ef\u968f\u7740\u81ea\u8fed\u4ee3\u6b21\u6570\u589e\u52a0\u51cf\u5c11\u5bf9\u6377\u5f84\u7684\u4f9d\u8d56\u3002\u5b9e\u9a8c\u5305\u62ec\u5728\u5408\u6210\u4efb\u52a1\u4e0a\u589e\u52a0\u5faa\u73afTransformer\u7684\u5faa\u73af\u6b21\u6570\uff0c\u4ee5\u53ca\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u589e\u52a0RL\u5fae\u8c03\u7684token\u9884\u7b97\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u636e\u8868\u660e\uff1a\u5728\u4ec5\u7ed3\u679c\u76d1\u7763\u4e0b\uff0cOOD\u6027\u80fd\u53ef\u968f\u7740\u8bad\u7ec3\u65f6\u63a8\u7406\u957f\u5ea6\u7684\u589e\u52a0\u800c\u6301\u7eed\u6539\u5584\uff0c\u5373\u4f7fID\u6027\u80fd\u5df2\u7ecf\u9971\u548c\u3002\u8fd9\u63ed\u793a\u4e86\u9c81\u68d2\u6027\u9700\u8981\u6bd4ID\u9a8c\u8bc1\u66f4\u5927\u7684\u9884\u7b97\uff0c\u4e3a\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002", "conclusion": "\u7814\u7a76\u8bc6\u522b\u4e86\u4e00\u4e2a\u65b0\u73b0\u8c61\uff1a\u589e\u52a0\u8bad\u7ec3\u65f6\u63a8\u7406\u957f\u5ea6\u53ef\u6539\u5584OOD\u6cdb\u5316\uff0c\u5373\u4f7fID\u6027\u80fd\u5df2\u9971\u548c\u3002\u8fd9\u6311\u6218\u4e86\u4ec5\u4f9d\u8d56ID\u9a8c\u8bc1\u786e\u5b9a\u6700\u4f18\u8bad\u7ec3\u9884\u7b97\u7684\u505a\u6cd5\uff0c\u8868\u660e\u9c81\u68d2\u6027\u9700\u8981\u66f4\u5927\u7684\u63a8\u7406\u957f\u5ea6\u9884\u7b97\u3002\u7814\u7a76\u4e3a\u7406\u89e3\u81ea\u8fed\u4ee3\u5982\u4f55\u6539\u5584\u6cdb\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u673a\u5236\uff0c\u5e76\u5bf9\u5b9e\u9645\u6a21\u578b\u8bad\u7ec3\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2602.00931", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00931", "abs": "https://arxiv.org/abs/2602.00931", "authors": ["Muhammad Ahmed Mohsin", "Muhammad Umer", "Ahsan Bilal", "Zihao He", "Muhammad Usman Rafique", "Asad Aali", "Muhammad Ali Jamshed", "John M. Cioffi", "Emily Fox"], "title": "Continuous-Utility Direct Preference Optimization", "comment": "Submitted to ICML 2026", "summary": "Large language model reasoning is often treated as a monolithic capability, relying on binary preference supervision that fails to capture partial progress or fine-grained reasoning quality. We introduce Continuous Utility Direct Preference Optimization (CU-DPO), a framework that aligns models to a portfolio of prompt-based cognitive strategies by replacing binary labels with continuous scores that capture fine-grained reasoning quality. We prove that learning with K strategies yields a Theta(K log K) improvement in sample complexity over binary preferences, and that DPO converges to the entropy-regularized utility-maximizing policy. To exploit this signal, we propose a two-stage training pipeline: (i) strategy selection, which optimizes the model to choose the best strategy for a given problem via best-vs-all comparisons, and (ii) execution refinement, which trains the model to correctly execute the selected strategy using margin-stratified pairs. On mathematical reasoning benchmarks, CU-DPO improves strategy selection accuracy from 35-46 percent to 68-78 percent across seven base models, yielding consistent downstream reasoning gains of up to 6.6 points on in-distribution datasets with effective transfer to out-of-distribution tasks.", "AI": {"tldr": "CU-DPO\uff1a\u7528\u8fde\u7eed\u6548\u7528\u8bc4\u5206\u66ff\u4ee3\u4e8c\u5143\u504f\u597d\uff0c\u901a\u8fc7\u7b56\u7565\u9009\u62e9\u548c\u6267\u884c\u4f18\u5316\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u8fc7\u4e8e\u7b80\u5355\uff0c\u4f7f\u7528\u4e8c\u5143\u504f\u597d\u76d1\u7763\u65e0\u6cd5\u6355\u6349\u90e8\u5206\u8fdb\u5c55\u548c\u7ec6\u7c92\u5ea6\u63a8\u7406\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u548c\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u8fde\u7eed\u6548\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u6846\u67b6\uff1a1\uff09\u7b56\u7565\u9009\u62e9\u9636\u6bb5\uff0c\u901a\u8fc7\u6700\u4f73vs\u6240\u6709\u6bd4\u8f83\u4f18\u5316\u6a21\u578b\u9009\u62e9\u6700\u4f73\u7b56\u7565\uff1b2\uff09\u6267\u884c\u4f18\u5316\u9636\u6bb5\uff0c\u4f7f\u7528\u8fb9\u7f18\u5206\u5c42\u5bf9\u8bad\u7ec3\u6a21\u578b\u6b63\u786e\u6267\u884c\u9009\u5b9a\u7b56\u7565\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\uff0cCU-DPO\u5c06\u7b56\u7565\u9009\u62e9\u51c6\u786e\u7387\u4ece35-46%\u63d0\u5347\u523068-78%\uff0c\u5728\u4e0b\u6e38\u63a8\u7406\u4efb\u52a1\u4e2d\u83b7\u5f97\u9ad8\u8fbe6.6\u5206\u7684\u63d0\u5347\uff0c\u5e76\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u5206\u5e03\u5916\u4efb\u52a1\u3002", "conclusion": "CU-DPO\u901a\u8fc7\u8fde\u7eed\u6548\u7528\u8bc4\u5206\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u7ec6\u7c92\u5ea6\u76d1\u7763\u4fe1\u53f7\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.00942", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00942", "abs": "https://arxiv.org/abs/2602.00942", "authors": ["Hao Ma", "Melis Ilayda Bal", "Liang Zhang", "Bingcong Li", "Niao He", "Melanie Zeilinger", "Michael Muehlebach"], "title": "SALAAD: Sparse And Low-Rank Adaptation via ADMM", "comment": null, "summary": "Modern large language models are increasingly deployed under compute and memory constraints, making flexible control of model capacity a central challenge. While sparse and low-rank structures naturally trade off capacity and performance, existing approaches often rely on heuristic designs that ignore layer and matrix heterogeneity or require model-specific architectural modifications. We propose SALAAD, a plug-and-play framework applicable to different model architectures that induces sparse and low-rank structures during training. By formulating structured weight learning under an augmented Lagrangian framework and introducing an adaptive controller that dynamically balances the training loss and structural constraints, SALAAD preserves the stability of standard training dynamics while enabling explicit control over the evolution of effective model capacity during training. Experiments across model scales show that SALAAD substantially reduces memory consumption during deployment while achieving performance comparable to ad-hoc methods. Moreover, a single training run yields a continuous spectrum of model capacities, enabling smooth and elastic deployment across diverse memory budgets without the need for retraining.", "AI": {"tldr": "SALAAD\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u6846\u67b6\uff0c\u53ef\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8bf1\u5bfc\u7a00\u758f\u548c\u4f4e\u79e9\u7ed3\u6784\uff0c\u5b9e\u73b0\u6a21\u578b\u5bb9\u91cf\u7684\u7075\u6d3b\u63a7\u5236\uff0c\u51cf\u5c11\u90e8\u7f72\u5185\u5b58\u6d88\u8017\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u5185\u5b58\u9884\u7b97\u3002", "motivation": "\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u53d7\u9650\u7684\u73af\u5883\u4e0b\u90e8\u7f72\uff0c\u9700\u8981\u7075\u6d3b\u63a7\u5236\u6a21\u578b\u5bb9\u91cf\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u8bbe\u8ba1\uff0c\u5ffd\u7565\u4e86\u5c42\u548c\u77e9\u9635\u7684\u5f02\u8d28\u6027\uff0c\u6216\u9700\u8981\u6a21\u578b\u7279\u5b9a\u7684\u67b6\u6784\u4fee\u6539\u3002", "method": "\u63d0\u51faSALAAD\u6846\u67b6\uff0c\u5728\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u6846\u67b6\u4e0b\u5236\u5b9a\u7ed3\u6784\u5316\u6743\u91cd\u5b66\u4e60\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u63a7\u5236\u5668\u52a8\u6001\u5e73\u8861\u8bad\u7ec3\u635f\u5931\u548c\u7ed3\u6784\u7ea6\u675f\uff0c\u4fdd\u6301\u6807\u51c6\u8bad\u7ec3\u52a8\u6001\u7684\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6709\u6548\u6a21\u578b\u5bb9\u91cf\u6f14\u53d8\u7684\u663e\u5f0f\u63a7\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSALAAD\u663e\u8457\u51cf\u5c11\u4e86\u90e8\u7f72\u65f6\u7684\u5185\u5b58\u6d88\u8017\uff0c\u6027\u80fd\u4e0e\u4e13\u95e8\u8bbe\u8ba1\u7684\u65b9\u6cd5\u76f8\u5f53\u3002\u5355\u6b21\u8bad\u7ec3\u8fd0\u884c\u4ea7\u751f\u8fde\u7eed\u7684\u6a21\u578b\u5bb9\u91cf\u8c31\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5728\u4e0d\u540c\u5185\u5b58\u9884\u7b97\u4e0b\u5b9e\u73b0\u5e73\u6ed1\u5f39\u6027\u90e8\u7f72\u3002", "conclusion": "SALAAD\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u53ef\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8bf1\u5bfc\u7a00\u758f\u548c\u4f4e\u79e9\u7ed3\u6784\uff0c\u5b9e\u73b0\u6a21\u578b\u5bb9\u91cf\u7684\u7075\u6d3b\u63a7\u5236\uff0c\u4e3a\u8ba1\u7b97\u548c\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\u7684\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00943", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00943", "abs": "https://arxiv.org/abs/2602.00943", "authors": ["Zhenyu Zhao", "David Zhang", "Ellie Zhao", "Ehsan Saberian"], "title": "Dynamic Prior Thompson Sampling for Cold-Start Exploration in Recommender Systems", "comment": null, "summary": "Cold-start exploration is a core challenge in large-scale recommender systems: new or data-sparse items must receive traffic to estimate value, but over-exploration harms users and wastes impressions. In practice, Thompson Sampling (TS) is often initialized with a uniform Beta(1,1) prior, implicitly assuming a 50% success rate for unseen items. When true base rates are far lower, this optimistic prior systematically over-allocates to weak items. The impact is amplified by batched policy updates and pipeline latency: for hours, newly launched items can remain effectively \"no data,\" so the prior dominates allocation before feedback is incorporated. We propose Dynamic Prior Thompson Sampling, a prior design that directly controls the probability that a new arm outcompetes the incumbent winner. Our key contribution is a closed-form quadratic solution for the prior mean that enforces P(X_j > Y_k) = epsilon at introduction time, making exploration intensity predictable and tunable while preserving TS Bayesian updates. Across Monte Carlo validation, offline batched simulations, and a large-scale online experiment on a thumbnail personalization system serving millions of users, dynamic priors deliver precise exploration control and improved efficiency versus a uniform-prior baseline.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u5148\u9a8c\u6c64\u666e\u68ee\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u5148\u9a8c\u5206\u5e03\u6765\u63a7\u5236\u65b0\u7269\u54c1\u7684\u63a2\u7d22\u6982\u7387\uff0c\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u51b7\u542f\u52a8\u63a2\u7d22\u8fc7\u5ea6\u7684\u95ee\u9898\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u4e2d\u51b7\u542f\u52a8\u63a2\u7d22\u7684\u6838\u5fc3\u6311\u6218\uff1a\u65b0\u7269\u54c1\u6216\u6570\u636e\u7a00\u758f\u7269\u54c1\u9700\u8981\u6d41\u91cf\u6765\u4f30\u8ba1\u4ef7\u503c\uff0c\u4f46\u8fc7\u5ea6\u63a2\u7d22\u4f1a\u4f24\u5bb3\u7528\u6237\u5e76\u6d6a\u8d39\u66dd\u5149\u3002\u4f20\u7edf\u6c64\u666e\u68ee\u91c7\u6837\u4f7f\u7528\u5747\u5300Beta(1,1)\u5148\u9a8c\uff0c\u5047\u8bbe\u65b0\u7269\u54c1\u670950%\u6210\u529f\u7387\uff0c\u5f53\u771f\u5b9e\u57fa\u7840\u7387\u8fdc\u4f4e\u4e8e\u6b64\u503c\u65f6\uff0c\u8fd9\u79cd\u4e50\u89c2\u5148\u9a8c\u4f1a\u7cfb\u7edf\u6027\u5730\u8fc7\u5ea6\u5206\u914d\u7ed9\u5f31\u7269\u54c1\u3002\u6279\u5904\u7406\u7b56\u7565\u66f4\u65b0\u548c\u7ba1\u9053\u5ef6\u8fdf\u8fdb\u4e00\u6b65\u653e\u5927\u4e86\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u5148\u9a8c\u6c64\u666e\u68ee\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5148\u9a8c\u5206\u5e03\u76f4\u63a5\u63a7\u5236\u65b0\u81c2\u80dc\u8fc7\u73b0\u6709\u8d62\u5bb6\u7684\u6982\u7387\u3002\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u4f9b\u5148\u9a8c\u5747\u503c\u7684\u95ed\u5f0f\u4e8c\u6b21\u89e3\uff0c\u786e\u4fdd\u5728\u5f15\u5165\u65f6P(X_j > Y_k) = epsilon\uff0c\u4f7f\u63a2\u7d22\u5f3a\u5ea6\u53ef\u9884\u6d4b\u4e14\u53ef\u8c03\uff0c\u540c\u65f6\u4fdd\u7559\u6c64\u666e\u68ee\u91c7\u6837\u7684\u8d1d\u53f6\u65af\u66f4\u65b0\u673a\u5236\u3002", "result": "\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u9a8c\u8bc1\u3001\u79bb\u7ebf\u6279\u5904\u7406\u6a21\u62df\u4ee5\u53ca\u5728\u670d\u52a1\u6570\u767e\u4e07\u7528\u6237\u7684\u7f29\u7565\u56fe\u4e2a\u6027\u5316\u7cfb\u7edf\u4e0a\u8fdb\u884c\u7684\u5927\u89c4\u6a21\u5728\u7ebf\u5b9e\u9a8c\uff0c\u52a8\u6001\u5148\u9a8c\u65b9\u6cd5\u76f8\u6bd4\u5747\u5300\u5148\u9a8c\u57fa\u7ebf\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u63a2\u7d22\u63a7\u5236\u548c\u6539\u8fdb\u7684\u6548\u7387\u3002", "conclusion": "\u52a8\u6001\u5148\u9a8c\u6c64\u666e\u68ee\u91c7\u6837\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63a7\u5236\u63a8\u8350\u7cfb\u7edf\u4e2d\u51b7\u542f\u52a8\u7269\u54c1\u7684\u63a2\u7d22\u5f3a\u5ea6\uff0c\u907f\u514d\u8fc7\u5ea6\u63a2\u7d22\u9020\u6210\u7684\u8d44\u6e90\u6d6a\u8d39\u548c\u7528\u6237\u4f53\u9a8c\u4e0b\u964d\uff0c\u5728\u4fdd\u6301\u8d1d\u53f6\u65af\u66f4\u65b0\u4f18\u52bf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u9884\u6d4b\u7684\u63a2\u7d22\u63a7\u5236\u3002"}}
{"id": "2602.00952", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00952", "abs": "https://arxiv.org/abs/2602.00952", "authors": ["Jing Wang", "Jie Shen", "Dean Foster", "Zohar Karnin", "Jeremy C Weiss"], "title": "Optimal Budgeted Adaptation of Large Language Models", "comment": null, "summary": "The trade-off between labeled data availability and downstream accuracy remains a central challenge in fine-tuning large language models (LLMs). We propose a principled framework for \\emph{budget-aware supervised fine-tuning} by casting LLM adaptation as a contextual Stackelberg game. In our formulation, the learner (leader) commits to a scoring policy and a label-querying strategy, while an adaptive environment (follower) selects challenging supervised alternatives in response. To explicitly address label efficiency, we incorporate a finite supervision budget directly into the learning objective. Our algorithm operates in the full-feedback regime and achieves $\\tilde{O}(d\\sqrt{T})$ regret under standard linear contextual assumptions. We extend the framework with a Largest-Latency-First (LLF) confidence gate that selectively queries labels, achieving a budget-aware regret bound of $\\tilde{O}(\\sqrt{dB} + c\\sqrt{B})$ with $B=\u03b2T$.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9884\u7b97\u611f\u77e5\u7684\u76d1\u7763\u5fae\u8c03\u6846\u67b6\uff0c\u5c06LLM\u9002\u5e94\u5efa\u6a21\u4e3a\u4e0a\u4e0b\u6587Stackelberg\u535a\u5f08\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6807\u7b7e\u67e5\u8be2\u5b9e\u73b0\u6807\u7b7e\u6548\u7387\u4f18\u5316\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u6807\u6ce8\u6570\u636e\u53ef\u7528\u6027\u4e0e\u4e0b\u6e38\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6807\u6ce8\u9884\u7b97\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u9ad8\u6548\u5229\u7528\u6807\u6ce8\u8d44\u6e90\u3002", "method": "\u5c06LLM\u9002\u5e94\u5efa\u6a21\u4e3a\u4e0a\u4e0b\u6587Stackelberg\u535a\u5f08\uff1a\u5b66\u4e60\u5668\uff08\u9886\u5bfc\u8005\uff09\u627f\u8bfa\u8bc4\u5206\u7b56\u7565\u548c\u6807\u7b7e\u67e5\u8be2\u7b56\u7565\uff0c\u81ea\u9002\u5e94\u73af\u5883\uff08\u8ddf\u968f\u8005\uff09\u9009\u62e9\u5177\u6709\u6311\u6218\u6027\u7684\u76d1\u7763\u66ff\u4ee3\u65b9\u6848\u3002\u5f15\u5165\u6709\u9650\u76d1\u7763\u9884\u7b97\u5230\u5b66\u4e60\u76ee\u6807\u4e2d\uff0c\u5e76\u91c7\u7528Largest-Latency-First\u7f6e\u4fe1\u95e8\u63a7\u673a\u5236\u8fdb\u884c\u9009\u62e9\u6027\u6807\u7b7e\u67e5\u8be2\u3002", "result": "\u5728\u5168\u53cd\u9988\u673a\u5236\u4e0b\u5b9e\u73b0$\\tilde{O}(d\\sqrt{T})$\u9057\u61be\u754c\uff1b\u901a\u8fc7LLF\u7f6e\u4fe1\u95e8\u63a7\uff0c\u5728\u9884\u7b97\u7ea6\u675f$B=\u03b2T$\u4e0b\u5b9e\u73b0$\\tilde{O}(\\sqrt{dB} + c\\sqrt{B})$\u7684\u9884\u7b97\u611f\u77e5\u9057\u61be\u754c\u3002", "conclusion": "\u63d0\u51fa\u7684\u9884\u7b97\u611f\u77e5\u76d1\u7763\u5fae\u8c03\u6846\u67b6\u901a\u8fc7\u535a\u5f08\u8bba\u5efa\u6a21\u548c\u9009\u62e9\u6027\u6807\u7b7e\u67e5\u8be2\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6807\u6ce8\u6570\u636e\u6709\u9650\u60c5\u51b5\u4e0b\u7684LLM\u9002\u5e94\u95ee\u9898\uff0c\u5728\u7406\u8bba\u4fdd\u8bc1\u4e0b\u5b9e\u73b0\u4e86\u6807\u7b7e\u6548\u7387\u4f18\u5316\u3002"}}
{"id": "2602.00953", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00953", "abs": "https://arxiv.org/abs/2602.00953", "authors": ["Sahar Almahfouz Nasser", "Juan Francisco Pesantez Borja", "Jincheng Liu", "Tanvir Hasan", "Zenghan Wang", "Suman Ghosh", "Sandeep Manandhar", "Shikhar Shiromani", "Twisha Shah", "Naoto Tokuyama", "Anant Madabhushi"], "title": "SAGE: Agentic Framework for Interpretable and Clinically Translatable Computational Pathology Biomarker Discovery", "comment": null, "summary": "Despite significant progress in computational pathology, many AI models remain black-box and difficult to interpret, posing a major barrier to clinical adoption due to limited transparency and explainability. This has motivated continued interest in engineered image-based biomarkers, which offer greater interpretability but are often proposed based on anecdotal evidence or fragmented prior literature rather than systematic biological validation. We introduce SAGE (Structured Agentic system for hypothesis Generation and Evaluation), an agentic AI system designed to identify interpretable, engineered pathology biomarkers by grounding them in biological evidence. SAGE integrates literature-anchored reasoning with multimodal data analysis to correlate image-derived features with molecular biomarkers, such as gene expression, and clinically relevant outcomes. By coordinating specialized agents for biological contextualization and empirical hypothesis validation, SAGE prioritizes transparent, biologically supported biomarkers and advances the clinical translation of computational pathology.", "AI": {"tldr": "SAGE\u662f\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u6587\u732e\u63a8\u7406\u548c\u591a\u6a21\u6001\u6570\u636e\u5206\u6790\uff0c\u5c06\u56fe\u50cf\u7279\u5f81\u4e0e\u5206\u5b50\u751f\u7269\u6807\u5fd7\u7269\u548c\u4e34\u5e8a\u7ed3\u679c\u5173\u8054\uff0c\u65e8\u5728\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u75c5\u7406\u5b66\u751f\u7269\u6807\u5fd7\u7269\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7684AI\u6a21\u578b\u591a\u4e3a\u9ed1\u76d2\u4e14\u96be\u4ee5\u89e3\u91ca\uff0c\u8fd9\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u7684\u900f\u660e\u5ea6\u3002\u867d\u7136\u5de5\u7a0b\u5316\u7684\u56fe\u50cf\u751f\u7269\u6807\u5fd7\u7269\u66f4\u5177\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u901a\u5e38\u57fa\u4e8e\u8f76\u4e8b\u8bc1\u636e\u6216\u96f6\u6563\u7684\u6587\u732e\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u7684\u751f\u7269\u5b66\u9a8c\u8bc1\u3002", "method": "SAGE\u7cfb\u7edf\u6574\u5408\u4e86\u6587\u732e\u951a\u5b9a\u63a8\u7406\u548c\u591a\u6a21\u6001\u6570\u636e\u5206\u6790\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u4ee3\u7406\u8fdb\u884c\u751f\u7269\u5b66\u80cc\u666f\u5316\u548c\u7ecf\u9a8c\u5047\u8bbe\u9a8c\u8bc1\uff0c\u5c06\u56fe\u50cf\u7279\u5f81\u4e0e\u57fa\u56e0\u8868\u8fbe\u7b49\u5206\u5b50\u751f\u7269\u6807\u5fd7\u7269\u4ee5\u53ca\u4e34\u5e8a\u7ed3\u679c\u76f8\u5173\u8054\u3002", "result": "SAGE\u80fd\u591f\u4f18\u5148\u9009\u62e9\u900f\u660e\u4e14\u5177\u6709\u751f\u7269\u5b66\u652f\u6301\u7684\u751f\u7269\u6807\u5fd7\u7269\uff0c\u63a8\u52a8\u8ba1\u7b97\u75c5\u7406\u5b66\u7684\u4e34\u5e8a\u8f6c\u5316\u3002", "conclusion": "SAGE\u7cfb\u7edf\u901a\u8fc7\u7ed3\u6784\u5316\u4ee3\u7406\u65b9\u6cd5\uff0c\u4e3a\u8ba1\u7b97\u75c5\u7406\u5b66\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u751f\u7269\u5b66\u9a8c\u8bc1\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u4e14\u4e34\u5e8a\u53ef\u7528\u7684\u75c5\u7406\u5b66\u751f\u7269\u6807\u5fd7\u7269\u3002"}}
{"id": "2602.00957", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00957", "abs": "https://arxiv.org/abs/2602.00957", "authors": ["Waqar Muhammad Ashraf", "Talha Ansar", "Fahad Ahmed", "Jawad Hussain", "Muhammad Mujtaba Abbas", "Vivek Dua"], "title": "From drift to adaptation to the failed ml model: Transfer Learning in Industrial MLOps", "comment": "Corresponding author: v.dua@ucl.ac.uk", "summary": "Model adaptation to production environment is critical for reliable Machine Learning Operations (MLOps), less attention is paid to developing systematic framework for updating the ML models when they fail under data drift. This paper compares the transfer learning enabled model update strategies including ensemble transfer learning (ETL), all-layers transfer learning (ALTL), and last-layer transfer learning (LLTL) for updating the failed feedforward artificial neural network (ANN) model. The flue gas differential pressure across the air preheater unit installed in a 660 MW thermal power plant is analyzed as a case study since it mimics the batch processes due to load cycling in the power plant. Updating the failed ANN model by three transfer learning techniques reveals that ETL provides relatively higher predictive accuracy for the batch size of 5 days than those of LLTL and ALTL. However, ALTL is found to be suitable for effective update of the model trained on large batch size (8 days). A mixed trend is observed for computational requirement (hyperparameter tuning and model training) of model update techniques for different batch sizes. These fundamental and empiric insights obtained from the batch process-based industrial case study can assist the MLOps practitioners in adapting the failed models to data drifts for the accurate monitoring of industrial processes.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e09\u79cd\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff08ETL\u3001ALTL\u3001LLTL\uff09\u7528\u4e8e\u66f4\u65b0\u5728\u6570\u636e\u6f02\u79fb\u4e0b\u5931\u6548\u7684ANN\u6a21\u578b\uff0c\u901a\u8fc7\u7535\u5382\u70df\u6c14\u538b\u5dee\u6848\u4f8b\u7814\u7a76\u53d1\u73b0ETL\u5728\u5c0f\u6279\u91cf\uff085\u5929\uff09\u65f6\u9884\u6d4b\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u800cALTL\u9002\u5408\u5927\u6279\u91cf\uff088\u5929\uff09\u66f4\u65b0\u3002", "motivation": "MLOps\u4e2d\u6a21\u578b\u9002\u5e94\u751f\u4ea7\u73af\u5883\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u6846\u67b6\u6765\u66f4\u65b0\u5728\u6570\u636e\u6f02\u79fb\u4e0b\u5931\u6548\u7684\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u5de5\u4e1a\u8fc7\u7a0b\u76d1\u63a7\u4e2d\u7684\u6a21\u578b\u66f4\u65b0\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff1a\u96c6\u6210\u8fc1\u79fb\u5b66\u4e60\uff08ETL\uff09\u3001\u5168\u5c42\u8fc1\u79fb\u5b66\u4e60\uff08ALTL\uff09\u548c\u6700\u540e\u4e00\u5c42\u8fc1\u79fb\u5b66\u4e60\uff08LLTL\uff09\uff0c\u7528\u4e8e\u66f4\u65b0\u5931\u6548\u7684\u524d\u9988\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANN\uff09\u6a21\u578b\u3002\u4ee5660MW\u706b\u529b\u53d1\u7535\u5382\u7a7a\u6c14\u9884\u70ed\u5668\u70df\u6c14\u538b\u5dee\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u6a21\u62df\u7535\u5382\u8d1f\u8377\u5faa\u73af\u7684\u6279\u5904\u7406\u8fc7\u7a0b\u3002", "result": "ETL\u57285\u5929\u6279\u91cf\u5927\u5c0f\u4e0b\u63d0\u4f9b\u76f8\u5bf9\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u800cALTL\u9002\u54088\u5929\u5927\u6279\u91cf\u4e0b\u7684\u6709\u6548\u6a21\u578b\u66f4\u65b0\u3002\u4e0d\u540c\u6279\u91cf\u5927\u5c0f\u7684\u8ba1\u7b97\u9700\u6c42\uff08\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u6a21\u578b\u8bad\u7ec3\uff09\u5448\u73b0\u6df7\u5408\u8d8b\u52bf\u3002", "conclusion": "\u4ece\u57fa\u4e8e\u6279\u5904\u7406\u7684\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u4e2d\u83b7\u5f97\u7684\u57fa\u7840\u548c\u5b9e\u8bc1\u89c1\u89e3\uff0c\u53ef\u4ee5\u5e2e\u52a9MLOps\u4ece\u4e1a\u8005\u5c06\u5931\u6548\u6a21\u578b\u9002\u5e94\u6570\u636e\u6f02\u79fb\uff0c\u5b9e\u73b0\u5de5\u4e1a\u8fc7\u7a0b\u7684\u51c6\u786e\u76d1\u63a7\u3002\u4e0d\u540c\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\u5728\u4e0d\u540c\u6279\u91cf\u5927\u5c0f\u4e0b\u5404\u6709\u4f18\u52a3\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.00959", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00959", "abs": "https://arxiv.org/abs/2602.00959", "authors": ["Yuheng Yang", "Siqi Zhu", "Tao Feng", "Ge Liu", "Jiaxuan You"], "title": "Probing the Knowledge Boundary: An Interactive Agentic Framework for Deep Knowledge Extraction", "comment": "Homepage: https://ulab-uiuc.github.io/KnowledgeExtraction/", "summary": "Large Language Models (LLMs) can be seen as compressed knowledge bases, but it remains unclear what knowledge they truly contain and how far their knowledge boundaries extend. Existing benchmarks are mostly static and provide limited support for systematic knowledge probing. In this paper, we propose an interactive agentic framework to systematically extract and quantify the knowledge of LLMs. Our method includes four adaptive exploration policies to probe knowledge at different granularities. To ensure the quality of extracted knowledge, we introduce a three-stage knowledge processing pipeline that combines vector-based filtering to remove exact duplicates, LLM-based adjudication to resolve ambiguous semantic overlaps, and domain-relevance auditing to retain valid knowledge units. Through extensive experiments, we find that recursive taxonomy is the most effective exploration strategy. We also observe a clear knowledge scaling law, where larger models consistently extract more knowledge. In addition, we identify a Pass@1-versus-Pass@k trade-off: domain-specialized models achieve higher initial accuracy but degrade rapidly, while general-purpose models maintain stable performance during extended extraction. Finally, our results show that differences in training data composition lead to distinct and measurable knowledge profiles across model families.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u63d0\u53d6\u548c\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u8fb9\u754c\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63a2\u7d22\u7b56\u7565\u548c\u77e5\u8bc6\u5904\u7406\u6d41\u7a0b\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u7684\u77e5\u8bc6\u6269\u5c55\u89c4\u5f8b\u548c\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u7684\u77e5\u8bc6\u7279\u5f81\u5dee\u5f02\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u88ab\u89c6\u4e3a\u538b\u7f29\u7684\u77e5\u8bc6\u5e93\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u662f\u9759\u6001\u7684\uff0c\u65e0\u6cd5\u7cfb\u7edf\u63a2\u6d4b\u6a21\u578b\u771f\u6b63\u5305\u542b\u7684\u77e5\u8bc6\u5185\u5bb9\u548c\u77e5\u8bc6\u8fb9\u754c\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u548c\u7406\u89e3LLM\u7684\u77e5\u8bc6\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u56db\u79cd\u81ea\u9002\u5e94\u63a2\u7d22\u7b56\u7565\u5728\u4e0d\u540c\u7c92\u5ea6\u4e0a\u63a2\u6d4b\u77e5\u8bc6\uff1b\u91c7\u7528\u4e09\u9636\u6bb5\u77e5\u8bc6\u5904\u7406\u6d41\u7a0b\uff1a\u5411\u91cf\u8fc7\u6ee4\u53bb\u9664\u91cd\u590d\u3001LLM\u88c1\u51b3\u89e3\u51b3\u8bed\u4e49\u91cd\u53e0\u3001\u9886\u57df\u76f8\u5173\u6027\u5ba1\u6838\u4fdd\u7559\u6709\u6548\u77e5\u8bc6\u5355\u5143\u3002", "result": "\u9012\u5f52\u5206\u7c7b\u6cd5\u662f\u6700\u6709\u6548\u7684\u63a2\u7d22\u7b56\u7565\uff1b\u89c2\u5bdf\u5230\u6e05\u6670\u7684\u77e5\u8bc6\u6269\u5c55\u89c4\u5f8b\uff0c\u6a21\u578b\u8d8a\u5927\u63d0\u53d6\u77e5\u8bc6\u8d8a\u591a\uff1b\u53d1\u73b0Pass@1\u4e0ePass@k\u7684\u6743\u8861\uff1a\u9886\u57df\u4e13\u7528\u6a21\u578b\u521d\u59cb\u51c6\u786e\u7387\u9ad8\u4f46\u5feb\u901f\u9000\u5316\uff0c\u901a\u7528\u6a21\u578b\u5728\u957f\u671f\u63d0\u53d6\u4e2d\u4fdd\u6301\u7a33\u5b9a\uff1b\u8bad\u7ec3\u6570\u636e\u7ec4\u6210\u5dee\u5f02\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u5177\u6709\u53ef\u6d4b\u91cf\u7684\u77e5\u8bc6\u7279\u5f81\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u7406\u89e3LLM\u77e5\u8bc6\u8fb9\u754c\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u89c4\u6a21\u3001\u4e13\u4e1a\u5316\u548c\u8bad\u7ec3\u6570\u636e\u5bf9\u77e5\u8bc6\u7ed3\u6784\u7684\u5f71\u54cd\uff0c\u4e3a\u6a21\u578b\u8bc4\u4f30\u548c\u77e5\u8bc6\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.00960", "categories": ["cs.LG", "cs.AI", "cs.CE", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00960", "abs": "https://arxiv.org/abs/2602.00960", "authors": ["Leonardo Ferreira Guilhoto", "Akshat Kaushal", "Paris Perdikaris"], "title": "Multimodal Scientific Learning Beyond Diffusions and Flows", "comment": null, "summary": "Scientific machine learning (SciML) increasingly requires models that capture multimodal conditional uncertainty arising from ill-posed inverse problems, multistability, and chaotic dynamics. While recent work has favored highly expressive implicit generative models such as diffusion and flow-based methods, these approaches are often data-hungry, computationally costly, and misaligned with the structured solution spaces frequently found in scientific problems. We demonstrate that Mixture Density Networks (MDNs) provide a principled yet largely overlooked alternative for multimodal uncertainty quantification in SciML. As explicit parametric density estimators, MDNs impose an inductive bias tailored to low-dimensional, multimodal physics, enabling direct global allocation of probability mass across distinct solution branches. This structure delivers strong data efficiency, allowing reliable recovery of separated modes in regimes where scientific data is scarce. We formalize these insights through a unified probabilistic framework contrasting explicit and implicit distribution networks, and demonstrate empirically that MDNs achieve superior generalization, interpretability, and sample efficiency across a range of inverse, multistable, and chaotic scientific regression tasks.", "AI": {"tldr": "MDNs\u4f5c\u4e3a\u663e\u5f0f\u53c2\u6570\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u4e3a\u591a\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u9690\u5f0f\u751f\u6210\u6a21\u578b\u3002", "motivation": "\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u9700\u8981\u5904\u7406\u591a\u6a21\u6001\u6761\u4ef6\u4e0d\u786e\u5b9a\u6027\uff08\u5982\u4e0d\u9002\u5b9a\u9006\u95ee\u9898\u3001\u591a\u7a33\u6001\u548c\u6df7\u6c8c\u52a8\u529b\u5b66\uff09\uff0c\u4f46\u5f53\u524d\u6d41\u884c\u7684\u9690\u5f0f\u751f\u6210\u6a21\u578b\uff08\u6269\u6563\u6a21\u578b\u3001\u6d41\u6a21\u578b\uff09\u5b58\u5728\u6570\u636e\u9700\u6c42\u5927\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u4e0e\u79d1\u5b66\u95ee\u9898\u7ed3\u6784\u5316\u89e3\u7a7a\u95f4\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u6df7\u5408\u5bc6\u5ea6\u7f51\u7edc\uff08MDNs\uff09\u4f5c\u4e3a\u663e\u5f0f\u53c2\u6570\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u76f4\u63a5\u5168\u5c40\u5206\u914d\u6982\u7387\u8d28\u91cf\u5230\u4e0d\u540c\u89e3\u5206\u652f\uff0c\u4e3a\u4f4e\u7ef4\u591a\u6a21\u6001\u7269\u7406\u95ee\u9898\u63d0\u4f9b\u7ed3\u6784\u5316\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "result": "MDNs\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u4ecd\u80fd\u53ef\u9760\u6062\u590d\u5206\u79bb\u7684\u6a21\u5f0f\uff0c\u5728\u591a\u79cd\u9006\u95ee\u9898\u3001\u591a\u7a33\u6001\u548c\u6df7\u6c8c\u79d1\u5b66\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6837\u672c\u6548\u7387\u3002", "conclusion": "MDNs\u4e3a\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u591a\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u88ab\u5ffd\u89c6\u4f46\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u6570\u636e\u7a00\u7f3a\u3001\u9700\u8981\u7ed3\u6784\u5316\u89e3\u7a7a\u95f4\u7684\u79d1\u5b66\u95ee\u9898\u3002"}}
{"id": "2602.00969", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00969", "abs": "https://arxiv.org/abs/2602.00969", "authors": ["Junlin Huang", "Wenyi Fang", "Zhenheng Tang", "Yuxin Wang", "Xueze Kang", "Yang Zheng", "Bo Li", "Xiaowen Chu"], "title": "On the Spectral Flattening of Quantized Embeddings", "comment": null, "summary": "Training Large Language Models (LLMs) at ultra-low precision is critically impeded by instability rooted in the conflict between discrete quantization constraints and the intrinsic heavy-tailed spectral nature of linguistic data. By formalizing the connection between Zipfian statistics and random matrix theory, we prove that the power-law decay in the singular value spectra of embeddings is a fundamental requisite for semantic encoding. We derive theoretical bounds showing that uniform quantization introduces a noise floor that disproportionately truncates this spectral tail, which induces spectral flattening and a strictly provable increase in the stable rank of representations. Empirical validation across diverse architectures including GPT-2 and TinyLlama corroborates that this geometric degradation precipitates representational collapse. This work not only quantifies the spectral sensitivity of LLMs but also establishes spectral fidelity as a necessary condition for stable low-bit optimization.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d85\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u6e90\u4e8e\u91cf\u5316\u566a\u58f0\u5bf9\u8bcd\u5d4c\u5165\u8c31\u5206\u5e03\u7684\u7834\u574f\uff0c\u7279\u522b\u662f\u622a\u65adZipf\u5206\u5e03\u7684\u5c3e\u90e8\uff0c\u5bfc\u81f4\u8868\u793a\u5d29\u6e83\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d85\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u4e2d\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u8fd9\u6e90\u4e8e\u79bb\u6563\u91cf\u5316\u7ea6\u675f\u4e0e\u8bed\u8a00\u6570\u636e\u56fa\u6709\u7684\u91cd\u5c3e\u8c31\u7279\u6027\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u9700\u8981\u7406\u89e3\u8fd9\u79cd\u4e0d\u7a33\u5b9a\u6027\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u5316Zipf\u7edf\u8ba1\u4e0e\u968f\u673a\u77e9\u9635\u7406\u8bba\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8bc1\u660e\u8bcd\u5d4c\u5165\u5947\u5f02\u503c\u8c31\u7684\u5e42\u5f8b\u8870\u51cf\u662f\u8bed\u4e49\u7f16\u7801\u7684\u57fa\u672c\u8981\u6c42\u3002\u63a8\u5bfc\u7406\u8bba\u754c\u9650\uff0c\u663e\u793a\u5747\u5300\u91cf\u5316\u5f15\u5165\u7684\u566a\u58f0\u4f1a\u4e0d\u6210\u6bd4\u4f8b\u5730\u622a\u65ad\u8c31\u5c3e\u90e8\uff0c\u5bfc\u81f4\u8c31\u5e73\u5766\u5316\u548c\u7a33\u5b9a\u79e9\u589e\u52a0\u3002", "result": "\u5728GPT-2\u548cTinyLlama\u7b49\u591a\u79cd\u67b6\u6784\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0c\u8fd9\u79cd\u51e0\u4f55\u9000\u5316\u4f1a\u5bfc\u81f4\u8868\u793a\u5d29\u6e83\u3002\u91cf\u5316\u4e86LLMs\u7684\u8c31\u654f\u611f\u6027\uff0c\u5e76\u5efa\u7acb\u8c31\u4fdd\u771f\u5ea6\u4f5c\u4e3a\u7a33\u5b9a\u4f4e\u6bd4\u7279\u4f18\u5316\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e0d\u4ec5\u91cf\u5316\u4e86LLMs\u7684\u8c31\u654f\u611f\u6027\uff0c\u8fd8\u786e\u7acb\u4e86\u8c31\u4fdd\u771f\u5ea6\u4f5c\u4e3a\u7a33\u5b9a\u4f4e\u6bd4\u7279\u4f18\u5316\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8d85\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.00974", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00974", "abs": "https://arxiv.org/abs/2602.00974", "authors": ["Adrien Aumon", "Myriam Lizotte", "Guy Wolf", "Kevin R. Moon", "Jake S. Rhodes"], "title": "Forest-Guided Semantic Transport for Label-Supervised Manifold Alignment", "comment": null, "summary": "Label-supervised manifold alignment bridges the gap between unsupervised and correspondence-based paradigms by leveraging shared label information to align multimodal datasets. Still, most existing methods rely on Euclidean geometry to model intra-domain relationships. This approach can fail when features are only weakly related to the task of interest, leading to noisy, semantically misleading structure and degraded alignment quality. To address this limitation, we introduce FoSTA (Forest-guided Semantic Transport Alignment), a scalable alignment framework that leverages forest-induced geometry to denoise intra-domain structure and recover task-relevant manifolds prior to alignment. FoSTA builds semantic representations directly from label-informed forest affinities and aligns them via fast, hierarchical semantic transport, capturing meaningful cross-domain relationships. Extensive comparisons with established baselines demonstrate that FoSTA improves correspondence recovery and label transfer on synthetic benchmarks and delivers strong performance in practical single-cell applications, including batch correction and biological conservation.", "AI": {"tldr": "FoSTA\u4f7f\u7528\u68ee\u6797\u5f15\u5bfc\u7684\u51e0\u4f55\u7ed3\u6784\u6765\u53bb\u566a\u8de8\u6a21\u6001\u6570\u636e\u96c6\u5bf9\u9f50\u4e2d\u7684\u4efb\u52a1\u76f8\u5173\u6d41\u5f62\uff0c\u901a\u8fc7\u8bed\u4e49\u4f20\u8f93\u5b9e\u73b0\u66f4\u597d\u7684\u5bf9\u5e94\u6062\u590d\u548c\u6807\u7b7e\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u6807\u7b7e\u76d1\u7763\u6d41\u5f62\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u5efa\u6a21\u57df\u5185\u5173\u7cfb\uff0c\u5f53\u7279\u5f81\u4e0e\u76ee\u6807\u4efb\u52a1\u5f31\u76f8\u5173\u65f6\u4f1a\u4ea7\u751f\u566a\u58f0\u548c\u8bed\u4e49\u8bef\u5bfc\u7ed3\u6784\uff0c\u5bfc\u81f4\u5bf9\u9f50\u8d28\u91cf\u4e0b\u964d\u3002", "method": "FoSTA\u6846\u67b6\u5229\u7528\u68ee\u6797\u8bf1\u5bfc\u7684\u51e0\u4f55\u7ed3\u6784\u53bb\u566a\u57df\u5185\u7ed3\u6784\uff0c\u5728\u5bf9\u9f50\u524d\u6062\u590d\u4efb\u52a1\u76f8\u5173\u6d41\u5f62\u3002\u76f4\u63a5\u4ece\u6807\u7b7e\u4fe1\u606f\u7684\u68ee\u6797\u4eb2\u548c\u5ea6\u6784\u5efa\u8bed\u4e49\u8868\u793a\uff0c\u901a\u8fc7\u5feb\u901f\u5206\u5c42\u8bed\u4e49\u4f20\u8f93\u8fdb\u884c\u5bf9\u9f50\u3002", "result": "\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6539\u8fdb\u4e86\u5bf9\u5e94\u6062\u590d\u548c\u6807\u7b7e\u8fc1\u79fb\uff0c\u5728\u5355\u7ec6\u80de\u5e94\u7528\uff08\u5305\u62ec\u6279\u6b21\u6821\u6b63\u548c\u751f\u7269\u5b66\u4fdd\u5b88\u6027\uff09\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\u3002", "conclusion": "FoSTA\u901a\u8fc7\u68ee\u6797\u5f15\u5bfc\u7684\u8bed\u4e49\u4f20\u8f93\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8de8\u6a21\u6001\u6570\u636e\u96c6\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00987", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00987", "abs": "https://arxiv.org/abs/2602.00987", "authors": ["Sawan Kumar", "Souvik Chakraborty"], "title": "Scalable Random Wavelet Features: Efficient Non-Stationary Kernel Approximation with Convergence Guarantees", "comment": "Accepted at ICLR 2026", "summary": "Modeling non-stationary processes, where statistical properties vary across the input domain, is a critical challenge in machine learning; yet most scalable methods rely on a simplifying assumption of stationarity. This forces a difficult trade-off: use expressive but computationally demanding models like Deep Gaussian Processes, or scalable but limited methods like Random Fourier Features (RFF). We close this gap by introducing Random Wavelet Features (RWF), a framework that constructs scalable, non-stationary kernel approximations by sampling from wavelet families. By harnessing the inherent localization and multi-resolution structure of wavelets, RWF generates an explicit feature map that captures complex, input-dependent patterns. Our framework provides a principled way to generalize RFF to the non-stationary setting and comes with a comprehensive theoretical analysis, including positive definiteness, unbiasedness, and uniform convergence guarantees. We demonstrate empirically on a range of challenging synthetic and real-world datasets that RWF outperforms stationary random features and offers a compelling accuracy-efficiency trade-off against more complex models, unlocking scalable and expressive kernel methods for a broad class of real-world non-stationary problems.", "AI": {"tldr": "\u63d0\u51faRandom Wavelet Features (RWF)\u6846\u67b6\uff0c\u901a\u8fc7\u5c0f\u6ce2\u91c7\u6837\u6784\u5efa\u53ef\u6269\u5c55\u7684\u975e\u5e73\u7a33\u6838\u8fd1\u4f3c\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u8868\u8fbe\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u975e\u5e73\u7a33\u8fc7\u7a0b\uff08\u7edf\u8ba1\u7279\u6027\u968f\u8f93\u5165\u57df\u53d8\u5316\uff09\u5efa\u6a21\u662f\u673a\u5668\u5b66\u4e60\u7684\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u53ef\u6269\u5c55\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u5e73\u7a33\u6027\u5047\u8bbe\uff0c\u5bfc\u81f4\u8868\u8fbe\u6027\u5f3a\u7684\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff08\u5982\u6df1\u5ea6\u9ad8\u65af\u8fc7\u7a0b\uff09\uff0c\u800c\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff08\u5982\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff09\u3002", "method": "\u5f15\u5165Random Wavelet Features (RWF)\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u5c0f\u6ce2\u65cf\u4e2d\u91c7\u6837\u6784\u5efa\u53ef\u6269\u5c55\u7684\u975e\u5e73\u7a33\u6838\u8fd1\u4f3c\u3002\u5229\u7528\u5c0f\u6ce2\u56fa\u6709\u7684\u5c40\u90e8\u5316\u548c\u591a\u5206\u8fa8\u7387\u7ed3\u6784\uff0c\u751f\u6210\u80fd\u591f\u6355\u6349\u590d\u6742\u3001\u8f93\u5165\u4f9d\u8d56\u6a21\u5f0f\u7684\u663e\u5f0f\u7279\u5f81\u6620\u5c04\u3002", "result": "RWF\u5728\u7406\u8bba\u5206\u6790\u4e0a\u63d0\u4f9b\u4e86\u6b63\u5b9a\u6027\u3001\u65e0\u504f\u6027\u548c\u4e00\u81f4\u6536\u655b\u4fdd\u8bc1\u3002\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRWF\u4f18\u4e8e\u5e73\u7a33\u968f\u673a\u7279\u5f81\u65b9\u6cd5\uff0c\u5e76\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6743\u8861\uff0c\u6027\u80fd\u53ef\u4e0e\u66f4\u590d\u6742\u6a21\u578b\u5ab2\u7f8e\u3002", "conclusion": "RWF\u6846\u67b6\u4e3a\u5e7f\u6cdb\u7684\u73b0\u5b9e\u4e16\u754c\u975e\u5e73\u7a33\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u8868\u8fbe\u6027\u5f3a\u7684\u6838\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u8868\u8fbe\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u5904\u7406\u975e\u5e73\u7a33\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01003", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01003", "abs": "https://arxiv.org/abs/2602.01003", "authors": ["Zhishen Sun", "Sizhe Dang", "Guang Dai", "Haishan Ye"], "title": "ESSAM: A Novel Competitive Evolution Strategies Approach to Reinforcement Learning for Memory Efficient LLMs Fine-Tuning", "comment": null, "summary": "Reinforcement learning (RL) has become a key training step for improving mathematical reasoning in large language models (LLMs), but it often has high GPU memory usage, which makes it hard to use in settings with limited resources. To reduce these issues, we propose Evolution Strategies with Sharpness-Aware Maximization (ESSAM), a full parameter fine-tuning framework that tightly combines the zero-order search in parameter space from Evolution Strategies (ES) with the Sharpness-Aware Maximization (SAM) to improve generalization. We conduct fine-tuning experiments on the mainstream mathematica reasoning task GSM8K. The results show that ESSAM achieves an average accuracy of 78.27\\% across all models and its overall performance is comparable to RL methods. It surpasses classic RL algorithm PPO with an accuracy of 77.72\\% and is comparable to GRPO with an accuracy of 78.34\\%, and even surpassing them on some models. In terms of GPU memory usage, ESSAM reduces the average GPU memory usage by $18\\times$ compared to PPO and by $10\\times$ compared to GRPO, achieving an extremely low GPU memory usage.", "AI": {"tldr": "ESSAM\u7ed3\u5408\u8fdb\u5316\u7b56\u7565\u548c\u9510\u5ea6\u611f\u77e5\u6700\u5927\u5316\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e0e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4eGPU\u5185\u5b58\u4f7f\u7528\uff08\u76f8\u6bd4PPO\u51cf\u5c1118\u500d\uff0c\u76f8\u6bd4GRPO\u51cf\u5c1110\u500d\uff09\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u65f6\u5b58\u5728GPU\u5185\u5b58\u4f7f\u7528\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faESSAM\u6846\u67b6\uff0c\u5c06\u8fdb\u5316\u7b56\u7565\uff08ES\uff09\u7684\u53c2\u6570\u7a7a\u95f4\u96f6\u9636\u641c\u7d22\u4e0e\u9510\u5ea6\u611f\u77e5\u6700\u5927\u5316\uff08SAM\uff09\u7d27\u5bc6\u7ed3\u5408\uff0c\u8fdb\u884c\u5168\u53c2\u6570\u5fae\u8c03\u4ee5\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728GSM8K\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cESSAM\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523078.27%\uff0c\u6027\u80fd\u4e0eRL\u65b9\u6cd5\u76f8\u5f53\uff0c\u8d85\u8d8aPPO\uff0877.72%\uff09\uff0c\u4e0eGRPO\uff0878.34%\uff09\u76f8\u5f53\uff0c\u5728\u67d0\u4e9b\u6a21\u578b\u4e0a\u751a\u81f3\u8d85\u8d8a\u3002GPU\u5185\u5b58\u4f7f\u7528\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "ESSAM\u5728\u4fdd\u6301\u4e0e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86GPU\u5185\u5b58\u9700\u6c42\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01005", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01005", "abs": "https://arxiv.org/abs/2602.01005", "authors": ["Deepak Bastola", "Pitambar Acharya", "Dipak Dulal", "Rabina Dhakal", "Yang Li"], "title": "Predicting Anemia Among Under-Five Children in Nepal Using Machine Learning and Deep Learning", "comment": "13 pages and submission to Public Health Nutrition is in progress", "summary": "Childhood anemia remains a major public health challenge in Nepal and is associated with impaired growth, cognition, and increased morbidity. Using World Health Organization hemoglobin thresholds, we defined anemia status for children aged 6-59 months and formulated a binary classification task by grouping all anemia severities as \\emph{anemic} versus \\emph{not anemic}. We analyzed Nepal Demographic and Health Survey (NDHS 2022) microdata comprising 1,855 children and initially considered 48 candidate features spanning demographic, socioeconomic, maternal, and child health characteristics. To obtain a stable and substantiated feature set, we applied four features selection techniques (Chi-square, mutual information, point-biserial correlation, and Boruta) and prioritized features supported by multi-method consensus. Five features: child age, recent fever, household size, maternal anemia, and parasite deworming were consistently selected by all methods, while amenorrhea, ethnicity indicators, and provinces were frequently retained. We then compared eight traditional machine learning classifiers (LR, KNN, DT, RF, XGBoost, SVM, NB, LDA) with two deep learning models (DNN and TabNet) using standard evaluation metrics, emphasizing F1-score and recall due to class imbalance. Among all models, logistic regression attained the best recall (0.701) and the highest F1-score (0.649), while DNN achieved the highest accuracy (0.709), and SVM yielded the strongest discrimination with the highest AUC (0.736). Overall, the results indicate that both machine learning and deep learning models can provide competitive anemia prediction and the interpretable features such as child age, infection proxy, maternal anemia, and deworming history are central for risk stratification and public health screening in Nepal.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4b\u5c3c\u6cca\u5c14\u513f\u7ae5\u8d2b\u8840\u72b6\u51b5\uff0c\u901a\u8fc7\u591a\u79cd\u7279\u5f81\u9009\u62e9\u6280\u672f\u8bc6\u522b\u5173\u952e\u98ce\u9669\u56e0\u7d20\uff0c\u5e76\u6bd4\u8f83\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u513f\u7ae5\u8d2b\u8840\u5728\u5c3c\u6cca\u5c14\u4ecd\u662f\u91cd\u5927\u516c\u5171\u536b\u751f\u6311\u6218\uff0c\u4e0e\u751f\u957f\u53d1\u80b2\u53d7\u635f\u3001\u8ba4\u77e5\u969c\u788d\u548c\u53d1\u75c5\u7387\u589e\u52a0\u76f8\u5173\u3002\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u9884\u6d4b\u6a21\u578b\u6765\u8bc6\u522b\u9ad8\u98ce\u9669\u513f\u7ae5\uff0c\u4e3a\u516c\u5171\u536b\u751f\u5e72\u9884\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u5c3c\u6cca\u5c14\u4eba\u53e3\u4e0e\u5065\u5eb7\u8c03\u67e5(NDHS 2022)\u76841,855\u540d6-59\u4e2a\u6708\u513f\u7ae5\u6570\u636e\uff0c\u5c06\u8d2b\u8840\u5b9a\u4e49\u4e3a\u4e8c\u5206\u7c7b\u4efb\u52a1\u3002\u91c7\u7528\u56db\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5(\u5361\u65b9\u68c0\u9a8c\u3001\u4e92\u4fe1\u606f\u3001\u70b9\u4e8c\u5217\u76f8\u5173\u3001Boruta)\u786e\u5b9a\u5173\u952e\u7279\u5f81\uff0c\u7136\u540e\u6bd4\u8f83\u516b\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b(LR\u3001KNN\u3001DT\u3001RF\u3001XGBoost\u3001SVM\u3001NB\u3001LDA)\u548c\u4e24\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b(DNN\u3001TabNet)\u7684\u6027\u80fd\u3002", "result": "\u903b\u8f91\u56de\u5f52\u83b7\u5f97\u6700\u4f73\u53ec\u56de\u7387(0.701)\u548c\u6700\u9ad8F1\u5206\u6570(0.649)\uff0cDNN\u8fbe\u5230\u6700\u9ad8\u51c6\u786e\u7387(0.709)\uff0cSVM\u5177\u6709\u6700\u5f3a\u7684\u533a\u5206\u80fd\u529b\uff0cAUC\u6700\u9ad8(0.736)\u3002\u6240\u6709\u65b9\u6cd5\u4e00\u81f4\u9009\u62e9\u7684\u4e94\u4e2a\u5173\u952e\u7279\u5f81\u4e3a\uff1a\u513f\u7ae5\u5e74\u9f84\u3001\u8fd1\u671f\u53d1\u70ed\u3001\u5bb6\u5ead\u89c4\u6a21\u3001\u6bcd\u4eb2\u8d2b\u8840\u72b6\u51b5\u548c\u5bc4\u751f\u866b\u9a71\u866b\u60c5\u51b5\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u90fd\u80fd\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u8d2b\u8840\u9884\u6d4b\uff0c\u513f\u7ae5\u5e74\u9f84\u3001\u611f\u67d3\u6307\u6807\u3001\u6bcd\u4eb2\u8d2b\u8840\u72b6\u51b5\u548c\u9a71\u866b\u5386\u53f2\u7b49\u53ef\u89e3\u91ca\u7279\u5f81\u5bf9\u4e8e\u5c3c\u6cca\u5c14\u7684\u98ce\u9669\u5206\u5c42\u548c\u516c\u5171\u536b\u751f\u7b5b\u67e5\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.01009", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01009", "abs": "https://arxiv.org/abs/2602.01009", "authors": ["Haoran Li", "Chenhan Xiao", "Lihao Mai", "Yang Weng", "Erik Blasch"], "title": "LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems", "comment": null, "summary": "Foundation models have transformed language, vision, and time series data analysis, yet progress on dynamic predictions for physical systems remains limited. Given the complexity of physical constraints, two challenges stand out. $(i)$ Physics-computation scalability: physics-informed learning can enforce physical regularization, but its computation (e.g., ODE integration) does not scale to extensive systems. $(ii)$ Knowledge-sharing efficiency: the attention mechanism is primarily computed within each system, which limits the extraction of shared ODE structures across systems. We show that enforcing ODE consistency does not require expensive nonlinear integration: a token-wise locally linear ODE representation preserves physical fidelity while scaling to foundation-model regimes. Thus, we propose novel token representations that respect locally linear ODE evolution. Such linearity substantially accelerates integration while accurately approximating the local data manifold. Second, we introduce a simple yet effective inter-system attention that augments attention with a common structure hub (CSH) that stores shared tokens and aggregates knowledge across systems. The resulting model, termed LASS-ODE (\\underline{LA}rge-\\underline{S}cale \\underline{S}mall \\underline{ODE}), is pretrained on our $40$GB ODE trajectory collections to enable strong in-domain performance, zero-shot generalization across diverse ODE systems, and additional improvements through fine-tuning.", "AI": {"tldr": "LASS-ODE\uff1a\u4e00\u79cd\u7528\u4e8e\u5927\u89c4\u6a21ODE\u7cfb\u7edf\u52a8\u6001\u9884\u6d4b\u7684\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5c40\u90e8\u7ebf\u6027ODE\u8868\u793a\u548c\u8de8\u7cfb\u7edf\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u7269\u7406\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u548c\u77e5\u8bc6\u5171\u4eab\u6548\u7387\u95ee\u9898", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5728\u7269\u7406\u7cfb\u7edf\u52a8\u6001\u9884\u6d4b\u65b9\u9762\u8fdb\u5c55\u6709\u9650\u3002\u4e3b\u8981\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a1\uff09\u7269\u7406\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\uff1a\u7269\u7406\u7ea6\u675f\u5b66\u4e60\u4e2d\u7684\u8ba1\u7b97\uff08\u5982ODE\u79ef\u5206\uff09\u65e0\u6cd5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u7cfb\u7edf\uff1b2\uff09\u77e5\u8bc6\u5171\u4eab\u6548\u7387\uff1a\u6ce8\u610f\u529b\u673a\u5236\u4e3b\u8981\u5728\u5355\u4e2a\u7cfb\u7edf\u5185\u8ba1\u7b97\uff0c\u9650\u5236\u4e86\u8de8\u7cfb\u7edf\u5171\u4eabODE\u7ed3\u6784\u7684\u63d0\u53d6\u3002", "method": "1\uff09\u63d0\u51fa\u5c40\u90e8\u7ebf\u6027ODE\u8868\u793a\uff1a\u901a\u8fc7token-wise\u7684\u5c40\u90e8\u7ebf\u6027ODE\u8868\u793a\u6765\u4fdd\u6301\u7269\u7406\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u5b9e\u73b0\u57fa\u7840\u6a21\u578b\u89c4\u6a21\u7684\u53ef\u6269\u5c55\u6027\uff1b2\uff09\u5f15\u5165\u8de8\u7cfb\u7edf\u6ce8\u610f\u529b\u673a\u5236\uff1a\u901a\u8fc7\u516c\u5171\u7ed3\u6784\u4e2d\u5fc3\uff08CSH\uff09\u5b58\u50a8\u5171\u4eabtoken\u5e76\u805a\u5408\u8de8\u7cfb\u7edf\u77e5\u8bc6\uff1b3\uff09\u572840GB ODE\u8f68\u8ff9\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "LASS-ODE\u5728\u9884\u8bad\u7ec3\u540e\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9886\u57df\u5185\u6027\u80fd\uff0c\u80fd\u591f\u96f6\u6837\u672c\u6cdb\u5316\u5230\u591a\u6837\u5316\u7684ODE\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u83b7\u5f97\u989d\u5916\u6539\u8fdb\u3002\u6a21\u578b\u663e\u8457\u52a0\u901f\u4e86\u79ef\u5206\u8ba1\u7b97\uff0c\u540c\u65f6\u51c6\u786e\u8fd1\u4f3c\u4e86\u5c40\u90e8\u6570\u636e\u6d41\u5f62\u3002", "conclusion": "\u901a\u8fc7\u5c40\u90e8\u7ebf\u6027ODE\u8868\u793a\u548c\u8de8\u7cfb\u7edf\u6ce8\u610f\u529b\u673a\u5236\uff0cLASS-ODE\u6210\u529f\u89e3\u51b3\u4e86\u7269\u7406\u7cfb\u7edf\u52a8\u6001\u9884\u6d4b\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u77e5\u8bc6\u5171\u4eab\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21ODE\u7cfb\u7edf\u7684\u57fa\u7840\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.01017", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01017", "abs": "https://arxiv.org/abs/2602.01017", "authors": ["Fuxin Wang", "Amr Alazali", "Yiqiao Zhong"], "title": "How Does Unfaithful Reasoning Emerge from Autoregressive Training? A Study of Synthetic Experiments", "comment": "25 pages, 23 figures", "summary": "Chain-of-thought (CoT) reasoning generated by large language models (LLMs) is often unfaithful: intermediate steps can be logically inconsistent or fail to reflect the causal relationship leading to the final answer. Despite extensive empirical observations, a fundamental understanding of CoT is lacking--what constitutes faithful CoT reasoning, and how unfaithfulness emerges from autoregressive training. We study these questions using well-controlled synthetic experiments, training small transformers on noisy data to solve modular arithmetic expressions step by step, a task we term Arithmetic Expression Reasoning. We find that models can learn faithful reasoning that causally follows the underlying arithmetic rules, but only when the training noise is below a critical threshold, a phenomenon attributable to simplicity bias. At higher noise levels, training dynamics exhibit a transition from faithful stepwise reasoning to unfaithful skip-step reasoning via an intermediate mixed mode characterized by a transient increase in prediction entropy. Mechanistic analysis reveals that models learn to encode internal uncertainty by resolving inconsistent reasoning steps, which suggests the emergence of implicit self-verification from autoregressive training.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u7814\u7a76CoT\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u8bad\u7ec3\u566a\u58f0\u4f4e\u4e8e\u4e34\u754c\u9608\u503c\u65f6\u6a21\u578b\u80fd\u5b66\u4e60\u5fe0\u5b9e\u63a8\u7406\uff0c\u9ad8\u4e8e\u9608\u503c\u65f6\u5219\u8f6c\u5411\u4e0d\u5fe0\u5b9e\u7684\u8df3\u8dc3\u63a8\u7406\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u901a\u8fc7\u89e3\u51b3\u4e0d\u4e00\u81f4\u63a8\u7406\u6b65\u9aa4\u6765\u7f16\u7801\u5185\u90e8\u4e0d\u786e\u5b9a\u6027\u7684\u673a\u5236\u3002", "motivation": "\u5c3d\u7ba1\u89c2\u5bdf\u5230CoT\u63a8\u7406\u5e38\u6709\u4e0d\u5fe0\u5b9e\u73b0\u8c61\uff08\u4e2d\u95f4\u6b65\u9aa4\u903b\u8f91\u4e0d\u4e00\u81f4\u6216\u672a\u80fd\u53cd\u6620\u56e0\u679c\u8054\u7cfb\uff09\uff0c\u4f46\u5bf9CoT\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u672c\u8d28\u4ee5\u53ca\u4e0d\u5fe0\u5b9e\u6027\u5982\u4f55\u4ece\u81ea\u56de\u5f52\u8bad\u7ec3\u4e2d\u4ea7\u751f\u7f3a\u4e4f\u6839\u672c\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u53d7\u63a7\u5408\u6210\u5b9e\u9a8c\uff0c\u8bad\u7ec3\u5c0f\u578btransformer\u5728\u566a\u58f0\u6570\u636e\u4e0a\u9010\u6b65\u89e3\u51b3\u6a21\u7b97\u672f\u8868\u8fbe\u5f0f\uff08\u79f0\u4e3a\u7b97\u672f\u8868\u8fbe\u5f0f\u63a8\u7406\u4efb\u52a1\uff09\uff0c\u5206\u6790\u8bad\u7ec3\u52a8\u6001\u548c\u673a\u5236\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u4ec5\u5728\u8bad\u7ec3\u566a\u58f0\u4f4e\u4e8e\u4e34\u754c\u9608\u503c\u65f6\u80fd\u5b66\u4e60\u5fe0\u5b9e\u63a8\u7406\uff08\u9075\u5faa\u7b97\u672f\u89c4\u5219\uff09\uff1b\u566a\u58f0\u8f83\u9ad8\u65f6\uff0c\u8bad\u7ec3\u52a8\u6001\u4ece\u5fe0\u5b9e\u9010\u6b65\u63a8\u7406\u8f6c\u5411\u4e0d\u5fe0\u5b9e\u8df3\u8dc3\u63a8\u7406\uff0c\u4e2d\u95f4\u51fa\u73b0\u9884\u6d4b\u71b5\u589e\u52a0\u7684\u6df7\u5408\u6a21\u5f0f\uff1b\u673a\u5236\u5206\u6790\u663e\u793a\u6a21\u578b\u901a\u8fc7\u89e3\u51b3\u4e0d\u4e00\u81f4\u63a8\u7406\u6b65\u9aa4\u6765\u7f16\u7801\u5185\u90e8\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "CoT\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u53d7\u8bad\u7ec3\u566a\u58f0\u9608\u503c\u5f71\u54cd\uff0c\u6a21\u578b\u80fd\u4ece\u81ea\u56de\u5f52\u8bad\u7ec3\u4e2d\u9690\u5f0f\u5b66\u4e60\u81ea\u6211\u9a8c\u8bc1\u673a\u5236\uff0c\u901a\u8fc7\u7f16\u7801\u5185\u90e8\u4e0d\u786e\u5b9a\u6027\u6765\u89e3\u6790\u4e0d\u4e00\u81f4\u63a8\u7406\u6b65\u9aa4\u3002"}}
{"id": "2602.01025", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01025", "abs": "https://arxiv.org/abs/2602.01025", "authors": ["Kaiyuan Cui", "Yige Li", "Yutao Wu", "Xingjun Ma", "Sarah Erfani", "Christopher Leckie", "Hanxun Huang"], "title": "Toward Universal and Transferable Jailbreak Attacks on Vision-Language Models", "comment": "ICLR 2026", "summary": "Vision-language models (VLMs) extend large language models (LLMs) with vision encoders, enabling text generation conditioned on both images and text. However, this multimodal integration expands the attack surface by exposing the model to image-based jailbreaks crafted to induce harmful responses. Existing gradient-based jailbreak methods transfer poorly, as adversarial patterns overfit to a single white-box surrogate and fail to generalise to black-box models. In this work, we propose Universal and transferable jailbreak (UltraBreak), a framework that constrains adversarial patterns through transformations and regularisation in the vision space, while relaxing textual targets through semantic-based objectives. By defining its loss in the textual embedding space of the target LLM, UltraBreak discovers universal adversarial patterns that generalise across diverse jailbreak objectives. This combination of vision-level regularisation and semantically guided textual supervision mitigates surrogate overfitting and enables strong transferability across both models and attack targets. Extensive experiments show that UltraBreak consistently outperforms prior jailbreak methods. Further analysis reveals why earlier approaches fail to transfer, highlighting that smoothing the loss landscape via semantic objectives is crucial for enabling universal and transferable jailbreaks. The code is publicly available in our \\href{https://github.com/kaiyuanCui/UltraBreak}{GitHub repository}.", "AI": {"tldr": "\u63d0\u51faUltraBreak\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u7a7a\u95f4\u53d8\u6362\u6b63\u5219\u5316\u548c\u8bed\u4e49\u5f15\u5bfc\u7684\u6587\u672c\u76ee\u6807\uff0c\u751f\u6210\u53ef\u8de8\u6a21\u578b\u548c\u653b\u51fb\u76ee\u6807\u8f6c\u79fb\u7684\u901a\u7528\u5bf9\u6297\u6a21\u5f0f\uff0c\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u8d8a\u72f1\u65b9\u6cd5\u8fc7\u62df\u5408\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\uff0c\u4f46\u4e5f\u6269\u5927\u4e86\u653b\u51fb\u9762\uff0c\u4f7f\u6a21\u578b\u9762\u4e34\u56fe\u50cf\u8d8a\u72f1\u653b\u51fb\u3002\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u8d8a\u72f1\u65b9\u6cd5\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u751f\u6210\u7684\u5bf9\u6297\u6a21\u5f0f\u5728\u5355\u4e00\u767d\u76d2\u4ee3\u7406\u6a21\u578b\u4e0a\u6709\u6548\uff0c\u4f46\u65e0\u6cd5\u6cdb\u5316\u5230\u9ed1\u76d2\u6a21\u578b\u3002", "method": "\u63d0\u51faUltraBreak\u6846\u67b6\uff1a1\uff09\u5728\u89c6\u89c9\u7a7a\u95f4\u901a\u8fc7\u53d8\u6362\u548c\u6b63\u5219\u5316\u7ea6\u675f\u5bf9\u6297\u6a21\u5f0f\uff1b2\uff09\u901a\u8fc7\u8bed\u4e49\u76ee\u6807\u653e\u677e\u6587\u672c\u76ee\u6807\uff1b3\uff09\u5728\u76ee\u6807LLM\u7684\u6587\u672c\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u53d1\u73b0\u901a\u7528\u5bf9\u6297\u6a21\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eUltraBreak\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u63ed\u793a\u4e86\u65e9\u671f\u65b9\u6cd5\u65e0\u6cd5\u8f6c\u79fb\u7684\u539f\u56e0\uff0c\u5f3a\u8c03\u901a\u8fc7\u8bed\u4e49\u76ee\u6807\u5e73\u6ed1\u635f\u5931\u666f\u89c2\u5bf9\u4e8e\u5b9e\u73b0\u901a\u7528\u53ef\u8f6c\u79fb\u8d8a\u72f1\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "UltraBreak\u901a\u8fc7\u89c6\u89c9\u7ea7\u6b63\u5219\u5316\u548c\u8bed\u4e49\u5f15\u5bfc\u7684\u6587\u672c\u76d1\u7763\u76f8\u7ed3\u5408\uff0c\u51cf\u8f7b\u4e86\u4ee3\u7406\u6a21\u578b\u8fc7\u62df\u5408\uff0c\u5b9e\u73b0\u4e86\u8de8\u6a21\u578b\u548c\u653b\u51fb\u76ee\u6807\u7684\u5f3a\u53ef\u8f6c\u79fb\u6027\uff0c\u4e3a\u7406\u89e3\u5bf9\u6297\u653b\u51fb\u7684\u6cdb\u5316\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2602.01027", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01027", "abs": "https://arxiv.org/abs/2602.01027", "authors": ["Xin Nie", "Haicheng Zhang", "Liang Dong", "Beining Feng", "Jinhong Weng", "Guiling Sun"], "title": "SFMP: Fine-Grained, Hardware-Friendly and Search-Free Mixed-Precision Quantization for Large Language Models", "comment": "24pages,17figures", "summary": "Mixed-precision quantization is a promising approach for compressing large language models under tight memory budgets. However, existing mixed-precision methods typically suffer from one of two limitations: they either rely on expensive discrete optimization to determine precision allocation, or introduce hardware inefficiencies due to irregular memory layouts. We propose SFMP, a search-free and hardware-friendly mixed-precision quantization framework for large language models. The framework is built upon four novel ideas: Fractional bit-width, which extends integer bit-width for weight matrix to fractional value and transforms discrete precision allocation as a continuous problem; 2)Block-wise mixed-precision, enabling fine-grained precision within weight matrices while remaining hardware-friendly; 3)Row-column weight reordering, which aggregates salient weights via row and column reordering, incurring only a small activation reordering overhead during inference; 4)Unified GEMM kernel, which supports mixed-precision GEMM at arbitrary average bit-width. Extensive experiments demonstrate that SFMP outperforms state-of-the-art layer-wise mixed-precision methods under the same memory constraints, while significantly reducing quantization cost and improving inference efficiency. Code is available at https://github.com/Nkniexin/SFMP", "AI": {"tldr": "SFMP\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u641c\u7d22\u3001\u786c\u4ef6\u53cb\u597d\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6570\u4f4d\u5bbd\u3001\u5757\u7ea7\u6df7\u5408\u7cbe\u5ea6\u3001\u884c\u5217\u91cd\u6392\u5e8f\u548c\u7edf\u4e00GEMM\u6838\u7b49\u521b\u65b0\u6280\u672f\uff0c\u5728\u76f8\u540c\u5185\u5b58\u7ea6\u675f\u4e0b\u4f18\u4e8e\u73b0\u6709\u5c42\u7ea7\u6df7\u5408\u7cbe\u5ea6\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u7cbe\u5ea6\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u8981\u4e48\u4f9d\u8d56\u6602\u8d35\u7684\u79bb\u6563\u4f18\u5316\u6765\u786e\u5b9a\u7cbe\u5ea6\u5206\u914d\uff0c\u8981\u4e48\u7531\u4e8e\u4e0d\u89c4\u5219\u5185\u5b58\u5e03\u5c40\u5bfc\u81f4\u786c\u4ef6\u6548\u7387\u4f4e\u4e0b\u3002\u9700\u8981\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u786c\u4ef6\u53cb\u597d\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u65b9\u6848\u3002", "method": "SFMP\u6846\u67b6\u5305\u542b\u56db\u4e2a\u5173\u952e\u6280\u672f\uff1a1)\u5206\u6570\u4f4d\u5bbd\uff1a\u5c06\u6743\u91cd\u77e9\u9635\u7684\u6574\u6570\u4f4d\u5bbd\u6269\u5c55\u4e3a\u5206\u6570\u503c\uff0c\u5c06\u79bb\u6563\u7cbe\u5ea6\u5206\u914d\u8f6c\u5316\u4e3a\u8fde\u7eed\u95ee\u9898\uff1b2)\u5757\u7ea7\u6df7\u5408\u7cbe\u5ea6\uff1a\u5728\u6743\u91cd\u77e9\u9635\u5185\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7cbe\u5ea6\u5206\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u786c\u4ef6\u53cb\u597d\u6027\uff1b3)\u884c\u5217\u6743\u91cd\u91cd\u6392\u5e8f\uff1a\u901a\u8fc7\u884c\u5217\u91cd\u6392\u5e8f\u805a\u5408\u91cd\u8981\u6743\u91cd\uff0c\u63a8\u7406\u65f6\u4ec5\u9700\u5c11\u91cf\u6fc0\u6d3b\u91cd\u6392\u5e8f\u5f00\u9500\uff1b4)\u7edf\u4e00GEMM\u6838\uff1a\u652f\u6301\u4efb\u610f\u5e73\u5747\u4f4d\u5bbd\u7684\u6df7\u5408\u7cbe\u5ea6GEMM\u8ba1\u7b97\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSFMP\u5728\u76f8\u540c\u5185\u5b58\u7ea6\u675f\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5c42\u7ea7\u6df7\u5408\u7cbe\u5ea6\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u91cf\u5316\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3002", "conclusion": "SFMP\u662f\u4e00\u4e2a\u65e0\u9700\u641c\u7d22\u3001\u786c\u4ef6\u53cb\u597d\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5206\u6570\u4f4d\u5bbd\u548c\u5757\u7ea7\u6df7\u5408\u7cbe\u5ea6\u7b49\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u538b\u7f29\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01039", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01039", "abs": "https://arxiv.org/abs/2602.01039", "authors": ["Zhiwei Ling", "Hailiang Zhao", "Chao Zhang", "Xiang Ao", "Ziqi Wang", "Cheng Zhang", "Zhen Qin", "Xinkui Zhao", "Kingsum Chow", "Yuanqing Wu", "MengChu Zhou"], "title": "Adaptive Dual-Weighting Framework for Federated Learning via Out-of-Distribution Detection", "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across large-scale distributed service nodes while preserving data privacy, making it a cornerstone of intelligent service systems in edge-cloud environments. However, in real-world service-oriented deployments, data generated by heterogeneous users, devices, and application scenarios are inherently non-IID. This severe data heterogeneity critically undermines the convergence stability, generalization ability, and ultimately the quality of service delivered by the global model. To address this challenge, we propose FLood, a novel FL framework inspired by out-of-distribution (OOD) detection. FLood dynamically counteracts the adverse effects of heterogeneity through a dual-weighting mechanism that jointly governs local training and global aggregation. At the client level, it adaptively reweights the supervised loss by upweighting pseudo-OOD samples, thereby encouraging more robust learning from distributionally misaligned or challenging data. At the server level, it refines model aggregation by weighting client contributions according to their OOD confidence scores, prioritizing updates from clients with higher in-distribution consistency and enhancing the global model's robustness and convergence stability. Extensive experiments across multiple benchmarks under diverse non-IID settings demonstrate that FLood consistently outperforms state-of-the-art FL methods in both accuracy and generalization. Furthermore, FLood functions as an orthogonal plug-in module: it seamlessly integrates with existing FL algorithms to boost their performance under heterogeneity without modifying their core optimization logic. These properties make FLood a practical and scalable solution for deploying reliable intelligent services in real-world federated environments.", "AI": {"tldr": "FLood\uff1a\u57fa\u4e8eOOD\u68c0\u6d4b\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u91cd\u52a0\u6743\u673a\u5236\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\uff0c\u63d0\u5347\u6a21\u578b\u6536\u655b\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u5b9e\u670d\u52a1\u90e8\u7f72\u4e2d\uff0c\u7528\u6237\u3001\u8bbe\u5907\u548c\u5e94\u7528\u573a\u666f\u7684\u5f02\u6784\u6027\u5bfc\u81f4\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff0c\u4e25\u91cd\u635f\u5bb3\u8054\u90a6\u5b66\u4e60\u5168\u5c40\u6a21\u578b\u7684\u6536\u655b\u7a33\u5b9a\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u670d\u52a1\u8d28\u91cf", "method": "\u63d0\u51faFLood\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u91cd\u52a0\u6743\u673a\u5236\uff1a1) \u5ba2\u6237\u7aef\u5c42\u9762\uff0c\u901a\u8fc7\u4e0a\u8c03\u4f2aOOD\u6837\u672c\u6743\u91cd\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u76d1\u7763\u635f\u5931\uff1b2) \u670d\u52a1\u5668\u5c42\u9762\uff0c\u6839\u636e\u5ba2\u6237\u7aefOOD\u7f6e\u4fe1\u5ea6\u5206\u6570\u52a0\u6743\u805a\u5408\u6a21\u578b\u66f4\u65b0", "result": "\u5728\u591a\u79cd\u975eIID\u8bbe\u7f6e\u4e0b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFLood\u5728\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e14\u53ef\u4f5c\u4e3a\u6b63\u4ea4\u63d2\u4ef6\u6a21\u5757\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7b97\u6cd5\u4e2d", "conclusion": "FLood\u4e3a\u73b0\u5b9e\u8054\u90a6\u73af\u5883\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u90e8\u7f72\u53ef\u9760\u7684\u667a\u80fd\u670d\u52a1\uff0c\u6709\u6548\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\u6311\u6218"}}
{"id": "2602.01045", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01045", "abs": "https://arxiv.org/abs/2602.01045", "authors": ["Zixin Jessie Chen", "Hao Chen", "Yizhou Liu", "Jeff Gore"], "title": "Superposition unifies power-law training dynamics", "comment": "17 pages, 14 figures", "summary": "We investigate the role of feature superposition in the emergence of power-law training dynamics using a teacher-student framework. We first derive an analytic theory for training without superposition, establishing that the power-law training exponent depends on both the input data statistics and channel importance. Remarkably, we discover that a superposition bottleneck induces a transition to a universal power-law exponent of $\\sim 1$, independent of data and channel statistics. This one over time training with superposition represents an up to tenfold acceleration compared to the purely sequential learning that takes place in the absence of superposition. Our finding that superposition leads to rapid training with a data-independent power law exponent may have important implications for a wide range of neural networks that employ superposition, including production-scale large language models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u7279\u5f81\u53e0\u52a0\u5bfc\u81f4\u8bad\u7ec3\u5448\u73b0\u666e\u9002\u76841/t\u5e42\u5f8b\u52a8\u6001\uff0c\u76f8\u6bd4\u65e0\u53e0\u52a0\u7684\u5e8f\u5217\u5b66\u4e60\u52a0\u901f\u9ad8\u8fbe10\u500d", "motivation": "\u7814\u7a76\u7279\u5f81\u53e0\u52a0\u5728\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u52a8\u6001\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7b49\u4f7f\u7528\u53e0\u52a0\u7684\u7f51\u7edc\u5177\u6709\u91cd\u8981\u610f\u4e49", "method": "\u4f7f\u7528\u5e08\u751f\u6846\u67b6\uff0c\u9996\u5148\u63a8\u5bfc\u65e0\u53e0\u52a0\u65f6\u7684\u89e3\u6790\u7406\u8bba\uff0c\u7136\u540e\u7814\u7a76\u53e0\u52a0\u74f6\u9888\u5982\u4f55\u5f71\u54cd\u8bad\u7ec3\u52a8\u6001", "result": "\u53d1\u73b0\u53e0\u52a0\u74f6\u9888\u5bfc\u81f4\u8bad\u7ec3\u5448\u73b0\u666e\u9002\u76841/t\u5e42\u5f8b\u6307\u6570\uff0c\u4e0e\u6570\u636e\u548c\u901a\u9053\u7edf\u8ba1\u65e0\u5173\uff0c\u76f8\u6bd4\u65e0\u53e0\u52a0\u52a0\u901f\u9ad8\u8fbe10\u500d", "conclusion": "\u7279\u5f81\u53e0\u52a0\u5bfc\u81f4\u5feb\u901f\u8bad\u7ec3\u548c\u6570\u636e\u65e0\u5173\u7684\u5e42\u5f8b\u6307\u6570\uff0c\u8fd9\u5bf9\u4f7f\u7528\u53e0\u52a0\u7684\u795e\u7ecf\u7f51\u7edc\uff08\u5305\u62ec\u751f\u4ea7\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff09\u6709\u91cd\u8981\u542f\u793a"}}
{"id": "2602.01051", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01051", "abs": "https://arxiv.org/abs/2602.01051", "authors": ["Rong Fu", "Wenxin Zhang", "Muge Qi", "Yang Li", "Yabin Jin", "Jiekai Wu", "Jiaxuan Lu", "Chunlei Meng", "Youjin Wang", "Zeli Su", "Juntao Gao", "Li Bao", "Qi Zhao", "Wei Luo", "Simon Fong"], "title": "SwiftRepertoire: Few-Shot Immune-Signature Synthesis via Dynamic Kernel Codes", "comment": "19 pages, 8 figures, 8 tables", "summary": "Repertoire-level analysis of T cell receptors offers a biologically grounded signal for disease detection and immune monitoring, yet practical deployment is impeded by label sparsity, cohort heterogeneity, and the computational burden of adapting large encoders to new tasks. We introduce a framework that synthesizes compact task-specific parameterizations from a learned dictionary of prototypes conditioned on lightweight task descriptors derived from repertoire probes and pooled embedding statistics. This synthesis produces small adapter modules applied to a frozen pretrained backbone, enabling immediate adaptation to novel tasks with only a handful of support examples and without full model fine-tuning. The architecture preserves interpretability through motif-aware probes and a calibrated motif discovery pipeline that links predictive decisions to sequence-level signals. Together, these components yield a practical, sample-efficient, and interpretable pathway for translating repertoire-informed models into diverse clinical and research settings where labeled data are scarce and computational resources are constrained.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4ece\u539f\u578b\u5b57\u5178\u5408\u6210\u4efb\u52a1\u7279\u5b9a\u53c2\u6570\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4efb\u52a1\u63cf\u8ff0\u7b26\u548c\u9002\u914d\u5668\u6a21\u5757\uff0c\u5b9e\u73b0\u5c11\u91cf\u6837\u672c\u4e0b\u7684T\u7ec6\u80de\u53d7\u4f53\u5e93\u5206\u6790\uff0c\u65e0\u9700\u5b8c\u6574\u5fae\u8c03", "motivation": "T\u7ec6\u80de\u53d7\u4f53\u5e93\u5206\u6790\u4e3a\u75be\u75c5\u68c0\u6d4b\u548c\u514d\u75ab\u76d1\u6d4b\u63d0\u4f9b\u751f\u7269\u5b66\u57fa\u7840\u4fe1\u53f7\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u6807\u7b7e\u7a00\u758f\u3001\u961f\u5217\u5f02\u8d28\u6027\u4ee5\u53ca\u5927\u578b\u7f16\u7801\u5668\u9002\u5e94\u65b0\u4efb\u52a1\u7684\u8ba1\u7b97\u8d1f\u62c5\u7b49\u6311\u6218", "method": "\u4ece\u5b66\u4e60\u7684\u539f\u578b\u5b57\u5178\u5408\u6210\u7d27\u51d1\u7684\u4efb\u52a1\u7279\u5b9a\u53c2\u6570\u5316\uff0c\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u4efb\u52a1\u63cf\u8ff0\u7b26\uff08\u6765\u81ea\u5e93\u63a2\u9488\u548c\u6c60\u5316\u5d4c\u5165\u7edf\u8ba1\uff09\uff0c\u751f\u6210\u5c0f\u578b\u9002\u914d\u5668\u6a21\u5757\u5e94\u7528\u4e8e\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3\u9aa8\u5e72\u7f51\u7edc", "result": "\u5b9e\u73b0\u4ec5\u9700\u5c11\u91cf\u652f\u6301\u6837\u672c\u5373\u53ef\u7acb\u5373\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u65e0\u9700\u5b8c\u6574\u6a21\u578b\u5fae\u8c03\uff0c\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u4f9b\u5b9e\u7528\u3001\u6837\u672c\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u9014\u5f84", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u6807\u7b7e\u6570\u636e\u7a00\u7f3a\u548c\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u7684\u4e34\u5e8a\u548c\u7814\u7a76\u73af\u5883\u4e2d\u90e8\u7f72\u5e93\u4fe1\u606f\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01053", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01053", "abs": "https://arxiv.org/abs/2602.01053", "authors": ["Hyesung Jeon", "Hyeongju Ha", "Jae-Joon Kim"], "title": "LRAgent: Efficient KV Cache Sharing for Multi-LoRA LLM Agents", "comment": "23 pages, 9 figures, 19 tables", "summary": "Role specialization in multi-LLM agent systems is often realized via multi-LoRA, where agents share a pretrained backbone and differ only through lightweight adapters. Despite sharing base model weights, each agent independently builds and stores its own KV cache for the same long, tool-augmented trajectories, incurring substantial memory and compute overhead. Existing KV cache sharing methods largely overlook this multi-LoRA setting. We observe that, across agents, cache differences are dominated by adapter outputs, while activations from the shared pretrained backbone remain highly similar. Based on this observation, we propose LRAgent, a KV cache sharing framework for multi-LoRA agents that decomposes the cache into a shared base component from the pretrained weights and an adapter-dependent component from LoRA weights. LRAgent reduces memory overhead by sharing the base component and storing the adapter component in its inherent low-rank form, and further reduces compute overhead, enabled by shared-$A$ multi-LoRA architectures, by also sharing the low-rank cache and avoiding redundant computations for contexts already processed by other agents. To efficiently reconstruct adapter contributions at runtime, we introduce Flash-LoRA-Attention, a kernel that reorders attention computation to avoid materializing the low-rank cache to full dimension. LRAgent achieves throughput and time-to-first-token latency close to fully shared caching, while preserving accuracy near the non-shared caching baseline across agentic question-answering benchmarks.", "AI": {"tldr": "LRAgent\uff1a\u9488\u5bf9\u591aLoRA\u667a\u80fd\u4f53\u7cfb\u7edf\u7684KV\u7f13\u5b58\u5171\u4eab\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u7f13\u5b58\u4e3a\u5171\u4eab\u57fa\u7840\u7ec4\u4ef6\u548c\u9002\u914d\u5668\u7ec4\u4ef6\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u591aLLM\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u867d\u7136\u5171\u4eab\u9884\u8bad\u7ec3\u4e3b\u5e72\u7f51\u7edc\uff0c\u4f46\u6bcf\u4e2a\u667a\u80fd\u4f53\u72ec\u7acb\u5b58\u50a8\u81ea\u5df1\u7684KV\u7f13\u5b58\uff0c\u5bfc\u81f4\u76f8\u540c\u5de5\u5177\u589e\u5f3a\u8f68\u8ff9\u7684\u91cd\u590d\u5b58\u50a8\u548c\u8ba1\u7b97\u5f00\u9500\u3002\u73b0\u6709KV\u7f13\u5b58\u5171\u4eab\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u591aLoRA\u8bbe\u7f6e\u3002", "method": "1. \u5c06KV\u7f13\u5b58\u5206\u89e3\u4e3a\u5171\u4eab\u57fa\u7840\u7ec4\u4ef6\uff08\u6765\u81ea\u9884\u8bad\u7ec3\u6743\u91cd\uff09\u548c\u9002\u914d\u5668\u76f8\u5173\u7ec4\u4ef6\uff08\u6765\u81eaLoRA\u6743\u91cd\uff09\uff1b2. \u5171\u4eab\u57fa\u7840\u7ec4\u4ef6\uff0c\u4ee5\u4f4e\u79e9\u5f62\u5f0f\u5b58\u50a8\u9002\u914d\u5668\u7ec4\u4ef6\uff1b3. \u5f15\u5165Flash-LoRA-Attention\u5185\u6838\uff0c\u907f\u514d\u5c06\u4f4e\u79e9\u7f13\u5b58\u7269\u5316\u4e3a\u5b8c\u6574\u7ef4\u5ea6\uff1b4. \u5229\u7528\u5171\u4eab-A\u591aLoRA\u67b6\u6784\u8fdb\u4e00\u6b65\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u667a\u80fd\u4f53\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLRAgent\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u5168\u5171\u4eab\u7f13\u5b58\u7684\u541e\u5410\u91cf\u548c\u9996\u6b21\u4ee4\u724c\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a5\u8fd1\u975e\u5171\u4eab\u7f13\u5b58\u57fa\u7ebf\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "LRAgent\u901a\u8fc7\u521b\u65b0\u7684\u7f13\u5b58\u5206\u89e3\u548c\u5171\u4eab\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591aLoRA\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684KV\u7f13\u5b58\u5197\u4f59\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u6548\u7387\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01058", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01058", "abs": "https://arxiv.org/abs/2602.01058", "authors": ["Dylan Zhang", "Yufeng Xu", "Haojin Wang", "Qingzhi Chen", "Hao Peng"], "title": "Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning", "comment": null, "summary": "Post-training of reasoning LLMs is a holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone.\n  We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to a mismatch typical in current SFT-RL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts.\n  We propose PEAR (Policy Evaluation-inspired Algorithm for Offline Learning Loss Re-weighting), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected.\n  We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen 2.5 and 3 and DeepSeek-distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass at 8 gains up to a 14.6 percent on AIME2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation.", "AI": {"tldr": "PEAR\u662f\u4e00\u79cdSFT\u9636\u6bb5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u91cd\u65b0\u52a0\u6743SFT\u635f\u5931\uff0c\u89e3\u51b3SFT\u4e0eRL\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u540e\u7eedRL\u8bad\u7ec3\u6548\u679c", "motivation": "\u5f53\u524dSFT-RL\u6d41\u7a0b\u5b58\u5728\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff1a\u79bb\u7ebfSFT\u6570\u636e\u751f\u6210\u5206\u5e03\u4e0e\u5728\u7ebfRL\u7b56\u7565\u5206\u5e03\u4e0d\u540c\uff0c\u5bfc\u81f4\u66f4\u5f3a\u7684SFT\u68c0\u67e5\u70b9\u5728\u76f8\u540cRL\u8bad\u7ec3\u540e\u53cd\u800c\u8868\u73b0\u66f4\u5dee", "method": "\u63d0\u51faPEAR\u65b9\u6cd5\uff0c\u4f7f\u7528\u91cd\u8981\u6027\u91c7\u6837\u91cd\u65b0\u52a0\u6743SFT\u635f\u5931\uff0c\u5305\u542btoken\u3001block\u548csequence\u4e09\u4e2a\u7ea7\u522b\u7684\u53d8\u4f53\uff0c\u53ef\u4e0e\u6807\u51c6SFT\u76ee\u6807\u7ed3\u5408\u4f7f\u7528", "result": "\u5728\u53ef\u9a8c\u8bc1\u63a8\u7406\u6e38\u620f\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cPEAR\u76f8\u6bd4\u6807\u51c6SFT\u6301\u7eed\u63d0\u5347RL\u540e\u6027\u80fd\uff0c\u5728AIME2025\u4e0a\u83b7\u5f97\u9ad8\u8fbe14.6%\u7684pass@8\u589e\u76ca", "conclusion": "PEAR\u662f\u8fc8\u5411\u66f4\u6574\u4f53\u5316LLM\u540e\u8bad\u7ec3\u7684\u6709\u6548\u6b65\u9aa4\uff0c\u8bbe\u8ba1SFT\u65f6\u8003\u8651\u4e0b\u6e38RL\u800c\u975e\u5b64\u7acb\u4f18\u5316\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6700\u7ec8\u6027\u80fd"}}
{"id": "2602.01083", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01083", "abs": "https://arxiv.org/abs/2602.01083", "authors": ["Adir Dayan", "Yam Eitan", "Haggai Maron"], "title": "On the Expressive Power of Permutation-Equivariant Weight-Space Networks", "comment": null, "summary": "Weight-space learning studies neural architectures that operate directly on the parameters of other neural networks. Motivated by the growing availability of pretrained models, recent work has demonstrated the effectiveness of weight-space networks across a wide range of tasks. SOTA weight-space networks rely on permutation-equivariant designs to improve generalization. However, this may negatively affect expressive power, warranting theoretical investigation. Importantly, unlike other structured domains, weight-space learning targets maps operating on both weight and function spaces, making expressivity analysis particularly subtle. While a few prior works provide partial expressivity results, a comprehensive characterization is still missing. In this work, we address this gap by developing a systematic theory for expressivity of weight-space networks. We first prove that all prominent permutation-equivariant networks are equivalent in expressive power. We then establish universality in both weight- and function-space settings under mild, natural assumptions on the input weights, and characterize the edge-case regimes where universality no longer holds. Together, these results provide a strong and unified foundation for the expressivity of weight-space networks.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u6743\u91cd\u7a7a\u95f4\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u4e3b\u8981\u7f6e\u6362\u7b49\u53d8\u7f51\u7edc\u5177\u6709\u76f8\u540c\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u5efa\u7acb\u4e86\u6743\u91cd\u7a7a\u95f4\u548c\u51fd\u6570\u7a7a\u95f4\u7684\u666e\u9002\u6027\uff0c\u540c\u65f6\u523b\u753b\u4e86\u666e\u9002\u6027\u5931\u6548\u7684\u8fb9\u7f18\u60c5\u51b5\u3002", "motivation": "\u968f\u7740\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u666e\u53ca\uff0c\u6743\u91cd\u7a7a\u95f4\u7f51\u7edc\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002\u73b0\u6709SOTA\u65b9\u6cd5\u4f9d\u8d56\u7f6e\u6362\u7b49\u53d8\u8bbe\u8ba1\u6765\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u8fd9\u53ef\u80fd\u5f71\u54cd\u8868\u8fbe\u80fd\u529b\uff0c\u9700\u8981\u7406\u8bba\u5206\u6790\u3002\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\u540c\u65f6\u6d89\u53ca\u6743\u91cd\u7a7a\u95f4\u548c\u51fd\u6570\u7a7a\u95f4\u7684\u6620\u5c04\uff0c\u4f7f\u5f97\u8868\u8fbe\u80fd\u529b\u5206\u6790\u7279\u522b\u5fae\u5999\uff0c\u73b0\u6709\u90e8\u5206\u7ed3\u679c\u4e0d\u5b8c\u6574\uff0c\u9700\u8981\u7cfb\u7edf\u7406\u8bba\u3002", "method": "\u5f00\u53d1\u4e86\u6743\u91cd\u7a7a\u95f4\u7f51\u7edc\u8868\u8fbe\u80fd\u529b\u7684\u7cfb\u7edf\u7406\u8bba\u3002\u9996\u5148\u8bc1\u660e\u4e86\u6240\u6709\u4e3b\u8981\u7f6e\u6362\u7b49\u53d8\u7f51\u7edc\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u662f\u7b49\u4ef7\u7684\u3002\u7136\u540e\u5728\u8f93\u5165\u6743\u91cd\u7684\u6e29\u548c\u81ea\u7136\u5047\u8bbe\u4e0b\uff0c\u5efa\u7acb\u4e86\u6743\u91cd\u7a7a\u95f4\u548c\u51fd\u6570\u7a7a\u95f4\u8bbe\u7f6e\u7684\u666e\u9002\u6027\uff0c\u5e76\u523b\u753b\u4e86\u666e\u9002\u6027\u4e0d\u518d\u6210\u7acb\u7684\u8fb9\u7f18\u60c5\u51b5\u3002", "result": "1) \u6240\u6709\u4e3b\u8981\u7f6e\u6362\u7b49\u53d8\u7f51\u7edc\u5177\u6709\u76f8\u540c\u7684\u8868\u8fbe\u80fd\u529b\uff1b2) \u5728\u6e29\u548c\u5047\u8bbe\u4e0b\uff0c\u6743\u91cd\u7a7a\u95f4\u7f51\u7edc\u5728\u6743\u91cd\u7a7a\u95f4\u548c\u51fd\u6570\u7a7a\u95f4\u90fd\u5177\u6709\u666e\u9002\u6027\uff1b3) \u660e\u786e\u4e86\u666e\u9002\u6027\u5931\u6548\u7684\u8fb9\u7f18\u60c5\u51b5\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u6743\u91cd\u7a7a\u95f4\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86\u6743\u91cd\u7a7a\u95f4\u7f51\u7edc\u8868\u8fbe\u80fd\u529b\u7406\u8bba\u5206\u6790\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u7cfb\u7edf\u800c\u5168\u9762\u7684\u8868\u5f81\u3002\u7ed3\u679c\u8868\u660e\u7f6e\u6362\u7b49\u53d8\u8bbe\u8ba1\u4e0d\u4f1a\u9650\u5236\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u5728\u5408\u7406\u6761\u4ef6\u4e0b\u4fdd\u8bc1\u4e86\u6743\u91cd\u7a7a\u95f4\u548c\u51fd\u6570\u7a7a\u95f4\u7684\u666e\u9002\u6027\uff0c\u4e3a\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.01105", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01105", "abs": "https://arxiv.org/abs/2602.01105", "authors": ["Zixiao Wang", "Yifei Shen", "Huishuai Zhang"], "title": "OLion: Approaching the Hadamard Ideal by Intersecting Spectral and $\\ell_{\\infty}$ Implicit Biases", "comment": "23 pages", "summary": "Many optimizers can be interpreted as steepest-descent methods under norm-induced geometries, and thus inherit corresponding implicit biases. We introduce \\nameA{} (\\fullname{}), which combines spectral control from orthogonalized update directions with $\\ell_\\infty$-style coordinate control from sign updates. \\nameA{} forms a Lion-style momentum direction, approximately orthogonalizes it via a few Newton--Schulz iterations, and then applies an entrywise sign, providing an efficient approximation to taking a maximal step over the intersection of the spectral and $\\ell_\\infty$ constraint sets (a scaled Hadamard-like set for matrix parameters). Despite the strong nonlinearity of orthogonalization and sign, we prove convergence under a mild, empirically verified diagonal-isotropy assumption. Across large-scale language and vision training, including GPT-2 and Llama pretraining, SiT image pretraining, and supervised fine-tuning, \\nameA{} matches or outperforms AdamW and Muon under comparable tuning while using only momentum-level optimizer state, and it mitigates optimizer mismatch when fine-tuning AdamW-pretrained checkpoints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aSpectral-Sign\u7684\u4f18\u5316\u5668\uff0c\u7ed3\u5408\u8c31\u63a7\u5236\u548c\u5750\u6807\u63a7\u5236\uff0c\u901a\u8fc7\u6b63\u4ea4\u5316\u52a8\u91cf\u65b9\u5411\u548c\u7b26\u53f7\u66f4\u65b0\uff0c\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u4e2d\u5339\u914d\u6216\u8d85\u8d8aAdamW\u548cMuon\uff0c\u540c\u65f6\u4f7f\u7528\u66f4\u5c11\u7684\u5185\u5b58\u3002", "motivation": "\u8bb8\u591a\u4f18\u5316\u5668\u53ef\u4ee5\u89e3\u91ca\u4e3a\u8303\u6570\u8bf1\u5bfc\u51e0\u4f55\u4e0b\u7684\u6700\u901f\u4e0b\u964d\u6cd5\uff0c\u4ece\u800c\u7ee7\u627f\u76f8\u5e94\u7684\u9690\u5f0f\u504f\u5dee\u3002\u672c\u6587\u65e8\u5728\u7ed3\u5408\u8c31\u63a7\u5236\uff08\u6765\u81ea\u6b63\u4ea4\u5316\u66f4\u65b0\u65b9\u5411\uff09\u548c\u2113\u221e\u98ce\u683c\u7684\u5750\u6807\u63a7\u5236\uff08\u6765\u81ea\u7b26\u53f7\u66f4\u65b0\uff09\uff0c\u4ee5\u5e73\u8861\u4f18\u5316\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51faSpectral-Sign\u4f18\u5316\u5668\uff1a1\uff09\u5f62\u6210Lion\u98ce\u683c\u7684\u52a8\u91cf\u65b9\u5411\uff1b2\uff09\u901a\u8fc7\u5c11\u91cfNewton-Schulz\u8fed\u4ee3\u8fd1\u4f3c\u6b63\u4ea4\u5316\u8be5\u65b9\u5411\uff1b3\uff09\u5e94\u7528\u9010\u5143\u7d20\u7684\u7b26\u53f7\u51fd\u6570\u3002\u8fd9\u63d0\u4f9b\u4e86\u5bf9\u8c31\u7ea6\u675f\u548c\u2113\u221e\u7ea6\u675f\u96c6\u4ea4\u96c6\uff08\u7f29\u653eHadamard-like\u96c6\u5408\uff09\u4e0a\u6700\u5927\u6b65\u957f\u7684\u6709\u6548\u8fd1\u4f3c\u3002", "result": "\u5728\u6b63\u4ea4\u5316\u548c\u7b26\u53f7\u7684\u5f3a\u975e\u7ebf\u6027\u4e0b\uff0c\u8bc1\u660e\u4e86\u5728\u7ecf\u9a8c\u9a8c\u8bc1\u7684\u5bf9\u89d2\u5404\u5411\u540c\u6027\u5047\u8bbe\u4e0b\u7684\u6536\u655b\u6027\u3002\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u548c\u89c6\u89c9\u8bad\u7ec3\u4e2d\uff08\u5305\u62ecGPT-2\u548cLlama\u9884\u8bad\u7ec3\u3001SiT\u56fe\u50cf\u9884\u8bad\u7ec3\u548c\u76d1\u7763\u5fae\u8c03\uff09\uff0cSpectral-Sign\u5728\u53ef\u6bd4\u8c03\u4f18\u4e0b\u5339\u914d\u6216\u4f18\u4e8eAdamW\u548cMuon\uff0c\u540c\u65f6\u4ec5\u4f7f\u7528\u52a8\u91cf\u7ea7\u522b\u7684\u4f18\u5316\u5668\u72b6\u6001\uff0c\u5e76\u5728\u5fae\u8c03AdamW\u9884\u8bad\u7ec3\u68c0\u67e5\u70b9\u65f6\u51cf\u8f7b\u4f18\u5316\u5668\u4e0d\u5339\u914d\u95ee\u9898\u3002", "conclusion": "Spectral-Sign\u901a\u8fc7\u7ed3\u5408\u8c31\u63a7\u5236\u548c\u5750\u6807\u63a7\u5236\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5185\u5b58\u53cb\u597d\u7684\u4f18\u5316\u5668\uff0c\u5728\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u5fae\u8c03\u573a\u666f\u4e2d\u80fd\u6709\u6548\u7f13\u89e3\u4f18\u5316\u5668\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2602.01113", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01113", "abs": "https://arxiv.org/abs/2602.01113", "authors": ["Wenjie Liang", "Ranhui Yan", "Jia Cai", "You-Gan Wang"], "title": "Single-Edge Node Injection Threats to GNN-Based Security Monitoring in Industrial Graph Systems", "comment": null, "summary": "Graph neural networks (GNNs) are increasingly adopted in industrial graph-based monitoring systems (e.g., Industrial internet of things (IIoT) device graphs, power-grid topology models, and manufacturing communication networks) to support anomaly detection, state estimation, and asset classification. In such settings, an adversary that compromises a small number of edge devices may inject counterfeit nodes (e.g., rogue sensors, virtualized endpoints, or spoofed substations) to bias downstream decisions while evading topology- and homophily-based sanitization. This paper formulates deployment-oriented node-injection attacks under constrained resources and proposes the \\emph{Single-Edge Graph Injection Attack} (SEGIA), in which each injected node attaches to the operational graph through a single edge. SEGIA integrates a pruned SGC surrogate, multi-hop neighborhood sampling, and reverse graph convolution-based feature synthesis with a similarity-regularized objective to preserve local homophily and survive edge pruning. Theoretical analysis and extensive evaluations across datasets and defenses show at least $25\\%$ higher attack success than representative baselines under substantially smaller edge budgets. These results indicate a system-level risk in industrial GNN deployments and motivate lightweight admission validation and neighborhood-consistency monitoring.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5de5\u4e1a\u56fe\u795e\u7ecf\u7f51\u7edc\u7cfb\u7edf\u7684\u5355\u8fb9\u56fe\u6ce8\u5165\u653b\u51fb\u65b9\u6cd5\uff08SEGIA\uff09\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u6ce8\u5165\u5c11\u91cf\u8282\u70b9\u5e76\u4ec5\u7528\u5355\u8fb9\u8fde\u63a5\u6765\u5f71\u54cdGNN\u51b3\u7b56\uff0c\u653b\u51fb\u6210\u529f\u7387\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad825%\u4ee5\u4e0a\u3002", "motivation": "\u5de5\u4e1aGNN\u7cfb\u7edf\uff08\u5982IIoT\u8bbe\u5907\u56fe\u3001\u7535\u7f51\u62d3\u6251\u6a21\u578b\u7b49\uff09\u9762\u4e34\u5b89\u5168\u5a01\u80c1\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u6ce8\u5165\u4f2a\u9020\u8282\u70b9\uff08\u5982\u6076\u610f\u4f20\u611f\u5668\u3001\u865a\u62df\u7aef\u70b9\uff09\u6765\u504f\u5411\u4e0b\u6e38\u51b3\u7b56\uff0c\u540c\u65f6\u9003\u907f\u57fa\u4e8e\u62d3\u6251\u548c\u540c\u8d28\u6027\u7684\u5b89\u5168\u68c0\u6d4b\u3002", "method": "\u63d0\u51faSEGIA\u653b\u51fb\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u526a\u679d\u7684SGC\u4ee3\u7406\u6a21\u578b\uff1b2\uff09\u591a\u8df3\u90bb\u57df\u91c7\u6837\uff1b3\uff09\u57fa\u4e8e\u53cd\u5411\u56fe\u5377\u79ef\u7684\u7279\u5f81\u5408\u6210\uff1b4\uff09\u76f8\u4f3c\u6027\u6b63\u5219\u5316\u76ee\u6807\u4ee5\u4fdd\u6301\u5c40\u90e8\u540c\u8d28\u6027\u5e76\u9003\u907f\u8fb9\u526a\u679d\u9632\u5fa1\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u663e\u8457\u66f4\u5c0f\u7684\u8fb9\u9884\u7b97\u4e0b\uff0cSEGIA\u653b\u51fb\u6210\u529f\u7387\u6bd4\u4ee3\u8868\u6027\u57fa\u7ebf\u65b9\u6cd5\u81f3\u5c11\u9ad825%\uff0c\u63ed\u793a\u4e86\u5de5\u4e1aGNN\u90e8\u7f72\u4e2d\u7684\u7cfb\u7edf\u6027\u98ce\u9669\u3002", "conclusion": "\u5de5\u4e1aGNN\u90e8\u7f72\u5b58\u5728\u7cfb\u7edf\u7ea7\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u8f7b\u91cf\u7ea7\u7684\u51c6\u5165\u9a8c\u8bc1\u548c\u90bb\u57df\u4e00\u81f4\u6027\u76d1\u63a7\u6765\u9632\u5fa1\u6b64\u7c7b\u8282\u70b9\u6ce8\u5165\u653b\u51fb\u3002"}}
{"id": "2602.01120", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01120", "abs": "https://arxiv.org/abs/2602.01120", "authors": ["Youkang Wang", "Jian Wang", "Rubing Chen", "Tianyi Zeng", "Xiao-Yong Wei", "Qing Li"], "title": "MarkovScale: Towards Optimal Sequential Scaling at Inference Time", "comment": "12 pages", "summary": "Sequential scaling is a prominent inference-time scaling paradigm, yet its performance improvements are typically modest and not well understood, largely due to the prevalence of heuristic, non-principled approaches that obscure clear optimality bounds. To address this, we propose a principled framework that models sequential scaling as a two-state Markov process. This approach reveals the underlying properties of sequential scaling and yields closed-form solutions for essential aspects, such as the specific conditions under which accuracy is improved and the theoretical upper, neutral, and lower performance bounds. Leveraging this formulation, we develop MarkovScale, a practical system that applies these optimality criteria to achieve a theoretically grounded balance between accuracy and efficiency. Comprehensive experiments across 3 backbone LLMs, 5 benchmarks, and over 20 configurations show that MarkovScale consistently outperforms state-of-the-art parallel and sequential scaling methods, representing a significant step toward optimal and resource-efficient inference in LLMs. The source code will be open upon acceptance at https://open-upon-acceptance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u987a\u5e8f\u7f29\u653e\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u6846\u67b6MarkovScale\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u987a\u5e8f\u7f29\u653e\u7684\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u5e76\u884c\u548c\u987a\u5e8f\u7f29\u653e\u65b9\u6cd5\u3002", "motivation": "\u987a\u5e8f\u7f29\u653e\u662f\u91cd\u8981\u7684\u63a8\u7406\u65f6\u7f29\u653e\u8303\u5f0f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\u3001\u975e\u539f\u5219\u6027\u7684\uff0c\u5bfc\u81f4\u6027\u80fd\u63d0\u5347\u6709\u9650\u4e14\u7f3a\u4e4f\u7406\u8bba\u7406\u89e3\uff0c\u9700\u8981\u5efa\u7acb\u539f\u5219\u6027\u6846\u67b6\u6765\u63ed\u793a\u5176\u6700\u4f18\u6027\u8fb9\u754c\u3002", "method": "\u5c06\u987a\u5e8f\u7f29\u653e\u5efa\u6a21\u4e3a\u4e24\u72b6\u6001\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\uff0c\u63a8\u5bfc\u51fa\u5c01\u95ed\u5f62\u5f0f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u51c6\u786e\u7387\u63d0\u5347\u7684\u7279\u5b9a\u6761\u4ef6\u4ee5\u53ca\u7406\u8bba\u4e0a\u9650\u3001\u4e2d\u6027\u548c\u4e0b\u9650\u6027\u80fd\u8fb9\u754c\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86MarkovScale\u7cfb\u7edf\u3002", "result": "\u57283\u4e2a\u9aa8\u5e72LLM\u30015\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u8d85\u8fc720\u79cd\u914d\u7f6e\u7684\u5b9e\u9a8c\u4e2d\uff0cMarkovScale\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5e76\u884c\u548c\u987a\u5e8f\u7f29\u653e\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u7387\u548c\u6548\u7387\u7684\u7406\u8bba\u5e73\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u987a\u5e8f\u7f29\u653e\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5176\u7406\u8bba\u6027\u8d28\uff0cMarkovScale\u7cfb\u7edf\u4ee3\u8868\u4e86\u5411LLM\u6700\u4f18\u548c\u8d44\u6e90\u9ad8\u6548\u63a8\u7406\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2602.01124", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01124", "abs": "https://arxiv.org/abs/2602.01124", "authors": ["Md Abrar Jahin", "Taufikur Rahman Fuad", "Jay Pujara", "Craig Knoblock"], "title": "ChronoSpike: An Adaptive Spiking Graph Neural Network for Dynamic Graphs", "comment": null, "summary": "Dynamic graph representation learning requires capturing both structural relationships and temporal evolution, yet existing approaches face a fundamental trade-off: attention-based methods achieve expressiveness at $O(T^2)$ complexity, while recurrent architectures suffer from gradient pathologies and dense state storage. Spiking neural networks offer event-driven efficiency but remain limited by sequential propagation, binary information loss, and local aggregation that misses global context. We propose ChronoSpike, an adaptive spiking graph neural network that integrates learnable LIF neurons with per-channel membrane dynamics, multi-head attentive spatial aggregation on continuous features, and a lightweight Transformer temporal encoder, enabling both fine-grained local modeling and long-range dependency capture with linear memory complexity $O(T \\cdot d)$. On three large-scale benchmarks, ChronoSpike outperforms twelve state-of-the-art baselines by $2.0\\%$ Macro-F1 and $2.4\\%$ Micro-F1 while achieving $3-10\\times$ faster training than recurrent methods with a constant 105K-parameter budget independent of graph size. We provide theoretical guarantees for membrane potential boundedness, gradient flow stability under contraction factor $\u03c1< 1$, and BIBO stability; interpretability analyses reveal heterogeneous temporal receptive fields and a learned primacy effect with $83-88\\%$ sparsity.", "AI": {"tldr": "ChronoSpike\uff1a\u4e00\u79cd\u81ea\u9002\u5e94\u8109\u51b2\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684LIF\u795e\u7ecf\u5143\u3001\u591a\u5934\u6ce8\u610f\u529b\u7a7a\u95f4\u805a\u5408\u548c\u8f7b\u91cf\u7ea7Transformer\u65f6\u95f4\u7f16\u7801\u5668\uff0c\u5b9e\u73b0\u7ebf\u6027\u5185\u5b58\u590d\u6742\u5ea6\u7684\u52a8\u6001\u56fe\u8868\u793a\u5b66\u4e60\uff0c\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u56fe\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u57fa\u672c\u6743\u8861\uff1a\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\u8868\u8fbe\u80fd\u529b\u5f3a\u4f46\u590d\u6742\u5ea6\u9ad8\uff08O(T\u00b2)\uff09\uff0c\u5faa\u73af\u67b6\u6784\u5b58\u5728\u68af\u5ea6\u95ee\u9898\u548c\u5bc6\u96c6\u72b6\u6001\u5b58\u50a8\u95ee\u9898\u3002\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u4e8b\u4ef6\u9a71\u52a8\u6548\u7387\uff0c\u4f46\u53d7\u9650\u4e8e\u987a\u5e8f\u4f20\u64ad\u3001\u4e8c\u8fdb\u5236\u4fe1\u606f\u4e22\u5931\u548c\u5c40\u90e8\u805a\u5408\u65e0\u6cd5\u6355\u83b7\u5168\u5c40\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faChronoSpike\u81ea\u9002\u5e94\u8109\u51b2\u56fe\u795e\u7ecf\u7f51\u7edc\uff1a1\uff09\u5177\u6709\u6bcf\u901a\u9053\u819c\u52a8\u529b\u5b66\u7684\u53ef\u5b66\u4e60LIF\u795e\u7ecf\u5143\uff1b2\uff09\u5728\u8fde\u7eed\u7279\u5f81\u4e0a\u8fdb\u884c\u591a\u5934\u6ce8\u610f\u529b\u7a7a\u95f4\u805a\u5408\uff1b3\uff09\u8f7b\u91cf\u7ea7Transformer\u65f6\u95f4\u7f16\u7801\u5668\u3002\u8be5\u65b9\u6cd5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5c40\u90e8\u5efa\u6a21\u548c\u957f\u7a0b\u4f9d\u8d56\u6355\u83b7\uff0c\u5177\u6709\u7ebf\u6027\u5185\u5b58\u590d\u6742\u5ea6O(T\u00b7d)\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cChronoSpike\u572812\u4e2a\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u4e0a\u63d0\u5347\u4e862.0% Macro-F1\u548c2.4% Micro-F1\uff0c\u8bad\u7ec3\u901f\u5ea6\u6bd4\u5faa\u73af\u65b9\u6cd5\u5feb3-10\u500d\uff0c\u53c2\u6570\u9884\u7b97\u6052\u5b9a\u4e3a105K\uff08\u4e0e\u56fe\u5927\u5c0f\u65e0\u5173\uff09\u3002\u7406\u8bba\u4fdd\u8bc1\u5305\u62ec\u819c\u7535\u4f4d\u6709\u754c\u6027\u3001\u6536\u7f29\u56e0\u5b50\u03c1<1\u4e0b\u7684\u68af\u5ea6\u6d41\u7a33\u5b9a\u6027\u3001BIBO\u7a33\u5b9a\u6027\u3002\u53ef\u89e3\u91ca\u6027\u5206\u6790\u663e\u793a\u5f02\u8d28\u65f6\u95f4\u611f\u53d7\u91ce\u548c\u5b66\u4e60\u7684\u9996\u56e0\u6548\u5e94\uff0c\u7a00\u758f\u5ea6\u8fbe83-88%\u3002", "conclusion": "ChronoSpike\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u6001\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u6548\u7387-\u8868\u8fbe\u80fd\u529b\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u4e0e\u6ce8\u610f\u529b\u673a\u5236\u7684\u521b\u65b0\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u52a8\u6001\u56fe\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01126", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01126", "abs": "https://arxiv.org/abs/2602.01126", "authors": ["Mengsha Kou", "Xiaoyu Xia", "Ziqi Wang", "Ibrahim Khalil", "Runkun Luo", "Jingwen Zhou", "Minhui Xue"], "title": "WinFLoRA: Incentivizing Client-Adaptive Aggregation in Federated LoRA under Privacy Heterogeneity", "comment": "12 pages", "summary": "Large Language Models (LLMs) increasingly underpin intelligent web applications, from chatbots to search and recommendation, where efficient specialization is essential. Low-Rank Adaptation (LoRA) enables such adaptation with minimal overhead, while federated LoRA allows web service providers to fine-tune shared models without data sharing. However, in privacy-sensitive deployments, clients inject varying levels of differential privacy (DP) noise, creating privacy heterogeneity that misaligns individual incentives and global performance. In this paper, we propose WinFLoRA, a privacy-heterogeneous federated LoRA that utilizes aggregation weights as incentives with noise awareness. Specifically, the noises from clients are estimated based on the uploaded LoRA adapters. A larger weight indicates greater influence on the global model and better downstream task performance, rewarding lower-noise contributions. By up-weighting low-noise updates, WinFLoRA improves global accuracy while accommodating clients' heterogeneous privacy requirements. Consequently, WinFLoRA aligns heterogeneous client utility in terms of privacy and downstream performance with global model objectives without third-party involvement. Extensive evaluations demonstrate that across multiple LLMs and datasets, WinFLoRA achieves up to 52.58% higher global accuracy and up to 2.56x client utility than state-of-the-art benchmarks. Source code is publicly available at https://github.com/koums24/WinFLoRA.git.", "AI": {"tldr": "WinFLoRA\uff1a\u4e00\u79cd\u9690\u79c1\u5f02\u6784\u7684\u8054\u90a6LoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u566a\u58f0\u611f\u77e5\u7684\u805a\u5408\u6743\u91cd\u6fc0\u52b1\u5ba2\u6237\u7aef\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u5168\u5c40\u6a21\u578b\u6027\u80fd", "motivation": "\u5728\u9690\u79c1\u654f\u611f\u7684\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u5ba2\u6237\u7aef\u6ce8\u5165\u4e0d\u540c\u7ea7\u522b\u7684\u5dee\u5206\u9690\u79c1\u566a\u58f0\uff0c\u5bfc\u81f4\u9690\u79c1\u5f02\u8d28\u6027\uff0c\u8fd9\u4f1a\u9519\u914d\u4e2a\u4f53\u6fc0\u52b1\u4e0e\u5168\u5c40\u6027\u80fd\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u5f02\u6784\u9690\u79c1\u9700\u6c42\u4e0e\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51faWinFLoRA\uff0c\u4e00\u79cd\u9690\u79c1\u5f02\u6784\u7684\u8054\u90a6LoRA\u6846\u67b6\u3002\u57fa\u4e8e\u4e0a\u4f20\u7684LoRA\u9002\u914d\u5668\u4f30\u8ba1\u5ba2\u6237\u7aef\u566a\u58f0\u6c34\u5e73\uff0c\u5c06\u805a\u5408\u6743\u91cd\u4f5c\u4e3a\u6fc0\u52b1\uff1a\u566a\u58f0\u8d8a\u4f4e\u7684\u5ba2\u6237\u7aef\u83b7\u5f97\u66f4\u5927\u6743\u91cd\uff0c\u4ece\u800c\u5728\u5168\u5c40\u6a21\u578b\u4e2d\u5177\u6709\u66f4\u5927\u5f71\u54cd\u529b\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e0\u9700\u7b2c\u4e09\u65b9\u53c2\u4e0e\uff0c\u81ea\u52a8\u5bf9\u9f50\u5f02\u6784\u5ba2\u6237\u7aef\u6548\u7528\u4e0e\u5168\u5c40\u76ee\u6807\u3002", "result": "\u5728\u591a\u4e2aLLM\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cWinFLoRA\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u51c6\u65b9\u6cd5\uff0c\u5168\u5c40\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534752.58%\uff0c\u5ba2\u6237\u7aef\u6548\u7528\u6700\u9ad8\u63d0\u53472.56\u500d\u3002", "conclusion": "WinFLoRA\u6210\u529f\u89e3\u51b3\u4e86\u9690\u79c1\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6fc0\u52b1\u9519\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u566a\u58f0\u611f\u77e5\u7684\u6743\u91cd\u5206\u914d\u673a\u5236\uff0c\u5728\u6ee1\u8db3\u5ba2\u6237\u7aef\u4e0d\u540c\u9690\u79c1\u9700\u6c42\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5168\u5c40\u6a21\u578b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6548\u7528\u7684\u5e73\u8861\u3002"}}
{"id": "2602.01128", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01128", "abs": "https://arxiv.org/abs/2602.01128", "authors": ["Mete Erdogan"], "title": "Tangent Space Fine-Tuning for Directional Preference Alignment in Large Language Models", "comment": null, "summary": "Our goal is to enable large language models (LLMs) to balance multiple human preference dimensions; such as helpfulness, safety, and verbosity, through principled and controllable alignment. Existing preference optimization methods, including Direct Preference Optimization (DPO), collapse feedback into a single scalar reward, fixing one balance among objectives and preventing traversal of the Pareto front. Recent work by Ortiz-Jimenez et al. (2023) showed that fine-tuning can be viewed in a model's tangent space, where linearized updates act as additive vectors that can be composed to jointly perform well on multiple tasks. Building on this formulation, we extend this idea to preference alignment and propose Tangent-Space Direct Preference Optimization (TS-DPO), which performs DPO within this locally linear regime to learn per-objective update directions. These directions can be linearly combined at inference to generate user-specified behaviors without additional optimization. Evaluated on the helpfulness-verbosity trade-off using the HelpSteer and UltraFeedback datasets, TS-DPO achieves broader Pareto-optimal coverage and smoother preference control than scalarized DPO. Canonical Correlation Analysis (CCA) further shows that tangent-space training amplifies canonical directions aligned with distinct preferences, improving disentanglement.", "AI": {"tldr": "TS-DPO\u5728\u5207\u7ebf\u7a7a\u95f4\u4e2d\u6267\u884cDPO\uff0c\u5b66\u4e60\u6bcf\u4e2a\u76ee\u6807\u7684\u66f4\u65b0\u65b9\u5411\uff0c\u53ef\u5728\u63a8\u7406\u65f6\u7ebf\u6027\u7ec4\u5408\u4ee5\u5b9e\u73b0\u7528\u6237\u6307\u5b9a\u7684\u884c\u4e3a\u5e73\u8861\uff0c\u65e0\u9700\u989d\u5916\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff08\u5982DPO\uff09\u5c06\u53cd\u9988\u538b\u7f29\u4e3a\u5355\u4e00\u6807\u91cf\u5956\u52b1\uff0c\u56fa\u5b9a\u4e86\u76ee\u6807\u95f4\u7684\u5e73\u8861\uff0c\u65e0\u6cd5\u904d\u5386\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u9650\u5236\u4e86LLM\u5728\u591a\u4e2a\u4eba\u7c7b\u504f\u597d\u7ef4\u5ea6\uff08\u5982\u5e2e\u52a9\u6027\u3001\u5b89\u5168\u6027\u3001\u5197\u957f\u5ea6\uff09\u4e0a\u7684\u53ef\u63a7\u5bf9\u9f50\u3002", "method": "\u57fa\u4e8e\u5207\u7ebf\u7a7a\u95f4\u5fae\u8c03\u7406\u8bba\uff0c\u63d0\u51fa\u5207\u7ebf\u7a7a\u95f4\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08TS-DPO\uff09\uff0c\u5728\u5c40\u90e8\u7ebf\u6027\u673a\u5236\u4e2d\u6267\u884cDPO\uff0c\u5b66\u4e60\u6bcf\u4e2a\u76ee\u6807\u7684\u66f4\u65b0\u65b9\u5411\u3002\u8fd9\u4e9b\u65b9\u5411\u53ef\u5728\u63a8\u7406\u65f6\u7ebf\u6027\u7ec4\u5408\uff0c\u751f\u6210\u7528\u6237\u6307\u5b9a\u7684\u884c\u4e3a\u3002", "result": "\u5728HelpSteer\u548cUltraFeedback\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5e2e\u52a9\u6027-\u5197\u957f\u5ea6\u6743\u8861\uff0cTS-DPO\u6bd4\u6807\u91cf\u5316DPO\u5b9e\u73b0\u4e86\u66f4\u5e7f\u6cdb\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u8986\u76d6\u548c\u66f4\u5e73\u6ed1\u7684\u504f\u597d\u63a7\u5236\u3002\u5178\u578b\u76f8\u5173\u5206\u6790\uff08CCA\uff09\u663e\u793a\u5207\u7ebf\u7a7a\u95f4\u8bad\u7ec3\u589e\u5f3a\u4e86\u4e0e\u4e0d\u540c\u504f\u597d\u5bf9\u9f50\u7684\u5178\u578b\u65b9\u5411\uff0c\u6539\u5584\u4e86\u53ef\u89e3\u8026\u6027\u3002", "conclusion": "TS-DPO\u901a\u8fc7\u5207\u7ebf\u7a7a\u95f4\u4e2d\u7684\u504f\u597d\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u5bf9\u591a\u4e2a\u4eba\u7c7b\u504f\u597d\u7ef4\u5ea6\u7684\u539f\u5219\u6027\u548c\u53ef\u63a7\u5e73\u8861\uff0c\u4e3aLLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.01135", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01135", "abs": "https://arxiv.org/abs/2602.01135", "authors": ["Hugo Math", "Rainer Lienhart"], "title": "TRACE: Scalable Amortized Causal Discovery from Single Sequences via Autoregressive Density Estimation", "comment": "8 pages, 6 figures,", "summary": "We study causal discovery from a single observed sequence of discrete events generated by a stochastic process, as encountered in vehicle logs, manufacturing systems, or patient trajectories. This regime is particularly challenging due to the absence of repeated samples, high dimensionality, and long-range temporal dependencies of the single observation during inference. We introduce TRACE, a scalable framework that repurposes autoregressive models as pretrained density estimators for conditional mutual information estimation. TRACE infers the summary causal graph between event types in a sequence, scaling linearly with the event vocabulary and supporting delayed causal effects, while being fully parallel on GPUs. We establish its theoretical identifiability under imperfect autoregressive models. Experiments demonstrate robust performance across different baselines and varying vocabulary sizes including an application to root-cause analysis in vehicle diagnostics with over 29,100 event types.", "AI": {"tldr": "TRACE\uff1a\u5229\u7528\u81ea\u56de\u5f52\u6a21\u578b\u4f5c\u4e3a\u9884\u8bad\u7ec3\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u4ece\u5355\u6761\u79bb\u6563\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u63a8\u65ad\u4e8b\u4ef6\u7c7b\u578b\u95f4\u7684\u56e0\u679c\u56fe\uff0c\u652f\u6301\u5ef6\u8fdf\u56e0\u679c\u6548\u5e94\uff0c\u5728GPU\u4e0a\u5b8c\u5168\u5e76\u884c\u5316", "motivation": "\u4ece\u5355\u6761\u79bb\u6563\u4e8b\u4ef6\u5e8f\u5217\uff08\u5982\u8f66\u8f86\u65e5\u5fd7\u3001\u5236\u9020\u7cfb\u7edf\u3001\u60a3\u8005\u8f68\u8ff9\uff09\u4e2d\u53d1\u73b0\u56e0\u679c\u5173\u7cfb\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u91cd\u590d\u6837\u672c\u3001\u9ad8\u7ef4\u5ea6\u548c\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56", "method": "TRACE\u6846\u67b6\u5c06\u81ea\u56de\u5f52\u6a21\u578b\u91cd\u65b0\u7528\u4f5c\u9884\u8bad\u7ec3\u5bc6\u5ea6\u4f30\u8ba1\u5668\u8fdb\u884c\u6761\u4ef6\u4e92\u4fe1\u606f\u4f30\u8ba1\uff0c\u63a8\u65ad\u4e8b\u4ef6\u7c7b\u578b\u95f4\u7684\u6458\u8981\u56e0\u679c\u56fe\uff0c\u652f\u6301\u5ef6\u8fdf\u56e0\u679c\u6548\u5e94\uff0c\u5728GPU\u4e0a\u5b8c\u5168\u5e76\u884c\u5316", "result": "\u5b9e\u9a8c\u663e\u793aTRACE\u5728\u4e0d\u540c\u57fa\u7ebf\u548c\u4e0d\u540c\u8bcd\u6c47\u91cf\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u5305\u62ec\u5728\u8d85\u8fc729,100\u4e2a\u4e8b\u4ef6\u7c7b\u578b\u7684\u8f66\u8f86\u8bca\u65ad\u6839\u56e0\u5206\u6790\u5e94\u7528\u4e2d", "conclusion": "TRACE\u4e3a\u4ece\u5355\u6761\u79bb\u6563\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7406\u8bba\u53ef\u8bc6\u522b\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u90fd\u8868\u73b0\u51fa\u8272"}}
{"id": "2602.01136", "categories": ["cs.LG", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.01136", "abs": "https://arxiv.org/abs/2602.01136", "authors": ["Ronald Katende"], "title": "A Unified Matrix-Spectral Framework for Stability and Interpretability in Deep Learning", "comment": "11 pages", "summary": "We develop a unified matrix-spectral framework for analyzing stability and interpretability in deep neural networks. Representing networks as data-dependent products of linear operators reveals spectral quantities governing sensitivity to input perturbations, label noise, and training dynamics.\n  We introduce a Global Matrix Stability Index that aggregates spectral information from Jacobians, parameter gradients, Neural Tangent Kernel operators, and loss Hessians into a single stability scale controlling forward sensitivity, attribution robustness, and optimization conditioning. We further show that spectral entropy refines classical operator-norm bounds by capturing typical, rather than purely worst-case, sensitivity.\n  These quantities yield computable diagnostics and stability-oriented regularization principles. Synthetic experiments and controlled studies on MNIST, CIFAR-10, and CIFAR-100 confirm that modest spectral regularization substantially improves attribution stability even when global spectral summaries change little.\n  The results establish a precise connection between spectral concentration and analytic stability, providing practical guidance for robustness-aware model design and training.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7684\u77e9\u9635\u8c31\u6846\u67b6\u5206\u6790\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7a33\u5b9a\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u5168\u5c40\u77e9\u9635\u7a33\u5b9a\u6027\u6307\u6570\u805a\u5408\u8c31\u4fe1\u606f\uff0c\u8bc1\u660e\u8c31\u71b5\u80fd\u6355\u6349\u5178\u578b\u654f\u611f\u6027\u800c\u975e\u6700\u574f\u60c5\u51b5\uff0c\u5b9e\u9a8c\u663e\u793a\u9002\u5ea6\u8c31\u6b63\u5219\u5316\u663e\u8457\u63d0\u5347\u5f52\u56e0\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u7a33\u5b9a\u6027\u5206\u6790\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\uff0c\u96be\u4ee5\u540c\u65f6\u5904\u7406\u8f93\u5165\u6270\u52a8\u3001\u6807\u7b7e\u566a\u58f0\u548c\u8bad\u7ec3\u52a8\u6001\u7684\u654f\u611f\u6027\u3002\u9700\u8981\u5efa\u7acb\u8fde\u63a5\u8c31\u7279\u6027\u4e0e\u7f51\u7edc\u5206\u6790\u7a33\u5b9a\u6027\u7684\u7cbe\u786e\u5173\u7cfb\uff0c\u4e3a\u9c81\u68d2\u6027\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u5c06\u7f51\u7edc\u8868\u793a\u4e3a\u6570\u636e\u4f9d\u8d56\u7684\u7ebf\u6027\u7b97\u5b50\u4e58\u79ef\uff0c\u5f15\u5165\u5168\u5c40\u77e9\u9635\u7a33\u5b9a\u6027\u6307\u6570\u805a\u5408\u96c5\u53ef\u6bd4\u77e9\u9635\u3001\u53c2\u6570\u68af\u5ea6\u3001\u795e\u7ecf\u6b63\u5207\u6838\u7b97\u5b50\u548c\u635f\u5931\u6d77\u68ee\u77e9\u9635\u7684\u8c31\u4fe1\u606f\u3002\u4f7f\u7528\u8c31\u71b5\u7ec6\u5316\u7ecf\u5178\u7b97\u5b50\u8303\u6570\u754c\uff0c\u6355\u6349\u5178\u578b\u654f\u611f\u6027\u800c\u975e\u6700\u574f\u60c5\u51b5\u3002", "result": "\u5728MNIST\u3001CIFAR-10\u548cCIFAR-100\u4e0a\u7684\u5408\u6210\u5b9e\u9a8c\u548c\u5bf9\u7167\u7814\u7a76\u8868\u660e\uff0c\u9002\u5ea6\u8c31\u6b63\u5219\u5316\u5373\u4f7f\u5168\u5c40\u8c31\u6458\u8981\u53d8\u5316\u4e0d\u5927\uff0c\u4e5f\u80fd\u663e\u8457\u6539\u5584\u5f52\u56e0\u7a33\u5b9a\u6027\u3002\u5efa\u7acb\u4e86\u8c31\u96c6\u4e2d\u5ea6\u4e0e\u5206\u6790\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u7cbe\u786e\u8054\u7cfb\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9c81\u68d2\u6027\u611f\u77e5\u7684\u6a21\u578b\u8bbe\u8ba1\u548c\u8bad\u7ec3\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u8bc1\u660e\u4e86\u8c31\u7279\u6027\u5728\u63a7\u5236\u524d\u5411\u654f\u611f\u6027\u3001\u5f52\u56e0\u9c81\u68d2\u6027\u548c\u4f18\u5316\u6761\u4ef6\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4e3a\u6df1\u5ea6\u7f51\u7edc\u7a33\u5b9a\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u8ba1\u7b97\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2602.01137", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01137", "abs": "https://arxiv.org/abs/2602.01137", "authors": ["Shiguang Wu", "Yaqing Wang", "Quanming Yao"], "title": "Self-Generative Adversarial Fine-Tuning for Large Language Models", "comment": null, "summary": "Fine-tuning large language models (LLMs) for alignment typically relies on supervised fine-tuning or reinforcement learning from human feedback, both limited by the cost and scarcity of high-quality annotations. Recent self-play and synthetic data approaches reduce this dependence but often rely on heuristic assumptions or ungrounded self-evaluation, which can cause bias accumulation and performance drift. In this paper, we propose Self-Generative Adversarial LLM (SGALM), a unified fine-tuning framework that formulates alignment as a generative adversarial game within a single LLM. SGALM jointly evolves generation and discrimination capabilities without external reward models. Theoretical and empirical results demonstrate that SGALM achieves state-of-the-art performance, serves as an effective alignment algorithm and a robust synthetic data engine.", "AI": {"tldr": "SGALM\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5bf9\u6297\u6e38\u620f\u7684\u81ea\u5bf9\u9f50\u6846\u67b6\uff0c\u5728\u5355\u4e2aLLM\u5185\u8054\u5408\u8fdb\u5316\u751f\u6210\u548c\u5224\u522b\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u5956\u52b1\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u5bf9\u9f50\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u6216\u5b58\u5728\u504f\u89c1\u79ef\u7d2f\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u5916\u90e8\u9ad8\u8d28\u91cf\u6807\u6ce8\u7684\u81ea\u5bf9\u9f50\u6846\u67b6\u3002", "method": "\u63d0\u51faSGALM\u6846\u67b6\uff0c\u5c06\u5bf9\u9f50\u95ee\u9898\u5efa\u6a21\u4e3a\u5355\u4e2aLLM\u5185\u90e8\u7684\u751f\u6210\u5bf9\u6297\u6e38\u620f\uff0c\u8054\u5408\u8bad\u7ec3\u751f\u6210\u5668\u548c\u5224\u522b\u5668\uff0c\u65e0\u9700\u5916\u90e8\u5956\u52b1\u6a21\u578b\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u5747\u8868\u660eSGALM\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u65e2\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u5bf9\u9f50\u7b97\u6cd5\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u7a33\u5065\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5f15\u64ce\u3002", "conclusion": "SGALM\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u81ea\u5bf9\u9f50\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u9ad8\u8d28\u91cf\u6807\u6ce8\u7684\u4f9d\u8d56\u548c\u504f\u89c1\u79ef\u7d2f\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u5b9e\u7528\u6027\u4e0a\u5747\u6709\u4f18\u52bf\u3002"}}
{"id": "2602.01139", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01139", "abs": "https://arxiv.org/abs/2602.01139", "authors": ["Yassine Abbahaddou"], "title": "Key Principles of Graph Machine Learning: Representation, Robustness, and Generalization", "comment": "PhD Thesis", "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning representations from structured data. Despite their growing popularity and success across various applications, GNNs encounter several challenges that limit their performance. in their generalization, robustness to adversarial perturbations, and the effectiveness of their representation learning capabilities. In this dissertation, I investigate these core aspects through three main contributions: (1) developing new representation learning techniques based on Graph Shift Operators (GSOs, aiming for enhanced performance across various contexts and applications, (2) introducing generalization-enhancing methods through graph data augmentation, and (3) developing more robust GNNs by leveraging orthonormalization techniques and noise-based defenses against adversarial attacks. By addressing these challenges, my work provides a more principled understanding of the limitations and potential of GNNs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6cdb\u5316\u6027\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u8868\u793a\u5b66\u4e60\u65b9\u9762\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u79fb\u4f4d\u7b97\u5b50\u7684\u8868\u793a\u5b66\u4e60\u3001\u56fe\u6570\u636e\u589e\u5f3a\u548c\u6b63\u4ea4\u5316\u9632\u5fa1\u4e09\u9879\u4e3b\u8981\u8d21\u732e\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u6cdb\u5316\u6027\u3001\u5bf9\u6297\u653b\u51fb\u9c81\u68d2\u6027\u548c\u8868\u793a\u5b66\u4e60\u6548\u679c\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u6838\u5fc3\u6311\u6218\u3002", "method": "1) \u57fa\u4e8e\u56fe\u79fb\u4f4d\u7b97\u5b50\u5f00\u53d1\u65b0\u7684\u8868\u793a\u5b66\u4e60\u6280\u672f\uff1b2) \u901a\u8fc7\u56fe\u6570\u636e\u589e\u5f3a\u5f15\u5165\u589e\u5f3a\u6cdb\u5316\u7684\u65b9\u6cd5\uff1b3) \u5229\u7528\u6b63\u4ea4\u5316\u6280\u672f\u548c\u57fa\u4e8e\u566a\u58f0\u7684\u9632\u5fa1\u673a\u5236\u5f00\u53d1\u66f4\u9c81\u68d2\u7684GNN\u5bf9\u6297\u653b\u51fb\u9632\u5fa1\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u6539\u8fdb\u7684\u8868\u793a\u5b66\u4e60\u6846\u67b6\u3001\u589e\u5f3a\u6cdb\u5316\u6027\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u4ee5\u53ca\u63d0\u9ad8\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u9632\u5fa1\u673a\u5236\uff0c\u4e3aGNN\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u66f4\u539f\u5219\u6027\u7684\u7406\u89e3\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3GNN\u5728\u6cdb\u5316\u3001\u9c81\u68d2\u6027\u548c\u8868\u793a\u5b66\u4e60\u65b9\u9762\u7684\u6838\u5fc3\u6311\u6218\uff0c\u8be5\u7814\u7a76\u4e3a\u7406\u89e3GNN\u7684\u5c40\u9650\u6027\u548c\u6f5c\u529b\u63d0\u4f9b\u4e86\u66f4\u539f\u5219\u6027\u7684\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.01140", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01140", "abs": "https://arxiv.org/abs/2602.01140", "authors": ["Haochen You", "Heng Zhang", "Hongyang He", "Yuqi Li", "Baojing Liu"], "title": "Generalized Radius and Integrated Codebook Transforms for Differentiable Vector Quantization", "comment": "This paper has been accepted as a conference paper at CPAL 2026", "summary": "Vector quantization (VQ) underpins modern generative and representation models by turning continuous latents into discrete tokens. Yet hard nearest-neighbor assignments are non-differentiable and are typically optimized with heuristic straight-through estimators, which couple the update step size to the quantization gap and train each code in isolation, leading to unstable gradients and severe codebook under-utilization at scale. In this paper, we introduce GRIT-VQ (Generalized Radius and Integrated Transform-Vector Quantization), a unified surrogate framework that keeps hard assignments in the forward pass while making VQ fully differentiable. GRIT-VQ replaces the straight-through estimator with a radius-based update that moves latents along the quantization direction with a controllable, geometry-aware step, and applies a data-agnostic integrated transform to the codebook so that all codes are updated through shared parameters instead of independently. Our theoretical analysis clarifies the fundamental optimization dynamics introduced by GRIT-VQ, establishing conditions for stable gradient flow, coordinated codebook evolution, and reliable avoidance of collapse across a broad family of quantizers. Across image reconstruction, image generation, and recommendation tokenization benchmarks, GRIT-VQ consistently improves reconstruction error, generative quality, and recommendation accuracy while substantially increasing codebook utilization compared to existing VQ variants.", "AI": {"tldr": "GRIT-VQ\u662f\u4e00\u79cd\u65b0\u578b\u5411\u91cf\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u534a\u5f84\u66f4\u65b0\u548c\u96c6\u6210\u53d8\u6362\u4f7f\u786c\u5206\u914d\u53ef\u5fae\u5206\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfVQ\u7684\u68af\u5ea6\u4e0d\u7a33\u5b9a\u548c\u7801\u672c\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5411\u91cf\u91cf\u5316(VQ)\u4f7f\u7528\u786c\u6700\u8fd1\u90bb\u5206\u914d\uff0c\u8fd9\u662f\u4e0d\u53ef\u5fae\u5206\u7684\uff0c\u901a\u5e38\u7528\u542f\u53d1\u5f0f\u76f4\u901a\u4f30\u8ba1\u5668\u4f18\u5316\u3002\u8fd9\u79cd\u65b9\u6cd5\u5c06\u66f4\u65b0\u6b65\u957f\u4e0e\u91cf\u5316\u95f4\u9699\u8026\u5408\uff0c\u5e76\u72ec\u7acb\u8bad\u7ec3\u6bcf\u4e2a\u7801\u5b57\uff0c\u5bfc\u81f4\u68af\u5ea6\u4e0d\u7a33\u5b9a\u548c\u5927\u89c4\u6a21\u7801\u672c\u5229\u7528\u7387\u4e25\u91cd\u4e0d\u8db3\u3002", "method": "GRIT-VQ\u5728\u6b63\u5411\u4f20\u64ad\u4e2d\u4fdd\u6301\u786c\u5206\u914d\uff0c\u4f46\u901a\u8fc7\u534a\u5f84\u66f4\u65b0\u548c\u96c6\u6210\u53d8\u6362\u4f7fVQ\u5b8c\u5168\u53ef\u5fae\u5206\u3002\u534a\u5f84\u66f4\u65b0\u6cbf\u91cf\u5316\u65b9\u5411\u4ee5\u53ef\u63a7\u7684\u51e0\u4f55\u611f\u77e5\u6b65\u957f\u79fb\u52a8\u6f5c\u5728\u8868\u793a\uff1b\u96c6\u6210\u53d8\u6362\u5bf9\u7801\u672c\u5e94\u7528\u6570\u636e\u65e0\u5173\u7684\u53d8\u6362\uff0c\u4f7f\u6240\u6709\u7801\u5b57\u901a\u8fc7\u5171\u4eab\u53c2\u6570\u66f4\u65b0\u800c\u975e\u72ec\u7acb\u66f4\u65b0\u3002", "result": "\u5728\u56fe\u50cf\u91cd\u5efa\u3001\u56fe\u50cf\u751f\u6210\u548c\u63a8\u8350\u7cfb\u7edf\u6807\u8bb0\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGRIT-VQ\u76f8\u6bd4\u73b0\u6709VQ\u53d8\u4f53\uff0c\u6301\u7eed\u6539\u5584\u4e86\u91cd\u5efa\u8bef\u5dee\u3001\u751f\u6210\u8d28\u91cf\u548c\u63a8\u8350\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u7801\u672c\u5229\u7528\u7387\u3002", "conclusion": "GRIT-VQ\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u66ff\u4ee3\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfVQ\u7684\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u9610\u660e\u4e86\u5176\u4f18\u5316\u52a8\u6001\uff0c\u4e3a\u7a33\u5b9a\u68af\u5ea6\u6d41\u3001\u534f\u8c03\u7801\u672c\u6f14\u5316\u548c\u907f\u514d\u5d29\u6e83\u63d0\u4f9b\u4e86\u6761\u4ef6\u3002"}}
{"id": "2602.01150", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.01150", "abs": "https://arxiv.org/abs/2602.01150", "authors": ["Jialong Sun", "Zeming Wei", "Jiaxuan Zou", "Jiacheng Gong", "Guanheng Wang", "Chengyang Dong", "Jialong Li", "Bo Liu"], "title": "Statistical MIA: Rethinking Membership Inference Attack for Reliable Unlearning Auditing", "comment": null, "summary": "Machine unlearning (MU) is essential for enforcing the right to be forgotten in machine learning systems. A key challenge of MU is how to reliably audit whether a model has truly forgotten specified training data. Membership Inference Attacks (MIAs) are widely used for unlearning auditing, where samples that evade membership detection are often regarded as successfully forgotten. After carefully revisiting the reliability of MIA, we show that this assumption is flawed: failed membership inference does not imply true forgetting. We theoretically demonstrate that MIA-based auditing, when formulated as a binary classification problem, inevitably incurs statistical errors whose magnitude cannot be observed during the auditing process. This leads to overly optimistic evaluations of unlearning performance, while incurring substantial computational overhead due to shadow model training. To address these limitations, we propose Statistical Membership Inference Attack (SMIA), a novel training-free and highly effective auditing framework. SMIA directly compares the distributions of member and non-member data using statistical tests, eliminating the need for learned attack models. Moreover, SMIA outputs both a forgetting rate and a corresponding confidence interval, enabling quantified reliability of the auditing results. Extensive experiments show that SMIA provides more reliable auditing with significantly lower computational cost than existing MIA-based approaches. Notably, the theoretical guarantees and empirical effectiveness of SMIA suggest it as a new paradigm for reliable machine unlearning auditing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSMIA\uff08\u7edf\u8ba1\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff09\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u7edf\u8ba1\u68c0\u9a8c\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u5ba1\u8ba1\u65b0\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMIA\u65b9\u6cd5\u53ef\u9760\u6027\u4e0d\u8db3\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u5ba1\u8ba1\u4e3b\u8981\u4f9d\u8d56\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff08MIA\uff09\uff0c\u4f46MIA\u5b58\u5728\u6839\u672c\u7f3a\u9677\uff1a\u6210\u5458\u63a8\u65ad\u5931\u8d25\u5e76\u4e0d\u7b49\u540c\u4e8e\u771f\u6b63\u9057\u5fd8\uff0c\u4e14\u4f1a\u4ea7\u751f\u65e0\u6cd5\u89c2\u6d4b\u7684\u7edf\u8ba1\u8bef\u5dee\uff0c\u5bfc\u81f4\u5ba1\u8ba1\u7ed3\u679c\u8fc7\u4e8e\u4e50\u89c2\uff0c\u540c\u65f6\u9700\u8981\u8bad\u7ec3\u5f71\u5b50\u6a21\u578b\u5e26\u6765\u5de8\u5927\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51faSMIA\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u8ba1\u68c0\u9a8c\u76f4\u63a5\u6bd4\u8f83\u6210\u5458\u6570\u636e\u548c\u975e\u6210\u5458\u6570\u636e\u7684\u5206\u5e03\u5dee\u5f02\uff0c\u65e0\u9700\u8bad\u7ec3\u653b\u51fb\u6a21\u578b\u3002SMIA\u8f93\u51fa\u9057\u5fd8\u7387\u548c\u7f6e\u4fe1\u533a\u95f4\uff0c\u63d0\u4f9b\u53ef\u91cf\u5316\u7684\u5ba1\u8ba1\u53ef\u9760\u6027\u8bc4\u4f30\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSMIA\u6bd4\u73b0\u6709MIA\u65b9\u6cd5\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u5ba1\u8ba1\u7ed3\u679c\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002SMIA\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8bc1\u6548\u679c\u8868\u660e\u5176\u53ef\u4f5c\u4e3a\u53ef\u9760\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u5ba1\u8ba1\u7684\u65b0\u8303\u5f0f\u3002", "conclusion": "SMIA\u901a\u8fc7\u7edf\u8ba1\u68c0\u9a8c\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edfMIA\u5ba1\u8ba1\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u8bad\u7ec3\u514d\u8d39\u3001\u9ad8\u6548\u53ef\u9760\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u5ba1\u8ba1\u6846\u67b6\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.01156", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01156", "abs": "https://arxiv.org/abs/2602.01156", "authors": ["Shunpeng Yang", "Ben Liu", "Hua Chen"], "title": "PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning", "comment": "Submitted to ICLR 2026", "summary": "Among on-policy reinforcement learning algorithms, Proximal Policy Optimization (PPO) demonstrates is widely favored for its simplicity, numerical stability, and strong empirical performance. Standard PPO relies on surrogate objectives defined via importance ratios, which require evaluating policy likelihood that is typically straightforward when the policy is modeled as a Gaussian distribution. However, extending PPO to more expressive, high-capacity policy models such as continuous normalizing flows (CNFs), also known as flow-matching models, is challenging because likelihood evaluation along the full flow trajectory is computationally expensive and often numerically unstable. To resolve this issue, we propose PolicyFlow, a novel on-policy CNF-based reinforcement learning algorithm that integrates expressive CNF policies with PPO-style objectives without requiring likelihood evaluation along the full flow path. PolicyFlow approximates importance ratios using velocity field variations along a simple interpolation path, reducing computational overhead without compromising training stability. To further prevent mode collapse and further encourage diverse behaviors, we propose the Brownian Regularizer, an implicit policy entropy regularizer inspired by Brownian motion, which is conceptually elegant and computationally lightweight. Experiments on diverse tasks across various environments including MultiGoal, PointMaze, IsaacLab and MuJoCo Playground show that PolicyFlow achieves competitive or superior performance compared to PPO using Gaussian policies and flow-based baselines including FPO and DPPO. Notably, results on MultiGoal highlight PolicyFlow's ability to capture richer multimodal action distributions.", "AI": {"tldr": "PolicyFlow\uff1a\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\uff08CNF\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u8fd1\u4f3c\u91cd\u8981\u6027\u6bd4\u7387\u907f\u514d\u6602\u8d35\u7684\u5168\u6d41\u8f68\u8ff9\u4f3c\u7136\u8bc4\u4f30\uff0c\u7ed3\u5408\u5e03\u6717\u6b63\u5219\u5668\u9632\u6b62\u6a21\u5f0f\u5d29\u6e83\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u6807\u51c6PPO\u548c\u9ad8\u65af\u7b56\u7565\u3002", "motivation": "\u6807\u51c6PPO\u4f9d\u8d56\u91cd\u8981\u6027\u6bd4\u7387\uff0c\u9700\u8981\u8bc4\u4f30\u7b56\u7565\u4f3c\u7136\uff0c\u5bf9\u4e8e\u9ad8\u65af\u5206\u5e03\u7b56\u7565\u7b80\u5355\u76f4\u63a5\u3002\u4f46\u5f53\u4f7f\u7528\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u7684\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\uff08CNF\uff09\u4f5c\u4e3a\u7b56\u7565\u6a21\u578b\u65f6\uff0c\u8bc4\u4f30\u5168\u6d41\u8f68\u8ff9\u7684\u4f3c\u7136\u8ba1\u7b97\u6602\u8d35\u4e14\u6570\u503c\u4e0d\u7a33\u5b9a\uff0c\u9650\u5236\u4e86PPO\u4e0e\u9ad8\u5bb9\u91cf\u7b56\u7565\u6a21\u578b\u7684\u7ed3\u5408\u3002", "method": "\u63d0\u51faPolicyFlow\u7b97\u6cd5\uff1a1\uff09\u901a\u8fc7\u901f\u5ea6\u573a\u53d8\u5316\u6cbf\u7b80\u5355\u63d2\u503c\u8def\u5f84\u8fd1\u4f3c\u91cd\u8981\u6027\u6bd4\u7387\uff0c\u907f\u514d\u5168\u6d41\u8f68\u8ff9\u7684\u4f3c\u7136\u8bc4\u4f30\uff1b2\uff09\u5f15\u5165\u5e03\u6717\u6b63\u5219\u5668\uff0c\u53d7\u5e03\u6717\u8fd0\u52a8\u542f\u53d1\uff0c\u4f5c\u4e3a\u9690\u5f0f\u7b56\u7565\u71b5\u6b63\u5219\u5668\uff0c\u9632\u6b62\u6a21\u5f0f\u5d29\u6e83\u5e76\u9f13\u52b1\u884c\u4e3a\u591a\u6837\u6027\u3002", "result": "\u5728MultiGoal\u3001PointMaze\u3001IsaacLab\u548cMuJoCo Playground\u7b49\u591a\u79cd\u73af\u5883\u4efb\u52a1\u4e0a\uff0cPolicyFlow\u76f8\u6bd4\u4f7f\u7528\u9ad8\u65af\u7b56\u7565\u7684PPO\u4ee5\u53caFPO\u3001DPPO\u7b49\u6d41\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002\u7279\u522b\u662f\u5728MultiGoal\u4efb\u52a1\u4e0a\uff0cPolicyFlow\u5c55\u73b0\u4e86\u6355\u6349\u66f4\u4e30\u5bcc\u591a\u6a21\u6001\u52a8\u4f5c\u5206\u5e03\u7684\u80fd\u529b\u3002", "conclusion": "PolicyFlow\u6210\u529f\u5c06\u8868\u8fbe\u80fd\u529b\u5f3a\u7684CNF\u7b56\u7565\u4e0ePPO\u5f0f\u76ee\u6807\u7ed3\u5408\uff0c\u901a\u8fc7\u8fd1\u4f3c\u91cd\u8981\u6027\u6bd4\u7387\u548c\u5e03\u6717\u6b63\u5219\u5668\u89e3\u51b3\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u9ad8\u5bb9\u91cf\u7b56\u7565\u6a21\u578b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.01157", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01157", "abs": "https://arxiv.org/abs/2602.01157", "authors": ["Mohammed Osman Gani", "Zhipeng He", "Chun Ouyang", "Sara Khalifa"], "title": "Multi-Horizon Electricity Price Forecasting with Deep Learning in the Australian National Electricity Market", "comment": "63 Pages", "summary": "Accurate electricity price forecasting (EPF) is essential for operational planning, trading, and flexible asset scheduling in liberalised power systems, yet remains challenging due to volatility, heavy-tailed spikes, and frequent regime shifts. While deep learning (DL) has been increasingly adopted in EPF to capture complex and nonlinear price dynamics, several important gaps persist: (i) limited attention to multi-day horizons beyond day-ahead forecasting, (ii) insufficient exploration of state-of-the-art (SOTA) time series DL models, and (iii) a predominant reliance on aggregated horizon-level evaluation that obscures time-of-day forecasting variation. To address these gaps, we propose a novel EPF framework that extends the forecast horizon to multi-day-ahead by systematically building forecasting models that leverage benchmarked SOTA time series DL models. We conduct a comprehensive evaluation to analyse time-of-day forecasting performance by integrating model assessment at intraday interval levels across all five regions in the Australian National Electricity Market (NEM). The results show that no single model consistently dominates across regions, metrics, and horizons. Overall, standard DL models deliver superior performance in most regions, while SOTA time series DL models demonstrate greater robustness to forecast horizon extension. Intraday interval-level evaluation reveals pronounced diurnal error patterns, indicating that absolute errors peak during the evening ramp, relative errors inflate during midday negative-price regimes, and directional accuracy degrades during periods of frequent trend changes. These findings suggest that future research on DL-based EPF can benefit from enriched feature representations and modelling strategies that enhance longer-term forecasting robustness while maintaining sensitivity to intraday volatility and structural price dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u65e5\u524d\u7535\u4ef7\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u6fb3\u5927\u5229\u4e9a\u7535\u529b\u5e02\u573a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u53d1\u73b0\u6807\u51c6DL\u6a21\u578b\u5728\u591a\u6570\u5730\u533a\u8868\u73b0\u66f4\u597d\uff0c\u800cSOTA\u65f6\u95f4\u5e8f\u5217DL\u6a21\u578b\u5bf9\u9884\u6d4b\u65f6\u57df\u6269\u5c55\u66f4\u5177\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u7535\u4ef7\u9884\u6d4b\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u5bf9\u591a\u65e5\u9884\u6d4b\u65f6\u57df\u5173\u6ce8\u6709\u9650\uff1b2) \u5bf9\u6700\u5148\u8fdb\u65f6\u95f4\u5e8f\u5217\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63a2\u7d22\u4e0d\u8db3\uff1b3) \u8fc7\u5ea6\u4f9d\u8d56\u805a\u5408\u65f6\u57df\u8bc4\u4f30\uff0c\u63a9\u76d6\u4e86\u65e5\u5185\u9884\u6d4b\u5dee\u5f02\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u5dee\u8ddd\u4ee5\u63d0\u5347\u7535\u4ef7\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u7535\u4ef7\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u65f6\u57df\u6269\u5c55\u5230\u591a\u65e5\u524d\uff0c\u7cfb\u7edf\u6784\u5efa\u57fa\u4e8e\u57fa\u51c6SOTA\u65f6\u95f4\u5e8f\u5217\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u6a21\u578b\u3002\u5728\u6fb3\u5927\u5229\u4e9a\u56fd\u5bb6\u7535\u529b\u5e02\u573a\u4e94\u4e2a\u533a\u57df\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u5206\u6790\u65e5\u5185\u65f6\u6bb5\u9884\u6d4b\u6027\u80fd\uff0c\u6574\u5408\u6a21\u578b\u5728\u65e5\u5185\u95f4\u9694\u6c34\u5e73\u7684\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1) \u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u533a\u57df\u3001\u6307\u6807\u548c\u65f6\u57df\u4e2d\u59cb\u7ec8\u5360\u4f18\uff1b2) \u6807\u51c6DL\u6a21\u578b\u5728\u591a\u6570\u5730\u533a\u8868\u73b0\u66f4\u4f18\uff1b3) SOTA\u65f6\u95f4\u5e8f\u5217DL\u6a21\u578b\u5bf9\u9884\u6d4b\u65f6\u57df\u6269\u5c55\u66f4\u5177\u9c81\u68d2\u6027\uff1b4) \u65e5\u5185\u95f4\u9694\u8bc4\u4f30\u63ed\u793a\u4e86\u660e\u663e\u7684\u663c\u591c\u8bef\u5dee\u6a21\u5f0f\uff1a\u7edd\u5bf9\u8bef\u5dee\u5728\u665a\u95f4\u722c\u5761\u671f\u8fbe\u5230\u5cf0\u503c\uff0c\u76f8\u5bf9\u8bef\u5dee\u5728\u5348\u95f4\u8d1f\u7535\u4ef7\u65f6\u6bb5\u81a8\u80c0\uff0c\u65b9\u5411\u51c6\u786e\u6027\u5728\u8d8b\u52bf\u9891\u7e41\u53d8\u5316\u671f\u95f4\u4e0b\u964d\u3002", "conclusion": "\u672a\u6765\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7535\u4ef7\u9884\u6d4b\u7814\u7a76\u53ef\u4ee5\u4ece\u4e30\u5bcc\u7684\u7279\u5f81\u8868\u793a\u548c\u5efa\u6a21\u7b56\u7565\u4e2d\u53d7\u76ca\uff0c\u8fd9\u4e9b\u7b56\u7565\u5e94\u589e\u5f3a\u957f\u671f\u9884\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u65e5\u5185\u6ce2\u52a8\u548c\u7ed3\u6784\u6027\u4ef7\u683c\u52a8\u6001\u7684\u654f\u611f\u6027\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u8003\u8651\u591a\u65e5\u9884\u6d4b\u65f6\u57df\u548c\u65e5\u5185\u9884\u6d4b\u5dee\u5f02\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.01176", "categories": ["cs.LG", "math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.01176", "abs": "https://arxiv.org/abs/2602.01176", "authors": ["Olaf Yunus Laitinen Imanov"], "title": "Multi-Fidelity Physics-Informed Neural Networks with Bayesian Uncertainty Quantification and Adaptive Residual Learning for Efficient Solution of Parametric Partial Differential Equations", "comment": "8 pages, 4 figures, 6 tables", "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful paradigm for solving partial differential equations (PDEs) by embedding physical laws directly into neural network training. However, solving high-fidelity PDEs remains computationally prohibitive, particularly for parametric systems requiring multiple evaluations across varying parameter configurations. This paper presents MF-BPINN, a novel multi-fidelity framework that synergistically combines physics-informed neural networks with Bayesian uncertainty quantification and adaptive residual learning. Our approach leverages abundant low-fidelity simulations alongside sparse high-fidelity data through a hierarchical neural architecture that learns nonlinear correlations across fidelity levels. We introduce an adaptive residual network with learnable gating mechanisms that dynamically balances linear and nonlinear fidelity discrepancies. Furthermore, we develop a rigorous Bayesian framework employing Hamiltonian Monte Carlo.", "AI": {"tldr": "MF-BPINN\uff1a\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u3001\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0e\u81ea\u9002\u5e94\u6b8b\u5dee\u5b66\u4e60\u7684\u591a\u4fdd\u771f\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u6c42\u89e3\u53c2\u6570\u5316\u504f\u5fae\u5206\u65b9\u7a0b", "motivation": "\u4f20\u7edf\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u5728\u6c42\u89e3\u9ad8\u4fdd\u771f\u5ea6\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u8de8\u591a\u4e2a\u53c2\u6570\u914d\u7f6e\u8fdb\u884c\u8bc4\u4f30\u7684\u53c2\u6570\u5316\u7cfb\u7edf\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5229\u7528\u4e0d\u540c\u4fdd\u771f\u5ea6\u7ea7\u522b\u7684\u6570\u636e\u8d44\u6e90\u3002", "method": "\u63d0\u51faMF-BPINN\u6846\u67b6\uff1a1\uff09\u91c7\u7528\u5206\u5c42\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b66\u4e60\u8de8\u4fdd\u771f\u5ea6\u7ea7\u522b\u7684\u975e\u7ebf\u6027\u76f8\u5173\u6027\uff1b2\uff09\u5f15\u5165\u5177\u6709\u53ef\u5b66\u4e60\u95e8\u63a7\u673a\u5236\u7684\u81ea\u9002\u5e94\u6b8b\u5dee\u7f51\u7edc\uff0c\u52a8\u6001\u5e73\u8861\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u4fdd\u771f\u5ea6\u5dee\u5f02\uff1b3\uff09\u5f00\u53d1\u57fa\u4e8e\u54c8\u5bc6\u987f\u8499\u7279\u5361\u6d1b\u7684\u4e25\u683c\u8d1d\u53f6\u65af\u6846\u67b6\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u534f\u540c\u5229\u7528\u4e30\u5bcc\u7684\u4f4e\u4fdd\u771f\u5ea6\u6a21\u62df\u6570\u636e\u548c\u7a00\u758f\u7684\u9ad8\u4fdd\u771f\u5ea6\u6570\u636e\uff0c\u663e\u8457\u964d\u4f4e\u6c42\u89e3\u9ad8\u4fdd\u771f\u5ea6\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "MF-BPINN\u4e3a\u53c2\u6570\u5316\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u9ad8\u6548\u6c42\u89e3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u591a\u4fdd\u771f\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u3001\u8d1d\u53f6\u65af\u63a8\u7406\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u673a\u5236\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u5b9e\u73b0\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.01179", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01179", "abs": "https://arxiv.org/abs/2602.01179", "authors": ["Zhichao Chen", "Zhan Zhuang", "Yunfei Teng", "Hao Wang", "Fangyikang Wang", "Zhengnan Li", "Tianqiao Liu", "Haoxuan Li", "Zhouchen Lin"], "title": "Rethinking the Flow-Based Gradual Domain Adaption: A Semi-Dual Optimal Transport Perspective", "comment": null, "summary": "Gradual domain adaptation (GDA) aims to mitigate domain shift by progressively adapting models from the source domain to the target domain via intermediate domains. However, real intermediate domains are often unavailable or ineffective, necessitating the synthesis of intermediate samples. Flow-based models have recently been used for this purpose by interpolating between source and target distributions; however, their training typically relies on sample-based log-likelihood estimation, which can discard useful information and thus degrade GDA performance. The key to addressing this limitation is constructing the intermediate domains via samples directly. To this end, we propose an Entropy-regularized Semi-dual Unbalanced Optimal Transport (E-SUOT) framework to construct intermediate domains. Specifically, we reformulate flow-based GDA as a Lagrangian dual problem and derive an equivalent semi-dual objective that circumvents the need for likelihood estimation. However, the dual problem leads to an unstable min-max training procedure. To alleviate this issue, we further introduce entropy regularization to convert it into a more stable alternative optimization procedure. Based on this, we propose a novel GDA training framework and provide theoretical analysis in terms of stability and generalization. Finally, extensive experiments are conducted to demonstrate the efficacy of the E-SUOT framework.", "AI": {"tldr": "\u63d0\u51faE-SUOT\u6846\u67b6\uff0c\u901a\u8fc7\u71b5\u6b63\u5219\u5316\u534a\u5bf9\u5076\u975e\u5e73\u8861\u6700\u4f18\u4f20\u8f93\u6784\u5efa\u4e2d\u95f4\u57df\uff0c\u89e3\u51b3\u57fa\u4e8e\u6d41\u7684\u6e10\u8fdb\u57df\u9002\u5e94\u4e2d\u6837\u672c\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\u3002", "motivation": "\u6e10\u8fdb\u57df\u9002\u5e94\u9700\u8981\u4e2d\u95f4\u57df\u6765\u7f13\u89e3\u57df\u504f\u79fb\uff0c\u4f46\u771f\u5b9e\u4e2d\u95f4\u57df\u5f80\u5f80\u4e0d\u53ef\u5f97\u6216\u65e0\u6548\u3002\u73b0\u6709\u57fa\u4e8e\u6d41\u7684\u65b9\u6cd5\u901a\u8fc7\u63d2\u503c\u6e90\u57df\u548c\u76ee\u6807\u57df\u5206\u5e03\u6765\u5408\u6210\u4e2d\u95f4\u6837\u672c\uff0c\u4f46\u5176\u8bad\u7ec3\u4f9d\u8d56\u6837\u672c\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\uff0c\u8fd9\u4f1a\u4e22\u5f03\u6709\u7528\u4fe1\u606f\uff0c\u964d\u4f4eGDA\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u71b5\u6b63\u5219\u5316\u534a\u5bf9\u5076\u975e\u5e73\u8861\u6700\u4f18\u4f20\u8f93(E-SUOT)\u6846\u67b6\uff1a1)\u5c06\u57fa\u4e8e\u6d41\u7684GDA\u91cd\u65b0\u8868\u8ff0\u4e3a\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u95ee\u9898\uff0c\u63a8\u5bfc\u51fa\u7b49\u4ef7\u534a\u5bf9\u5076\u76ee\u6807\uff0c\u907f\u514d\u4f3c\u7136\u4f30\u8ba1\uff1b2)\u5f15\u5165\u71b5\u6b63\u5219\u5316\u5c06\u5bf9\u5076\u95ee\u9898\u7684\u4e0d\u7a33\u5b9amin-max\u8bad\u7ec3\u8f6c\u6362\u4e3a\u66f4\u7a33\u5b9a\u7684\u4ea4\u66ff\u4f18\u5316\u8fc7\u7a0b\uff1b3)\u57fa\u4e8e\u6b64\u63d0\u51fa\u65b0\u7684GDA\u8bad\u7ec3\u6846\u67b6\u3002", "result": "\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86E-SUOT\u6846\u67b6\u7684\u6709\u6548\u6027\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u5173\u4e8e\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u6027\u7684\u7406\u8bba\u5206\u6790\u3002", "conclusion": "E-SUOT\u6846\u67b6\u901a\u8fc7\u71b5\u6b63\u5219\u5316\u534a\u5bf9\u5076\u975e\u5e73\u8861\u6700\u4f18\u4f20\u8f93\u6709\u6548\u6784\u5efa\u4e2d\u95f4\u57df\uff0c\u89e3\u51b3\u4e86\u57fa\u4e8e\u6d41\u7684\u6e10\u8fdb\u57df\u9002\u5e94\u4e2d\u6837\u672c\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u5bfc\u81f4\u7684\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u63d0\u5347\u4e86GDA\u6027\u80fd\u3002"}}
{"id": "2602.01182", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01182", "abs": "https://arxiv.org/abs/2602.01182", "authors": ["Zhichao Chen", "Hao Wang", "Fangyikang Wang", "Licheng Pan", "Zhengnan Li", "Yunfei Teng", "Haoxuan Li", "Zhouchen Lin"], "title": "Analyzing and Improving Diffusion Models for Time-Series Data Imputation: A Proximal Recursion Perspective", "comment": null, "summary": "Diffusion models (DMs) have shown promise for Time-Series Data Imputation (TSDI); however, their performance remains inconsistent in complex scenarios. We attribute this to two primary obstacles: (1) non-stationary temporal dynamics, which can bias the inference trajectory and lead to outlier-sensitive imputations; and (2) objective inconsistency, since imputation favors accurate pointwise recovery whereas DMs are inherently trained to generate diverse samples. To better understand these issues, we analyze DM-based TSDI process through a proximal-operator perspective and uncover that an implicit Wasserstein distance regularization inherent in the process hinders the model's ability to counteract non-stationarity and dissipative regularizer, thereby amplifying diversity at the expense of fidelity. Building on this insight, we propose a novel framework called SPIRIT (Semi-Proximal Transport Regularized time-series Imputation). Specifically, we introduce entropy-induced Bregman divergence to relax the mass preserving constraint in the Wasserstein distance, formulate the semi-proximal transport (SPT) discrepancy, and theoretically prove the robustness of SPT against non-stationarity. Subsequently, we remove the dissipative structure and derive the complete SPIRIT workflow, with SPT serving as the proximal operator. Extensive experiments demonstrate the effectiveness of the proposed SPIRIT approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSPIRIT\u6846\u67b6\uff0c\u901a\u8fc7\u534a\u8fd1\u7aef\u4f20\u8f93\u6b63\u5219\u5316\u89e3\u51b3\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u63d2\u8865\u4e2d\u7684\u975e\u5e73\u7a33\u6027\u548c\u76ee\u6807\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u9ad8\u63d2\u8865\u51c6\u786e\u6027\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u63d2\u8865\u4e2d\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u4e3b\u8981\u9762\u4e34\u4e24\u4e2a\u969c\u788d\uff1a1) \u975e\u5e73\u7a33\u65f6\u95f4\u52a8\u6001\u5bfc\u81f4\u63a8\u65ad\u8f68\u8ff9\u504f\u5dee\u548c\u5f02\u5e38\u503c\u654f\u611f\uff1b2) \u76ee\u6807\u4e0d\u4e00\u81f4\u6027\uff0c\u63d2\u8865\u9700\u8981\u51c6\u786e\u70b9\u6062\u590d\u800c\u6269\u6563\u6a21\u578b\u672c\u8d28\u751f\u6210\u591a\u6837\u6837\u672c\u3002", "method": "\u4ece\u8fd1\u7aef\u7b97\u5b50\u89d2\u5ea6\u5206\u6790\u6269\u6563\u6a21\u578b\u63d2\u8865\u8fc7\u7a0b\uff0c\u63d0\u51faSPIRIT\u6846\u67b6\uff1a\u5f15\u5165\u71b5\u8bf1\u5bfcBregman\u6563\u5ea6\u677e\u5f1bWasserstein\u8ddd\u79bb\u7684\u8d28\u91cf\u4fdd\u6301\u7ea6\u675f\uff0c\u6784\u5efa\u534a\u8fd1\u7aef\u4f20\u8f93\u5dee\u5f02\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u6297\u975e\u5e73\u7a33\u6027\uff0c\u79fb\u9664\u8017\u6563\u7ed3\u6784\u5e76\u5efa\u7acb\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eSPIRIT\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u6269\u6563\u6a21\u578b\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u63d2\u8865\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "SPIRIT\u6846\u67b6\u901a\u8fc7\u534a\u8fd1\u7aef\u4f20\u8f93\u6b63\u5219\u5316\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u63d2\u8865\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.01186", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01186", "abs": "https://arxiv.org/abs/2602.01186", "authors": ["Fabio Turazza", "Marco Picone", "Marco Mamei"], "title": "The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global Statistics", "comment": "Accepted at the International Conference on Learning Representations (ICLR) 2026", "summary": "Classical Federated Learning relies on a multi-round iterative process of model exchange and aggregation between server and clients, with high communication costs and privacy risks from repeated model transmissions. In contrast, one-shot federated learning (OFL) alleviates these limitations by reducing communication to a single round, thereby lowering overhead and enhancing practical deployability. Nevertheless, most existing one-shot approaches remain either impractical or constrained, for example, they often depend on the availability of a public dataset, assume homogeneous client models, or require uploading additional data or model information. To overcome these issues, we introduce the Gaussian-Head OFL (GH-OFL) family, a suite of one-shot federated methods that assume class-conditional Gaussianity of pretrained embeddings. Clients transmit only sufficient statistics (per-class counts and first/second-order moments) and the server builds heads via three components: (i) Closed-form Gaussian heads (NB/LDA/QDA) computed directly from the received statistics; (ii) FisherMix, a linear head with cosine margin trained on synthetic samples drawn in an estimated Fisher subspace; and (iii) Proto-Hyper, a lightweight low-rank residual head that refines Gaussian logits via knowledge distillation on those synthetic samples. In our experiments, GH-OFL methods deliver state-of-the-art robustness and accuracy under strong non-IID skew while remaining strictly data-free.", "AI": {"tldr": "\u63d0\u51faGH-OFL\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u65af\u5047\u8bbe\u548c\u7edf\u8ba1\u4fe1\u606f\u4f20\u8f93\u5b9e\u73b0\u5355\u8f6e\u8054\u90a6\u5b66\u4e60\uff0c\u65e0\u9700\u516c\u5171\u6570\u636e\u96c6\uff0c\u5728\u975eIID\u6570\u636e\u4e0b\u4fdd\u6301\u9ad8\u6027\u80fd", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5b58\u5728\u591a\u8f6e\u901a\u4fe1\u6210\u672c\u9ad8\u548c\u9690\u79c1\u98ce\u9669\u95ee\u9898\uff0c\u73b0\u6709\u5355\u8f6e\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u4e0d\u5b9e\u7528\uff0c\u8981\u4e48\u4f9d\u8d56\u516c\u5171\u6570\u636e\u96c6\u3001\u5047\u8bbe\u540c\u8d28\u6a21\u578b\u6216\u9700\u8981\u4e0a\u4f20\u989d\u5916\u6570\u636e", "method": "\u63d0\u51faGH-OFL\u65b9\u6cd5\u65cf\uff1a\u5ba2\u6237\u7aef\u4ec5\u4f20\u8f93\u7edf\u8ba1\u4fe1\u606f\uff08\u7c7b\u522b\u8ba1\u6570\u548c\u4e00/\u4e8c\u9636\u77e9\uff09\uff0c\u670d\u52a1\u5668\u901a\u8fc7\u4e09\u79cd\u7ec4\u4ef6\u6784\u5efa\u5206\u7c7b\u5934\uff1a1) \u57fa\u4e8e\u7edf\u8ba1\u4fe1\u606f\u7684\u95ed\u5f0f\u9ad8\u65af\u5934\uff1b2) \u5728Fisher\u5b50\u7a7a\u95f4\u751f\u6210\u5408\u6210\u6837\u672c\u8bad\u7ec3\u7684FisherMix\u7ebf\u6027\u5934\uff1b3) \u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u4f18\u5316\u7684Proto-Hyper\u8f7b\u91cf\u6b8b\u5dee\u5934", "result": "GH-OFL\u65b9\u6cd5\u5728\u5f3a\u975eIID\u6570\u636e\u504f\u659c\u4e0b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u6570\u636e\u65e0\u5173\u6027", "conclusion": "GH-OFL\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u9ad8\u6548\u7684\u5355\u8f6e\u8054\u90a6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u548c\u9690\u79c1\u98ce\u9669\uff0c\u65e0\u9700\u516c\u5171\u6570\u636e\u96c6\u6216\u989d\u5916\u6570\u636e\u4e0a\u4f20"}}
{"id": "2602.01196", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01196", "abs": "https://arxiv.org/abs/2602.01196", "authors": ["Jin Li", "Yue Wu", "Mengsha Huang", "Yuhao Sun", "Hao He", "Xianyuan Zhan"], "title": "Unraveling the Hidden Dynamical Structure in Recurrent Neural Policies", "comment": null, "summary": "Recurrent neural policies are widely used in partially observable control and meta-RL tasks. Their abilities to maintain internal memory and adapt quickly to unseen scenarios have offered them unparalleled performance when compared to non-recurrent counterparts. However, until today, the underlying mechanisms for their superior generalization and robustness performance remain poorly understood. In this study, by analyzing the hidden state domain of recurrent policies learned over a diverse set of training methods, model architectures, and tasks, we find that stable cyclic structures consistently emerge during interaction with the environment. Such cyclic structures share a remarkable similarity with \\textit{limit cycles} in dynamical system analysis, if we consider the policy and the environment as a joint hybrid dynamical system. Moreover, we uncover that the geometry of such limit cycles also has a structured correspondence with the policies' behaviors. These findings offer new perspectives to explain many nice properties of recurrent policies: the emergence of limit cycles stabilizes both the policies' internal memory and the task-relevant environmental states, while suppressing nuisance variability arising from environmental uncertainty; the geometry of limit cycles also encodes relational structures of behaviors, facilitating easier skill adaptation when facing non-stationary environments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7b56\u7565\u5728\u8bad\u7ec3\u4e2d\u4f1a\u81ea\u53d1\u5f62\u6210\u7a33\u5b9a\u7684\u6781\u9650\u73af\u7ed3\u6784\uff0c\u8fd9\u79cd\u7ed3\u6784\u80fd\u7a33\u5b9a\u5185\u90e8\u8bb0\u5fc6\u548c\u73af\u5883\u72b6\u6001\uff0c\u6291\u5236\u73af\u5883\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u7f16\u7801\u884c\u4e3a\u5173\u7cfb\u7ed3\u6784\uff0c\u4ece\u800c\u89e3\u91ca\u5176\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7b56\u7565\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u63a7\u5236\u548c\u5143\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u4f18\u8d8a\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u7684\u5185\u5728\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u5faa\u73af\u7b56\u7565\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff0c\u89e3\u91ca\u5176\u4e3a\u4f55\u6bd4\u975e\u5faa\u73af\u7b56\u7565\u8868\u73b0\u66f4\u597d\u3002", "method": "\u901a\u8fc7\u5206\u6790\u591a\u79cd\u8bad\u7ec3\u65b9\u6cd5\u3001\u6a21\u578b\u67b6\u6784\u548c\u4efb\u52a1\u4e0b\u5b66\u4e60\u7684\u5faa\u73af\u7b56\u7565\u7684\u9690\u85cf\u72b6\u6001\u57df\uff0c\u53d1\u73b0\u4e0e\u73af\u5883\u4ea4\u4e92\u65f6\u7a33\u5b9a\u5faa\u73af\u7ed3\u6784\u4f1a\u81ea\u53d1\u5f62\u6210\u3002\u5c06\u7b56\u7565\u548c\u73af\u5883\u89c6\u4e3a\u8054\u5408\u6df7\u5408\u52a8\u529b\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u5faa\u73af\u7ed3\u6784\u4e0e\u52a8\u529b\u7cfb\u7edf\u5206\u6790\u4e2d\u7684\u6781\u9650\u73af\u76f8\u4f3c\u3002", "result": "\u53d1\u73b0\u5faa\u73af\u7b56\u7565\u5728\u8bad\u7ec3\u4e2d\u4f1a\u5f62\u6210\u7a33\u5b9a\u7684\u6781\u9650\u73af\u7ed3\u6784\uff0c\u8fd9\u79cd\u7ed3\u6784\u80fd\u7a33\u5b9a\u5185\u90e8\u8bb0\u5fc6\u548c\u4efb\u52a1\u76f8\u5173\u73af\u5883\u72b6\u6001\uff0c\u6291\u5236\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u7684\u5e72\u6270\u3002\u6781\u9650\u73af\u7684\u51e0\u4f55\u7ed3\u6784\u8fd8\u4e0e\u7b56\u7565\u884c\u4e3a\u5b58\u5728\u7ed3\u6784\u5316\u5bf9\u5e94\u5173\u7cfb\u3002", "conclusion": "\u6781\u9650\u73af\u7684\u51fa\u73b0\u4e3a\u89e3\u91ca\u5faa\u73af\u7b56\u7565\u7684\u4f18\u8d8a\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff1a\u6781\u9650\u73af\u7a33\u5b9a\u4e86\u5185\u90e8\u8bb0\u5fc6\u548c\u73af\u5883\u72b6\u6001\uff0c\u6291\u5236\u4e86\u73af\u5883\u4e0d\u786e\u5b9a\u6027\uff1b\u6781\u9650\u73af\u51e0\u4f55\u7ed3\u6784\u7f16\u7801\u4e86\u884c\u4e3a\u5173\u7cfb\uff0c\u5728\u9762\u5bf9\u975e\u5e73\u7a33\u73af\u5883\u65f6\u4fc3\u8fdb\u4e86\u6280\u80fd\u9002\u5e94\u3002"}}
{"id": "2602.01212", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01212", "abs": "https://arxiv.org/abs/2602.01212", "authors": ["Marco Chen", "Xianbiao Qi", "Yelin He", "Jiaquan Ye", "Rong Xiao"], "title": "SimpleGPT: Improving GPT via A Simple Normalization Strategy", "comment": "We propose SimpleGPT, a simple yet effective GPT model, and provide theoretical insights into its mathematical foundations. We validate our theoretical findings through extensive experiments on large GPT models at parameter scales 1B, 1.4B, 7B and 8B", "summary": "In this work, we revisit Transformer optimization through the lens of second-order geometry and establish a direct connection between architectural design, activation scale, the Hessian matrix, and the maximum tolerable learning rate. We introduce a simple normalization strategy, termed SimpleNorm, which stabilizes intermediate activation scales by construction. Then, by analyzing the Hessian of the loss with respect to network activations, we theoretically show that SimpleNorm significantly reduces the spectral norm of the Hessian, thereby permitting larger stable learning rates. We validate our theoretical findings through extensive experiments on large GPT models at parameter scales 1B, 1.4B, 7B and 8B. Empirically, SimpleGPT, our SimpleNorm-based network, tolerates learning rates 3$\\times$-10$\\times$ larger than standard convention, consistently demonstrates strong optimization stability, and achieves substantially better performance than well-established baselines. Specifically, when training 7B-scale models for 60K steps, SimpleGPT achieves a training loss that is 0.08 lower than that of LLaMA2 with QKNorm, reducing the loss from 2.290 to 2.208. Our source code will be released at https://github.com/Ocram7/SimpleGPT.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u4e8c\u9636\u51e0\u4f55\u5206\u6790Transformer\u4f18\u5316\uff0c\u63d0\u51faSimpleNorm\u5f52\u4e00\u5316\u7b56\u7565\u7a33\u5b9a\u6fc0\u6d3b\u5c3a\u5ea6\uff0c\u7406\u8bba\u4e0a\u964d\u4f4eHessian\u77e9\u9635\u8c31\u8303\u6570\uff0c\u4f7f\u5b66\u4e60\u7387\u53ef\u63d0\u9ad83-10\u500d\uff0c\u57281B-8B\u53c2\u6570\u89c4\u6a21GPT\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u4f18\u5316\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6Transformer\u4f18\u5316\u95ee\u9898\uff0c\u4ece\u4e8c\u9636\u51e0\u4f55\u89d2\u5ea6\u5efa\u7acb\u67b6\u6784\u8bbe\u8ba1\u3001\u6fc0\u6d3b\u5c3a\u5ea6\u3001Hessian\u77e9\u9635\u4e0e\u6700\u5927\u53ef\u5bb9\u5fcd\u5b66\u4e60\u7387\u4e4b\u95f4\u7684\u76f4\u63a5\u8054\u7cfb\uff0c\u89e3\u51b3\u5927\u6a21\u578b\u8bad\u7ec3\u4e2d\u5b66\u4e60\u7387\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faSimpleNorm\u5f52\u4e00\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u6784\u9020\u7a33\u5b9a\u4e2d\u95f4\u6fc0\u6d3b\u5c3a\u5ea6\uff1b\u7406\u8bba\u5206\u6790\u635f\u5931\u51fd\u6570\u5bf9\u7f51\u7edc\u6fc0\u6d3b\u7684Hessian\u77e9\u9635\uff0c\u8bc1\u660eSimpleNorm\u663e\u8457\u964d\u4f4eHessian\u8c31\u8303\u6570\uff0c\u4ece\u800c\u5141\u8bb8\u66f4\u5927\u7684\u7a33\u5b9a\u5b66\u4e60\u7387\u3002", "result": "\u57281B\u30011.4B\u30017B\u30018B\u53c2\u6570\u89c4\u6a21\u7684GPT\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0cSimpleGPT\uff08\u57fa\u4e8eSimpleNorm\u7684\u7f51\u7edc\uff09\u53ef\u5bb9\u5fcd\u6bd4\u6807\u51c6\u60ef\u4f8b\u9ad83-10\u500d\u7684\u5b66\u4e60\u7387\uff0c\u4f18\u5316\u7a33\u5b9a\u6027\u5f3a\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u30027B\u6a21\u578b\u8bad\u7ec360K\u6b65\u65f6\uff0c\u8bad\u7ec3\u635f\u5931\u6bd4LLaMA2+QKNorm\u4f4e0.08\uff08\u4ece2.290\u964d\u81f32.208\uff09\u3002", "conclusion": "SimpleNorm\u901a\u8fc7\u7a33\u5b9a\u6fc0\u6d3b\u5c3a\u5ea6\u548c\u964d\u4f4eHessian\u8c31\u8303\u6570\uff0c\u6709\u6548\u63d0\u5347Transformer\u4f18\u5316\u7a33\u5b9a\u6027\uff0c\u5141\u8bb8\u66f4\u5927\u5b66\u4e60\u7387\uff0c\u663e\u8457\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6027\u80fd\u3002"}}
{"id": "2602.01217", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.01217", "abs": "https://arxiv.org/abs/2602.01217", "authors": ["Lucas Lange", "Adrian B\u00f6ttinger", "Victor Christen", "Anushka Vidanage", "Peter Christen", "Erhard Rahm"], "title": "Learning from Anonymized and Incomplete Tabular Data", "comment": null, "summary": "User-driven privacy allows individuals to control whether and at what granularity their data is shared, leading to datasets that mix original, generalized, and missing values within the same records and attributes. While such representations are intuitive for privacy, they pose challenges for machine learning, which typically treats non-original values as new categories or as missing, thereby discarding generalization semantics. For learning from such tabular data, we propose novel data transformation strategies that account for heterogeneous anonymization and evaluate them alongside standard imputation and LLM-based approaches. We employ multiple datasets, privacy configurations, and deployment scenarios, demonstrating that our method reliably regains utility. Our results show that generalized values are preferable to pure suppression, that the best data preparation strategy depends on the scenario, and that consistent data representations are crucial for maintaining downstream utility. Overall, our findings highlight that effective learning is tied to the appropriate handling of anonymized values.", "AI": {"tldr": "\u7528\u6237\u9a71\u52a8\u7684\u9690\u79c1\u4fdd\u62a4\u5bfc\u81f4\u6570\u636e\u96c6\u4e2d\u6df7\u5408\u4e86\u539f\u59cb\u503c\u3001\u6cdb\u5316\u503c\u548c\u7f3a\u5931\u503c\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u5f02\u8d28\u533f\u540d\u5316\u6570\u636e\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u6570\u636e\u8f6c\u6362\u7b56\u7565\u6765\u6062\u590d\u6570\u636e\u6548\u7528\u3002", "motivation": "\u7528\u6237\u9a71\u52a8\u7684\u9690\u79c1\u4fdd\u62a4\u5141\u8bb8\u4e2a\u4eba\u63a7\u5236\u6570\u636e\u5171\u4eab\u7684\u7c92\u5ea6\uff0c\u5bfc\u81f4\u6570\u636e\u96c6\u4e2d\u540c\u65f6\u5b58\u5728\u539f\u59cb\u503c\u3001\u6cdb\u5316\u503c\u548c\u7f3a\u5931\u503c\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5c06\u975e\u539f\u59cb\u503c\u89c6\u4e3a\u65b0\u7c7b\u522b\u6216\u7f3a\u5931\u503c\uff0c\u4e22\u5f03\u4e86\u6cdb\u5316\u8bed\u4e49\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u79cd\u5f02\u8d28\u533f\u540d\u5316\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684\u6570\u636e\u8f6c\u6362\u7b56\u7565\u6765\u5904\u7406\u5f02\u8d28\u533f\u540d\u5316\uff0c\u8003\u8651\u4e86\u6cdb\u5316\u8bed\u4e49\uff0c\u5e76\u4e0e\u6807\u51c6\u7684\u63d2\u8865\u65b9\u6cd5\u548c\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1) \u6cdb\u5316\u503c\u4f18\u4e8e\u7eaf\u6291\u5236\uff1b2) \u6700\u4f73\u6570\u636e\u51c6\u5907\u7b56\u7565\u53d6\u51b3\u4e8e\u5177\u4f53\u573a\u666f\uff1b3) \u4e00\u81f4\u7684\u6570\u636e\u8868\u793a\u5bf9\u4fdd\u6301\u4e0b\u6e38\u6548\u7528\u81f3\u5173\u91cd\u8981\uff1b4) \u672c\u6587\u65b9\u6cd5\u80fd\u53ef\u9760\u5730\u6062\u590d\u6570\u636e\u6548\u7528\u3002", "conclusion": "\u6709\u6548\u7684\u673a\u5668\u5b66\u4e60\u4e0e\u9002\u5f53\u5904\u7406\u533f\u540d\u5316\u503c\u5bc6\u5207\u76f8\u5173\uff0c\u9700\u8981\u6839\u636e\u9690\u79c1\u914d\u7f6e\u548c\u90e8\u7f72\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u6570\u636e\u51c6\u5907\u7b56\u7565\uff0c\u6cdb\u5316\u503c\u6bd4\u7eaf\u6291\u5236\u66f4\u80fd\u4fdd\u6301\u6570\u636e\u6548\u7528\u3002"}}
{"id": "2602.01219", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01219", "abs": "https://arxiv.org/abs/2602.01219", "authors": ["Qishuai Wen", "Zhiyuan Huang", "Xianghan Meng", "Wei He", "Chun-Guang Li"], "title": "MiTA Attention: Efficient Fast-Weight Scaling via a Mixture of Top-$k$ Activations", "comment": null, "summary": "The attention operator in Transformers can be viewed as a two-layer fast-weight MLP, whose weights are dynamically instantiated from input tokens and whose width equals sequence length $N$. As the context extends, the expressive capacity of such an $N$-width MLP increases, but scaling its fast weights becomes prohibitively expensive for extremely long sequences. Recently, this fast-weight scaling perspective has motivated the Mixture-of-Experts (MoE) attention, which partitions the sequence into fast-weight experts and sparsely routes the tokens to them. In this paper, we elevate this perspective to a unifying framework for a wide range of efficient attention methods by interpreting them as scaling fast weights through routing and/or compression. Then we propose a compress-and-route strategy, which compresses the $N$-width MLP into a narrower one using a small set of landmark queries and constructs deformable experts by gathering top-$k$ activated key-value pairs for each landmark query. We call this strategy a Mixture of Top-$k$ Activations (MiTA), and refer to the resulting efficient mechanism as MiTA attention. Preliminary experiments on vision tasks demonstrate the promise of our MiTA attention and motivate further investigation on its optimization and broader applications in more challenging settings.", "AI": {"tldr": "\u63d0\u51faMiTA\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u538b\u7f29\u548c\u8def\u7531\u7b56\u7565\u5c06\u4f20\u7edf\u6ce8\u610f\u529b\u4e2d\u7684N\u5bbd\u5ea6MLP\u538b\u7f29\u4e3a\u66f4\u7a84\u7684MLP\uff0c\u4f7f\u7528\u5730\u6807\u67e5\u8be2\u548ctop-k\u6fc0\u6d3b\u952e\u503c\u5bf9\u6784\u5efa\u53ef\u53d8\u5f62\u4e13\u5bb6\uff0c\u5b9e\u73b0\u9ad8\u6548\u6ce8\u610f\u529b\u8ba1\u7b97\u3002", "motivation": "\u4f20\u7edfTransformer\u6ce8\u610f\u529b\u53ef\u89c6\u4e3a\u5bbd\u5ea6\u7b49\u4e8e\u5e8f\u5217\u957f\u5ea6N\u7684\u4e24\u5c42\u5feb\u901f\u6743\u91cdMLP\uff0c\u968f\u7740\u5e8f\u5217\u589e\u957f\uff0c\u5176\u8868\u8fbe\u80fd\u529b\u589e\u5f3a\u4f46\u8ba1\u7b97\u6210\u672c\u6025\u5267\u589e\u52a0\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u8868\u8fbe\u80fd\u529b\u53c8\u80fd\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002", "method": "\u63d0\u51fa\u538b\u7f29\u548c\u8def\u7531\u7b56\u7565\uff1a1) \u4f7f\u7528\u5c11\u91cf\u5730\u6807\u67e5\u8be2\u5c06N\u5bbd\u5ea6MLP\u538b\u7f29\u4e3a\u66f4\u7a84\u7684MLP\uff1b2) \u4e3a\u6bcf\u4e2a\u5730\u6807\u67e5\u8be2\u6536\u96c6top-k\u6fc0\u6d3b\u7684\u952e\u503c\u5bf9\u6784\u5efa\u53ef\u53d8\u5f62\u4e13\u5bb6\uff1b3) \u5f62\u6210\u6df7\u5408top-k\u6fc0\u6d3b(MiTA)\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\u4e86MiTA\u6ce8\u610f\u529b\u7684\u6f5c\u529b\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u5728\u66f4\u5177\u6311\u6218\u6027\u573a\u666f\u4e2d\u5e94\u7528\u3002", "conclusion": "\u5c06\u9ad8\u6548\u6ce8\u610f\u529b\u65b9\u6cd5\u7edf\u4e00\u89e3\u91ca\u4e3a\u901a\u8fc7\u8def\u7531\u548c/\u6216\u538b\u7f29\u6765\u6269\u5c55\u5feb\u901f\u6743\u91cd\u7684\u6846\u67b6\uff0c\u63d0\u51fa\u7684MiTA\u6ce8\u610f\u529b\u901a\u8fc7\u538b\u7f29\u548c\u8def\u7531\u7b56\u7565\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u7684\u63d0\u5347\uff0c\u4e3a\u957f\u5e8f\u5217\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01233", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01233", "abs": "https://arxiv.org/abs/2602.01233", "authors": ["Tianhao Miao", "Zhongyuan Bao", "Lejun Zhang"], "title": "Lotus: Efficient LLM Training by Randomized Low-Rank Gradient Projection with Adaptive Subspace Switching", "comment": null, "summary": "Training efficiency in large-scale models is typically assessed through memory consumption, training time, and model performance. Current methods often exhibit trade-offs among these metrics, as optimizing one generally degrades at least one of the others. Addressing this trade-off remains a central challenge in algorithm design. While GaLore enables memory-efficient training by updating gradients in a low-rank subspace, it incurs a comparable extra training time cost due to the Singular Value Decomposition(SVD) process on gradients. In this paper, we propose Lotus, a method that resolves this trade-off by simply modifying the projection process. We propose a criterion that quantifies the displacement of the unit gradient to enable efficient transitions between low-rank gradient subspaces. Experimental results indicate that Lotus is the most efficient method, achieving a 30% reduction in training time and a 40% decrease in memory consumption for gradient and optimizer states. Additionally, it outperforms the baseline method in both pre-training and fine-tuning tasks.", "AI": {"tldr": "Lotus\u662f\u4e00\u79cd\u89e3\u51b3\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u6743\u8861\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fee\u6539\u6295\u5f71\u8fc7\u7a0b\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u5728\u5185\u5b58\u6d88\u8017\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u4f18\u5316\u4e00\u4e2a\u6307\u6807\u901a\u5e38\u4f1a\u635f\u5bb3\u5176\u4ed6\u6307\u6807\u3002GaLore\u867d\u7136\u901a\u8fc7\u4f4e\u79e9\u68af\u5ea6\u66f4\u65b0\u51cf\u5c11\u5185\u5b58\u6d88\u8017\uff0c\u4f46SVD\u8fc7\u7a0b\u589e\u52a0\u4e86\u8bad\u7ec3\u65f6\u95f4\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\u6548\u7387\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faLotus\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fee\u6539\u6295\u5f71\u8fc7\u7a0b\uff0c\u5f15\u5165\u91cf\u5316\u5355\u4f4d\u68af\u5ea6\u4f4d\u79fb\u7684\u6807\u51c6\uff0c\u5b9e\u73b0\u5728\u4f4e\u79e9\u68af\u5ea6\u5b50\u7a7a\u95f4\u4e4b\u95f4\u7684\u9ad8\u6548\u8f6c\u6362\uff0c\u907f\u514d\u6602\u8d35\u7684SVD\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aLotus\u662f\u6700\u6709\u6548\u7684\u65b9\u6cd5\uff1a\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1130%\uff0c\u68af\u5ea6\u548c\u4f18\u5316\u5668\u72b6\u6001\u7684\u5185\u5b58\u6d88\u8017\u964d\u4f4e40%\uff0c\u5728\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u4efb\u52a1\u4e2d\u90fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Lotus\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6548\u7387\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u6295\u5f71\u4fee\u6539\u5b9e\u73b0\u4e86\u8bad\u7ec3\u65f6\u95f4\u3001\u5185\u5b58\u6d88\u8017\u548c\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u4f18\u5316\u3002"}}
{"id": "2602.01247", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01247", "abs": "https://arxiv.org/abs/2602.01247", "authors": ["Maryam Maghsoudi", "Ayushi Mishra"], "title": "Mechanistic Interpretability of Brain-to-Speech Models Across Speech Modes", "comment": null, "summary": "Brain-to-speech decoding models demonstrate robust performance in vocalized, mimed, and imagined speech; yet, the fundamental mechanisms via which these models capture and transmit information across different speech modalities are less explored. In this work, we use mechanistic interpretability to causally investigate the internal representations of a neural speech decoder. We perform cross-mode activation patching of internal activations across speech modes, and use tri-modal interpolation to examine whether speech representations vary discretely or continuously. We use coarse-to-fine causal tracing and causal scrubbing to find localized causal structure, allowing us to find internal subspaces that are sufficient for cross-mode transfer. In order to determine how finely distributed these effects are within layers, we perform neuron-level activation patching. We discover that small but not distributed subsets of neurons, rather than isolated units, affect the cross-mode transfer. Our results show that speech modes lie on a shared continuous causal manifold, and cross-mode transfer is mediated by compact, layer-specific subspaces rather than diffuse activity. Together, our findings give a causal explanation for how speech modality information is organized and used in brain-to-speech decoding models, revealing hierarchical and direction-dependent representational structure across speech modes.", "AI": {"tldr": "\u4f7f\u7528\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7814\u7a76\u795e\u7ecf\u8bed\u97f3\u89e3\u7801\u5668\u7684\u5185\u90e8\u8868\u793a\uff0c\u53d1\u73b0\u8bed\u97f3\u6a21\u6001\u4f4d\u4e8e\u5171\u4eab\u8fde\u7eed\u56e0\u679c\u6d41\u5f62\u4e0a\uff0c\u8de8\u6a21\u6001\u4f20\u8f93\u7531\u7d27\u51d1\u7684\u5c42\u7279\u5b9a\u5b50\u7a7a\u95f4\u800c\u975e\u6269\u6563\u6d3b\u52a8\u4ecb\u5bfc\u3002", "motivation": "\u5c3d\u7ba1\u8111\u5230\u8bed\u97f3\u89e3\u7801\u6a21\u578b\u5728\u53d1\u58f0\u3001\u6a21\u4eff\u548c\u60f3\u8c61\u8bed\u97f3\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u5982\u4f55\u5728\u4e0d\u540c\u8bed\u97f3\u6a21\u6001\u95f4\u6355\u83b7\u548c\u4f20\u9012\u4fe1\u606f\u7684\u57fa\u672c\u673a\u5236\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff1a\u8de8\u6a21\u6001\u6fc0\u6d3b\u4fee\u8865\u3001\u4e09\u6a21\u6001\u63d2\u503c\u3001\u7c97\u5230\u7ec6\u56e0\u679c\u8ffd\u8e2a\u3001\u56e0\u679c\u64e6\u9664\uff0c\u4ee5\u53ca\u795e\u7ecf\u5143\u7ea7\u6fc0\u6d3b\u4fee\u8865\u6765\u7814\u7a76\u5185\u90e8\u8868\u793a\u3002", "result": "\u53d1\u73b0\u8bed\u97f3\u6a21\u6001\u4f4d\u4e8e\u5171\u4eab\u8fde\u7eed\u56e0\u679c\u6d41\u5f62\u4e0a\uff1b\u8de8\u6a21\u6001\u4f20\u8f93\u7531\u7d27\u51d1\u7684\u5c42\u7279\u5b9a\u5b50\u7a7a\u95f4\u4ecb\u5bfc\uff1b\u5c0f\u800c\u975e\u5206\u5e03\u7684\u5b50\u96c6\u795e\u7ecf\u5143\u5f71\u54cd\u8de8\u6a21\u6001\u4f20\u8f93\uff1b\u5b58\u5728\u5c42\u6b21\u6027\u548c\u65b9\u5411\u4f9d\u8d56\u7684\u8868\u793a\u7ed3\u6784\u3002", "conclusion": "\u4e3a\u8111\u5230\u8bed\u97f3\u89e3\u7801\u6a21\u578b\u4e2d\u8bed\u97f3\u6a21\u6001\u4fe1\u606f\u7684\u7ec4\u7ec7\u548c\u4f7f\u7528\u63d0\u4f9b\u4e86\u56e0\u679c\u89e3\u91ca\uff0c\u63ed\u793a\u4e86\u8de8\u8bed\u97f3\u6a21\u6001\u7684\u5c42\u6b21\u6027\u548c\u65b9\u5411\u4f9d\u8d56\u8868\u793a\u7ed3\u6784\u3002"}}
{"id": "2602.01260", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01260", "abs": "https://arxiv.org/abs/2602.01260", "authors": ["Soumyadeep Roy", "Shashwat Kushwaha", "Ambedkar Dukkipati"], "title": "Sample Efficient Active Algorithms for Offline Reinforcement Learning", "comment": null, "summary": "Offline reinforcement learning (RL) enables policy learning from static data but often suffers from poor coverage of the state-action space and distributional shift problems. This problem can be addressed by allowing limited online interactions to selectively refine uncertain regions of the learned value function, which is referred to as Active Reinforcement Learning (ActiveRL). While there has been good empirical success, no theoretical analysis is available in the literature. We fill this gap by developing a rigorous sample-complexity analysis of ActiveRL through the lens of Gaussian Process (GP) uncertainty modeling. In this respect, we propose an algorithm and using GP concentration inequalities and information-gain bounds, we derive high-probability guarantees showing that an $\u03b5$-optimal policy can be learned with ${\\mathcal{O}}(1/\u03b5^2)$ active transitions, improving upon the $\u03a9(1/\u03b5^2(1-\u03b3)^4)$ rate of purely offline methods. Our results reveal that ActiveRL achieves near-optimal information efficiency, that is, guided uncertainty reduction leads to accelerated value-function convergence with minimal online data. Our analysis builds on GP concentration inequalities and information-gain bounds, bridging Bayesian nonparametric regression and reinforcement learning theories. We conduct several experiments to validate the algorithm and theoretical findings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ActiveRL\u7b97\u6cd5\uff0c\u901a\u8fc7\u6709\u9650\u5728\u7ebf\u4ea4\u4e92\u9009\u62e9\u6027\u4f18\u5316\u4ef7\u503c\u51fd\u6570\u7684\u4e0d\u786e\u5b9a\u533a\u57df\uff0c\u5c06\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u590d\u6742\u5ea6\u4ece\u03a9(1/\u03b5\u00b2(1-\u03b3)\u2074)\u63d0\u5347\u5230O(1/\u03b5\u00b2)\uff0c\u5b9e\u73b0\u8fd1\u6700\u4f18\u4fe1\u606f\u6548\u7387\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5b58\u5728\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u8986\u76d6\u4e0d\u8db3\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u9700\u8981\u5141\u8bb8\u6709\u9650\u5728\u7ebf\u4ea4\u4e92\u6765\u9009\u62e9\u6027\u4f18\u5316\u4ef7\u503c\u51fd\u6570\u7684\u4e0d\u786e\u5b9a\u533a\u57df\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u5206\u6790\u3002", "method": "\u63d0\u51faActiveRL\u7b97\u6cd5\uff0c\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff0c\u4f7f\u7528GP\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u548c\u4fe1\u606f\u589e\u76ca\u8fb9\u754c\uff0c\u901a\u8fc7\u4e3b\u52a8\u9009\u62e9\u4e0d\u786e\u5b9a\u533a\u57df\u8fdb\u884c\u5728\u7ebf\u4ea4\u4e92\u6765\u52a0\u901f\u4ef7\u503c\u51fd\u6570\u6536\u655b\u3002", "result": "\u7406\u8bba\u8bc1\u660eActiveRL\u80fd\u4ee5O(1/\u03b5\u00b2)\u7684\u4e3b\u52a8\u8f6c\u79fb\u5b66\u4e60\u03b5-\u6700\u4f18\u7b56\u7565\uff0c\u76f8\u6bd4\u7eaf\u79bb\u7ebf\u65b9\u6cd5\u7684\u03a9(1/\u03b5\u00b2(1-\u03b3)\u2074)\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5b9e\u73b0\u8fd1\u6700\u4f18\u4fe1\u606f\u6548\u7387\u3002", "conclusion": "ActiveRL\u901a\u8fc7\u5f15\u5bfc\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\uff0c\u4ee5\u6700\u5c0f\u5728\u7ebf\u6570\u636e\u5b9e\u73b0\u52a0\u901f\u4ef7\u503c\u51fd\u6570\u6536\u655b\uff0c\u8fde\u63a5\u4e86\u8d1d\u53f6\u65af\u975e\u53c2\u6570\u56de\u5f52\u548c\u5f3a\u5316\u5b66\u4e60\u7406\u8bba\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u548c\u7406\u8bba\u53d1\u73b0\u3002"}}
{"id": "2602.01265", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01265", "abs": "https://arxiv.org/abs/2602.01265", "authors": ["Jiangnan Zhu", "Yukai Xu", "Li Xiong", "Yixuan Liu", "Junxu Liu", "Hong kyu Lee", "Yujie Gu"], "title": "BicKD: Bilateral Contrastive Knowledge Distillation", "comment": null, "summary": "Knowledge distillation (KD) is a machine learning framework that transfers knowledge from a teacher model to a student model. The vanilla KD proposed by Hinton et al. has been the dominant approach in logit-based distillation and demonstrates compelling performance. However, it only performs sample-wise probability alignment between teacher and student's predictions, lacking an mechanism for class-wise comparison. Besides, vanilla KD imposes no structural constraint on the probability space. In this work, we propose a simple yet effective methodology, bilateral contrastive knowledge distillation (BicKD). This approach introduces a novel bilateral contrastive loss, which intensifies the orthogonality among different class generalization spaces while preserving consistency within the same class. The bilateral formulation enables explicit comparison of both sample-wise and class-wise prediction patterns between teacher and student. By emphasizing probabilistic orthogonality, BicKD further regularizes the geometric structure of the predictive distribution. Extensive experiments show that our BicKD method enhances knowledge transfer, and consistently outperforms state-of-the-art knowledge distillation techniques across various model architectures and benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u8fb9\u5bf9\u6bd4\u77e5\u8bc6\u84b8\u998f(BicKD)\uff0c\u901a\u8fc7\u53cc\u8fb9\u5bf9\u6bd4\u635f\u5931\u589e\u5f3a\u7c7b\u95f4\u6b63\u4ea4\u6027\u548c\u7c7b\u5185\u4e00\u81f4\u6027\uff0c\u6539\u8fdb\u4f20\u7edf\u77e5\u8bc6\u84b8\u998f\u7684\u6837\u672c\u5bf9\u9f50\u9650\u5236", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u84b8\u998f(Hinton KD)\u53ea\u8fdb\u884c\u6837\u672c\u7ea7\u6982\u7387\u5bf9\u9f50\uff0c\u7f3a\u4e4f\u7c7b\u7ea7\u6bd4\u8f83\u673a\u5236\uff0c\u4e14\u5bf9\u6982\u7387\u7a7a\u95f4\u6ca1\u6709\u7ed3\u6784\u7ea6\u675f\uff0c\u9650\u5236\u4e86\u77e5\u8bc6\u8fc1\u79fb\u6548\u679c", "method": "\u63d0\u51fa\u53cc\u8fb9\u5bf9\u6bd4\u77e5\u8bc6\u84b8\u998f(BicKD)\uff0c\u5f15\u5165\u53cc\u8fb9\u5bf9\u6bd4\u635f\u5931\uff0c\u589e\u5f3a\u4e0d\u540c\u7c7b\u6cdb\u5316\u7a7a\u95f4\u7684\u6b63\u4ea4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u540c\u7c7b\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u6837\u672c\u7ea7\u548c\u7c7b\u7ea7\u9884\u6d4b\u6a21\u5f0f\u7684\u663e\u5f0f\u6bd4\u8f83", "result": "\u5728\u591a\u79cd\u6a21\u578b\u67b6\u6784\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBicKD\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u8fc1\u79fb\u6548\u679c\uff0c\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u77e5\u8bc6\u84b8\u998f\u6280\u672f", "conclusion": "BicKD\u901a\u8fc7\u53cc\u8fb9\u5bf9\u6bd4\u635f\u5931\u548c\u6982\u7387\u6b63\u4ea4\u6027\u6b63\u5219\u5316\uff0c\u6709\u6548\u6539\u8fdb\u4e86\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u4e3a\u6982\u7387\u5206\u5e03\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u51e0\u4f55\u7ed3\u6784\u7ea6\u675f"}}
{"id": "2602.01267", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01267", "abs": "https://arxiv.org/abs/2602.01267", "authors": ["Jiayu Bai", "Danchen Yu", "Zhenyu Liao", "TianQi Hou", "Feng Zhou", "Robert C. Qiu", "Zenan Ling"], "title": "Diving into Kronecker Adapters: Component Design Matters", "comment": null, "summary": "Kronecker adapters have emerged as a promising approach for fine-tuning large-scale models, enabling high-rank updates through tunable component structures. However, existing work largely treats the component structure as a fixed or heuristic design choice, leaving the dimensions and number of Kronecker components underexplored. In this paper, we identify component structure as a key factor governing the capacity of Kronecker adapters. We perform a fine-grained analysis of both the dimensions and number of Kronecker components. In particular, we show that the alignment between Kronecker adapters and full fine-tuning depends on component configurations. Guided by these insights, we propose Component Designed Kronecker Adapters (CDKA). We further provide parameter-budget-aware configuration guidelines and a tailored training stabilization strategy for practical deployment. Experiments across various natural language processing tasks demonstrate the effectiveness of CDKA. Code is available at https://github.com/rainstonee/CDKA.", "AI": {"tldr": "CDKA\u63d0\u51fa\u901a\u8fc7\u7cbe\u7ec6\u8bbe\u8ba1Kronecker\u9002\u914d\u5668\u7684\u7ec4\u4ef6\u7ed3\u6784\uff08\u7ef4\u5ea6\u548c\u6570\u91cf\uff09\u6765\u4f18\u5316\u53c2\u6570\u6548\u7387\u5fae\u8c03\uff0c\u5e76\u63d0\u4f9b\u53c2\u6570\u9884\u7b97\u611f\u77e5\u7684\u914d\u7f6e\u6307\u5357\u548c\u8bad\u7ec3\u7a33\u5b9a\u7b56\u7565\u3002", "motivation": "\u73b0\u6709Kronecker\u9002\u914d\u5668\u65b9\u6cd5\u5927\u591a\u5c06\u7ec4\u4ef6\u7ed3\u6784\u89c6\u4e3a\u56fa\u5b9a\u6216\u542f\u53d1\u5f0f\u8bbe\u8ba1\u9009\u62e9\uff0c\u5bf9\u7ec4\u4ef6\u7ef4\u5ea6\u548c\u6570\u91cf\u7684\u63a2\u7d22\u4e0d\u8db3\u3002\u4f5c\u8005\u53d1\u73b0\u7ec4\u4ef6\u7ed3\u6784\u662f\u63a7\u5236Kronecker\u9002\u914d\u5668\u5bb9\u91cf\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e14\u4e0e\u5168\u53c2\u6570\u5fae\u8c03\u7684\u5339\u914d\u5ea6\u53d6\u51b3\u4e8e\u7ec4\u4ef6\u914d\u7f6e\u3002", "method": "\u63d0\u51faComponent Designed Kronecker Adapters (CDKA)\uff0c\u5bf9Kronecker\u9002\u914d\u5668\u7684\u7ec4\u4ef6\u7ef4\u5ea6\u548c\u6570\u91cf\u8fdb\u884c\u7cbe\u7ec6\u5206\u6790\uff0c\u63d0\u4f9b\u53c2\u6570\u9884\u7b97\u611f\u77e5\u7684\u914d\u7f6e\u6307\u5357\uff0c\u5e76\u8bbe\u8ba1\u4e13\u95e8\u7684\u8bad\u7ec3\u7a33\u5b9a\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86CDKA\u7684\u6709\u6548\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u7ec4\u4ef6\u7ed3\u6784\u8bbe\u8ba1\u5bf9Kronecker\u9002\u914d\u5668\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0cCDKA\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u7ec4\u4ef6\u914d\u7f6e\u4f18\u5316\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u53c2\u6570\u6548\u7387\u5fae\u8c03\u6548\u679c\u3002"}}
{"id": "2602.01270", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01270", "abs": "https://arxiv.org/abs/2602.01270", "authors": ["Boxuan Zhang", "Weipu Zhang", "Zhaohan Feng", "Wei Xiao", "Jian Sun", "Jie Chen", "Gang Wang"], "title": "Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular Latent Dynamics", "comment": null, "summary": "A fundamental challenge in multi-task reinforcement learning (MTRL) is achieving sample efficiency in visual domains where tasks exhibit substantial heterogeneity in both observations and dynamics. Model-based reinforcement learning offers a promising path to improved sample efficiency through world models, but standard monolithic architectures struggle to capture diverse task dynamics, resulting in poor reconstruction and prediction accuracy. We introduce Mixture-of-World Models (MoW), a scalable architecture that combines modular variational autoencoders for task-adaptive visual compression, a hybrid Transformer-based dynamics model with task-conditioned experts and a shared backbone, and a gradient-based task clustering strategy for efficient parameter allocation. On the Atari 100k benchmark, a single MoW agent trained once on 26 Atari games achieves a mean human-normalized score of 110.4%, competitive with the score of 114.2% achieved by STORM, an ensemble of 26 task-specific models, while using 50% fewer parameters. On Meta-World, MoW achieves a 74.5% average success rate within 300 thousand environment steps, establishing a new state of the art. These results demonstrate that MoW provides a scalable and parameter-efficient foundation for generalist world models.", "AI": {"tldr": "MoW\u662f\u4e00\u79cd\u7528\u4e8e\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u7684\u6df7\u5408\u4e16\u754c\u6a21\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u89c6\u89c9\u7f16\u7801\u3001\u4efb\u52a1\u6761\u4ef6\u5316\u4e13\u5bb6\u548c\u68af\u5ea6\u805a\u7c7b\u7b56\u7565\uff0c\u5728Atari\u548cMeta-World\u4e0a\u5b9e\u73b0\u4e86\u53c2\u6570\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u7ed3\u679c\u3002", "motivation": "\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u5728\u89c6\u89c9\u9886\u57df\u4e2d\u9762\u4e34\u6837\u672c\u6548\u7387\u6311\u6218\uff0c\u7279\u522b\u662f\u5f53\u4efb\u52a1\u5728\u89c2\u6d4b\u548c\u52a8\u6001\u7279\u6027\u4e0a\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\u65f6\u3002\u4f20\u7edf\u7684\u5355\u4e00\u4e16\u754c\u6a21\u578b\u67b6\u6784\u96be\u4ee5\u6355\u6349\u591a\u6837\u5316\u7684\u4efb\u52a1\u52a8\u6001\uff0c\u5bfc\u81f4\u91cd\u5efa\u548c\u9884\u6d4b\u51c6\u786e\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u4e16\u754c\u6a21\u578b\uff08MoW\uff09\u67b6\u6784\uff1a1\uff09\u4f7f\u7528\u6a21\u5757\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\u8fdb\u884c\u4efb\u52a1\u81ea\u9002\u5e94\u89c6\u89c9\u538b\u7f29\uff1b2\uff09\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u6df7\u5408\u52a8\u6001\u6a21\u578b\uff0c\u5305\u542b\u4efb\u52a1\u6761\u4ef6\u5316\u4e13\u5bb6\u548c\u5171\u4eab\u4e3b\u5e72\uff1b3\uff09\u5b9e\u65bd\u57fa\u4e8e\u68af\u5ea6\u7684\u4efb\u52a1\u805a\u7c7b\u7b56\u7565\u8fdb\u884c\u9ad8\u6548\u53c2\u6570\u5206\u914d\u3002", "result": "\u5728Atari 100k\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5355\u4e2aMoW\u4ee3\u7406\u572826\u4e2aAtari\u6e38\u620f\u4e0a\u83b7\u5f97110.4%\u7684\u5e73\u5747\u4eba\u7c7b\u6807\u51c6\u5316\u5206\u6570\uff0c\u4e0e\u9700\u898126\u4e2a\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u7684STORM\uff08114.2%\uff09\u76f8\u5f53\uff0c\u4f46\u53c2\u6570\u51cf\u5c1150%\u3002\u5728Meta-World\u4e0a\uff0cMoW\u572830\u4e07\u6b65\u5185\u8fbe\u523074.5%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u521b\u4e0b\u65b0\u8bb0\u5f55\u3002", "conclusion": "MoW\u4e3a\u901a\u7528\u4e16\u754c\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u53c2\u6570\u9ad8\u6548\u7684\u57fa\u7840\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u89c6\u89c9\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u53c2\u6570\u9700\u6c42\u3002"}}
{"id": "2602.01271", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01271", "abs": "https://arxiv.org/abs/2602.01271", "authors": ["Burak Demirel", "Pablo Soldati", "Yu Wang"], "title": "From Intents to Actions: Agentic AI in Autonomous Networks", "comment": null, "summary": "Telecommunication networks are increasingly expected to operate autonomously while supporting heterogeneous services with diverse and often conflicting intents -- that is, performance objectives, constraints, and requirements specific to each service. However, transforming high-level intents -- such as ultra-low latency, high throughput, or energy efficiency -- into concrete control actions (i.e., low-level actuator commands) remains beyond the capability of existing heuristic approaches. This work introduces an Agentic AI system for intent-driven autonomous networks, structured around three specialized agents. A supervisory interpreter agent, powered by language models, performs both lexical parsing of intents into executable optimization templates and cognitive refinement based on feedback, constraint feasibility, and evolving network conditions. An optimizer agent converts these templates into tractable optimization problems, analyzes trade-offs, and derives preferences across objectives. Lastly, a preference-driven controller agent, based on multi-objective reinforcement learning, leverages these preferences to operate near the Pareto frontier of network performance that best satisfies the original intent. Collectively, these agents enable networks to autonomously interpret, reason over, adapt to, and act upon diverse intents and network conditions in a scalable manner.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e09\u4e2a\u667a\u80fd\u4f53\u7684AI\u7cfb\u7edf\uff0c\u7528\u4e8e\u610f\u56fe\u9a71\u52a8\u7684\u81ea\u6cbb\u7f51\u7edc\uff1a\u76d1\u7763\u89e3\u91ca\u5668\u5c06\u9ad8\u5c42\u610f\u56fe\u89e3\u6790\u4e3a\u53ef\u6267\u884c\u4f18\u5316\u6a21\u677f\uff0c\u4f18\u5316\u5668\u5c06\u5176\u8f6c\u5316\u4e3a\u4f18\u5316\u95ee\u9898\u5e76\u5206\u6790\u6743\u8861\uff0c\u504f\u597d\u9a71\u52a8\u63a7\u5236\u5668\u57fa\u4e8e\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u7f51\u7edc\u63a7\u5236\u3002", "motivation": "\u7535\u4fe1\u7f51\u7edc\u9700\u8981\u81ea\u4e3b\u8fd0\u884c\u5e76\u652f\u6301\u5177\u6709\u591a\u6837\u5316\u4e14\u5e38\u51b2\u7a81\u610f\u56fe\u7684\u5f02\u6784\u670d\u52a1\uff0c\u4f46\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u5c06\u9ad8\u5c42\u610f\u56fe\uff08\u5982\u8d85\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u3001\u80fd\u6548\uff09\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u63a7\u5236\u52a8\u4f5c\u3002", "method": "\u6784\u5efa\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff1a1) \u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u76d1\u7763\u89e3\u91ca\u5668\uff0c\u8fdb\u884c\u610f\u56fe\u7684\u8bcd\u6cd5\u89e3\u6790\u548c\u8ba4\u77e5\u7ec6\u5316\uff1b2) \u4f18\u5316\u5668\uff0c\u5c06\u6a21\u677f\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u7684\u4f18\u5316\u95ee\u9898\u5e76\u5206\u6790\u6743\u8861\uff1b3) \u57fa\u4e8e\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u504f\u597d\u9a71\u52a8\u63a7\u5236\u5668\uff0c\u5229\u7528\u504f\u597d\u5b9e\u73b0\u7f51\u7edc\u63a7\u5236\u3002", "result": "\u8be5\u7cfb\u7edf\u4f7f\u7f51\u7edc\u80fd\u591f\u4ee5\u53ef\u6269\u5c55\u7684\u65b9\u5f0f\u81ea\u4e3b\u89e3\u91ca\u3001\u63a8\u7406\u3001\u9002\u5e94\u548c\u6267\u884c\u591a\u6837\u5316\u7684\u610f\u56fe\u548c\u7f51\u7edc\u6761\u4ef6\uff0c\u4f7f\u7f51\u7edc\u8fd0\u884c\u63a5\u8fd1\u6700\u80fd\u6ee1\u8db3\u539f\u59cb\u610f\u56fe\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "\u63d0\u51fa\u7684\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e3a\u610f\u56fe\u9a71\u52a8\u7684\u81ea\u6cbb\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e86\u4ece\u9ad8\u5c42\u610f\u56fe\u5230\u5177\u4f53\u63a7\u5236\u52a8\u4f5c\u7684\u7aef\u5230\u7aef\u81ea\u4e3b\u8f6c\u6362\u3002"}}
{"id": "2602.01279", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01279", "abs": "https://arxiv.org/abs/2602.01279", "authors": ["Sergio Calvo-Ordo\u00f1ez", "Jonathan Plenk", "Richard Bergna", "\u00c1lvaro Cartea", "Yarin Gal", "Jose Miguel Hern\u00e1ndez-Lobato", "Kamil Ciosek"], "title": "Richer Bayesian Last Layers with Subsampled NTK Features", "comment": "Preprint, work in progress", "summary": "Bayesian Last Layers (BLLs) provide a convenient and computationally efficient way to estimate uncertainty in neural networks. However, they underestimate epistemic uncertainty because they apply a Bayesian treatment only to the final layer, ignoring uncertainty induced by earlier layers. We propose a method that improves BLLs by leveraging a projection of Neural Tangent Kernel (NTK) features onto the space spanned by the last-layer features. This enables posterior inference that accounts for variability of the full network while retaining the low computational cost of inference of a standard BLL. We show that our method yields posterior variances that are provably greater or equal to those of a standard BLL, correcting its tendency to underestimate epistemic uncertainty. To further reduce computational cost, we introduce a uniform subsampling scheme for estimating the projection matrix and for posterior inference. We derive approximation bounds for both types of sub-sampling. Empirical evaluations on UCI regression, contextual bandits, image classification, and out-of-distribution detection tasks in image and tabular datasets, demonstrate improved calibration and uncertainty estimates compared to standard BLLs and competitive baselines, while reducing computational cost.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u8d1d\u53f6\u65af\u6700\u540e\u4e00\u5c42\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u795e\u7ecf\u6b63\u5207\u6838\u7279\u5f81\u6295\u5f71\u5230\u6700\u540e\u4e00\u5c42\u7279\u5f81\u7a7a\u95f4\uff0c\u6765\u66f4\u597d\u5730\u4f30\u8ba1\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u8d1d\u53f6\u65af\u6700\u540e\u4e00\u5c42\u867d\u7136\u8ba1\u7b97\u9ad8\u6548\uff0c\u4f46\u4f4e\u4f30\u4e86\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u56e0\u4e3a\u5b83\u53ea\u5bf9\u6700\u540e\u4e00\u5c42\u8fdb\u884c\u8d1d\u53f6\u65af\u5904\u7406\uff0c\u5ffd\u7565\u4e86\u524d\u9762\u5c42\u5f15\u5165\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u5229\u7528\u795e\u7ecf\u6b63\u5207\u6838\u7279\u5f81\u6295\u5f71\u5230\u6700\u540e\u4e00\u5c42\u7279\u5f81\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u4f7f\u540e\u9a8c\u63a8\u65ad\u80fd\u591f\u8003\u8651\u6574\u4e2a\u7f51\u7edc\u7684\u53d8\u5f02\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6807\u51c6BLL\u7684\u4f4e\u8ba1\u7b97\u6210\u672c\u3002\u8fd8\u5f15\u5165\u4e86\u5747\u5300\u5b50\u91c7\u6837\u65b9\u6848\u6765\u4f30\u8ba1\u6295\u5f71\u77e9\u9635\u548c\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad\u3002", "result": "\u8be5\u65b9\u6cd5\u4ea7\u751f\u7684\u540e\u9a8c\u65b9\u5dee\u7406\u8bba\u4e0a\u5927\u4e8e\u6216\u7b49\u4e8e\u6807\u51c6BLL\uff0c\u7ea0\u6b63\u4e86\u5176\u4f4e\u4f30\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u8d8b\u52bf\u3002\u5728UCI\u56de\u5f52\u3001\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u3001\u56fe\u50cf\u5206\u7c7b\u4ee5\u53ca\u56fe\u50cf\u548c\u8868\u683c\u6570\u636e\u96c6\u7684\u5206\u5e03\u5916\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u6807\u51c6BLL\u548c\u7ade\u4e89\u57fa\u7ebf\uff0c\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6821\u51c6\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7NTK\u7279\u5f81\u6295\u5f71\u6709\u6548\u6539\u8fdb\u4e86\u8d1d\u53f6\u65af\u6700\u540e\u4e00\u5c42\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u66f4\u597d\u5730\u4f30\u8ba1\u4e86\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.01285", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01285", "abs": "https://arxiv.org/abs/2602.01285", "authors": ["Kangjun Noh", "Seongchan Lee", "Ilmun Kim", "Kyungwoo Song"], "title": "Multi-LLM Adaptive Conformal Inference for Reliable LLM Responses", "comment": "Accepted to ICLR 2026", "summary": "Ensuring factuality is essential for the safe use of Large Language Models (LLMs) in high-stakes domains such as medicine and law. Conformal inference provides distribution-free guarantees, but existing approaches are either overly conservative, discarding many true-claims, or rely on adaptive error rates and simple linear models that fail to capture complex group structures. To address these challenges, we reformulate conformal inference in a multiplicative filtering setting, modeling factuality as a product of claim-level scores. Our method, Multi-LLM Adaptive Conformal Inference (MACI), leverages ensembles to produce more accurate factuality-scores, which in our experiments led to higher retention, while validity is preserved through group-conditional calibration. Experiments show that MACI consistently achieves user-specified coverage with substantially higher retention and lower time cost than baselines. Our repository is available at https://github.com/MLAI-Yonsei/MACI", "AI": {"tldr": "MACI\u662f\u4e00\u79cd\u57fa\u4e8e\u4e58\u6cd5\u8fc7\u6ee4\u7684\u7f6e\u4fe1\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u6a21\u578b\u751f\u6210\u66f4\u51c6\u786e\u7684\u4e8b\u5b9e\u6027\u5206\u6570\uff0c\u5728\u4fdd\u8bc1\u8986\u76d6\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u771f\u5b9e\u58f0\u660e\u7684\u4fdd\u7559\u7387\u3002", "motivation": "\u5728\u533b\u5b66\u548c\u6cd5\u5f8b\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u786e\u4fdd\u4e8b\u5b9e\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u7f6e\u4fe1\u63a8\u7406\u65b9\u6cd5\u8981\u4e48\u8fc7\u4e8e\u4fdd\u5b88\uff08\u4e22\u5f03\u5927\u91cf\u771f\u5b9e\u58f0\u660e\uff09\uff0c\u8981\u4e48\u4f9d\u8d56\u81ea\u9002\u5e94\u9519\u8bef\u7387\u548c\u7b80\u5355\u7ebf\u6027\u6a21\u578b\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u7684\u7fa4\u4f53\u7ed3\u6784\u3002", "method": "\u5c06\u7f6e\u4fe1\u63a8\u7406\u91cd\u65b0\u6784\u5efa\u4e3a\u4e58\u6cd5\u8fc7\u6ee4\u6846\u67b6\uff0c\u5c06\u4e8b\u5b9e\u6027\u5efa\u6a21\u4e3a\u58f0\u660e\u7ea7\u5206\u6570\u7684\u4e58\u79ef\u3002MACI\u5229\u7528\u96c6\u6210\u6a21\u578b\u751f\u6210\u66f4\u51c6\u786e\u7684\u4e8b\u5b9e\u6027\u5206\u6570\uff0c\u5e76\u901a\u8fc7\u7fa4\u4f53\u6761\u4ef6\u6821\u51c6\u4fdd\u6301\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMACI\u59cb\u7ec8\u80fd\u8fbe\u5230\u7528\u6237\u6307\u5b9a\u7684\u8986\u76d6\u7387\uff0c\u540c\u65f6\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4fdd\u7559\u7387\u5e76\u964d\u4f4e\u4e86\u65f6\u95f4\u6210\u672c\u3002", "conclusion": "MACI\u901a\u8fc7\u4e58\u6cd5\u8fc7\u6ee4\u6846\u67b6\u548c\u96c6\u6210\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u6709\u6548\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u771f\u5b9e\u58f0\u660e\u7684\u4fdd\u7559\u7387\uff0c\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u4e8b\u5b9e\u6027\u4fdd\u969c\u65b9\u6cd5\u3002"}}
{"id": "2602.01288", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01288", "abs": "https://arxiv.org/abs/2602.01288", "authors": ["Chenghua Zhu", "Siyan Wu", "Xiangkang Zeng", "Zishan Xu", "Zhaolu Kang", "Yifu Guo", "Yuquan Lu", "Junduan Huang", "Guojing Zhou"], "title": "EDIS: Diagnosing LLM Reasoning via Entropy Dynamics", "comment": "Under review at ICML 2026", "summary": "Entropy-based confidence signals are increasingly leveraged to improve reasoning in large language models (LLMs), yet existing approaches treat confidence as a static quantity -- typically aggregated over tokens. We show that the \\emph{temporal evolution} of confidence during generation carries richer information than aggregate statistics alone. Analyzing token-level entropy trajectories, we identify characteristic patterns distinguishing correct from incorrect reasoning: erroneous solutions exhibit unstable dynamics, including burst spikes (sustained uncertainty growth) and peak-valley spikes (sharp rebounds following transient confidence). These patterns persist across models and training stages, suggesting they reflect intrinsic properties of reasoning failure rather than superficial noise. To formalize this observation, we introduce the Entropy Dynamics Instability Score (\\textbf{EDIS}), a trajectory-level metric quantifying instability in entropy evolution. EDIS serves as an effective diagnostic signal for inference-time selection, substantially improving reasoning accuracy, and offers a promising direction for training-time sample curation. Our findings establish entropy dynamics as an underexplored yet informative lens for understanding and improving LLM reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u5206\u6790\u751f\u6210\u8fc7\u7a0b\u4e2d\u71b5\u7684\u52a8\u6001\u6f14\u5316\uff08\u800c\u975e\u9759\u6001\u805a\u5408\uff09\u6765\u6539\u8fdbLLM\u63a8\u7406\uff0c\u53d1\u73b0\u9519\u8bef\u63a8\u7406\u5177\u6709\u4e0d\u7a33\u5b9a\u7684\u71b5\u8f68\u8ff9\u6a21\u5f0f\uff0c\u5e76\u5f15\u5165EDIS\u6307\u6807\u91cf\u5316\u8fd9\u79cd\u4e0d\u7a33\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u7f6e\u4fe1\u5ea6\u89c6\u4e3a\u9759\u6001\u91cf\uff08\u901a\u5e38\u5728token\u4e0a\u805a\u5408\uff09\uff0c\u4f46\u751f\u6210\u8fc7\u7a0b\u4e2d\u7f6e\u4fe1\u5ea6\u7684\u65f6\u5e8f\u6f14\u5316\u53ef\u80fd\u5305\u542b\u66f4\u4e30\u5bcc\u7684\u4fe1\u606f\uff0c\u53ef\u7528\u4e8e\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u63a8\u7406\u3002", "method": "\u5206\u6790token\u7ea7\u71b5\u8f68\u8ff9\uff0c\u8bc6\u522b\u9519\u8bef\u63a8\u7406\u7684\u7279\u5f81\u6a21\u5f0f\uff08\u5982\u7206\u53d1\u6027\u5c16\u5cf0\u548c\u5cf0\u8c37\u5c16\u5cf0\uff09\uff0c\u5f15\u5165\u71b5\u52a8\u6001\u4e0d\u7a33\u5b9a\u6027\u8bc4\u5206\uff08EDIS\uff09\u91cf\u5316\u71b5\u6f14\u5316\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u7528\u4e8e\u63a8\u7406\u65f6\u9009\u62e9\u548c\u8bad\u7ec3\u65f6\u6837\u672c\u7b5b\u9009\u3002", "result": "\u9519\u8bef\u89e3\u51b3\u65b9\u6848\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u7684\u52a8\u6001\u7279\u6027\uff0c\u5305\u62ec\u7206\u53d1\u6027\u5c16\u5cf0\uff08\u6301\u7eed\u4e0d\u786e\u5b9a\u6027\u589e\u957f\uff09\u548c\u5cf0\u8c37\u5c16\u5cf0\uff08\u77ed\u6682\u7f6e\u4fe1\u540e\u6025\u5267\u53cd\u5f39\uff09\u3002\u8fd9\u4e9b\u6a21\u5f0f\u5728\u4e0d\u540c\u6a21\u578b\u548c\u8bad\u7ec3\u9636\u6bb5\u6301\u7eed\u5b58\u5728\uff0cEDIS\u4f5c\u4e3a\u8bca\u65ad\u4fe1\u53f7\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u3002", "conclusion": "\u71b5\u52a8\u6001\u4e3a\u7406\u89e3\u548c\u6539\u8fdbLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u89c6\u89d2\uff0cEDIS\u5728\u63a8\u7406\u65f6\u9009\u62e9\u548c\u8bad\u7ec3\u65f6\u6837\u672c\u7b5b\u9009\u65b9\u9762\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2602.01289", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01289", "abs": "https://arxiv.org/abs/2602.01289", "authors": ["Dung Anh Hoang", "Cuong Pham anh Trung Le", "Jianfei Cai", "Toan Do"], "title": "Gradient-Aligned Calibration for Post-Training Quantization of Diffusion Models", "comment": null, "summary": "Diffusion models have shown remarkable performance in image synthesis by progressively estimating a smooth transition from a Gaussian distribution of noise to a real image. Unfortunately, their practical deployment is limited by slow inference speed, high memory usage, and the computational demands of the noise estimation process. Post-training quantization (PTQ) emerges as a promising solution to accelerate sampling and reduce memory overhead for diffusion models. Existing PTQ methods for diffusion models typically apply uniform weights to calibration samples across timesteps, which is sub-optimal since data at different timesteps may contribute differently to the diffusion process. Additionally, due to varying activation distributions and gradients across timesteps, a uniform quantization approach is sub-optimal. Each timestep requires a different gradient direction for optimal quantization, and treating them equally can lead to conflicting gradients that degrade performance. In this paper, we propose a novel PTQ method that addresses these challenges by assigning appropriate weights to calibration samples. Specifically, our approach learns to assign optimal weights to calibration samples to align the quantized model's gradients across timesteps, facilitating the quantization process. Extensive experiments on CIFAR-10, LSUN-Bedrooms, and ImageNet demonstrate the superiority of our method compared to other PTQ methods for diffusion models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6269\u6563\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u4e3a\u4e0d\u540c\u65f6\u95f4\u6b65\u7684\u6821\u51c6\u6837\u672c\u5206\u914d\u6700\u4f18\u6743\u91cd\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u5747\u5300\u6743\u91cd\u5206\u914d\u548c\u68af\u5ea6\u51b2\u7a81\u7684\u95ee\u9898\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u867d\u7136\u56fe\u50cf\u5408\u6210\u6027\u80fd\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u63a8\u7406\u901f\u5ea6\u6162\u3001\u5185\u5b58\u5360\u7528\u9ad8\u3001\u566a\u58f0\u4f30\u8ba1\u8ba1\u7b97\u9700\u6c42\u5927\u7684\u95ee\u9898\u3002\u540e\u8bad\u7ec3\u91cf\u5316\u662f\u52a0\u901f\u91c7\u6837\u548c\u51cf\u5c11\u5185\u5b58\u5f00\u9500\u7684\u53ef\u884c\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u4e0d\u540c\u65f6\u95f4\u6b65\u4f7f\u7528\u5747\u5300\u6743\u91cd\u5206\u914d\u6821\u51c6\u6837\u672c\uff0c\u8fd9\u4e0d\u591f\u4f18\u5316\uff0c\u56e0\u4e3a\u4e0d\u540c\u65f6\u95f4\u6b65\u7684\u6570\u636e\u5bf9\u6269\u6563\u8fc7\u7a0b\u7684\u8d21\u732e\u4e0d\u540c\uff0c\u4e14\u6fc0\u6d3b\u5206\u5e03\u548c\u68af\u5ea6\u53d8\u5316\u5bfc\u81f4\u5747\u5300\u91cf\u5316\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u4e3a\u6821\u51c6\u6837\u672c\u5206\u914d\u6700\u4f18\u6743\u91cd\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u6743\u91cd\u5206\u914d\uff0c\u4f7f\u91cf\u5316\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u95f4\u6b65\u7684\u68af\u5ea6\u5bf9\u9f50\uff0c\u4ece\u800c\u4fc3\u8fdb\u91cf\u5316\u8fc7\u7a0b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4e3a\u4e0d\u540c\u65f6\u95f4\u6b65\u7684\u6821\u51c6\u6837\u672c\u5206\u914d\u9002\u5f53\u7684\u6743\u91cd\uff0c\u89e3\u51b3\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\u3002", "result": "\u5728CIFAR-10\u3001LSUN-Bedrooms\u548cImageNet\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u5176\u4ed6\u6269\u6563\u6a21\u578b\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u3002", "conclusion": "\u901a\u8fc7\u4e3a\u4e0d\u540c\u65f6\u95f4\u6b65\u7684\u6821\u51c6\u6837\u672c\u5b66\u4e60\u6700\u4f18\u6743\u91cd\u5206\u914d\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u6269\u6563\u6a21\u578b\u540e\u8bad\u7ec3\u91cf\u5316\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u9ad8\u91cf\u5316\u6548\u679c\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u5b9e\u7528\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01295", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01295", "abs": "https://arxiv.org/abs/2602.01295", "authors": ["Yu Chen", "Yuhao Liu", "Jiatai Huang", "Yihan Du", "Longbo Huang"], "title": "The BoBW Algorithms for Heavy-Tailed MDPs", "comment": null, "summary": "We investigate episodic Markov Decision Processes with heavy-tailed feedback (HTMDPs). Existing approaches for HTMDPs are conservative in stochastic environments and lack adaptivity in adversarial regimes. In this work, we propose algorithms ```HT-FTRL-OM``` and ```HT-FTRL-UOB``` for HTMDPs that achieve Best-of-Both-Worlds (BoBW) guarantees: instance-independent regret in adversarial environments and logarithmic instance-dependent regret in self-bounding (including the stochastic case) environments. For the known transition setting, ```HT-FTRL-OM``` applies the Follow-The-Regularized-Leader (FTRL) framework over occupancy measures with novel skipping loss estimators, achieving a $\\widetilde{\\mathcal{O}}(T^{1/\u03b1})$ regret bound in adversarial regimes and a $\\mathcal{O}(\\log T)$ regret in stochastic regimes. Building upon this framework, we develop a novel algorithm ```HT-FTRL-UOB``` to tackle the more challenging unknown-transition setting. This algorithm employs a pessimistic skipping loss estimator and achieves a $\\widetilde{\\mathcal{O}}(T^{1/\u03b1} + \\sqrt{T})$ regret in adversarial regimes and a $\\mathcal{O}(\\log^2(T))$ regret in stochastic regimes. Our analysis overcomes key barriers through several technical insights, including a local control mechanism for heavy-tailed shifted losses, a new suboptimal-mass propagation principle, and a novel regret decomposition that isolates transition uncertainty from heavy-tailed estimation errors and skipping bias.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u7b97\u6cd5HT-FTRL-OM\u548cHT-FTRL-UOB\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u91cd\u5c3e\u53cd\u9988\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\"\u4e24\u5168\u5176\u7f8e\"\u7684\u9057\u61be\u4fdd\u8bc1\uff1a\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u83b7\u5f97\u5b9e\u4f8b\u65e0\u5173\u7684\u9057\u61be\uff0c\u5728\u81ea\u7ea6\u675f\uff08\u5305\u62ec\u968f\u673a\uff09\u73af\u5883\u4e2d\u83b7\u5f97\u5bf9\u6570\u5b9e\u4f8b\u4f9d\u8d56\u7684\u9057\u61be\u3002", "motivation": "\u73b0\u6709\u5904\u7406\u91cd\u5c3e\u53cd\u9988MDP\u7684\u65b9\u6cd5\u5728\u968f\u673a\u73af\u5883\u4e2d\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7f3a\u4e4f\u9002\u5e94\u6027\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u9002\u5e94\u4e24\u79cd\u73af\u5883\u7684\u7b97\u6cd5\uff0c\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u3002", "method": "HT-FTRL-OM\u7b97\u6cd5\u5728\u5df2\u77e5\u8f6c\u79fb\u6982\u7387\u8bbe\u7f6e\u4e0b\uff0c\u91c7\u7528FTRL\u6846\u67b6\u7ed3\u5408\u65b0\u9896\u7684\u8df3\u8fc7\u635f\u5931\u4f30\u8ba1\u5668\u3002HT-FTRL-UOB\u7b97\u6cd5\u9488\u5bf9\u672a\u77e5\u8f6c\u79fb\u6982\u7387\u8bbe\u7f6e\uff0c\u4f7f\u7528\u60b2\u89c2\u8df3\u8fc7\u635f\u5931\u4f30\u8ba1\u5668\uff0c\u5e76\u5f15\u5165\u5c40\u90e8\u63a7\u5236\u673a\u5236\u3001\u6b21\u4f18\u8d28\u91cf\u4f20\u64ad\u539f\u7406\u7b49\u5173\u952e\u6280\u672f\u3002", "result": "HT-FTRL-OM\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u83b7\u5f97$\\widetilde{\\mathcal{O}}(T^{1/\u03b1})$\u9057\u61be\uff0c\u5728\u968f\u673a\u73af\u5883\u4e2d\u83b7\u5f97$\\mathcal{O}(\\log T)$\u9057\u61be\u3002HT-FTRL-UOB\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u83b7\u5f97$\\widetilde{\\mathcal{O}}(T^{1/\u03b1} + \\sqrt{T})$\u9057\u61be\uff0c\u5728\u968f\u673a\u73af\u5883\u4e2d\u83b7\u5f97$\\mathcal{O}(\\log^2(T))$\u9057\u61be\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u9996\u6b21\u5b9e\u73b0\u4e86\u91cd\u5c3e\u53cd\u9988MDP\u4e2d\u7684\"\u4e24\u5168\u5176\u7f8e\"\u4fdd\u8bc1\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6280\u672f\u6d1e\u5bdf\u514b\u670d\u4e86\u5173\u952e\u969c\u788d\uff0c\u4e3a\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u5b66\u4e60\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01308", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01308", "abs": "https://arxiv.org/abs/2602.01308", "authors": ["Hengjie Cao", "Mengyi Chen", "Yifeng Yang", "Fang Dong", "Ruijun Huang", "Anrui Chen", "Jixian Zhou", "Mingzhi Dong", "Yujiang Wang", "Dongsheng Li", "Wenyi Fang", "Yuanyi Lin", "Fan Wu", "Li Shang"], "title": "Dispelling the Curse of Singularities in Neural Network Optimizations", "comment": null, "summary": "This work investigates the optimization instability of deep neural networks from a less-explored yet insightful perspective: the emergence and amplification of singularities in the parametric space. Our analysis reveals that parametric singularities inevitably grow with gradient updates and further intensify alignment with representations, leading to increased singularities in the representation space. We show that the gradient Frobenius norms are bounded by the top singular values of the weight matrices, and as training progresses, the mutually reinforcing growth of weight and representation singularities, termed the curse of singularities, relaxes these bounds, escalating the risk of sharp loss explosions. To counter this, we propose Parametric Singularity Smoothing (PSS), a lightweight, flexible, and effective method for smoothing the singular spectra of weight matrices. Extensive experiments across diverse datasets, architectures, and optimizers demonstrate that PSS mitigates instability, restores trainability even after failure, and improves both training efficiency and generalization.", "AI": {"tldr": "\u8bba\u6587\u4ece\u53c2\u6570\u7a7a\u95f4\u5947\u5f02\u6027\u7684\u89d2\u5ea6\u7814\u7a76\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u4e0d\u7a33\u5b9a\u6027\uff0c\u63d0\u51fa\u53c2\u6570\u5947\u5f02\u6027\u5e73\u6ed1\u65b9\u6cd5\u7f13\u89e3\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027", "motivation": "\u7814\u7a76\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u4e0d\u7a33\u5b9a\u6027\u7684\u6df1\u5c42\u539f\u56e0\uff0c\u4ece\u53c2\u6570\u7a7a\u95f4\u5947\u5f02\u6027\u8fd9\u4e00\u8f83\u5c11\u63a2\u7d22\u4f46\u5bcc\u6709\u6d1e\u5bdf\u529b\u7684\u89c6\u89d2\u51fa\u53d1\uff0c\u63ed\u793a\u53c2\u6570\u5947\u5f02\u6027\u5982\u4f55\u968f\u8bad\u7ec3\u8fc7\u7a0b\u589e\u957f\u5e76\u5f71\u54cd\u6a21\u578b\u7a33\u5b9a\u6027", "method": "\u63d0\u51fa\u53c2\u6570\u5947\u5f02\u6027\u5e73\u6ed1\uff08PSS\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u6ed1\u6743\u91cd\u77e9\u9635\u7684\u5947\u5f02\u8c31\u6765\u7f13\u89e3\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u8f7b\u91cf\u3001\u7075\u6d3b\u4e14\u6709\u6548", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u67b6\u6784\u548c\u4f18\u5316\u5668\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPSS\u80fd\u591f\u7f13\u89e3\u4e0d\u7a33\u5b9a\u6027\uff0c\u5373\u4f7f\u5728\u8bad\u7ec3\u5931\u8d25\u540e\u4e5f\u80fd\u6062\u590d\u53ef\u8bad\u7ec3\u6027\uff0c\u540c\u65f6\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b", "conclusion": "\u53c2\u6570\u7a7a\u95f4\u5947\u5f02\u6027\u7684\u589e\u957f\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u4e0d\u7a33\u5b9a\u7684\u91cd\u8981\u539f\u56e0\uff0c\u901a\u8fc7PSS\u65b9\u6cd5\u5e73\u6ed1\u5947\u5f02\u8c31\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd"}}
{"id": "2602.01312", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01312", "abs": "https://arxiv.org/abs/2602.01312", "authors": ["Han Tong", "Shubhangi Ghosh", "Haolin Zou", "Arian Maleki"], "title": "Imperfect Influence, Preserved Rankings: A Theory of TRAK for Data Attribution", "comment": null, "summary": "Data attribution, tracing a model's prediction back to specific training data, is an important tool for interpreting sophisticated AI models. The widely used TRAK algorithm addresses this challenge by first approximating the underlying model with a kernel machine and then leveraging techniques developed for approximating the leave-one-out (ALO) risk. Despite its strong empirical performance, the theoretical conditions under which the TRAK approximations are accurate as well as the regimes in which they break down remain largely unexplored. In this paper, we provide a theoretical analysis of the TRAK algorithm, characterizing its performance and quantifying the errors introduced by the approximations on which the method relies. We show that although the approximations incur significant errors, TRAK's estimated influence remains highly correlated with the original influence and therefore largely preserves the relative ranking of data points. We corroborate our theoretical results through extensive simulations and empirical studies.", "AI": {"tldr": "TRAK\u7b97\u6cd5\u7528\u4e8e\u6570\u636e\u5f52\u56e0\uff0c\u901a\u8fc7\u6838\u673a\u5668\u8fd1\u4f3c\u6a21\u578b\u5e76\u5229\u7528ALO\u98ce\u9669\u8fd1\u4f3c\u6280\u672f\uff0c\u672c\u6587\u7406\u8bba\u5206\u6790\u5176\u6027\u80fd\uff0c\u53d1\u73b0\u8fd1\u4f3c\u8bef\u5dee\u867d\u5927\u4f46\u4fdd\u6301\u6570\u636e\u70b9\u76f8\u5bf9\u6392\u5e8f\u7684\u76f8\u5173\u6027", "motivation": "TRAK\u7b97\u6cd5\u5728\u6570\u636e\u5f52\u56e0\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u7406\u8bba\u51c6\u786e\u6027\u548c\u5931\u6548\u6761\u4ef6\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u7406\u8bba\u5206\u6790\u6765\u7406\u89e3\u5176\u6027\u80fd\u8fb9\u754c", "method": "\u5bf9TRAK\u7b97\u6cd5\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u91cf\u5316\u65b9\u6cd5\u4f9d\u8d56\u7684\u8fd1\u4f3c\u5f15\u5165\u7684\u8bef\u5dee\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c", "result": "\u5c3d\u7ba1\u8fd1\u4f3c\u5f15\u5165\u663e\u8457\u8bef\u5dee\uff0c\u4f46TRAK\u4f30\u8ba1\u7684\u5f71\u54cd\u4e0e\u539f\u59cb\u5f71\u54cd\u9ad8\u5ea6\u76f8\u5173\uff0c\u57fa\u672c\u4fdd\u6301\u6570\u636e\u70b9\u7684\u76f8\u5bf9\u6392\u5e8f", "conclusion": "TRAK\u7b97\u6cd5\u5728\u6570\u636e\u5f52\u56e0\u4e2d\u6709\u6548\uff0c\u8fd1\u4f3c\u8bef\u5dee\u4e0d\u5f71\u54cd\u76f8\u5bf9\u6392\u5e8f\u7684\u4fdd\u6301\uff0c\u4e3a\u7406\u89e3\u7b97\u6cd5\u6027\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e"}}
{"id": "2602.01322", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01322", "abs": "https://arxiv.org/abs/2602.01322", "authors": ["Panagiotis Koromilas", "Andreas D. Demou", "James Oldfield", "Yannis Panagakis", "Mihalis Nicolaou"], "title": "PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding", "comment": null, "summary": "Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms. However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether \"Starbucks\" arises from the composition of \"star\" and \"coffee\" features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on a shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 2-10$\\times$ larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency ($r = 0.06$ vs. $r = 0.82$ for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition, largely independent of surface statistics.", "AI": {"tldr": "PolySAE\u6269\u5c55\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u9ad8\u9636\u9879\u5efa\u6a21\u7279\u5f81\u4ea4\u4e92\uff0c\u89e3\u51b3\u7ebf\u6027SAE\u65e0\u6cd5\u6355\u6349\u7ec4\u5408\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7ec4\u5408\u7279\u5f81\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u5047\u8bbe\u7279\u5f81\u901a\u8fc7\u7ebf\u6027\u91cd\u6784\u76f8\u52a0\uff0c\u65e0\u6cd5\u533a\u5206\u7ec4\u5408\u7ed3\u6784\uff08\u5982\"Starbucks\"\u662f\"star\"\u548c\"coffee\"\u7684\u7ec4\u5408\u8fd8\u662f\u5171\u73b0\uff09\uff0c\u5bfc\u81f4\u4e3a\u590d\u5408\u6982\u5ff5\u5206\u914d\u5355\u4e00\u7279\u5f81\u800c\u975e\u53ef\u89e3\u91ca\u7684\u7ec4\u6210\u90e8\u5206\u3002", "method": "PolySAE\u5728SAE\u89e3\u7801\u5668\u4e2d\u5f15\u5165\u9ad8\u9636\u9879\uff0c\u901a\u8fc7\u5171\u4eab\u6295\u5f71\u5b50\u7a7a\u95f4\u4e0a\u7684\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\u5efa\u6a21\u7279\u5f81\u5bf9\u548c\u4e09\u5143\u7279\u5f81\u4ea4\u4e92\uff0c\u540c\u65f6\u4fdd\u6301\u7ebf\u6027\u7f16\u7801\u5668\u4ee5\u786e\u4fdd\u53ef\u89e3\u91ca\u6027\uff0c\u53c2\u6570\u5f00\u9500\u5c0f\uff08GPT2\u4e0a\u4ec53%\uff09\u3002", "result": "\u5728\u56db\u4e2a\u8bed\u8a00\u6a21\u578b\u548c\u4e09\u79cdSAE\u53d8\u4f53\u4e0a\uff0cPolySAE\u5e73\u5747\u63d0\u5347\u7ea68%\u7684\u63a2\u6d4bF1\u5206\u6570\uff0c\u4fdd\u6301\u76f8\u5f53\u7684\u91cd\u6784\u8bef\u5dee\uff0c\u7c7b\u522b\u6761\u4ef6\u7279\u5f81\u5206\u5e03\u7684Wasserstein\u8ddd\u79bb\u589e\u52a02-10\u500d\uff0c\u4ea4\u4e92\u6743\u91cd\u4e0e\u5171\u73b0\u9891\u7387\u76f8\u5173\u6027\u6781\u4f4e\uff08r=0.06 vs SAE\u7279\u5f81\u534f\u65b9\u5dee\u7684r=0.82\uff09\u3002", "conclusion": "\u591a\u9879\u5f0f\u9879\u80fd\u6355\u6349\u5f62\u6001\u7ed1\u5b9a\u548c\u77ed\u8bed\u7ec4\u5408\u7b49\u7ec4\u5408\u7ed3\u6784\uff0c\u57fa\u672c\u72ec\u7acb\u4e8e\u8868\u9762\u7edf\u8ba1\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u89e3\u91ca\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.01338", "categories": ["cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01338", "abs": "https://arxiv.org/abs/2602.01338", "authors": ["Fan Chen", "Sinho Chewi", "Constantinos Daskalakis", "Alexander Rakhlin"], "title": "High-accuracy sampling for diffusion models and log-concave distributions", "comment": null, "summary": "We present algorithms for diffusion model sampling which obtain $\u03b4$-error in $\\mathrm{polylog}(1/\u03b4)$ steps, given access to $\\widetilde O(\u03b4)$-accurate score estimates in $L^2$. This is an exponential improvement over all previous results. Specifically, under minimal data assumptions, the complexity is $\\widetilde O(d\\,\\mathrm{polylog}(1/\u03b4))$ where $d$ is the dimension of the data; under a non-uniform $L$-Lipschitz condition, the complexity is $\\widetilde O(\\sqrt{dL}\\,\\mathrm{polylog}(1/\u03b4))$; and if the data distribution has intrinsic dimension $d_\\star$, then the complexity reduces to $\\widetilde O(d_\\star\\,\\mathrm{polylog}(1/\u03b4))$. Our approach also yields the first $\\mathrm{polylog}(1/\u03b4)$ complexity sampler for general log-concave distributions using only gradient evaluations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6269\u6563\u6a21\u578b\u91c7\u6837\u7b97\u6cd5\uff0c\u80fd\u4ee5polylog(1/\u03b4)\u6b65\u6570\u8fbe\u5230\u03b4\u8bef\u5dee\uff0c\u76f8\u6bd4\u4e4b\u524d\u5de5\u4f5c\u5b9e\u73b0\u4e86\u6307\u6570\u7ea7\u6539\u8fdb\uff0c\u5e76\u5728\u4e0d\u540c\u6570\u636e\u5047\u8bbe\u4e0b\u7ed9\u51fa\u590d\u6742\u5ea6\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u91c7\u6837\u65b9\u6cd5\u5728\u8fbe\u5230\u03b4\u8bef\u5dee\u65f6\u9700\u8981\u8f83\u591a\u6b65\u9aa4\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u91c7\u6837\u7b97\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u6240\u9700\u6b65\u6570\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u6269\u6563\u6a21\u578b\u91c7\u6837\u7b97\u6cd5\uff0c\u5728L^2\u8303\u6570\u4e0b\u4f7f\u7528O(\u03b4)-\u7cbe\u786e\u7684\u5206\u6570\u4f30\u8ba1\uff0c\u901a\u8fc7\u6539\u8fdb\u91c7\u6837\u7b56\u7565\u5b9e\u73b0\u6307\u6570\u7ea7\u52a0\u901f\u3002", "result": "\u5728\u6700\u5c0f\u6570\u636e\u5047\u8bbe\u4e0b\u590d\u6742\u5ea6\u4e3aO(d polylog(1/\u03b4))\uff1b\u5728\u975e\u5747\u5300L-Lipschitz\u6761\u4ef6\u4e0b\u4e3aO(\u221a(dL) polylog(1/\u03b4))\uff1b\u5f53\u6570\u636e\u5206\u5e03\u5177\u6709\u5185\u5728\u7ef4\u5ea6d*\u65f6\uff0c\u590d\u6742\u5ea6\u964d\u81f3O(d* polylog(1/\u03b4))\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6269\u6563\u6a21\u578b\u91c7\u6837\u7684\u6307\u6570\u7ea7\u52a0\u901f\uff0c\u5e76\u4e3a\u4e00\u822c\u5bf9\u6570\u51f9\u5206\u5e03\u63d0\u4f9b\u4e86\u9996\u4e2a\u4ec5\u4f7f\u7528\u68af\u5ea6\u8bc4\u4f30\u7684polylog(1/\u03b4)\u590d\u6742\u5ea6\u91c7\u6837\u5668\u3002"}}
{"id": "2602.01339", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01339", "abs": "https://arxiv.org/abs/2602.01339", "authors": ["Difei Xu", "Youming Tao", "Meng Ding", "Chenglin Fan", "Di Wang"], "title": "Finding Differentially Private Second Order Stationary Points in Stochastic Minimax Optimization", "comment": null, "summary": "We provide the first study of the problem of finding differentially private (DP) second-order stationary points (SOSP) in stochastic (non-convex) minimax optimization. Existing literature either focuses only on first-order stationary points for minimax problems or on SOSP for classical stochastic minimization problems. This work provides, for the first time, a unified and detailed treatment of both empirical and population risks. Specifically, we propose a purely first-order method that combines a nested gradient descent--ascent scheme with SPIDER-style variance reduction and Gaussian perturbations to ensure privacy. A key technical device is a block-wise ($q$-period) analysis that controls the accumulation of stochastic variance and privacy noise without summing over the full iteration horizon, yielding a unified treatment of both empirical-risk and population formulations. Under standard smoothness, Hessian-Lipschitzness, and strong concavity assumptions, we establish high-probability guarantees for reaching an $(\u03b1,\\sqrt{\u03c1_\u03a6\u03b1})$-approximate second-order stationary point with $\u03b1= \\mathcal{O}( (\\frac{\\sqrt{d}}{n\\varepsilon})^{2/3})$ for empirical risk objectives and $\\mathcal{O}(\\frac{1}{n^{1/3}} + (\\frac{\\sqrt{d}}{n\\varepsilon})^{1/2})$ for population objectives, matching the best known rates for private first-order stationarity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7814\u7a76\u4e86\u5728\u968f\u673a\u975e\u51f8\u6781\u5c0f\u6781\u5927\u4f18\u5316\u4e2d\u5bfb\u627e\u5dee\u5206\u9690\u79c1\u4e8c\u9636\u5e73\u7a33\u70b9\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u5d4c\u5957\u68af\u5ea6\u4e0b\u964d-\u4e0a\u5347\u3001SPIDER\u65b9\u5dee\u7f29\u51cf\u548c\u9ad8\u65af\u6270\u52a8\u7684\u4e00\u9636\u65b9\u6cd5\uff0c\u5728\u7ecf\u9a8c\u98ce\u9669\u548c\u603b\u4f53\u98ce\u9669\u4e0b\u90fd\u83b7\u5f97\u4e86\u5339\u914d\u4e00\u9636\u5e73\u7a33\u70b9\u7684\u6700\u4f73\u9690\u79c1\u6536\u655b\u7387\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u8981\u4e48\u53ea\u5173\u6ce8\u6781\u5c0f\u6781\u5927\u95ee\u9898\u7684\u4e00\u9636\u5e73\u7a33\u70b9\uff0c\u8981\u4e48\u53ea\u5173\u6ce8\u7ecf\u5178\u968f\u673a\u6700\u5c0f\u5316\u95ee\u9898\u7684\u4e8c\u9636\u5e73\u7a33\u70b9\u3002\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u968f\u673a\u6781\u5c0f\u6781\u5927\u4f18\u5316\u4e2d\u7684\u5dee\u5206\u9690\u79c1\u4e8c\u9636\u5e73\u7a33\u70b9\u95ee\u9898\uff0c\u4e3a\u7ecf\u9a8c\u98ce\u9669\u548c\u603b\u4f53\u98ce\u9669\u63d0\u4f9b\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7eaf\u4e00\u9636\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u5d4c\u5957\u68af\u5ea6\u4e0b\u964d-\u4e0a\u5347\u65b9\u6848\u3001SPIDER\u98ce\u683c\u7684\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u548c\u9ad8\u65af\u6270\u52a8\u6765\u786e\u4fdd\u9690\u79c1\u3002\u5173\u952e\u6280\u672f\u662f\u91c7\u7528\u5757\u72b6\uff08q\u5468\u671f\uff09\u5206\u6790\u6765\u63a7\u5236\u968f\u673a\u65b9\u5dee\u548c\u9690\u79c1\u566a\u58f0\u7684\u7d2f\u79ef\uff0c\u65e0\u9700\u5bf9\u6574\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u6c42\u548c\uff0c\u4ece\u800c\u7edf\u4e00\u5904\u7406\u7ecf\u9a8c\u98ce\u9669\u548c\u603b\u4f53\u98ce\u9669\u3002", "result": "\u5728\u6807\u51c6\u5149\u6ed1\u6027\u3001Hessian-Lipschitz\u6027\u548c\u5f3a\u51f9\u6027\u5047\u8bbe\u4e0b\uff0c\u5efa\u7acb\u4e86\u9ad8\u6982\u7387\u4fdd\u8bc1\uff1a\u5bf9\u4e8e\u7ecf\u9a8c\u98ce\u9669\u76ee\u6807\uff0c\u8fbe\u5230(\u03b1,\u221a(\u03c1_\u03a6\u03b1))-\u8fd1\u4f3c\u4e8c\u9636\u5e73\u7a33\u70b9\uff0c\u5176\u4e2d\u03b1=O((\u221ad/n\u03b5)^{2/3})\uff1b\u5bf9\u4e8e\u603b\u4f53\u76ee\u6807\uff0c\u03b1=O(1/n^{1/3} + (\u221ad/n\u03b5)^{1/2})\uff0c\u5339\u914d\u4e86\u9690\u79c1\u4e00\u9636\u5e73\u7a33\u6027\u7684\u6700\u4f73\u5df2\u77e5\u901f\u7387\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u4e3a\u968f\u673a\u6781\u5c0f\u6781\u5927\u4f18\u5316\u4e2d\u7684\u5dee\u5206\u9690\u79c1\u4e8c\u9636\u5e73\u7a33\u70b9\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7814\u7a76\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7ecf\u9a8c\u98ce\u9669\u548c\u603b\u4f53\u98ce\u9669\u4e0b\u90fd\u8fbe\u5230\u4e86\u6700\u4f18\u6536\u655b\u7387\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u7684\u7a7a\u767d\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u590d\u6742\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2602.01357", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01357", "abs": "https://arxiv.org/abs/2602.01357", "authors": ["Shangzhe Li", "Xuchao Zhang", "Chetan Bansal", "Weitong Zhang"], "title": "Your Self-Play Algorithm is Secretly an Adversarial Imitator: Understanding LLM Self-Play through the Lens of Imitation Learning", "comment": "35 pages, 5 tables, 3 figures", "summary": "Self-play post-training methods has emerged as an effective approach for finetuning large language models and turn the weak language model into strong language model without preference data. However, the theoretical foundations for self-play finetuning remain underexplored. In this work, we tackle this by connecting self-play finetuning with adversarial imitation learning by formulating finetuning procedure as a min-max game between the model and a regularized implicit reward player parameterized by the model itself. This perspective unifies self-play imitation and general preference alignment within a common framework. Under this formulation, we present a game-theoretic analysis showing that the self-play finetuning will converge to it's equilibrium. Guided by this theoretical formulation, we propose a new self-play imitation finetuning algorithm based on the $\u03c7^2$-divergence variational objective with bounded rewards and improved stability. Experiments on various of language model finetuning tasks demonstrate consistent improvements over existing self-play methods and validate our theoretical insights.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u81ea\u535a\u5f08\u5fae\u8c03\u4e0e\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u51fa\u57fa\u4e8e\u03c7\u00b2\u6563\u5ea6\u7684\u53d8\u5206\u76ee\u6807\u7b97\u6cd5\uff0c\u5728\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u81ea\u535a\u5f08\u540e\u8bad\u7ec3\u65b9\u6cd5\u5df2\u6210\u4e3a\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u65e0\u9700\u504f\u597d\u6570\u636e\u5373\u53ef\u5c06\u5f31\u8bed\u8a00\u6a21\u578b\u8f6c\u53d8\u4e3a\u5f3a\u8bed\u8a00\u6a21\u578b\u3002\u7136\u800c\uff0c\u81ea\u535a\u5f08\u5fae\u8c03\u7684\u7406\u8bba\u57fa\u7840\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5c06\u5fae\u8c03\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u6a21\u578b\u4e0e\u7531\u6a21\u578b\u672c\u8eab\u53c2\u6570\u5316\u7684\u6b63\u5219\u5316\u9690\u5f0f\u5956\u52b1\u73a9\u5bb6\u4e4b\u95f4\u7684min-max\u535a\u5f08\uff0c\u63d0\u51fa\u57fa\u4e8e\u03c7\u00b2\u6563\u5ea6\u53d8\u5206\u76ee\u6807\u7684\u81ea\u535a\u5f08\u6a21\u4eff\u5fae\u8c03\u7b97\u6cd5\uff0c\u5177\u6709\u6709\u754c\u5956\u52b1\u548c\u6539\u8fdb\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u591a\u79cd\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u81ea\u535a\u5f08\u65b9\u6cd5\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "\u901a\u8fc7\u5c06\u81ea\u535a\u5f08\u5fae\u8c03\u4e0e\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60\u8054\u7cfb\u8d77\u6765\uff0c\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u6536\u655b\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u7a33\u5b9a\u7684\u7b97\u6cd5\uff0c\u4e3a\u81ea\u535a\u5f08\u5fae\u8c03\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6539\u8fdb\u3002"}}
{"id": "2602.01359", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01359", "abs": "https://arxiv.org/abs/2602.01359", "authors": ["Jinju Park", "Seokho Kang"], "title": "PaAno: Patch-Based Representation Learning for Time-Series Anomaly Detection", "comment": "Accepted by the 14th International Conference on Learning Representations (ICLR 2026)", "summary": "Although recent studies on time-series anomaly detection have increasingly adopted ever-larger neural network architectures such as transformers and foundation models, they incur high computational costs and memory usage, making them impractical for real-time and resource-constrained scenarios. Moreover, they often fail to demonstrate significant performance gains over simpler methods under rigorous evaluation protocols. In this study, we propose Patch-based representation learning for time-series Anomaly detection (PaAno), a lightweight yet effective method for fast and efficient time-series anomaly detection. PaAno extracts short temporal patches from time-series training data and uses a 1D convolutional neural network to embed each patch into a vector representation. The model is trained using a combination of triplet loss and pretext loss to ensure the embeddings capture informative temporal patterns from input patches. During inference, the anomaly score at each time step is computed by comparing the embeddings of its surrounding patches to those of normal patches extracted from the training time-series. Evaluated on the TSB-AD benchmark, PaAno achieved state-of-the-art performance, significantly outperforming existing methods, including those based on heavy architectures, on both univariate and multivariate time-series anomaly detection across various range-wise and point-wise performance measures.", "AI": {"tldr": "PaAno\uff1a\u57fa\u4e8e\u8865\u4e01\u8868\u793a\u7684\u8f7b\u91cf\u7ea7\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u75281D CNN\u63d0\u53d6\u65f6\u95f4\u8865\u4e01\u7279\u5f81\uff0c\u7ed3\u5408\u4e09\u5143\u7ec4\u635f\u5931\u548c\u9884\u6587\u672c\u635f\u5931\u8bad\u7ec3\uff0c\u5728TSB-AD\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982transformer\u548c\u57fa\u7840\u6a21\u578b\uff09\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u5185\u5b58\u5360\u7528\u5927\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u548c\u8d44\u6e90\u53d7\u9650\u573a\u666f\uff0c\u4e14\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002\u9700\u8981\u8f7b\u91cf\u7ea7\u4f46\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u4ece\u65f6\u95f4\u5e8f\u5217\u8bad\u7ec3\u6570\u636e\u4e2d\u63d0\u53d6\u77ed\u65f6\u95f4\u8865\u4e01\uff0c\u4f7f\u75281D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5c06\u6bcf\u4e2a\u8865\u4e01\u5d4c\u5165\u4e3a\u5411\u91cf\u8868\u793a\u3002\u7ed3\u5408\u4e09\u5143\u7ec4\u635f\u5931\u548c\u9884\u6587\u672c\u635f\u5931\u8bad\u7ec3\u6a21\u578b\uff0c\u786e\u4fdd\u5d4c\u5165\u6355\u83b7\u8f93\u5165\u8865\u4e01\u7684\u4fe1\u606f\u6027\u65f6\u95f4\u6a21\u5f0f\u3002", "result": "\u5728TSB-AD\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPaAno\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u5404\u79cd\u8303\u56f4\u6027\u548c\u70b9\u6027\u6027\u80fd\u6307\u6807\u4e0a\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ec\u57fa\u4e8e\u91cd\u578b\u67b6\u6784\u7684\u65b9\u6cd5\uff09\u3002", "conclusion": "PaAno\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4f46\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u8ba1\u7b97\u6210\u672c\u548c\u5185\u5b58\u95ee\u9898\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u9002\u5408\u5b9e\u65f6\u548c\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2602.01365", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01365", "abs": "https://arxiv.org/abs/2602.01365", "authors": ["Wang Yang", "Shouren Wang", "Chaoda Song", "Chuang Ma", "Xinpeng Li", "Nengbo Wang", "Kaixiong Zhou", "Vipin Chaudhary", "Xiaotian Han"], "title": "When Domains Interact: Asymmetric and Order-Sensitive Cross-Domain Effects in Reinforcement Learning for Reasoning", "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has become a key technique for improving reasoning abilities in large language models, yet its behavior under different domain sequencing strategies is poorly understood. In particular, the impact of sequential (one domain at a time) versus mixed-domain (multiple domain at a time) training in GRPO has not been systematically studied. We provide the first systematic analysis of training-order effects across math, science, logic, and puzzle reasoning tasks. We found (1) single-domain generalization is highly asymmetric: training on other domains improves math reasoning by approximately 25\\% accuracy, while yielding negligible transfer to logic and puzzle; (2) cross-domain interactions are highly order-dependent: training in the order math$\\rightarrow$science achieves 83\\% / 41\\% accuracy on math / science, while reversing the order to science$\\rightarrow$math degrades performance to 77\\% / 25\\%; (3) no single strategy is universally optimal in multi-domain training: sequential training favors math (up to 84\\%), mixed training favors science and logic, and poor ordering can incur large performance gaps (from 70\\% to 56\\%). Overall, our findings demonstrate that GRPO under multi-domain settings exhibits pronounced asymmetry, order sensitivity, and strategy dependence, highlighting the necessity of domain-aware and order-aware training design.", "AI": {"tldr": "GRPO\u5728\u4e0d\u540c\u9886\u57df\u8bad\u7ec3\u987a\u5e8f\u7b56\u7565\u4e0b\u7684\u884c\u4e3a\u5206\u6790\uff1a\u53d1\u73b0\u5355\u9886\u57df\u6cdb\u5316\u9ad8\u5ea6\u4e0d\u5bf9\u79f0\u3001\u8de8\u9886\u57df\u4ea4\u4e92\u9ad8\u5ea6\u987a\u5e8f\u4f9d\u8d56\u3001\u65e0\u5355\u4e00\u6700\u4f18\u591a\u9886\u57df\u8bad\u7ec3\u7b56\u7565\uff0c\u5f3a\u8c03\u9700\u8981\u9886\u57df\u611f\u77e5\u548c\u987a\u5e8f\u611f\u77e5\u7684\u8bad\u7ec3\u8bbe\u8ba1\u3002", "motivation": "GRPO\u5df2\u6210\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5176\u5728\u4e0d\u540c\u9886\u57df\u6392\u5e8f\u7b56\u7565\u4e0b\u7684\u884c\u4e3a\u7406\u89e3\u4e0d\u8db3\u3002\u7279\u522b\u662f\u987a\u5e8f\u8bad\u7ec3\uff08\u4e00\u6b21\u4e00\u4e2a\u9886\u57df\uff09\u4e0e\u6df7\u5408\u9886\u57df\u8bad\u7ec3\uff08\u591a\u4e2a\u9886\u57df\u540c\u65f6\uff09\u5728GRPO\u4e2d\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u5bf9\u6570\u5b66\u3001\u79d1\u5b66\u3001\u903b\u8f91\u548c\u8c1c\u9898\u63a8\u7406\u4efb\u52a1\u8fdb\u884c\u8bad\u7ec3\u987a\u5e8f\u6548\u5e94\u7684\u9996\u6b21\u7cfb\u7edf\u5206\u6790\uff0c\u6bd4\u8f83\u987a\u5e8f\u8bad\u7ec3\u4e0e\u6df7\u5408\u9886\u57df\u8bad\u7ec3\u7b56\u7565\u3002", "result": "1. \u5355\u9886\u57df\u6cdb\u5316\u9ad8\u5ea6\u4e0d\u5bf9\u79f0\uff1a\u5728\u5176\u4ed6\u9886\u57df\u8bad\u7ec3\u53ef\u5c06\u6570\u5b66\u63a8\u7406\u51c6\u786e\u7387\u63d0\u5347\u7ea625%\uff0c\u4f46\u5bf9\u903b\u8f91\u548c\u8c1c\u9898\u63a8\u7406\u51e0\u4e4e\u6ca1\u6709\u8fc1\u79fb\u6548\u679c\uff1b2. \u8de8\u9886\u57df\u4ea4\u4e92\u9ad8\u5ea6\u987a\u5e8f\u4f9d\u8d56\uff1a\u6570\u5b66\u2192\u79d1\u5b66\u987a\u5e8f\u8bad\u7ec3\u5728\u6570\u5b66/\u79d1\u5b66\u4e0a\u8fbe\u523083%/41%\u51c6\u786e\u7387\uff0c\u800c\u79d1\u5b66\u2192\u6570\u5b66\u987a\u5e8f\u5219\u964d\u81f377%/25%\uff1b3. \u65e0\u5355\u4e00\u6700\u4f18\u591a\u9886\u57df\u8bad\u7ec3\u7b56\u7565\uff1a\u987a\u5e8f\u8bad\u7ec3\u6709\u5229\u4e8e\u6570\u5b66\uff08\u6700\u9ad884%\uff09\uff0c\u6df7\u5408\u8bad\u7ec3\u6709\u5229\u4e8e\u79d1\u5b66\u548c\u903b\u8f91\uff0c\u4e0d\u826f\u6392\u5e8f\u53ef\u80fd\u5bfc\u81f4\u5927\u6027\u80fd\u5dee\u8ddd\uff08\u4ece70%\u964d\u81f356%\uff09\u3002", "conclusion": "GRPO\u5728\u591a\u9886\u57df\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u660e\u663e\u7684\u4e0d\u5bf9\u79f0\u6027\u3001\u987a\u5e8f\u654f\u611f\u6027\u548c\u7b56\u7565\u4f9d\u8d56\u6027\uff0c\u7a81\u663e\u4e86\u9886\u57df\u611f\u77e5\u548c\u987a\u5e8f\u611f\u77e5\u8bad\u7ec3\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2602.01367", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01367", "abs": "https://arxiv.org/abs/2602.01367", "authors": ["Pinar Erbil", "Alberto Archetti", "Eugenio Lomurno", "Matteo Matteucci"], "title": "Deep Variational Contrastive Learning for Joint Risk Stratification and Time-to-Event Estimation", "comment": null, "summary": "Survival analysis is essential for clinical decision-making, as it allows practitioners to estimate time-to-event outcomes, stratify patient risk profiles, and guide treatment planning. Deep learning has revolutionized this field with unprecedented predictive capabilities but faces a fundamental trade-off between performance and interpretability. While neural networks achieve high accuracy, their black-box nature limits clinical adoption. Conversely, deep clustering-based methods that stratify patients into interpretable risk groups typically sacrifice predictive power. We propose CONVERSE (CONtrastive Variational Ensemble for Risk Stratification and Estimation), a deep survival model that bridges this gap by unifying variational autoencoders with contrastive learning for interpretable risk stratification. CONVERSE combines variational embeddings with multiple intra- and inter-cluster contrastive losses. Self-paced learning progressively incorporates samples from easy to hard, improving training stability. The model supports cluster-specific survival heads, enabling accurate ensemble predictions. Comprehensive evaluation on four benchmark datasets demonstrates that CONVERSE achieves competitive or superior performance compared to existing deep survival methods, while maintaining meaningful patient stratification.", "AI": {"tldr": "CONVERSE\u662f\u4e00\u4e2a\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u5bf9\u6bd4\u5b66\u4e60\u7684\u6df1\u5ea6\u751f\u5b58\u5206\u6790\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u98ce\u9669\u5206\u5c42", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u751f\u5b58\u5206\u6790\u4e2d\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u6839\u672c\u6743\u8861\u95ee\u9898\u3002\u795e\u7ecf\u7f51\u7edc\u867d\u7136\u9884\u6d4b\u51c6\u786e\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u57fa\u4e8e\u805a\u7c7b\u7684\u53ef\u89e3\u91ca\u65b9\u6cd5\u901a\u5e38\u727a\u7272\u9884\u6d4b\u80fd\u529b\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u7684\u91c7\u7eb3", "method": "CONVERSE\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4f7f\u7528\u53d8\u5206\u5d4c\u5165\u548c\u591a\u79cd\u7c07\u5185\u3001\u7c07\u95f4\u5bf9\u6bd4\u635f\u5931\u3002\u91c7\u7528\u81ea\u6b65\u5b66\u4e60\u4ece\u6613\u5230\u96be\u9010\u6b65\u7eb3\u5165\u6837\u672c\uff0c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u652f\u6301\u7c07\u7279\u5b9a\u7684\u751f\u5b58\u5934\uff0c\u5b9e\u73b0\u51c6\u786e\u7684\u96c6\u6210\u9884\u6d4b", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0cCONVERSE\u76f8\u6bd4\u73b0\u6709\u6df1\u5ea6\u751f\u5b58\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u610f\u4e49\u7684\u60a3\u8005\u5206\u5c42", "conclusion": "CONVERSE\u901a\u8fc7\u7edf\u4e00\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u6210\u529f\u5f25\u5408\u4e86\u6df1\u5ea6\u751f\u5b58\u5206\u6790\u4e2d\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u4e86\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u98ce\u9669\u5206\u5c42\u5de5\u5177"}}
{"id": "2602.01399", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01399", "abs": "https://arxiv.org/abs/2602.01399", "authors": ["Fabian Fumagalli", "Landon Butler", "Justin Singh Kang", "Kannan Ramchandran", "R. Teal Witter"], "title": "An Odd Estimator for Shapley Values", "comment": null, "summary": "The Shapley value is a ubiquitous framework for attribution in machine learning, encompassing feature importance, data valuation, and causal inference. However, its exact computation is generally intractable, necessitating efficient approximation methods. While the most effective and popular estimators leverage the paired sampling heuristic to reduce estimation error, the theoretical mechanism driving this improvement has remained opaque. In this work, we provide an elegant and fundamental justification for paired sampling: we prove that the Shapley value depends exclusively on the odd component of the set function, and that paired sampling orthogonalizes the regression objective to filter out the irrelevant even component. Leveraging this insight, we propose OddSHAP, a novel consistent estimator that performs polynomial regression solely on the odd subspace. By utilizing the Fourier basis to isolate this subspace and employing a proxy model to identify high-impact interactions, OddSHAP overcomes the combinatorial explosion of higher-order approximations. Through an extensive benchmark evaluation, we find that OddSHAP achieves state-of-the-art estimation accuracy.", "AI": {"tldr": "OddSHAP\uff1a\u4e00\u79cd\u65b0\u9896\u7684Shapley\u503c\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u5229\u7528\u5947\u5b50\u7a7a\u95f4\u56de\u5f52\u548c\u5085\u91cc\u53f6\u57fa\u5206\u89e3\uff0c\u663e\u8457\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6", "motivation": "Shapley\u503c\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7cbe\u786e\u8ba1\u7b97\u901a\u5e38\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u9ad8\u6548\u8fd1\u4f3c\u65b9\u6cd5\u3002\u73b0\u6709\u6700\u6709\u6548\u7684\u4f30\u8ba1\u5668\u4f7f\u7528\u914d\u5bf9\u91c7\u6837\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4f46\u5176\u7406\u8bba\u673a\u5236\u4e00\u76f4\u4e0d\u660e\u786e\u3002", "method": "\u8bc1\u660e\u4e86Shapley\u503c\u4ec5\u4f9d\u8d56\u4e8e\u96c6\u5408\u51fd\u6570\u7684\u5947\u5206\u91cf\uff0c\u914d\u5bf9\u91c7\u6837\u901a\u8fc7\u6b63\u4ea4\u5316\u56de\u5f52\u76ee\u6807\u6765\u8fc7\u6ee4\u65e0\u5173\u7684\u5076\u5206\u91cf\u3002\u63d0\u51faOddSHAP\u4f30\u8ba1\u5668\uff1a1\uff09\u4f7f\u7528\u5085\u91cc\u53f6\u57fa\u5206\u89e3\u9694\u79bb\u5947\u5b50\u7a7a\u95f4\uff1b2\uff09\u5728\u5947\u5b50\u7a7a\u95f4\u4e0a\u8fdb\u884c\u591a\u9879\u5f0f\u56de\u5f52\uff1b3\uff09\u4f7f\u7528\u4ee3\u7406\u6a21\u578b\u8bc6\u522b\u9ad8\u5f71\u54cd\u529b\u4ea4\u4e92\uff0c\u907f\u514d\u9ad8\u9636\u8fd1\u4f3c\u7684\u7ec4\u5408\u7206\u70b8\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u57fa\u51c6\u8bc4\u4f30\uff0cOddSHAP\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "\u4e3a\u914d\u5bf9\u91c7\u6837\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5947\u5b50\u7a7a\u95f4\u56de\u5f52\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u8fdb\u4e86Shapley\u503c\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.01419", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01419", "abs": "https://arxiv.org/abs/2602.01419", "authors": ["Dennis Gross", "Helge Spieker", "Arnaud Gotlieb", "Emmanuel Stathatos", "Panorios Benardos", "George-Christopher Vosniakos"], "title": "Semi-supervised CAPP Transformer Learning via Pseudo-labeling", "comment": null, "summary": "High-level Computer-Aided Process Planning (CAPP) generates manufacturing process plans from part specifications. It suffers from limited dataset availability in industry, reducing model generalization. We propose a semi-supervised learning approach to improve transformer-based CAPP transformer models without manual labeling. An oracle, trained on available transformer behaviour data, filters correct predictions from unseen parts, which are then used for one-shot retraining. Experiments on small-scale datasets with simulated ground truth across the full data distribution show consistent accuracy gains over baselines, demonstrating the method's effectiveness in data-scarce manufacturing environments.", "AI": {"tldr": "\u63d0\u51fa\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u63d0\u5347\u57fa\u4e8eTransformer\u7684CAPP\u6a21\u578b\u6027\u80fd\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff0c\u901a\u8fc7\u8bad\u7ec3oracle\u7b5b\u9009\u6b63\u786e\u9884\u6d4b\u7528\u4e8e\u4e00\u6b21\u6027\u91cd\u8bad\u7ec3", "motivation": "\u5de5\u4e1a\u4e2dCAPP\u9762\u4e34\u6570\u636e\u96c6\u6709\u9650\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e0b\u7684\u6a21\u578b\u6027\u80fd\u63d0\u5347", "method": "\u4f7f\u7528\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff1a\u8bad\u7ec3oracle\u6a21\u578b\u7b5b\u9009\u6b63\u786e\u9884\u6d4b\uff0c\u5c06\u7b5b\u9009\u51fa\u7684\u9884\u6d4b\u7528\u4e8e\u4e00\u6b21\u6027\u91cd\u8bad\u7ec3\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8", "result": "\u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u4f7f\u7528\u6a21\u62df\u771f\u5b9e\u6570\u636e\u5206\u5e03\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u4e00\u81f4\u7684\u51c6\u786e\u7387\u63d0\u5347", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u7f3a\u7684\u5236\u9020\u73af\u5883\u4e2d\u6709\u6548\uff0c\u80fd\u63d0\u5347CAPP\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b"}}
{"id": "2602.01428", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01428", "abs": "https://arxiv.org/abs/2602.01428", "authors": ["Weiqing He", "Xiang Li", "Li Shen", "Weijie Su", "Qi Long"], "title": "Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models", "comment": "Accepted at ICLR 2026", "summary": "Watermarking is a principled approach for tracing the provenance of large language model (LLM) outputs, but its deployment in practice is hindered by inference inefficiency. Speculative sampling accelerates inference, with efficiency improving as the acceptance rate between draft and target models increases. Yet recent work reveals a fundamental trade-off: higher watermark strength reduces acceptance, preventing their simultaneous achievement. We revisit this trade-off and show it is not absolute. We introduce a quantitative measure of watermark strength that governs statistical detectability and is maximized when tokens are deterministic functions of pseudorandom numbers. Using this measure, we fully characterize the trade-off as a constrained optimization problem and derive explicit Pareto curves for two existing watermarking schemes. Finally, we introduce a principled mechanism that injects pseudorandomness into draft-token acceptance, ensuring maximal watermark strength while maintaining speculative sampling efficiency. Experiments further show that this approach improves detectability without sacrificing efficiency. Our findings uncover a principle that unites speculative sampling and watermarking, paving the way for their efficient and practical deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u63a8\u6d4b\u91c7\u6837\u6548\u7387\u7684\u540c\u65f6\u6700\u5927\u5316\u6c34\u5370\u5f3a\u5ea6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u6c34\u5370\u5f3a\u5ea6\u4e0e\u63a8\u6d4b\u91c7\u6837\u63a5\u53d7\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u6280\u672f\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002\u63a8\u6d4b\u91c7\u6837\u53ef\u4ee5\u52a0\u901f\u63a8\u7406\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u8868\u660e\u6c34\u5370\u5f3a\u5ea6\u4e0e\u63a8\u6d4b\u91c7\u6837\u63a5\u53d7\u7387\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u6743\u8861\uff1a\u66f4\u9ad8\u7684\u6c34\u5370\u5f3a\u5ea6\u4f1a\u964d\u4f4e\u63a5\u53d7\u7387\uff0c\u963b\u788d\u4e24\u8005\u540c\u65f6\u5b9e\u73b0\u3002", "method": "1. \u5f15\u5165\u91cf\u5316\u6c34\u5370\u5f3a\u5ea6\u5ea6\u91cf\uff0c\u8be5\u5ea6\u91cf\u63a7\u5236\u7edf\u8ba1\u53ef\u68c0\u6d4b\u6027\uff0c\u5e76\u5728\u4ee4\u724c\u662f\u4f2a\u968f\u673a\u6570\u7684\u786e\u5b9a\u6027\u51fd\u6570\u65f6\u8fbe\u5230\u6700\u5927\uff1b2. \u5c06\u6743\u8861\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u4e24\u79cd\u73b0\u6709\u6c34\u5370\u65b9\u6848\u63a8\u5bfc\u663e\u5f0f\u5e15\u7d2f\u6258\u66f2\u7ebf\uff1b3. \u63d0\u51fa\u539f\u5219\u6027\u673a\u5236\uff0c\u5c06\u4f2a\u968f\u673a\u6027\u6ce8\u5165\u8349\u7a3f\u4ee4\u724c\u63a5\u53d7\u8fc7\u7a0b\uff0c\u786e\u4fdd\u6700\u5927\u6c34\u5370\u5f3a\u5ea6\u540c\u65f6\u4fdd\u6301\u63a8\u6d4b\u91c7\u6837\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u6548\u7387\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u53ef\u68c0\u6d4b\u6027\u3002\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u63a8\u6d4b\u91c7\u6837\u4e0e\u6c34\u5370\u4e4b\u95f4\u7684\u7edf\u4e00\u539f\u7406\uff0c\u4e3a\u4e24\u8005\u7684\u9ad8\u6548\u5b9e\u7528\u90e8\u7f72\u94fa\u5e73\u9053\u8def\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u6c34\u5370\u5f3a\u5ea6\u4e0e\u63a8\u6d4b\u91c7\u6837\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u5e76\u975e\u7edd\u5bf9\uff0c\u901a\u8fc7\u5f15\u5165\u4f2a\u968f\u673a\u6027\u6ce8\u5165\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u63a8\u6d4b\u91c7\u6837\u6548\u7387\u7684\u540c\u65f6\u6700\u5927\u5316\u6c34\u5370\u5f3a\u5ea6\uff0c\u5b9e\u73b0\u4e24\u8005\u7684\u534f\u540c\u4f18\u5316\u3002"}}
{"id": "2602.01433", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01433", "abs": "https://arxiv.org/abs/2602.01433", "authors": ["Muhammad Hasan Ferdous", "Md Osman Gani"], "title": "DCD: Decomposition-based Causal Discovery from Autocorrelated and Non-Stationary Temporal Data", "comment": null, "summary": "Multivariate time series in domains such as finance, climate science, and healthcare often exhibit long-term trends, seasonal patterns, and short-term fluctuations, complicating causal inference under non-stationarity and autocorrelation. Existing causal discovery methods typically operate on raw observations, making them vulnerable to spurious edges and misattributed temporal dependencies. We introduce a decomposition-based causal discovery framework that separates each time series into trend, seasonal, and residual components and performs component-specific causal analysis. Trend components are assessed using stationarity tests, seasonal components using kernel-based dependence measures, and residual components using constraint-based causal discovery. The resulting component-level graphs are integrated into a unified multi-scale causal structure. This approach isolates long- and short-range causal effects, reduces spurious associations, and improves interpretability. Across extensive synthetic benchmarks and real-world climate data, our framework more accurately recovers ground-truth causal structure than state-of-the-art baselines, particularly under strong non-stationarity and temporal autocorrelation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5206\u89e3\u7684\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u8d8b\u52bf\u3001\u5b63\u8282\u6027\u548c\u6b8b\u5dee\u5206\u91cf\uff0c\u5206\u522b\u8fdb\u884c\u56e0\u679c\u5206\u6790\uff0c\u6700\u540e\u6574\u5408\u4e3a\u7edf\u4e00\u7684\u591a\u5c3a\u5ea6\u56e0\u679c\u7ed3\u6784\u3002", "motivation": "\u591a\u5143\u65f6\u95f4\u5e8f\u5217\uff08\u91d1\u878d\u3001\u6c14\u5019\u79d1\u5b66\u3001\u533b\u7597\u7b49\u9886\u57df\uff09\u5e38\u5448\u73b0\u957f\u671f\u8d8b\u52bf\u3001\u5b63\u8282\u6a21\u5f0f\u548c\u77ed\u671f\u6ce2\u52a8\uff0c\u5728\u975e\u5e73\u7a33\u6027\u548c\u81ea\u76f8\u5173\u6761\u4ef6\u4e0b\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u5f88\u590d\u6742\u3002\u73b0\u6709\u65b9\u6cd5\u76f4\u63a5\u5728\u539f\u59cb\u89c2\u6d4b\u4e0a\u64cd\u4f5c\uff0c\u5bb9\u6613\u4ea7\u751f\u865a\u5047\u8fb9\u548c\u9519\u8bef\u5f52\u56e0\u7684\u65f6\u95f4\u4f9d\u8d56\u3002", "method": "1. \u5c06\u6bcf\u4e2a\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u8d8b\u52bf\u3001\u5b63\u8282\u6027\u548c\u6b8b\u5dee\u5206\u91cf\uff1b2. \u5bf9\u8d8b\u52bf\u5206\u91cf\u4f7f\u7528\u5e73\u7a33\u6027\u68c0\u9a8c\uff1b3. \u5bf9\u5b63\u8282\u6027\u5206\u91cf\u4f7f\u7528\u57fa\u4e8e\u6838\u7684\u4f9d\u8d56\u5ea6\u91cf\uff1b4. \u5bf9\u6b8b\u5dee\u5206\u91cf\u4f7f\u7528\u57fa\u4e8e\u7ea6\u675f\u7684\u56e0\u679c\u53d1\u73b0\uff1b5. \u5c06\u5206\u91cf\u7ea7\u56fe\u6574\u5408\u4e3a\u7edf\u4e00\u7684\u591a\u5c3a\u5ea6\u56e0\u679c\u7ed3\u6784\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u6c14\u5019\u6570\u636e\u4e0a\uff0c\u8be5\u6846\u67b6\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u66f4\u51c6\u786e\u5730\u6062\u590d\u771f\u5b9e\u56e0\u679c\u7ed3\u6784\uff0c\u7279\u522b\u662f\u5728\u5f3a\u975e\u5e73\u7a33\u6027\u548c\u65f6\u95f4\u81ea\u76f8\u5173\u6761\u4ef6\u4e0b\u3002", "conclusion": "\u5206\u89e3\u65b9\u6cd5\u80fd\u5206\u79bb\u957f\u671f\u548c\u77ed\u671f\u56e0\u679c\u6548\u5e94\uff0c\u51cf\u5c11\u865a\u5047\u5173\u8054\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u975e\u5e73\u7a33\u548c\u81ea\u76f8\u5173\u65f6\u95f4\u5e8f\u5217\u7684\u56e0\u679c\u53d1\u73b0\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2602.01434", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.01434", "abs": "https://arxiv.org/abs/2602.01434", "authors": ["Andrea Montanari", "Zihao Wang"], "title": "Phase Transitions for Feature Learning in Neural Networks", "comment": "74 pages; 17 pdf figures", "summary": "According to a popular viewpoint, neural networks learn from data by first identifying low-dimensional representations, and subsequently fitting the best model in this space. Recent works provide a formalization of this phenomenon when learning multi-index models. In this setting, we are given $n$ i.i.d. pairs $({\\boldsymbol x}_i,y_i)$, where the covariate vectors ${\\boldsymbol x}_i\\in\\mathbb{R}^d$ are isotropic, and responses $y_i$ only depend on ${\\boldsymbol x}_i$ through a $k$-dimensional projection ${\\boldsymbol \u0398}_*^{\\sf T}{\\boldsymbol x}_i$. Feature learning amounts to learning the latent space spanned by ${\\boldsymbol \u0398}_*$.\n  In this context, we study the gradient descent dynamics of two-layer neural networks under the proportional asymptotics $n,d\\to\\infty$, $n/d\\to\u03b4$, while the dimension of the latent space $k$ and the number of hidden neurons $m$ are kept fixed. Earlier work establishes that feature learning via polynomial-time algorithms is possible if $\u03b4> \u03b4_{\\text{alg}}$, for $\u03b4_{\\text{alg}}$ a threshold depending on the data distribution, and is impossible (within a certain class of algorithms) below $\u03b4_{\\text{alg}}$. Here we derive an analogous threshold $\u03b4_{\\text{NN}}$ for two-layer networks. Our characterization of $\u03b4_{\\text{NN}}$ opens the way to study the dependence of learning dynamics on the network architecture and training algorithm.\n  The threshold $\u03b4_{\\text{NN}}$ is determined by the following scenario. Training first visits points for which the gradient of the empirical risk is large and learns the directions spanned by these gradients. Then the gradient becomes smaller and the dynamics becomes dominated by negative directions of the Hessian. The threshold $\u03b4_{\\text{NN}}$ corresponds to a phase transition in the spectrum of the Hessian in this second phase.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u5728\u6bd4\u4f8b\u6e10\u8fd1\u6761\u4ef6\u4e0b\u5b66\u4e60\u591a\u7d22\u5f15\u6a21\u578b\u7684\u68af\u5ea6\u4e0b\u964d\u52a8\u529b\u5b66\uff0c\u63a8\u5bfc\u51fa\u7279\u5f81\u5b66\u4e60\u7684\u9608\u503c\u03b4_NN\uff0c\u8be5\u9608\u503c\u7531Hessian\u77e9\u9635\u8c31\u7684\u76f8\u53d8\u51b3\u5b9a\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u5b66\u4e60\u6570\u636e\u4e2d\u7684\u4f4e\u7ef4\u8868\u793a\uff0c\u7279\u522b\u662f\u5728\u591a\u7d22\u5f15\u6a21\u578b\u8bbe\u7f6e\u4e0b\uff0c\u7406\u89e3\u7279\u5f81\u5b66\u4e60\u7684\u7406\u8bba\u9608\u503c\u6761\u4ef6\u3002", "method": "\u5728\u6bd4\u4f8b\u6e10\u8fd1\u6846\u67b6\u4e0b\uff08n,d\u2192\u221e\uff0cn/d\u2192\u03b4\uff09\uff0c\u5206\u6790\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u68af\u5ea6\u4e0b\u964d\u52a8\u529b\u5b66\uff0c\u5176\u4e2d\u6f5c\u5728\u7a7a\u95f4\u7ef4\u5ea6k\u548c\u9690\u85cf\u795e\u7ecf\u5143\u6570m\u56fa\u5b9a\u3002\u901a\u8fc7\u7814\u7a76\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u68af\u5ea6\u548cHessian\u77e9\u9635\u7684\u884c\u4e3a\u6765\u786e\u5b9a\u7279\u5f81\u5b66\u4e60\u9608\u503c\u3002", "result": "\u63a8\u5bfc\u51fa\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u7279\u5f81\u5b66\u4e60\u9608\u503c\u03b4_NN\uff0c\u8be5\u9608\u503c\u5bf9\u5e94\u4e8e\u8bad\u7ec3\u7b2c\u4e8c\u9636\u6bb5Hessian\u77e9\u9635\u8c31\u7684\u76f8\u53d8\u3002\u8bad\u7ec3\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\u5b66\u4e60\u5927\u68af\u5ea6\u65b9\u5411\uff0c\u7136\u540e\u53d7Hessian\u8d1f\u65b9\u5411\u4e3b\u5bfc\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u8bad\u7ec3\u7b97\u6cd5\u5bf9\u5b66\u4e60\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u03b4_NN\u9608\u503c\u7684\u8868\u5f81\u4f7f\u5f97\u80fd\u591f\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u7f51\u7edc\u914d\u7f6e\u4e0b\u7684\u5b66\u4e60\u884c\u4e3a\u3002"}}
{"id": "2602.01437", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01437", "abs": "https://arxiv.org/abs/2602.01437", "authors": ["Yinsong Wang", "Shahin Shahrampour"], "title": "Theoretical Analysis of Measure Consistency Regularization for Partially Observed Data", "comment": null, "summary": "The problem of corrupted data, missing features, or missing modalities continues to plague the modern machine learning landscape. To address this issue, a class of regularization methods that enforce consistency between imputed and fully observed data has emerged as a promising approach for improving model generalization, particularly in partially observed settings. We refer to this class of methods as Measure Consistency Regularization (MCR). Despite its empirical success in various applications, such as image inpainting, data imputation and semi-supervised learning, a fundamental understanding of the theoretical underpinnings of MCR remains limited. This paper bridges this gap by offering theoretical insights into why, when, and how MCR enhances imputation quality under partial observability, viewed through the lens of neural network distance.\n  Our theoretical analysis identifies the term responsible for MCR's generalization advantage and extends to the imperfect training regime, demonstrating that this advantage is not always guaranteed. Guided by these insights, we propose a novel training protocol that monitors the duality gap to determine an early stopping point that preserves the generalization benefit. We then provide detailed empirical evidence to support our theoretical claims and to show the effectiveness and accuracy of our proposed stopping condition. We further provide a set of real-world data simulations to show the versatility of MCR under different model architectures designed for different data sources.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u795e\u7ecf\u7f51\u7edc\u8ddd\u79bb\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u5206\u6790\u4e86\u6d4b\u91cf\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff08MCR\uff09\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6570\u636e\u4e0b\u63d0\u5347\u63d2\u8865\u8d28\u91cf\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5bf9\u5076\u95f4\u9699\u76d1\u63a7\u7684\u65e9\u505c\u8bad\u7ec3\u534f\u8bae\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6d4b\u91cf\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff08MCR\uff09\u5728\u56fe\u50cf\u4fee\u590d\u3001\u6570\u636e\u63d2\u8865\u548c\u534a\u76d1\u7763\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u7ecf\u9a8c\u6210\u529f\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u4ecd\u7136\u6709\u9650\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4ece\u7406\u8bba\u89d2\u5ea6\u7406\u89e3MCR\u4e3a\u4f55\u3001\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u63d0\u5347\u90e8\u5206\u53ef\u89c2\u6d4b\u6570\u636e\u4e0b\u7684\u63d2\u8865\u8d28\u91cf\u3002", "method": "1. \u4ece\u795e\u7ecf\u7f51\u7edc\u8ddd\u79bb\u7684\u7406\u8bba\u89c6\u89d2\u5206\u6790MCR\uff1b2. \u8bc6\u522bMCR\u5e26\u6765\u6cdb\u5316\u4f18\u52bf\u7684\u5173\u952e\u9879\uff1b3. \u63d0\u51fa\u57fa\u4e8e\u5bf9\u5076\u95f4\u9699\u76d1\u63a7\u7684\u65e9\u505c\u8bad\u7ec3\u534f\u8bae\uff1b4. \u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6a21\u62df\u9a8c\u8bc1\u7406\u8bba\u4e3b\u5f20\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eMCR\u7684\u6cdb\u5316\u4f18\u52bf\u5e76\u975e\u603b\u662f\u4fdd\u8bc1\uff0c\u7279\u522b\u662f\u5728\u4e0d\u5b8c\u7f8e\u8bad\u7ec3\u673a\u5236\u4e0b\u3002\u63d0\u51fa\u7684\u57fa\u4e8e\u5bf9\u5076\u95f4\u9699\u76d1\u63a7\u7684\u65e9\u505c\u65b9\u6cd5\u80fd\u6709\u6548\u4fdd\u7559\u6cdb\u5316\u4f18\u52bf\uff0c\u5b9e\u8bc1\u7ed3\u679c\u652f\u6301\u4e86\u7406\u8bba\u4e3b\u5f20\uff0c\u5e76\u5c55\u793a\u4e86MCR\u5728\u4e0d\u540c\u6570\u636e\u6e90\u548c\u6a21\u578b\u67b6\u6784\u4e0b\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aMCR\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u9610\u660e\u4e86\u5176\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6570\u636e\u4e0b\u7684\u5de5\u4f5c\u673a\u5236\uff0c\u63d0\u51fa\u7684\u65e9\u505c\u8bad\u7ec3\u534f\u8bae\u80fd\u6709\u6548\u63d0\u5347MCR\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u4e3a\u5904\u7406\u6570\u636e\u635f\u574f\u3001\u7279\u5f81\u7f3a\u5931\u6216\u591a\u6a21\u6001\u7f3a\u5931\u7b49\u5b9e\u9645\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2602.01439", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01439", "abs": "https://arxiv.org/abs/2602.01439", "authors": ["Perry Dong", "Kuo-Han Hung", "Alexander Swerdlow", "Dorsa Sadigh", "Chelsea Finn"], "title": "TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse", "comment": null, "summary": "Despite scale driving substantial recent advancements in machine learning, reinforcement learning (RL) methods still primarily use small value functions. Naively scaling value functions -- including with a transformer architecture, which is known to be highly scalable -- often results in learning instability and worse performance. In this work, we ask what prevents transformers from scaling effectively for value functions? Through empirical analysis, we identify the critical failure mode in this scaling: attention scores collapse as capacity increases. Our key insight is that we can effectively prevent this collapse and stabilize training by controlling the entropy of the attention scores, thereby enabling the use of larger models. To this end, we propose Transformer Q-Learning (TQL), a method that unlocks the scaling potential of transformers in learning value functions in RL. Our approach yields up to a 43% improvement in performance when scaling from the smallest to the largest network sizes, while prior methods suffer from performance degradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTransformer Q-Learning (TQL)\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u6ce8\u610f\u529b\u5206\u6570\u7684\u71b5\u6765\u7a33\u5b9a\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u4ef7\u503c\u51fd\u6570\u7f29\u653e\u65f6\u6ce8\u610f\u529b\u5206\u6570\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u4f7fTransformer\u80fd\u591f\u6709\u6548\u6269\u5c55\u3002", "motivation": "\u5c3d\u7ba1\u89c4\u6a21\u6269\u5c55\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4ecd\u4e3b\u8981\u4f7f\u7528\u5c0f\u578b\u4ef7\u503c\u51fd\u6570\u3002\u7b80\u5355\u5730\u5c06Transformer\u67b6\u6784\u7528\u4e8e\u4ef7\u503c\u51fd\u6570\u6269\u5c55\u901a\u5e38\u4f1a\u5bfc\u81f4\u5b66\u4e60\u4e0d\u7a33\u5b9a\u548c\u6027\u80fd\u4e0b\u964d\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76Transformer\u5728\u4ef7\u503c\u51fd\u6570\u6269\u5c55\u4e2d\u7684\u969c\u788d\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u8bc6\u522b\u4e86\u6ce8\u610f\u529b\u5206\u6570\u5d29\u6e83\u662f\u6269\u5c55\u5931\u8d25\u7684\u5173\u952e\u539f\u56e0\uff0c\u63d0\u51fa\u901a\u8fc7\u63a7\u5236\u6ce8\u610f\u529b\u5206\u6570\u7684\u71b5\u6765\u9632\u6b62\u5d29\u6e83\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u5f00\u53d1\u4e86Transformer Q-Learning (TQL)\u65b9\u6cd5\uff0c\u6709\u6548\u7a33\u5b9a\u8bad\u7ec3\u5e76\u5b9e\u73b0Transformer\u5728\u4ef7\u503c\u51fd\u6570\u5b66\u4e60\u4e2d\u7684\u6269\u5c55\u6f5c\u529b\u3002", "result": "TQL\u65b9\u6cd5\u5728\u4ece\u6700\u5c0f\u5230\u6700\u5927\u7f51\u7edc\u89c4\u6a21\u7684\u6269\u5c55\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe43%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u800c\u5148\u524d\u65b9\u6cd5\u5728\u6269\u5c55\u65f6\u4f1a\u51fa\u73b0\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u901a\u8fc7\u63a7\u5236\u6ce8\u610f\u529b\u5206\u6570\u7684\u71b5\u53ef\u4ee5\u6709\u6548\u9632\u6b62Transformer\u5728\u4ef7\u503c\u51fd\u6570\u6269\u5c55\u4e2d\u7684\u5d29\u6e83\u95ee\u9898\uff0cTQL\u65b9\u6cd5\u6210\u529f\u89e3\u9501\u4e86Transformer\u5728\u5f3a\u5316\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u5b66\u4e60\u4e2d\u7684\u6269\u5c55\u6f5c\u529b\u3002"}}
{"id": "2602.01442", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01442", "abs": "https://arxiv.org/abs/2602.01442", "authors": ["Donald Ye"], "title": "The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks", "comment": "8 pages, 4 figures. Submitted to the ICLR 2026 Workshop on Latent & Implicit Thinking (LIT). Code:https://anonymous.4open.science/r/ICLR_2026_LIT-workshop_CG-D42B", "summary": "Removing ''important'' high-gradient components from a neural network can improve generalization, while removing unimportant'' low-gradient components can destroy it. We demonstrate this paradox by formalizing the \\textit{Gradient-Causal Gap} in Transformers trained on algorithmic tasks. While gradient magnitude and causal importance align on simple tasks ($\u03c1=0.73$ for reversal), this relationship collapses as task complexity increases ($\u03c1=0.32$ for sorting), sometimes becoming inverted ($\u03c1=-0.11$). Pruning experiments reveal that gradient magnitude is not merely inaccurate but \\textit{unpredictably} so. Removing low-gradient ''Hidden Heroes'' consistently devastates OOD accuracy ($-32\\%$). Removing high-gradient ''Gradient Bloats'' is a coin flip: harmless in most seeds (indicating optimization noise), catastrophic in others (indicating overfitting circuits). This unpredictability means gradient-based pruning cannot reliably preserve model capabilities.", "AI": {"tldr": "\u68af\u5ea6\u5927\u5c0f\u4e0e\u56e0\u679c\u91cd\u8981\u6027\u5728Transformer\u4e2d\u5e76\u4e0d\u4e00\u81f4\uff0c\u68af\u5ea6\u5927\u5c0f\u65e0\u6cd5\u53ef\u9760\u6307\u5bfc\u526a\u679d", "motivation": "\u7814\u7a76\u68af\u5ea6\u5927\u5c0f\u4e0e\u6a21\u578b\u7ec4\u4ef6\u56e0\u679c\u91cd\u8981\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a2\u7d22\u68af\u5ea6\u5927\u5c0f\u662f\u5426\u53ef\u9760\u6307\u5bfc\u795e\u7ecf\u7f51\u7edc\u526a\u679d", "method": "\u5728\u7b97\u6cd5\u4efb\u52a1\u4e0a\u8bad\u7ec3Transformer\uff0c\u5206\u6790\u68af\u5ea6\u5927\u5c0f\u4e0e\u56e0\u679c\u91cd\u8981\u6027\u7684\u76f8\u5173\u6027\uff0c\u8fdb\u884c\u526a\u679d\u5b9e\u9a8c\u9a8c\u8bc1\u68af\u5ea6\u6307\u5bfc\u7684\u6709\u6548\u6027", "result": "\u7b80\u5355\u4efb\u52a1\u4e2d\u68af\u5ea6\u4e0e\u56e0\u679c\u91cd\u8981\u6027\u76f8\u5173(\u03c1=0.73)\uff0c\u590d\u6742\u4efb\u52a1\u4e2d\u76f8\u5173\u6027\u5d29\u6e83(\u03c1=0.32)\u751a\u81f3\u53cd\u8f6c(\u03c1=-0.11)\u3002\u526a\u679d\u4f4e\u68af\u5ea6\"\u9690\u85cf\u82f1\u96c4\"\u4e25\u91cd\u635f\u5bb3OOD\u51c6\u786e\u7387(-32%)\uff0c\u526a\u679d\u9ad8\u68af\u5ea6\"\u68af\u5ea6\u81a8\u80c0\"\u7ed3\u679c\u4e0d\u53ef\u9884\u6d4b", "conclusion": "\u68af\u5ea6\u5927\u5c0f\u65e0\u6cd5\u53ef\u9760\u6307\u5bfc\u526a\u679d\uff0c\u68af\u5ea6\u4e0e\u56e0\u679c\u91cd\u8981\u6027\u5173\u7cfb\u968f\u4efb\u52a1\u590d\u6742\u5ea6\u53d8\u5316\uff0c\u57fa\u4e8e\u68af\u5ea6\u7684\u526a\u679d\u65b9\u6cd5\u65e0\u6cd5\u53ef\u9760\u4fdd\u7559\u6a21\u578b\u80fd\u529b"}}
{"id": "2602.01445", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01445", "abs": "https://arxiv.org/abs/2602.01445", "authors": ["Ons Saadallah", "M\u00e1ty\u00e1s and\u00f3", "Tam\u00e1s G\u00e1bor Orosz"], "title": "A Meta-Knowledge-Augmented LLM Framework for Hyperparameter Optimization in Time-Series Forecasting", "comment": null, "summary": "Hyperparameter optimization (HPO) plays a central role in the performance of deep learning models, yet remains computationally expensive and difficult to interpret, particularly for time-series forecasting. While Bayesian Optimization (BO) is a standard approach, it typically treats tuning tasks independently and provides limited insight into its decisions. Recent advances in large language models (LLMs) offer new opportunities to incorporate structured prior knowledge and reasoning into optimization pipelines. We introduce LLM-AutoOpt, a hybrid HPO framework that combines BO with LLM-based contextual reasoning. The framework encodes dataset meta-features, model descriptions, historical optimization outcomes, and target objectives as structured meta-knowledge within LLM prompts, using BO to initialize the search and mitigate cold-start effects. This design enables context-aware and stable hyperparameter refinement while exposing the reasoning behind optimization decisions. Experiments on a multivariate time series forecasting benchmark demonstrate that LLM-AutoOpt achieves improved predictive performance and more interpretable optimization behavior compared to BO and LLM baselines without meta-knowledge.", "AI": {"tldr": "LLM-AutoOpt\uff1a\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u4e0eLLM\u63a8\u7406\u7684\u6df7\u5408\u8d85\u53c2\u6570\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u63d0\u5347\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u8d85\u53c2\u6570\u4f18\u5316\u4e2d\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u3002\u867d\u7136\u8d1d\u53f6\u65af\u4f18\u5316\u662f\u6807\u51c6\u65b9\u6cd5\uff0c\u4f46\u901a\u5e38\u5c06\u8c03\u4f18\u4efb\u52a1\u89c6\u4e3a\u72ec\u7acb\uff0c\u4e14\u51b3\u7b56\u8fc7\u7a0b\u7f3a\u4e4f\u6d1e\u5bdf\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\u4e3a\u5c06\u7ed3\u6784\u5316\u5148\u9a8c\u77e5\u8bc6\u548c\u63a8\u7406\u878d\u5165\u4f18\u5316\u6d41\u7a0b\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "\u63d0\u51faLLM-AutoOpt\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u4e0e\u57fa\u4e8eLLM\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u3002\u6846\u67b6\u5c06\u6570\u636e\u96c6\u5143\u7279\u5f81\u3001\u6a21\u578b\u63cf\u8ff0\u3001\u5386\u53f2\u4f18\u5316\u7ed3\u679c\u548c\u76ee\u6807\u76ee\u6807\u7f16\u7801\u4e3aLLM\u63d0\u793a\u4e2d\u7684\u7ed3\u6784\u5316\u5143\u77e5\u8bc6\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u521d\u59cb\u5316\u641c\u7d22\u5e76\u7f13\u89e3\u51b7\u542f\u52a8\u6548\u5e94\u3002\u8fd9\u79cd\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u4e14\u7a33\u5b9a\u7684\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u540c\u65f6\u66b4\u9732\u4f18\u5316\u51b3\u7b56\u80cc\u540e\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLLM-AutoOpt\u76f8\u6bd4\u6ca1\u6709\u5143\u77e5\u8bc6\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u548cLLM\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u9884\u6d4b\u6027\u80fd\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u884c\u4e3a\u3002", "conclusion": "LLM-AutoOpt\u6210\u529f\u5730\u5c06LLM\u63a8\u7406\u80fd\u529b\u4e0e\u8d1d\u53f6\u65af\u4f18\u5316\u76f8\u7ed3\u5408\uff0c\u4e3a\u8d85\u53c2\u6570\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u3002"}}
{"id": "2602.01453", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01453", "abs": "https://arxiv.org/abs/2602.01453", "authors": ["Idan Barnea", "Orin Levy", "Yishay Mansour"], "title": "Provable Cooperative Multi-Agent Exploration for Reward-Free MDPs", "comment": null, "summary": "We study cooperative multi-agent reinforcement learning in the setting of reward-free exploration, where multiple agents jointly explore an unknown MDP in order to learn its dynamics (without observing rewards). We focus on a tabular finite-horizon MDP and adopt a phased learning framework. In each learning phase, multiple agents independently interact with the environment. More specifically, in each learning phase, each agent is assigned a policy, executes it, and observes the resulting trajectory. Our primary goal is to characterize the tradeoff between the number of learning phases and the number of agents, especially when the number of learning phases is small.\n  Our results identify a sharp transition governed by the horizon $H$. When the number of learning phases equals $H$, we present a computationally efficient algorithm that uses only $\\tilde{O}(S^6 H^6 A / \u03b5^2)$ agents to obtain an $\u03b5$ approximation of the dynamics (i.e., yields an $\u03b5$-optimal policy for any reward function). We complement our algorithm with a lower bound showing that any algorithm restricted to $\u03c1< H$ phases requires at least $A^{H/\u03c1}$ agents to achieve constant accuracy. Thus, we show that it is essential to have an order of $H$ learning phases if we limit the number of agents to be polynomial.", "AI": {"tldr": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u65e0\u5956\u52b1\u63a2\u7d22\u95ee\u9898\uff0c\u5206\u6790\u5b66\u4e60\u9636\u6bb5\u6570\u4e0e\u667a\u80fd\u4f53\u6570\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u53d1\u73b0\u7531\u65f6\u95f4\u6b65\u957fH\u63a7\u5236\u7684\u5c16\u9510\u8f6c\u53d8\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u65e0\u5956\u52b1\u63a2\u7d22\u8bbe\u7f6e\u4e0b\u7684\u5408\u4f5c\u95ee\u9898\uff0c\u63a2\u7d22\u591a\u4e2a\u667a\u80fd\u4f53\u5982\u4f55\u5728\u6ca1\u6709\u5956\u52b1\u89c2\u5bdf\u7684\u60c5\u51b5\u4e0b\u8054\u5408\u63a2\u7d22\u672a\u77e5MDP\u4ee5\u5b66\u4e60\u5176\u52a8\u6001\u7279\u6027\uff0c\u7279\u522b\u5173\u6ce8\u5b66\u4e60\u9636\u6bb5\u6570\u4e0e\u667a\u80fd\u4f53\u6570\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u5206\u9636\u6bb5\u5b66\u4e60\u6846\u67b6\uff0c\u6bcf\u4e2a\u5b66\u4e60\u9636\u6bb5\u4e2d\u591a\u4e2a\u667a\u80fd\u4f53\u72ec\u7acb\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u88ab\u5206\u914d\u4e00\u4e2a\u7b56\u7565\u5e76\u6267\u884c\uff0c\u89c2\u5bdf\u4ea7\u751f\u7684\u8f68\u8ff9\u3002\u63d0\u51fa\u8ba1\u7b97\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u5f53\u5b66\u4e60\u9636\u6bb5\u6570\u7b49\u4e8eH\u65f6\uff0c\u4ec5\u9700\u591a\u9879\u5f0f\u6570\u91cf\u7684\u667a\u80fd\u4f53\u5373\u53ef\u83b7\u5f97\u52a8\u6001\u7279\u6027\u7684\u03b5\u8fd1\u4f3c\u3002", "result": "\u5f53\u5b66\u4e60\u9636\u6bb5\u6570\u7b49\u4e8eH\u65f6\uff0c\u63d0\u51fa\u7b97\u6cd5\u4ec5\u9700\u00d5(S\u2076H\u2076A/\u03b5\u00b2)\u4e2a\u667a\u80fd\u4f53\u5373\u53ef\u83b7\u5f97\u52a8\u6001\u7279\u6027\u7684\u03b5\u8fd1\u4f3c\uff1b\u5f53\u5b66\u4e60\u9636\u6bb5\u6570\u03c1<H\u65f6\uff0c\u4efb\u4f55\u7b97\u6cd5\u81f3\u5c11\u9700\u8981A^(H/\u03c1)\u4e2a\u667a\u80fd\u4f53\u624d\u80fd\u8fbe\u5230\u6052\u5b9a\u7cbe\u5ea6\uff0c\u8868\u660e\u9700\u8981H\u91cf\u7ea7\u7684\u5b66\u4e60\u9636\u6bb5\u624d\u80fd\u5c06\u667a\u80fd\u4f53\u6570\u91cf\u9650\u5236\u5728\u591a\u9879\u5f0f\u7ea7\u522b\u3002", "conclusion": "\u5728\u591a\u667a\u80fd\u4f53\u65e0\u5956\u52b1\u63a2\u7d22\u4e2d\uff0c\u5b66\u4e60\u9636\u6bb5\u6570\u4e0e\u667a\u80fd\u4f53\u6570\u91cf\u4e4b\u95f4\u5b58\u5728\u7531H\u63a7\u5236\u7684\u5c16\u9510\u6743\u8861\uff1a\u9700\u8981H\u91cf\u7ea7\u7684\u5b66\u4e60\u9636\u6bb5\u624d\u80fd\u5b9e\u73b0\u667a\u80fd\u4f53\u6570\u91cf\u7684\u591a\u9879\u5f0f\u7f29\u653e\uff0c\u5426\u5219\u9700\u8981\u6307\u6570\u7ea7\u6570\u91cf\u7684\u667a\u80fd\u4f53\u3002"}}
{"id": "2602.01454", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01454", "abs": "https://arxiv.org/abs/2602.01454", "authors": ["Amirreza Shiralinasab Langari", "Leila Yeganeh", "Kim Khoa Nguyen"], "title": "Modeling Topological Impact on Node Attribute Distributions in Attributed Graphs", "comment": null, "summary": "We investigate how the topology of attributed graphs influences the distribution of node attributes. This work offers a novel perspective by treating topology and attributes as structurally distinct but interacting components. We introduce an algebraic approach that combines a graph's topology with the probability distribution of node attributes, resulting in topology-influenced distributions. First, we develop a categorical framework to formalize how a node perceives the graph's topology. We then quantify this point of view and integrate it with the distribution of node attributes to capture topological effects. We interpret these topology-conditioned distributions as approximations of the posteriors $P(\\cdot \\mid v)$ and $P(\\cdot \\mid \\mathcal{G})$.\n  We further establish a principled sufficiency condition by showing that, on complete graphs, where topology carries no informative structure, our construction recovers the original attribute distribution. To evaluate our approach, we introduce an intentionally simple testbed model, $\\textbf{ID}$, and use unsupervised graph anomaly detection as a probing task.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee3\u6570\u65b9\u6cd5\uff0c\u5c06\u56fe\u62d3\u6251\u4e0e\u8282\u70b9\u5c5e\u6027\u5206\u5e03\u76f8\u7ed3\u5408\uff0c\u5f62\u6210\u62d3\u6251\u5f71\u54cd\u5206\u5e03\uff0c\u7528\u4e8e\u56fe\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u3002", "motivation": "\u7814\u7a76\u56fe\u62d3\u6251\u5982\u4f55\u5f71\u54cd\u8282\u70b9\u5c5e\u6027\u7684\u5206\u5e03\uff0c\u5c06\u62d3\u6251\u548c\u5c5e\u6027\u89c6\u4e3a\u7ed3\u6784\u4e0d\u540c\u4f46\u76f8\u4e92\u4f5c\u7528\u7684\u7ec4\u4ef6\uff0c\u4e3a\u7406\u89e3\u56fe\u6570\u636e\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "method": "1. \u5f00\u53d1\u8303\u7574\u8bba\u6846\u67b6\u5f62\u5f0f\u5316\u8282\u70b9\u5bf9\u56fe\u62d3\u6251\u7684\u611f\u77e5\uff1b2. \u91cf\u5316\u8fd9\u79cd\u89c6\u89d2\u5e76\u4e0e\u8282\u70b9\u5c5e\u6027\u5206\u5e03\u6574\u5408\uff1b3. \u5f15\u5165\u7b80\u5355\u7684\u6d4b\u8bd5\u6a21\u578bID\uff1b4. \u4f7f\u7528\u65e0\u76d1\u7763\u56fe\u5f02\u5e38\u68c0\u6d4b\u4f5c\u4e3a\u9a8c\u8bc1\u4efb\u52a1\u3002", "result": "\u5efa\u7acb\u4e86\u5145\u5206\u6027\u6761\u4ef6\uff1a\u5728\u5b8c\u5168\u56fe\u4e2d\uff0c\u62d3\u6251\u4e0d\u643a\u5e26\u4fe1\u606f\u7ed3\u6784\u65f6\uff0c\u8be5\u65b9\u6cd5\u80fd\u6062\u590d\u539f\u59cb\u5c5e\u6027\u5206\u5e03\u3002\u901a\u8fc7\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4ee3\u6570\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u56fe\u62d3\u6251\u4e0e\u8282\u70b9\u5c5e\u6027\u5206\u5e03\u76f8\u7ed3\u5408\uff0c\u4e3a\u7406\u89e3\u62d3\u6251\u5982\u4f55\u5f71\u54cd\u5c5e\u6027\u5206\u5e03\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5c55\u793a\u4e86\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.01456", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01456", "abs": "https://arxiv.org/abs/2602.01456", "authors": ["Yilun Kuang", "Yash Dagade", "Tim G. J. Rudner", "Randall Balestriero", "Yann LeCun"], "title": "Rectified LpJEPA: Joint-Embedding Predictive Architectures with Sparse and Maximum-Entropy Representations", "comment": null, "summary": "Joint-Embedding Predictive Architectures (JEPA) learn view-invariant representations and admit projection-based distribution matching for collapse prevention. Existing approaches regularize representations towards isotropic Gaussian distributions, but inherently favor dense representations and fail to capture the key property of sparsity observed in efficient representations. We introduce Rectified Distribution Matching Regularization (RDMReg), a sliced two-sample distribution-matching loss that aligns representations to a Rectified Generalized Gaussian (RGG) distribution. RGG enables explicit control over expected $\\ell_0$ norm through rectification, while preserving maximum-entropy up to rescaling under expected $\\ell_p$ norm constraints. Equipping JEPAs with RDMReg yields Rectified LpJEPA, which strictly generalizes prior Gaussian-based JEPAs. Empirically, Rectified LpJEPA learns sparse, non-negative representations with favorable sparsity-performance trade-offs and competitive downstream performance on image classification benchmarks, demonstrating that RDMReg effectively enforces sparsity while preserving task-relevant information.", "AI": {"tldr": "\u63d0\u51faRDMReg\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u5c06JEPA\u8868\u793a\u5bf9\u9f50\u5230Rectified Generalized Gaussian\u5206\u5e03\uff0c\u5b9e\u73b0\u7a00\u758f\u8868\u793a\u63a7\u5236\uff0c\u4f18\u4e8e\u73b0\u6709\u9ad8\u65af\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709JEPA\u65b9\u6cd5\u4f7f\u7528\u5404\u5411\u540c\u6027\u9ad8\u65af\u5206\u5e03\u6b63\u5219\u5316\u8868\u793a\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u504f\u5411\u5bc6\u96c6\u8868\u793a\uff0c\u65e0\u6cd5\u6355\u6349\u9ad8\u6548\u8868\u793a\u4e2d\u7684\u7a00\u758f\u6027\u8fd9\u4e00\u5173\u952e\u7279\u6027\u3002", "method": "\u5f15\u5165Rectified Distribution Matching Regularization (RDMReg)\uff0c\u4e00\u79cd\u5207\u7247\u53cc\u6837\u672c\u5206\u5e03\u5339\u914d\u635f\u5931\uff0c\u5c06\u8868\u793a\u5bf9\u9f50\u5230Rectified Generalized Gaussian (RGG)\u5206\u5e03\u3002RGG\u901a\u8fc7\u6574\u6d41\u673a\u5236\u663e\u5f0f\u63a7\u5236\u671f\u671b\u21130\u8303\u6570\uff0c\u540c\u65f6\u5728\u671f\u671b\u2113p\u8303\u6570\u7ea6\u675f\u4e0b\u4fdd\u6301\u6700\u5927\u71b5\u3002", "result": "Rectified LpJEPA\u5b66\u4e60\u5230\u7a00\u758f\u3001\u975e\u8d1f\u8868\u793a\uff0c\u5728\u7a00\u758f\u6027\u4e0e\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u83b7\u5f97\u6709\u7ade\u4e89\u529b\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "RDMReg\u80fd\u6709\u6548\u5f3a\u5236\u7a00\u758f\u6027\u540c\u65f6\u4fdd\u7559\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff0cRectified LpJEPA\u4e25\u683c\u6cdb\u5316\u4e86\u5148\u524d\u57fa\u4e8e\u9ad8\u65af\u7684JEPA\u65b9\u6cd5\u3002"}}
{"id": "2602.01468", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01468", "abs": "https://arxiv.org/abs/2602.01468", "authors": ["Viet Nguyen", "Tuan Minh Pham", "Thinh Cao", "Tan Dinh", "Huy Nguyen", "Nhat Ho", "Alessandro Rinaldo"], "title": "A Statistical Theory of Gated Attention through the Lens of Hierarchical Mixture of Experts", "comment": "Viet Nguyen, Tuan Minh Pham, and Thinh Cao contributed equally to this work", "summary": "Self-attention has greatly contributed to the success of the widely used Transformer architecture by enabling learning from data with long-range dependencies. In an effort to improve performance, a gated attention model that leverages a gating mechanism within the multi-head self-attention has recently been proposed as a promising alternative. Gated attention has been empirically demonstrated to increase the expressiveness of low-rank mapping in standard attention and even to eliminate the attention sink phenomenon. Despite its efficacy, a clear theoretical understanding of gated attention's benefits remains lacking in the literature. To close this gap, we rigorously show that each entry in a gated attention matrix or a multi-head self-attention matrix can be written as a hierarchical mixture of experts. By recasting learning as an expert estimation problem, we demonstrate that gated attention is more sample-efficient than multi-head self-attention. In particular, while the former needs only a polynomial number of data points to estimate an expert, the latter requires exponentially many data points to achieve the same estimation error. Furthermore, our analysis also provides a theoretical justification for why gated attention yields higher performance when a gate is placed at the output of the scaled dot product attention or the value map rather than at other positions in the multi-head self-attention architecture.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u95e8\u63a7\u6ce8\u610f\u529b\u6bd4\u591a\u5934\u81ea\u6ce8\u610f\u529b\u66f4\u6837\u672c\u9ad8\u6548\uff0c\u524d\u8005\u53ea\u9700\u591a\u9879\u5f0f\u6570\u91cf\u6837\u672c\u4f30\u8ba1\u4e13\u5bb6\uff0c\u540e\u8005\u9700\u8981\u6307\u6570\u7ea7\u6837\u672c\u8fbe\u5230\u76f8\u540c\u8bef\u5dee\u3002", "motivation": "\u95e8\u63a7\u6ce8\u610f\u529b\u5728\u591a\u5934\u81ea\u6ce8\u610f\u529b\u4e2d\u5f15\u5165\u95e8\u63a7\u673a\u5236\uff0c\u7ecf\u9a8c\u4e0a\u80fd\u63d0\u5347\u6027\u80fd\u3001\u589e\u52a0\u8868\u8fbe\u80fd\u529b\u5e76\u6d88\u9664\u6ce8\u610f\u529b\u6c47\u805a\u73b0\u8c61\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u7406\u89e3\u5176\u4f18\u52bf\u3002", "method": "\u5c06\u95e8\u63a7\u6ce8\u610f\u529b\u77e9\u9635\u548c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u77e9\u9635\u7684\u6bcf\u4e2a\u6761\u76ee\u91cd\u65b0\u8868\u8ff0\u4e3a\u5206\u5c42\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u5c06\u5b66\u4e60\u95ee\u9898\u8f6c\u5316\u4e3a\u4e13\u5bb6\u4f30\u8ba1\u95ee\u9898\uff0c\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u95e8\u63a7\u6ce8\u610f\u529b\u6bd4\u591a\u5934\u81ea\u6ce8\u610f\u529b\u66f4\u6837\u672c\u9ad8\u6548\uff1a\u95e8\u63a7\u6ce8\u610f\u529b\u53ea\u9700\u591a\u9879\u5f0f\u6570\u91cf\u6570\u636e\u70b9\u4f30\u8ba1\u4e13\u5bb6\uff0c\u800c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u9700\u8981\u6307\u6570\u7ea7\u6570\u636e\u70b9\u624d\u80fd\u8fbe\u5230\u76f8\u540c\u4f30\u8ba1\u8bef\u5dee\u3002", "conclusion": "\u95e8\u63a7\u6ce8\u610f\u529b\u7684\u7406\u8bba\u4f18\u52bf\u5728\u4e8e\u5176\u6837\u672c\u6548\u7387\u66f4\u9ad8\uff0c\u4e14\u4e3a\u95e8\u63a7\u673a\u5236\u653e\u7f6e\u5728\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b\u8f93\u51fa\u6216\u503c\u6620\u5c04\u4f4d\u7f6e\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2602.01469", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01469", "abs": "https://arxiv.org/abs/2602.01469", "authors": ["Mude Hui", "Xin Huang", "Jaime Campos Salas", "Yue Sun", "Nathan Pemberton", "Xiang Song", "Ashish Khetan", "George Karypis"], "title": "P-EAGLE: Parallel-Drafting EAGLE with Scalable Training", "comment": null, "summary": "Reasoning LLMs produce longer outputs, requiring speculative decoding drafters trained on extended sequences. Parallel drafting - predicting multiple tokens per forward pass - offers latency benefits over sequential generation, but training complexity scales quadratically with the product of sequence length and parallel positions, rendering long-context training impractical. We present P(arallel)-EAGLE, which transforms EAGLE from autoregressive to parallel multi-token prediction via a learnable shared hidden state. To scale training to long contexts, we develop a framework featuring attention mask pre-computation and sequence partitioning techniques, enabling gradient accumulation within individual sequences for parallel-prediction training. We implement P-EAGLE in vLLM and demonstrate speedups of 1.10-1.36x over autoregressive EAGLE-3 across GPT-OSS 120B, 20B, and Qwen3-Coder 30B.", "AI": {"tldr": "P-EAGLE\u5c06EAGLE\u4ece\u81ea\u56de\u5f52\u8f6c\u6362\u4e3a\u5e76\u884c\u591atoken\u9884\u6d4b\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5171\u4eab\u9690\u85cf\u72b6\u6001\u5b9e\u73b0\uff0c\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5728\u63a8\u7406\u65f6\u83b7\u5f971.10-1.36\u500d\u52a0\u901f\u3002", "motivation": "\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u66f4\u957f\u8f93\u51fa\u9700\u8981\u8bad\u7ec3\u5728\u957f\u5e8f\u5217\u4e0a\u7684\u63a8\u6d4b\u89e3\u7801\u8349\u7a3f\u6a21\u578b\u3002\u5e76\u884c\u8349\u7a3f\uff08\u6bcf\u6b21\u524d\u5411\u4f20\u64ad\u9884\u6d4b\u591a\u4e2atoken\uff09\u76f8\u6bd4\u987a\u5e8f\u751f\u6210\u6709\u5ef6\u8fdf\u4f18\u52bf\uff0c\u4f46\u8bad\u7ec3\u590d\u6742\u5ea6\u968f\u5e8f\u5217\u957f\u5ea6\u548c\u5e76\u884c\u4f4d\u7f6e\u4e58\u79ef\u5448\u4e8c\u6b21\u65b9\u589e\u957f\uff0c\u4f7f\u5f97\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u63d0\u51faP-EAGLE\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5171\u4eab\u9690\u85cf\u72b6\u6001\u5c06EAGLE\u4ece\u81ea\u56de\u5f52\u8f6c\u6362\u4e3a\u5e76\u884c\u591atoken\u9884\u6d4b\u3002\u4e3a\u6269\u5c55\u5230\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u6ce8\u610f\u529b\u63a9\u7801\u9884\u8ba1\u7b97\u548c\u5e8f\u5217\u5206\u533a\u6280\u672f\u7684\u6846\u67b6\uff0c\u652f\u6301\u5728\u5355\u4e2a\u5e8f\u5217\u5185\u8fdb\u884c\u68af\u5ea6\u7d2f\u79ef\u7684\u5e76\u884c\u9884\u6d4b\u8bad\u7ec3\u3002", "result": "\u5728vLLM\u4e2d\u5b9e\u73b0P-EAGLE\uff0c\u5728GPT-OSS 120B\u300120B\u548cQwen3-Coder 30B\u6a21\u578b\u4e0a\u76f8\u6bd4\u81ea\u56de\u5f52EAGLE-3\u83b7\u5f971.10-1.36\u500d\u7684\u52a0\u901f\u3002", "conclusion": "P-EAGLE\u6210\u529f\u89e3\u51b3\u4e86\u5e76\u884c\u8349\u7a3f\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u591atoken\u5e76\u884c\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\u3002"}}
{"id": "2602.01480", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01480", "abs": "https://arxiv.org/abs/2602.01480", "authors": ["Eric Regis", "Sinho Chewi"], "title": "Rod Flow: A Continuous-Time Model for Gradient Descent at the Edge of Stability", "comment": null, "summary": "How can we understand gradient-based training over non-convex landscapes? The edge of stability phenomenon, introduced in Cohen et al. (2021), indicates that the answer is not so simple: namely, gradient descent (GD) with large step sizes often diverges away from the gradient flow. In this regime, the \"Central Flow\", recently proposed in Cohen et al. (2025), provides an accurate ODE approximation to the GD dynamics over many architectures. In this work, we propose Rod Flow, an alternative ODE approximation, which carries the following advantages: (1) it rests on a principled derivation stemming from a physical picture of GD iterates as an extended one-dimensional object -- a \"rod\"; (2) it better captures GD dynamics for simple toy examples and matches the accuracy of Central Flow for representative neural network architectures, and (3) is explicit and cheap to compute. Theoretically, we prove that Rod Flow correctly predicts the critical sharpness threshold and explains self-stabilization in quartic potentials. We validate our theory with a range of numerical experiments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRod Flow\u4f5c\u4e3a\u68af\u5ea6\u4e0b\u964d\u5728\u975e\u51f8\u666f\u89c2\u4e2d\u8bad\u7ec3\u7684\u65b0ODE\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684Central Flow\uff0cRod Flow\u57fa\u4e8e\u7269\u7406\u56fe\u50cf\u63a8\u5bfc\uff0c\u80fd\u66f4\u597d\u6355\u6349GD\u52a8\u6001\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u5e76\u80fd\u9884\u6d4b\u4e34\u754c\u9510\u5ea6\u9608\u503c\u3002", "motivation": "\u7406\u89e3\u68af\u5ea6\u4e0b\u964d\u5728\u975e\u51f8\u666f\u89c2\u4e2d\u7684\u8bad\u7ec3\u884c\u4e3a\u3002Cohen\u7b49\u4eba(2021)\u63d0\u51fa\u7684\"\u7a33\u5b9a\u6027\u8fb9\u7f18\"\u73b0\u8c61\u8868\u660e\uff0c\u5927\u5b66\u4e60\u7387\u7684\u68af\u5ea6\u4e0b\u964d\u4f1a\u504f\u79bb\u68af\u5ea6\u6d41\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u52a8\u6001\u8fd1\u4f3c\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRod Flow ODE\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5c06GD\u8fed\u4ee3\u89c6\u4e3a\u4e00\u7ef4\u6269\u5c55\u5bf9\u8c61\uff08\"\u6746\"\uff09\u8fdb\u884c\u7269\u7406\u56fe\u50cf\u63a8\u5bfc\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u539f\u7406\u6027\u63a8\u5bfc\uff0c\u80fd\u66f4\u597d\u6355\u6349GD\u52a8\u6001\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "result": "Rod Flow\u5728\u7b80\u5355\u73a9\u5177\u793a\u4f8b\u4e2d\u80fd\u66f4\u597d\u6355\u6349GD\u52a8\u6001\uff0c\u5728\u4ee3\u8868\u6027\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u4e0eCentral Flow\u7cbe\u5ea6\u76f8\u5f53\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86Rod Flow\u80fd\u6b63\u786e\u9884\u6d4b\u4e34\u754c\u9510\u5ea6\u9608\u503c\u5e76\u89e3\u91ca\u56db\u6b21\u52bf\u4e2d\u7684\u81ea\u7a33\u5b9a\u73b0\u8c61\u3002", "conclusion": "Rod Flow\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684ODE\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7269\u7406\u539f\u7406\u63a8\u5bfc\uff0c\u80fd\u51c6\u786e\u8fd1\u4f3c\u5927\u5b66\u4e60\u7387\u4e0b\u68af\u5ea6\u4e0b\u964d\u7684\u52a8\u6001\uff0c\u4e3a\u7406\u89e3\u975e\u51f8\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.01483", "categories": ["cs.LG", "cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.01483", "abs": "https://arxiv.org/abs/2602.01483", "authors": ["Edwin V. Bonilla", "He Zhao", "Daniel M. Steinberg"], "title": "Causal Preference Elicitation", "comment": null, "summary": "We propose causal preference elicitation, a Bayesian framework for expert-in-the-loop causal discovery that actively queries local edge relations to concentrate a posterior over directed acyclic graphs (DAGs). From any black-box observational posterior, we model noisy expert judgments with a three-way likelihood over edge existence and direction. Posterior inference uses a flexible particle approximation, and queries are selected by an efficient expected information gain criterion on the expert's categorical response. Experiments on synthetic graphs, protein signaling data, and a human gene perturbation benchmark show faster posterior concentration and improved recovery of directed effects under tight query budgets.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u504f\u597d\u83b7\u53d6\u6846\u67b6\uff0c\u901a\u8fc7\u4e3b\u52a8\u67e5\u8be2\u4e13\u5bb6\u5bf9\u5c40\u90e8\u8fb9\u5173\u7cfb\u7684\u5224\u65ad\u6765\u52a0\u901f\u56e0\u679c\u56fe\u540e\u9a8c\u5206\u5e03\u6536\u655b", "motivation": "\u4f20\u7edf\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u800c\u4e13\u5bb6\u77e5\u8bc6\u53ef\u4ee5\u8865\u5145\u6570\u636e\u4e0d\u8db3\uff0c\u4f46\u5982\u4f55\u6709\u6548\u6574\u5408\u4e13\u5bb6\u5224\u65ad\u5e76\u51cf\u5c11\u67e5\u8be2\u6210\u672c\u662f\u5173\u952e\u95ee\u9898", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u4ece\u89c2\u6d4b\u540e\u9a8c\u51fa\u53d1\uff0c\u7528\u4e09\u5206\u7c7b\u4f3c\u7136\u5efa\u6a21\u4e13\u5bb6\u5bf9\u8fb9\u5b58\u5728\u548c\u65b9\u5411\u7684\u566a\u58f0\u5224\u65ad\uff0c\u4f7f\u7528\u7c92\u5b50\u8fd1\u4f3c\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad\uff0c\u57fa\u4e8e\u671f\u671b\u4fe1\u606f\u589e\u76ca\u9009\u62e9\u67e5\u8be2", "result": "\u5728\u5408\u6210\u56fe\u3001\u86cb\u767d\u8d28\u4fe1\u53f7\u6570\u636e\u548c\u4eba\u7c7b\u57fa\u56e0\u6270\u52a8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u6709\u9650\u67e5\u8be2\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u540e\u9a8c\u6536\u655b\u548c\u66f4\u597d\u7684\u6709\u5411\u6548\u5e94\u6062\u590d", "conclusion": "\u56e0\u679c\u504f\u597d\u83b7\u53d6\u6846\u67b6\u6709\u6548\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u56e0\u679c\u53d1\u73b0\u6548\u7387\uff0c\u7279\u522b\u9002\u7528\u4e8e\u67e5\u8be2\u9884\u7b97\u6709\u9650\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f"}}
{"id": "2602.01485", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01485", "abs": "https://arxiv.org/abs/2602.01485", "authors": ["Muheng Li", "Jian Qian", "Wenlong Mou"], "title": "Predicting and improving test-time scaling laws via reward tail-guided search", "comment": "33 pages, 5 figures", "summary": "Test-time scaling has emerged as a critical avenue for enhancing the reasoning capabilities of Large Language Models (LLMs). Though the straight-forward ''best-of-$N$'' (BoN) strategy has already demonstrated significant improvements in performance, it lacks principled guidance on the choice of $N$, budget allocation, and multi-stage decision-making, thereby leaving substantial room for optimization. While many works have explored such optimization, rigorous theoretical guarantees remain limited. In this work, we propose new methodologies to predict and improve scaling properties via tail-guided search. By estimating the tail distribution of rewards, our method predicts the scaling law of LLMs without the need for exhaustive evaluations. Leveraging this prediction tool, we introduce Scaling-Law Guided (SLG) Search, a new test-time algorithm that dynamically allocates compute to identify and exploit intermediate states with the highest predicted potential. We theoretically prove that SLG achieves vanishing regret compared to perfect-information oracles, and achieves expected rewards that would otherwise require a polynomially larger compute budget required when using BoN. Empirically, we validate our framework across different LLMs and reward models, confirming that tail-guided allocation consistently achieves higher reward yields than Best-of-$N$ under identical compute budgets. Our code is available at https://github.com/PotatoJnny/Scaling-Law-Guided-search.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5c3e\u90e8\u5206\u5e03\u9884\u6d4b\u7684\u7f29\u653e\u5b9a\u5f8b\u5f15\u5bfc\u641c\u7d22\u65b9\u6cd5\uff0c\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u4f18\u5316LLM\u63a8\u7406\u80fd\u529b\uff0c\u76f8\u6bd4\u4f20\u7edfBest-of-N\u7b56\u7565\u83b7\u5f97\u66f4\u9ad8\u5956\u52b1\u6536\u76ca\u3002", "motivation": "\u73b0\u6709Best-of-N\u7b56\u7565\u7f3a\u4e4f\u5bf9N\u503c\u9009\u62e9\u3001\u9884\u7b97\u5206\u914d\u548c\u591a\u9636\u6bb5\u51b3\u7b56\u7684\u539f\u5219\u6027\u6307\u5bfc\uff0c\u5b58\u5728\u4f18\u5316\u7a7a\u95f4\uff0c\u4e14\u76f8\u5173\u4f18\u5316\u65b9\u6cd5\u7f3a\u4e4f\u4e25\u683c\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u901a\u8fc7\u4f30\u8ba1\u5956\u52b1\u7684\u5c3e\u90e8\u5206\u5e03\u9884\u6d4bLLM\u7f29\u653e\u5b9a\u5f8b\uff0c\u65e0\u9700\u7a77\u4e3e\u8bc4\u4f30\uff1b\u57fa\u4e8e\u6b64\u63d0\u51fa\u7f29\u653e\u5b9a\u5f8b\u5f15\u5bfc\u641c\u7d22\u7b97\u6cd5\uff0c\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u8bc6\u522b\u548c\u5229\u7528\u5177\u6709\u6700\u9ad8\u9884\u6d4b\u6f5c\u529b\u7684\u4e2d\u95f4\u72b6\u6001\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660eSLG\u76f8\u6bd4\u5b8c\u7f8e\u4fe1\u606f\u9884\u8a00\u673a\u5b9e\u73b0\u53ef\u5ffd\u7565\u7684\u9057\u61be\uff0c\u8fbe\u5230\u76f8\u540c\u9884\u671f\u5956\u52b1\u6240\u9700\u8ba1\u7b97\u9884\u7b97\u6bd4Best-of-N\u591a\u9879\u5f0f\u7ea7\u51cf\u5c11\uff1b\u5b9e\u8bc1\u9a8c\u8bc1\u5728\u4e0d\u540cLLM\u548c\u5956\u52b1\u6a21\u578b\u4e0a\u5747\u4f18\u4e8eBest-of-N\u3002", "conclusion": "\u5c3e\u90e8\u5f15\u5bfc\u5206\u914d\u65b9\u6cd5\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u6bd4Best-of-N\u83b7\u5f97\u66f4\u9ad8\u5956\u52b1\u6536\u76ca\uff0c\u4e3aLLM\u6d4b\u8bd5\u65f6\u7f29\u653e\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u7684\u4f18\u5316\u6846\u67b6\u3002"}}
{"id": "2602.01486", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01486", "abs": "https://arxiv.org/abs/2602.01486", "authors": ["Xuesong Wang", "Michael Groom", "Rafael Oliveira", "He Zhao", "Terence O'Kane", "Edwin V. Bonilla"], "title": "Multi-Scale Wavelet Transformers for Operator Learning of Dynamical Systems", "comment": null, "summary": "Recent years have seen a surge in data-driven surrogates for dynamical systems that can be orders of magnitude faster than numerical solvers. However, many machine learning-based models such as neural operators exhibit spectral bias, attenuating high-frequency components that often encode small-scale structure. This limitation is particularly damaging in applications such as weather forecasting, where misrepresented high frequencies can induce long-horizon instability. To address this issue, we propose multi-scale wavelet transformers (MSWTs), which learn system dynamics in a tokenized wavelet domain. The wavelet transform explicitly separates low- and high-frequency content across scales. MSWTs leverage a wavelet-preserving downsampling scheme that retains high-frequency features and employ wavelet-based attention to capture dependencies across scales and frequency bands. Experiments on chaotic dynamical systems show substantial error reductions and improved long horizon spectral fidelity. On the ERA5 climate reanalysis, MSWTs further reduce climatological bias, demonstrating their effectiveness in a real-world forecasting setting.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5c3a\u5ea6\u5c0f\u6ce2\u53d8\u6362\u5668(MSWT)\uff0c\u901a\u8fc7\u5728\u4ee4\u724c\u5316\u5c0f\u6ce2\u57df\u5b66\u4e60\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u89e3\u51b3\u795e\u7ecf\u7b97\u5b50\u7b49\u6a21\u578b\u4e2d\u7684\u9891\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u548c\u9891\u8c31\u4fdd\u771f\u5ea6\u3002", "motivation": "\u8bb8\u591a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u4ee3\u7406\u6a21\u578b\uff08\u5982\u795e\u7ecf\u7b97\u5b50\uff09\u5b58\u5728\u9891\u8c31\u504f\u5dee\uff0c\u4f1a\u8870\u51cf\u9ad8\u9891\u6210\u5206\uff0c\u800c\u8fd9\u4e9b\u9ad8\u9891\u6210\u5206\u901a\u5e38\u7f16\u7801\u5c0f\u5c3a\u5ea6\u7ed3\u6784\u3002\u5728\u5929\u6c14\u9884\u62a5\u7b49\u5e94\u7528\u4e2d\uff0c\u9ad8\u9891\u6210\u5206\u7684\u8bef\u8868\u793a\u4f1a\u5bfc\u81f4\u957f\u671f\u9884\u6d4b\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u591a\u5c3a\u5ea6\u5c0f\u6ce2\u53d8\u6362\u5668(MSWT)\uff1a1) \u5728\u4ee4\u724c\u5316\u5c0f\u6ce2\u57df\u5b66\u4e60\u7cfb\u7edf\u52a8\u529b\u5b66\uff1b2) \u5c0f\u6ce2\u53d8\u6362\u660e\u786e\u5206\u79bb\u4e0d\u540c\u5c3a\u5ea6\u7684\u4f4e\u9891\u548c\u9ad8\u9891\u5185\u5bb9\uff1b3) \u91c7\u7528\u4fdd\u7559\u5c0f\u6ce2\u7279\u5f81\u7684\u964d\u91c7\u6837\u65b9\u6848\u4fdd\u6301\u9ad8\u9891\u7279\u5f81\uff1b4) \u4f7f\u7528\u57fa\u4e8e\u5c0f\u6ce2\u7684\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u8de8\u5c3a\u5ea6\u548c\u9891\u5e26\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u6df7\u6c8c\u52a8\u529b\u5b66\u7cfb\u7edf\u5b9e\u9a8c\u4e2d\uff0cMSWT\u663e\u8457\u51cf\u5c11\u4e86\u8bef\u5dee\u5e76\u6539\u5584\u4e86\u957f\u671f\u9891\u8c31\u4fdd\u771f\u5ea6\u3002\u5728ERA5\u6c14\u5019\u518d\u5206\u6790\u6570\u636e\u4e0a\uff0c\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e86\u6c14\u5019\u5b66\u504f\u5dee\uff0c\u5c55\u793a\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u9884\u6d4b\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "MSWT\u901a\u8fc7\u5728\u5c0f\u6ce2\u57df\u4e2d\u5b66\u4e60\u52a8\u529b\u5b66\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9891\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u9891\u7279\u5f81\u7684\u540c\u65f6\u6539\u5584\u4e86\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\uff0c\u5728\u590d\u6742\u52a8\u529b\u5b66\u7cfb\u7edf\u548c\u771f\u5b9e\u6c14\u5019\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.01493", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01493", "abs": "https://arxiv.org/abs/2602.01493", "authors": ["Zhuoyuan Wang", "Hanjiang Hu", "Xiyu Deng", "Saviz Mowlavi", "Yorie Nakahira"], "title": "OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference", "comment": null, "summary": "Solving diverse partial differential equations (PDEs) is fundamental in science and engineering. Large language models (LLMs) have demonstrated strong capabilities in code generation, symbolic reasoning, and tool use, but reliably solving PDEs across heterogeneous settings remains challenging. Prior work on LLM-based code generation and transformer-based foundation models for PDE learning has shown promising advances. However, a persistent trade-off between execution success rate and numerical accuracy arises, particularly when generalization to unseen parameters and boundary conditions is required. In this work, we propose OpInf-LLM, an LLM parametric PDE solving framework based on operator inference. The proposed framework leverages a small amount of solution data to enable accurate prediction of diverse PDE instances, including unseen parameters and configurations, and provides seamless integration with LLMs for natural language specification of PDE solving tasks. Its low computational demands and unified tool interface further enable a high execution success rate across heterogeneous settings. By combining operator inference with LLM capabilities, OpInf-LLM opens new possibilities for generalizable reduced-order modeling in LLM-based PDE solving.", "AI": {"tldr": "OpInf-LLM\uff1a\u57fa\u4e8e\u7b97\u5b50\u63a8\u7406\u7684LLM\u53c2\u6570\u5316PDE\u6c42\u89e3\u6846\u67b6\uff0c\u5229\u7528\u5c11\u91cf\u89e3\u6570\u636e\u51c6\u786e\u9884\u6d4b\u591a\u79cdPDE\u5b9e\u4f8b\uff0c\u5305\u62ec\u672a\u89c1\u53c2\u6570\u548c\u914d\u7f6e", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u548c\u7b26\u53f7\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u6c42\u89e3\u5f02\u6784\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\uff0c\u6267\u884c\u6210\u529f\u7387\u4e0e\u6570\u503c\u7cbe\u5ea6\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u7279\u522b\u662f\u5728\u6cdb\u5316\u5230\u672a\u89c1\u53c2\u6570\u548c\u8fb9\u754c\u6761\u4ef6\u65f6\u5b58\u5728\u6311\u6218", "method": "\u63d0\u51faOpInf-LLM\u6846\u67b6\uff0c\u7ed3\u5408\u7b97\u5b50\u63a8\u7406\u4e0eLLM\u80fd\u529b\uff0c\u5229\u7528\u5c11\u91cf\u89e3\u6570\u636e\u8fdb\u884c\u53c2\u6570\u5316PDE\u6c42\u89e3\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u5de5\u5177\u63a5\u53e3\u548c\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u89c4\u8303", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5305\u62ec\u672a\u89c1\u53c2\u6570\u548c\u914d\u7f6e\u5728\u5185\u7684\u591a\u79cdPDE\u5b9e\u4f8b\uff0c\u8ba1\u7b97\u9700\u6c42\u4f4e\uff0c\u5728\u5f02\u6784\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u9ad8\u6267\u884c\u6210\u529f\u7387", "conclusion": "OpInf-LLM\u901a\u8fc7\u7ed3\u5408\u7b97\u5b50\u63a8\u7406\u4e0eLLM\u80fd\u529b\uff0c\u4e3a\u57fa\u4e8eLLM\u7684PDE\u6c42\u89e3\u4e2d\u7684\u53ef\u6cdb\u5316\u964d\u9636\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027"}}
{"id": "2602.01505", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01505", "abs": "https://arxiv.org/abs/2602.01505", "authors": ["Navdeep Kumar", "Tehila Dahan", "Lior Cohen", "Ananyabrata Barua", "Giorgia Ramponi", "Kfir Yehuda Levy", "Shie Mannor"], "title": "Optimal Sample Complexity for Single Time-Scale Actor-Critic with Momentum", "comment": null, "summary": "We establish an optimal sample complexity of $O(\u03b5^{-2})$ for obtaining an $\u03b5$-optimal global policy using a single-timescale actor-critic (AC) algorithm in infinite-horizon discounted Markov decision processes (MDPs) with finite state-action spaces, improving upon the prior state of the art of $O(\u03b5^{-3})$. Our approach applies STORM (STOchastic Recursive Momentum) to reduce variance in the critic updates. However, because samples are drawn from a nonstationary occupancy measure induced by the evolving policy, variance reduction via STORM alone is insufficient. To address this challenge, we maintain a buffer of small fraction of recent samples and uniformly sample from it for each critic update. Importantly, these mechanisms are compatible with existing deep learning architectures and require only minor modifications, without compromising practical applicability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5355\u65f6\u95f4\u5c3a\u5ea6\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff0c\u5728\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u4e2d\u5b9e\u73b0O(\u03b5\u207b\u00b2)\u7684\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\uff0c\u76f8\u6bd4\u4e4b\u524dO(\u03b5\u207b\u00b3)\u6709\u663e\u8457\u6539\u8fdb", "motivation": "\u73b0\u6709\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\u5728\u65e0\u9650\u65f6\u57df\u6298\u6263\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u6837\u672c\u590d\u6742\u5ea6\u4e3aO(\u03b5\u207b\u00b3)\uff0c\u5b58\u5728\u6539\u8fdb\u7a7a\u95f4\u3002\u9700\u8981\u89e3\u51b3\u975e\u5e73\u7a33\u91c7\u6837\u5206\u5e03\u5e26\u6765\u7684\u65b9\u5dee\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u7684\u517c\u5bb9\u6027", "method": "\u7ed3\u5408STORM\u65b9\u5dee\u51cf\u5c11\u6280\u672f\u548c\u7f13\u51b2\u533a\u673a\u5236\uff1a1) \u4f7f\u7528STORM\u51cf\u5c11\u8bc4\u8bba\u5bb6\u66f4\u65b0\u7684\u65b9\u5dee\uff1b2) \u7ef4\u62a4\u6700\u8fd1\u6837\u672c\u7684\u5c0f\u7f13\u51b2\u533a\uff0c\u4ece\u4e2d\u5747\u5300\u91c7\u6837\u7528\u4e8e\u8bc4\u8bba\u5bb6\u66f4\u65b0\uff1b3) \u91c7\u7528\u5355\u65f6\u95f4\u5c3a\u5ea6\u67b6\u6784", "result": "\u5b9e\u73b0\u4e86O(\u03b5\u207b\u00b2)\u7684\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709O(\u03b5\u207b\u00b3)\u7ed3\u679c\u3002\u8be5\u65b9\u6cd5\u4e0e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u517c\u5bb9\uff0c\u4ec5\u9700\u5fae\u5c0f\u4fee\u6539\uff0c\u4e0d\u635f\u5bb3\u5b9e\u9645\u5e94\u7528\u6027", "conclusion": "\u901a\u8fc7\u7ed3\u5408STORM\u65b9\u5dee\u51cf\u5c11\u548c\u7f13\u51b2\u533a\u91c7\u6837\u673a\u5236\uff0c\u6210\u529f\u8bbe\u8ba1\u51fa\u5177\u6709\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\u7684\u5355\u65f6\u95f4\u5c3a\u5ea6\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6837\u672c\u6548\u7387\u63d0\u4f9b\u4e86\u91cd\u8981\u6539\u8fdb"}}
{"id": "2602.01510", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.01510", "abs": "https://arxiv.org/abs/2602.01510", "authors": ["Hengzhe Zhang", "Qi Chen", "Bing Xue", "Wolfgang Banzhaf", "Mengjie Zhang"], "title": "Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization", "comment": null, "summary": "Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u7f16\u7a0b\u7684\u7279\u5f81\u6784\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u7ecf\u9a8c\u98ce\u9669\u548cvicinal Jensen gap\u6765\u63a7\u5236\u8fc7\u62df\u5408\uff0c\u5e76\u5f15\u5165\u566a\u58f0\u4f30\u8ba1\u548c\u6d41\u5f62\u5165\u4fb5\u68c0\u6d4b\u673a\u5236\uff0c\u572858\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u9057\u4f20\u7f16\u7a0b\u7279\u5f81\u6784\u5efa\u867d\u7136\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u8fc7\u62df\u5408\u95ee\u9898\u9650\u5236\u4e86\u5176\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002\u9700\u8981\u6539\u8fdb\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u548c\u6570\u636e\u589e\u5f3a\u53ef\u80fd\u4ea7\u751f\u4e0d\u73b0\u5b9e\u6837\u672c\u7684\u60c5\u51b5\u4e0b\u3002", "method": "1. \u8bc1\u660evicinal risk\u53ef\u901a\u8fc7\u7ecf\u9a8c\u98ce\u9669\u52a0\u6b63\u5219\u5316\u9879\uff08\u6709\u9650\u5dee\u5206\u6216vicinal Jensen gap\uff09\u6765\u754c\u5b9a\uff1b2. \u63d0\u51fa\u8fdb\u5316\u7279\u5f81\u6784\u5efa\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u7ecf\u9a8c\u98ce\u9669\u548cvicinal Jensen gap\uff1b3. \u5f00\u53d1\u566a\u58f0\u4f30\u8ba1\u7b56\u7565\u52a8\u6001\u8c03\u6574\u6b63\u5219\u5316\u5f3a\u5ea6\uff1b4. \u63d0\u51fa\u6d41\u5f62\u5165\u4fb5\u68c0\u6d4b\u673a\u5236\u9632\u6b62\u6570\u636e\u589e\u5f3a\u4ea7\u751f\u4e0d\u73b0\u5b9e\u6837\u672c\u3002", "result": "\u572858\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJensen gap\u6700\u5c0f\u5316\u6bd4\u5176\u4ed6\u590d\u6742\u5ea6\u5ea6\u91cf\u66f4\u6709\u6548\u3002\u4e0e15\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u6bd4\u8f83\u663e\u793a\uff0c\u91c7\u7528\u6240\u63d0\u8fc7\u62df\u5408\u63a7\u5236\u7b56\u7565\u7684\u9057\u4f20\u7f16\u7a0b\u83b7\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u63d0\u51fa\u7684\u57fa\u4e8evicinal Jensen gap\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u80fd\u6709\u6548\u63a7\u5236\u9057\u4f20\u7f16\u7a0b\u7279\u5f81\u6784\u5efa\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.01516", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01516", "abs": "https://arxiv.org/abs/2602.01516", "authors": ["Enzo Nicolas Spotorno", "Matheus Wagner", "Antonio Augusto Medeiros Frohlich"], "title": "White-Box Neural Ensemble for Vehicular Plasticity: Quantifying the Efficiency Cost of Symbolic Auditability in Adaptive NMPC", "comment": "5 pages, 1 table, 1 figure, submitted to IEEE VTC 2026 Recent Results Track", "summary": "We present a white-box adaptive NMPC architecture that resolves vehicular plasticity (adaptation to varying operating regimes without retraining) by arbitrating among frozen, regime-specific neural specialists using a Modular Sovereignty paradigm. The ensemble dynamics are maintained as a fully traversable symbolic graph in CasADi, enabling maximal runtime auditability. Synchronous simulation validates rapid adaptation (~7.3 ms) and near-ideal tracking fidelity under compound regime shifts (friction, mass, drag) where non-adaptive baselines fail. Empirical benchmarking quantifies the transparency cost: symbolic graph maintenance increases solver latency by 72-102X versus compiled parametric physics models, establishing the efficiency price of strict white-box implementation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u767d\u76d2\u81ea\u9002\u5e94NMPC\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u4e3b\u6743\u8303\u5f0f\u4ef2\u88c1\u591a\u4e2a\u51bb\u7ed3\u7684\u3001\u7279\u5b9a\u5de5\u51b5\u7684\u795e\u7ecf\u7f51\u7edc\u4e13\u5bb6\uff0c\u89e3\u51b3\u8f66\u8f86\u53ef\u5851\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u5de5\u51b5", "motivation": "\u89e3\u51b3\u8f66\u8f86\u63a7\u5236\u7cfb\u7edf\u5728\u4e0d\u540c\u5de5\u51b5\uff08\u6469\u64e6\u3001\u8d28\u91cf\u3001\u963b\u529b\u7b49\uff09\u4e0b\u7684\u9002\u5e94\u6027\u95ee\u9898\uff0c\u4f20\u7edf\u975e\u81ea\u9002\u5e94\u57fa\u51c6\u65b9\u6cd5\u5728\u590d\u5408\u5de5\u51b5\u53d8\u5316\u4e0b\u4f1a\u5931\u6548\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5feb\u901f\u9002\u5e94\u53c8\u4fdd\u6301\u767d\u76d2\u53ef\u5ba1\u8ba1\u6027\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u91c7\u7528\u6a21\u5757\u5316\u4e3b\u6743\u8303\u5f0f\uff0c\u4ef2\u88c1\u591a\u4e2a\u51bb\u7ed3\u7684\u3001\u7279\u5b9a\u5de5\u51b5\u7684\u795e\u7ecf\u7f51\u7edc\u4e13\u5bb6\uff1b\u5c06\u96c6\u6210\u52a8\u529b\u5b66\u7ef4\u62a4\u4e3aCasADi\u4e2d\u5b8c\u5168\u53ef\u904d\u5386\u7684\u7b26\u53f7\u56fe\uff0c\u5b9e\u73b0\u6700\u5927\u8fd0\u884c\u65f6\u53ef\u5ba1\u8ba1\u6027\uff1b\u901a\u8fc7\u540c\u6b65\u4eff\u771f\u9a8c\u8bc1\u65b9\u6cd5", "result": "\u9a8c\u8bc1\u4e86\u5feb\u901f\u9002\u5e94\u80fd\u529b\uff08\u7ea67.3\u6beb\u79d2\uff09\uff0c\u5728\u590d\u5408\u5de5\u51b5\u53d8\u5316\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u7684\u8ddf\u8e2a\u7cbe\u5ea6\uff1b\u91cf\u5316\u4e86\u900f\u660e\u5ea6\u6210\u672c\uff1a\u7b26\u53f7\u56fe\u7ef4\u62a4\u4f7f\u6c42\u89e3\u5668\u5ef6\u8fdf\u589e\u52a072-102\u500d\uff0c\u5efa\u7acb\u4e86\u4e25\u683c\u767d\u76d2\u5b9e\u73b0\u7684\u6548\u7387\u4ee3\u4ef7", "conclusion": "\u63d0\u51fa\u7684\u767d\u76d2\u81ea\u9002\u5e94NMPC\u67b6\u6784\u6210\u529f\u89e3\u51b3\u4e86\u8f66\u8f86\u53ef\u5851\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5b8c\u5168\u53ef\u5ba1\u8ba1\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5feb\u901f\u5de5\u51b5\u9002\u5e94\uff0c\u4f46\u9700\u8981\u6743\u8861\u900f\u660e\u5ea6\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u5e73\u8861"}}
{"id": "2602.01519", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01519", "abs": "https://arxiv.org/abs/2602.01519", "authors": ["Shiju Zhao", "Junhao Hu", "Jiaqi Zheng", "Guihai Chen"], "title": "You Need an Encoder for Native Position-Independent Caching", "comment": "12 pages, 10 figures. Welcome back, Encoder", "summary": "The Key-Value (KV) cache of Large Language Models (LLMs) is prefix-based, making it highly inefficient for processing contexts retrieved in arbitrary order. Position-Independent Caching (PIC) has been proposed to enable KV reuse without positional constraints; however, existing approaches often incur substantial accuracy degradation, limiting their practical adoption. To address this issue, we propose native PIC by reintroducing the encoder to prevalent decoder-only LLMs and explicitly training it to support PIC. We further develop COMB, a PIC-aware caching system that integrates seamlessly with existing inference frameworks. Experimental results show that COMB reduces Time-to-First-Token (TTFT) by 51-94% and increases throughput by 3$\\times$ with comparable accuracy. Furthermore, the quality improvement when using DeepSeek-V2-Lite-Chat demonstrates the applicability of COMB to other types of decoder-only LLMs. Our code is available at https://github.com/shijuzhao/Comb.", "AI": {"tldr": "\u63d0\u51fa\u539f\u751f\u4f4d\u7f6e\u65e0\u5173\u7f13\u5b58(PIC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u4ec5\u89e3\u7801\u5668LLM\u91cd\u65b0\u5f15\u5165\u7f16\u7801\u5668\u5e76\u663e\u5f0f\u8bad\u7ec3\u6765\u652f\u6301PIC\uff0c\u5f00\u53d1COMB\u7f13\u5b58\u7cfb\u7edf\uff0c\u663e\u8457\u964d\u4f4e\u9996token\u5ef6\u8fdf\u5e76\u63d0\u5347\u541e\u5410\u91cf", "motivation": "\u73b0\u6709LLM\u7684KV\u7f13\u5b58\u57fa\u4e8e\u524d\u7f00\uff0c\u5bf9\u4efb\u610f\u987a\u5e8f\u68c0\u7d22\u7684\u4e0a\u4e0b\u6587\u5904\u7406\u6548\u7387\u4f4e\u4e0b\u3002\u73b0\u6709PIC\u65b9\u6cd5\u901a\u5e38\u5bfc\u81f4\u663e\u8457\u7cbe\u5ea6\u4e0b\u964d\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528", "method": "\u63d0\u51fa\u539f\u751fPIC\u65b9\u6cd5\uff1a\u4e3a\u6d41\u884c\u7684\u4ec5\u89e3\u7801\u5668LLM\u91cd\u65b0\u5f15\u5165\u7f16\u7801\u5668\u5e76\u663e\u5f0f\u8bad\u7ec3\u4ee5\u652f\u6301PIC\uff1b\u5f00\u53d1COMB\u7f13\u5b58\u7cfb\u7edf\uff0c\u4e0e\u73b0\u6709\u63a8\u7406\u6846\u67b6\u65e0\u7f1d\u96c6\u6210", "result": "COMB\u5c06\u9996token\u65f6\u95f4(TTFT)\u964d\u4f4e51-94%\uff0c\u541e\u5410\u91cf\u63d0\u53473\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u8f83\u7684\u7cbe\u5ea6\uff1b\u5728DeepSeek-V2-Lite-Chat\u4e0a\u7684\u8d28\u91cf\u6539\u8fdb\u8bc1\u660e\u4e86COMB\u5bf9\u5176\u4ed6\u4ec5\u89e3\u7801\u5668LLM\u7684\u9002\u7528\u6027", "conclusion": "\u539f\u751fPIC\u65b9\u6cd5\u901a\u8fc7\u91cd\u65b0\u5f15\u5165\u7f16\u7801\u5668\u5e76\u663e\u5f0f\u8bad\u7ec3\u6709\u6548\u89e3\u51b3\u4e86PIC\u7684\u7cbe\u5ea6\u95ee\u9898\uff0cCOMB\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u6548\u7387"}}
{"id": "2602.01522", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01522", "abs": "https://arxiv.org/abs/2602.01522", "authors": ["Haoran Zhao", "Soyeon Caren Han", "Eduard Hovy"], "title": "When Is Rank-1 Enough? Geometry-Guided Initialization for Parameter-Efficient Fine-Tuning", "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) is a standard way to adapt multimodal large language models, yet extremely low-rank settings -- especially rank-1 LoRA -- are often unstable. We show that this instability is not solely due to limited capacity: in the rank-1 regime, optimization is highly sensitive to the update direction. Concretely, pretrained vision and text features form mismatched anisotropic regions, yielding a dominant \"gap\" direction that acts like a translation component and disproportionately steers early gradients under rank-1 constraints. Analyzing pretrained representations, we identify a modality-gap axis that dominates early gradient flow, while a random rank-1 initialization is unlikely to align with it, leading to weak gradients and training collapse. We propose Gap-Init, a geometry-aware initialization that aligns the rank-1 LoRA direction with an estimated modality-gap vector from a small calibration set, while keeping the initial LoRA update zero. Across multiple vision-language tasks and backbones, Gap-Init consistently stabilizes rank-1 training and can match or outperform strong rank-8 baselines. Our results suggest that at the extreme low-rank limit, initial alignment can matter as much as rank itself.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faGap-Init\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06rank-1 LoRA\u65b9\u5411\u4e0e\u6a21\u6001\u95f4\u9699\u5411\u91cf\u5bf9\u9f50\uff0c\u89e3\u51b3\u4e86\u6781\u4f4e\u79e9PEFT\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u662f\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u4f46\u5728\u6781\u4f4e\u79e9\u8bbe\u7f6e\uff08\u7279\u522b\u662frank-1 LoRA\uff09\u4e0b\u5e38\u5e38\u4e0d\u7a33\u5b9a\u3002\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u4e0d\u7a33\u5b9a\u6027\u4e0d\u4ec5\u6e90\u4e8e\u5bb9\u91cf\u9650\u5236\uff0c\u66f4\u4e0e\u4f18\u5316\u65b9\u5411\u654f\u611f\u6027\u6709\u5173\uff1a\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u548c\u6587\u672c\u7279\u5f81\u5f62\u6210\u4e0d\u5339\u914d\u7684\u5404\u5411\u5f02\u6027\u533a\u57df\uff0c\u4ea7\u751f\u4e3b\u5bfc\u7684\"\u95f4\u9699\"\u65b9\u5411\uff0c\u5728rank-1\u7ea6\u675f\u4e0b\u4f1a\u4e0d\u6210\u6bd4\u4f8b\u5730\u5f15\u5bfc\u65e9\u671f\u68af\u5ea6\u3002", "method": "\u63d0\u51faGap-Init\u65b9\u6cd5\uff1a1\uff09\u5206\u6790\u9884\u8bad\u7ec3\u8868\u793a\uff0c\u8bc6\u522b\u4e3b\u5bfc\u65e9\u671f\u68af\u5ea6\u6d41\u7684\u6a21\u6001\u95f4\u9699\u8f74\uff1b2\uff09\u4f7f\u7528\u5c0f\u578b\u6821\u51c6\u96c6\u4f30\u8ba1\u6a21\u6001\u95f4\u9699\u5411\u91cf\uff1b3\uff09\u5c06rank-1 LoRA\u65b9\u5411\u4e0e\u8be5\u6a21\u6001\u95f4\u9699\u5411\u91cf\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u6301\u521d\u59cbLoRA\u66f4\u65b0\u4e3a\u96f6\u3002\u8fd9\u79cd\u51e0\u4f55\u611f\u77e5\u521d\u59cb\u5316\u786e\u4fdd\u4f18\u5316\u65b9\u5411\u4e0e\u7279\u5f81\u7a7a\u95f4\u7684\u5173\u952e\u51e0\u4f55\u7ed3\u6784\u4e00\u81f4\u3002", "result": "\u5728\u591a\u4e2a\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u548c\u9aa8\u5e72\u7f51\u7edc\u4e0a\uff0cGap-Init\u80fd\u591f\u7a33\u5b9arank-1\u8bad\u7ec3\uff0c\u6027\u80fd\u5339\u914d\u751a\u81f3\u8d85\u8fc7\u5f3a\u5927\u7684rank-8\u57fa\u7ebf\u3002\u5b9e\u9a8c\u8868\u660e\u5728\u6781\u7aef\u4f4e\u79e9\u9650\u5236\u4e0b\uff0c\u521d\u59cb\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u53ef\u80fd\u4e0e\u79e9\u672c\u8eab\u76f8\u5f53\u3002", "conclusion": "\u6781\u4f4e\u79e9PEFT\u8bad\u7ec3\u7684\u4e0d\u7a33\u5b9a\u6027\u4e3b\u8981\u6e90\u4e8e\u4f18\u5316\u65b9\u5411\u654f\u611f\u6027\u800c\u975e\u5bb9\u91cf\u9650\u5236\u3002\u901a\u8fc7\u51e0\u4f55\u611f\u77e5\u521d\u59cb\u5316\u5c06LoRA\u65b9\u5411\u4e0e\u6a21\u6001\u95f4\u9699\u5411\u91cf\u5bf9\u9f50\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u5728\u6781\u7aef\u4f4e\u79e9\u9650\u5236\u4e0b\uff0c\u521d\u59cb\u5bf9\u9f50\u7b56\u7565\u4e0e\u589e\u52a0\u79e9\u5177\u6709\u540c\u7b49\u91cd\u8981\u6027\u3002"}}
{"id": "2602.01523", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01523", "abs": "https://arxiv.org/abs/2602.01523", "authors": ["Akifumi Wachi", "Hirota Kinoshita", "Shokichi Takakura", "Rei Higuchi", "Taiji Suzuki"], "title": "A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning", "comment": "28 pages", "summary": "Reinforcement learning (RL) is a dominant paradigm for improving the reasoning abilities of large language models, yet its effectiveness varies across tasks and compute budgets. We propose a \\emph{relative-budget} theory explaining this variation through a single quantity called relative budget $\u03be:= H/\\mathbb{E}[T]$, where $H$ is the generation horizon (token budget) and $T$ denotes the number of tokens until the first correct solution under a base policy. We show that $\u03be$ determines sample efficiency by controlling reward variance and the likelihood of informative trajectories. Our analysis reveals three regimes: in the \\emph{deficient} regime ($\u03be\\to 0$), informative trajectories are rare and the sample complexity explodes; in the \\emph{balanced} regime ($\u03be=\u0398(1)$), informative trajectories occur with non-negligible probability and RL is maximally sample-efficient; and in the \\emph{ample} regime ($\u03be\\to \\infty$), learning remains stable but marginal gains per iteration diminish. We further provide finite-sample guarantees for online RL that characterize learning progress across these regimes. Specifically, in a case study under idealized distributional assumptions, we show that the relative budget grows linearly over iterations. Our empirical results confirm these predictions in realistic settings, identifying a budget $\u03be\\in [1.5, 2.0]$ that maximizes learning efficiency and coincides with peak reasoning performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u76f8\u5bf9\u9884\u7b97\u7406\u8bba\uff0c\u89e3\u91caRL\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u8ba1\u7b97\u9884\u7b97\u4e0b\u6548\u679c\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u901a\u8fc7\u76f8\u5bf9\u9884\u7b97\u03be=H/E[T]\u5212\u5206\u4e09\u4e2a\u5b66\u4e60\u9636\u6bb5\uff0c\u5e76\u7ed9\u51fa\u6709\u9650\u6837\u672c\u4fdd\u8bc1\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u6548\u679c\u4e0d\u4e00\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u8ba1\u7b97\u9884\u7b97\u4e0e\u5b66\u4e60\u6548\u7387\u5173\u7cfb\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u6765\u7406\u89e3RL\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u9884\u7b97\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u76f8\u5bf9\u9884\u7b97\u7406\u8bba\uff0c\u5b9a\u4e49\u76f8\u5bf9\u9884\u7b97\u03be=H/E[T]\uff0c\u5176\u4e2dH\u4e3a\u751f\u6210\u65f6\u57df\uff08token\u9884\u7b97\uff09\uff0cT\u4e3a\u57fa\u7840\u7b56\u7565\u4e0b\u9996\u6b21\u6b63\u786e\u89e3\u524d\u7684token\u6570\u3002\u7406\u8bba\u5206\u6790\u4e09\u4e2a\u5b66\u4e60\u9636\u6bb5\uff1a\u4e0d\u8db3\u3001\u5e73\u8861\u548c\u5145\u8db3\uff0c\u5e76\u7ed9\u51fa\u5728\u7ebfRL\u7684\u6709\u9650\u6837\u672c\u4fdd\u8bc1\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u03be\u51b3\u5b9a\u6837\u672c\u6548\u7387\uff0c\u63a7\u5236\u5956\u52b1\u65b9\u5dee\u548c\u4fe1\u606f\u8f68\u8ff9\u6982\u7387\u3002\u5b9e\u8bc1\u53d1\u73b0\u03be\u2208[1.5, 2.0]\u65f6\u5b66\u4e60\u6548\u7387\u6700\u9ad8\uff0c\u4e0e\u5cf0\u503c\u63a8\u7406\u6027\u80fd\u4e00\u81f4\u3002\u5728\u7406\u60f3\u5206\u5e03\u5047\u8bbe\u4e0b\uff0c\u76f8\u5bf9\u9884\u7b97\u968f\u8fed\u4ee3\u7ebf\u6027\u589e\u957f\u3002", "conclusion": "\u76f8\u5bf9\u9884\u7b97\u03be\u662f\u7406\u89e3RL\u5b66\u4e60\u6548\u7387\u7684\u5173\u952e\u5355\u4e00\u91cf\u5ea6\uff0c\u80fd\u591f\u89e3\u91ca\u4e0d\u540c\u4efb\u52a1\u548c\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4e3aRL\u5b9e\u8df5\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\uff0c\u5e2e\u52a9\u786e\u5b9a\u6700\u4f18\u8ba1\u7b97\u8d44\u6e90\u914d\u7f6e\u3002"}}
{"id": "2602.01526", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01526", "abs": "https://arxiv.org/abs/2602.01526", "authors": ["Jianqiao Zheng", "Hemanth Saratchandran", "Simon Lucey"], "title": "The Inlet Rank Collapse in Implicit Neural Representations: Diagnosis and Unified Remedy", "comment": null, "summary": "Implicit Neural Representations (INRs) have revolutionized continuous signal modeling, yet they struggle to recover fine-grained details within finite training budgets. While empirical techniques, such as positional encoding (PE), sinusoidal activations (SIREN), and batch normalization (BN), effectively mitigate this, their theoretical justifications are predominantly post hoc, focusing on the global NTK spectrum only after modifications are applied. In this work, we reverse this paradigm by introducing a structural diagnostic framework. By performing a layer-wise decomposition of the NTK, we mathematically identify the ``Inlet Rank Collapse'': a phenomenon where the low-dimensional input coordinates fail to span the high-dimensional embedding space, creating a fundamental rank deficiency at the first layer that acts as an expressive bottleneck for the entire network. This framework provides a unified perspective to re-interpret PE, SIREN, and BN as different forms of rank restoration. Guided by this diagnosis, we derive a Rank-Expanding Initialization, a minimalist remedy that ensures the representation rank scales with the layer width without architectural modifications or computational overhead. Our results demonstrate that this principled remedy enables standard MLPs to achieve high-fidelity reconstructions, proving that the key to empowering INRs lies in the structural optimization of the initial rank propagation to effectively populate the latent space.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u95f4NTK\u5206\u89e3\u8bc6\u522b\u4e86\"\u5165\u53e3\u79e9\u584c\u7f29\"\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u79e9\u6269\u5c55\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4f7f\u6807\u51c6MLP\u80fd\u591f\u5b9e\u73b0\u9ad8\u4fdd\u771f\u91cd\u5efa\u3002", "motivation": "\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u5728\u6709\u9650\u8bad\u7ec3\u9884\u7b97\u4e0b\u96be\u4ee5\u6062\u590d\u7ec6\u7c92\u5ea6\u7ec6\u8282\u3002\u867d\u7136\u7ecf\u9a8c\u6280\u672f\u5982\u4f4d\u7f6e\u7f16\u7801\u3001\u6b63\u5f26\u6fc0\u6d3b\u548c\u6279\u91cf\u5f52\u4e00\u5316\u80fd\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u5176\u7406\u8bba\u89e3\u91ca\u591a\u4e3a\u4e8b\u540e\u5206\u6790\uff0c\u4ec5\u5173\u6ce8\u4fee\u6539\u540e\u7684\u5168\u5c40NTK\u8c31\u3002\u9700\u8981\u4ece\u7ed3\u6784\u89d2\u5ea6\u7406\u89e3INRs\u7684\u8868\u8fbe\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u95f4\u795e\u7ecf\u6b63\u5207\u6838\uff08NTK\uff09\u5206\u89e3\uff0c\u6570\u5b66\u8bc6\u522b\"\u5165\u53e3\u79e9\u584c\u7f29\"\u73b0\u8c61\u3002\u57fa\u4e8e\u6b64\u8bca\u65ad\uff0c\u63a8\u5bfc\u51fa\u79e9\u6269\u5c55\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u786e\u4fdd\u8868\u793a\u79e9\u968f\u5c42\u5bbd\u6269\u5c55\uff0c\u65e0\u9700\u67b6\u6784\u4fee\u6539\u6216\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u79e9\u6269\u5c55\u521d\u59cb\u5316\u4f7f\u6807\u51c6MLP\u80fd\u591f\u5b9e\u73b0\u9ad8\u4fdd\u771f\u91cd\u5efa\uff0c\u8bc1\u660e\u8d4b\u80fdINRs\u7684\u5173\u952e\u5728\u4e8e\u521d\u59cb\u79e9\u4f20\u64ad\u7684\u7ed3\u6784\u4f18\u5316\uff0c\u4ee5\u6709\u6548\u586b\u5145\u6f5c\u5728\u7a7a\u95f4\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3INRs\u7684\u8868\u8fbe\u74f6\u9888\u63d0\u4f9b\u4e86\u7edf\u4e00\u89c6\u89d2\uff0c\u5c06\u73b0\u6709\u6280\u672f\u91cd\u65b0\u89e3\u91ca\u4e3a\u4e0d\u540c\u5f62\u5f0f\u7684\u79e9\u6062\u590d\u3002\u79e9\u6269\u5c55\u521d\u59cb\u5316\u4f5c\u4e3a\u6700\u5c0f\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u4f18\u5316\u521d\u59cb\u79e9\u4f20\u64ad\u5bf9\u63d0\u5347INRs\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.01553", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01553", "abs": "https://arxiv.org/abs/2602.01553", "authors": ["Quang Truong", "Yu Song", "Donald Loveland", "Mingxuan Ju", "Tong Zhao", "Neil Shah", "Jiliang Tang"], "title": "Plain Transformers are Surprisingly Powerful Link Predictors", "comment": null, "summary": "Link prediction is a core challenge in graph machine learning, demanding models that capture rich and complex topological dependencies. While Graph Neural Networks (GNNs) are the standard solution, state-of-the-art pipelines often rely on explicit structural heuristics or memory-intensive node embeddings -- approaches that struggle to generalize or scale to massive graphs. Emerging Graph Transformers (GTs) offer a potential alternative but often incur significant overhead due to complex structural encodings, hindering their applications to large-scale link prediction. We challenge these sophisticated paradigms with PENCIL, an encoder-only plain Transformer that replaces hand-crafted priors with attention over sampled local subgraphs, retaining the scalability and hardware efficiency of standard Transformers. Through experimental and theoretical analysis, we show that PENCIL extracts richer structural signals than GNNs, implicitly generalizing a broad class of heuristics and subgraph-based expressivity. Empirically, PENCIL outperforms heuristic-informed GNNs and is far more parameter-efficient than ID-embedding--based alternatives, while remaining competitive across diverse benchmarks -- even without node features. Our results challenge the prevailing reliance on complex engineering techniques, demonstrating that simple design choices are potentially sufficient to achieve the same capabilities.", "AI": {"tldr": "PENCIL\uff1a\u4e00\u79cd\u4ec5\u4f7f\u7528\u7f16\u7801\u5668\u7684\u6734\u7d20Transformer\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u91c7\u6837\u5b50\u56fe\u8fdb\u884c\u94fe\u63a5\u9884\u6d4b\uff0c\u65e0\u9700\u624b\u5de5\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u7684\u540c\u65f6\u8d85\u8d8a\u4e86\u542f\u53d1\u5f0fGNN\u548cID\u5d4c\u5165\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u56fe\u94fe\u63a5\u9884\u6d4b\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff1aGNN\u4f9d\u8d56\u663e\u5f0f\u7ed3\u6784\u542f\u53d1\u5f0f\u6216\u5185\u5b58\u5bc6\u96c6\u578b\u8282\u70b9\u5d4c\u5165\uff0c\u96be\u4ee5\u6cdb\u5316\u548c\u6269\u5c55\u5230\u5927\u89c4\u6a21\u56fe\uff1b\u56feTransformer\u5219\u56e0\u590d\u6742\u7ed3\u6784\u7f16\u7801\u5e26\u6765\u663e\u8457\u5f00\u9500\u3002\u9700\u8981\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u80fd\u6355\u83b7\u4e30\u5bcc\u62d3\u6251\u4f9d\u8d56\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faPENCIL\u6a21\u578b\uff0c\u91c7\u7528\u4ec5\u7f16\u7801\u5668\u7684\u6734\u7d20Transformer\u67b6\u6784\uff0c\u7528\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u91c7\u6837\u7684\u5c40\u90e8\u5b50\u56fe\uff0c\u66ff\u4ee3\u624b\u5de5\u8bbe\u8ba1\u7684\u5148\u9a8c\u77e5\u8bc6\u3002\u8be5\u65b9\u6cd5\u4fdd\u6301\u4e86\u6807\u51c6Transformer\u7684\u53ef\u6269\u5c55\u6027\u548c\u786c\u4ef6\u6548\u7387\uff0c\u80fd\u591f\u9690\u5f0f\u6cdb\u5316\u5e7f\u6cdb\u7684\u542f\u53d1\u5f0f\u548c\u57fa\u4e8e\u5b50\u56fe\u7684\u8868\u8fbe\u80fd\u529b\u3002", "result": "PENCIL\u5728\u5b9e\u9a8c\u4e2d\u8d85\u8d8a\u4e86\u542f\u53d1\u5f0fGNN\uff0c\u6bd4\u57fa\u4e8eID\u5d4c\u5165\u7684\u65b9\u6cd5\u53c2\u6570\u6548\u7387\u66f4\u9ad8\uff0c\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u8282\u70b9\u7279\u5f81\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8868\u73b0\u826f\u597d\u3002\u7406\u8bba\u5206\u6790\u8868\u660ePENCIL\u80fd\u63d0\u53d6\u6bd4GNN\u66f4\u4e30\u5bcc\u7684\u7ed3\u6784\u4fe1\u53f7\u3002", "conclusion": "\u7814\u7a76\u6311\u6218\u4e86\u5f53\u524d\u4f9d\u8d56\u590d\u6742\u5de5\u7a0b\u6280\u672f\u7684\u8303\u5f0f\uff0c\u8bc1\u660e\u7b80\u5355\u7684\u8bbe\u8ba1\u9009\u62e9\u53ef\u80fd\u8db3\u4ee5\u5b9e\u73b0\u76f8\u540c\u7684\u529f\u80fd\u3002PENCIL\u5c55\u793a\u4e86\u6734\u7d20Transformer\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01554", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01554", "abs": "https://arxiv.org/abs/2602.01554", "authors": ["Lv Tang", "Tianyi Zheng", "Bo Li", "Xingyu Li"], "title": "InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual Tokenization in Unified MLLMs", "comment": null, "summary": "Unified multimodal large language models (MLLMs) integrate image understanding and generation in a single framework, with the visual tokenizer acting as the sole interface that maps visual inputs into tokens for downstream tasks. However, existing shared-token designs are mostly architecture-driven and lack an explicit criterion for what information tokens should preserve to support both understanding and generation. Therefore, we introduce a capacity-constrained perspective, highlighting that in shared-token unified MLLMs the visual tokenizer behaves as a compute-bounded learner, so the token budget should prioritize reusable structure over hard-to-exploit high-entropy variations and redundancy. Motivated by this perspective, we propose InfoTok, an information-regularized visual tokenization mechanism grounded in the Information Bottleneck (IB) principle. InfoTok formulates tokenization as controlling information flow from images to shared tokens to multimodal outputs, yielding a principled trade-off between compression and task relevance via mutual-information regularization. We integrate InfoTok into three representative unified MLLMs without introducing any additional training data. Experiments show consistent improvements on both understanding and generation, supporting information-regularized tokenization as a principled foundation for learning a shared token space in unified MLLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faInfoTok\uff0c\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u7406\u7684\u4fe1\u606f\u6b63\u5219\u5316\u89c6\u89c9\u5206\u8bcd\u673a\u5236\uff0c\u7528\u4e8e\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u63a7\u5236\u4fe1\u606f\u6d41\u5b9e\u73b0\u538b\u7f29\u4e0e\u4efb\u52a1\u76f8\u5173\u6027\u7684\u5e73\u8861\uff0c\u5728\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5171\u4eab\u5206\u8bcd\u8bbe\u8ba1\u5927\u591a\u662f\u67b6\u6784\u9a71\u52a8\u7684\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u6807\u51c6\u6765\u786e\u5b9a\u5206\u8bcd\u5e94\u8be5\u4fdd\u7559\u54ea\u4e9b\u4fe1\u606f\u6765\u540c\u65f6\u652f\u6301\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u3002\u4f5c\u8005\u4ece\u5bb9\u91cf\u7ea6\u675f\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u8ba4\u4e3a\u89c6\u89c9\u5206\u8bcd\u5668\u5e94\u4f18\u5148\u4fdd\u7559\u53ef\u91cd\u7528\u7684\u7ed3\u6784\uff0c\u800c\u975e\u96be\u4ee5\u5229\u7528\u7684\u9ad8\u71b5\u53d8\u5316\u548c\u5197\u4f59\u4fe1\u606f\u3002", "method": "\u63d0\u51faInfoTok\uff0c\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u7406\u7684\u4fe1\u606f\u6b63\u5219\u5316\u89c6\u89c9\u5206\u8bcd\u673a\u5236\u3002\u8be5\u65b9\u6cd5\u5c06\u5206\u8bcd\u8fc7\u7a0b\u5f62\u5f0f\u5316\u4e3a\u63a7\u5236\u4ece\u56fe\u50cf\u5230\u5171\u4eab\u5206\u8bcd\u518d\u5230\u591a\u6a21\u6001\u8f93\u51fa\u7684\u4fe1\u606f\u6d41\uff0c\u901a\u8fc7\u4e92\u4fe1\u606f\u6b63\u5219\u5316\u5b9e\u73b0\u538b\u7f29\u4e0e\u4efb\u52a1\u76f8\u5173\u6027\u7684\u6743\u8861\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6570\u636e\uff0c\u53ef\u96c6\u6210\u5230\u73b0\u6709\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u96c6\u6210InfoTok\u540e\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u9a8c\u8bc1\u4e86\u4fe1\u606f\u6b63\u5219\u5316\u5206\u8bcd\u4f5c\u4e3a\u5b66\u4e60\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5171\u4eab\u5206\u8bcd\u7a7a\u95f4\u7684\u539f\u5219\u6027\u57fa\u7840\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4fe1\u606f\u6b63\u5219\u5316\u5206\u8bcd\u4e3a\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u5171\u4eab\u5206\u8bcd\u7a7a\u95f4\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002InfoTok\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u539f\u7406\u63a7\u5236\u4fe1\u606f\u6d41\uff0c\u5728\u538b\u7f29\u4e0e\u4efb\u52a1\u76f8\u5173\u6027\u4e4b\u95f4\u5b9e\u73b0\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2602.01558", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01558", "abs": "https://arxiv.org/abs/2602.01558", "authors": ["Yiming Ma", "Lixu Wang", "Lionel Z. Wang", "Hongkun Yang", "Haoming Sun", "Xin Xu", "Jiaqi Wu", "Bin Chen", "Wei Dong"], "title": "How Implicit Bias Accumulates and Propagates in LLM Long-term Memory", "comment": "Under review, and the first two authors contribute equally", "summary": "Long-term memory mechanisms enable Large Language Models (LLMs) to maintain continuity and personalization across extended interaction lifecycles, but they also introduce new and underexplored risks related to fairness. In this work, we study how implicit bias, defined as subtle statistical prejudice, accumulates and propagates within LLMs equipped with long-term memory. To support systematic analysis, we introduce the Decision-based Implicit Bias (DIB) Benchmark, a large-scale dataset comprising 3,776 decision-making scenarios across nine social domains, designed to quantify implicit bias in long-term decision processes. Using a realistic long-horizon simulation framework, we evaluate six state-of-the-art LLMs integrated with three representative memory architectures on DIB and demonstrate that LLMs' implicit bias does not remain static but intensifies over time and propagates across unrelated domains. We further analyze mitigation strategies and show that a static system-level prompting baseline provides limited and short-lived debiasing effects. To address this limitation, we propose Dynamic Memory Tagging (DMT), an agentic intervention that enforces fairness constraints at memory write time. Extensive experimental results show that DMT substantially reduces bias accumulation and effectively curtails cross-domain bias propagation.", "AI": {"tldr": "\u7814\u7a76LLMs\u957f\u671f\u8bb0\u5fc6\u673a\u5236\u4e2d\u7684\u9690\u6027\u504f\u89c1\u79ef\u7d2f\u4e0e\u4f20\u64ad\u95ee\u9898\uff0c\u63d0\u51fa\u52a8\u6001\u8bb0\u5fc6\u6807\u8bb0\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u504f\u89c1", "motivation": "LLMs\u7684\u957f\u671f\u8bb0\u5fc6\u673a\u5236\u867d\u7136\u80fd\u7ef4\u6301\u4ea4\u4e92\u8fde\u7eed\u6027\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u516c\u5e73\u6027\u98ce\u9669\uff0c\u7279\u522b\u662f\u9690\u6027\u504f\u89c1\u5728\u957f\u671f\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u79ef\u7d2f\u548c\u4f20\u64ad\u95ee\u9898\u5c1a\u672a\u5145\u5206\u7814\u7a76", "method": "1) \u521b\u5efaDIB\u57fa\u51c6\u6570\u636e\u96c6\uff083,776\u4e2a\u51b3\u7b56\u573a\u666f\uff0c9\u4e2a\u793e\u4f1a\u9886\u57df\uff09\uff1b2) \u4f7f\u7528\u957f\u671f\u6a21\u62df\u6846\u67b6\u8bc4\u4f306\u4e2aLLMs\u548c3\u79cd\u8bb0\u5fc6\u67b6\u6784\uff1b3) \u63d0\u51fa\u52a8\u6001\u8bb0\u5fc6\u6807\u8bb0(DMT)\u65b9\u6cd5\uff0c\u5728\u8bb0\u5fc6\u5199\u5165\u65f6\u5f3a\u5236\u6267\u884c\u516c\u5e73\u7ea6\u675f", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u7684\u9690\u6027\u504f\u89c1\u4f1a\u968f\u65f6\u95f4\u52a0\u5267\u5e76\u5728\u4e0d\u76f8\u5173\u9886\u57df\u95f4\u4f20\u64ad\uff1b\u9759\u6001\u7cfb\u7edf\u63d0\u793a\u53bb\u504f\u6548\u679c\u6709\u9650\u4e14\u77ed\u6682\uff1bDMT\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u504f\u89c1\u79ef\u7d2f\u5e76\u6709\u6548\u6291\u5236\u8de8\u9886\u57df\u504f\u89c1\u4f20\u64ad", "conclusion": "LLMs\u957f\u671f\u8bb0\u5fc6\u4e2d\u7684\u9690\u6027\u504f\u89c1\u662f\u52a8\u6001\u79ef\u7d2f\u548c\u4f20\u64ad\u7684\u7cfb\u7edf\u6027\u95ee\u9898\uff0c\u9700\u8981\u52a8\u6001\u5e72\u9884\u7b56\u7565\uff1bDMT\u65b9\u6cd5\u4e3a\u7f13\u89e3\u8bb0\u5fc6\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01564", "categories": ["cs.LG", "math.AP", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.01564", "abs": "https://arxiv.org/abs/2602.01564", "authors": ["Geuntaek Seo", "Minseop Shin", "Pierre Monmarch\u00e9", "Beomjun Choi"], "title": "Local Exponential Stability of Mean-Field Langevin Descent-Ascent in Wasserstein Space", "comment": null, "summary": "We study the mean-field Langevin descent-ascent (MFL-DA), a coupled optimization dynamics on the space of probability measures for entropically regularized two-player zero-sum games. Although the associated mean-field objective admits a unique mixed Nash equilibrium, the long-time behavior of the original MFL-DA for general nonconvex-nonconcave payoffs has remained largely open. Answering an open question posed by Wang and Chizat (COLT 2024), we provide a partial resolution by proving that this equilibrium is locally exponentially stable: if the initialization is sufficiently close in Wasserstein metric, the dynamics trends to the equilibrium at an exponential rate. The key to our analysis is to establish a coercivity estimate for the entropy near equilibrium via spectral analysis of the linearized operator. We show that this coercivity effectively reveals a local displacement convex-concave structure, thereby driving contraction. This result settles the local stability and quantitative rate questions of Wang and Chizat, leaving global convergence as a remaining open challenge.", "AI": {"tldr": "\u8bc1\u660e\u4e86\u5747\u503c\u573aLangevin\u4e0b\u964d-\u4e0a\u5347\u52a8\u529b\u5b66\u5728\u71b5\u6b63\u5219\u5316\u4e8c\u4eba\u96f6\u548c\u535a\u5f08\u4e2d\u5c40\u90e8\u6307\u6570\u7a33\u5b9a\uff1a\u5f53\u521d\u59cb\u5316\u8db3\u591f\u63a5\u8fd1\u65f6\uff0c\u4ee5\u6307\u6570\u901f\u7387\u6536\u655b\u5230\u6df7\u5408\u7eb3\u4ec0\u5747\u8861\u3002", "motivation": "\u867d\u7136\u5747\u503c\u573a\u76ee\u6807\u51fd\u6570\u5b58\u5728\u552f\u4e00\u6df7\u5408\u7eb3\u4ec0\u5747\u8861\uff0c\u4f46\u5bf9\u4e8e\u4e00\u822c\u975e\u51f8-\u975e\u51f9\u652f\u4ed8\u51fd\u6570\uff0c\u539f\u59cbMFL-DA\u52a8\u529b\u5b66\u7684\u957f\u671f\u884c\u4e3a\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u56de\u7b54Wang\u548cChizat\uff08COLT 2024\uff09\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7ebf\u6027\u5316\u7b97\u5b50\u7684\u8c31\u5206\u6790\uff0c\u5728\u5747\u8861\u70b9\u9644\u8fd1\u5efa\u7acb\u71b5\u7684\u5f3a\u5236\u6027\u4f30\u8ba1\u3002\u8fd9\u79cd\u5f3a\u5236\u6027\u63ed\u793a\u4e86\u5c40\u90e8\u4f4d\u79fb\u51f8-\u51f9\u7ed3\u6784\uff0c\u4ece\u800c\u9a71\u52a8\u6536\u7f29\u3002", "result": "\u8bc1\u660e\u4e86\u5747\u8861\u70b9\u662f\u5c40\u90e8\u6307\u6570\u7a33\u5b9a\u7684\uff1a\u5982\u679c\u521d\u59cb\u5316\u5728Wasserstein\u5ea6\u91cf\u4e0b\u8db3\u591f\u63a5\u8fd1\uff0c\u52a8\u529b\u5b66\u5c06\u4ee5\u6307\u6570\u901f\u7387\u8d8b\u5411\u5747\u8861\u3002", "conclusion": "\u89e3\u51b3\u4e86Wang\u548cChizat\u63d0\u51fa\u7684\u5c40\u90e8\u7a33\u5b9a\u6027\u548c\u5b9a\u91cf\u901f\u7387\u95ee\u9898\uff0c\u4f46\u5168\u5c40\u6536\u655b\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002"}}
{"id": "2602.01576", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01576", "abs": "https://arxiv.org/abs/2602.01576", "authors": ["Woosung Koh", "Sungjun Han", "Segyu Lee", "Se-Young Yun", "Jamin Shin"], "title": "Generative Visual Code Mobile World Models", "comment": "Pre-print (technical report)", "summary": "Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.", "AI": {"tldr": "gWorld\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u53ef\u6e32\u67d3\u4ee3\u7801\u751f\u6210\u7684\u53ef\u89c6\u5316\u79fb\u52a8GUI\u4e16\u754c\u6a21\u578b\u65b0\u8303\u5f0f\uff0c\u4f7f\u7528\u5355\u4e2a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u53ef\u6267\u884c\u7684\u7f51\u9875\u4ee3\u7801\u800c\u975e\u76f4\u63a5\u751f\u6210\u50cf\u7d20\uff0c\u5728\u51c6\u786e\u6027\u4e0e\u6a21\u578b\u5927\u5c0f\u95f4\u5efa\u7acb\u4e86\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "motivation": "\u5f53\u524d\u79fb\u52a8GUI\u4e16\u754c\u6a21\u578b\u9762\u4e34\u5173\u952e\u6743\u8861\uff1a\u57fa\u4e8e\u6587\u672c\u7684\u6a21\u578b\u727a\u7272\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u800c\u89c6\u89c9\u6a21\u578b\u5728\u7cbe\u786e\u6587\u672c\u6e32\u67d3\u65b9\u9762\u5b58\u5728\u7f3a\u9677\uff0c\u9700\u8981\u4f9d\u8d56\u7f13\u6162\u590d\u6742\u7684\u5916\u90e8\u6a21\u578b\u7ba1\u9053\u3002\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u89c6\u89c9\u4e16\u754c\u5efa\u6a21\u901a\u8fc7\u53ef\u6e32\u67d3\u4ee3\u7801\u751f\u6210\u7684\u65b0\u8303\u5f0f\uff1a\u4f7f\u7528\u5355\u4e2a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2aGUI\u72b6\u6001\u4f5c\u4e3a\u53ef\u6267\u884c\u7684\u7f51\u9875\u4ee3\u7801\uff08\u800c\u975e\u76f4\u63a5\u751f\u6210\u50cf\u7d20\uff09\uff0c\u7ed3\u5408\u4e86\u8bed\u8a00\u5148\u9a8c\u7684\u7cbe\u786e\u6587\u672c\u6e32\u67d3\u80fd\u529b\u548c\u7ed3\u6784\u5316\u7f51\u9875\u4ee3\u7801\u9884\u8bad\u7ec3\u7684\u9ad8\u4fdd\u771f\u89c6\u89c9\u751f\u6210\u80fd\u529b\u3002", "result": "\u57284\u4e2a\u5206\u5e03\u5185\u548c2\u4e2a\u5206\u5e03\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cgWorld\uff088B\u548c32B\u53c2\u6570\uff09\u5728\u51c6\u786e\u6027\u4e0e\u6a21\u578b\u5927\u5c0f\u65b9\u9762\u5efa\u7acb\u4e86\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u4f18\u4e8e8\u4e2a\u524d\u6cbf\u5f00\u6e90\u6a21\u578b\uff08\u6700\u5927\u6a21\u578b\u89c4\u6a21\u8d85\u8fc750\u500d\uff09\u3002\u6570\u636e\u6269\u5c55\u3001\u7ba1\u9053\u7ec4\u4ef6\u4f18\u5316\u548c\u4e16\u754c\u5efa\u6a21\u6539\u8fdb\u5747\u5e26\u6765\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u53ef\u6e32\u67d3\u4ee3\u7801\u751f\u6210\u7684\u89c6\u89c9\u4e16\u754c\u5efa\u6a21\u8303\u5f0f\u6210\u529f\u89e3\u51b3\u4e86\u79fb\u52a8GUI\u4e16\u754c\u6a21\u578b\u7684\u5173\u952e\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u6587\u672c\u6e32\u67d3\u548c\u9ad8\u4fdd\u771f\u89c6\u89c9\u751f\u6210\u7684\u7ed3\u5408\uff0c\u4e3a\u79fb\u52a8GUI\u4ee3\u7406\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2602.01581", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01581", "abs": "https://arxiv.org/abs/2602.01581", "authors": ["Yao Zhao", "Kwang-Sung Jun"], "title": "Nearly Optimal Active Preference Learning and Its Application to LLM Alignment", "comment": null, "summary": "Aligning large language models (LLMs) depends on high-quality datasets of human preference labels, which are costly to collect. Although active learning has been studied to improve sample efficiency relative to passive collection, many existing approaches adopt classical experimental design criteria such as G- or D-optimality. These objectives are not tailored to the structure of preference learning, leaving open the design of problem-specific algorithms. In this work, we identify a simple intuition specific to preference learning that calls into question the suitability of these existing design objectives. Motivated by this insight, we propose two active learning algorithms. The first provides the first instance-dependent label complexity guarantee for this setting, and the second is a simple, practical greedy method. We evaluate our algorithm on real-world preference datasets and observe improved sample efficiency compared to existing methods.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u504f\u597d\u5b66\u4e60\u7684\u9ad8\u6548\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u6cd5\u63d0\u5347\u6837\u672c\u6548\u7387", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4f9d\u8d56\u9ad8\u8d28\u91cf\u4eba\u7c7b\u504f\u597d\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u6536\u96c6\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u91c7\u7528\u7ecf\u5178\u5b9e\u9a8c\u8bbe\u8ba1\u51c6\u5219\uff08\u5982G-\u6216D-\u6700\u4f18\u6027\uff09\uff0c\u8fd9\u4e9b\u76ee\u6807\u672a\u9488\u5bf9\u504f\u597d\u5b66\u4e60\u7ed3\u6784\u5b9a\u5236\uff0c\u9700\u8981\u8bbe\u8ba1\u95ee\u9898\u7279\u5b9a\u7684\u7b97\u6cd5\u3002", "method": "\u57fa\u4e8e\u504f\u597d\u5b66\u4e60\u7279\u5b9a\u76f4\u89c9\u63d0\u51fa\u4e24\u79cd\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\uff1a\u7b2c\u4e00\u79cd\u63d0\u4f9b\u8be5\u573a\u666f\u4e0b\u9996\u4e2a\u5b9e\u4f8b\u4f9d\u8d56\u7684\u6807\u7b7e\u590d\u6742\u5ea6\u4fdd\u8bc1\uff1b\u7b2c\u4e8c\u79cd\u662f\u7b80\u5355\u5b9e\u7528\u7684\u8d2a\u5a6a\u65b9\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u504f\u597d\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u7b97\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u89c2\u5bdf\u5230\u6837\u672c\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u9488\u5bf9\u504f\u597d\u5b66\u4e60\u8bbe\u8ba1\u7684\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\u6bd4\u4f20\u7edf\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u6cd5\u66f4\u6709\u6548\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u6570\u636e\u6536\u96c6\u6210\u672c\u3002"}}
{"id": "2602.01585", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01585", "abs": "https://arxiv.org/abs/2602.01585", "authors": ["Xu Zhang", "Qitong Wang", "Peng Wang", "Wei Wang"], "title": "A Lightweight Sparse Interaction Network for Time Series Forecasting", "comment": "The paper is published in AAAI Conference on Artificial Intelligence, AAAI 2025. The code is available at the link https://github.com/Meteor-Stars/LSINet", "summary": "Recent work shows that linear models can outperform several transformer models in long-term time-series forecasting (TSF). However, instead of explicitly performing temporal interaction through self-attention, linear models implicitly perform it based on stacked MLP structures, which may be insufficient in capturing the complex temporal dependencies and their performance still has potential for improvement. To this end, we propose a Lightweight Sparse Interaction Network (LSINet) for TSF task. Inspired by the sparsity of self-attention, we propose a Multihead Sparse Interaction Mechanism (MSIM). Different from self-attention, MSIM learns the important connections between time steps through sparsity-induced Bernoulli distribution to capture temporal dependencies for TSF. The sparsity is ensured by the proposed self-adaptive regularization loss. Moreover, we observe the shareability of temporal interactions and propose to perform Shared Interaction Learning (SIL) for MSIM to further enhance efficiency and improve convergence. LSINet is a linear model comprising only MLP structures with low overhead and equipped with explicit temporal interaction mechanisms. Extensive experiments on public datasets show that LSINet achieves both higher accuracy and better efficiency than advanced linear models and transformer models in TSF tasks. The code is available at the link https://github.com/Meteor-Stars/LSINet.", "AI": {"tldr": "LSINet\u662f\u4e00\u4e2a\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u8f7b\u91cf\u7ea7\u7a00\u758f\u4ea4\u4e92\u7f51\u7edc\uff0c\u901a\u8fc7\u591a\u5934\u90e8\u7a00\u758f\u4ea4\u4e92\u673a\u5236\u548c\u5171\u4eab\u4ea4\u4e92\u5b66\u4e60\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u6a21\u578b\u6548\u7387\u7684\u540c\u65f6\u663e\u5f0f\u5730\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f18\u4e8e\u73b0\u6709\u7ebf\u6027\u6a21\u578b\u548cTransformer\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u6a21\u578b\u867d\u7136\u5728\u67d0\u4e9b\u957f\u65f6\u5e8f\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8eTransformer\u6a21\u578b\uff0c\u4f46\u5b83\u4eec\u901a\u8fc7\u5806\u53e0MLP\u7ed3\u6784\u9690\u5f0f\u5730\u8fdb\u884c\u65f6\u95f4\u4ea4\u4e92\uff0c\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u590d\u6742\u7684\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u6027\u80fd\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u63d0\u51faLSINet\uff0c\u5305\u542b\uff1a1) \u591a\u5934\u90e8\u7a00\u758f\u4ea4\u4e92\u673a\u5236(MSIM)\uff0c\u901a\u8fc7\u5b66\u4e60\u7a00\u758f\u8bf1\u5bfc\u7684\u4f2f\u52aa\u5229\u5206\u5e03\u6765\u5b66\u4e60\u65f6\u95f4\u6b65\u4e4b\u95f4\u7684\u91cd\u8981\u8fde\u63a5\uff1b2) \u81ea\u9002\u5e94\u6b63\u5219\u5316\u635f\u5931\u786e\u4fdd\u7a00\u758f\u6027\uff1b3) \u5171\u4eab\u4ea4\u4e92\u5b66\u4e60(SIL)\u5229\u7528\u65f6\u95f4\u4ea4\u4e92\u7684\u53ef\u5171\u4eab\u6027\u63d0\u9ad8\u6548\u7387\u548c\u6536\u655b\u6027\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cLSINet\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u6bd4\u5148\u8fdb\u7684\u7ebf\u6027\u6a21\u578b\u548cTransformer\u6a21\u578b\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u597d\u7684\u6548\u7387\u3002", "conclusion": "LSINet\u901a\u8fc7\u663e\u5f0f\u7684\u65f6\u95f4\u4ea4\u4e92\u673a\u5236\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u6a21\u578b\u4f4e\u5f00\u9500\u7684\u540c\u65f6\uff0c\u6709\u6548\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5b9e\u73b0\u4e86\u7cbe\u5ea6\u548c\u6548\u7387\u7684\u53cc\u91cd\u63d0\u5347\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01588", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01588", "abs": "https://arxiv.org/abs/2602.01588", "authors": ["Huu Hiep Nguyen", "Minh Hoang Nguyen", "Dung Nguyen", "Hung Le"], "title": "Spectral Text Fusion: A Frequency-Aware Approach to Multimodal Time-Series Forecasting", "comment": null, "summary": "Multimodal time series forecasting is crucial in real-world applications, where decisions depend on both numerical data and contextual signals. The core challenge is to effectively combine temporal numerical patterns with the context embedded in other modalities, such as text. While most existing methods align textual features with time-series patterns one step at a time, they neglect the multiscale temporal influences of contextual information such as time-series cycles and dynamic shifts. This mismatch between local alignment and global textual context can be addressed by spectral decomposition, which separates time series into frequency components capturing both short-term changes and long-term trends. In this paper, we propose SpecTF, a simple yet effective framework that integrates the effect of textual data on time series in the frequency domain. Our method extracts textual embeddings, projects them into the frequency domain, and fuses them with the time series' spectral components using a lightweight cross-attention mechanism. This adaptively reweights frequency bands based on textual relevance before mapping the results back to the temporal domain for predictions. Experimental results demonstrate that SpecTF significantly outperforms state-of-the-art models across diverse multi-modal time series datasets while utilizing considerably fewer parameters. Code is available at https://github.com/hiepnh137/SpecTF.", "AI": {"tldr": "SpecTF\uff1a\u4e00\u79cd\u5728\u9891\u57df\u4e2d\u6574\u5408\u6587\u672c\u6570\u636e\u5bf9\u65f6\u95f4\u5e8f\u5217\u5f71\u54cd\u7684\u7b80\u5355\u6709\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u8c31\u5206\u89e3\u548c\u8f7b\u91cf\u7ea7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9010\u70b9\u5bf9\u9f50\u6587\u672c\u7279\u5f81\u4e0e\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\uff0c\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5982\u65f6\u95f4\u5e8f\u5217\u5468\u671f\u548c\u52a8\u6001\u53d8\u5316\uff09\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u5f71\u54cd\uff0c\u5bfc\u81f4\u5c40\u90e8\u5bf9\u9f50\u4e0e\u5168\u5c40\u6587\u672c\u4e0a\u4e0b\u6587\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faSpecTF\u6846\u67b6\uff1a1\uff09\u63d0\u53d6\u6587\u672c\u5d4c\u5165\uff1b2\uff09\u5c06\u5176\u6295\u5f71\u5230\u9891\u57df\uff1b3\uff09\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u65f6\u95f4\u5e8f\u5217\u7684\u9891\u8c31\u5206\u91cf\u878d\u5408\uff1b4\uff09\u6839\u636e\u6587\u672c\u76f8\u5173\u6027\u81ea\u9002\u5e94\u91cd\u65b0\u52a0\u6743\u9891\u5e26\uff1b5\uff09\u5c06\u7ed3\u679c\u6620\u5c04\u56de\u65f6\u57df\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSpecTF\u5728\u591a\u79cd\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u540c\u65f6\u4f7f\u7528\u7684\u53c2\u6570\u6570\u91cf\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "SpecTF\u901a\u8fc7\u5728\u9891\u57df\u4e2d\u6574\u5408\u6587\u672c\u6570\u636e\u5bf9\u65f6\u95f4\u5e8f\u5217\u7684\u5f71\u54cd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5c3a\u5ea6\u65f6\u95f4\u5f71\u54cd\u95ee\u9898\uff0c\u4e3a\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01599", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01599", "abs": "https://arxiv.org/abs/2602.01599", "authors": ["Israel Adewuyi", "Solomon Okibe", "Vladmir Ivanov"], "title": "The Multiple Ticket Hypothesis: Random Sparse Subnetworks Suffice for RLVR", "comment": null, "summary": "The Lottery Ticket Hypothesis demonstrated that sparse subnetworks can match full-model performance, suggesting parameter redundancy. Meanwhile, in Reinforcement Learning with Verifiable Rewards (RLVR), recent work has shown that updates concentrate on a sparse subset of parameters, which further lends evidence to this underlying redundancy. We study the simplest possible way to exploit this redundancy: training only a randomly selected subset of parameters at extreme sparsities. Empirically, we find that training just 1\\% of parameters matches or exceeds full-parameter RLVR finetuning across 3 models and 2 task domains. Moreover, different random masks show minimal overlap ($\\leq 0.005$ Jaccard similarity) and yet all succeed, suggesting pretrained models contain many viable sparse subnetworks rather than one privileged set. We term this the Multiple Ticket Hypothesis. We explain this phenomenon through the implicit per-step KL constraint in RLVR, which restricts updates to a low-dimensional subspace, enabling arbitrary sparse masks to succeed.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u591a\u7968\u5047\u8bf4\"\uff1a\u9884\u8bad\u7ec3\u6a21\u578b\u5305\u542b\u591a\u4e2a\u53ef\u884c\u7684\u7a00\u758f\u5b50\u7f51\u7edc\uff0c\u800c\u975e\u5355\u4e00\u7279\u6743\u96c6\u5408\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728RLVR\u4e2d\u4ec5\u8bad\u7ec31%\u7684\u968f\u673a\u53c2\u6570\u5c31\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u5168\u53c2\u6570\u5fae\u8c03\u6548\u679c\u3002", "motivation": "\u5f69\u7968\u5047\u8bf4\u8868\u660e\u7a00\u758f\u5b50\u7f51\u7edc\u80fd\u8fbe\u5230\u5b8c\u6574\u6a21\u578b\u6027\u80fd\uff0cRLVR\u4e2d\u66f4\u65b0\u96c6\u4e2d\u5728\u7a00\u758f\u53c2\u6570\u5b50\u96c6\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u53c2\u6570\u5197\u4f59\u3002\u672c\u7814\u7a76\u63a2\u7d22\u5229\u7528\u8fd9\u79cd\u5197\u4f59\u7684\u6700\u7b80\u5355\u65b9\u5f0f\uff1a\u5728\u6781\u7aef\u7a00\u758f\u5ea6\u4e0b\u4ec5\u8bad\u7ec3\u968f\u673a\u9009\u62e9\u7684\u53c2\u6570\u5b50\u96c6\u3002", "method": "\u91c7\u7528\u6700\u7b80\u5355\u7684\u65b9\u6cd5\uff1a\u5728RLVR\uff08\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u4e2d\uff0c\u4ec5\u8bad\u7ec3\u968f\u673a\u9009\u62e9\u7684\u53c2\u6570\u5b50\u96c6\uff08\u6781\u7aef\u7a00\u758f\u5ea6\u59821%\uff09\u3002\u7814\u7a76\u4e0d\u540c\u968f\u673a\u63a9\u7801\u7684\u91cd\u53e0\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7RLVR\u4e2d\u9690\u5f0f\u7684\u6bcf\u6b65KL\u7ea6\u675f\u6765\u89e3\u91ca\u73b0\u8c61\u3002", "result": "\u4ec5\u8bad\u7ec31%\u7684\u53c2\u6570\u5c31\u80fd\u57283\u4e2a\u6a21\u578b\u548c2\u4e2a\u4efb\u52a1\u9886\u57df\u4e2d\u5339\u914d\u6216\u8d85\u8fc7\u5168\u53c2\u6570RLVR\u5fae\u8c03\u3002\u4e0d\u540c\u968f\u673a\u63a9\u7801\u91cd\u53e0\u5ea6\u6781\u4f4e\uff08Jaccard\u76f8\u4f3c\u5ea6\u22640.005\uff09\uff0c\u4f46\u90fd\u80fd\u6210\u529f\uff0c\u8868\u660e\u5b58\u5728\u591a\u4e2a\u53ef\u884c\u7684\u7a00\u758f\u5b50\u7f51\u7edc\u3002", "conclusion": "\u9884\u8bad\u7ec3\u6a21\u578b\u5305\u542b\u8bb8\u591a\u53ef\u884c\u7684\u7a00\u758f\u5b50\u7f51\u7edc\u800c\u975e\u5355\u4e00\u7279\u6743\u96c6\u5408\uff0c\u79f0\u4e3a\"\u591a\u7968\u5047\u8bf4\"\u3002RLVR\u4e2d\u7684\u9690\u5f0fKL\u7ea6\u675f\u5c06\u66f4\u65b0\u9650\u5236\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\uff0c\u4f7f\u5f97\u4efb\u610f\u7a00\u758f\u63a9\u7801\u90fd\u80fd\u6210\u529f\u3002"}}
{"id": "2602.01601", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01601", "abs": "https://arxiv.org/abs/2602.01601", "authors": ["Hieu Trung Nguyen", "Bao Nguyen", "Wenao Ma", "Yuzhi Zhao", "Ruifeng She", "Viet Anh Nguyen"], "title": "Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards", "comment": "Accepted at ICLR 2026", "summary": "Sampling efficiency is a key bottleneck in reinforcement learning with verifiable rewards. Existing group-based policy optimization methods, such as GRPO, allocate a fixed number of rollouts for all training prompts. This uniform allocation implicitly treats all prompts as equally informative, and could lead to inefficient computational budget usage and impede training progress. We introduce \\Ours, a Variance-Informed Predictive allocation strategy that allocates a given rollout budget to the prompts in the incumbent batch to minimize the expected gradient variance of the policy update. At each iteration, \\Ours~uses a lightweight Gaussian process model to predict per-prompt success probabilities based on recent rollouts. These probability predictions are translated into variance estimates, which are then fed into a convex optimization problem to determine the optimal rollout allocations under a hard compute budget constraint. Empirical results show that \\Ours~consistently improves sampling efficiency and achieves higher performance than uniform or heuristic allocation strategies in multiple benchmarks. Our code will be available at https://github.com/HieuNT91/VIP.", "AI": {"tldr": "VIP\u662f\u4e00\u79cd\u57fa\u4e8e\u65b9\u5dee\u4fe1\u606f\u7684\u9884\u6d4b\u6027\u5206\u914d\u7b56\u7565\uff0c\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u9884\u6d4b\u6bcf\u4e2a\u63d0\u793a\u7684\u6210\u529f\u6982\u7387\uff0c\u4f18\u5316rollout\u5206\u914d\u4ee5\u6700\u5c0f\u5316\u7b56\u7565\u66f4\u65b0\u7684\u68af\u5ea6\u65b9\u5dee\uff0c\u4ece\u800c\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u7684\u91c7\u6837\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7ec4\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff08\u5982GRPO\uff09\u4e3a\u6240\u6709\u8bad\u7ec3\u63d0\u793a\u5206\u914d\u56fa\u5b9a\u6570\u91cf\u7684rollout\uff0c\u8fd9\u79cd\u5747\u5300\u5206\u914d\u9690\u542b\u5730\u5047\u8bbe\u6240\u6709\u63d0\u793a\u5177\u6709\u540c\u7b49\u4fe1\u606f\u91cf\uff0c\u53ef\u80fd\u5bfc\u81f4\u8ba1\u7b97\u9884\u7b97\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\u5e76\u963b\u788d\u8bad\u7ec3\u8fdb\u5c55\u3002", "method": "VIP\u4f7f\u7528\u8f7b\u91cf\u7ea7\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u57fa\u4e8e\u6700\u8fd1\u7684rollout\u9884\u6d4b\u6bcf\u4e2a\u63d0\u793a\u7684\u6210\u529f\u6982\u7387\uff0c\u5c06\u8fd9\u4e9b\u6982\u7387\u9884\u6d4b\u8f6c\u6362\u4e3a\u65b9\u5dee\u4f30\u8ba1\uff0c\u7136\u540e\u901a\u8fc7\u51f8\u4f18\u5316\u95ee\u9898\u5728\u786c\u8ba1\u7b97\u9884\u7b97\u7ea6\u675f\u4e0b\u786e\u5b9a\u6700\u4f18\u7684rollout\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVIP\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u9ad8\u91c7\u6837\u6548\u7387\uff0c\u5e76\u6bd4\u5747\u5300\u5206\u914d\u6216\u542f\u53d1\u5f0f\u5206\u914d\u7b56\u7565\u83b7\u5f97\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "conclusion": "VIP\u901a\u8fc7\u65b9\u5dee\u611f\u77e5\u7684\u9884\u6d4b\u6027\u5206\u914d\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u91c7\u6837\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u4e3a\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8ba1\u7b97\u9884\u7b97\u5206\u914d\u65b9\u6cd5\u3002"}}
{"id": "2602.01605", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01605", "abs": "https://arxiv.org/abs/2602.01605", "authors": ["Anthony Bao", "Venkata Hasith Vattikuti", "Jeffrey Lai", "William Gilpin"], "title": "Universal Redundancies in Time Series Foundation Models", "comment": null, "summary": "Time Series Foundation Models (TSFMs) leverage extensive pretraining to accurately predict unseen time series during inference, without the need for task-specific fine-tuning. Through large-scale evaluations on standard benchmarks, we find that leading transformer-based TSFMs exhibit redundant components in their intermediate layers. We introduce a set of tools for mechanistic interpretability of TSFMs, including ablations of specific components and direct logit attribution on the residual stream. Our findings are consistent across several leading TSFMs with diverse architectures, and across a diverse set of real-world and synthetic time-series datasets. We discover that all models in our study are robust to ablations of entire layers. Furthermore, we develop a theoretical framework framing transformers as kernel regressors, motivating a purely intrinsic strategy for ablating heads based on the stable rank of the per-head projection matrices. Using this approach, we uncover the specific heads responsible for degenerate phenomena widely observed in TSFMs, such as parroting of motifs from the context and seasonality bias. Our study sheds light on the universal properties of this emerging class of architectures for continuous-time sequence modeling.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5b58\u5728\u4e2d\u95f4\u5c42\u5197\u4f59\uff0c\u63d0\u51fa\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff0c\u53d1\u73b0\u6a21\u578b\u5bf9\u6574\u5c42\u526a\u679d\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u8bc6\u522b\u51fa\u5bfc\u81f4\u7279\u5b9a\u9000\u5316\u73b0\u8c61\uff08\u5982\u6a21\u5f0f\u91cd\u590d\u548c\u5b63\u8282\u6027\u504f\u5dee\uff09\u7684\u6ce8\u610f\u529b\u5934\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5b9e\u73b0\u96f6\u6837\u672c\u9884\u6d4b\uff0c\u4f46\u5bf9\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u7f3a\u4e4f\u7406\u89e3\u3002\u7814\u7a76\u8005\u53d1\u73b0\u73b0\u6709Transformer-based TSFMs\u5b58\u5728\u4e2d\u95f4\u5c42\u5197\u4f59\uff0c\u9700\u8981\u5f00\u53d1\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u6765\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u7684\u5de5\u4f5c\u539f\u7406\u548c\u6f5c\u5728\u95ee\u9898\u3002", "method": "1) \u5f00\u53d1TSFMs\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u96c6\uff0c\u5305\u62ec\u7279\u5b9a\u7ec4\u4ef6\u6d88\u878d\u548c\u6b8b\u5dee\u6d41\u4e0a\u7684\u76f4\u63a5logit\u5f52\u56e0\uff1b2) \u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5c06Transformer\u89c6\u4e3a\u6838\u56de\u5f52\u5668\uff0c\u57fa\u4e8e\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u6295\u5f71\u77e9\u9635\u7684\u7a33\u5b9a\u79e9\u8fdb\u884c\u5185\u5728\u526a\u679d\uff1b3) \u5728\u591a\u4e2a\u9886\u5148\u7684TSFM\u67b6\u6784\u548c\u591a\u6837\u5316\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u8bc4\u4f30\u3002", "result": "1) \u6240\u6709\u7814\u7a76\u6a21\u578b\u5bf9\u6574\u5c42\u526a\u679d\u90fd\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff1b2) \u8bc6\u522b\u51fa\u5bfc\u81f4TSFMs\u4e2d\u5e7f\u6cdb\u89c2\u5bdf\u5230\u7684\u9000\u5316\u73b0\u8c61\uff08\u5982\u4e0a\u4e0b\u6587\u6a21\u5f0f\u91cd\u590d\u548c\u5b63\u8282\u6027\u504f\u5dee\uff09\u7684\u7279\u5b9a\u6ce8\u610f\u529b\u5934\uff1b3) \u53d1\u73b0\u4e0d\u540c\u67b6\u6784\u7684TSFMs\u5177\u6709\u4e00\u81f4\u7684\u5197\u4f59\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u8fde\u7eed\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\u65b0\u5174\u67b6\u6784\u7684\u666e\u904d\u7279\u6027\uff0c\u4e3a\u7406\u89e3\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u5de5\u4f5c\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5e76\u5c55\u793a\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u8bc6\u522b\u548c\u89e3\u51b3\u6a21\u578b\u9000\u5316\u95ee\u9898\u65b9\u9762\u7684\u4ef7\u503c\u3002"}}
{"id": "2602.01606", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01606", "abs": "https://arxiv.org/abs/2602.01606", "authors": ["Zeqiao Li", "Yijing Wang", "Haoyu Wang", "Zheng Li", "Zhiqiang Zuo"], "title": "Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching", "comment": null, "summary": "Diffusion policies are expressive yet incur high inference latency. Flow Matching (FM) enables one-step generation, but integrating it into Maximum Entropy Reinforcement Learning (MaxEnt RL) is challenging: the optimal policy is an intractable energy-based distribution, and the efficient log-likelihood estimation required to balance exploration and exploitation suffers from severe discretization bias. We propose \\textbf{F}low-based \\textbf{L}og-likelihood-\\textbf{A}ware \\textbf{M}aximum \\textbf{E}ntropy RL (\\textbf{FLAME}), a principled framework that addresses these challenges. First, we derive a Q-Reweighted FM objective that bypasses partition function estimation via importance reweighting. Second, we design a decoupled entropy estimator that rigorously corrects bias, which enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Third, we integrate the MeanFlow formulation to achieve expressive and efficient one-step control. Empirical results on MuJoCo show that FLAME outperforms Gaussian baselines and matches multi-step diffusion policies with significantly lower inference cost. Code is available at https://github.com/lzqw/FLAME.", "AI": {"tldr": "FLAME\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u5355\u6b65\u751f\u6210\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u91cd\u52a0\u6743\u548c\u504f\u5dee\u6821\u6b63\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u63a8\u7406\u5ef6\u8fdf\u548c\u79bb\u6563\u5316\u504f\u5dee\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8868\u8fbe\u529b\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u6269\u6563\u7b56\u7565\u867d\u7136\u8868\u8fbe\u529b\u5f3a\u4f46\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0c\u800c\u6d41\u5339\u914d\u53ef\u4ee5\u5b9e\u73b0\u5355\u6b65\u751f\u6210\u4f46\u96be\u4ee5\u96c6\u6210\u5230\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u56e0\u4e3a\u6700\u4f18\u7b56\u7565\u662f\u96be\u4ee5\u5904\u7406\u7684\u57fa\u4e8e\u80fd\u91cf\u7684\u5206\u5e03\uff0c\u4e14\u9ad8\u6548\u7684\u4f3c\u7136\u4f30\u8ba1\u5b58\u5728\u4e25\u91cd\u7684\u79bb\u6563\u5316\u504f\u5dee\u3002", "method": "1) \u63d0\u51faQ-\u91cd\u52a0\u6743\u6d41\u5339\u914d\u76ee\u6807\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u91cd\u52a0\u6743\u7ed5\u8fc7\u914d\u5206\u51fd\u6570\u4f30\u8ba1\uff1b2) \u8bbe\u8ba1\u89e3\u8026\u7684\u71b5\u4f30\u8ba1\u5668\uff0c\u4e25\u683c\u6821\u6b63\u504f\u5dee\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a2\u7d22\uff1b3) \u96c6\u6210MeanFlow\u516c\u5f0f\u5b9e\u73b0\u8868\u8fbe\u529b\u5f3a\u4e14\u9ad8\u6548\u7684\u5355\u6b65\u63a7\u5236\u3002", "result": "\u5728MuJoCo\u5b9e\u9a8c\u4e2d\uff0cFLAME\u4f18\u4e8e\u9ad8\u65af\u57fa\u7ebf\uff0c\u4e0e\u591a\u6b65\u6269\u6563\u7b56\u7565\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u63a8\u7406\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "FLAME\u4e3a\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u6d41\u5339\u914d\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u63a8\u7406\u5ef6\u8fdf\u548c\u79bb\u6563\u5316\u504f\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8868\u8fbe\u529b\u5f3a\u4e14\u9ad8\u6548\u7684\u5355\u6b65\u63a7\u5236\u3002"}}
{"id": "2602.01611", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01611", "abs": "https://arxiv.org/abs/2602.01611", "authors": ["Weizheng Gu", "Chengze Li", "Zhuohao Yu", "Mengyuan Sun", "Zhibang Yang", "Wei Wang", "Hongrui Jia", "Shikun Zhang", "Wei Ye"], "title": "What Do Agents Learn from Trajectory-SFT: Semantics or Interfaces?", "comment": null, "summary": "Large language models are increasingly evaluated as interactive agents, yet standard agent benchmarks conflate two qualitatively distinct sources of success: semantic tool-use and interface-specific interaction pattern memorization. Because both mechanisms can yield identical task success on the original interface, benchmark scores alone are not identifiable evidence of environment-invariant capability. We propose PIPE, a protocol-level evaluation augmentation for diagnosing interface reliance by minimally rewriting environment interfaces while preserving task semantics and execution behavior. Across 16 environments from AgentBench and AgentGym and a range of open-source and API-based agents, PIPE reveals that trajectory-SFT substantially amplifies interface shortcutting: trained agents degrade sharply under minimal interface rewrites, while non-trajectory-trained models remain largely stable. We further introduce Interface Reliance (IR), a counterbalanced alias-based metric that quantifies preference for training-time interfaces, and show that interface shortcutting exhibits environment-dependent, non-monotonic training dynamics that remain invisible under standard evaluation. Our code is available at https://anonymous.4open.science/r/What-Do-Agents-Learn-from-Trajectory-SFT-Semantics-or-Interfaces--0831/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPIPE\u534f\u8bae\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63ed\u793a\u667a\u80fd\u4f53\u5728\u8f68\u8ff9\u76d1\u7763\u5fae\u8c03\u540e\u8fc7\u5ea6\u4f9d\u8d56\u8bad\u7ec3\u63a5\u53e3\u800c\u975e\u8bed\u4e49\u7406\u89e3\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u63a5\u53e3\u6539\u5199\u8bca\u65ad\u63a5\u53e3\u4f9d\u8d56\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4ea4\u4e92\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u5b58\u5728\u6df7\u6dc6\uff1a\u65e0\u6cd5\u533a\u5206\u662f\u771f\u6b63\u7684\u8bed\u4e49\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u8bb0\u4f4f\u4e86\u7279\u5b9a\u63a5\u53e3\u7684\u4ea4\u4e92\u6a21\u5f0f\u3002\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u8bc6\u522b\u73af\u5883\u4e0d\u53d8\u7684\u80fd\u529b\u8bc1\u636e\u3002", "method": "\u63d0\u51faPIPE\uff08\u534f\u8bae\u7ea7\u8bc4\u4f30\u589e\u5f3a\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6539\u5199\u73af\u5883\u63a5\u53e3\uff08\u4fdd\u6301\u4efb\u52a1\u8bed\u4e49\u548c\u6267\u884c\u884c\u4e3a\u4e0d\u53d8\uff09\u6765\u8bca\u65ad\u63a5\u53e3\u4f9d\u8d56\u3002\u5f15\u5165\u63a5\u53e3\u4f9d\u8d56\u5ea6\uff08IR\uff09\u6307\u6807\uff0c\u91cf\u5316\u667a\u80fd\u4f53\u5bf9\u8bad\u7ec3\u65f6\u63a5\u53e3\u7684\u504f\u597d\u3002", "result": "\u572816\u4e2a\u73af\u5883\u548c\u591a\u79cd\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff1a\u8f68\u8ff9\u76d1\u7763\u5fae\u8c03\u663e\u8457\u52a0\u5267\u63a5\u53e3\u6377\u5f84\u4f9d\u8d56\uff0c\u8bad\u7ec3\u540e\u7684\u667a\u80fd\u4f53\u5728\u6700\u5c0f\u63a5\u53e3\u6539\u5199\u4e0b\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u800c\u975e\u8f68\u8ff9\u8bad\u7ec3\u6a21\u578b\u4fdd\u6301\u7a33\u5b9a\u3002\u63a5\u53e3\u6377\u5f84\u4f9d\u8d56\u5448\u73b0\u73af\u5883\u76f8\u5173\u3001\u975e\u5355\u8c03\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "conclusion": "\u6807\u51c6\u8bc4\u4f30\u65e0\u6cd5\u63ed\u793a\u667a\u80fd\u4f53\u662f\u5426\u771f\u6b63\u5b66\u4e60\u8bed\u4e49\u7406\u89e3\u8fd8\u662f\u63a5\u53e3\u6a21\u5f0f\u8bb0\u5fc6\u3002PIPE\u65b9\u6cd5\u80fd\u6709\u6548\u8bca\u65ad\u63a5\u53e3\u4f9d\u8d56\uff0c\u8f68\u8ff9\u76d1\u7763\u5fae\u8c03\u5bb9\u6613\u5bfc\u81f4\u667a\u80fd\u4f53\u8fc7\u5ea6\u4f9d\u8d56\u8bad\u7ec3\u63a5\u53e3\u800c\u975e\u5b66\u4e60\u5e95\u5c42\u8bed\u4e49\u80fd\u529b\u3002"}}
{"id": "2602.01613", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01613", "abs": "https://arxiv.org/abs/2602.01613", "authors": ["Sergii Kozyrev", "Davyd Maiboroda"], "title": "A Practical Tensor-Network Compression Pipeline for Production-Scale Large Language Models", "comment": "13 pages, 5 figures", "summary": "Large language models are limited in deployment by GPU memory and inference latency. We present Minima, a production compression pipeline that learns where and how to structurally compress a Transformer and turns that compression into real serving gains. Minima trains a lightweight convolutional predictor to estimate layer- and patch-level sensitivity, applies a mixture of Tucker, tensor-train, and tensor-ring decompositions to low-sensitivity regions, performs a short healing fine-tune, and executes the resulting operators with custom Triton and CUDA kernels. The reduced memory footprint enables speculative decoding with a small draft model and a larger verifier. On Qwen3-32B at an 8k-token context window, Minima reduces peak VRAM from 64 GiB to 40 GiB. For a single active request, throughput increases from 40 tokens per second (baseline) to 50 tokens per second (Minima) and 75 tokens per second (Minima with speculative decoding). Under 50 parallel requests, throughput is 34, 44, and 53 tokens per second respectively, showing that Minima remains effective under high concurrency even when speculative decoding gains compress. We position Minima relative to recent tensor-network, low-rank plus quantization, and cross-layer sharing methods, and argue that it is a practical step toward more aggressive structural compression via shared tensor backbones with tiny per-layer adapters.", "AI": {"tldr": "Minima\u662f\u4e00\u4e2a\u751f\u4ea7\u7ea7\u538b\u7f29\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u538b\u7f29Transformer\u6a21\u578b\u6765\u51cf\u5c11GPU\u5185\u5b58\u5360\u7528\u548c\u63a8\u7406\u5ef6\u8fdf\uff0c\u7ed3\u5408\u591a\u79cd\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u548c\u81ea\u5b9a\u4e49\u5185\u6838\u5b9e\u73b0\uff0c\u652f\u6301\u63a8\u6d4b\u89e3\u7801\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u90e8\u7f72\u65f6\u53d7\u5230GPU\u5185\u5b58\u548c\u63a8\u7406\u5ef6\u8fdf\u7684\u9650\u5236\uff0c\u9700\u8981\u6709\u6548\u7684\u538b\u7f29\u65b9\u6cd5\u6765\u964d\u4f4e\u8d44\u6e90\u9700\u6c42\u5e76\u63d0\u5347\u670d\u52a1\u6027\u80fd\u3002", "method": "\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5377\u79ef\u9884\u6d4b\u5668\u8bc4\u4f30\u5c42\u548c\u8865\u4e01\u7ea7\u522b\u7684\u654f\u611f\u6027\uff0c\u5bf9\u4f4e\u654f\u611f\u6027\u533a\u57df\u5e94\u7528Tucker\u3001\u5f20\u91cf\u5206\u89e3\u548c\u5f20\u91cf\u73af\u5206\u89e3\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u8fdb\u884c\u77ed\u671f\u4fee\u590d\u5fae\u8c03\uff0c\u5e76\u4f7f\u7528\u81ea\u5b9a\u4e49Triton\u548cCUDA\u5185\u6838\u6267\u884c\u64cd\u4f5c\u3002", "result": "\u5728Qwen3-32B\u6a21\u578b\u4e0a\uff0c\u5cf0\u503cVRAM\u4ece64GiB\u964d\u81f340GiB\uff1b\u5355\u8bf7\u6c42\u541e\u5410\u91cf\u4ece40tokens/s\u63d0\u5347\u81f350tokens/s\uff08Minima\uff09\u548c75tokens/s\uff08\u5e26\u63a8\u6d4b\u89e3\u7801\uff09\uff1b50\u4e2a\u5e76\u884c\u8bf7\u6c42\u4e0b\u541e\u5410\u91cf\u4e3a34\u300144\u300153tokens/s\u3002", "conclusion": "Minima\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u7ed3\u6784\u5316\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u5171\u4eab\u5f20\u91cf\u9aa8\u5e72\u7f51\u7edc\u548c\u5fae\u5c0f\u5c42\u9002\u914d\u5668\uff0c\u4e3a\u66f4\u6fc0\u8fdb\u7684\u538b\u7f29\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2602.01614", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01614", "abs": "https://arxiv.org/abs/2602.01614", "authors": ["Qi Cheng", "Licheng Liu", "Yao Zhang", "Mu Hong", "Yiqun Xie", "Xiaowei Jia"], "title": "AgroFlux: A Spatial-Temporal Benchmark for Carbon and Nitrogen Flux Prediction in Agricultural Ecosystems", "comment": null, "summary": "Agroecosystem, which heavily influenced by human actions and accounts for a quarter of global greenhouse gas emissions (GHGs), plays a crucial role in mitigating global climate change and securing environmental sustainability. However, we can't manage what we can't measure. Accurately quantifying the pools and fluxes in the carbon, nutrient, and water nexus of the agroecosystem is therefore essential for understanding the underlying drivers of GHG and developing effective mitigation strategies. Conventional approaches like soil sampling, process-based models, and black-box machine learning models are facing challenges such as data sparsity, high spatiotemporal heterogeneity, and complex subsurface biogeochemical and physical processes. Developing new trustworthy approaches such as AI-empowered models, will require the AI-ready benchmark dataset and outlined protocols, which unfortunately do not exist. In this work, we introduce a first-of-its-kind spatial-temporal agroecosystem GHG benchmark dataset that integrates physics-based model simulations from Ecosys and DayCent with real-world observations from eddy covariance flux towers and controlled-environment facilities. We evaluate the performance of various sequential deep learning models on carbon and nitrogen flux prediction, including LSTM-based models, temporal CNN-based model, and Transformer-based models. Furthermore, we explored transfer learning to leverage simulated data to improve the generalization of deep learning models on real-world observations. Our benchmark dataset and evaluation framework contribute to the development of more accurate and scalable AI-driven agroecosystem models, advancing our understanding of ecosystem-climate interactions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u9996\u4e2a\u65f6\u7a7a\u519c\u4e1a\u751f\u6001\u7cfb\u7edf\u6e29\u5ba4\u6c14\u4f53\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u7269\u7406\u6a21\u578b\u6a21\u62df\u4e0e\u771f\u5b9e\u89c2\u6d4b\u6570\u636e\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u78b3\u6c2e\u901a\u91cf\u9884\u6d4b\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u63a2\u7d22\u4e86\u8fc1\u79fb\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "motivation": "\u519c\u4e1a\u751f\u6001\u7cfb\u7edf\u5360\u5168\u7403\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u56db\u5206\u4e4b\u4e00\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u571f\u58e4\u91c7\u6837\u3001\u8fc7\u7a0b\u6a21\u578b\u3001\u9ed1\u7bb1\u673a\u5668\u5b66\u4e60\uff09\u9762\u4e34\u6570\u636e\u7a00\u758f\u3001\u65f6\u7a7a\u5f02\u8d28\u6027\u9ad8\u3001\u5730\u4e0b\u8fc7\u7a0b\u590d\u6742\u7b49\u6311\u6218\u3002\u7f3a\u4e4fAI\u5c31\u7eea\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u534f\u8bae\u963b\u788d\u4e86\u53ef\u4fe1\u8d56AI\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "1. \u521b\u5efa\u9996\u4e2a\u65f6\u7a7a\u519c\u4e1a\u751f\u6001\u7cfb\u7edf\u6e29\u5ba4\u6c14\u4f53\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6574\u5408Ecosys\u548cDayCent\u7269\u7406\u6a21\u578b\u6a21\u62df\u6570\u636e\u3001\u6da1\u5ea6\u534f\u65b9\u5dee\u901a\u91cf\u5854\u89c2\u6d4b\u6570\u636e\u3001\u53d7\u63a7\u73af\u5883\u8bbe\u65bd\u6570\u636e\uff1b2. \u8bc4\u4f30\u591a\u79cd\u5e8f\u5217\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08LSTM\u3001\u65f6\u5e8fCNN\u3001Transformer\uff09\u5728\u78b3\u6c2e\u901a\u91cf\u9884\u6d4b\u4e0a\u7684\u6027\u80fd\uff1b3. \u63a2\u7d22\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u62df\u6570\u636e\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u771f\u5b9e\u89c2\u6d4b\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2a\u7efc\u5408\u7269\u7406\u6a21\u62df\u4e0e\u771f\u5b9e\u89c2\u6d4b\u7684\u519c\u4e1a\u751f\u6001\u7cfb\u7edf\u6e29\u5ba4\u6c14\u4f53\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fc1\u79fb\u5b66\u4e60\u5728\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\u4e3a\u5f00\u53d1\u66f4\u51c6\u786e\u3001\u53ef\u6269\u5c55\u7684AI\u9a71\u52a8\u519c\u4e1a\u751f\u6001\u7cfb\u7edf\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u5bf9\u751f\u6001\u7cfb\u7edf-\u6c14\u5019\u76f8\u4e92\u4f5c\u7528\u7684\u7406\u89e3\uff0c\u652f\u6301\u6e29\u5ba4\u6c14\u4f53\u51cf\u6392\u7b56\u7565\u7684\u5236\u5b9a\u3002"}}
{"id": "2602.01619", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01619", "abs": "https://arxiv.org/abs/2602.01619", "authors": ["Seyed Mohammad Hadi Hosseini", "Mahdieh Soleymani Baghshah"], "title": "SUSD: Structured Unsupervised Skill Discovery through State Factorization", "comment": "Accepted as a conference paper at ICLR 2026", "summary": "Unsupervised Skill Discovery (USD) aims to autonomously learn a diverse set of skills without relying on extrinsic rewards. One of the most common USD approaches is to maximize the Mutual Information (MI) between skill latent variables and states. However, MI-based methods tend to favor simple, static skills due to their invariance properties, limiting the discovery of dynamic, task-relevant behaviors. Distance-Maximizing Skill Discovery (DSD) promotes more dynamic skills by leveraging state-space distances, yet still fall short in encouraging comprehensive skill sets that engage all controllable factors or entities in the environment. In this work, we introduce SUSD, a novel framework that harnesses the compositional structure of environments by factorizing the state space into independent components (e.g., objects or controllable entities). SUSD allocates distinct skill variables to different factors, enabling more fine-grained control on the skill discovery process. A dynamic model also tracks learning across factors, adaptively steering the agent's focus toward underexplored factors. This structured approach not only promotes the discovery of richer and more diverse skills, but also yields a factorized skill representation that enables fine-grained and disentangled control over individual entities which facilitates efficient training of compositional downstream tasks via Hierarchical Reinforcement Learning (HRL). Our experimental results across three environments, with factors ranging from 1 to 10, demonstrate that our method can discover diverse and complex skills without supervision, significantly outperforming existing unsupervised skill discovery methods in factorized and complex environments. Code is publicly available at: https://github.com/hadi-hosseini/SUSD.", "AI": {"tldr": "SUSD\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u73af\u5883\u56e0\u5b50\u5206\u89e3\u7684\u65e0\u76d1\u7763\u6280\u80fd\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u72b6\u6001\u7a7a\u95f4\u5206\u89e3\u4e3a\u72ec\u7acb\u7ec4\u4ef6\u5e76\u4e3a\u4e0d\u540c\u56e0\u5b50\u5206\u914d\u6280\u80fd\u53d8\u91cf\uff0c\u5b9e\u73b0\u4e86\u66f4\u7ec6\u7c92\u5ea6\u7684\u6280\u80fd\u53d1\u73b0\u548c\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u6280\u80fd\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u65b9\u6cd5\u503e\u5411\u4e8e\u53d1\u73b0\u7b80\u5355\u9759\u6001\u6280\u80fd\uff0c\u800c\u57fa\u4e8e\u8ddd\u79bb\u6700\u5927\u5316\u7684\u65b9\u6cd5\u867d\u7136\u80fd\u4fc3\u8fdb\u52a8\u6001\u6280\u80fd\uff0c\u4f46\u4ecd\u65e0\u6cd5\u5145\u5206\u63a2\u7d22\u6240\u6709\u53ef\u63a7\u56e0\u5b50\u6216\u5b9e\u4f53\u3002", "method": "SUSD\u5c06\u72b6\u6001\u7a7a\u95f4\u5206\u89e3\u4e3a\u72ec\u7acb\u56e0\u5b50\uff08\u5982\u5bf9\u8c61\u6216\u53ef\u63a7\u5b9e\u4f53\uff09\uff0c\u4e3a\u4e0d\u540c\u56e0\u5b50\u5206\u914d\u72ec\u7acb\u7684\u6280\u80fd\u53d8\u91cf\uff0c\u5e76\u4f7f\u7528\u52a8\u6001\u6a21\u578b\u8ddf\u8e2a\u5404\u56e0\u5b50\u7684\u5b66\u4e60\u8fdb\u5ea6\uff0c\u81ea\u9002\u5e94\u5730\u5c06\u667a\u80fd\u4f53\u6ce8\u610f\u529b\u8f6c\u5411\u672a\u5145\u5206\u63a2\u7d22\u7684\u56e0\u5b50\u3002", "result": "\u57281\u523010\u4e2a\u56e0\u5b50\u7684\u4e09\u4e2a\u73af\u5883\u4e2d\uff0cSUSD\u80fd\u591f\u53d1\u73b0\u591a\u6837\u4e14\u590d\u6742\u7684\u6280\u80fd\uff0c\u5728\u56e0\u5b50\u5316\u590d\u6742\u73af\u5883\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763\u6280\u80fd\u53d1\u73b0\u65b9\u6cd5\uff0c\u5e76\u4ea7\u751f\u56e0\u5b50\u5316\u7684\u6280\u80fd\u8868\u793a\u3002", "conclusion": "SUSD\u901a\u8fc7\u5229\u7528\u73af\u5883\u7ec4\u5408\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u66f4\u4e30\u5bcc\u591a\u6837\u7684\u6280\u80fd\u53d1\u73b0\uff0c\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u89e3\u8026\u7684\u5b9e\u4f53\u63a7\u5236\uff0c\u4e3a\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7ec4\u5408\u4e0b\u6e38\u4efb\u52a1\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u57fa\u7840\u3002"}}
{"id": "2602.01626", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01626", "abs": "https://arxiv.org/abs/2602.01626", "authors": ["Mehdi Setayesh", "Mahdi Beitollahi", "Yasser H. Khalil", "Hongliang Li"], "title": "Toward Enhancing Representation Learning in Federated Multi-Task Settings", "comment": "This paper has been accepted at ICLR 2026", "summary": "Federated multi-task learning (FMTL) seeks to collaboratively train customized models for users with different tasks while preserving data privacy. Most existing approaches assume model congruity (i.e., the use of fully or partially homogeneous models) across users, which limits their applicability in realistic settings. To overcome this limitation, we aim to learn a shared representation space across tasks rather than shared model parameters. To this end, we propose Muscle loss, a novel contrastive learning objective that simultaneously aligns representations from all participating models. Unlike existing multi-view or multi-model contrastive methods, which typically align models pairwise, Muscle loss can effectively capture dependencies across tasks because its minimization is equivalent to the maximization of mutual information among all the models' representations. Building on this principle, we develop FedMuscle, a practical and communication-efficient FMTL algorithm that naturally handles both model and task heterogeneity. Experiments on diverse image and language tasks demonstrate that FedMuscle consistently outperforms state-of-the-art baselines, delivering substantial improvements and robust performance across heterogeneous settings.", "AI": {"tldr": "FedMuscle\uff1a\u4e00\u79cd\u57fa\u4e8eMuscle\u635f\u5931\u51fd\u6570\u7684\u8054\u90a6\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u5f02\u6784\u6a21\u578b\u8868\u793a\uff0c\u89e3\u51b3\u6a21\u578b\u548c\u4efb\u52a1\u5f02\u8d28\u6027\u95ee\u9898", "motivation": "\u73b0\u6709\u8054\u90a6\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u5047\u8bbe\u6a21\u578b\u540c\u8d28\u6027\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u5f02\u6784\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u6a21\u578b\u548c\u4efb\u52a1\u5f02\u8d28\u6027\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u9690\u79c1\u3002", "method": "\u63d0\u51faMuscle\u635f\u5931\u51fd\u6570\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff0c\u540c\u65f6\u5bf9\u9f50\u6240\u6709\u53c2\u4e0e\u6a21\u578b\u7684\u8868\u793a\u3002\u57fa\u4e8e\u6b64\u5f00\u53d1FedMuscle\u7b97\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6a21\u578b\u8868\u793a\u95f4\u7684\u4e92\u4fe1\u606f\u6765\u6355\u83b7\u4efb\u52a1\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u591a\u79cd\u56fe\u50cf\u548c\u8bed\u8a00\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedMuscle\u5728\u5f02\u6784\u8bbe\u7f6e\u4e0b\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u4f9b\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u9c81\u68d2\u8868\u73b0\u3002", "conclusion": "FedMuscle\u901a\u8fc7\u5171\u4eab\u8868\u793a\u7a7a\u95f4\u800c\u975e\u6a21\u578b\u53c2\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u6a21\u578b\u548c\u4efb\u52a1\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.01629", "categories": ["cs.LG", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01629", "abs": "https://arxiv.org/abs/2602.01629", "authors": ["Renukanandan Tumu", "Aditya Singh", "Rahul Mangharam"], "title": "AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments", "comment": null, "summary": "Rigorous uncertainty quantification is essential for the safe deployment of autonomous systems in unconstrained environments. Conformal Prediction (CP) provides a distribution-free framework for this task, yet its standard formulations rely on exchangeability assumptions that are violated by the distribution shifts inherent in real-world robotics. Existing online CP methods maintain target coverage by adaptively scaling the conformal threshold, but typically employ a static nonconformity score function. We show that this fixed geometry leads to highly conservative, volume-inefficient prediction regions when environments undergo structural shifts. To address this, we propose \\textbf{AdaptNC}, a framework for the joint online adaptation of both the nonconformity score parameters and the conformal threshold. AdaptNC leverages an adaptive reweighting scheme to optimize score functions, and introduces a replay buffer mechanism to mitigate the coverage instability that occurs during score transitions. We evaluate AdaptNC on diverse robotic benchmarks involving multi-agent policy changes, environmental changes and sensor degradation. Our results demonstrate that AdaptNC significantly reduces prediction region volume compared to state-of-the-art threshold-only baselines while maintaining target coverage levels.", "AI": {"tldr": "AdaptNC\uff1a\u8054\u5408\u5728\u7ebf\u9002\u5e94\u975e\u5171\u5f62\u5206\u6570\u53c2\u6570\u548c\u5171\u5f62\u9608\u503c\u7684\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u76ee\u6807\u8986\u76d6\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u9884\u6d4b\u533a\u57df\u4f53\u79ef", "motivation": "\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u5b58\u5728\u5206\u5e03\u504f\u79fb\uff0c\u8fdd\u53cd\u4f20\u7edf\u5171\u5f62\u9884\u6d4b\u7684\u4ea4\u6362\u6027\u5047\u8bbe\u3002\u73b0\u6709\u5728\u7ebfCP\u65b9\u6cd5\u4ec5\u81ea\u9002\u5e94\u8c03\u6574\u9608\u503c\uff0c\u4f46\u4f7f\u7528\u9759\u6001\u7684\u975e\u5171\u5f62\u5206\u6570\u51fd\u6570\uff0c\u5bfc\u81f4\u5728\u73af\u5883\u7ed3\u6784\u53d8\u5316\u65f6\u9884\u6d4b\u533a\u57df\u8fc7\u4e8e\u4fdd\u5b88\u4e14\u4f53\u79ef\u4f4e\u6548\u3002", "method": "\u63d0\u51faAdaptNC\u6846\u67b6\uff0c\u8054\u5408\u5728\u7ebf\u9002\u5e94\u975e\u5171\u5f62\u5206\u6570\u53c2\u6570\u548c\u5171\u5f62\u9608\u503c\u3002\u91c7\u7528\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u65b9\u6848\u4f18\u5316\u5206\u6570\u51fd\u6570\uff0c\u5e76\u5f15\u5165\u56de\u653e\u7f13\u51b2\u533a\u673a\u5236\u7f13\u89e3\u5206\u6570\u8f6c\u6362\u671f\u95f4\u7684\u8986\u76d6\u7387\u4e0d\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u591a\u667a\u80fd\u4f53\u7b56\u7565\u53d8\u5316\u3001\u73af\u5883\u53d8\u5316\u548c\u4f20\u611f\u5668\u9000\u5316\u7b49\u591a\u6837\u5316\u673a\u5668\u4eba\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAdaptNC\u76f8\u6bd4\u4ec5\u8c03\u6574\u9608\u503c\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u76ee\u6807\u8986\u76d6\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u9884\u6d4b\u533a\u57df\u4f53\u79ef\u3002", "conclusion": "AdaptNC\u901a\u8fc7\u8054\u5408\u9002\u5e94\u975e\u5171\u5f62\u5206\u6570\u548c\u9608\u503c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5728\u7ebfCP\u65b9\u6cd5\u5728\u73af\u5883\u7ed3\u6784\u53d8\u5316\u4e0b\u7684\u4fdd\u5b88\u6027\u95ee\u9898\uff0c\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u5728\u975e\u7ea6\u675f\u73af\u5883\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u4e25\u683c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2602.01635", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01635", "abs": "https://arxiv.org/abs/2602.01635", "authors": ["Jinwoo Park", "Hyeongwon Kang", "Seung Hun Han", "Pilsung Kang"], "title": "COMET: Codebook-based Online-adaptive Multi-scale Embedding for Time-series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection is a critical task across various industrial domains. However, capturing temporal dependencies and multivariate correlations within patch-level representation learning remains underexplored, and reliance on single-scale patterns limits the detection of anomalies across different temporal ranges. Furthermore, focusing on normal data representations makes models vulnerable to distribution shifts at inference time. To address these limitations, we propose Codebook-based Online-adaptive Multi-scale Embedding for Time-series anomaly detection (COMET), which consists of three key components: (1) Multi-scale Patch Encoding captures temporal dependencies and inter-variable correlations across multiple patch scales. (2) Vector-Quantized Coreset learns representative normal patterns via codebook and detects anomalies with a dual-score combining quantization error and memory distance. (3) Online Codebook Adaptation generates pseudo-labels based on codebook entries and dynamically adapts the model at inference through contrastive learning. Experiments on five benchmark datasets demonstrate that COMET achieves the best performance in 36 out of 45 evaluation metrics, validating its effectiveness across diverse environments.", "AI": {"tldr": "COMET\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7801\u672c\u7684\u5728\u7ebf\u81ea\u9002\u5e94\u591a\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u8865\u4e01\u7f16\u7801\u3001\u5411\u91cf\u91cf\u5316\u6838\u5fc3\u96c6\u548c\u5728\u7ebf\u7801\u672c\u9002\u5e94\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u5728\u8865\u4e01\u7ea7\u8868\u793a\u5b66\u4e60\u4e2d\u672a\u80fd\u5145\u5206\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u591a\u53d8\u91cf\u76f8\u5173\u6027\uff1b2\uff09\u4f9d\u8d56\u5355\u5c3a\u5ea6\u6a21\u5f0f\u9650\u5236\u4e86\u4e0d\u540c\u65f6\u95f4\u8303\u56f4\u5f02\u5e38\u7684\u68c0\u6d4b\uff1b3\uff09\u4e13\u6ce8\u4e8e\u6b63\u5e38\u6570\u636e\u8868\u793a\u4f7f\u6a21\u578b\u5728\u63a8\u7406\u65f6\u5bb9\u6613\u53d7\u5230\u5206\u5e03\u504f\u79fb\u7684\u5f71\u54cd\u3002", "method": "COMET\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1\uff09\u591a\u5c3a\u5ea6\u8865\u4e01\u7f16\u7801\uff1a\u6355\u6349\u591a\u4e2a\u8865\u4e01\u5c3a\u5ea6\u4e0a\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u53d8\u91cf\u95f4\u76f8\u5173\u6027\uff1b2\uff09\u5411\u91cf\u91cf\u5316\u6838\u5fc3\u96c6\uff1a\u901a\u8fc7\u7801\u672c\u5b66\u4e60\u4ee3\u8868\u6027\u6b63\u5e38\u6a21\u5f0f\uff0c\u5e76\u4f7f\u7528\u91cf\u5316\u8bef\u5dee\u548c\u8bb0\u5fc6\u8ddd\u79bb\u7684\u53cc\u91cd\u8bc4\u5206\u68c0\u6d4b\u5f02\u5e38\uff1b3\uff09\u5728\u7ebf\u7801\u672c\u9002\u5e94\uff1a\u57fa\u4e8e\u7801\u672c\u6761\u76ee\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5728\u63a8\u7406\u65f6\u52a8\u6001\u9002\u5e94\u6a21\u578b\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCOMET\u572845\u4e2a\u8bc4\u4f30\u6307\u6807\u4e2d\u768436\u4e2a\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u6837\u5316\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "COMET\u901a\u8fc7\u7ed3\u5408\u591a\u5c3a\u5ea6\u8868\u793a\u5b66\u4e60\u3001\u7801\u672c\u5b66\u4e60\u548c\u5728\u7ebf\u81ea\u9002\u5e94\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.01637", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01637", "abs": "https://arxiv.org/abs/2602.01637", "authors": ["Sreenivasan Mohandas"], "title": "Chance-Constrained Inference for Hallucination Risk Control in Large Language Models", "comment": null, "summary": "Large language models generate outputs stochastically and may produce fluent but invalid responses, including factual hallucinations. Existing mitigation strategies reduce average error rates but do not provide explicit control over the \\emph{frequency} of such failures under repeated use. We formulate inference as a deployment-time risk control problem and introduce \\emph{chance-constrained inference}, which directly bounds the probability of hallucinations among accepted generations. Hallucinations are modeled as stochastic constraint violations, and we show that confidence-based selective prediction does not, in general, imply probabilistic risk guarantees. To enforce chance constraints efficiently, we propose a sequential, anytime-valid inference procedure that adaptively certifies feasibility or infeasibility using finite samples, avoiding conservative fixed-sample bounds. Experiments on questions inspired by NaturalQuestions and controlled multi-hop question answering demonstrate reliable risk control, early detection of intrinsically infeasible inputs, and safe composition under repeated use, while confidence-based baselines fail to provide consistent guarantees.", "AI": {"tldr": "\u63d0\u51fa\u673a\u4f1a\u7ea6\u675f\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u987a\u5e8f\u9a8c\u8bc1\u65b9\u6cd5\u63a7\u5236\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u98ce\u9669\u6982\u7387\uff0c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u98ce\u9669\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u964d\u4f4e\u5e73\u5747\u9519\u8bef\u7387\uff0c\u4f46\u65e0\u6cd5\u5728\u91cd\u590d\u4f7f\u7528\u4e2d\u660e\u786e\u63a7\u5236\u5e7b\u89c9\u53d1\u751f\u7684\u9891\u7387\u3002\u9700\u8981\u4e00\u79cd\u80fd\u63d0\u4f9b\u6982\u7387\u98ce\u9669\u4fdd\u8bc1\u7684\u63a8\u7406\u6846\u67b6\u3002", "method": "\u5c06\u63a8\u7406\u5efa\u6a21\u4e3a\u90e8\u7f72\u65f6\u7684\u98ce\u9669\u63a7\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u673a\u4f1a\u7ea6\u675f\u63a8\u7406\u6846\u67b6\u3002\u4f7f\u7528\u987a\u5e8f\u3001\u968f\u65f6\u6709\u6548\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6709\u9650\u6837\u672c\u81ea\u9002\u5e94\u5730\u9a8c\u8bc1\u53ef\u884c\u6027\u6216\u4e0d\u53ef\u884c\u6027\uff0c\u907f\u514d\u4fdd\u5b88\u7684\u56fa\u5b9a\u6837\u672c\u754c\u9650\u3002", "result": "\u5728NaturalQuestions\u98ce\u683c\u95ee\u9898\u548c\u53d7\u63a7\u591a\u8df3\u95ee\u7b54\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u53ef\u9760\u63a7\u5236\u98ce\u9669\uff0c\u65e9\u671f\u68c0\u6d4b\u5185\u5728\u4e0d\u53ef\u884c\u8f93\u5165\uff0c\u5e76\u5728\u91cd\u590d\u4f7f\u7528\u4e0b\u5b89\u5168\u7ec4\u5408\uff0c\u800c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u57fa\u7ebf\u65b9\u6cd5\u65e0\u6cd5\u63d0\u4f9b\u4e00\u81f4\u4fdd\u8bc1\u3002", "conclusion": "\u673a\u4f1a\u7ea6\u675f\u63a8\u7406\u4e3a\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u8bc1\u660e\u7684\u98ce\u9669\u63a7\u5236\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u660e\u786e\u6982\u7387\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5e7b\u89c9\u9891\u7387\u7684\u76f4\u63a5\u7ea6\u675f\u3002"}}
{"id": "2602.01642", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01642", "abs": "https://arxiv.org/abs/2602.01642", "authors": ["Matias D. Cattaneo", "Boris Shigida"], "title": "The Effect of Mini-Batch Noise on the Implicit Bias of Adam", "comment": null, "summary": "With limited high-quality data and growing compute, multi-epoch training is gaining back its importance across sub-areas of deep learning. Adam(W), versions of which are go-to optimizers for many tasks such as next token prediction, has two momentum hyperparameters $(\u03b2_1, \u03b2_2)$ controlling memory and one very important hyperparameter, batch size, controlling (in particular) the amount mini-batch noise. We introduce a theoretical framework to understand how mini-batch noise influences the implicit bias of memory in Adam (depending on $\u03b2_1$, $\u03b2_2$) towards sharper or flatter regions of the loss landscape, which is commonly observed to correlate with the generalization gap in multi-epoch training. We find that in the case of large batch sizes, higher $\u03b2_2$ increases the magnitude of anti-regularization by memory (hurting generalization), but as the batch size becomes smaller, the dependence of (anti-)regulariation on $\u03b2_2$ is reversed. A similar monotonicity shift (in the opposite direction) happens in $\u03b2_1$. In particular, the commonly \"default\" pair $(\u03b2_1, \u03b2_2) = (0.9, 0.999)$ is a good choice if batches are small; for larger batches, in many settings moving $\u03b2_1$ closer to $\u03b2_2$ is much better in terms of validation accuracy in multi-epoch training. Moreover, our theoretical derivations connect the scale of the batch size at which the shift happens to the scale of the critical batch size. We illustrate this effect in experiments with small-scale data in the about-to-overfit regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86Adam\u4f18\u5316\u5668\u4e2d\u52a8\u91cf\u8d85\u53c2\u6570(\u03b2\u2081, \u03b2\u2082)\u548c\u6279\u6b21\u5927\u5c0f\u5982\u4f55\u901a\u8fc7\u5c0f\u6279\u6b21\u566a\u58f0\u5f71\u54cd\u591a\u8f6e\u8bad\u7ec3\u4e2d\u7684\u9690\u5f0f\u504f\u5dee\uff0c\u53d1\u73b0\u6279\u6b21\u5927\u5c0f\u4f1a\u6539\u53d8\u03b2\u2081\u548c\u03b2\u2082\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u9ad8\u8d28\u91cf\u6570\u636e\u6709\u9650\u800c\u8ba1\u7b97\u8d44\u6e90\u589e\u957f\uff0c\u591a\u8f6e\u8bad\u7ec3\u5728\u6df1\u5ea6\u5b66\u4e60\u5404\u9886\u57df\u91cd\u65b0\u53d8\u5f97\u91cd\u8981\u3002Adam\u4f18\u5316\u5668\u4f5c\u4e3a\u8bb8\u591a\u4efb\u52a1\uff08\u5982\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\uff09\u7684\u9996\u9009\u4f18\u5316\u5668\uff0c\u5176\u52a8\u91cf\u8d85\u53c2\u6570(\u03b2\u2081, \u03b2\u2082)\u548c\u6279\u6b21\u5927\u5c0f\u5bf9\u6cdb\u5316\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u6846\u67b6\u7406\u89e3\u5c0f\u6279\u6b21\u566a\u58f0\u5982\u4f55\u901a\u8fc7Adam\u7684\u5185\u5b58\u673a\u5236\u5f71\u54cd\u635f\u5931\u666f\u89c2\u7684\u9510\u5ea6\u504f\u597d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u5c0f\u6279\u6b21\u566a\u58f0\u5982\u4f55\u5f71\u54cdAdam\u4e2d\u5185\u5b58\u7684\u9690\u5f0f\u504f\u5dee\uff0c\u7814\u7a76\u03b2\u2081\u3001\u03b2\u2082\u548c\u6279\u6b21\u5927\u5c0f\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u7406\u8bba\u63a8\u5bfc\u8fde\u63a5\u4e86\u6279\u6b21\u5927\u5c0f\u5c3a\u5ea6\u53d8\u5316\u4e0e\u4e34\u754c\u6279\u6b21\u5927\u5c0f\u5c3a\u5ea6\uff0c\u5e76\u5728\u63a5\u8fd1\u8fc7\u62df\u5408\u7684\u5c0f\u89c4\u6a21\u6570\u636e\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "result": "\u53d1\u73b0\u6279\u6b21\u5927\u5c0f\u4f1a\u6539\u53d8\u03b2\u2081\u548c\u03b2\u2082\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\u65b9\u5411\uff1a\u5728\u5927\u6279\u6b21\u65f6\uff0c\u8f83\u9ad8\u7684\u03b2\u2082\u4f1a\u589e\u52a0\u5185\u5b58\u7684\u53cd\u6b63\u5219\u5316\u7a0b\u5ea6\uff08\u635f\u5bb3\u6cdb\u5316\uff09\uff1b\u4f46\u5728\u5c0f\u6279\u6b21\u65f6\uff0c\u8fd9\u79cd\u4f9d\u8d56\u5173\u7cfb\u4f1a\u53cd\u8f6c\u3002\u03b2\u2081\u4e5f\u8868\u73b0\u51fa\u7c7b\u4f3c\u4f46\u65b9\u5411\u76f8\u53cd\u7684\u5355\u8c03\u6027\u53d8\u5316\u3002\u5e38\u7528\u7684\u9ed8\u8ba4\u53c2\u6570(0.9, 0.999)\u4ec5\u9002\u7528\u4e8e\u5c0f\u6279\u6b21\uff1b\u5bf9\u4e8e\u5927\u6279\u6b21\uff0c\u5c06\u03b2\u2081\u8c03\u6574\u5230\u63a5\u8fd1\u03b2\u2082\u7684\u503c\u5728\u591a\u8f6e\u8bad\u7ec3\u4e2d\u80fd\u83b7\u5f97\u66f4\u597d\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\u3002", "conclusion": "Adam\u4f18\u5316\u5668\u7684\u52a8\u91cf\u8d85\u53c2\u6570\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u6279\u6b21\u5927\u5c0f\uff0c\u6279\u6b21\u5927\u5c0f\u4f1a\u6539\u53d8\u03b2\u2081\u548c\u03b2\u2082\u5bf9\u9690\u5f0f\u504f\u5dee\u7684\u5f71\u54cd\u65b9\u5411\u3002\u7406\u8bba\u6846\u67b6\u63ed\u793a\u4e86\u5c0f\u6279\u6b21\u566a\u58f0\u3001\u5185\u5b58\u673a\u5236\u548c\u635f\u5931\u666f\u89c2\u9510\u5ea6\u504f\u597d\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u4e3a\u591a\u8f6e\u8bad\u7ec3\u4e2dAdam\u8d85\u53c2\u6570\u8c03\u4f18\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2602.01643", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01643", "abs": "https://arxiv.org/abs/2602.01643", "authors": ["Xichen Sun", "Wentao Wei", "Jiahua Rao", "Jiancong Xie", "Yuedong Yang"], "title": "De Novo Molecular Generation from Mass Spectra via Many-Body Enhanced Diffusion", "comment": null, "summary": "Molecular structure generation from mass spectrometry is fundamental for understanding cellular metabolism and discovering novel compounds. Although tandem mass spectrometry (MS/MS) enables the high-throughput acquisition of fragment fingerprints, these spectra often reflect higher-order interactions involving the concerted cleavage of multiple atoms and bonds-crucial for resolving complex isomers and non-local fragmentation mechanisms. However, most existing methods adopt atom-centric and pairwise interaction modeling, overlooking higher-order edge interactions and lacking the capacity to systematically capture essential many-body characteristics for structure generation. To overcome these limitations, we present MBGen, a Many-Body enhanced diffusion framework for de novo molecular structure Generation from mass spectra. By integrating a many-body attention mechanism and higher-order edge modeling, MBGen comprehensively leverages the rich structural information encoded in MS/MS spectra, enabling accurate de novo generation and isomer differentiation for novel molecules. Experimental results on the NPLIB1 and MassSpecGym benchmarks demonstrate that MBGen achieves superior performance, with improvements of up to 230% over state-of-the-art methods, highlighting the scientific value and practical utility of many-body modeling for mass spectrometry-based molecular generation. Further analysis and ablation studies show that our approach effectively captures higher-order interactions and exhibits enhanced sensitivity to complex isomeric and non-local fragmentation information.", "AI": {"tldr": "MBGen\uff1a\u57fa\u4e8e\u591a\u4f53\u589e\u5f3a\u6269\u6563\u6846\u67b6\u7684\u8d28\u8c31\u4ece\u5934\u5206\u5b50\u7ed3\u6784\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u4f53\u6ce8\u610f\u529b\u673a\u5236\u548c\u9ad8\u9636\u8fb9\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u5206\u5b50\u751f\u6210\u548c\u5f02\u6784\u4f53\u533a\u5206\u6027\u80fd", "motivation": "\u73b0\u6709\u8d28\u8c31\u5206\u5b50\u7ed3\u6784\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\u539f\u5b50\u4e2d\u5fc3\u548c\u6210\u5bf9\u76f8\u4e92\u4f5c\u7528\u5efa\u6a21\uff0c\u5ffd\u7565\u4e86\u9ad8\u9636\u8fb9\u76f8\u4e92\u4f5c\u7528\uff0c\u65e0\u6cd5\u7cfb\u7edf\u6355\u6349\u591a\u4f53\u7279\u5f81\uff0c\u9650\u5236\u4e86\u590d\u6742\u5f02\u6784\u4f53\u548c\u975e\u5c40\u90e8\u65ad\u88c2\u673a\u5236\u7684\u89e3\u6790\u80fd\u529b", "method": "\u63d0\u51faMBGen\u591a\u4f53\u589e\u5f3a\u6269\u6563\u6846\u67b6\uff0c\u6574\u5408\u591a\u4f53\u6ce8\u610f\u529b\u673a\u5236\u548c\u9ad8\u9636\u8fb9\u5efa\u6a21\uff0c\u5145\u5206\u5229\u7528MS/MS\u8c31\u56fe\u4e2d\u7f16\u7801\u7684\u4e30\u5bcc\u7ed3\u6784\u4fe1\u606f", "result": "\u5728NPLIB1\u548cMassSpecGym\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMBGen\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u5e45\u5ea6\u9ad8\u8fbe230%\uff0c\u80fd\u6709\u6548\u6355\u6349\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u5e76\u5bf9\u590d\u6742\u5f02\u6784\u4f53\u548c\u975e\u5c40\u90e8\u65ad\u88c2\u4fe1\u606f\u8868\u73b0\u51fa\u589e\u5f3a\u654f\u611f\u6027", "conclusion": "\u591a\u4f53\u5efa\u6a21\u5728\u8d28\u8c31\u5206\u5b50\u7ed3\u6784\u751f\u6210\u4e2d\u5177\u6709\u91cd\u8981\u79d1\u5b66\u4ef7\u503c\u548c\u5b9e\u9645\u6548\u7528\uff0cMBGen\u6846\u67b6\u4e3a\u4ece\u5934\u5206\u5b50\u751f\u6210\u548c\u5f02\u6784\u4f53\u533a\u5206\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01644", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01644", "abs": "https://arxiv.org/abs/2602.01644", "authors": ["Gloria Felicia", "Nolan Bryant", "Handi Putra", "Ayaan Gazali", "Eliel Lobo", "Esteban Rojas"], "title": "From Perception to Action: Spatial AI Agents and World Models", "comment": "61 pages, 742 citations, 1 figure, 3 tables. Survey paper on spatial AI agents, embodied AI, graph neural networks, and world models", "summary": "While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7edf\u4e00\u7684\u4e09\u8f74\u5206\u7c7b\u6cd5\uff0c\u8fde\u63a5\u667a\u80fd\u4f53\u80fd\u529b\u4e0e\u7a7a\u95f4\u4efb\u52a1\uff0c\u5f3a\u8c03\u7a7a\u95f4\u667a\u80fd\u5bf9\u5177\u8eab\u667a\u80fd\u4f53\u7684\u91cd\u8981\u6027\uff0c\u5e76\u8bc6\u522b\u51fa\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\u548c\u516d\u5927\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8981\u4e48\u5173\u6ce8\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u8981\u4e48\u5173\u6ce8\u7a7a\u95f4\u9886\u57df\uff0c\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u8fde\u63a5\u8fd9\u4e24\u79cd\u4e92\u8865\u80fd\u529b\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7b26\u53f7\u9886\u57df\u7684\u6210\u529f\u96be\u4ee5\u76f4\u63a5\u8fc1\u79fb\u5230\u7269\u7406\u4e16\u754c\uff0c\u7a7a\u95f4\u667a\u80fd\uff08\u611f\u77e53D\u7ed3\u6784\u3001\u63a8\u7406\u7269\u4f53\u5173\u7cfb\u3001\u5728\u7269\u7406\u7ea6\u675f\u4e0b\u884c\u52a8\uff09\u5bf9\u5177\u8eab\u667a\u80fd\u4f53\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff02000\u591a\u7bc7\u8bba\u6587\uff08\u5f15\u7528742\u7bc7\u9876\u7ea7\u4f1a\u8bae\u8bba\u6587\uff09\uff0c\u63d0\u51fa\u7edf\u4e00\u7684\u4e09\u8f74\u5206\u7c7b\u6cd5\uff1a\u80fd\u529b\u8f74\u3001\u4efb\u52a1\u8f74\u548c\u5c3a\u5ea6\u8f74\u3002\u533a\u5206\u7a7a\u95f4\u57fa\u7840\uff08\u51e0\u4f55\u548c\u7269\u7406\u7684\u5ea6\u91cf\u7406\u89e3\uff09\u4e0e\u7b26\u53f7\u57fa\u7840\uff08\u56fe\u50cf\u4e0e\u6587\u672c\u5173\u8054\uff09\uff0c\u5f3a\u8c03\u611f\u77e5\u672c\u8eab\u4e0d\u8d4b\u4e88\u667a\u80fd\u4f53\u80fd\u529b\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\uff1a1\uff09\u5206\u5c42\u8bb0\u5fc6\u7cfb\u7edf\u5bf9\u957f\u65f6\u7a0b\u7a7a\u95f4\u4efb\u52a1\u5f88\u91cd\u8981\uff1b2\uff09GNN-LLM\u96c6\u6210\u662f\u7ed3\u6784\u5316\u7a7a\u95f4\u63a8\u7406\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff1b3\uff09\u4e16\u754c\u6a21\u578b\u5bf9\u8de8\u5fae\u89c2\u5230\u5b8f\u89c2\u7a7a\u95f4\u5c3a\u5ea6\u7684\u5b89\u5168\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u63d0\u51fa\u4e86\u516d\u5927\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u9700\u8981\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u6765\u6807\u51c6\u5316\u8de8\u9886\u57df\u8bc4\u4f30\u3002\u8be5\u5206\u7c7b\u6cd5\u4e3a\u7edf\u4e00\u788e\u7247\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u673a\u5668\u4eba\u3001\u81ea\u52a8\u9a7e\u9a76\u548c\u5730\u7406\u7a7a\u95f4\u667a\u80fd\u7b49\u9886\u57df\u4e0b\u4e00\u4ee3\u7a7a\u95f4\u611f\u77e5\u81ea\u4e3b\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.01651", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01651", "abs": "https://arxiv.org/abs/2602.01651", "authors": ["Zichao Wei"], "title": "On the Spatiotemporal Dynamics of Generalization in Neural Networks", "comment": null, "summary": "Why do neural networks fail to generalize addition from 16-digit to 32-digit numbers, while a child who learns the rule can apply it to arbitrarily long sequences? We argue that this failure is not an engineering problem but a violation of physical postulates. Drawing inspiration from physics, we identify three constraints that any generalizing system must satisfy: (1) Locality -- information propagates at finite speed; (2) Symmetry -- the laws of computation are invariant across space and time; (3) Stability -- the system converges to discrete attractors that resist noise accumulation. From these postulates, we derive -- rather than design -- the Spatiotemporal Evolution with Attractor Dynamics (SEAD) architecture: a neural cellular automaton where local convolutional rules are iterated until convergence. Experiments on three tasks validate our theory: (1) Parity -- demonstrating perfect length generalization via light-cone propagation; (2) Addition -- achieving scale-invariant inference from L=16 to L=1 million with 100% accuracy, exhibiting input-adaptive computation; (3) Rule 110 -- learning a Turing-complete cellular automaton without trajectory divergence. Our results suggest that the gap between statistical learning and logical reasoning can be bridged -- not by scaling parameters, but by respecting the physics of computation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSEAD\u67b6\u6784\uff0c\u4ece\u7269\u7406\u539f\u7406\u63a8\u5bfc\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u89e3\u51b3\u6570\u5b57\u52a0\u6cd5\u7b49\u4efb\u52a1\u7684\u957f\u5ea6\u6cdb\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u4ece16\u4f4d\u5230100\u4e07\u4f4d\u7684\u5b8c\u7f8e\u6cdb\u5316\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u50cf\u4eba\u7c7b\u4e00\u6837\u5c06\u52a0\u6cd5\u89c4\u5219\u4ece16\u4f4d\u6570\u6cdb\u5316\u523032\u4f4d\u6570\uff0c\u8fd9\u4e0d\u4ec5\u662f\u5de5\u7a0b\u95ee\u9898\uff0c\u800c\u662f\u8fdd\u53cd\u4e86\u7269\u7406\u57fa\u672c\u539f\u7406\u3002\u8bba\u6587\u65e8\u5728\u4ece\u7269\u7406\u7ea6\u675f\u51fa\u53d1\uff0c\u6784\u5efa\u80fd\u591f\u771f\u6b63\u6cdb\u5316\u7684\u8ba1\u7b97\u7cfb\u7edf\u3002", "method": "\u4ece\u4e09\u4e2a\u7269\u7406\u7ea6\u675f\uff08\u5c40\u90e8\u6027\u3001\u5bf9\u79f0\u6027\u3001\u7a33\u5b9a\u6027\uff09\u63a8\u5bfc\u51faSEAD\u67b6\u6784\uff1a\u4e00\u79cd\u795e\u7ecf\u7ec6\u80de\u81ea\u52a8\u673a\uff0c\u901a\u8fc7\u5c40\u90e8\u5377\u79ef\u89c4\u5219\u7684\u8fed\u4ee3\u76f4\u5230\u6536\u655b\u3002\u8be5\u65b9\u6cd5\u4e0d\u662f\u8bbe\u8ba1\u51fa\u6765\u7684\uff0c\u800c\u662f\u4ece\u57fa\u672c\u539f\u7406\u63a8\u5bfc\u51fa\u6765\u7684\u3002", "result": "\u5728\u4e09\u4e2a\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff1a1\uff09\u5947\u5076\u6027\u4efb\u52a1\uff1a\u901a\u8fc7\u5149\u9525\u4f20\u64ad\u5b9e\u73b0\u5b8c\u7f8e\u957f\u5ea6\u6cdb\u5316\uff1b2\uff09\u52a0\u6cd5\u4efb\u52a1\uff1a\u4eceL=16\u5230L=100\u4e07\u5b9e\u73b0100%\u51c6\u786e\u7387\uff0c\u5c55\u793a\u8f93\u5165\u81ea\u9002\u5e94\u8ba1\u7b97\uff1b3\uff09Rule 110\uff1a\u5b66\u4e60\u56fe\u7075\u5b8c\u5907\u7684\u7ec6\u80de\u81ea\u52a8\u673a\u800c\u65e0\u8f68\u8ff9\u53d1\u6563\u3002", "conclusion": "\u7edf\u8ba1\u5b66\u4e60\u4e0e\u903b\u8f91\u63a8\u7406\u4e4b\u95f4\u7684\u9e3f\u6c9f\u53ef\u4ee5\u901a\u8fc7\u5c0a\u91cd\u8ba1\u7b97\u7684\u7269\u7406\u539f\u7406\u6765\u5f25\u5408\uff0c\u800c\u4e0d\u662f\u901a\u8fc7\u6269\u5927\u53c2\u6570\u89c4\u6a21\u3002SEAD\u67b6\u6784\u5c55\u793a\u4e86\u4ece\u7269\u7406\u7ea6\u675f\u63a8\u5bfc\u8ba1\u7b97\u67b6\u6784\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.01658", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01658", "abs": "https://arxiv.org/abs/2602.01658", "authors": ["Seyed Mohammad Hadi Hosseini", "Amir Najafi", "Mahdieh Soleymani Baghshah"], "title": "Efficient Adversarial Attacks on High-dimensional Offline Bandits", "comment": "Accepted at ICLR 2026 Conference", "summary": "Bandit algorithms have recently emerged as a powerful tool for evaluating machine learning models, including generative image models and large language models, by efficiently identifying top-performing candidates without exhaustive comparisons. These methods typically rely on a reward model, often distributed with public weights on platforms such as Hugging Face, to provide feedback to the bandit. While online evaluation is expensive and requires repeated trials, offline evaluation with logged data has become an attractive alternative. However, the adversarial robustness of offline bandit evaluation remains largely unexplored, particularly when an attacker perturbs the reward model (rather than the training data) prior to bandit training. In this work, we fill this gap by investigating, both theoretically and empirically, the vulnerability of offline bandit training to adversarial manipulations of the reward model. We introduce a novel threat model in which an attacker exploits offline data in high-dimensional settings to hijack the bandit's behavior. Starting with linear reward functions and extending to nonlinear models such as ReLU neural networks, we study attacks on two Hugging Face evaluators used for generative model assessment: one measuring aesthetic quality and the other assessing compositional alignment. Our results show that even small, imperceptible perturbations to the reward model's weights can drastically alter the bandit's behavior. From a theoretical perspective, we prove a striking high-dimensional effect: as input dimensionality increases, the perturbation norm required for a successful attack decreases, making modern applications such as image evaluation especially vulnerable. Extensive experiments confirm that naive random perturbations are ineffective, whereas carefully targeted perturbations achieve near-perfect attack success rates ...", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u79bb\u7ebfbandit\u8bad\u7ec3\u5bf9\u5956\u52b1\u6a21\u578b\u5bf9\u6297\u6027\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u5373\u4f7f\u5bf9\u5956\u52b1\u6a21\u578b\u6743\u91cd\u8fdb\u884c\u5fae\u5c0f\u6270\u52a8\u4e5f\u80fd\u663e\u8457\u6539\u53d8bandit\u884c\u4e3a\uff0c\u9ad8\u7ef4\u5e94\u7528\u4e2d\u653b\u51fb\u5c24\u5176\u5bb9\u6613\u6210\u529f\u3002", "motivation": "\u79bb\u7ebfbandit\u8bc4\u4f30\u5df2\u6210\u4e3a\u8bc4\u4f30\u751f\u6210\u6a21\u578b\u7684\u91cd\u8981\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u672a\u5145\u5206\u63a2\u8ba8\u5956\u52b1\u6a21\u578b\u88ab\u5bf9\u6297\u6027\u653b\u51fb\u65f6\u7684\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u7814\u7a76\u653b\u51fb\u8005\u5982\u4f55\u5229\u7528\u9ad8\u7ef4\u79bb\u7ebf\u6570\u636e\u52ab\u6301bandit\u884c\u4e3a\u3002\u4ece\u7ebf\u6027\u5956\u52b1\u51fd\u6570\u6269\u5c55\u5230\u975e\u7ebf\u6027\u6a21\u578b\uff08\u5982ReLU\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u9488\u5bf9Hugging Face\u4e0a\u7684\u4e24\u4e2a\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u5668\uff08\u7f8e\u5b66\u8d28\u91cf\u548c\u7ec4\u5408\u5bf9\u9f50\uff09\u8fdb\u884c\u653b\u51fb\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a\u968f\u673a\u6270\u52a8\u65e0\u6548\uff0c\u4f46\u9488\u5bf9\u6027\u5fae\u5c0f\u6270\u52a8\u80fd\u5b9e\u73b0\u63a5\u8fd1\u5b8c\u7f8e\u7684\u653b\u51fb\u6210\u529f\u7387\u3002\u7406\u8bba\u8bc1\u660e\u9ad8\u7ef4\u6548\u5e94\uff1a\u8f93\u5165\u7ef4\u5ea6\u589e\u52a0\u65f6\uff0c\u6210\u529f\u653b\u51fb\u6240\u9700\u7684\u6270\u52a8\u8303\u6570\u51cf\u5c0f\uff0c\u4f7f\u56fe\u50cf\u8bc4\u4f30\u7b49\u73b0\u4ee3\u5e94\u7528\u7279\u522b\u8106\u5f31\u3002", "conclusion": "\u79bb\u7ebfbandit\u8bad\u7ec3\u5bf9\u5956\u52b1\u6a21\u578b\u7684\u5bf9\u6297\u6027\u653b\u51fb\u9ad8\u5ea6\u8106\u5f31\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u573a\u666f\u4e0b\u3002\u8fd9\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u4e8e\u516c\u5f00\u5956\u52b1\u6a21\u578b\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2602.01667", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01667", "abs": "https://arxiv.org/abs/2602.01667", "authors": ["Siu Lun Chau", "Soroush H. Zargarbashi", "Yusuf Sale", "Michele Caprio"], "title": "Quantifying Epistemic Predictive Uncertainty in Conformal Prediction", "comment": "42 pages", "summary": "We study the problem of quantifying epistemic predictive uncertainty (EPU) -- that is, uncertainty faced at prediction time due to the existence of multiple plausible predictive models -- within the framework of conformal prediction (CP). To expose the implicit model multiplicity underlying CP, we build on recent results showing that, under a mild assumption, any full CP procedure induces a set of closed and convex predictive distributions, commonly referred to as a credal set. Importantly, the conformal prediction region (CPR) coincides exactly with the set of labels to which all distributions in the induced credal set assign probability at least $1-\u03b1$. As our first contribution, we prove that this characterisation also holds in split CP. Building on this connection, we then propose a computationally efficient and analytically tractable uncertainty measure, based on \\emph{Maximum Mean Imprecision}, to quantify the EPU by measuring the degree of conflicting information within the induced credal set. Experiments on active learning and selective classification demonstrate that the quantified EPU provides substantially more informative and fine-grained uncertainty assessments than reliance on CPR size alone. More broadly, this work highlights the potential of CP serving as a principled basis for decision-making under epistemic uncertainty.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u5171\u5f62\u9884\u6d4b\u6846\u67b6\u4e0b\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u8ba4\u77e5\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5e73\u5747\u4e0d\u7cbe\u786e\u5ea6\u6d4b\u91cf\u8bf1\u5bfc\u4fe1\u5ea6\u96c6\u5408\u4e2d\u7684\u4fe1\u606f\u51b2\u7a81\u7a0b\u5ea6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u91cf\u5316\u9884\u6d4b\u65f6\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff08\u7531\u4e8e\u5b58\u5728\u591a\u4e2a\u5408\u7406\u9884\u6d4b\u6a21\u578b\u800c\u4ea7\u751f\u7684\u4e0d\u786e\u5b9a\u6027\uff09\u3002\u73b0\u6709\u5171\u5f62\u9884\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9884\u6d4b\u533a\u57df\u5927\u5c0f\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6a21\u578b\u591a\u91cd\u6027\u5bfc\u81f4\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u7cbe\u7ec6\u5ea6\u91cf\u3002", "method": "\u65b9\u6cd5\u57fa\u4e8e\u5171\u5f62\u9884\u6d4b\u4e0e\u4fe1\u5ea6\u96c6\u5408\u7684\u5173\u8054\uff1a\u8bc1\u660e\u4efb\u4f55\u5b8c\u6574\u7684\u5171\u5f62\u9884\u6d4b\u8fc7\u7a0b\u90fd\u4f1a\u8bf1\u5bfc\u51fa\u4e00\u4e2a\u95ed\u51f8\u9884\u6d4b\u5206\u5e03\u96c6\u5408\uff08\u4fe1\u5ea6\u96c6\u5408\uff09\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u57fa\u4e8e\u6700\u5927\u5e73\u5747\u4e0d\u7cbe\u786e\u5ea6\u7684\u8ba1\u7b97\u9ad8\u6548\u4e14\u89e3\u6790\u53ef\u5904\u7406\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u6d4b\u91cf\u8bf1\u5bfc\u4fe1\u5ea6\u96c6\u5408\u4e2d\u7684\u4fe1\u606f\u51b2\u7a81\u7a0b\u5ea6\u3002", "result": "\u5728\u4e3b\u52a8\u5b66\u4e60\u548c\u9009\u62e9\u6027\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u91cf\u5316\u7684\u8ba4\u77e5\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6bd4\u5355\u7eaf\u4f9d\u8d56\u5171\u5f62\u9884\u6d4b\u533a\u57df\u5927\u5c0f\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u3001\u66f4\u7ec6\u7c92\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u3002\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u5236\u5b9a\u6f5c\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u5171\u5f62\u9884\u6d4b\u4e0e\u4fe1\u5ea6\u96c6\u5408\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5171\u5f62\u9884\u6d4b\u4f5c\u4e3a\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0b\u51b3\u7b56\u5236\u5b9a\u7684\u7406\u8bba\u57fa\u7840\u6f5c\u529b\u3002"}}
{"id": "2602.01668", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01668", "abs": "https://arxiv.org/abs/2602.01668", "authors": ["Qianyang Li", "Xingjun Zhang", "Shaoxun Wang", "Jia Wei", "Yueqi Xing"], "title": "ASGMamba: Adaptive Spectral Gating Mamba for Multivariate Time Series Forecasting", "comment": null, "summary": "Long-term multivariate time series forecasting (LTSF) plays a crucial role in various high-performance computing applications, including real-time energy grid management and large-scale traffic flow simulation. However, existing solutions face a dilemma: Transformer-based models suffer from quadratic complexity, limiting their scalability on long sequences, while linear State Space Models (SSMs) often struggle to distinguish valuable signals from high-frequency noise, leading to wasted state capacity. To bridge this gap, we propose ASGMamba, an efficient forecasting framework designed for resource-constrained supercomputing environments. ASGMamba integrates a lightweight Adaptive Spectral Gating (ASG) mechanism that dynamically filters noise based on local spectral energy, enabling the Mamba backbone to focus its state evolution on robust temporal dynamics. Furthermore, we introduce a hierarchical multi-scale architecture with variable-specific Node Embeddings to capture diverse physical characteristics. Extensive experiments on nine benchmarks demonstrate that ASGMamba achieves state-of-the-art accuracy. While keeping strictly $$\\mathcal{O}(L)$$ complexity we significantly reduce the memory usage on long-horizon tasks, thus establishing ASGMamba as a scalable solution for high-throughput forecasting in resource limited environments.The code is available at https://github.com/hit636/ASGMamba", "AI": {"tldr": "ASGMamba\uff1a\u4e00\u79cd\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8d85\u7b97\u73af\u5883\u7684\u9ad8\u6548\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u8c31\u95e8\u63a7\u548cMamba\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e24\u96be\uff1aTransformer\u6a21\u578b\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u96be\u4ee5\u5904\u7406\u957f\u5e8f\u5217\uff1b\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u96be\u4ee5\u533a\u5206\u6709\u4ef7\u503c\u4fe1\u53f7\u4e0e\u9ad8\u9891\u566a\u58f0\uff0c\u5bfc\u81f4\u72b6\u6001\u5bb9\u91cf\u6d6a\u8d39\u3002\u9700\u8981\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u8d85\u7b97\u73af\u5883\u8bbe\u8ba1\u9ad8\u6548\u9884\u6d4b\u6846\u67b6\u3002", "method": "\u63d0\u51faASGMamba\u6846\u67b6\uff1a1) \u8f7b\u91cf\u7ea7\u81ea\u9002\u5e94\u8c31\u95e8\u63a7\u673a\u5236\uff0c\u57fa\u4e8e\u5c40\u90e8\u8c31\u80fd\u91cf\u52a8\u6001\u8fc7\u6ee4\u566a\u58f0\uff1b2) Mamba\u4e3b\u5e72\u7f51\u7edc\u4e13\u6ce8\u4e8e\u9c81\u68d2\u7684\u65f6\u95f4\u52a8\u6001\uff1b3) \u5206\u5c42\u591a\u5c3a\u5ea6\u67b6\u6784\uff0c\u5305\u542b\u53d8\u91cf\u7279\u5b9a\u7684\u8282\u70b9\u5d4c\u5165\u4ee5\u6355\u6349\u4e0d\u540c\u7269\u7406\u7279\u6027", "result": "\u57289\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u51c6\u786e\u7387\uff0c\u5728\u4fdd\u6301\u4e25\u683cO(L)\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u957f\u65f6\u9884\u6d4b\u4efb\u52a1\u7684\u5185\u5b58\u4f7f\u7528", "conclusion": "ASGMamba\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u9ad8\u541e\u5410\u91cf\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861"}}
{"id": "2602.01682", "categories": ["cs.LG", "cs.DS", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01682", "abs": "https://arxiv.org/abs/2602.01682", "authors": ["Taihei Oki", "Shinsaku Sakaue"], "title": "Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets", "comment": null, "summary": "We study online inverse linear optimization, also known as contextual recommendation, where a learner sequentially infers an agent's hidden objective vector from observed optimal actions over feasible sets that change over time. The learner aims to recommend actions that perform well under the agent's true objective, and the performance is measured by the regret, defined as the cumulative gap between the agent's optimal values and those achieved by the learner's recommended actions. Prior work has established a regret bound of $O(d\\log T)$, as well as a finite but exponentially large bound of $\\exp(O(d\\log d))$, where $d$ is the dimension of the optimization problem and $T$ is the time horizon, while a regret lower bound of $\u03a9(d)$ is known (Gollapudi et al. 2021; Sakaue et al. 2025). Whether a finite regret bound polynomial in $d$ is achievable or not has remained an open question. We partially resolve this by showing that when the feasible sets are M-convex -- a broad class that includes matroids -- a finite regret bound of $O(d\\log d)$ is possible. We achieve this by combining a structural characterization of optimal solutions on M-convex sets with a geometric volume argument. Moreover, we extend our approach to adversarially corrupted feedback in up to $C$ rounds. We obtain a regret bound of $O((C+1)d\\log d)$ without prior knowledge of $C$, by monitoring directed graphs induced by the observed feedback to detect corruptions adaptively.", "AI": {"tldr": "\u5728\u7ebf\u9006\u7ebf\u6027\u4f18\u5316\u4e2d\uff0c\u5f53\u53ef\u884c\u96c6\u662fM-\u51f8\u96c6\u65f6\uff0c\u53ef\u4ee5\u5b9e\u73b0O(d log d)\u7684\u6709\u9650\u9057\u61be\u754c\uff0c\u89e3\u51b3\u4e86\u591a\u9879\u5f0f\u9057\u61be\u662f\u5426\u53ef\u8fbe\u7684\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u5728\u7ebf\u9006\u7ebf\u6027\u4f18\u5316\uff08\u4e0a\u4e0b\u6587\u63a8\u8350\uff09\u4e2d\uff0c\u5b66\u4e60\u8005\u4ece\u968f\u65f6\u95f4\u53d8\u5316\u7684\u53ef\u884c\u96c6\u4e2d\u89c2\u5bdf\u6700\u4f18\u52a8\u4f5c\u6765\u63a8\u65ad\u4ee3\u7406\u7684\u9690\u85cf\u76ee\u6807\u5411\u91cf\u3002\u5148\u524d\u5de5\u4f5c\u5efa\u7acb\u4e86O(d log T)\u7684\u9057\u61be\u754c\u548c\u6307\u6570\u5927\u7684\u6709\u9650\u9057\u61be\u754c\uff0c\u800c\u03a9(d)\u7684\u4e0b\u754c\u5df2\u77e5\u3002\u662f\u5426\u5b58\u5728\u591a\u9879\u5f0f\u4e8ed\u7684\u6709\u9650\u9057\u61be\u754c\u4e00\u76f4\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u7ed3\u5408M-\u51f8\u96c6\u4e0a\u6700\u4f18\u89e3\u7684\u7ed3\u6784\u7279\u5f81\u4e0e\u51e0\u4f55\u4f53\u79ef\u8bba\u8bc1\u3002\u5bf9\u4e8e\u5bf9\u6297\u6027\u635f\u574f\u53cd\u9988\uff0c\u901a\u8fc7\u76d1\u6d4b\u89c2\u5bdf\u53cd\u9988\u8bf1\u5bfc\u7684\u6709\u5411\u56fe\u6765\u81ea\u9002\u5e94\u68c0\u6d4b\u635f\u574f\uff0c\u65e0\u9700\u4e8b\u5148\u77e5\u9053\u635f\u574f\u8f6e\u6570C\u3002", "result": "\u5f53\u53ef\u884c\u96c6\u662fM-\u51f8\u96c6\uff08\u5305\u62ec\u62df\u9635\uff09\u65f6\uff0c\u5b9e\u73b0\u4e86O(d log d)\u7684\u6709\u9650\u9057\u61be\u754c\u3002\u5bf9\u4e8e\u6700\u591aC\u8f6e\u5bf9\u6297\u6027\u635f\u574f\u53cd\u9988\uff0c\u83b7\u5f97\u4e86O((C+1)d log d)\u7684\u9057\u61be\u754c\uff0c\u4e14\u65e0\u9700\u4e8b\u5148\u77e5\u9053C\u3002", "conclusion": "\u90e8\u5206\u89e3\u51b3\u4e86\u5728\u7ebf\u9006\u7ebf\u6027\u4f18\u5316\u4e2d\u591a\u9879\u5f0f\u9057\u61be\u662f\u5426\u53ef\u8fbe\u7684\u5f00\u653e\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728M-\u51f8\u96c6\u6761\u4ef6\u4e0b\u53ef\u4ee5\u5b9e\u73b0O(d log d)\u7684\u6709\u9650\u9057\u61be\u754c\uff0c\u5e76\u6269\u5c55\u5230\u5bf9\u6297\u6027\u635f\u574f\u53cd\u9988\u573a\u666f\u3002"}}
{"id": "2602.01685", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01685", "abs": "https://arxiv.org/abs/2602.01685", "authors": ["Byeonghu Na", "Hyungho Na", "Yeongmin Kim", "Suhyeon Jo", "HeeSun Bae", "Mina Kang", "Il-Chul Moon"], "title": "Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment", "comment": "Accepted at ICLR 2026", "summary": "Large language models (LLMs) are commonly aligned with human preferences using reinforcement learning from human feedback (RLHF). In this method, LLM policies are generally optimized through reward maximization with Kullback-Leibler (KL) divergence regularization of the reference policy. However, KL and its $f$-divergence variants only compare token probabilities at identical indices, failing to capture semantic similarity. We propose Wasserstein Policy Regularization (WPR), a semantic-aware regularization for the RLHF framework based on the entropy-regularized Wasserstein distance, which incorporates the geometry of the token space. The dual formulation of the distance expresses the regularization as penalty terms applied to the reward via optimal dual variables, which yield a tractable objective compatible with standard RL algorithms. Empirically, our method outperforms KL- and $f$-divergence-based baselines, demonstrating the benefits of semantic-aware policy distances for alignment. Our code is available at https://github.com/aailab-kaist/WPR.", "AI": {"tldr": "\u63d0\u51faWasserstein Policy Regularization (WPR)\uff0c\u4e00\u79cd\u57fa\u4e8e\u71b5\u6b63\u5219\u5316Wasserstein\u8ddd\u79bb\u7684\u8bed\u4e49\u611f\u77e5\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdbRLHF\u6846\u67b6\uff0c\u901a\u8fc7\u8003\u8651\u6807\u8bb0\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u6765\u66f4\u597d\u5730\u6355\u6349\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "motivation": "\u5f53\u524dRLHF\u65b9\u6cd5\u4f7f\u7528KL\u6563\u5ea6\u53ca\u5176f-\u6563\u5ea6\u53d8\u4f53\u4f5c\u4e3a\u6b63\u5219\u5316\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u53ea\u6bd4\u8f83\u76f8\u540c\u7d22\u5f15\u4f4d\u7f6e\u7684\u6807\u8bb0\u6982\u7387\uff0c\u65e0\u6cd5\u6355\u6349\u8bed\u4e49\u76f8\u4f3c\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8003\u8651\u6807\u8bb0\u7a7a\u95f4\u51e0\u4f55\u7ed3\u6784\u7684\u8bed\u4e49\u611f\u77e5\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faWasserstein Policy Regularization (WPR)\uff0c\u57fa\u4e8e\u71b5\u6b63\u5219\u5316Wasserstein\u8ddd\u79bb\uff0c\u901a\u8fc7\u8ddd\u79bb\u7684\u5bf9\u5076\u516c\u5f0f\u5c06\u6b63\u5219\u5316\u8868\u793a\u4e3a\u901a\u8fc7\u6700\u4f18\u5bf9\u5076\u53d8\u91cf\u5e94\u7528\u4e8e\u5956\u52b1\u7684\u60e9\u7f5a\u9879\uff0c\u5f97\u5230\u4e0e\u6807\u51c6RL\u7b97\u6cd5\u517c\u5bb9\u7684\u53ef\u5904\u7406\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u4e8eKL\u6563\u5ea6\u548cf-\u6563\u5ea6\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8bed\u4e49\u611f\u77e5\u7b56\u7565\u8ddd\u79bb\u5728\u6a21\u578b\u5bf9\u9f50\u4e2d\u7684\u4f18\u52bf\u3002", "conclusion": "WPR\u901a\u8fc7\u5f15\u5165\u8003\u8651\u6807\u8bb0\u7a7a\u95f4\u51e0\u4f55\u7ed3\u6784\u7684Wasserstein\u8ddd\u79bb\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u8bed\u4e49\u611f\u77e5\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u6539\u8fdb\u4e86RLHF\u6846\u67b6\u4e2d\u7684\u7b56\u7565\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2602.01703", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01703", "abs": "https://arxiv.org/abs/2602.01703", "authors": ["Pengyu Li", "Lingling Zhang", "Zhitao Gao", "Yanrui Wu", "Yuxuan Dong", "Huan Liu", "Bifan Wei", "Jun Liu"], "title": "$\\textbf{AGT$^{AO}$}$: Robust and Stabilized LLM Unlearning via Adversarial Gating Training with Adaptive Orthogonality", "comment": null, "summary": "While Large Language Models (LLMs) have achieved remarkable capabilities, they unintentionally memorize sensitive data, posing critical privacy and security risks. Machine unlearning is pivotal for mitigating these risks, yet existing paradigms face a fundamental dilemma: aggressive unlearning often induces catastrophic forgetting that degrades model utility, whereas conservative strategies risk superficial forgetting, leaving models vulnerable to adversarial recovery. To address this trade-off, we propose $\\textbf{AGT$^{AO}$}$ (Adversarial Gating Training with Adaptive Orthogonality), a unified framework designed to reconcile robust erasure with utility preservation. Specifically, our approach introduces $\\textbf{Adaptive Orthogonality (AO)}$ to dynamically mitigate geometric gradient conflicts between forgetting and retention objectives, thereby minimizing unintended knowledge degradation. Concurrently, $\\textbf{Adversarial Gating Training (AGT)}$ formulates unlearning as a latent-space min-max game, employing a curriculum-based gating mechanism to simulate and counter internal recovery attempts. Extensive experiments demonstrate that $\\textbf{AGT$^{AO}$}$ achieves a superior trade-off between unlearning efficacy (KUR $\\approx$ 0.01) and model utility (MMLU 58.30). Code is available at https://github.com/TiezMind/AGT-unlearning.", "AI": {"tldr": "\u63d0\u51faAGTAO\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6b63\u4ea4\u6027\u548c\u5bf9\u6297\u95e8\u63a7\u8bad\u7ec3\u89e3\u51b3LLM\u9057\u5fd8\u4e2d\u7684\u9057\u5fd8\u4e0e\u4fdd\u7559\u5e73\u8861\u95ee\u9898", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f1a\u65e0\u610f\u4e2d\u8bb0\u5fc6\u654f\u611f\u6570\u636e\uff0c\u5e26\u6765\u9690\u79c1\u548c\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u9762\u4e34\u4e24\u96be\uff1a\u6fc0\u8fdb\u9057\u5fd8\u4f1a\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u964d\u4f4e\u6a21\u578b\u6548\u7528\uff0c\u4fdd\u5b88\u7b56\u7565\u5219\u53ef\u80fd\u53ea\u662f\u8868\u9762\u9057\u5fd8\uff0c\u6a21\u578b\u4ecd\u6613\u53d7\u5bf9\u6297\u6062\u590d\u653b\u51fb\u3002", "method": "\u63d0\u51faAGTAO\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u81ea\u9002\u5e94\u6b63\u4ea4\u6027(AO)\uff1a\u52a8\u6001\u7f13\u89e3\u9057\u5fd8\u548c\u4fdd\u7559\u76ee\u6807\u4e4b\u95f4\u7684\u51e0\u4f55\u68af\u5ea6\u51b2\u7a81\uff1b2) \u5bf9\u6297\u95e8\u63a7\u8bad\u7ec3(AGT)\uff1a\u5c06\u9057\u5fd8\u5efa\u6a21\u4e3a\u6f5c\u5728\u7a7a\u95f4\u7684\u6700\u5c0f\u6700\u5927\u535a\u5f08\uff0c\u91c7\u7528\u8bfe\u7a0b\u5f0f\u95e8\u63a7\u673a\u5236\u6a21\u62df\u548c\u5bf9\u6297\u5185\u90e8\u6062\u590d\u5c1d\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAGTAO\u5728\u9057\u5fd8\u6548\u679c(KUR \u2248 0.01)\u548c\u6a21\u578b\u6548\u7528(MMLU 58.30)\u4e4b\u95f4\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u5e73\u8861\u3002", "conclusion": "AGTAO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u9057\u5fd8\u4e2d\u7684\u9057\u5fd8-\u4fdd\u7559\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u64e6\u9664\u4e0e\u6548\u7528\u4fdd\u6301\u7684\u7edf\u4e00\u3002"}}
{"id": "2602.01705", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01705", "abs": "https://arxiv.org/abs/2602.01705", "authors": ["Haoqiang Kang", "Yizhe Zhang", "Nikki Lijing Kuang", "Yi-An Ma", "Lianhui Qin"], "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner", "comment": null, "summary": "Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.", "AI": {"tldr": "LaDi-RL\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u63a2\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u5728\u8bed\u4e49\u5c42\u9762\u8fdb\u884c\u63a8\u7406\u8f68\u8ff9\u63a2\u7d22\uff0c\u89e3\u51b3\u4e86\u79bb\u6563RL\u4e2d\u7684\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u79bb\u6563\u7684\u601d\u7ef4\u94fe\u751f\u6210\u6765\u6539\u8fdbLLM\u63a8\u7406\uff0c\u4f46\u5728token\u7a7a\u95f4\u4e2d\u7684\u63a2\u7d22\u5e38\u5e38\u56e0\u7b56\u7565\u71b5\u964d\u4f4e\u800c\u906d\u53d7\u591a\u6837\u6027\u5d29\u6e83\uff0c\u8fd9\u662f\u7531\u4e8e\u79bb\u6563RL\u4e2d\u7684\u6a21\u5f0f\u6fc0\u53d1\u884c\u4e3a\u5bfc\u81f4\u7684\u3002", "method": "\u63d0\u51faLatent Diffusion Reasoning with Reinforcement Learning (LaDi-RL)\u6846\u67b6\uff1a1\uff09\u5728\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a2\u7d22\uff0c\u6f5c\u5728\u53d8\u91cf\u7f16\u7801\u8bed\u4e49\u7ea7\u63a8\u7406\u8f68\u8ff9\uff1b2\uff09\u901a\u8fc7\u5f15\u5bfc\u6269\u6563\u5efa\u6a21\u63a2\u7d22\uff0c\u591a\u6b65\u53bb\u566a\u5206\u5e03\u968f\u673a\u6027\u5e76\u4fdd\u7559\u591a\u4e2a\u5171\u5b58\u89e3\u51b3\u65b9\u6848\u6a21\u5f0f\uff1b3\uff09\u5c06\u6f5c\u5728\u7a7a\u95f4\u63a2\u7d22\u4e0e\u6587\u672c\u7a7a\u95f4\u751f\u6210\u89e3\u8026\uff0c\u7ed3\u5408\u6587\u672c\u7b56\u7565\u83b7\u5f97\u989d\u5916\u6536\u76ca\u3002", "result": "\u5728\u4ee3\u7801\u751f\u6210\u548c\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u79bb\u6563RL\u57fa\u7ebf\uff0c\u5728pass@1\u548cpass@k\u6307\u6807\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff1a\u4ee3\u7801\u751f\u6210pass@1\u7edd\u5bf9\u589e\u76ca+9.4%\uff0c\u6570\u5b66\u63a8\u7406pass@1\u7edd\u5bf9\u589e\u76ca+5.7%\u3002", "conclusion": "\u57fa\u4e8e\u6269\u6563\u7684\u6f5c\u5728RL\u4e3a\u79bb\u6563token\u7ea7RL\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u539f\u5219\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u63a2\u7d22\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2602.01718", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01718", "abs": "https://arxiv.org/abs/2602.01718", "authors": ["Sora Nakai", "Youssef Fadhloun", "Kacem Mathlouthi", "Kotaro Yoshida", "Ganesh Talluri", "Ioannis Mitliagkas", "Hiroki Naganuma"], "title": "Revisiting Generalization Measures Beyond IID: An Empirical Study under Distributional Shift", "comment": null, "summary": "Generalization remains a central yet unresolved challenge in deep learning, particularly the ability to predict a model's performance beyond its training distribution using quantities available prior to test-time evaluation. Building on the large-scale study of Jiang et al. (2020). and concerns by Dziugaite et al. (2020). about instability across training configurations, we benchmark the robustness of generalization measures beyond IID regime. We train small-to-medium models over 10,000 hyperparameter configurations and evaluate more than 40 measures computable from the trained model and the available training data alone. We significantly broaden the experimental scope along multiple axes: (i) extending the evaluation beyond the standard IID setting to include benchmarking for robustness across diverse distribution shifts, (ii) evaluating multiple architectures and training recipes, and (iii) newly incorporating calibration- and information-criteria-based measures to assess their alignment with both IID and OOD generalization. We find that distribution shifts can substantially alter the predictive performance of many generalization measures, while a smaller subset remains comparatively stable across settings.", "AI": {"tldr": "\u5927\u89c4\u6a21\u7814\u7a76\u8bc4\u4f30\u4e8640\u591a\u79cd\u6cdb\u5316\u5ea6\u91cf\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u591a\u6570\u5ea6\u91cf\u5bf9\u5206\u5e03\u53d8\u5316\u654f\u611f\uff0c\u53ea\u6709\u5c11\u6570\u5ea6\u91cf\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u76f8\u5bf9\u7a33\u5b9a\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6cdb\u5316\u80fd\u529b\u9884\u6d4b\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u3002\u5148\u524d\u7814\u7a76\u5b58\u5728\u8bad\u7ec3\u914d\u7f6e\u4e0d\u7a33\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u9700\u8981\u8bc4\u4f30\u6cdb\u5316\u5ea6\u91cf\u5728\u975eIID\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u6269\u5c55\u4e86\u5927\u89c4\u6a21\u5b9e\u9a8c\u8303\u56f4\uff1a\u8bad\u7ec310,000\u4e2a\u8d85\u53c2\u6570\u914d\u7f6e\u7684\u5c0f\u5230\u4e2d\u578b\u6a21\u578b\uff1b\u8bc4\u4f3040\u591a\u79cd\u4ec5\u4ece\u8bad\u7ec3\u6a21\u578b\u548c\u8bad\u7ec3\u6570\u636e\u53ef\u8ba1\u7b97\u7684\u5ea6\u91cf\uff1b\u6269\u5c55\u5230\u975eIID\u8bbe\u7f6e\uff0c\u5305\u62ec\u591a\u6837\u5316\u7684\u5206\u5e03\u504f\u79fb\uff1b\u8bc4\u4f30\u591a\u79cd\u67b6\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\uff1b\u65b0\u7eb3\u5165\u57fa\u4e8e\u6821\u51c6\u548c\u4fe1\u606f\u51c6\u5219\u7684\u5ea6\u91cf\u3002", "result": "\u5206\u5e03\u504f\u79fb\u663e\u8457\u6539\u53d8\u4e86\u8bb8\u591a\u6cdb\u5316\u5ea6\u91cf\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u800c\u8f83\u5c0f\u7684\u5b50\u96c6\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u76f8\u5bf9\u7a33\u5b9a\u3002\u8fd9\u8868\u660e\u6cdb\u5316\u5ea6\u91cf\u5bf9\u5206\u5e03\u53d8\u5316\u654f\u611f\uff0c\u53ea\u6709\u5c11\u6570\u5ea6\u91cf\u5177\u6709\u8de8\u573a\u666f\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6cdb\u5316\u5ea6\u91cf\u7684\u9884\u6d4b\u6027\u80fd\u53d7\u5206\u5e03\u504f\u79fb\u5f71\u54cd\u663e\u8457\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u5ea6\u91cf\u6765\u51c6\u786e\u9884\u6d4b\u6a21\u578b\u5728\u975eIID\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002\u7814\u7a76\u4e3a\u7406\u89e3\u6cdb\u5316\u5ea6\u91cf\u5728\u73b0\u5b9e\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2602.01734", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01734", "abs": "https://arxiv.org/abs/2602.01734", "authors": ["Lianhai Ren", "Yucheng Ding", "Xiao Liu", "Qianxiao Li", "Peng Cheng", "Yeyun Gong"], "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration", "comment": null, "summary": "Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via $\u03bc$P, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMSign\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5468\u671f\u6027\u5e94\u7528\u77e9\u9635\u7b26\u53f7\u64cd\u4f5c\u6062\u590d\u7a33\u5b9a\u79e9\uff0c\u6709\u6548\u9632\u6b62LLM\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u7206\u70b8\u95ee\u9898\uff0c\u8ba1\u7b97\u5f00\u9500\u5c0f\u4e8e7.0%\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u8868\u73b0\u4e3a\u7a81\u7136\u7684\u68af\u5ea6\u7206\u70b8\uff0c\u6d6a\u8d39\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002\u9700\u8981\u7406\u89e3\u5e76\u89e3\u51b3\u8fd9\u79cd\u4e0d\u7a33\u5b9a\u6027\u673a\u5236\u3002", "method": "\u901a\u8fc7\u03bcP\u7f29\u653e\u76845M\u53c2\u6570NanoGPT\u6a21\u578b\u7814\u7a76\u8bad\u7ec3\u5931\u8d25\uff0c\u8bc6\u522b\u51fa\u4e24\u4e2a\u5173\u952e\u73b0\u8c61\uff1a\u6743\u91cd\u77e9\u9635\u7a33\u5b9a\u79e9\u5feb\u901f\u4e0b\u964d\u548c\u76f8\u90bb\u5c42\u96c5\u53ef\u6bd4\u77e9\u9635\u5bf9\u9f50\u5ea6\u589e\u52a0\u3002\u63d0\u51faMSign\u4f18\u5316\u5668\uff0c\u5468\u671f\u6027\u5e94\u7528\u77e9\u9635\u7b26\u53f7\u64cd\u4f5c\u6765\u6062\u590d\u7a33\u5b9a\u79e9\u3002", "result": "\u57285M\u52303B\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cMSign\u80fd\u6709\u6548\u9632\u6b62\u8bad\u7ec3\u5931\u8d25\uff0c\u8ba1\u7b97\u5f00\u9500\u5c0f\u4e8e7.0%\u3002\u7406\u8bba\u8bc1\u660e\u7a33\u5b9a\u79e9\u4e0b\u964d\u548c\u96c5\u53ef\u6bd4\u77e9\u9635\u5bf9\u9f50\u5171\u540c\u5bfc\u81f4\u68af\u5ea6\u8303\u6570\u968f\u7f51\u7edc\u6df1\u5ea6\u6307\u6570\u589e\u957f\u3002", "conclusion": "MSign\u901a\u8fc7\u6253\u7834\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u673a\u5236\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7a33\u5b9a\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u3002"}}
{"id": "2602.01736", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01736", "abs": "https://arxiv.org/abs/2602.01736", "authors": ["Qinwei Ma", "Jingzhe Shi", "Jiahao Qiu", "Zaiwen Yang"], "title": "Position: The Inevitable End of One-Architecture-Fits-All-Domains in Time Series Forecasting", "comment": "14 pages, 3 figures, 2 tables", "summary": "Recent work has questioned the effectiveness and robustness of neural network architectures for time series forecasting tasks. We summarize these concerns and analyze groundly their inherent limitations: i.e. the irreconcilable conflict between single (or few similar) domains SOTA and generalizability over general domains for time series forecasting neural network architecture designs. Moreover, neural networks architectures for general domain time series forecasting are becoming more and more complicated and their performance has almost saturated in recent years. As a result, network architectures developed aiming at fitting general time series domains are almost not inspiring for real world practices for certain single (or few similar) domains such as Finance, Weather, Traffic, etc: each specific domain develops their own methods that rarely utilize advances in neural network architectures of time series community in recent 2-3 years. As a result, we call for the time series community to shift focus away from research on time series neural network architectures for general domains: these researches have become saturated and away from domain-specific SOTAs over time. We should either (1) focus on deep learning methods for certain specific domain(s), or (2) turn to the development of meta-learning methods for general domains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8d28\u7591\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u6709\u6548\u6027\uff0c\u6307\u51fa\u5176\u5728\u7279\u5b9a\u9886\u57df\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u547c\u5401\u7814\u7a76\u91cd\u70b9\u8f6c\u5411\u9886\u57df\u4e13\u7528\u65b9\u6cd5\u6216\u5143\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\uff0c\u4f46\u6027\u80fd\u5df2\u8d8b\u4e8e\u9971\u548c\u3002\u8fd9\u4e9b\u67b6\u6784\u4e0e\u7279\u5b9a\u9886\u57df\uff08\u5982\u91d1\u878d\u3001\u5929\u6c14\u3001\u4ea4\u901a\uff09\u7684SOTA\u65b9\u6cd5\u5b58\u5728\u4e0d\u53ef\u8c03\u548c\u7684\u51b2\u7a81\uff0c\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u4e2d\u5f88\u5c11\u91c7\u7528\u6700\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8fdb\u5c55\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5206\u6790\u73b0\u6709\u7814\u7a76\uff0c\u603b\u7ed3\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u56fa\u6709\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5176\u4e0e\u7279\u5b9a\u9886\u57dfSOTA\u65b9\u6cd5\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u4f5c\u8005\u63d0\u51fa\u4e24\u79cd\u66ff\u4ee3\u65b9\u5411\uff1a\u4e13\u6ce8\u4e8e\u7279\u5b9a\u9886\u57df\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u6216\u8f6c\u5411\u901a\u7528\u9886\u57df\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u5f00\u53d1\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u7814\u7a76\u5df2\u8d8b\u4e8e\u9971\u548c\uff0c\u4e14\u4e0e\u7279\u5b9a\u9886\u57df\u7684\u6700\u4f73\u5b9e\u8df5\u8131\u8282\u3002\u8fd9\u4e9b\u67b6\u6784\u5728\u7279\u5b9a\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u542f\u53d1\u6709\u9650\uff0c\u5bfc\u81f4\u5404\u9886\u57df\u7ee7\u7eed\u4f7f\u7528\u81ea\u5df1\u7684\u4e13\u7528\u65b9\u6cd5\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u793e\u533a\u5e94\u5c06\u7814\u7a76\u91cd\u70b9\u4ece\u901a\u7528\u9886\u57df\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8f6c\u5411\uff1a1\uff09\u7279\u5b9a\u9886\u57df\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u62162\uff09\u901a\u7528\u9886\u57df\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u3002\u901a\u7528\u67b6\u6784\u7814\u7a76\u5df2\u9971\u548c\u4e14\u4e0e\u9886\u57dfSOTA\u8131\u8282\u3002"}}
{"id": "2602.01744", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01744", "abs": "https://arxiv.org/abs/2602.01744", "authors": ["Mingwei Xu", "Xuan Lin", "Xinnan Guo", "Wanqing Xu", "Wanyun Cui"], "title": "Softmax Linear Attention: Reclaiming Global Competition", "comment": "11 pages,4 figures", "summary": "While linear attention reduces the quadratic complexity of standard Transformers to linear time, it often lags behind in expressivity due to the removal of softmax normalization. This omission eliminates \\emph{global competition}, a critical mechanism that enables models to sharply focus on relevant information amidst long-context noise. In this work, we propose \\textbf{Softmax Linear Attention (SLA)}, a framework designed to restore this competitive selection without sacrificing efficiency. By lifting the softmax operation from the token level to the head level, SLA leverages attention heads as coarse semantic slots, applying a competitive gating mechanism to dynamically select the most relevant subspaces. This reintroduces the ``winner-take-all'' dynamics essential for precise retrieval and robust long-context understanding. Distinct from prior methods that focus on refining local kernel functions, SLA adopts a broader perspective by exploiting the higher-level multi-head aggregation structure. Extensive experiments demonstrate that SLA consistently enhances state-of-the-art linear baselines (RetNet, GLA, GDN) across language modeling and long-context benchmarks, particularly in challenging retrieval scenarios where it significantly boosts robustness against noise, validating its capability to restore precise focus while maintaining linear complexity.", "AI": {"tldr": "SLA\uff08Softmax Linear Attention\uff09\u901a\u8fc7\u5c06softmax\u64cd\u4f5c\u4ecetoken\u7ea7\u522b\u63d0\u5347\u5230head\u7ea7\u522b\uff0c\u5728\u7ebf\u6027\u6ce8\u610f\u529b\u4e2d\u6062\u590d\u4e86\u5168\u5c40\u7ade\u4e89\u673a\u5236\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u68c0\u7d22\u80fd\u529b\u3002", "motivation": "\u7ebf\u6027\u6ce8\u610f\u529b\u867d\u7136\u5c06\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u7ebf\u6027\u65f6\u95f4\uff0c\u4f46\u7531\u4e8e\u79fb\u9664\u4e86softmax\u5f52\u4e00\u5316\uff0c\u5931\u53bb\u4e86\u5168\u5c40\u7ade\u4e89\u673a\u5236\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u566a\u58f0\u4e2d\u96be\u4ee5\u805a\u7126\u76f8\u5173\u4fe1\u606f\uff0c\u8868\u8fbe\u80fd\u529b\u53d7\u9650\u3002", "method": "\u63d0\u51faSoftmax Linear Attention\uff08SLA\uff09\u6846\u67b6\uff0c\u5c06softmax\u64cd\u4f5c\u4ecetoken\u7ea7\u522b\u63d0\u5347\u5230head\u7ea7\u522b\uff0c\u5229\u7528\u6ce8\u610f\u529b\u5934\u4f5c\u4e3a\u7c97\u7c92\u5ea6\u8bed\u4e49\u69fd\uff0c\u901a\u8fc7\u7ade\u4e89\u95e8\u63a7\u673a\u5236\u52a8\u6001\u9009\u62e9\u6700\u76f8\u5173\u7684\u5b50\u7a7a\u95f4\uff0c\u6062\u590d\"\u8d62\u5bb6\u901a\u5403\"\u7684\u52a8\u6001\u7279\u6027\u3002", "result": "SLA\u5728\u8bed\u8a00\u5efa\u6a21\u548c\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u5347\u4e86\u6700\u5148\u8fdb\u7684\u7ebf\u6027\u57fa\u7ebf\u6a21\u578b\uff08RetNet\u3001GLA\u3001GDN\uff09\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u68c0\u7d22\u573a\u666f\u4e2d\u663e\u8457\u589e\u5f3a\u4e86\u6297\u566a\u58f0\u9c81\u68d2\u6027\u3002", "conclusion": "SLA\u901a\u8fc7head\u7ea7\u522b\u7684softmax\u7ade\u4e89\u673a\u5236\uff0c\u6210\u529f\u5728\u7ebf\u6027\u6ce8\u610f\u529b\u4e2d\u6062\u590d\u4e86\u7cbe\u786e\u805a\u7126\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01745", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01745", "abs": "https://arxiv.org/abs/2602.01745", "authors": ["Wenhao Yu", "Shaohang Wei", "Jiahong Liu", "Yifan Li", "Minda Hu", "Aiwei Liu", "Hao Zhang", "Irwin King"], "title": "Probability-Entropy Calibration: An Elastic Indicator for Adaptive Fine-tuning", "comment": null, "summary": "Token-level reweighting is a simple yet effective mechanism for controlling supervised fine-tuning, but common indicators are largely one-dimensional: the ground-truth probability reflects downstream alignment, while token entropy reflects intrinsic uncertainty induced by the pre-training prior. Ignoring entropy can misidentify noisy or easily replaceable tokens as learning-critical, while ignoring probability fails to reflect target-specific alignment. RankTuner introduces a probability--entropy calibration signal, the Relative Rank Indicator, which compares the rank of the ground-truth token with its expected rank under the prediction distribution. The inverse indicator is used as a token-wise Relative Scale to reweight the fine-tuning objective, focusing updates on truly under-learned tokens without over-penalizing intrinsically uncertain positions. Experiments on multiple backbones show consistent improvements on mathematical reasoning benchmarks, transfer gains on out-of-distribution reasoning, and pre code generation performance over probability-only or entropy-only reweighting baselines.", "AI": {"tldr": "RankTuner\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387-\u71b5\u6821\u51c6\u7684token\u7ea7\u91cd\u52a0\u6743\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f8\u5bf9\u79e9\u6307\u6807\u8bc6\u522b\u771f\u6b63\u9700\u8981\u5b66\u4e60\u7684token\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u6982\u7387\u6216\u71b5\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684token\u7ea7\u91cd\u52a0\u6743\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e00\u7ef4\u6307\u6807\uff1a\u771f\u5b9e\u6982\u7387\u53cd\u6620\u4e0b\u6e38\u5bf9\u9f50\uff0ctoken\u71b5\u53cd\u6620\u9884\u8bad\u7ec3\u5148\u9a8c\u5f15\u5165\u7684\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u3002\u5ffd\u7565\u71b5\u4f1a\u8bef\u5c06\u566a\u58f0\u6216\u6613\u66ff\u6362token\u8bc6\u522b\u4e3a\u5b66\u4e60\u5173\u952e\uff0c\u800c\u5ffd\u7565\u6982\u7387\u5219\u65e0\u6cd5\u53cd\u6620\u76ee\u6807\u7279\u5b9a\u5bf9\u9f50\u3002", "method": "RankTuner\u5f15\u5165\u6982\u7387-\u71b5\u6821\u51c6\u4fe1\u53f7\u2014\u2014\u76f8\u5bf9\u79e9\u6307\u6807\uff0c\u6bd4\u8f83\u771f\u5b9etoken\u7684\u79e9\u4e0e\u5176\u5728\u9884\u6d4b\u5206\u5e03\u4e0b\u7684\u671f\u671b\u79e9\u3002\u4f7f\u7528\u8be5\u6307\u6807\u7684\u5012\u6570\u4f5c\u4e3atoken\u7ea7\u76f8\u5bf9\u5c3a\u5ea6\u6765\u91cd\u52a0\u6743\u5fae\u8c03\u76ee\u6807\uff0c\u4e13\u6ce8\u4e8e\u771f\u6b63\u672a\u5145\u5206\u5b66\u4e60\u7684token\uff0c\u800c\u4e0d\u8fc7\u5ea6\u60e9\u7f5a\u5185\u5728\u4e0d\u786e\u5b9a\u7684\u4f4d\u7f6e\u3002", "result": "\u5728\u591a\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u83b7\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u5728\u5206\u5e03\u5916\u63a8\u7406\u4e0a\u5b9e\u73b0\u8fc1\u79fb\u589e\u76ca\uff0c\u5728\u4ee3\u7801\u751f\u6210\u6027\u80fd\u4e0a\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u6982\u7387\u6216\u71b5\u7684\u91cd\u52a0\u6743\u57fa\u7ebf\u3002", "conclusion": "RankTuner\u901a\u8fc7\u6982\u7387-\u71b5\u6821\u51c6\u6709\u6548\u8bc6\u522b\u5173\u952e\u5b66\u4e60token\uff0c\u5728\u76d1\u7763\u5fae\u8c03\u63a7\u5236\u4e2d\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684token\u7ea7\u91cd\u52a0\u6743\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5404\u79cd\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2602.01746", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01746", "abs": "https://arxiv.org/abs/2602.01746", "authors": ["Hongyi Peng", "Han Yu", "Xiaoxiao Li", "Qiang Yang"], "title": "Rethinking LoRA for Data Heterogeneous Federated Learning: Subspace and State Alignment", "comment": null, "summary": "Low-Rank Adaptation (LoRA) is widely used for federated fine-tuning. Yet under non-IID settings, it can substantially underperform full-parameter fine-tuning. Through with-high-probability robustness analysis, we uncover that this gap can be attributed to two coupled mismatches: (i) update-space mismatch, where clients optimize in a low-rank subspace but aggregation occurs in the full space; and (ii) optimizer-state mismatch, where unsynchronized adaptive states amplify drift across rounds. We propose FedGaLore, which combines client-side GaLore-style gradient-subspace optimization with server-side drift-robust synchronization of projected second-moment states via spectral shared-signal extraction, to address this challenge. Across NLU, vision, and NLG benchmarks, FedGaLore improves robustness and accuracy over state-of-the-art federated LoRA baselines in non-IID settings.", "AI": {"tldr": "FedGaLore\uff1a\u9488\u5bf9\u975eIID\u8054\u90a6\u5b66\u4e60\u4e2dLoRA\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u51fa\u7ed3\u5408\u5ba2\u6237\u7aefGaLore\u68af\u5ea6\u5b50\u7a7a\u95f4\u4f18\u5316\u548c\u670d\u52a1\u5668\u7aef\u8c31\u5171\u4eab\u4fe1\u53f7\u63d0\u53d6\u7684\u9c81\u68d2\u540c\u6b65\u65b9\u6cd5", "motivation": "\u5728\u975eIID\u8054\u90a6\u5b66\u4e60\u8bbe\u7f6e\u4e2d\uff0c\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u65b9\u6cd5\u76f8\u6bd4\u5168\u53c2\u6570\u5fae\u8c03\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8fd9\u6e90\u4e8e\u66f4\u65b0\u7a7a\u95f4\u4e0d\u5339\u914d\u548c\u4f18\u5316\u5668\u72b6\u6001\u4e0d\u5339\u914d\u4e24\u4e2a\u8026\u5408\u95ee\u9898", "method": "\u63d0\u51faFedGaLore\u65b9\u6cd5\uff1a\u5ba2\u6237\u7aef\u91c7\u7528GaLore\u98ce\u683c\u7684\u68af\u5ea6\u5b50\u7a7a\u95f4\u4f18\u5316\uff0c\u670d\u52a1\u5668\u7aef\u901a\u8fc7\u8c31\u5171\u4eab\u4fe1\u53f7\u63d0\u53d6\u540c\u6b65\u6295\u5f71\u7684\u7b2c\u4e8c\u77e9\u72b6\u6001\uff0c\u4ee5\u589e\u5f3a\u6f02\u79fb\u9c81\u68d2\u6027", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFedGaLore\u5728\u975eIID\u8bbe\u7f6e\u4e0b\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u8054\u90a6LoRA\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027", "conclusion": "\u901a\u8fc7\u89e3\u51b3LoRA\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u4e0d\u5339\u914d\u95ee\u9898\uff0cFedGaLore\u4e3a\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u8054\u90a6\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01751", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.01751", "abs": "https://arxiv.org/abs/2602.01751", "authors": ["Kunyi Fan", "Mengjie Chen", "Longlong Li", "Cunquan Qu"], "title": "MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network", "comment": "Submitted to ICASSP 2026", "summary": "Predicting drug-drug interactions (DDIs) is essential for safe pharmacological treatments. Previous graph neural network (GNN) models leverage molecular structures and interaction networks but mostly rely on linear aggregation and symmetric assumptions, limiting their ability to capture nonlinear and heterogeneous patterns. We propose MGKAN, a Graph Kolmogorov-Arnold Network that introduces learnable basis functions into asymmetric DDI prediction. MGKAN replaces conventional MLP transformations with KAN-driven basis functions, enabling more expressive and nonlinear modeling of drug relationships. To capture pharmacological dependencies, MGKAN integrates three network views-an asymmetric DDI network, a co-interaction network, and a biochemical similarity network-with role-specific embeddings to preserve directional semantics. A fusion module combines linear attention and nonlinear transformation to enhance representational capacity. On two benchmark datasets, MGKAN outperforms seven state-of-the-art baselines. Ablation studies and case studies confirm its predictive accuracy and effectiveness in modeling directional drug effects.", "AI": {"tldr": "MGKAN\u662f\u4e00\u79cd\u57fa\u4e8e\u56feKolmogorov-Arnold\u7f51\u7edc\u7684\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u57fa\u51fd\u6570\u548c\u975e\u5bf9\u79f0\u7f51\u7edc\u89c6\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86DDI\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GNN\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u7ebf\u6027\u805a\u5408\u548c\u5bf9\u79f0\u5047\u8bbe\uff0c\u96be\u4ee5\u6355\u6349\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u7684\u975e\u7ebf\u6027\u6a21\u5f0f\u548c\u5f02\u8d28\u6027\u7279\u5f81\uff0c\u9650\u5236\u4e86DDI\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faMGKAN\u6a21\u578b\uff1a1) \u7528KAN\u9a71\u52a8\u7684\u57fa\u51fd\u6570\u66ff\u4ee3\u4f20\u7edfMLP\u53d8\u6362\uff1b2) \u6574\u5408\u4e09\u79cd\u7f51\u7edc\u89c6\u56fe\uff08\u975e\u5bf9\u79f0DDI\u7f51\u7edc\u3001\u5171\u76f8\u4e92\u4f5c\u7528\u7f51\u7edc\u3001\u751f\u5316\u76f8\u4f3c\u6027\u7f51\u7edc\uff09\uff1b3) \u4f7f\u7528\u89d2\u8272\u7279\u5b9a\u5d4c\u5165\u4fdd\u6301\u65b9\u5411\u8bed\u4e49\uff1b4) \u878d\u5408\u7ebf\u6027\u6ce8\u610f\u529b\u548c\u975e\u7ebf\u6027\u53d8\u6362\u6a21\u5757\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cMGKAN\u8d85\u8d8a\u4e867\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\u3002\u6d88\u878d\u7814\u7a76\u548c\u6848\u4f8b\u5206\u6790\u8bc1\u5b9e\u4e86\u5176\u9884\u6d4b\u51c6\u786e\u6027\u4ee5\u53ca\u5728\u5efa\u6a21\u65b9\u5411\u6027\u836f\u7269\u6548\u5e94\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "MGKAN\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u57fa\u51fd\u6570\u548c\u975e\u5bf9\u79f0\u7f51\u7edc\u5efa\u6a21\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u6355\u6349\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u7684\u590d\u6742\u6a21\u5f0f\uff0c\u4e3a\u5b89\u5168\u836f\u7269\u6cbb\u7597\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684DDI\u9884\u6d4b\u5de5\u5177\u3002"}}
{"id": "2602.01763", "categories": ["cs.LG", "cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.01763", "abs": "https://arxiv.org/abs/2602.01763", "authors": ["Xiaowei Ye", "Xiaoyu He", "Chao Liao", "Chen Wu", "Pinyan Lu"], "title": "A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention", "comment": null, "summary": "Transformers serve as the foundation of most modern large language models. To mitigate the quadratic complexity of standard full attention, various efficient attention mechanisms, such as linear and hybrid attention, have been developed. A fundamental gap remains: their expressive power relative to full attention lacks a rigorous theoretical characterization. In this work, we theoretically characterize the performance differences among these attention mechanisms. Our theory applies to all linear attention variants that can be formulated as a recurrence, including Mamba, DeltaNet, etc. Specifically, we establish an expressiveness hierarchy: for the sequential function composition-a multi-step reasoning task that must occur within a model's forward pass, an ($L+1$)-layer full attention network is sufficient, whereas any hybrid network interleaving $L-1$ layers of full attention with a substantially larger number ($2^{3L^2}$) of linear attention layers cannot solve it. This result demonstrates a clear separation in expressive power between the two types of attention. Our work provides the first provable separation between hybrid attention and standard full attention, offering a theoretical perspective for understanding the fundamental capabilities and limitations of different attention mechanisms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5168\u6ce8\u610f\u529b\u4e0e\u6df7\u5408\u6ce8\u610f\u529b\uff08\u7ebf\u6027\u6ce8\u610f\u529b\uff09\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u7684\u4e25\u683c\u5206\u79bb\uff1a\u5bf9\u4e8e\u591a\u6b65\u63a8\u7406\u4efb\u52a1\uff0cL+1\u5c42\u5168\u6ce8\u610f\u529b\u7f51\u7edc\u8db3\u591f\u89e3\u51b3\uff0c\u4f46\u5373\u4f7f\u6df7\u5408L-1\u5c42\u5168\u6ce8\u610f\u529b\u4e0e\u6307\u6570\u7ea7\uff082^{3L^2}\uff09\u7ebf\u6027\u6ce8\u610f\u529b\u5c42\u4e5f\u65e0\u6cd5\u89e3\u51b3\u3002", "motivation": "\u5f53\u524d\u5404\u79cd\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\uff08\u5982\u7ebf\u6027\u6ce8\u610f\u529b\u3001\u6df7\u5408\u6ce8\u610f\u529b\uff09\u867d\u7136\u7f13\u89e3\u4e86\u5168\u6ce8\u610f\u529b\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u8868\u8fbe\u80fd\u529b\u76f8\u5bf9\u4e8e\u5168\u6ce8\u610f\u529b\u7684\u4e25\u683c\u7406\u8bba\u523b\u753b\u3002\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\uff0c\u7406\u89e3\u4e0d\u540c\u6ce8\u610f\u529b\u673a\u5236\u7684\u57fa\u672c\u80fd\u529b\u548c\u9650\u5236\u3002", "method": "\u5efa\u7acb\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4e0d\u540c\u6ce8\u610f\u529b\u673a\u5236\u7684\u8868\u8fbe\u80fd\u529b\u3002\u7279\u522b\u5173\u6ce8\u80fd\u591f\u8868\u793a\u4e3a\u9012\u5f52\u5f62\u5f0f\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u53d8\u4f53\uff08\u5305\u62ecMamba\u3001DeltaNet\u7b49\uff09\u3002\u901a\u8fc7\u5b9a\u4e49\u5e8f\u5217\u51fd\u6570\u7ec4\u5408\u8fd9\u4e00\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u51c6\uff0c\u6bd4\u8f83\u4e0d\u540c\u6ce8\u610f\u529b\u67b6\u6784\u7684\u89e3\u51b3\u80fd\u529b\u3002", "result": "\u8bc1\u660e\u4e86\u8868\u8fbe\u80fd\u529b\u5c42\u6b21\uff1a\u5bf9\u4e8e\u5e8f\u5217\u51fd\u6570\u7ec4\u5408\u4efb\u52a1\uff0cL+1\u5c42\u5168\u6ce8\u610f\u529b\u7f51\u7edc\u8db3\u591f\u89e3\u51b3\uff0c\u4f46\u4efb\u4f55\u6df7\u5408L-1\u5c42\u5168\u6ce8\u610f\u529b\u4e0e\u6307\u6570\u7ea7\uff082^{3L^2}\uff09\u7ebf\u6027\u6ce8\u610f\u529b\u5c42\u7684\u7f51\u7edc\u90fd\u65e0\u6cd5\u89e3\u51b3\u3002\u8fd9\u662f\u9996\u6b21\u63d0\u4f9b\u6df7\u5408\u6ce8\u610f\u529b\u4e0e\u6807\u51c6\u5168\u6ce8\u610f\u529b\u4e4b\u95f4\u7684\u53ef\u8bc1\u660e\u5206\u79bb\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u4ece\u7406\u8bba\u4e0a\u523b\u753b\u4e86\u4e0d\u540c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u8bc1\u660e\u4e86\u5168\u6ce8\u610f\u529b\u4e0e\u6df7\u5408\u6ce8\u610f\u529b\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u7684\u4e25\u683c\u5206\u79bb\u3002\u4e3a\u7406\u89e3\u4e0d\u540c\u6ce8\u610f\u529b\u673a\u5236\u7684\u57fa\u672c\u80fd\u529b\u548c\u9650\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u89c6\u89d2\uff0c\u5bf9\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\u7684\u8bbe\u8ba1\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2602.01766", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01766", "abs": "https://arxiv.org/abs/2602.01766", "authors": ["Runsong Zhao", "Shilei Liu", "Jiwei Tang", "Langming Liu", "Haibin Chen", "Weidong Zhang", "Yujin Yuan", "Tong Xiao", "Jingbo Zhu", "Wenbo Su", "Bo Zheng"], "title": "CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling", "comment": null, "summary": "The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that enables LLMs to handle arbitrarily long sequences with constant memory usage and linear time complexity. Designed as an efficient, plug-in module, CoMeT can be integrated into pre-trained models with only minimal fine-tuning. It operates on sequential data chunks, using a dual-memory system to manage context: a temporary memory on a FIFO queue for recent events, and a global memory with a gated update rule for long-range dependencies. These memories then act as a dynamic soft prompt for the next chunk. To enable efficient fine-tuning on extremely long contexts, we introduce a novel layer-level pipeline parallelism strategy. The effectiveness of our approach is remarkable: a model equipped with CoMeT and fine-tuned on 32k contexts can accurately retrieve a passkey from any position within a 1M token sequence. On the SCROLLS benchmark, CoMeT surpasses other efficient methods and achieves performance comparable to a full-attention baseline on summarization tasks. Its practical effectiveness is further validated on real-world agent and user behavior QA tasks. The code is available at: https://anonymous.4open.science/r/comet-B00B/", "AI": {"tldr": "CoMeT\u662f\u4e00\u79cd\u65b0\u578bTransformer\u67b6\u6784\uff0c\u901a\u8fc7\u53cc\u5185\u5b58\u7cfb\u7edf\u548c\u5206\u5757\u5904\u7406\u5b9e\u73b0\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u6052\u5b9a\u5185\u5b58\u4f7f\u7528\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u957f\u5e8f\u5217\u3002", "motivation": "\u6807\u51c6Transformer\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u548c\u65e0\u9650\u589e\u957f\u7684KV\u7f13\u5b58\u662f\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u4e3b\u8981\u969c\u788d\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u67b6\u6784\u6765\u5904\u7406\u4efb\u610f\u957f\u5e8f\u5217\u3002", "method": "CoMeT\u91c7\u7528\u53cc\u5185\u5b58\u7cfb\u7edf\uff1aFIFO\u961f\u5217\u7684\u4e34\u65f6\u5185\u5b58\u5904\u7406\u8fd1\u671f\u4e8b\u4ef6\uff0c\u5e26\u95e8\u63a7\u66f4\u65b0\u89c4\u5219\u7684\u5168\u5c40\u5185\u5b58\u5904\u7406\u957f\u7a0b\u4f9d\u8d56\uff1b\u4f5c\u4e3a\u63d2\u4ef6\u6a21\u5757\u96c6\u6210\u5230\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u5c42\u7ea7\u6d41\u6c34\u7ebf\u5e76\u884c\u7b56\u7565\u8fdb\u884c\u9ad8\u6548\u5fae\u8c03\u3002", "result": "\u572832k\u4e0a\u4e0b\u6587\u5fae\u8c03\u7684\u6a21\u578b\u80fd\u57281M token\u5e8f\u5217\u4e2d\u51c6\u786e\u68c0\u7d22\u4efb\u610f\u4f4d\u7f6e\u7684\u5bc6\u7801\uff1b\u5728SCROLLS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u5176\u4ed6\u9ad8\u6548\u65b9\u6cd5\uff0c\u5728\u6458\u8981\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e0e\u5168\u6ce8\u610f\u529b\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff1b\u5728\u5b9e\u9645\u4ee3\u7406\u548c\u7528\u6237\u884c\u4e3aQA\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "CoMeT\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u5185\u5b58\u7cfb\u7edf\u548c\u5206\u5757\u5904\u7406\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86Transformer\u5904\u7406\u957f\u5e8f\u5217\u65f6\u7684\u5185\u5b58\u548c\u65f6\u95f4\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01769", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01769", "abs": "https://arxiv.org/abs/2602.01769", "authors": ["Yuanshuai Li", "Yuping Yan", "Jirui Han", "Fei Ming", "Lingjuan Lv", "Yaochu Jin"], "title": "IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination", "comment": null, "summary": "Hallucination remains a fundamental challenge for Multimodal Large Language Models (MLLMs). While Direct Preference Optimization (DPO) is a key alignment framework, existing approaches often rely heavily on costly external evaluators for scoring or rewriting, incurring off-policy learnability gaps and discretization loss. Due to the lack of access to internal states, such feedback overlooks the fine-grained conflicts between different modalities that lead to hallucinations during generation.\n  To address this issue, we propose IRIS (Implicit Reward-Guided Internal Sifting), which leverages continuous implicit rewards in the native log-probability space to preserve full information density and capture internal modal competition. This on-policy paradigm eliminates learnability gaps by utilizing self-generated preference pairs. By sifting these pairs based on multimodal implicit rewards, IRIS ensures that optimization is driven by signals that directly resolve modal conflicts. Extensive experiments demonstrate that IRIS achieves highly competitive performance on key hallucination benchmarks using only 5.7k samples, without requiring any external feedback during preference alignment. These results confirm that IRIS provides an efficient and principled paradigm for mitigating MLLM hallucinations.", "AI": {"tldr": "IRIS\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u5f0f\u5956\u52b1\u7684\u5185\u90e8\u7b5b\u9009\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fde\u7eed\u9690\u5f0f\u5956\u52b1\u5728\u539f\u751f\u5bf9\u6570\u6982\u7387\u7a7a\u95f4\u4e2d\u6355\u6349\u6a21\u6001\u7ade\u4e89\uff0c\u65e0\u9700\u5916\u90e8\u8bc4\u4f30\u5668\u5373\u53ef\u7f13\u89e3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eDPO\u7684\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u5916\u90e8\u8bc4\u4f30\u5668\u8fdb\u884c\u8bc4\u5206\u6216\u91cd\u5199\uff0c\u5b58\u5728\u79bb\u7b56\u7565\u5b66\u4e60\u5dee\u8ddd\u548c\u79bb\u6563\u5316\u635f\u5931\uff0c\u4e14\u65e0\u6cd5\u8bbf\u95ee\u5185\u90e8\u72b6\u6001\u6765\u6355\u6349\u5bfc\u81f4\u5e7b\u89c9\u7684\u6a21\u6001\u95f4\u7ec6\u7c92\u5ea6\u51b2\u7a81\u3002", "method": "IRIS\u5229\u7528\u539f\u751f\u5bf9\u6570\u6982\u7387\u7a7a\u95f4\u4e2d\u7684\u8fde\u7eed\u9690\u5f0f\u5956\u52b1\u4fdd\u6301\u5b8c\u6574\u4fe1\u606f\u5bc6\u5ea6\uff0c\u6355\u6349\u5185\u90e8\u6a21\u6001\u7ade\u4e89\u3002\u901a\u8fc7\u57fa\u4e8e\u81ea\u751f\u6210\u504f\u597d\u5bf9\u8fdb\u884c\u5185\u90e8\u7b5b\u9009\uff0c\u786e\u4fdd\u4f18\u5316\u7531\u76f4\u63a5\u89e3\u51b3\u6a21\u6001\u51b2\u7a81\u7684\u4fe1\u53f7\u9a71\u52a8\u3002", "result": "\u5728\u5173\u952e\u5e7b\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ec5\u4f7f\u75285.7k\u6837\u672c\u5c31\u5b9e\u73b0\u4e86\u9ad8\u5ea6\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u65e0\u9700\u5728\u504f\u597d\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u4efb\u4f55\u5916\u90e8\u53cd\u9988\u3002", "conclusion": "IRIS\u4e3a\u7f13\u89e3MLLM\u5e7b\u89c9\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u539f\u5219\u6027\u7684\u8303\u5f0f\uff0c\u901a\u8fc7\u9690\u5f0f\u5956\u52b1\u5f15\u5bfc\u7684\u5185\u90e8\u7b5b\u9009\u6709\u6548\u89e3\u51b3\u6a21\u6001\u51b2\u7a81\u95ee\u9898\u3002"}}
{"id": "2602.01772", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.01772", "abs": "https://arxiv.org/abs/2602.01772", "authors": ["Yucheng Liao", "Han Wen", "Weinan E", "Weijie Zhang"], "title": "DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics", "comment": "21 pages, 5 figures", "summary": "Data-independent acquisition mass spectrometry (DIA-MS) has established itself as a cornerstone of proteomic profiling and large-scale systems biology, offering unparalleled depth and reproducibility. Current DIA analysis frameworks, however, require semi-supervised training within each run for peptide-spectrum match (PSM) re-scoring. This approach is prone to overfitting and lacks generalizability across diverse species and experimental conditions. Here, we present DIA-CLIP, a pre-trained model shifting the DIA analysis paradigm from semi-supervised training to universal cross-modal representation learning. By integrating dual-encoder contrastive learning framework with encoder-decoder architecture, DIA-CLIP establishes a unified cross-modal representation for peptides and corresponding spectral features, achieving high-precision, zero-shot PSM inference. Extensive evaluations across diverse benchmarks demonstrate that DIA-CLIP consistently outperforms state-of-the-art tools, yielding up to a 45% increase in protein identification while achieving a 12% reduction in entrapment identifications. Moreover, DIA-CLIP holds immense potential for diverse practical applications, such as single-cell and spatial proteomics, where its enhanced identification depth facilitates the discovery of novel biomarkers and the elucidates of intricate cellular mechanisms.", "AI": {"tldr": "DIA-CLIP\u662f\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u5b9e\u73b0\u96f6\u6837\u672c\u80bd\u6bb5-\u8c31\u56fe\u5339\u914d\uff0c\u663e\u8457\u63d0\u5347\u86cb\u767d\u8d28\u9274\u5b9a\u6570\u91cf\u5e76\u51cf\u5c11\u5047\u9633\u6027", "motivation": "\u5f53\u524dDIA-MS\u5206\u6790\u6846\u67b6\u9700\u8981\u5728\u6bcf\u4e2a\u5b9e\u9a8c\u4e2d\u534a\u76d1\u7763\u8bad\u7ec3\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\u4e14\u7f3a\u4e4f\u8de8\u7269\u79cd\u548c\u5b9e\u9a8c\u6761\u4ef6\u7684\u6cdb\u5316\u80fd\u529b", "method": "\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u548c\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5efa\u7acb\u80bd\u6bb5\u4e0e\u5bf9\u5e94\u8c31\u56fe\u7279\u5f81\u7684\u7edf\u4e00\u8de8\u6a21\u6001\u8868\u793a", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u86cb\u767d\u8d28\u9274\u5b9a\u6570\u91cf\u63d0\u5347\u8fbe45%\uff0c\u8bf1\u9975\u9274\u5b9a\u51cf\u5c1112%", "conclusion": "DIA-CLIP\u5c06DIA\u5206\u6790\u8303\u5f0f\u4ece\u534a\u76d1\u7763\u8bad\u7ec3\u8f6c\u5411\u901a\u7528\u8de8\u6a21\u6001\u5b66\u4e60\uff0c\u5728\u5355\u7ec6\u80de\u548c\u7a7a\u95f4\u86cb\u767d\u8d28\u7ec4\u5b66\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b"}}
{"id": "2602.01776", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01776", "abs": "https://arxiv.org/abs/2602.01776", "authors": ["Mingyue Cheng", "Xiaoyu Tao", "Qi Liu", "Ze Guo", "Enhong Chen"], "title": "Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting", "comment": null, "summary": "Time series forecasting has traditionally been formulated as a model-centric, static, and single-pass prediction problem that maps historical observations to future values. While this paradigm has driven substantial progress, it proves insufficient in adaptive and multi-turn settings where forecasting requires informative feature extraction, reasoning-driven inference, iterative refinement, and continual adaptation over time. In this paper, we argue for agentic time series forecasting (ATSF), which reframes forecasting as an agentic process composed of perception, planning, action, reflection, and memory. Rather than focusing solely on predictive models, ATSF emphasizes organizing forecasting as an agentic workflow that can interact with tools, incorporate feedback from outcomes, and evolve through experience accumulation. We outline three representative implementation paradigms -- workflow-based design, agentic reinforcement learning, and a hybrid agentic workflow paradigm -- and discuss the opportunities and challenges that arise when shifting from model-centric prediction to agentic forecasting. Together, this position aims to establish agentic forecasting as a foundation for future research at the intersection of time series forecasting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4ece\u4f20\u7edf\u7684\u6a21\u578b\u4e2d\u5fc3\u8303\u5f0f\u8f6c\u53d8\u4e3a\u667a\u80fd\u4f53\u5316\u9884\u6d4b\uff08ATSF\uff09\uff0c\u5c06\u9884\u6d4b\u91cd\u6784\u4e3a\u7531\u611f\u77e5\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u53cd\u601d\u548c\u8bb0\u5fc6\u7ec4\u6210\u7684\u667a\u80fd\u4f53\u5316\u8fc7\u7a0b\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u5b83\u4eec\u662f\u6a21\u578b\u4e2d\u5fc3\u3001\u9759\u6001\u3001\u5355\u6b21\u9884\u6d4b\u7684\u8303\u5f0f\uff0c\u65e0\u6cd5\u9002\u5e94\u9700\u8981\u4fe1\u606f\u7279\u5f81\u63d0\u53d6\u3001\u63a8\u7406\u9a71\u52a8\u63a8\u65ad\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u6301\u7eed\u65f6\u95f4\u9002\u5e94\u7684\u81ea\u9002\u5e94\u591a\u8f6e\u9884\u6d4b\u573a\u666f\u3002", "method": "\u63d0\u51fa\u667a\u80fd\u4f53\u5316\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08ATSF\uff09\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u91cd\u6784\u4e3a\u667a\u80fd\u4f53\u5316\u8fc7\u7a0b\uff0c\u5305\u542b\u611f\u77e5\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u53cd\u601d\u548c\u8bb0\u5fc6\u7ec4\u4ef6\u3002\u4ecb\u7ecd\u4e86\u4e09\u79cd\u5b9e\u73b0\u8303\u5f0f\uff1a\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684\u8bbe\u8ba1\u3001\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u548c\u6df7\u5408\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u8303\u5f0f\u3002", "result": "\u5efa\u7acb\u4e86\u667a\u80fd\u4f53\u5316\u9884\u6d4b\u4f5c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u672a\u6765\u7814\u7a76\u7684\u57fa\u7840\u6846\u67b6\uff0c\u63a2\u8ba8\u4e86\u4ece\u6a21\u578b\u4e2d\u5fc3\u9884\u6d4b\u5411\u667a\u80fd\u4f53\u5316\u9884\u6d4b\u8f6c\u53d8\u6240\u5e26\u6765\u7684\u673a\u9047\u548c\u6311\u6218\u3002", "conclusion": "\u667a\u80fd\u4f53\u5316\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e3a\u81ea\u9002\u5e94\u3001\u591a\u8f6e\u9884\u6d4b\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4e0e\u5de5\u5177\u4ea4\u4e92\u3001\u6574\u5408\u7ed3\u679c\u53cd\u9988\u5e76\u901a\u8fc7\u7ecf\u9a8c\u79ef\u7d2f\u4e0d\u65ad\u6f14\u5316\uff0c\u4ee3\u8868\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u7684\u91cd\u8981\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2602.01777", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01777", "abs": "https://arxiv.org/abs/2602.01777", "authors": ["M. Arashi", "M. Amintoosi"], "title": "Stein-Rule Shrinkage for Stochastic Gradient Estimation in High Dimensions", "comment": null, "summary": "Stochastic gradient methods are central to large-scale learning, yet their analysis typically treats mini-batch gradients as unbiased estimators of the population gradient. In high-dimensional settings, however, classical results from statistical decision theory show that unbiased estimators are generally inadmissible under quadratic loss, suggesting that standard stochastic gradients may be suboptimal from a risk perspective. In this work, we formulate stochastic gradient computation as a high-dimensional estimation problem and introduce a decision-theoretic framework based on Stein-rule shrinkage. We construct a shrinkage gradient estimator that adaptively contracts noisy mini-batch gradients toward a stable restricted estimator derived from historical momentum. The shrinkage intensity is determined in a data-driven manner using an online estimate of gradient noise variance, leveraging second-moment statistics commonly maintained by adaptive optimization methods. Under a Gaussian noise model and for dimension p>=3, we show that the proposed estimator uniformly dominates the standard stochastic gradient under squared error loss and is minimax-optimal in the classical decision-theoretic sense. We further demonstrate how this estimator can be incorporated into the Adam optimizer, yielding a practical algorithm with negligible additional computational cost. Empirical evaluations on CIFAR10 and CIFAR100, across multiple levels of label noise, show consistent improvements over Adam in the large-batch regime. Ablation studies indicate that the gains arise primarily from selectively applying shrinkage to high-dimensional convolutional layers, while indiscriminate shrinkage across all parameters degrades performance. These results illustrate that classical shrinkage principles provide a principled and effective approach to improving stochastic gradient estimation in modern deep learning.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eStein\u89c4\u5219\u6536\u7f29\u7684\u968f\u673a\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u6536\u7f29\u566a\u58f0\u5c0f\u6279\u91cf\u68af\u5ea6\u5411\u52a8\u91cf\u7a33\u5b9a\u4f30\u8ba1\u5668\uff0c\u5728Adam\u4f18\u5316\u5668\u4e2d\u5b9e\u73b0\u6027\u80fd\u63d0\u5347", "motivation": "\u4f20\u7edf\u968f\u673a\u68af\u5ea6\u65b9\u6cd5\u5c06\u5c0f\u6279\u91cf\u68af\u5ea6\u89c6\u4e3a\u65e0\u504f\u4f30\u8ba1\uff0c\u4f46\u9ad8\u7ef4\u7edf\u8ba1\u51b3\u7b56\u7406\u8bba\u8868\u660e\u65e0\u504f\u4f30\u8ba1\u5728\u4e8c\u6b21\u635f\u5931\u4e0b\u901a\u5e38\u4e0d\u53ef\u63a5\u53d7\uff0c\u6807\u51c6\u968f\u673a\u68af\u5ea6\u53ef\u80fd\u4ece\u98ce\u9669\u89d2\u5ea6\u662f\u6b21\u4f18\u7684", "method": "\u5c06\u968f\u673a\u68af\u5ea6\u8ba1\u7b97\u6784\u5efa\u4e3a\u9ad8\u7ef4\u4f30\u8ba1\u95ee\u9898\uff0c\u57fa\u4e8eStein\u89c4\u5219\u6536\u7f29\u6784\u5efa\u6536\u7f29\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u81ea\u9002\u5e94\u5730\u5c06\u566a\u58f0\u5c0f\u6279\u91cf\u68af\u5ea6\u6536\u7f29\u5230\u5386\u53f2\u52a8\u91cf\u5bfc\u51fa\u7684\u7a33\u5b9a\u53d7\u9650\u4f30\u8ba1\u5668\uff0c\u6536\u7f29\u5f3a\u5ea6\u901a\u8fc7\u5728\u7ebf\u4f30\u8ba1\u68af\u5ea6\u566a\u58f0\u65b9\u5dee\u6570\u636e\u9a71\u52a8\u786e\u5b9a", "result": "\u5728p>=3\u7684\u9ad8\u65af\u566a\u58f0\u6a21\u578b\u4e0b\uff0c\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u5728\u5e73\u65b9\u8bef\u5dee\u635f\u5931\u4e0b\u4e00\u81f4\u4f18\u4e8e\u6807\u51c6\u968f\u673a\u68af\u5ea6\uff0c\u4e14\u662f\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7684\uff1b\u5728Adam\u4f18\u5316\u5668\u4e2d\u5b9e\u73b0\uff0cCIFAR10\u548cCIFAR100\u5b9e\u9a8c\u663e\u793a\u5728\u5927\u6279\u91cf\u60c5\u51b5\u4e0b\u76f8\u6bd4Adam\u6709\u6301\u7eed\u6539\u8fdb", "conclusion": "\u7ecf\u5178\u6536\u7f29\u539f\u5219\u4e3a\u6539\u8fdb\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u968f\u673a\u68af\u5ea6\u4f30\u8ba1\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6709\u6548\u65b9\u6cd5\uff0c\u9009\u62e9\u6027\u5e94\u7528\u4e8e\u9ad8\u7ef4\u5377\u79ef\u5c42\u53ef\u83b7\u5f97\u6027\u80fd\u589e\u76ca"}}
{"id": "2602.01791", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01791", "abs": "https://arxiv.org/abs/2602.01791", "authors": ["Zheng Zhang", "Ao Lu", "Yuanhao Zeng", "Ziwei Shan", "Jinjin Guo", "Lufei Li", "Yexin Li", "Kan Ren"], "title": "Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has catalyzed significant breakthroughs in complex LLM reasoning within verifiable domains, such as mathematics and programming. Recent efforts have sought to extend this paradigm to open-ended tasks by employing LLMs-as-a-Judge to provide sequence-level rewards for policy optimization. However, these rewards are inherently sparse, failing to provide the fine-grained supervision necessary for generating complex, long-form trajectories. Furthermore, current work treats the Judge as a black-box oracle, discarding the rich intermediate feedback signals encoded in it. To address these limitations, we introduce Grad2Reward, a novel framework that extracts dense process rewards directly from the Judge's model inference process via a single backward pass. By leveraging gradient-based attribution, Grad2Reward enables precise token-level credit assignment, substantially enhancing training efficiency and reasoning quality. Additionally, Grad2Reward introduces a self-judging mechanism, allowing the policy to improve through its own evaluative signals without training specialized reward models or reliance on superior external Judges. The experiments demonstrate that policies optimized with Grad2Reward achieve outstanding performance across diverse open-ended tasks, affirming its effectiveness and broad generalizability.", "AI": {"tldr": "Grad2Reward\uff1a\u901a\u8fc7\u5355\u6b21\u53cd\u5411\u4f20\u64ad\u4eceLLM\u6cd5\u5b98\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u63d0\u53d6\u5bc6\u96c6\u8fc7\u7a0b\u5956\u52b1\uff0c\u89e3\u51b3\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684token\u7ea7\u4fe1\u7528\u5206\u914d\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u63a8\u7406\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u5728\u5f00\u653e\u4efb\u52a1\u4e2d\u4f7f\u7528LLM-as-a-Judge\u63d0\u4f9b\u5e8f\u5217\u7ea7\u5956\u52b1\uff0c\u4f46\u8fd9\u4e9b\u5956\u52b1\u7a00\u758f\u4e14\u65e0\u6cd5\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u76d1\u7763\uff0c\u540c\u65f6\u5c06\u6cd5\u5b98\u89c6\u4e3a\u9ed1\u76d2\uff0c\u5ffd\u7565\u4e86\u5176\u4e2d\u95f4\u53cd\u9988\u4fe1\u53f7\u3002", "method": "\u63d0\u51faGrad2Reward\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u5f52\u56e0\u4ece\u6cd5\u5b98\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u63d0\u53d6\u5bc6\u96c6\u8fc7\u7a0b\u5956\u52b1\uff0c\u5b9e\u73b0token\u7ea7\u4fe1\u7528\u5206\u914d\uff0c\u5e76\u5f15\u5165\u81ea\u5224\u65ad\u673a\u5236\u8ba9\u7b56\u7565\u901a\u8fc7\u81ea\u8eab\u8bc4\u4f30\u4fe1\u53f7\u6539\u8fdb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528Grad2Reward\u4f18\u5316\u7684\u7b56\u7565\u5728\u591a\u79cd\u5f00\u653e\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u5e7f\u6cdb\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Grad2Reward\u901a\u8fc7\u63d0\u53d6\u6cd5\u5b98\u6a21\u578b\u7684\u5bc6\u96c6\u8fc7\u7a0b\u5956\u52b1\uff0c\u89e3\u51b3\u4e86\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u653e\u4efb\u52a1\u4e2d\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u6548\u7387\u548c\u63a8\u7406\u8d28\u91cf\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2602.01826", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01826", "abs": "https://arxiv.org/abs/2602.01826", "authors": ["Yaxiang Zhang", "Yingru Li", "Jiacai Liu", "Jiawei Xu", "Ziniu Li", "Qian Liu", "Haoyuan Li"], "title": "Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It", "comment": null, "summary": "Reinforcement Learning (RL) for training Large Language Models is notoriously unstable. While recent studies attribute this to \"training inference mismatch stemming\" from inconsistent hybrid engines, standard remedies, such as Importance Sampling, might fail during extended training runs. In this work, we analyze this instability through the lens of optimization, demonstrating that gradient noise and training-inference mismatch escalate in tandem as training progresses. Meanwhile, we find that the mismatch can be effectively suppressed by shrinking the update size. Taken together, we deduce that the mismatch is not merely a static numerical discrepancy, but a dynamic failure coupled with the model's optimization. Based on this insight, we propose a simple yet effective solution: a specialized Learning Rate (LR) scheduler. Instead of pre-defined decay schedule in traditional LR scheduler, our method dynamically triggers LR decay based on response length, which we identify as a reliable early-warning signal for impending instability. Empirical evidence suggests that by reducing the learning rate as gradient noise rises, we can consistently stabilize RL training and keep the training-inference mismatch at a safe level.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u54cd\u5e94\u957f\u5ea6\u7684\u52a8\u6001\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u7528\u4e8e\u7a33\u5b9a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u89e3\u51b3\u8bad\u7ec3-\u63a8\u7406\u4e0d\u5339\u914d\u548c\u68af\u5ea6\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u5982\u91cd\u8981\u6027\u91c7\u6837\u5728\u957f\u671f\u8bad\u7ec3\u4e2d\u53ef\u80fd\u5931\u6548\u3002\u7814\u7a76\u53d1\u73b0\u8bad\u7ec3-\u63a8\u7406\u4e0d\u5339\u914d\u548c\u68af\u5ea6\u566a\u58f0\u4f1a\u968f\u7740\u8bad\u7ec3\u8fdb\u5c55\u800c\u52a0\u5267\uff0c\u9700\u8981\u65b0\u7684\u7a33\u5b9a\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e13\u95e8\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u4e0d\u91c7\u7528\u9884\u5b9a\u4e49\u7684\u8870\u51cf\u8ba1\u5212\uff0c\u800c\u662f\u57fa\u4e8e\u54cd\u5e94\u957f\u5ea6\u52a8\u6001\u89e6\u53d1\u5b66\u4e60\u7387\u8870\u51cf\u3002\u54cd\u5e94\u957f\u5ea6\u88ab\u8bc6\u522b\u4e3a\u5373\u5c06\u53d1\u751f\u4e0d\u7a33\u5b9a\u7684\u53ef\u9760\u65e9\u671f\u9884\u8b66\u4fe1\u53f7\u3002", "result": "\u901a\u8fc7\u5728\u5b66\u4e60\u7387\u4e0a\u5347\u65f6\u964d\u4f4e\u5b66\u4e60\u7387\uff0c\u80fd\u591f\u6301\u7eed\u7a33\u5b9aRL\u8bad\u7ec3\uff0c\u5e76\u5c06\u8bad\u7ec3-\u63a8\u7406\u4e0d\u5339\u914d\u4fdd\u6301\u5728\u5b89\u5168\u6c34\u5e73\u3002\u7ecf\u9a8c\u8bc1\u636e\u652f\u6301\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bad\u7ec3-\u63a8\u7406\u4e0d\u5339\u914d\u4e0d\u662f\u9759\u6001\u6570\u503c\u5dee\u5f02\uff0c\u800c\u662f\u4e0e\u6a21\u578b\u4f18\u5316\u8026\u5408\u7684\u52a8\u6001\u6545\u969c\u3002\u57fa\u4e8e\u54cd\u5e94\u957f\u5ea6\u7684\u52a8\u6001\u5b66\u4e60\u7387\u8c03\u5ea6\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u7a33\u5b9a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002"}}
{"id": "2602.01828", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01828", "abs": "https://arxiv.org/abs/2602.01828", "authors": ["Dionisia Naddeo", "Jonas Linkerh\u00e4gner", "Nicola Toschi", "Geri Skenderi", "Veronica Lachi"], "title": "Hyperbolic Graph Neural Networks Under the Microscope: The Role of Geometry-Task Alignment", "comment": null, "summary": "Many complex networks exhibit hyperbolic structural properties, making hyperbolic space a natural candidate for representing hierarchical and tree-like graphs with low distortion. Based on this observation, Hyperbolic Graph Neural Networks (HGNNs) have been widely adopted as a principled choice for representation learning on tree-like graphs. In this work, we question this paradigm by proposing an additional condition of geometry-task alignment, i.e., whether the metric structure of the target follows that of the input graph. We theoretically and empirically demonstrate the capability of HGNNs to recover low-distortion representations on two synthetic regression problems, and show that their geometric inductive bias becomes helpful when the problem requires preserving metric structure. Additionally, we evaluate HGNNs on the tasks of link prediction and node classification by jointly analyzing predictive performance and embedding distortion, revealing that only link prediction is geometry-aligned. Overall, our findings shift the focus from only asking \"Is the graph hyperbolic?\" to also questioning \"Is the task aligned with hyperbolic geometry?\", showing that HGNNs consistently outperform Euclidean models under such alignment, while their advantage vanishes otherwise.", "AI": {"tldr": "HGNNs\u4ec5\u5728\u51e0\u4f55\u4efb\u52a1\u5bf9\u9f50\u65f6\u4f18\u4e8e\u6b27\u51e0\u91cc\u5f97\u6a21\u578b\uff0c\u5f53\u4efb\u52a1\u9700\u8981\u4fdd\u6301\u5ea6\u91cf\u7ed3\u6784\u65f6\u53cc\u66f2\u51e0\u4f55\u7684\u5f52\u7eb3\u504f\u7f6e\u624d\u6709\u6548", "motivation": "\u8d28\u7591\u5f53\u524dHGNNs\u4f5c\u4e3a\u6811\u72b6\u56fe\u8868\u793a\u5b66\u4e60\u9996\u9009\u8303\u5f0f\u7684\u5408\u7406\u6027\uff0c\u63d0\u51fa\u9700\u8981\u8003\u8651\u51e0\u4f55\u4efb\u52a1\u5bf9\u9f50\u6761\u4ef6", "method": "\u63d0\u51fa\u51e0\u4f55\u4efb\u52a1\u5bf9\u9f50\u6982\u5ff5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5728\u4e24\u4e2a\u5408\u6210\u56de\u5f52\u95ee\u9898\u4e0a\u6d4b\u8bd5HGNNs\u6062\u590d\u4f4e\u5931\u771f\u8868\u793a\u7684\u80fd\u529b\uff0c\u5e76\u5728\u94fe\u63a5\u9884\u6d4b\u548c\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u8054\u5408\u5206\u6790\u9884\u6d4b\u6027\u80fd\u548c\u5d4c\u5165\u5931\u771f", "result": "HGNNs\u5728\u9700\u8981\u4fdd\u6301\u5ea6\u91cf\u7ed3\u6784\u7684\u95ee\u9898\u4e2d\u80fd\u6709\u6548\u6062\u590d\u4f4e\u5931\u771f\u8868\u793a\uff0c\u4f46\u4ec5\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u51e0\u4f55\u5bf9\u9f50\uff0c\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f18\u52bf\u6d88\u5931", "conclusion": "\u7814\u7a76\u91cd\u70b9\u5e94\u4ece\"\u56fe\u662f\u5426\u53cc\u66f2\"\u8f6c\u5411\"\u4efb\u52a1\u662f\u5426\u4e0e\u53cc\u66f2\u51e0\u4f55\u5bf9\u9f50\"\uff0cHGNNs\u4ec5\u5728\u51e0\u4f55\u5bf9\u9f50\u65f6\u4f18\u4e8e\u6b27\u51e0\u91cc\u5f97\u6a21\u578b"}}
{"id": "2602.01839", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2602.01839", "abs": "https://arxiv.org/abs/2602.01839", "authors": ["Ru Zhang", "Xunkai Li", "Yaxin Deng", "Sicheng Liu", "Daohan Su", "Qiangqiang Dai", "Hongchao Qin", "Rong-Hua Li", "Guoren Wang", "Jia Li"], "title": "DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis", "comment": "12 pages, 4 figures", "summary": "Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models.\n  To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.", "AI": {"tldr": "DOGMA\u662f\u4e00\u4e2a\u6570\u636e\u4e2d\u5fc3\u7684\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u751f\u7269\u5148\u9a8c\u77e5\u8bc6\u8fdb\u884c\u6570\u636e\u7ed3\u6784\u91cd\u5851\u548c\u8bed\u4e49\u589e\u5f3a\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\u56fe\u6784\u5efa\u548c\u8de8\u7269\u79cd\u5bf9\u9f50\uff0c\u5728\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5b66\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u65e9\u671f\u5e8f\u5217\u65b9\u6cd5\u5c06\u7ec6\u80de\u89c6\u4e3a\u72ec\u7acb\u5b9e\u4f53\uff0c\u5ffd\u7565\u4e86\u7ec6\u80de\u95f4\u7684\u529f\u80fd\u5173\u7cfb\uff1b2\uff09\u7ed3\u6784\u5316\u65b9\u6cd5\u867d\u7136\u6355\u6349\u7ec6\u80de\u95f4\u5173\u7cfb\uff0c\u4f46\u4f9d\u8d56\u542f\u53d1\u5f0f\u89c4\u5219\u800c\u5ffd\u7565\u4e86\u751f\u7269\u5148\u9a8c\u77e5\u8bc6\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u56fe\u8868\u793a\u6548\u679c\u4e0d\u4f73\u3002", "method": "DOGMA\u662f\u4e00\u4e2a\u6574\u4f53\u6027\u6570\u636e\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u751f\u7269\u5148\u9a8c\u77e5\u8bc6\u8fdb\u884c\u6570\u636e\u91cd\u5851\uff1a1\uff09\u4f7f\u7528\u7edf\u8ba1\u951a\u70b9\u3001\u7ec6\u80de\u672c\u4f53\u548c\u7cfb\u7edf\u53d1\u80b2\u6811\u5b9e\u73b0\u786e\u5b9a\u6027\u56fe\u6784\u5efa\u548c\u8de8\u7269\u79cd\u5bf9\u9f50\uff1b2\uff09\u5229\u7528\u57fa\u56e0\u672c\u4f53\u6574\u5408\u529f\u80fd\u5148\u9a8c\u77e5\u8bc6\uff0c\u5f25\u8865\u7279\u5f81\u5c42\u9762\u7684\u8bed\u4e49\u5dee\u8ddd\u3002", "result": "\u5728\u590d\u6742\u7684\u591a\u7269\u79cd\u3001\u591a\u5668\u5b98\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDOGMA\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u96f6\u6837\u672c\u9c81\u68d2\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "DOGMA\u901a\u8fc7\u7cfb\u7edf\u6574\u5408\u751f\u7269\u5148\u9a8c\u77e5\u8bc6\uff0c\u8d85\u8d8a\u4e86\u4f9d\u8d56\u968f\u673a\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\uff0c\u4e3a\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u9c81\u68d2\u7684\u6570\u636e\u4e2d\u5fc3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01842", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01842", "abs": "https://arxiv.org/abs/2602.01842", "authors": ["Jinbin Bai", "Yixuan Li", "Yuchen Zhu", "Yi Xin", "Qingyu Shi", "Aosong Feng", "Xiaohong Liu", "Molei Tao", "Jianru Xue", "Xiangtai Li", "Ming-Hsuan Yang"], "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models", "comment": null, "summary": "Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.", "AI": {"tldr": "Prism\u662f\u4e00\u4e2a\u9488\u5bf9\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u8f68\u8ff9\u641c\u7d22\u3001\u5c40\u90e8\u5206\u652f\u4e0e\u90e8\u5206\u91cd\u63a9\u7801\u3001\u4ee5\u53ca\u81ea\u9a8c\u8bc1\u53cd\u9988\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b97\u6cd5\u4e3b\u8981\u57fa\u4e8e\u81ea\u56de\u5f52\u89e3\u7801\uff0c\u4e0d\u9002\u5408\u5e76\u884c\u89e3\u7801\u7684\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u91ca\u653edLLMs\u7684\u751f\u6210\u6f5c\u529b\u3002", "method": "\u63d0\u51faPrism\u6846\u67b6\uff1a1\uff09\u5206\u5c42\u8f68\u8ff9\u641c\u7d22\uff0c\u5728\u65e9\u671f\u5230\u4e2d\u671f\u7684\u53bb\u566a\u7a97\u53e3\u52a8\u6001\u526a\u679d\u548c\u91cd\u65b0\u5206\u914d\u8ba1\u7b97\uff1b2\uff09\u5c40\u90e8\u5206\u652f\u4e0e\u90e8\u5206\u91cd\u63a9\u7801\uff0c\u5728\u4fdd\u7559\u9ad8\u7f6e\u4fe1\u5ea6\u4ee4\u724c\u7684\u540c\u65f6\u63a2\u7d22\u591a\u6837\u5316\u5b9e\u73b0\uff1b3\uff09\u81ea\u9a8c\u8bc1\u53cd\u9988\uff0c\u901a\u8fc7\u81ea\u8bc4\u4f30\u63d0\u793a\u66ff\u4ee3\u5916\u90e8\u9a8c\u8bc1\u5668\u3002", "result": "\u5728\u4e09\u4e2adLLM\u6a21\u578b\uff08LLaDA 8B Instruct\u3001Dream 7B Instruct\u3001LLaDA 2.0-mini\uff09\u7684\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPrism\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\uff0c\u4ee5\u663e\u8457\u66f4\u5c11\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u5339\u914d\u4e86\u6700\u4f73N\u4e2a\u6837\u672c\u7684\u6027\u80fd\u3002", "conclusion": "Prism\u4e3a\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8ba1\u7b97\u5206\u914d\u548c\u81ea\u9a8c\u8bc1\u673a\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2602.01845", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.01845", "abs": "https://arxiv.org/abs/2602.01845", "authors": ["Furkan Eris"], "title": "No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation", "comment": null, "summary": "Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \\textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $\u03c1= 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference", "AI": {"tldr": "Proust\u662f\u4e00\u4e2a309M\u53c2\u6570\u7684\u56e0\u679c\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u67b6\u6784\u521b\u65b0\u5f25\u5408\u4e86\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff08\u9002\u5408\u5ea6\u9884\u6d4b\uff09\u548c\u56e0\u679c\u6a21\u578b\uff08\u751f\u6210\u80fd\u529b\uff09\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u5927\u5e45\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u4e00\u4e2a\u6839\u672c\u6027\u5206\u6b67\uff1a\u63a9\u7801\u8bed\u8a00\u6a21\u578b\u64c5\u957f\u9002\u5408\u5ea6\u9884\u6d4b\uff0c\u800c\u56e0\u679c\u6a21\u578b\u652f\u6301\u751f\u6210\u4efb\u52a1\uff0c\u8feb\u4f7f\u7814\u7a76\u4eba\u5458\u7ef4\u62a4\u4e24\u5957\u5206\u79bb\u7684\u67b6\u6784\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u6a21\u578b\u6765\u540c\u65f6\u5177\u5907\u8fd9\u4e24\u79cd\u80fd\u529b\u3002", "method": "\u5f15\u5165Proust\u6a21\u578b\uff0c\u91c7\u7528\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e2d\u501f\u9274\u7684\u67b6\u6784\u521b\u65b0\uff1a\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\uff08\u5171\u4eabK/V\u6295\u5f71\uff09\u3001\u8de8\u5c42\u503c\u6b8b\u5dee\u8fde\u63a5\u548c\u6df1\u5ea6\u56e0\u679c\u5377\u79ef\u3002\u572833B tokens\u4e0a\u8bad\u7ec3\uff0c\u8017\u65f640 B200 GPU\u5c0f\u65f6\u3002", "result": "\u5728ProteinGym\u66ff\u4ee3\u4efb\u52a1\u4e0a\u8fbe\u5230Spearman \u03c1=0.390\uff0c\u4e0e\u9700\u898150-200\u500d\u8ba1\u7b97\u91cf\u7684\u63a9\u7801\u8bed\u8a00\u6a21\u578b\u76f8\u5f53\uff1b\u5728indels\u4efb\u52a1\u4e0a\u521b\u4e0b\u65b0SOTA\uff0c\u8d85\u8d8a\u592720\u500d\u7684\u6a21\u578b\uff1b\u5728EVEREST\u75c5\u6bd2\u9002\u5408\u5ea6\u57fa\u51c6\u4e0a\u63a5\u8fd1\u7ed3\u6784\u611f\u77e5\u65b9\u6cd5\u3002", "conclusion": "Proust\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u627e\u5230\u4e86\u5e73\u8861\u70b9\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u56e0\u679c\u6a21\u578b\u56fa\u6709\u7684\u751f\u6210\u80fd\u529b\u3002\u53ef\u89e3\u91ca\u6027\u5206\u6790\u8868\u660e\u4f4d\u7f6e\u71b5\u65b9\u5dee\u53ef\u4ee5\u9884\u6d4b\u68c0\u7d22\u589e\u5f3a\u7684\u6548\u679c\uff0c\u8fd9\u4e9b\u89c1\u89e3\u53ef\u4ee5\u6307\u5bfc\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b49\u80fd\u529b\u5f00\u53d1\u3002"}}
{"id": "2602.01849", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01849", "abs": "https://arxiv.org/abs/2602.01849", "authors": ["Ziwei Luo", "Ziqi Jin", "Lei Wang", "Lidong Bing", "Thomas B. Sch\u00f6n"], "title": "Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models", "comment": "Project page: https://algolzw.github.io/sr-smc", "summary": "This work presents self-rewarding sequential Monte Carlo (SMC), an inference-time scaling algorithm enabling effective sampling of masked diffusion language models (MDLMs). Our algorithm stems from the observation that most existing MDLMs rely on a confidence-based sampling strategy, where only tokens with the highest prediction confidence are preserved at each step. This restricts the generation to a noise-sensitive, greedy decoding paradigm, resulting in an inevitable collapse in the diversity of possible paths. We address this problem by launching multiple interacting diffusion processes in parallel, referred to as particles, for trajectory exploration. Importantly, we introduce the trajectory-level confidence as a self-rewarding signal for assigning particle importance weights. During sampling, particles are iteratively weighted and resampled to systematically steer generation towards globally confident, high-quality samples. Our self-rewarding SMC is verified on various masked diffusion language models and benchmarks, achieving significant improvement without extra training or reward guidance, while effectively converting parallel inference capacity into improved sampling quality. Our code is available at https://github.com/Algolzw/self-rewarding-smc.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u5956\u52b1\u5e8f\u5217\u8499\u7279\u5361\u6d1b\uff08SMC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u591a\u4e2a\u4ea4\u4e92\u7684\u6269\u6563\u8fc7\u7a0b\uff08\u7c92\u5b50\uff09\u6765\u63a2\u7d22\u8f68\u8ff9\uff0c\u4f7f\u7528\u8f68\u8ff9\u7ea7\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u81ea\u5956\u52b1\u4fe1\u53f7\u5206\u914d\u7c92\u5b50\u6743\u91cd\uff0c\u4ece\u800c\u63d0\u5347\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u91c7\u6837\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5927\u591a\u4f9d\u8d56\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u91c7\u6837\u7b56\u7565\uff0c\u53ea\u4fdd\u7559\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u6700\u9ad8\u7684token\u3002\u8fd9\u9650\u5236\u4e86\u751f\u6210\u8fc7\u7a0b\uff0c\u4f7f\u5176\u9677\u5165\u5bf9\u566a\u58f0\u654f\u611f\u3001\u8d2a\u5a6a\u7684\u89e3\u7801\u8303\u5f0f\uff0c\u5bfc\u81f4\u53ef\u80fd\u8def\u5f84\u7684\u591a\u6837\u6027\u4e0d\u53ef\u907f\u514d\u7684\u5d29\u6e83\u3002", "method": "\u63d0\u51fa\u81ea\u5956\u52b1\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff1a1\uff09\u5e76\u884c\u542f\u52a8\u591a\u4e2a\u4ea4\u4e92\u7684\u6269\u6563\u8fc7\u7a0b\uff08\u7c92\u5b50\uff09\u8fdb\u884c\u8f68\u8ff9\u63a2\u7d22\uff1b2\uff09\u5f15\u5165\u8f68\u8ff9\u7ea7\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u81ea\u5956\u52b1\u4fe1\u53f7\uff0c\u7528\u4e8e\u5206\u914d\u7c92\u5b50\u91cd\u8981\u6027\u6743\u91cd\uff1b3\uff09\u5728\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u7c92\u5b50\u88ab\u8fed\u4ee3\u52a0\u6743\u548c\u91cd\u91c7\u6837\uff0c\u7cfb\u7edf\u5730\u5c06\u751f\u6210\u5f15\u5bfc\u5411\u5168\u5c40\u7f6e\u4fe1\u5ea6\u9ad8\u3001\u9ad8\u8d28\u91cf\u7684\u6837\u672c\u3002", "result": "\u5728\u5404\u79cd\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u81ea\u5956\u52b1SMC\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u5956\u52b1\u6307\u5bfc\uff0c\u540c\u65f6\u6709\u6548\u5730\u5c06\u5e76\u884c\u63a8\u7406\u80fd\u529b\u8f6c\u5316\u4e3a\u6539\u8fdb\u7684\u91c7\u6837\u8d28\u91cf\u3002", "conclusion": "\u81ea\u5956\u52b1SMC\u662f\u4e00\u79cd\u63a8\u7406\u65f6\u6269\u5c55\u7b97\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u91c7\u6837\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u8f68\u8ff9\u7ea7\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u81ea\u5956\u52b1\u4fe1\u53f7\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7f6e\u4fe1\u5ea6\u91c7\u6837\u7b56\u7565\u5bfc\u81f4\u7684\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91c7\u6837\u8d28\u91cf\u3002"}}
{"id": "2602.01853", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01853", "abs": "https://arxiv.org/abs/2602.01853", "authors": ["Xiangkun Wu", "Qianglin Wen", "Yingying Zhang", "Hongtu Zhu", "Ting Li", "Chengchun Shi"], "title": "Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning", "comment": null, "summary": "A/B testing has become a gold standard for modern technological companies to conduct policy evaluation. Yet, its application to time series experiments, where policies are sequentially assigned over time, remains challenging. Existing designs suffer from two limitations: (i) they do not fully leverage the entire history for treatment allocation; (ii) they rely on strong assumptions to approximate the objective function (e.g., the mean squared error of the estimated treatment effect) for optimizing the design. We first establish an impossibility theorem showing that failure to condition on the full history leads to suboptimal designs, due to the dynamic dependencies in time series experiments. To address both limitations simultaneously, we next propose a transformer reinforcement learning (RL) approach which leverages transformers to condition allocation on the entire history and employs RL to directly optimize the MSE without relying on restrictive assumptions. Empirical evaluations on synthetic data, a publicly available dispatch simulator, and a real-world ridesharing dataset demonstrate that our proposal consistently outperforms existing designs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u5f3a\u5316\u5b66\u4e60\u7684\u65f6\u95f4\u5e8f\u5217A/B\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5b8c\u6574\u5386\u53f2\u4fe1\u606f\u548c\u76f4\u63a5\u4f18\u5316MSE\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8bbe\u8ba1", "motivation": "\u65f6\u95f4\u5e8f\u5217A/B\u6d4b\u8bd5\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u5b8c\u6574\u5386\u53f2\u4fe1\u606f\u8fdb\u884c\u5e72\u9884\u5206\u914d\uff0c\u4e14\u4f9d\u8d56\u5f3a\u5047\u8bbe\u6765\u8fd1\u4f3c\u76ee\u6807\u51fd\u6570\uff08\u5982\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u7684\u5747\u65b9\u8bef\u5dee\uff09", "method": "\u63d0\u51faTransformer\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528Transformer\u57fa\u4e8e\u5b8c\u6574\u5386\u53f2\u4fe1\u606f\u8fdb\u884c\u5e72\u9884\u5206\u914d\uff0c\u5e76\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u76f4\u63a5\u4f18\u5316\u5747\u65b9\u8bef\u5dee\uff0c\u907f\u514d\u4f9d\u8d56\u9650\u5236\u6027\u5047\u8bbe", "result": "\u5728\u5408\u6210\u6570\u636e\u3001\u516c\u5f00\u8c03\u5ea6\u6a21\u62df\u5668\u548c\u771f\u5b9e\u7f51\u7ea6\u8f66\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u8bbe\u8ba1", "conclusion": "\u901a\u8fc7\u540c\u65f6\u89e3\u51b3\u5386\u53f2\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u548c\u76ee\u6807\u51fd\u6570\u8fd1\u4f3c\u5047\u8bbe\u8fc7\u5f3a\u7684\u95ee\u9898\uff0cTransformer\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e3a\u65f6\u95f4\u5e8f\u5217A/B\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u8bbe\u8ba1\u65b9\u6848"}}
{"id": "2602.01855", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.01855", "abs": "https://arxiv.org/abs/2602.01855", "authors": ["Blagoj Hristov", "Hristijan Gjoreski", "Vesna Ojleska Latkoska", "Gorjan Nadzinski"], "title": "Time2Vec-Integrated Transformer for Robust Gesture Recognition from Low-Density sEMG", "comment": null, "summary": "Accurate and responsive myoelectric prosthesis control typically relies on complex, dense multi-sensor arrays, which limits consumer accessibility. This paper presents a novel, data-efficient deep learning framework designed to achieve precise and accurate control using minimal sensor hardware. Leveraging an external dataset of 8 subjects, our approach implements a hybrid Transformer optimized for sparse, two-channel surface electromyography (sEMG). Unlike standard architectures that use fixed positional encodings, we integrate Time2Vec learnable temporal embeddings to capture the stochastic temporal warping inherent in biological signals. Furthermore, we employ a normalized additive fusion strategy that aligns the latent distributions of spatial and temporal features, preventing the destructive interference common in standard implementations. A two-stage curriculum learning protocol is utilized to ensure robust feature extraction despite data scarcity. The proposed architecture achieves a state-of-the-art multi-subject F1-score of 95.7% $\\pm$ 0.20% for a 10-class movement set, statistically outperforming both a standard Transformer with fixed encodings and a recurrent CNN-LSTM model. Architectural optimization reveals that a balanced allocation of model capacity between spatial and temporal dimensions yields the highest stability. Furthermore, while direct transfer to a new unseen subject led to poor accuracy due to domain shifts, a rapid calibration protocol utilizing only two trials per gesture recovered performance from 21.0% $\\pm$ 2.98% to 96.9% $\\pm$ 0.52%. By validating that high-fidelity temporal embeddings can compensate for low spatial resolution, this work challenges the necessity of high-density sensing. The proposed framework offers a robust, cost-effective blueprint for next-generation prosthetic interfaces capable of rapid personalization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53cc\u901a\u9053sEMG\u7684\u6df7\u5408Transformer\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u65f6\u95f4\u5d4c\u5165\u548c\u5f52\u4e00\u5316\u878d\u5408\u7b56\u7565\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u808c\u7535\u5047\u80a2\u63a7\u5236\uff0c\u6311\u6218\u9ad8\u5bc6\u5ea6\u4f20\u611f\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u4f20\u7edf\u808c\u7535\u5047\u80a2\u63a7\u5236\u4f9d\u8d56\u590d\u6742\u5bc6\u96c6\u7684\u591a\u4f20\u611f\u5668\u9635\u5217\uff0c\u9650\u5236\u4e86\u6d88\u8d39\u8005\u53ef\u53ca\u6027\u3002\u9700\u8981\u5f00\u53d1\u4f7f\u7528\u6700\u5c11\u4f20\u611f\u5668\u786c\u4ef6\u4f46\u4ecd\u80fd\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\u7684\u6570\u636e\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u6df7\u5408Transformer\u67b6\u6784\uff0c\u91c7\u7528Time2Vec\u53ef\u5b66\u4e60\u65f6\u95f4\u5d4c\u5165\u6355\u83b7\u751f\u7269\u4fe1\u53f7\u7684\u968f\u673a\u65f6\u95f4\u626d\u66f2\uff0c\u4f7f\u7528\u5f52\u4e00\u5316\u52a0\u6027\u878d\u5408\u7b56\u7565\u5bf9\u9f50\u7a7a\u95f4\u548c\u65f6\u95f4\u7279\u5f81\u7684\u6f5c\u5728\u5206\u5e03\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u534f\u8bae\u786e\u4fdd\u6570\u636e\u7a00\u7f3a\u4e0b\u7684\u9c81\u68d2\u7279\u5f81\u63d0\u53d6\u3002", "result": "\u572810\u7c7b\u52a8\u4f5c\u96c6\u4e0a\u8fbe\u523095.7% \u00b1 0.20%\u7684\u591a\u53d7\u8bd5\u8005F1\u5206\u6570\uff0c\u4f18\u4e8e\u6807\u51c6Transformer\u548cCNN-LSTM\u6a21\u578b\u3002\u5feb\u901f\u6821\u51c6\u534f\u8bae\u4ec5\u9700\u6bcf\u4e2a\u624b\u52bf\u4e24\u4e2a\u8bd5\u9a8c\u5373\u53ef\u5c06\u6027\u80fd\u4ece21.0% \u00b1 2.98%\u6062\u590d\u523096.9% \u00b1 0.52%\u3002", "conclusion": "\u9ad8\u4fdd\u771f\u65f6\u95f4\u5d4c\u5165\u53ef\u4ee5\u8865\u507f\u4f4e\u7a7a\u95f4\u5206\u8fa8\u7387\uff0c\u6311\u6218\u4e86\u9ad8\u5bc6\u5ea6\u4f20\u611f\u7684\u5fc5\u8981\u6027\u3002\u8be5\u6846\u67b6\u4e3a\u80fd\u591f\u5feb\u901f\u4e2a\u6027\u5316\u7684\u4e0b\u4e00\u4ee3\u5047\u80a2\u63a5\u53e3\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u84dd\u56fe\u3002"}}
{"id": "2602.01877", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.01877", "abs": "https://arxiv.org/abs/2602.01877", "authors": ["Zichun Wang", "Gar Goei Loke", "Ruiting Zuo"], "title": "Autocorrelated Optimize-via-Estimate: Predict-then-Optimize versus Finite-sample Optimal", "comment": null, "summary": "Models that directly optimize for out-of-sample performance in the finite-sample regime have emerged as a promising alternative to traditional estimate-then-optimize approaches in data-driven optimization. In this work, we compare their performance in the context of autocorrelated uncertainties, specifically, under a Vector Autoregressive Moving Average VARMA(p,q) process. We propose an autocorrelated Optimize-via-Estimate (A-OVE) model that obtains an out-of-sample optimal solution as a function of sufficient statistics, and propose a recursive form for computing its sufficient statistics. We evaluate these models on a portfolio optimization problem with trading costs. A-OVE achieves low regret relative to a perfect information oracle, outperforming predict-then-optimize machine learning benchmarks. Notably, machine learning models with higher accuracy can have poorer decision quality, echoing the growing literature in data-driven optimization. Performance is retained under small mis-specification.", "AI": {"tldr": "\u63d0\u51faA-OVE\u6a21\u578b\u7528\u4e8e\u81ea\u76f8\u5173\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u6570\u636e\u9a71\u52a8\u4f18\u5316\uff0c\u5728\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u4e2d\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u9057\u61be\u503c", "motivation": "\u4f20\u7edf\"\u5148\u4f30\u8ba1\u540e\u4f18\u5316\"\u65b9\u6cd5\u5728\u6709\u9650\u6837\u672c\u4e0b\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u7684\uff0c\u7279\u522b\u662f\u5728\u81ea\u76f8\u5173\u4e0d\u786e\u5b9a\u6027(VARMA\u8fc7\u7a0b)\u573a\u666f\u4e0b\uff0c\u9700\u8981\u76f4\u63a5\u4f18\u5316\u6837\u672c\u5916\u6027\u80fd\u7684\u6a21\u578b", "method": "\u63d0\u51fa\u81ea\u76f8\u5173\u4f18\u5316-\u4f30\u8ba1(A-OVE)\u6a21\u578b\uff0c\u901a\u8fc7\u5145\u5206\u7edf\u8ba1\u91cf\u83b7\u5f97\u6837\u672c\u5916\u6700\u4f18\u89e3\uff0c\u5e76\u5f00\u53d1\u9012\u5f52\u5f62\u5f0f\u8ba1\u7b97\u5145\u5206\u7edf\u8ba1\u91cf", "result": "A-OVE\u5728\u5e26\u4ea4\u6613\u6210\u672c\u7684\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u4e2d\u76f8\u5bf9\u4e8e\u5b8c\u7f8e\u4fe1\u606f\u57fa\u51c6\u83b7\u5f97\u4f4e\u9057\u61be\u503c\uff0c\u4f18\u4e8e\u9884\u6d4b-\u4f18\u5316\u673a\u5668\u5b66\u4e60\u57fa\u51c6\uff0c\u4e14\u6027\u80fd\u5728\u8f7b\u5fae\u6a21\u578b\u8bef\u8bbe\u4e0b\u4fdd\u6301\u7a33\u5065", "conclusion": "\u76f4\u63a5\u4f18\u5316\u6837\u672c\u5916\u6027\u80fd\u7684\u6a21\u578b\u5728\u81ea\u76f8\u5173\u4e0d\u786e\u5b9a\u6027\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5373\u4f7f\u9884\u6d4b\u7cbe\u5ea6\u66f4\u9ad8\u4e5f\u53ef\u80fd\u51b3\u7b56\u8d28\u91cf\u66f4\u5dee\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u9a71\u52a8\u4f18\u5316\u9886\u57df\u7684\u65b0\u53d1\u73b0"}}
{"id": "2602.01897", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01897", "abs": "https://arxiv.org/abs/2602.01897", "authors": ["Sungheon Jeong", "Sanggeon Yun", "Ryozo Masukawa", "Wenjun Haung", "Hanning Chen", "Mohsen Imani"], "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs", "comment": null, "summary": "Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce \\emph{internal flow signatures} that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact \\emph{moving} readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. \\emph{Code is available at} \\texttt{github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs}.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5185\u90e8\u6d41\u7b7e\u540d\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u68c0\u67e5\u548c\u7cbe\u70bc\uff0c\u901a\u8fc7\u76d1\u6d4b\u6df1\u5ea6\u52a8\u6001\u6765\u68c0\u6d4b\u548c\u4fee\u6b63\u4e0d\u5fe0\u5b9e\u4e8e\u4e0a\u4e0b\u6587\u7684\u751f\u6210\u5185\u5bb9\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u751f\u6210\u6d41\u7545\u4f46\u4e0d\u5fe0\u5b9e\u4e8e\u4e0a\u4e0b\u6587\u7684\u5185\u5bb9\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u6216\u751f\u6210\u540e\u7684\u72ec\u7acb\u5224\u65ad\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4ece\u6a21\u578b\u5185\u90e8\u51b3\u7b56\u52a8\u6001\u8fdb\u884c\u81ea\u6211\u68c0\u67e5\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5185\u90e8\u6d41\u7b7e\u540d\uff0c\u901a\u8fc7\u504f\u7f6e\u4e2d\u5fc3\u76d1\u6d4b\u7a33\u5b9atoken\u7ea7\u52a8\u6001\uff0c\u5728\u6df1\u5ea6\u7a97\u53e3\u5185\u6784\u5efa\u79fb\u52a8\u8bfb\u53d6\u5bf9\u9f50\u5b50\u7a7a\u95f4\uff0c\u4f7f\u7528\u6b63\u4ea4\u4f20\u8f93\u5bf9\u9f50\u76f8\u90bb\u7a97\u53e3\uff0c\u63d0\u53d6\u6df1\u5ea6\u53ef\u6bd4\u8f83\u7684\u4f20\u8f93\u6b65\u957f\u3001\u8f6c\u5411\u89d2\u548c\u5b50\u7a7a\u95f4\u6f02\u79fb\u7b49\u7279\u5f81\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7GRU\u9a8c\u8bc1\u5668\u8fdb\u884c\u81ea\u6211\u68c0\u67e5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u68c0\u6d4b\u4e0d\u5fe0\u5b9e\u751f\u6210\uff0c\u5b9a\u4f4d\u95ee\u9898\u6df1\u5ea6\u4e8b\u4ef6\uff0c\u5e76\u901a\u8fc7\u56de\u6eda\u5230\u95ee\u9898token\u5e76\u94b3\u5236\u5f02\u5e38\u4f20\u8f93\u6b65\u957f\u8fdb\u884c\u9488\u5bf9\u6027\u7cbe\u70bc\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u4ea4\u6b8b\u5dee\u4e0d\u53d8\u3002", "conclusion": "\u63d0\u51fa\u7684\u5185\u90e8\u6d41\u7b7e\u540d\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u5b9a\u4f4d\u548c\u4f4e\u5f00\u9500\u7684\u81ea\u6211\u68c0\u67e5\uff0c\u80fd\u591f\u4ece\u5185\u90e8\u51b3\u7b56\u52a8\u6001\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u9a8c\u8bc1\u548c\u7cbe\u70bc\u3002"}}
{"id": "2602.01898", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01898", "abs": "https://arxiv.org/abs/2602.01898", "authors": ["Sanna Jarl", "Maria B\u00e5nkestad", "Jonathan J. S. Scragg", "Jens Sj\u00f6lund"], "title": "Observation-dependent Bayesian active learning via input-warped Gaussian processes", "comment": "13 pages", "summary": "Bayesian active learning relies on the precise quantification of predictive uncertainty to explore unknown function landscapes. While Gaussian process surrogates are the standard for such tasks, an underappreciated fact is that their posterior variance depends on the observed outputs only through the hyperparameters, rendering exploration largely insensitive to the actual measurements. We propose to inject observation-dependent feedback by warping the input space with a learned, monotone reparameterization. This mechanism allows the design policy to expand or compress regions of the input space in response to observed variability, thereby shaping the behavior of variance-based acquisition functions. We demonstrate that while such warps can be trained via marginal likelihood, a novel self-supervised objective yields substantially better performance. Our approach improves sample efficiency across a range of active learning benchmarks, particularly in regimes where non-stationarity challenges traditional methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5355\u8c03\u91cd\u53c2\u6570\u5316\u626d\u66f2\u8f93\u5165\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u4f7f\u8d1d\u53f6\u65af\u4e3b\u52a8\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u7b56\u7565\u80fd\u591f\u6839\u636e\u89c2\u6d4b\u53cd\u9988\u8c03\u6574\u8f93\u5165\u7a7a\u95f4\uff0c\u63d0\u9ad8\u91c7\u6837\u6548\u7387", "motivation": "\u4f20\u7edf\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\u7684\u540e\u9a8c\u65b9\u5dee\u4ec5\u901a\u8fc7\u8d85\u53c2\u6570\u4f9d\u8d56\u4e8e\u89c2\u6d4b\u8f93\u51fa\uff0c\u5bfc\u81f4\u63a2\u7d22\u7b56\u7565\u5bf9\u5b9e\u9645\u6d4b\u91cf\u4e0d\u654f\u611f\u3002\u9700\u8981\u6ce8\u5165\u89c2\u6d4b\u4f9d\u8d56\u7684\u53cd\u9988\u673a\u5236\u6765\u6539\u8fdb\u4e3b\u52a8\u5b66\u4e60\u7684\u63a2\u7d22\u6548\u7387", "method": "\u901a\u8fc7\u5b66\u4e60\u7684\u5355\u8c03\u91cd\u53c2\u6570\u5316\u5bf9\u8f93\u5165\u7a7a\u95f4\u8fdb\u884c\u626d\u66f2\uff0c\u4f7f\u8bbe\u8ba1\u7b56\u7565\u80fd\u591f\u6839\u636e\u89c2\u6d4b\u53d8\u5f02\u6027\u6269\u5c55\u6216\u538b\u7f29\u8f93\u5165\u7a7a\u95f4\u533a\u57df\uff0c\u4ece\u800c\u5851\u9020\u57fa\u4e8e\u65b9\u5dee\u7684\u91c7\u96c6\u51fd\u6570\u884c\u4e3a\u3002\u63d0\u51fa\u65b0\u7684\u81ea\u76d1\u7763\u76ee\u6807\u6765\u8bad\u7ec3\u8fd9\u79cd\u626d\u66f2", "result": "\u8be5\u65b9\u6cd5\u5728\u4e00\u7cfb\u5217\u4e3b\u52a8\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86\u91c7\u6837\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u975e\u5e73\u7a33\u6027\u6311\u6218\u4f20\u7edf\u65b9\u6cd5\u7684\u573a\u666f\u4e0b\u8868\u73b0\u663e\u8457\u66f4\u597d", "conclusion": "\u901a\u8fc7\u8f93\u5165\u7a7a\u95f4\u626d\u66f2\u6ce8\u5165\u89c2\u6d4b\u4f9d\u8d56\u53cd\u9988\u662f\u6539\u8fdb\u8d1d\u53f6\u65af\u4e3b\u52a8\u5b66\u4e60\u63a2\u7d22\u7b56\u7565\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u81ea\u76d1\u7763\u8bad\u7ec3\u76ee\u6807\u6bd4\u4f20\u7edf\u7684\u8fb9\u7f18\u4f3c\u7136\u8bad\u7ec3\u6548\u679c\u66f4\u597d"}}
{"id": "2602.01903", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01903", "abs": "https://arxiv.org/abs/2602.01903", "authors": ["Mingyi Li", "Taira Tsuchiya", "Kenji Yamanishi"], "title": "Data- and Variance-dependent Regret Bounds for Online Tabular MDPs", "comment": "80pages, 4tables", "summary": "This work studies online episodic tabular Markov decision processes (MDPs) with known transitions and develops best-of-both-worlds algorithms that achieve refined data-dependent regret bounds in the adversarial regime and variance-dependent regret bounds in the stochastic regime. We quantify MDP complexity using a first-order quantity and several new data-dependent measures for the adversarial regime, including a second-order quantity and a path-length measure, as well as variance-based measures for the stochastic regime. To adapt to these measures, we develop algorithms based on global optimization and policy optimization, both built on optimistic follow-the-regularized-leader with log-barrier regularization. For global optimization, our algorithms achieve first-order, second-order, and path-length regret bounds in the adversarial regime, and in the stochastic regime, they achieve a variance-aware gap-independent bound and a variance-aware gap-dependent bound that is polylogarithmic in the number of episodes. For policy optimization, our algorithms achieve the same data- and variance-dependent adaptivity, up to a factor of the episode horizon, by exploiting a new optimistic $Q$-function estimator. Finally, we establish regret lower bounds in terms of data-dependent complexity measures for the adversarial regime and a variance measure for the stochastic regime, implying that the regret upper bounds achieved by the global-optimization approach are nearly optimal.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u7ebf\u8868\u683cMDP\uff0c\u5f00\u53d1\u4e86\"\u4e24\u5168\u5176\u7f8e\"\u7b97\u6cd5\uff0c\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u5b9e\u73b0\u6570\u636e\u4f9d\u8d56\u7684\u9057\u61be\u754c\uff0c\u5728\u968f\u673a\u73af\u5883\u4e2d\u5b9e\u73b0\u65b9\u5dee\u4f9d\u8d56\u7684\u9057\u61be\u754c\u3002", "motivation": "\u73b0\u6709MDP\u7b97\u6cd5\u901a\u5e38\u5728\u5bf9\u6297\u6027\u6216\u968f\u673a\u73af\u5883\u4e2d\u5206\u522b\u4f18\u5316\uff0c\u7f3a\u4e4f\u80fd\u540c\u65f6\u9002\u5e94\u4e24\u79cd\u73af\u5883\u7684\u7edf\u4e00\u7b97\u6cd5\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u65e2\u80fd\u5904\u7406\u5bf9\u6297\u6027\u73af\u5883\u53c8\u80fd\u5229\u7528\u968f\u673a\u73af\u5883\u7ed3\u6784\u7684\u901a\u7528\u7b97\u6cd5\u3002", "method": "\u57fa\u4e8e\u4e50\u89c2\u8ddf\u968f\u6b63\u5219\u5316\u9886\u5bfc\u8005(optimistic FTRL)\u548c\u5bf9\u6570\u969c\u788d\u6b63\u5219\u5316\uff0c\u5f00\u53d1\u4e86\u5168\u5c40\u4f18\u5316\u548c\u7b56\u7565\u4f18\u5316\u4e24\u79cd\u7b97\u6cd5\u3002\u5168\u5c40\u4f18\u5316\u76f4\u63a5\u4f18\u5316\u4ef7\u503c\u51fd\u6570\uff0c\u7b56\u7565\u4f18\u5316\u4f7f\u7528\u65b0\u7684\u4e50\u89c2Q\u51fd\u6570\u4f30\u8ba1\u5668\u3002", "result": "\u5168\u5c40\u4f18\u5316\u7b97\u6cd5\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u5b9e\u73b0\u4e00\u9636\u3001\u4e8c\u9636\u548c\u8def\u5f84\u957f\u5ea6\u9057\u61be\u754c\uff0c\u5728\u968f\u673a\u73af\u5883\u4e2d\u5b9e\u73b0\u65b9\u5dee\u611f\u77e5\u7684\u65e0\u95f4\u9699\u754c\u548c\u95f4\u9699\u4f9d\u8d56\u754c(\u5bf9\u6570\u591a\u9879\u5f0f)\u3002\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u8fbe\u5230\u7c7b\u4f3c\u7684\u81ea\u9002\u5e94\u6027(\u76f8\u5dee\u4e00\u4e2a\u65f6\u95f4\u6b65\u56e0\u5b50)\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5bf9\u6297\u6027\u548c\u968f\u673a\u73af\u5883\u4e2d\u90fd\u5b9e\u73b0\u4e86\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u9057\u61be\u754c\uff0c\u901a\u8fc7\u65b0\u7684\u590d\u6742\u6027\u5ea6\u91cf\u5efa\u7acb\u4e86\u7406\u8bba\u4e0b\u754c\uff0c\u9a8c\u8bc1\u4e86\u5168\u5c40\u4f18\u5316\u65b9\u6cd5\u7684\u8fd1\u6700\u4f18\u6027\u3002"}}
{"id": "2602.01914", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01914", "abs": "https://arxiv.org/abs/2602.01914", "authors": ["Wenbo Pan", "Zhichao Liu", "Xianlong Wang", "Haining Yu", "Xiaohua Jia"], "title": "Towards Long-Horizon Interpretability: Efficient and Faithful Multi-Token Attribution for Reasoning LLMs", "comment": "ICML 2025 submission", "summary": "Token attribution methods provide intuitive explanations for language model outputs by identifying causally important input tokens. However, as modern LLMs increasingly rely on extended reasoning chains, existing schemes face two critical challenges: (1) efficiency bottleneck, where attributing a target span of M tokens within a context of length N requires O(M*N) operations, making long-context attribution prohibitively slow; and (2) faithfulness drop, where intermediate reasoning tokens absorb attribution mass, preventing importance from propagating back to the original input. To address these, we introduce FlashTrace, an efficient multi-token attribution method that employs span-wise aggregation to compute attribution over multi-token targets in a single pass, while maintaining faithfulness. Moreover, we design a recursive attribution mechanism that traces importance through intermediate reasoning chains back to source inputs. Extensive experiments on long-context retrieval (RULER) and multi-step reasoning (MATH, MorehopQA) tasks demonstrate that FlashTrace achieves over 130x speedup over existing baselines while maintaining superior faithfulness. We further analyze the dynamics of recursive attribution, showing that even a single recursive hop improves faithfulness by tracing importance through the reasoning chain.", "AI": {"tldr": "FlashTrace\uff1a\u4e00\u79cd\u9ad8\u6548\u7684\u591atoken\u5f52\u56e0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8span\u805a\u5408\u548c\u9012\u5f52\u5f52\u56e0\u673a\u5236\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u5f52\u56e0\u7684\u6548\u7387\u74f6\u9888\u548c\u5fe0\u5b9e\u5ea6\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709token\u5f52\u56e0\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u6548\u7387\u74f6\u9888 - \u5728\u957f\u5ea6\u4e3aN\u7684\u4e0a\u4e0b\u6587\u4e2d\u5f52\u56e0M\u4e2atoken\u9700\u8981O(M*N)\u64cd\u4f5c\uff0c\u957f\u4e0a\u4e0b\u6587\u5f52\u56e0\u6781\u5176\u7f13\u6162\uff1b2) \u5fe0\u5b9e\u5ea6\u4e0b\u964d - \u4e2d\u95f4\u63a8\u7406token\u5438\u6536\u5f52\u56e0\u8d28\u91cf\uff0c\u963b\u6b62\u91cd\u8981\u6027\u4f20\u64ad\u56de\u539f\u59cb\u8f93\u5165\u3002", "method": "FlashTrace\u91c7\u7528\u8de8span\u805a\u5408\u5728\u5355\u6b21\u8ba1\u7b97\u4e2d\u5b8c\u6210\u591atoken\u76ee\u6807\u7684\u5f52\u56e0\uff0c\u540c\u65f6\u8bbe\u8ba1\u9012\u5f52\u5f52\u56e0\u673a\u5236\uff0c\u901a\u8fc7\u4e2d\u95f4\u63a8\u7406\u94fe\u5c06\u91cd\u8981\u6027\u8ffd\u8e2a\u56de\u6e90\u8f93\u5165\u3002", "result": "\u5728\u957f\u4e0a\u4e0b\u6587\u68c0\u7d22(RULER)\u548c\u591a\u6b65\u63a8\u7406(MATH, MorehopQA)\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFlashTrace\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u83b7\u5f97\u8d85\u8fc7130\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u9ad8\u7684\u5fe0\u5b9e\u5ea6\u3002\u9012\u5f52\u5f52\u56e0\u5206\u6790\u663e\u793a\uff0c\u5373\u4f7f\u5355\u6b21\u9012\u5f52\u8df3\u8f6c\u4e5f\u80fd\u901a\u8fc7\u8ffd\u8e2a\u63a8\u7406\u94fe\u63d0\u5347\u5fe0\u5b9e\u5ea6\u3002", "conclusion": "FlashTrace\u901a\u8fc7\u9ad8\u6548\u7684\u8de8span\u805a\u5408\u548c\u9012\u5f52\u5f52\u56e0\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u5f52\u56e0\u7684\u6548\u7387\u74f6\u9888\u548c\u5fe0\u5b9e\u5ea6\u4e0b\u964d\u95ee\u9898\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01915", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01915", "abs": "https://arxiv.org/abs/2602.01915", "authors": ["Elad Sharony", "Tom Jurgenson", "Orr Krupnik", "Dotan Di Castro", "Shie Mannor"], "title": "VLM-Guided Experience Replay", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) and Vision-Language Models (VLMs) have enabled powerful semantic and multimodal reasoning capabilities, creating new opportunities to enhance sample efficiency, high-level planning, and interpretability in reinforcement learning (RL). While prior work has integrated LLMs and VLMs into various components of RL, the replay buffer, a core component for storing and reusing experiences, remains unexplored. We propose addressing this gap by leveraging VLMs to guide the prioritization of experiences in the replay buffer. Our key idea is to use a frozen, pre-trained VLM (requiring no fine-tuning) as an automated evaluator to identify and prioritize promising sub-trajectories from the agent's experiences. Across scenarios, including game-playing and robotics, spanning both discrete and continuous domains, agents trained with our proposed prioritization method achieve 11-52% higher average success rates and improve sample efficiency by 19-45% compared to previous approaches. https://esharony.me/projects/vlm-rb/", "AI": {"tldr": "\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u56de\u653e\u7f13\u51b2\u533a\u7684\u7ecf\u9a8c\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u65e0\u9700\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u6210\u529f\u7387\u548c\u6837\u672c\u6548\u7387", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5df2\u5728\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u4e2a\u7ec4\u4ef6\u4e2d\u5f97\u5230\u5e94\u7528\uff0c\u4f46\u56de\u653e\u7f13\u51b2\u533a\u8fd9\u4e00\u5b58\u50a8\u548c\u91cd\u7528\u7ecf\u9a8c\u7684\u6838\u5fc3\u7ec4\u4ef6\u5c1a\u672a\u88ab\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5229\u7528VLM\u7684\u8bed\u4e49\u548c\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u6765\u6307\u5bfc\u7ecf\u9a8c\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u51bb\u7ed3VLM\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u4f30\u5668\uff0c\u65e0\u9700\u5fae\u8c03\uff0c\u4ece\u667a\u80fd\u4f53\u7ecf\u9a8c\u4e2d\u8bc6\u522b\u5e76\u4f18\u5148\u5904\u7406\u6709\u524d\u666f\u7684\u5b50\u8f68\u8ff9\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u6e38\u620f\u548c\u673a\u5668\u4eba\u7b49\u79bb\u6563\u548c\u8fde\u7eed\u9886\u57df\u3002", "result": "\u5728\u6e38\u620f\u548c\u673a\u5668\u4eba\u573a\u666f\u4e2d\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\uff0c\u5e73\u5747\u6210\u529f\u7387\u63d0\u534711-52%\uff0c\u6837\u672c\u6548\u7387\u63d0\u9ad819-45%\u3002", "conclusion": "VLM\u53ef\u4ee5\u6709\u6548\u5730\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u56de\u653e\u7f13\u51b2\u533a\u7684\u7ecf\u9a8c\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.01920", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01920", "abs": "https://arxiv.org/abs/2602.01920", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen"], "title": "PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks", "comment": null, "summary": "Graph neural networks (GNNs) often struggle in class-imbalanced settings, where minority classes are under-represented and predictions are biased toward majorities. We propose \\textbf{PIMPC-GNN}, a physics-informed multi-phase consensus framework for imbalanced node classification. Our method integrates three complementary dynamics: (i) thermodynamic diffusion, which spreads minority labels to capture long-range dependencies, (ii) Kuramoto synchronisation, which aligns minority nodes through oscillatory consensus, and (iii) spectral embedding, which separates classes via structural regularisation. These perspectives are combined through class-adaptive ensemble weighting and trained with an imbalance-aware loss that couples balanced cross-entropy with physics-based constraints. Across five benchmark datasets and imbalance ratios from 5-100, PIMPC-GNN outperforms 16 state-of-the-art baselines, achieving notable gains in minority-class recall (up to +12.7\\%) and balanced accuracy (up to +8.3\\%). Beyond empirical improvements, the framework also provides interpretable insights into consensus dynamics in graph learning. The code is available at \\texttt{https://github.com/afofanah/PIMPC-GNN}.", "AI": {"tldr": "\u63d0\u51faPIMPC-GNN\u6846\u67b6\uff0c\u901a\u8fc7\u70ed\u529b\u5b66\u6269\u6563\u3001Kuramoto\u540c\u6b65\u548c\u8c31\u5d4c\u5165\u4e09\u79cd\u7269\u7406\u52a8\u529b\u5b66\u673a\u5236\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u8282\u70b9\u5206\u7c7b\u4e2d\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5c11\u6570\u7c7b\u53ec\u56de\u7387\u548c\u5e73\u8861\u51c6\u786e\u7387\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5c11\u6570\u7c7b\u522b\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u9884\u6d4b\u504f\u5411\u591a\u6570\u7c7b\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u504f\u5dee\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u4e09\u79cd\u4e92\u8865\u7684\u7269\u7406\u52a8\u529b\u5b66\uff1a\u70ed\u529b\u5b66\u6269\u6563\u4f20\u64ad\u5c11\u6570\u7c7b\u6807\u7b7e\u6355\u83b7\u957f\u7a0b\u4f9d\u8d56\uff1bKuramoto\u540c\u6b65\u901a\u8fc7\u632f\u8361\u5171\u8bc6\u5bf9\u9f50\u5c11\u6570\u7c7b\u8282\u70b9\uff1b\u8c31\u5d4c\u5165\u901a\u8fc7\u7ed3\u6784\u6b63\u5219\u5316\u5206\u79bb\u7c7b\u522b\u3002\u4f7f\u7528\u7c7b\u522b\u81ea\u9002\u5e94\u96c6\u6210\u6743\u91cd\u548c\u7ed3\u5408\u5e73\u8861\u4ea4\u53c9\u71b5\u4e0e\u7269\u7406\u7ea6\u675f\u7684\u4e0d\u5e73\u8861\u611f\u77e5\u635f\u5931\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u57285\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c5-100\u7684\u4e0d\u5e73\u8861\u6bd4\u4f8b\u4e0b\uff0cPIMPC-GNN\u4f18\u4e8e16\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c11\u6570\u7c7b\u53ec\u56de\u7387\u63d0\u5347\u9ad8\u8fbe12.7%\uff0c\u5e73\u8861\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe8.3%\u3002", "conclusion": "PIMPC-GNN\u6846\u67b6\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u4e86\u7c7b\u522b\u4e0d\u5e73\u8861\u8282\u70b9\u5206\u7c7b\u7684\u6027\u80fd\uff0c\u8fd8\u4e3a\u56fe\u5b66\u4e60\u4e2d\u7684\u5171\u8bc6\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.01922", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01922", "abs": "https://arxiv.org/abs/2602.01922", "authors": ["Orell Trautmann", "Olaf Wolkenhauer", "Cl\u00e9mence R\u00e9da"], "title": "Embedding Learning on Multiplex Networks for Link Prediction", "comment": null, "summary": "Over the past years, embedding learning on networks has shown tremendous results in link prediction tasks for complex systems, with a wide range of real-life applications. Learning a representation for each node in a knowledge graph allows us to capture topological and semantic information, which can be processed in downstream analyses later. In the link prediction task, high-dimensional network information is encoded into low-dimensional vectors, which are then fed to a predictor to infer new connections between nodes in the network. As the network complexity (that is, the numbers of connections and types of interactions) grows, embedding learning turns out increasingly challenging. This review covers published models on embedding learning on multiplex networks for link prediction. First, we propose refined taxonomies to classify and compare models, depending on the type of embeddings and embedding techniques. Second, we review and address the problem of reproducible and fair evaluation of embedding learning on multiplex networks for the link prediction task. Finally, we tackle evaluation on directed multiplex networks by proposing a novel and fair testing procedure. This review constitutes a crucial step towards the development of more performant and tractable embedding learning approaches for multiplex networks and their fair evaluation for the link prediction task. We also suggest guidelines on the evaluation of models, and provide an informed perspective on the challenges and tools currently available to address downstream analyses applied to multiplex networks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u662f\u4e00\u7bc7\u5173\u4e8e\u591a\u8def\u7f51\u7edc\u5d4c\u5165\u5b66\u4e60\u7528\u4e8e\u94fe\u8def\u9884\u6d4b\u7684\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u5206\u7c7b\u6cd5\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u65e8\u5728\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u590d\u6742\u6027\u7684\u589e\u52a0\uff08\u8fde\u63a5\u6570\u91cf\u548c\u4ea4\u4e92\u7c7b\u578b\u589e\u591a\uff09\uff0c\u591a\u8def\u7f51\u7edc\u4e0a\u7684\u5d4c\u5165\u5b66\u4e60\u53d8\u5f97\u8d8a\u6765\u8d8a\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u6a21\u578b\u9700\u8981\u7cfb\u7edf\u7684\u5206\u7c7b\u548c\u516c\u5e73\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "1. \u63d0\u51fa\u7ec6\u5316\u7684\u5206\u7c7b\u6cd5\uff0c\u6839\u636e\u5d4c\u5165\u7c7b\u578b\u548c\u5d4c\u5165\u6280\u672f\u5bf9\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u548c\u6bd4\u8f83\uff1b2. \u56de\u987e\u5e76\u89e3\u51b3\u591a\u8def\u7f51\u7edc\u4e0a\u5d4c\u5165\u5b66\u4e60\u7684\u53ef\u91cd\u590d\u6027\u548c\u516c\u5e73\u8bc4\u4f30\u95ee\u9898\uff1b3. \u9488\u5bf9\u6709\u5411\u591a\u8def\u7f51\u7edc\u63d0\u51fa\u65b0\u9896\u4e14\u516c\u5e73\u7684\u6d4b\u8bd5\u6d41\u7a0b\u3002", "result": "\u8be5\u7efc\u8ff0\u4e3a\u591a\u8def\u7f51\u7edc\u5d4c\u5165\u5b66\u4e60\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u5305\u62ec\u5206\u7c7b\u6cd5\u3001\u8bc4\u4f30\u6307\u5357\u548c\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u53ef\u5904\u7406\u7684\u5d4c\u5165\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u662f\u63a8\u52a8\u591a\u8def\u7f51\u7edc\u5d4c\u5165\u5b66\u4e60\u65b9\u6cd5\u53d1\u5c55\u53ca\u5176\u516c\u5e73\u8bc4\u4f30\u7684\u5173\u952e\u4e00\u6b65\uff0c\u4e3a\u4e0b\u6e38\u5206\u6790\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u9488\u548c\u5de5\u5177\u89c6\u89d2\u3002"}}
{"id": "2602.01924", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01924", "abs": "https://arxiv.org/abs/2602.01924", "authors": ["Luc\u00eda Gonz\u00e1lez-Zamorano", "Nuria Balb\u00e1s-Esteban", "Vanessa G\u00f3mez-Verdejo", "Albert Belenguer-Llorens", "Carlos Sevilla-Salcedo"], "title": "Bayesian Integration of Nonlinear Incomplete Clinical Data", "comment": null, "summary": "Multimodal clinical data are characterized by high dimensionality, heterogeneous representations, and structured missingness, posing significant challenges for predictive modeling, data integration, and interpretability. We propose BIONIC (Bayesian Integration of Nonlinear Incomplete Clinical data), a unified probabilistic framework that integrates heterogeneous multimodal data under missingness through a joint generative-discriminative latent architecture. BIONIC uses pretrained embeddings for complex modalities such as medical images and clinical text, while incorporating structured clinical variables directly within a Bayesian multimodal formulation. The proposed framework enables robust learning in partially observed and semi-supervised settings by explicitly modeling modality-level and variable-level missingness, as well as missing labels. We evaluate BIONIC on three multimodal clinical and biomedical datasets, demonstrating strong and consistent discriminative performance compared to representative multimodal baselines, particularly under incomplete data scenarios. Beyond predictive accuracy, BIONIC provides intrinsic interpretability through its latent structure, enabling population-level analysis of modality relevance and supporting clinically meaningful insight.", "AI": {"tldr": "BIONIC\u662f\u4e00\u4e2a\u8d1d\u53f6\u65af\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u96c6\u6210\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u9ad8\u7ef4\u5f02\u6784\u6570\u636e\u548c\u7ed3\u6784\u5316\u7f3a\u5931\uff0c\u901a\u8fc7\u751f\u6210-\u5224\u522b\u8054\u5408\u67b6\u6784\u5b9e\u73b0\u9c81\u68d2\u9884\u6d4b\u548c\u5185\u5728\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u5177\u6709\u9ad8\u7ef4\u5ea6\u3001\u5f02\u6784\u8868\u793a\u548c\u7ed3\u6784\u5316\u7f3a\u5931\u7684\u7279\u70b9\uff0c\u8fd9\u7ed9\u9884\u6d4b\u5efa\u6a21\u3001\u6570\u636e\u96c6\u6210\u548c\u53ef\u89e3\u91ca\u6027\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u7279\u5f81\u3002", "method": "\u63d0\u51faBIONIC\uff08\u8d1d\u53f6\u65af\u975e\u7ebf\u6027\u4e0d\u5b8c\u5168\u4e34\u5e8a\u6570\u636e\u96c6\u6210\uff09\u6846\u67b6\uff0c\u91c7\u7528\u8054\u5408\u751f\u6210-\u5224\u522b\u6f5c\u5728\u67b6\u6784\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u5d4c\u5165\u5904\u7406\u533b\u5b66\u56fe\u50cf\u548c\u4e34\u5e8a\u6587\u672c\u7b49\u590d\u6742\u6a21\u6001\uff0c\u5c06\u7ed3\u6784\u5316\u4e34\u5e8a\u53d8\u91cf\u76f4\u63a5\u7eb3\u5165\u8d1d\u53f6\u65af\u591a\u6a21\u6001\u516c\u5f0f\u4e2d\uff0c\u663e\u5f0f\u5efa\u6a21\u6a21\u6001\u7ea7\u548c\u53d8\u91cf\u7ea7\u7f3a\u5931\u4ee5\u53ca\u7f3a\u5931\u6807\u7b7e\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u4e34\u5e8a\u548c\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4ee3\u8868\u6027\u591a\u6a21\u6001\u57fa\u7ebf\u65b9\u6cd5\uff0cBIONIC\u8868\u73b0\u51fa\u5f3a\u5927\u4e14\u4e00\u81f4\u7684\u5224\u522b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4e0d\u5b8c\u5168\u6570\u636e\u573a\u666f\u4e0b\u3002\u9664\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u5916\uff0c\u8fd8\u901a\u8fc7\u6f5c\u5728\u7ed3\u6784\u63d0\u4f9b\u5185\u5728\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "BIONIC\u4e3a\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u96c6\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6982\u7387\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5f02\u6784\u6570\u636e\u548c\u7f3a\u5931\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u89e3\u91ca\uff0c\u652f\u6301\u6a21\u6001\u76f8\u5173\u6027\u5206\u6790\u548c\u4e34\u5e8a\u6d1e\u5bdf\u3002"}}
{"id": "2602.01935", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.01935", "abs": "https://arxiv.org/abs/2602.01935", "authors": ["Annabelle Sujun Tang", "Christopher Priebe", "Lianhui Qin", "Hadi Esmaeilzadeh"], "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation", "comment": null, "summary": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.", "AI": {"tldr": "COLT\uff1a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u591aLLM\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eabMCTS\u6811\u5b9e\u73b0\u7f16\u8bd1\u5668\u4f18\u5316\uff0c\u7528\u5c0f\u6a21\u578b\u4e3a\u4e3b\u3001\u5927\u6a21\u578b\u4e3a\u8f85\u7684\u534f\u4f5c\u65b9\u5f0f\u964d\u4f4e\u63a8\u7406\u6210\u672c", "motivation": "\u6a21\u578b\u670d\u52a1\u6210\u672c\u4e3b\u5bfcAI\u7cfb\u7edf\uff0c\u7f16\u8bd1\u5668\u4f18\u5316\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u5355\u4e2a\u5927\u6a21\u578b\u6210\u672c\u9ad8\uff0c\u800c\u5c0f\u6a21\u578b\u5355\u72ec\u4f7f\u7528\u4e0d\u53ef\u9760\u3002\u672c\u6587\u63a2\u7d22\u591aLLM\u534f\u4f5c\u80fd\u5426\u8fbe\u5230\u6216\u8d85\u8d8a\u5355\u4e2a\u5927\u6a21\u578b\u7684\u6027\u80fd", "method": "\u63d0\u51faCOLT\u6846\u67b6\uff0c\u5728\u5355\u4e2aMCTS\u8fc7\u7a0b\u4e2d\u534f\u8c03\u591a\u4e2a\u6a21\u578b\u3002\u4f7f\u7528\u5171\u4eabMCTS\u6811\u4f5c\u4e3a\u534f\u4f5c\u57fa\u7840\uff0c\u652f\u6301\u8f6c\u6362\u524d\u7f00\u91cd\u7528\u548c\u8de8\u6a21\u578b\u4ef7\u503c\u4f20\u64ad\u3002\u6bcf\u4e2a\u8fed\u4ee3\u4e2d\uff0c\u5f53\u524dLLM\u63d0\u51fa\u8054\u5408\u52a8\u4f5c\uff08\u7f16\u8bd1\u5668\u8f6c\u6362\uff0c\u4e0b\u4e00\u4e2a\u67e5\u8be2\u7684\u6a21\u578b\uff09\u3002\u5f15\u5165\u6a21\u578b\u611f\u77e5\u6811\u7b56\u7565\uff08\u504f\u5411\u5c0f\u6a21\u578b\u4f46\u4fdd\u6301\u63a2\u7d22\uff09\u548c\u822a\u5411\u4fee\u6b63\u673a\u5236\uff08\u5f53\u641c\u7d22\u6301\u7eed\u9000\u5316\u65f6\u5347\u7ea7\u5230\u5927\u6a21\u578b\uff09", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u6846\u67b6\u8bbe\u8ba1\u8868\u660e\u80fd\u591f\u964d\u4f4e\u63a8\u7406\u6210\u672c\u540c\u65f6\u4fdd\u6301\u4f18\u5316\u6027\u80fd", "conclusion": "\u901a\u8fc7\u8f7b\u91cf\u7ea7\u591aLLM\u534f\u4f5c\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u7f16\u8bd1\u5668\u4f18\u5316\u4e2d\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u5e73\u8861\uff0c\u907f\u514d\u4f20\u7edf\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u590d\u6742\u673a\u5236"}}
{"id": "2602.01936", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01936", "abs": "https://arxiv.org/abs/2602.01936", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen"], "title": "PIMCST: Physics-Informed Multi-Phase Consensus and Spatio-Temporal Few-Shot Learning for Traffic Flow Forecasting", "comment": null, "summary": "Accurate traffic flow prediction remains a fundamental challenge in intelligent transportation systems, particularly in cross-domain, data-scarce scenarios where limited historical data hinders model training and generalisation. The complex spatio-temporal dependencies and nonlinear dynamics of urban mobility networks further complicate few-shot learning across different cities. This paper proposes MCPST, a novel Multi-phase Consensus Spatio-Temporal framework for few-shot traffic forecasting that reconceptualises traffic prediction as a multi-phase consensus learning problem. Our framework introduces three core innovations: (1) a multi-phase engine that models traffic dynamics through diffusion, synchronisation, and spectral embeddings for comprehensive dynamic characterisation; (2) an adaptive consensus mechanism that dynamically fuses phase-specific predictions while enforcing consistency; and (3) a structured meta-learning strategy for rapid adaptation to new cities with minimal data. We establish extensive theoretical guarantees, including representation theorems with bounded approximation errors and generalisation bounds for few-shot adaptation. Through experiments on four real-world datasets, MCPST outperforms fourteen state-of-the-art methods in spatio-temporal graph learning methods, dynamic graph transfer learning methods, prompt-based spatio-temporal prediction methods and cross-domain few-shot settings, improving prediction accuracy while reducing required training data and providing interpretable insights. The implementation code is available at https://github.com/afofanah/MCPST.", "AI": {"tldr": "MCPST\u662f\u4e00\u4e2a\u7528\u4e8e\u5c11\u6837\u672c\u4ea4\u901a\u9884\u6d4b\u7684\u591a\u9636\u6bb5\u5171\u8bc6\u65f6\u7a7a\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u4ea4\u901a\u52a8\u6001\u7684\u6269\u6563\u3001\u540c\u6b65\u548c\u8c31\u5d4c\u5165\uff0c\u52a8\u6001\u878d\u5408\u9636\u6bb5\u7279\u5b9a\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528\u7ed3\u6784\u5316\u5143\u5b66\u4e60\u5feb\u901f\u9002\u5e94\u65b0\u57ce\u5e02\uff0c\u5728\u5c11\u6570\u636e\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\uff0c\u8de8\u57df\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684\u51c6\u786e\u4ea4\u901a\u6d41\u9884\u6d4b\u662f\u4e00\u4e2a\u6839\u672c\u6027\u6311\u6218\u3002\u6709\u9650\u7684\u5386\u53f2\u6570\u636e\u963b\u788d\u4e86\u6a21\u578b\u8bad\u7ec3\u548c\u6cdb\u5316\uff0c\u800c\u57ce\u5e02\u79fb\u52a8\u7f51\u7edc\u7684\u590d\u6742\u65f6\u7a7a\u4f9d\u8d56\u6027\u548c\u975e\u7ebf\u6027\u52a8\u6001\u8fdb\u4e00\u6b65\u4f7f\u4e0d\u540c\u57ce\u5e02\u95f4\u7684\u5c11\u6837\u672c\u5b66\u4e60\u53d8\u5f97\u590d\u6742\u3002", "method": "\u63d0\u51faMCPST\u6846\u67b6\uff0c\u5c06\u4ea4\u901a\u9884\u6d4b\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u591a\u9636\u6bb5\u5171\u8bc6\u5b66\u4e60\u95ee\u9898\u3002\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a1\uff09\u591a\u9636\u6bb5\u5f15\u64ce\uff0c\u901a\u8fc7\u6269\u6563\u3001\u540c\u6b65\u548c\u8c31\u5d4c\u5165\u5efa\u6a21\u4ea4\u901a\u52a8\u6001\uff1b2\uff09\u81ea\u9002\u5e94\u5171\u8bc6\u673a\u5236\uff0c\u52a8\u6001\u878d\u5408\u9636\u6bb5\u7279\u5b9a\u9884\u6d4b\u5e76\u5f3a\u5236\u4e00\u81f4\u6027\uff1b3\uff09\u7ed3\u6784\u5316\u5143\u5b66\u4e60\u7b56\u7565\uff0c\u7528\u6700\u5c11\u6570\u636e\u5feb\u901f\u9002\u5e94\u65b0\u57ce\u5e02\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMCPST\u5728\u65f6\u7a7a\u56fe\u5b66\u4e60\u65b9\u6cd5\u3001\u52a8\u6001\u56fe\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u65f6\u7a7a\u9884\u6d4b\u65b9\u6cd5\u548c\u8de8\u57df\u5c11\u6837\u672c\u8bbe\u7f6e\u4e2d\uff0c\u4f18\u4e8e14\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u6240\u9700\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u89c1\u89e3\u3002", "conclusion": "MCPST\u901a\u8fc7\u591a\u9636\u6bb5\u5171\u8bc6\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u57df\u5c11\u6837\u672c\u4ea4\u901a\u9884\u6d4b\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01937", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01937", "abs": "https://arxiv.org/abs/2602.01937", "authors": ["Suhan Guo", "Bingxu Wang", "Shaodan Zhang", "Furao Shen"], "title": "T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation", "comment": null, "summary": "Time series forecasting plays a critical role in decision-making across many real-world applications. Unlike data in vision and language domains, time series data is inherently tied to the evolution of underlying processes and can only accumulate as real-world time progresses, limiting the effectiveness of scale-driven pretraining alone. This time-bound constraint poses a challenge for enabling large language models (LLMs) to acquire forecasting capability, as existing approaches primarily rely on representation-level alignment or inference-time temporal modules rather than explicitly teaching forecasting behavior to the LLM. We propose T-LLM, a temporal distillation framework that equips general-purpose LLMs with time series forecasting capability by transferring predictive behavior from a lightweight temporal teacher during training. The teacher combines trend modeling and frequency-domain analysis to provide structured temporal supervision, and is removed entirely at inference, leaving the LLM as the sole forecasting model. Experiments on benchmark datasets and infectious disease forecasting tasks demonstrate that T-LLM consistently outperforms existing LLM-based forecasting methods under full-shot, few-shot, and zero-shot settings, while enabling a simple and efficient deployment pipeline.", "AI": {"tldr": "T-LLM\u662f\u4e00\u4e2a\u65f6\u95f4\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u8f7b\u91cf\u7ea7\u65f6\u95f4\u6559\u5e08\u7684\u9884\u6d4b\u884c\u4e3a\u8f6c\u79fb\u5230\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u4f7f\u5176\u5177\u5907\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u80fd\u529b\uff0c\u5728\u63a8\u7406\u65f6\u65e0\u9700\u989d\u5916\u6a21\u5757\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53d7\u9650\u4e8e\u65f6\u95f4\u6f14\u8fdb\u7279\u6027\uff0c\u65e0\u6cd5\u50cf\u89c6\u89c9\u548c\u8bed\u8a00\u6570\u636e\u90a3\u6837\u901a\u8fc7\u89c4\u6a21\u9a71\u52a8\u9884\u8bad\u7ec3\u83b7\u5f97\u6709\u6548\u9884\u6d4b\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8868\u793a\u5c42\u5bf9\u9f50\u6216\u63a8\u7406\u65f6\u7684\u65f6\u95f4\u6a21\u5757\uff0c\u672a\u80fd\u660e\u786e\u6559\u5bfcLLM\u9884\u6d4b\u884c\u4e3a\u3002", "method": "\u63d0\u51faT-LLM\u65f6\u95f4\u84b8\u998f\u6846\u67b6\uff1a\u4f7f\u7528\u7ed3\u5408\u8d8b\u52bf\u5efa\u6a21\u548c\u9891\u57df\u5206\u6790\u7684\u8f7b\u91cf\u7ea7\u65f6\u95f4\u6559\u5e08\u63d0\u4f9b\u7ed3\u6784\u5316\u65f6\u95f4\u76d1\u7763\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u5c06\u9884\u6d4b\u884c\u4e3a\u8f6c\u79fb\u5230LLM\u4e2d\uff0c\u63a8\u7406\u65f6\u5b8c\u5168\u79fb\u9664\u6559\u5e08\uff0c\u4ec5\u4fdd\u7559LLM\u4f5c\u4e3a\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4f20\u67d3\u75c5\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cT-LLM\u5728\u5168\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u65b9\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u7b80\u5355\u9ad8\u6548\u7684\u90e8\u7f72\u6d41\u7a0b\u3002", "conclusion": "T-LLM\u6210\u529f\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u80fd\u529b\u8d4b\u4e88\u901a\u7528LLM\uff0c\u901a\u8fc7\u65f6\u95f4\u84b8\u998f\u6846\u67b6\u89e3\u51b3\u4e86\u65f6\u95f4\u7ea6\u675f\u4e0b\u7684\u9884\u6d4b\u6311\u6218\uff0c\u4e3aLLM\u5728\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.01949", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01949", "abs": "https://arxiv.org/abs/2602.01949", "authors": ["Leonardo Stoppani", "Davide Bacciu", "Shahab Mokarizadeh"], "title": "Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity", "comment": "Accepted at ESANN 2026", "summary": "Diffusion models have become widely popular for automated floorplan generation, producing highly realistic layouts conditioned on user-defined constraints. However, optimizing for perceptual metrics such as the Fr\u00e9chet Inception Distance (FID) causes limited design diversity. To address this, we propose the Diversity Score (DS), a metric that quantifies layout diversity under fixed constraints. Moreover, to improve geometric consistency, we introduce a Boundary Cross-Attention (BCA) module that enables conditioning on building boundaries. Our experiments show that BCA significantly improves boundary adherence, while prolonged training drives diversity collapse undiagnosed by FID, revealing a critical trade-off between realism and diversity. Out-Of-Distribution evaluations further demonstrate the models' reliance on dataset priors, emphasizing the need for generative systems that explicitly balance fidelity, diversity, and generalization in architectural design tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u591a\u6837\u6027\u8bc4\u5206\uff08DS\uff09\u6765\u91cf\u5316\u56fa\u5b9a\u7ea6\u675f\u4e0b\u7684\u5e03\u5c40\u591a\u6837\u6027\uff0c\u5e76\u5f15\u5165\u8fb9\u754c\u4ea4\u53c9\u6ce8\u610f\u529b\uff08BCA\uff09\u6a21\u5757\u6765\u63d0\u5347\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u63ed\u793a\u4e86\u751f\u6210\u5f0f\u5efa\u7b51\u8bbe\u8ba1\u4e2d\u771f\u5b9e\u6027\u4e0e\u591a\u6837\u6027\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u81ea\u52a8\u5e73\u9762\u56fe\u751f\u6210\u4e2d\u5df2\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u57fa\u4e8eFID\u7b49\u611f\u77e5\u6307\u6807\u7684\u4f18\u5316\u5bfc\u81f4\u8bbe\u8ba1\u591a\u6837\u6027\u6709\u9650\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u591a\u6837\u6027\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u771f\u5b9e\u6027\u3001\u591a\u6837\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u591a\u6837\u6027\u8bc4\u5206\uff08DS\uff09\u6765\u91cf\u5316\u56fa\u5b9a\u7ea6\u675f\u4e0b\u7684\u5e03\u5c40\u591a\u6837\u6027\uff1b\u5f15\u5165\u8fb9\u754c\u4ea4\u53c9\u6ce8\u610f\u529b\uff08BCA\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u5efa\u7b51\u8fb9\u754c\u6765\u63d0\u5347\u51e0\u4f55\u4e00\u81f4\u6027\uff1b\u8fdb\u884c\u957f\u65f6\u95f4\u8bad\u7ec3\u5b9e\u9a8c\u548c\u5206\u5e03\u5916\u8bc4\u4f30\u3002", "result": "BCA\u663e\u8457\u6539\u5584\u4e86\u8fb9\u754c\u9075\u5faa\u6027\uff1b\u957f\u65f6\u95f4\u8bad\u7ec3\u5bfc\u81f4\u591a\u6837\u6027\u5d29\u6e83\uff0c\u800cFID\u672a\u80fd\u68c0\u6d4b\u5230\u8fd9\u4e00\u73b0\u8c61\uff1b\u5206\u5e03\u5916\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5bf9\u6570\u636e\u96c6\u5148\u9a8c\u7684\u4f9d\u8d56\uff0c\u63ed\u793a\u4e86\u771f\u5b9e\u6027\u4e0e\u591a\u6837\u6027\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u3002", "conclusion": "\u5efa\u7b51\u8bbe\u8ba1\u7684\u751f\u6210\u7cfb\u7edf\u9700\u8981\u660e\u786e\u5e73\u8861\u4fdd\u771f\u5ea6\u3001\u591a\u6837\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u63d0\u51fa\u7684DS\u548cBCA\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u5728\u591a\u6837\u6027\u4fdd\u6301\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.01953", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01953", "abs": "https://arxiv.org/abs/2602.01953", "authors": ["Dmitrij Schlesinger", "Boris Flach", "Alexander Shekhovtsov"], "title": "Deep Multivariate Models with Parametric Conditionals", "comment": null, "summary": "We consider deep multivariate models for heterogeneous collections of random variables. In the context of computer vision, such collections may e.g. consist of images, segmentations, image attributes, and latent variables. When developing such models, most existing works start from an application task and design the model components and their dependencies to meet the needs of the chosen task. This has the disadvantage of limiting the applicability of the resulting model for other downstream tasks. Here, instead, we propose to represent the joint probability distribution by means of conditional probability distributions for each group of variables conditioned on the rest. Such models can then be used for practically any possible downstream task. Their learning can be approached as training a parametrised Markov chain kernel by maximising the data likelihood of its limiting distribution. This has the additional advantage of allowing a wide range of semi-supervised learning scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u6df1\u5ea6\u591a\u5143\u6a21\u578b\uff0c\u901a\u8fc7\u8bad\u7ec3\u53c2\u6570\u5316\u9a6c\u5c14\u53ef\u592b\u94fe\u6838\u6765\u5b66\u4e60\u8054\u5408\u5206\u5e03\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u548c\u534a\u76d1\u7763\u5b66\u4e60\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u591a\u5143\u6a21\u578b\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u5e94\u7528\u4efb\u52a1\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u5728\u5176\u4ed6\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u6982\u7387\u5206\u5e03\u8868\u793a\u8054\u5408\u6982\u7387\u5206\u5e03\uff0c\u5c06\u6bcf\u4e2a\u53d8\u91cf\u7ec4\u57fa\u4e8e\u5176\u4ed6\u53d8\u91cf\u8fdb\u884c\u6761\u4ef6\u5efa\u6a21\u3002\u901a\u8fc7\u6700\u5927\u5316\u6570\u636e\u4f3c\u7136\u6765\u8bad\u7ec3\u53c2\u6570\u5316\u9a6c\u5c14\u53ef\u592b\u94fe\u6838\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u8868\u793a\u5f02\u6784\u53d8\u91cf\u96c6\u5408\u7684\u8054\u5408\u5206\u5e03\uff0c\u9002\u7528\u4e8e\u51e0\u4e4e\u6240\u6709\u53ef\u80fd\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u652f\u6301\u5e7f\u6cdb\u7684\u534a\u76d1\u7763\u5b66\u4e60\u573a\u666f\u3002", "conclusion": "\u57fa\u4e8e\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u6df1\u5ea6\u591a\u5143\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u7075\u6d3b\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.01956", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01956", "abs": "https://arxiv.org/abs/2602.01956", "authors": ["Seonghyeon Park", "Jewon Yeom", "Jaewon Sok", "Jeongjae Park", "Heejun Kim", "Taesup Kim"], "title": "Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation", "comment": null, "summary": "Quantifying uncertainty in Large Language Models (LLMs) is essential for mitigating hallucinations and enabling risk-aware deployment in safety-critical tasks. However, estimating Epistemic Uncertainty(EU) via Deep Ensembles is computationally prohibitive at the scale of modern models. We propose a framework that leverages the small draft models to efficiently estimate token-level EU, bypassing the need for full-scale ensembling. Theoretically grounded in a Bias-Variance Decomposition, our approach approximates EU via Jensen-Shannon divergence among drafts (variance proxy) and KL divergence between the draft mixture and the target (bias proxy). To further ensure accuracy without significant overhead, we introduce Online Stochastic Distillation (OSD) to efficiently approximate target aggregation and the Data-Diverse Drafts (DDD) strategy to enhance draft diversity for better target approximation. Extensive experiments on GSM8K demonstrate that our method reduces the estimation error (RMSE) by up to 37% compared to baselines. Crucially, our approach achieves Hallucination Detection performance competitive with heavy perturbation-based methods like TokUR while incurring negligible inference costs, offering a practical solution for uncertainty-aware LLM deployment.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u5c0f\u578b\u8349\u7a3f\u6a21\u578b\u9ad8\u6548\u4f30\u8ba1LLM\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u6846\u67b6\uff0c\u907f\u514d\u5927\u89c4\u6a21\u96c6\u6210\u8ba1\u7b97\u5f00\u9500", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5bf9\u4e8e\u51cf\u5c11\u5e7b\u89c9\u548c\u5b89\u5168\u5173\u952e\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u901a\u8fc7\u6df1\u5ea6\u96c6\u6210\u4f30\u8ba1\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5728\u6a21\u578b\u89c4\u6a21\u4e0b\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8", "method": "\u57fa\u4e8e\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\u7406\u8bba\u6846\u67b6\uff0c\u4f7f\u7528\u8349\u7a3f\u6a21\u578b\u95f4\u7684Jensen-Shannon\u6563\u5ea6\u8fd1\u4f3c\u65b9\u5dee\uff0c\u8349\u7a3f\u6df7\u5408\u4e0e\u76ee\u6807\u95f4\u7684KL\u6563\u5ea6\u8fd1\u4f3c\u504f\u5dee\uff1b\u5f15\u5165\u5728\u7ebf\u968f\u673a\u84b8\u998f\u9ad8\u6548\u8fd1\u4f3c\u76ee\u6807\u805a\u5408\uff0c\u4ee5\u53ca\u6570\u636e\u591a\u6837\u5316\u8349\u7a3f\u7b56\u7565\u589e\u5f3a\u591a\u6837\u6027", "result": "\u5728GSM8K\u4e0a\u4f30\u8ba1\u8bef\u5dee\uff08RMSE\uff09\u964d\u4f4e\u8fbe37%\uff0c\u5e7b\u89c9\u68c0\u6d4b\u6027\u80fd\u4e0e\u8ba1\u7b97\u5bc6\u96c6\u578b\u65b9\u6cd5\u76f8\u5f53\u4f46\u63a8\u7406\u6210\u672c\u53ef\u5ffd\u7565", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5LLM\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500"}}
{"id": "2602.01960", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01960", "abs": "https://arxiv.org/abs/2602.01960", "authors": ["Christos Ziakas", "Amir Bar", "Alessandra Russo"], "title": "Grounding Generated Videos in Feasible Plans via World Models", "comment": null, "summary": "Large-scale video generative models have shown emerging capabilities as zero-shot visual planners, yet video-generated plans often violate temporal consistency and physical constraints, leading to failures when mapped to executable actions. To address this, we propose Grounding Video Plans with World Models (GVP-WM), a planning method that grounds video-generated plans into feasible action sequences using a learned action-conditioned world model. At test-time, GVP-WM first generates a video plan from initial and goal observations, then projects the video guidance onto the manifold of dynamically feasible latent trajectories via video-guided latent collocation. In particular, we formulate grounding as a goal-conditioned latent-space trajectory optimization problem that jointly optimizes latent states and actions under world-model dynamics, while preserving semantic alignment with the video-generated plan. Empirically, GVP-WM recovers feasible long-horizon plans from zero-shot image-to-video-generated and motion-blurred videos that violate physical constraints, across navigation and manipulation simulation tasks.", "AI": {"tldr": "\u63d0\u51faGVP-WM\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u5c06\u89c6\u9891\u751f\u6210\u8ba1\u5212\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u52a8\u4f5c\u5e8f\u5217\uff0c\u89e3\u51b3\u89c6\u9891\u8ba1\u5212\u8fdd\u53cd\u7269\u7406\u7ea6\u675f\u7684\u95ee\u9898", "motivation": "\u5927\u89c4\u6a21\u89c6\u9891\u751f\u6210\u6a21\u578b\u4f5c\u4e3a\u96f6\u6837\u672c\u89c6\u89c9\u89c4\u5212\u5668\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u751f\u6210\u7684\u89c6\u9891\u8ba1\u5212\u7ecf\u5e38\u8fdd\u53cd\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u7269\u7406\u7ea6\u675f\uff0c\u5bfc\u81f4\u6620\u5c04\u5230\u53ef\u6267\u884c\u52a8\u4f5c\u65f6\u5931\u8d25", "method": "GVP-WM\u65b9\u6cd5\uff1a1) \u4ece\u521d\u59cb\u548c\u76ee\u6807\u89c2\u5bdf\u751f\u6210\u89c6\u9891\u8ba1\u5212\uff1b2) \u901a\u8fc7\u89c6\u9891\u5f15\u5bfc\u7684\u6f5c\u5728\u5171\u4f4d\u6cd5\u5c06\u89c6\u9891\u5f15\u5bfc\u6295\u5f71\u5230\u52a8\u6001\u53ef\u884c\u7684\u6f5c\u5728\u8f68\u8ff9\u6d41\u5f62\u4e0a\uff1b3) \u5c06\u63a5\u5730\u95ee\u9898\u8868\u8ff0\u4e3a\u76ee\u6807\u6761\u4ef6\u6f5c\u5728\u7a7a\u95f4\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u5728\u4e16\u754c\u6a21\u578b\u52a8\u6001\u7ea6\u675f\u4e0b\u8054\u5408\u4f18\u5316\u6f5c\u5728\u72b6\u6001\u548c\u52a8\u4f5c\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u89c6\u9891\u8ba1\u5212\u7684\u8bed\u4e49\u5bf9\u9f50", "result": "GVP-WM\u80fd\u591f\u4ece\u8fdd\u53cd\u7269\u7406\u7ea6\u675f\u7684\u96f6\u6837\u672c\u56fe\u50cf\u5230\u89c6\u9891\u751f\u6210\u548c\u8fd0\u52a8\u6a21\u7cca\u89c6\u9891\u4e2d\u6062\u590d\u53ef\u884c\u7684\u957f\u65f6\u7a0b\u8ba1\u5212\uff0c\u5728\u5bfc\u822a\u548c\u64cd\u4f5c\u6a21\u62df\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548", "conclusion": "\u63d0\u51fa\u7684GVP-WM\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u89c6\u9891\u751f\u6210\u8ba1\u5212\u63a5\u5730\u5230\u53ef\u884c\u7684\u52a8\u4f5c\u5e8f\u5217\u4e2d\uff0c\u89e3\u51b3\u4e86\u89c6\u9891\u8ba1\u5212\u8fdd\u53cd\u7269\u7406\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u4e3a\u89c6\u89c9\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01962", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01962", "abs": "https://arxiv.org/abs/2602.01962", "authors": ["Arip Asadulaev", "Maksim Bobrin", "Salem Lahlou", "Dmitry Dylov", "Fakhri Karray", "Martin Takac"], "title": "Zero-Shot Off-Policy Learning", "comment": null, "summary": "Off-policy learning methods seek to derive an optimal policy directly from a fixed dataset of prior interactions. This objective presents significant challenges, primarily due to the inherent distributional shift and value function overestimation bias. These issues become even more noticeable in zero-shot reinforcement learning, where an agent trained on reward-free data must adapt to new tasks at test time without additional training. In this work, we address the off-policy problem in a zero-shot setting by discovering a theoretical connection of successor measures to stationary density ratios. Using this insight, our algorithm can infer optimal importance sampling ratios, effectively performing a stationary distribution correction with an optimal policy for any task on the fly. We benchmark our method in motion tracking tasks on SMPL Humanoid, continuous control on ExoRL, and for the long-horizon OGBench tasks. Our technique seamlessly integrates into forward-backward representation frameworks and enables fast-adaptation to new tasks in a training-free regime. More broadly, this work bridges off-policy learning and zero-shot adaptation, offering benefits to both research areas.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u96f6\u6837\u672c\u5f3a\u5316\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u89e3\u51b3\u79bb\u7b56\u7565\u5b66\u4e60\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u7acb\u540e\u7ee7\u5ea6\u91cf\u4e0e\u5e73\u7a33\u5bc6\u5ea6\u6bd4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5feb\u901f\u9002\u5e94\u65b0\u4efb\u52a1\u7684\u80fd\u529b\u3002", "motivation": "\u79bb\u7b56\u7565\u5b66\u4e60\u76f4\u63a5\u4ece\u56fa\u5b9a\u6570\u636e\u96c6\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u9762\u4e34\u5206\u5e03\u504f\u79fb\u548c\u4ef7\u503c\u51fd\u6570\u9ad8\u4f30\u504f\u5dee\u7684\u6311\u6218\uff0c\u5728\u96f6\u6837\u672c\u5f3a\u5316\u5b66\u4e60\u4e2d\u5c24\u4e3a\u7a81\u51fa\uff0c\u56e0\u4e3a\u667a\u80fd\u4f53\u5fc5\u987b\u5728\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b0\u4efb\u52a1\u800c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "method": "\u901a\u8fc7\u53d1\u73b0\u540e\u7ee7\u5ea6\u91cf\u4e0e\u5e73\u7a33\u5bc6\u5ea6\u6bd4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u63d0\u51fa\u7b97\u6cd5\u53ef\u4ee5\u63a8\u65ad\u6700\u4f18\u91cd\u8981\u6027\u91c7\u6837\u6bd4\uff0c\u5b9e\u73b0\u5bf9\u4efb\u610f\u4efb\u52a1\u7684\u5e73\u7a33\u5206\u5e03\u6821\u6b63\uff0c\u5e76\u96c6\u6210\u5230\u524d\u5411-\u540e\u5411\u8868\u793a\u6846\u67b6\u4e2d\u3002", "result": "\u5728SMPL Humanoid\u7684\u8fd0\u52a8\u8ddf\u8e2a\u4efb\u52a1\u3001ExoRL\u7684\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4ee5\u53ca\u957f\u65f6\u57dfOGBench\u4efb\u52a1\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5feb\u901f\u9002\u5e94\u65b0\u4efb\u52a1\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5728\u79bb\u7b56\u7565\u5b66\u4e60\u548c\u96f6\u6837\u672c\u9002\u5e94\u4e4b\u95f4\u5efa\u7acb\u4e86\u6865\u6881\uff0c\u4e3a\u4e24\u4e2a\u7814\u7a76\u9886\u57df\u90fd\u5e26\u6765\u4e86\u76ca\u5904\uff0c\u5b9e\u73b0\u4e86\u5728\u8bad\u7ec3\u81ea\u7531\u673a\u5236\u4e0b\u5bf9\u65b0\u4efb\u52a1\u7684\u5feb\u901f\u9002\u5e94\u3002"}}
{"id": "2602.01966", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01966", "abs": "https://arxiv.org/abs/2602.01966", "authors": ["Hongzhuo Yu", "Fei Zhu", "Guo-Sen Xie", "Ling Shao"], "title": "Self-Consolidation for Self-Evolving Agents", "comment": null, "summary": "While large language model (LLM) agents have demonstrated impressive problem-solving capabilities, they typically operate as static systems, lacking the ability to evolve through lifelong interaction. Existing attempts to bridge this gap primarily rely on retrieving successful past trajectories as demonstrations. However, this paradigm faces two critical limitations. First, by focusing solely on success, agents overlook the rich pedagogical value embedded in failed attempts, preventing them from identifying and avoiding recurrent pitfalls. Second, continually accumulating textual experiences not only increases the time consumption during retrieval but also inevitably introduces noise and exhausts the largest context window of current LLMs. To address these challenges, we propose a novel self-evolving framework for LLM agents that introduces a complementary evolution mechanism: First, a contrastive reflection strategy is introduced to explicitly summarize error-prone patterns and capture reusable insights. Second, we propose a self-consolidation mechanism that distills non-parametric textual experience into compact learnable parameters. This enables the agent to internalize extensive historical experience directly into its latent space. Extensive experiments demonstrate the advantages of our method in long-term agent evolution.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdLLM\u667a\u80fd\u4f53\u81ea\u6211\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u53cd\u601d\u603b\u7ed3\u9519\u8bef\u6a21\u5f0f\uff0c\u5e76\u5c06\u6587\u672c\u7ecf\u9a8c\u84b8\u998f\u4e3a\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u5b9e\u73b0\u957f\u671f\u8fdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u901a\u5e38\u662f\u9759\u6001\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u901a\u8fc7\u7ec8\u8eab\u4ea4\u4e92\u8fdb\u5316\u7684\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u68c0\u7d22\u6210\u529f\u8f68\u8ff9\u4f5c\u4e3a\u6f14\u793a\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1) \u53ea\u5173\u6ce8\u6210\u529f\u800c\u5ffd\u7565\u4e86\u5931\u8d25\u5c1d\u8bd5\u4e2d\u7684\u6559\u5b66\u4ef7\u503c\uff1b2) \u6301\u7eed\u79ef\u7d2f\u6587\u672c\u7ecf\u9a8c\u4f1a\u589e\u52a0\u68c0\u7d22\u65f6\u95f4\u3001\u5f15\u5165\u566a\u58f0\u5e76\u8017\u5c3d\u4e0a\u4e0b\u6587\u7a97\u53e3", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u6211\u8fdb\u5316\u6846\u67b6\uff1a1) \u5f15\u5165\u5bf9\u6bd4\u53cd\u601d\u7b56\u7565\uff0c\u660e\u786e\u603b\u7ed3\u6613\u9519\u6a21\u5f0f\u5e76\u6355\u6349\u53ef\u91cd\u7528\u89c1\u89e3\uff1b2) \u63d0\u51fa\u81ea\u6211\u6574\u5408\u673a\u5236\uff0c\u5c06\u975e\u53c2\u6570\u5316\u6587\u672c\u7ecf\u9a8c\u84b8\u998f\u4e3a\u7d27\u51d1\u7684\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5c06\u5e7f\u6cdb\u7684\u5386\u53f2\u7ecf\u9a8c\u5185\u5316\u5230\u5176\u6f5c\u5728\u7a7a\u95f4\u4e2d", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u957f\u671f\u667a\u80fd\u4f53\u8fdb\u5316\u65b9\u9762\u7684\u4f18\u52bf", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5bf9\u6bd4\u53cd\u601d\u548c\u7ecf\u9a8c\u84b8\u998f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u667a\u80fd\u4f53\u8fdb\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u957f\u671f\u5b66\u4e60\u548c\u9002\u5e94\u80fd\u529b"}}
{"id": "2602.01975", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01975", "abs": "https://arxiv.org/abs/2602.01975", "authors": ["Meng Li", "Peisong Wang", "Yuantian Shao", "Qinghao Hu", "Hongjian Fang", "Yifan Zhang", "Zhihui Wei", "Jian Cheng"], "title": "IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs", "comment": null, "summary": "Large Language Models (LLMs) achieve strong performance across diverse tasks but face deployment challenges due to their massive size. Structured pruning offers acceleration benefits but leads to significant performance degradation. Recent PCA-based pruning methods have alleviated this issue by retaining key activation components, but are only applied between modules in order to fuse the transformation matrix, which introduces extra parameters and severely disrupts activation distributions due to residual connections. To address these issues, we propose IntraSlice, a framework that applies block-wise module-intra PCA compression pruning. By leveraging the structural characteristics of Transformer modules, we design an approximate PCA method whose transformation matrices can be fully fused into the model without additional parameters. We also introduce a PCA-based global pruning ratio estimator that further considers the distribution of compressed activations, building on conventional module importance. We validate our method on Llama2, Llama3, and Phi series across various language benchmarks. Experimental results demonstrate that our approach achieves superior compression performance compared to recent baselines at the same compression ratio or inference speed.", "AI": {"tldr": "IntraSlice\uff1a\u4e00\u79cd\u57fa\u4e8e\u6a21\u5757\u5185PCA\u538b\u7f29\u526a\u679d\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8fd1\u4f3cPCA\u65b9\u6cd5\u548c\u5168\u5c40\u526a\u679d\u6bd4\u4f8b\u4f30\u8ba1\u5668\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u6a21\u578b\u538b\u7f29", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u9762\u4e34\u5de8\u5927\u89c4\u6a21\u6311\u6218\uff0c\u7ed3\u6784\u5316\u526a\u679d\u867d\u7136\u80fd\u52a0\u901f\u4f46\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u73b0\u6709PCA\u526a\u679d\u65b9\u6cd5\u4ec5\u5728\u6a21\u5757\u95f4\u5e94\u7528\uff0c\u5f15\u5165\u989d\u5916\u53c2\u6570\u4e14\u6b8b\u5dee\u8fde\u63a5\u4f1a\u4e25\u91cd\u7834\u574f\u6fc0\u6d3b\u5206\u5e03", "method": "\u63d0\u51faIntraSlice\u6846\u67b6\uff0c\u91c7\u7528\u6a21\u5757\u5185\u5757\u7ea7PCA\u538b\u7f29\u526a\u679d\u3002\u5229\u7528Transformer\u6a21\u5757\u7ed3\u6784\u7279\u6027\u8bbe\u8ba1\u8fd1\u4f3cPCA\u65b9\u6cd5\uff0c\u5176\u53d8\u6362\u77e9\u9635\u53ef\u5b8c\u5168\u878d\u5408\u5230\u6a21\u578b\u4e2d\u800c\u4e0d\u589e\u52a0\u53c2\u6570\u3002\u5f15\u5165\u57fa\u4e8ePCA\u7684\u5168\u5c40\u526a\u679d\u6bd4\u4f8b\u4f30\u8ba1\u5668\uff0c\u5728\u4f20\u7edf\u6a21\u5757\u91cd\u8981\u6027\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u8003\u8651\u538b\u7f29\u6fc0\u6d3b\u7684\u5206\u5e03", "result": "\u5728Llama2\u3001Llama3\u548cPhi\u7cfb\u5217\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u5728\u5404\u79cd\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u76f8\u540c\u538b\u7f29\u6bd4\u6216\u63a8\u7406\u901f\u5ea6\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u4f18\u7684\u538b\u7f29\u6027\u80fd", "conclusion": "IntraSlice\u901a\u8fc7\u6a21\u5757\u5185PCA\u538b\u7f29\u526a\u679d\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u7684\u6a21\u578b\u538b\u7f29\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.01976", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01976", "abs": "https://arxiv.org/abs/2602.01976", "authors": ["Hongwei Yan", "Guanglong Sun", "Kanglei Zhou", "Qian Li", "Liyuan Wang", "Yi Zhong"], "title": "FlyPrompt: Brain-Inspired Random-Expanded Routing with Temporal-Ensemble Experts for General Continual Learning", "comment": "33 pages. Accepted by ICLR 2026", "summary": "General continual learning (GCL) challenges intelligent systems to learn from single-pass, non-stationary data streams without clear task boundaries. While recent advances in continual parameter-efficient tuning (PET) of pretrained models show promise, they typically rely on multiple training epochs and explicit task cues, limiting their effectiveness in GCL scenarios. Moreover, existing methods often lack targeted design and fail to address two fundamental challenges in continual PET: how to allocate expert parameters to evolving data distributions, and how to improve their representational capacity under limited supervision. Inspired by the fruit fly's hierarchical memory system characterized by sparse expansion and modular ensembles, we propose FlyPrompt, a brain-inspired framework that decomposes GCL into two subproblems: expert routing and expert competence improvement. FlyPrompt introduces a randomly expanded analytic router for instance-level expert activation and a temporal ensemble of output heads to dynamically adapt decision boundaries over time. Extensive theoretical and empirical evaluations demonstrate FlyPrompt's superior performance, achieving up to 11.23%, 12.43%, and 7.62% gains over state-of-the-art baselines on CIFAR-100, ImageNet-R, and CUB-200, respectively. Our source code is available at https://github.com/AnAppleCore/FlyGCL.", "AI": {"tldr": "FlyPrompt\u662f\u4e00\u4e2a\u53d7\u679c\u8747\u5927\u8111\u542f\u53d1\u7684\u901a\u7528\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u8def\u7531\u548c\u4e13\u5bb6\u80fd\u529b\u6539\u8fdb\u89e3\u51b3\u5355\u6b21\u8bad\u7ec3\u3001\u65e0\u4efb\u52a1\u8fb9\u754c\u7684\u6301\u7eed\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6301\u7eed\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u591a\u8f6e\u8bad\u7ec3\u548c\u660e\u786e\u7684\u4efb\u52a1\u8fb9\u754c\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u901a\u7528\u6301\u7eed\u5b66\u4e60\u573a\u666f\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u9488\u5bf9\u6027\u8bbe\u8ba1\uff0c\u672a\u80fd\u89e3\u51b3\u4e24\u4e2a\u6838\u5fc3\u6311\u6218\uff1a\u5982\u4f55\u4e3a\u6f14\u5316\u6570\u636e\u5206\u5e03\u5206\u914d\u4e13\u5bb6\u53c2\u6570\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u6709\u9650\u76d1\u7763\u4e0b\u63d0\u5347\u8868\u5f81\u80fd\u529b\u3002", "method": "\u53d7\u679c\u8747\u5206\u5c42\u8bb0\u5fc6\u7cfb\u7edf\u542f\u53d1\uff0cFlyPrompt\u5c06\u901a\u7528\u6301\u7eed\u5b66\u4e60\u5206\u89e3\u4e3a\u4e13\u5bb6\u8def\u7531\u548c\u4e13\u5bb6\u80fd\u529b\u6539\u8fdb\u4e24\u4e2a\u5b50\u95ee\u9898\u3002\u5f15\u5165\u968f\u673a\u6269\u5c55\u7684\u5206\u6790\u8def\u7531\u5668\u8fdb\u884c\u5b9e\u4f8b\u7ea7\u4e13\u5bb6\u6fc0\u6d3b\uff0c\u5e76\u4f7f\u7528\u8f93\u51fa\u5934\u7684\u65f6\u5e8f\u96c6\u6210\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u8fb9\u754c\u3002", "result": "\u5728CIFAR-100\u3001ImageNet-R\u548cCUB-200\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8611.23%\u300112.43%\u548c7.62%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "FlyPrompt\u901a\u8fc7\u8111\u542f\u53d1\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u901a\u7528\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u4e13\u5bb6\u53c2\u6570\u5206\u914d\u548c\u8868\u5f81\u80fd\u529b\u63d0\u5347\u95ee\u9898\uff0c\u4e3a\u5355\u6b21\u8bad\u7ec3\u3001\u65e0\u4efb\u52a1\u8fb9\u754c\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.01990", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01990", "abs": "https://arxiv.org/abs/2602.01990", "authors": ["Zhen-Hao Xie", "Jun-Tao Tang", "Yu-Cheng Shi", "Han-Jia Ye", "De-Chuan Zhan", "Da-Wei Zhou"], "title": "SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) achieve strong performance through instruction tuning, but real-world deployment requires them to continually expand their capabilities, making Multimodal Continual Instruction Tuning (MCIT) essential. Recent methods leverage sparse expert routing to promote task specialization, but we find that the expert routing process suffers from drift as the data distribution evolves. For example, a grounding query that previously activated localization experts may instead be routed to irrelevant experts after learning OCR tasks. Meanwhile, the grounding-related experts can be overwritten by new tasks and lose their original functionality. Such failure reflects two problems: router drift, where expert selection becomes inconsistent over time, and expert drift, where shared experts are overwritten across tasks. Therefore, we propose StAbilized Mixture-of-Experts (SAME) for MCIT. To address router drift, SAME stabilizes expert selection by decomposing routing dynamics into orthogonal subspaces and updating only task-relevant directions. To mitigate expert drift, we regulate expert updates via curvature-aware scaling using historical input covariance in a rehearsal-free manner. SAME also introduces adaptive expert activation to freeze selected experts during training, reducing redundant computation and cross-task interference. Extensive experiments demonstrate its SOTA performance.", "AI": {"tldr": "SAME\u65b9\u6cd5\u901a\u8fc7\u6b63\u4ea4\u5b50\u7a7a\u95f4\u5206\u89e3\u7a33\u5b9a\u4e13\u5bb6\u9009\u62e9\uff0c\u5229\u7528\u5386\u53f2\u8f93\u5165\u534f\u65b9\u5dee\u8fdb\u884c\u66f2\u7387\u611f\u77e5\u7f29\u653e\u6765\u7f13\u89e3\u4e13\u5bb6\u6f02\u79fb\uff0c\u5b9e\u73b0\u65e0\u6392\u7ec3\u7684\u591a\u6a21\u6001\u6301\u7eed\u6307\u4ee4\u8c03\u4f18", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u6301\u7eed\u6269\u5c55\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u7a00\u758f\u4e13\u5bb6\u8def\u7531\u65b9\u6cd5\u5b58\u5728\u4e13\u5bb6\u8def\u7531\u6f02\u79fb\u548c\u4e13\u5bb6\u529f\u80fd\u88ab\u8986\u76d6\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d", "method": "\u63d0\u51faSAME\u65b9\u6cd5\uff1a1) \u5c06\u8def\u7531\u52a8\u6001\u5206\u89e3\u5230\u6b63\u4ea4\u5b50\u7a7a\u95f4\uff0c\u53ea\u66f4\u65b0\u4efb\u52a1\u76f8\u5173\u65b9\u5411\u6765\u7a33\u5b9a\u4e13\u5bb6\u9009\u62e9\uff1b2) \u5229\u7528\u5386\u53f2\u8f93\u5165\u534f\u65b9\u5dee\u8fdb\u884c\u66f2\u7387\u611f\u77e5\u7f29\u653e\u6765\u8c03\u8282\u4e13\u5bb6\u66f4\u65b0\uff1b3) \u5f15\u5165\u81ea\u9002\u5e94\u4e13\u5bb6\u6fc0\u6d3b\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u65f6\u51bb\u7ed3\u9009\u5b9a\u4e13\u5bb6", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eSAME\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73", "conclusion": "SAME\u901a\u8fc7\u7a33\u5b9a\u4e13\u5bb6\u8def\u7531\u548c\u8c03\u8282\u4e13\u5bb6\u66f4\u65b0\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u8def\u7531\u6f02\u79fb\u548c\u4e13\u5bb6\u6f02\u79fb\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b"}}
{"id": "2602.01997", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01997", "abs": "https://arxiv.org/abs/2602.01997", "authors": ["Safal Shrestha", "Anubhav Shrestha", "Aadim Nepal", "Minwu Kim", "Keith Ross"], "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs", "comment": null, "summary": "Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.", "AI": {"tldr": "\u5c42\u526a\u679d\u80fd\u538b\u7f29\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u4fdd\u6301\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u5728\u751f\u6210\u5f0f\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e25\u91cd\u9000\u5316\uff0c\u7279\u522b\u662f\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u3002\u901a\u8fc7\u81ea\u751f\u6210\u54cd\u5e94\u7684\u76d1\u7763\u5fae\u8c03\u53ef\u4ee5\u90e8\u5206\u6062\u590d\u6027\u80fd\uff0c\u4f46\u751f\u6210\u63a8\u7406\u7684\u6062\u590d\u4ecd\u6709\u6839\u672c\u6027\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u5c42\u526a\u679d\u6280\u672f\u5728\u538b\u7f29\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u867d\u7136\u80fd\u4fdd\u6301\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u5728\u751f\u6210\u5f0f\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e25\u91cd\u9000\u5316\u3002\u9700\u8981\u7814\u7a76\u6df1\u5ea6\u51cf\u5c11\u5bf9\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u7d22\u5728\u6709\u9650\u540e\u8bad\u7ec3\u8d44\u6e90\u4e0b\u7684\u6062\u590d\u7b56\u7565\u3002", "method": "1. \u7cfb\u7edf\u7814\u7a76\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\uff0c\u5206\u6790\u6df1\u5ea6\u51cf\u5c11\u5bf9\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u7684\u5f71\u54cd\uff1b2. \u8bc4\u4f30\u7b97\u6cd5\u80fd\u529b\u9000\u5316\uff0c\u5305\u62ec\u7b97\u672f\u8ba1\u7b97\u548c\u62ec\u53f7\u5e73\u8861\u751f\u6210\uff1b3. \u5728\u6709\u9650\u540e\u8bad\u7ec3\u8d44\u6e90\u4e0b\uff0c\u91c7\u7528\u57fa\u4e8e\u81ea\u751f\u6210\u54cd\u5e94\u7684\u76d1\u7763\u5fae\u8c03\u4f5c\u4e3a\u7f13\u89e3\u7b56\u7565\u3002", "result": "1. \u5206\u7c7b\u4efb\u52a1\u53ef\u6062\u590d90%\u57fa\u7ebf\u6027\u80fd\uff1b2. \u751f\u6210\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u76f8\u6bd4\u5148\u524d\u540e\u526a\u679d\u6280\u672f\u63d0\u534720-30\u4e2a\u767e\u5206\u70b9\uff1b3. \u4f46\u751f\u6210\u63a8\u7406\u7684\u6062\u590d\u4ecd\u6709\u6839\u672c\u6027\u9650\u5236\uff0c\u4e3b\u8981\u9002\u7528\u4e8e\u8f83\u4f4e\u526a\u679d\u6bd4\u4f8b\u3002", "conclusion": "\u5c42\u526a\u679d\u5bf9\u751f\u6210\u5f0f\u63a8\u7406\u5b58\u5728\u5b9e\u8df5\u9650\u5236\uff0c\u6df1\u5ea6\u51cf\u5c11\u4e3b\u8981\u5728\u8f83\u4f4e\u526a\u679d\u6bd4\u4f8b\u4e0b\u6709\u6548\u3002\u7814\u7a76\u4e3a\u53d7\u9650\u540e\u8bad\u7ec3\u673a\u5236\u4e0b\u7684\u6df1\u5ea6\u51cf\u5c11\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2602.02001", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02001", "abs": "https://arxiv.org/abs/2602.02001", "authors": ["Yoonjun Cho", "Dongjae Jeon", "Soeun Kim", "Moongyu Jeon", "Albert No"], "title": "Preserve-Then-Quantize: Balancing Rank Budgets for Quantization Error Reconstruction in LLMs", "comment": null, "summary": "Quantization Error Reconstruction (QER) reduces accuracy loss in Post-Training Quantization (PTQ) by approximating weights as $\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$, using a rank-$r$ correction to reconstruct quantization error. Prior methods devote the full rank budget to error reconstruction, which is suboptimal when $\\mathbf{W}$ has intrinsic low-rank structure and quantization corrupts dominant directions. We propose Structured Residual Reconstruction (SRR), a rank-allocation framework that preserves the top-$k$ singular subspace of the activation-scaled weight before quantization, quantizes only the residual, and uses the remaining rank $r-k$ for error reconstruction. We derive a theory-guided criterion for selecting $k$ by balancing quantization-exposed energy and unrecoverable error under rank constraints. We further show that resulting $\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ parameterization naturally supports Quantized Parameter-Efficient Fine-Tuning (QPEFT), and stabilizes fine-tuning via gradient scaling along preserved directions. Experiments demonstrate consistent perplexity reductions across diverse models and quantization settings in PTQ, along with a 5.9 percentage-point average gain on GLUE under 2-bit QPEFT.", "AI": {"tldr": "SRR\u63d0\u51fa\u7ed3\u6784\u5316\u6b8b\u5dee\u91cd\u5efa\u6846\u67b6\uff0c\u5728\u91cf\u5316\u8bef\u5dee\u91cd\u5efa\u4e2d\u4fdd\u7559\u6743\u91cd\u7684\u4e3b\u8981\u5947\u5f02\u5b50\u7a7a\u95f4\uff0c\u5e73\u8861\u91cf\u5316\u66b4\u9732\u80fd\u91cf\u4e0e\u4e0d\u53ef\u6062\u590d\u8bef\u5dee\uff0c\u63d0\u5347PTQ\u7cbe\u5ea6\u5e76\u652f\u6301QPEFT\u3002", "motivation": "\u73b0\u6709\u91cf\u5316\u8bef\u5dee\u91cd\u5efa\u65b9\u6cd5\u5c06\u6240\u6709\u79e9\u9884\u7b97\u7528\u4e8e\u8bef\u5dee\u91cd\u5efa\uff0c\u5f53\u6743\u91cd\u5177\u6709\u5185\u5728\u4f4e\u79e9\u7ed3\u6784\u4e14\u91cf\u5316\u7834\u574f\u4e3b\u5bfc\u65b9\u5411\u65f6\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u662f\u6700\u4f18\u7684\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u6b8b\u5dee\u91cd\u5efa(SRR)\uff1a1) \u4fdd\u7559\u6fc0\u6d3b\u7f29\u653e\u6743\u91cd\u7684top-k\u5947\u5f02\u5b50\u7a7a\u95f4\uff1b2) \u4ec5\u91cf\u5316\u6b8b\u5dee\u90e8\u5206\uff1b3) \u4f7f\u7528\u5269\u4f59\u79e9(r-k)\u8fdb\u884c\u8bef\u5dee\u91cd\u5efa\u3002\u7406\u8bba\u6307\u5bfc\u9009\u62e9k\u503c\uff0c\u5e73\u8861\u91cf\u5316\u66b4\u9732\u80fd\u91cf\u4e0e\u79e9\u7ea6\u675f\u4e0b\u7684\u4e0d\u53ef\u6062\u590d\u8bef\u5dee\u3002", "result": "\u5728PTQ\u4e2d\uff0cSRR\u5728\u4e0d\u540c\u6a21\u578b\u548c\u91cf\u5316\u8bbe\u7f6e\u4e0b\u6301\u7eed\u964d\u4f4e\u56f0\u60d1\u5ea6\uff1b\u57282\u4f4dQPEFT\u4e0b\uff0cGLUE\u4efb\u52a1\u5e73\u5747\u63d0\u53475.9\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "SRR\u901a\u8fc7\u7ed3\u6784\u5316\u79e9\u5206\u914d\u6846\u67b6\uff0c\u5728\u91cf\u5316\u8bef\u5dee\u91cd\u5efa\u4e2d\u66f4\u597d\u5730\u5e73\u8861\u6743\u91cd\u7ed3\u6784\u4fdd\u7559\u4e0e\u8bef\u5dee\u6821\u6b63\uff0c\u63d0\u5347\u91cf\u5316\u6a21\u578b\u7cbe\u5ea6\u5e76\u652f\u6301\u7a33\u5b9a\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3002"}}
{"id": "2602.02009", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02009", "abs": "https://arxiv.org/abs/2602.02009", "authors": ["Ali Baheri"], "title": "Logic-Guided Vector Fields for Constrained Generative Modeling", "comment": null, "summary": "Neuro-symbolic systems aim to combine the expressive structure of symbolic logic with the flexibility of neural learning; yet, generative models typically lack mechanisms to enforce declarative constraints at generation time. We propose Logic-Guided Vector Fields (LGVF), a neuro-symbolic framework that injects symbolic knowledge, specified as differentiable relaxations of logical constraints, into flow matching generative models. LGVF couples two complementary mechanisms: (1) a training-time logic loss that penalizes constraint violations along continuous flow trajectories, with weights that emphasize correctness near the target distribution; and (2) an inference-time adjustment that steers sampling using constraint gradients, acting as a lightweight, logic-informed correction to the learned dynamics. We evaluate LGVF on three constrained generation case studies spanning linear, nonlinear, and multi-region feasibility constraints. Across all settings, LGVF reduces constraint violations by 59-82% compared to standard flow matching and achieves the lowest violation rates in each case. In the linear and ring settings, LGVF also improves distributional fidelity as measured by MMD, while in the multi-obstacle setting, we observe a satisfaction-fidelity trade-off, with improved feasibility but increased MMD. Beyond quantitative gains, LGVF yields constraint-aware vector fields exhibiting emergent obstacle-avoidance behavior, routing samples around forbidden regions without explicit path planning.", "AI": {"tldr": "LGVF\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u5f15\u5bfc\u7684\u5411\u91cf\u573a\u5c06\u7b26\u53f7\u7ea6\u675f\u6ce8\u5165\u6d41\u5339\u914d\u751f\u6210\u6a21\u578b\uff0c\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u903b\u8f91\u635f\u5931\uff0c\u63a8\u7406\u65f6\u4f7f\u7528\u7ea6\u675f\u68af\u5ea6\u8c03\u6574\u91c7\u6837\uff0c\u663e\u8457\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u65e8\u5728\u7ed3\u5408\u7b26\u53f7\u903b\u8f91\u7684\u8868\u8fbe\u7ed3\u6784\u548c\u795e\u7ecf\u5b66\u4e60\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u73b0\u6709\u751f\u6210\u6a21\u578b\u7f3a\u4e4f\u5728\u751f\u6210\u65f6\u5f3a\u5236\u6267\u884c\u58f0\u660e\u6027\u7ea6\u675f\u7684\u673a\u5236\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5c06\u7b26\u53f7\u77e5\u8bc6\u6ce8\u5165\u751f\u6210\u8fc7\u7a0b\uff0c\u786e\u4fdd\u751f\u6210\u6837\u672c\u6ee1\u8db3\u903b\u8f91\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u903b\u8f91\u5f15\u5bfc\u5411\u91cf\u573a\uff08LGVF\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u673a\u5236\uff1a1\uff09\u8bad\u7ec3\u65f6\u903b\u8f91\u635f\u5931\uff0c\u6cbf\u8fde\u7eed\u6d41\u8f68\u8ff9\u60e9\u7f5a\u7ea6\u675f\u8fdd\u53cd\uff0c\u6743\u91cd\u5f3a\u8c03\u76ee\u6807\u5206\u5e03\u9644\u8fd1\u7684\u6b63\u786e\u6027\uff1b2\uff09\u63a8\u7406\u65f6\u8c03\u6574\uff0c\u4f7f\u7528\u7ea6\u675f\u68af\u5ea6\u5f15\u5bfc\u91c7\u6837\uff0c\u4f5c\u4e3a\u5bf9\u5b66\u4e60\u52a8\u529b\u5b66\u7684\u8f7b\u91cf\u7ea7\u903b\u8f91\u4fee\u6b63\u3002", "result": "\u5728\u4e09\u4e2a\u7ea6\u675f\u751f\u6210\u6848\u4f8b\uff08\u7ebf\u6027\u3001\u975e\u7ebf\u6027\u548c\u591a\u533a\u57df\u53ef\u884c\u6027\u7ea6\u675f\uff09\u4e2d\uff0cLGVF\u76f8\u6bd4\u6807\u51c6\u6d41\u5339\u914d\u5c06\u7ea6\u675f\u8fdd\u53cd\u51cf\u5c1159-82%\uff0c\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u8fbe\u5230\u6700\u4f4e\u8fdd\u53cd\u7387\u3002\u5728\u7ebf\u6027\u548c\u73af\u5f62\u8bbe\u7f6e\u4e2d\uff0cLGVF\u8fd8\u63d0\u9ad8\u4e86\u5206\u5e03\u4fdd\u771f\u5ea6\uff08MMD\uff09\uff0c\u5728\u591a\u969c\u788d\u8bbe\u7f6e\u4e2d\u89c2\u5bdf\u5230\u53ef\u884c\u6027-\u4fdd\u771f\u5ea6\u6743\u8861\u3002", "conclusion": "LGVF\u6210\u529f\u5c06\u7b26\u53f7\u7ea6\u675f\u6ce8\u5165\u751f\u6210\u6a21\u578b\uff0c\u663e\u8457\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\uff0c\u4ea7\u751f\u5177\u6709\u6d8c\u73b0\u907f\u969c\u884c\u4e3a\u7684\u7ea6\u675f\u611f\u77e5\u5411\u91cf\u573a\uff0c\u65e0\u9700\u663e\u5f0f\u8def\u5f84\u89c4\u5212\u5373\u53ef\u7ed5\u8fc7\u7981\u6b62\u533a\u57df\uff0c\u5c55\u793a\u4e86\u795e\u7ecf\u7b26\u53f7\u751f\u6210\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.02013", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02013", "abs": "https://arxiv.org/abs/2602.02013", "authors": ["Xiaoyi Jiang", "Andreas Nienk\u00f6tter"], "title": "SNAP: A Self-Consistent Agreement Principle with Application to Robust Computation", "comment": null, "summary": "We introduce SNAP (Self-coNsistent Agreement Principle), a self-supervised framework for robust computation based on mutual agreement. Based on an Agreement-Reliability Hypothesis SNAP assigns weights that quantify agreement, emphasizing trustworthy items and downweighting outliers without supervision or prior knowledge. A key result is the Exponential Suppression of Outlier Weights, ensuring that outliers contribute negligibly to computations, even in high-dimensional settings. We study properties of SNAP weighting scheme and show its practical benefits on vector averaging and subspace estimation. Particularly, we demonstrate that non-iterative SNAP outperforms the iterative Weiszfeld algorithm and two variants of multivariate median of means. SNAP thus provides a flexible, easy-to-use, broadly applicable approach to robust computation.", "AI": {"tldr": "SNAP\u662f\u4e00\u4e2a\u57fa\u4e8e\u76f8\u4e92\u4e00\u81f4\u6027\u7684\u81ea\u76d1\u7763\u9c81\u68d2\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u4e00\u81f4\u6027-\u53ef\u9760\u6027\u5047\u8bbe\u4e3a\u6570\u636e\u9879\u5206\u914d\u6743\u91cd\uff0c\u5f3a\u8c03\u53ef\u4fe1\u9879\u76ee\u5e76\u6291\u5236\u5f02\u5e38\u503c\uff0c\u65e0\u9700\u76d1\u7763\u6216\u5148\u9a8c\u77e5\u8bc6\u3002", "motivation": "\u4f20\u7edf\u9c81\u68d2\u8ba1\u7b97\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8fed\u4ee3\u4f18\u5316\u6216\u5148\u9a8c\u77e5\u8bc6\uff0cSNAP\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u6613\u4e8e\u4f7f\u7528\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u9c81\u68d2\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u65b9\u5f0f\u81ea\u52a8\u8bc6\u522b\u548c\u6291\u5236\u5f02\u5e38\u503c\u3002", "method": "\u57fa\u4e8e\u4e00\u81f4\u6027-\u53ef\u9760\u6027\u5047\u8bbe\uff0cSNAP\u901a\u8fc7\u91cf\u5316\u6570\u636e\u9879\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u6765\u5206\u914d\u6743\u91cd\uff0c\u5f3a\u8c03\u53ef\u4fe1\u9879\u76ee\u5e76\u964d\u4f4e\u5f02\u5e38\u503c\u7684\u5f71\u54cd\u3002\u5173\u952e\u7279\u6027\u662f\u5f02\u5e38\u503c\u6743\u91cd\u7684\u6307\u6570\u6291\u5236\uff0c\u786e\u4fdd\u5f02\u5e38\u503c\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e2d\u5bf9\u8ba1\u7b97\u8d21\u732e\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "result": "SNAP\u5728\u5411\u91cf\u5e73\u5747\u548c\u5b50\u7a7a\u95f4\u4f30\u8ba1\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u975e\u8fed\u4ee3\u7684SNAP\u4f18\u4e8e\u8fed\u4ee3\u7684Weiszfeld\u7b97\u6cd5\u548c\u4e24\u79cd\u591a\u5143\u4e2d\u4f4d\u6570\u5747\u503c\u53d8\u4f53\uff0c\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u4f18\u52bf\u3002", "conclusion": "SNAP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u6613\u4e8e\u4f7f\u7528\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u9c81\u68d2\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u7684\u4e00\u81f4\u6027\u539f\u5219\u6709\u6548\u6291\u5236\u5f02\u5e38\u503c\uff0c\u4e3a\u9c81\u68d2\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.02015", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02015", "abs": "https://arxiv.org/abs/2602.02015", "authors": ["Jewon Yeom", "Kyubyung Chae", "Hyunggyu Lim", "Yoonna Oh", "Dongyoon Yang", "Taesup Kim"], "title": "Robust Domain Generalization under Divergent Marginal and Conditional Distributions", "comment": null, "summary": "Domain generalization (DG) aims to learn predictive models that can generalize to unseen domains. Most existing DG approaches focus on learning domain-invariant representations under the assumption of conditional distribution shift (i.e., primarily addressing changes in $P(X\\mid Y)$ while assuming $P(Y)$ remains stable). However, real-world scenarios with multiple domains often involve compound distribution shifts where both the marginal label distribution $P(Y)$ and the conditional distribution $P(X\\mid Y)$ vary simultaneously. To address this, we propose a unified framework for robust domain generalization under divergent marginal and conditional distributions. We derive a novel risk bound for unseen domains by explicitly decomposing the joint distribution into marginal and conditional components and characterizing risk gaps arising from both sources of divergence. To operationalize this bound, we design a meta-learning procedure that minimizes and validates the proposed risk bound across seen domains, ensuring strong generalization to unseen ones. Empirical evaluations demonstrate that our method achieves state-of-the-art performance not only on conventional DG benchmarks but also in challenging multi-domain long-tailed recognition settings where both marginal and conditional shifts are pronounced.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u57df\u6cdb\u5316\u6846\u67b6\uff0c\u540c\u65f6\u5904\u7406\u8fb9\u9645\u5206\u5e03P(Y)\u548c\u6761\u4ef6\u5206\u5e03P(X|Y)\u7684\u590d\u5408\u5206\u5e03\u504f\u79fb\uff0c\u901a\u8fc7\u5206\u89e3\u98ce\u9669\u8fb9\u754c\u548c\u5143\u5b66\u4e60\u5b9e\u73b0\u9c81\u68d2\u6cdb\u5316\u3002", "motivation": "\u73b0\u6709\u57df\u6cdb\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6761\u4ef6\u5206\u5e03\u504f\u79fb(P(X|Y)\u53d8\u5316)\uff0c\u5047\u8bbeP(Y)\u7a33\u5b9a\u3002\u4f46\u73b0\u5b9e\u591a\u57df\u573a\u666f\u4e2d\uff0c\u8fb9\u9645\u6807\u7b7e\u5206\u5e03P(Y)\u548c\u6761\u4ef6\u5206\u5e03P(X|Y)\u5e38\u540c\u65f6\u53d8\u5316\uff0c\u9700\u8981\u5904\u7406\u590d\u5408\u5206\u5e03\u504f\u79fb\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff1a1) \u63a8\u5bfc\u672a\u89c1\u57df\u7684\u98ce\u9669\u8fb9\u754c\uff0c\u663e\u5f0f\u5206\u89e3\u8fb9\u9645\u548c\u6761\u4ef6\u5206\u5e03\u5206\u91cf\uff1b2) \u8bbe\u8ba1\u5143\u5b66\u4e60\u7a0b\u5e8f\uff0c\u6700\u5c0f\u5316\u5e76\u9a8c\u8bc1\u6240\u63d0\u98ce\u9669\u8fb9\u754c\uff0c\u786e\u4fdd\u5bf9\u672a\u89c1\u57df\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u65b9\u6cd5\u5728\u4f20\u7edf\u57df\u6cdb\u5316\u57fa\u51c6\u548c\u5177\u6709\u663e\u8457\u8fb9\u9645\u4e0e\u6761\u4ef6\u504f\u79fb\u7684\u591a\u57df\u957f\u5c3e\u8bc6\u522b\u573a\u666f\u4e2d\uff0c\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5904\u7406\u590d\u5408\u5206\u5e03\u504f\u79fb\uff0c\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u57df\u6cdb\u5316\uff0c\u7279\u522b\u662f\u5728\u73b0\u5b9e\u4e16\u754c\u591a\u57df\u573a\u666f\u4e2d\u3002"}}
{"id": "2602.02016", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02016", "abs": "https://arxiv.org/abs/2602.02016", "authors": ["Ionut-Vlad Modoranu", "Philip Zmushko", "Erik Schultheis", "Mher Safaryan", "Dan Alistarh"], "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers", "comment": null, "summary": "Shampoo is one of the leading approximate second-order optimizers: a variant of it has won the MLCommons AlgoPerf competition, and it has been shown to produce models with lower activation outliers that are easier to compress. Yet, applying Shampoo currently comes at the cost of significant computational slowdown, due to its expensive internal operations. In this paper, we take a significant step to address this shortcoming by proposing \\method (for \\textbf{D}istributed \\textbf{A}ccelerated \\textbf{SH}ampoo), a faster implementation of Distributed Shampoo based on two main new techniques: First, we show that preconditioner blocks can be stacked into 3D tensors to significantly improve GPU utilization; second, we introduce the Newton-DB iteration and the Chebyshev polynomial approximations as novel and faster approaches for computing the inverse matrix roots required by Shampoo. Along with these algorithmic contributions, we provide a first in-depth analysis of how matrix scaling critically affects Shampoo convergence. On the practical side, our GPU-aware implementation achieves up to $4.83\\times$ faster optimizer steps compared to the well-optimized Distributed Shampoo, while Newton-DB attains the lowest validation perplexity per iteration among all tested methods. Our code is available at https://github.com/IST-DASLab/DASH.", "AI": {"tldr": "DASH\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u5feb\u7684\u5206\u5e03\u5f0fShampoo\u4f18\u5316\u5668\u5b9e\u73b0\uff0c\u901a\u8fc73D\u5f20\u91cf\u5806\u53e0\u548c\u65b0\u7684\u77e9\u9635\u6839\u9006\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5728GPU\u4e0a\u5b9e\u73b0\u4e864.83\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u597d\u7684\u6536\u655b\u6027\u80fd\u3002", "motivation": "Shampoo\u4f5c\u4e3a\u9886\u5148\u7684\u8fd1\u4f3c\u4e8c\u9636\u4f18\u5316\u5668\uff0c\u5728MLCommons AlgoPerf\u7ade\u8d5b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u4ea7\u751f\u66f4\u6613\u538b\u7f29\u7684\u6a21\u578b\u3002\u4f46\u5f53\u524d\u5b9e\u73b0\u5b58\u5728\u663e\u8457\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86DASH\uff08\u5206\u5e03\u5f0f\u52a0\u901fShampoo\uff09\uff0c\u5305\u542b\u4e24\u9879\u6838\u5fc3\u6280\u672f\uff1a1\uff09\u5c06\u9884\u5904\u7406\u5668\u5757\u5806\u53e0\u62103D\u5f20\u91cf\u4ee5\u63d0\u9ad8GPU\u5229\u7528\u7387\uff1b2\uff09\u5f15\u5165Newton-DB\u8fed\u4ee3\u548c\u5207\u6bd4\u96ea\u592b\u591a\u9879\u5f0f\u903c\u8fd1\u4f5c\u4e3a\u8ba1\u7b97\u77e9\u9635\u6839\u9006\u7684\u65b0\u65b9\u6cd5\u3002\u540c\u65f6\u5206\u6790\u4e86\u77e9\u9635\u7f29\u653e\u5bf9\u6536\u655b\u7684\u5173\u952e\u5f71\u54cd\u3002", "result": "GPU\u611f\u77e5\u5b9e\u73b0\u76f8\u6bd4\u4f18\u5316\u540e\u7684\u5206\u5e03\u5f0fShampoo\u5b9e\u73b0\u4e86\u9ad8\u8fbe4.83\u500d\u7684\u4f18\u5316\u5668\u6b65\u9aa4\u52a0\u901f\u3002Newton-DB\u5728\u6240\u6709\u6d4b\u8bd5\u65b9\u6cd5\u4e2d\u83b7\u5f97\u4e86\u6bcf\u8fed\u4ee3\u6700\u4f4e\u7684\u9a8c\u8bc1\u56f0\u60d1\u5ea6\u3002", "conclusion": "DASH\u663e\u8457\u63d0\u5347\u4e86Shampoo\u4f18\u5316\u5668\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4f7f\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u5177\u53ef\u884c\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f18\u8d8a\u7684\u6536\u655b\u6027\u80fd\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.02045", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02045", "abs": "https://arxiv.org/abs/2602.02045", "authors": ["Yiming Yang", "Xiaoyuan Cheng", "Yi He", "Kaiyu Li", "Wenxuan Yuan", "Zhuo Sun"], "title": "On Stability and Robustness of Diffusion Posterior Sampling for Bayesian Inverse Problems", "comment": null, "summary": "Diffusion models have recently emerged as powerful learned priors for Bayesian inverse problems (BIPs). Diffusion-based solvers rely on a presumed likelihood for the observations in BIPs to guide the generation process. However, the link between likelihood and recovery quality for BIPs is unclear in previous works. We bridge this gap by characterizing the posterior approximation error and proving the \\emph{stability} of the diffusion-based solvers. Meanwhile, an immediate result of our findings on stability demonstrates the lack of robustness in diffusion-based solvers, which remains unexplored. This can degrade performance when the presumed likelihood mismatches the unknown true data generation processes. To address this issue, we propose a simple yet effective solution, \\emph{robust diffusion posterior sampling}, which is provably \\emph{robust} and compatible with existing gradient-based posterior samplers. Empirical results on scientific inverse problems and natural image tasks validate the effectiveness and robustness of our method, showing consistent performance improvements under challenging likelihood misspecifications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u7684\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u5728\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u4e2d\u56e0\u4f3c\u7136\u51fd\u6570\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5df2\u6210\u4e3a\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u7684\u5f3a\u5927\u5148\u9a8c\uff0c\u4f46\u73b0\u6709\u6269\u6563\u6c42\u89e3\u5668\u4f9d\u8d56\u4e8e\u9884\u8bbe\u7684\u89c2\u6d4b\u4f3c\u7136\u51fd\u6570\u3002\u5f53\u9884\u8bbe\u4f3c\u7136\u4e0e\u771f\u5b9e\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4e0d\u5339\u914d\u65f6\uff0c\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u73b0\u6709\u5de5\u4f5c\u7f3a\u4e4f\u5bf9\u8fd9\u79cd\u9c81\u68d2\u6027\u95ee\u9898\u7684\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u9c81\u68d2\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0e\u73b0\u6709\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u540e\u9a8c\u91c7\u6837\u5668\u517c\u5bb9\uff0c\u80fd\u591f\u5904\u7406\u4f3c\u7136\u51fd\u6570\u4e0d\u5339\u914d\u7684\u60c5\u51b5\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u6269\u6563\u6c42\u89e3\u5668\u7684\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5176\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u63d0\u51fa\u7684\u9c81\u68d2\u65b9\u6cd5\u5728\u79d1\u5b66\u9006\u95ee\u9898\u548c\u81ea\u7136\u56fe\u50cf\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u4f3c\u7136\u4e0d\u5339\u914d\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u6269\u6563\u6a21\u578b\u5728\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u4e2d\u4f3c\u7136\u51fd\u6570\u4e0e\u6062\u590d\u8d28\u91cf\u5173\u7cfb\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u9c81\u68d2\u6269\u6563\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u4f3c\u7136\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.02047", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02047", "abs": "https://arxiv.org/abs/2602.02047", "authors": ["Peijie Dong", "Ruibo Fan", "Yuechen Tao", "Di Mou", "Wenhu Hu", "Zhenheng Tang", "Yinghao Yu", "Jiamang Wang", "Wenbo Su", "Guodong Yang", "Liping Zhang", "Xiaowen Chu", "Baochun Li", "Bo Li"], "title": "Dissecting Outlier Dynamics in LLM NVFP4 Pretraining", "comment": "39 pages, 32 figures", "summary": "Training large language models using 4-bit arithmetic enhances throughput and memory efficiency. Yet, the limited dynamic range of FP4 increases sensitivity to outliers. While NVFP4 mitigates quantization error via hierarchical microscaling, a persistent loss gap remains compared to BF16. This study conducts a longitudinal analysis of outlier dynamics across architecture during NVFP4 pretraining, focusing on where they localize, why they occur, and how they evolve temporally. We find that, compared with Softmax Attention (SA), Linear Attention (LA) reduces per-tensor heavy tails but still exhibits persistent block-level spikes under block quantization. Our analysis attributes outliers to specific architectural components: Softmax in SA, gating in LA, and SwiGLU in FFN, with \"post-QK\" operations exhibiting higher sensitivity to quantization. Notably, outliers evolve from transient spikes early in training to a small set of persistent hot channels (i.e., channels with persistently large magnitudes) in later stages. Based on these findings, we introduce Hot-Channel Patch (HCP), an online compensation mechanism that identifies hot channels and reinjects residuals using hardware-efficient kernels. We then develop CHON, an NVFP4 training recipe integrating HCP with post-QK operation protection. On GLA-1.3B model trained for 60B tokens, CHON reduces the loss gap to BF16 from 0.94% to 0.58% while maintaining downstream accuracy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86NVFP4\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u4e2d\u7684\u5f02\u5e38\u503c\u95ee\u9898\uff0c\u53d1\u73b0Softmax Attention\u3001Linear Attention\u548cSwiGLU\u7b49\u7ec4\u4ef6\u662f\u5f02\u5e38\u503c\u4e3b\u8981\u6765\u6e90\uff0c\u5e76\u63d0\u51faHot-Channel Patch\u5728\u7ebf\u8865\u507f\u673a\u5236\uff0c\u5c06BF16\u7684\u635f\u5931\u5dee\u8ddd\u4ece0.94%\u964d\u81f30.58%\u3002", "motivation": "\u4f7f\u75284\u4f4d\u7b97\u672f\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u63d0\u9ad8\u541e\u5410\u91cf\u548c\u5185\u5b58\u6548\u7387\uff0c\u4f46FP4\u7684\u52a8\u6001\u8303\u56f4\u6709\u9650\u589e\u52a0\u4e86\u5bf9\u5f02\u5e38\u503c\u7684\u654f\u611f\u6027\u3002\u867d\u7136NVFP4\u901a\u8fc7\u5206\u5c42\u5fae\u7f29\u653e\u51cf\u8f7b\u91cf\u5316\u8bef\u5dee\uff0c\u4f46\u4e0eBF16\u76f8\u6bd4\u4ecd\u5b58\u5728\u635f\u5931\u5dee\u8ddd\u3002\u9700\u8981\u6df1\u5165\u5206\u6790\u5f02\u5e38\u503c\u52a8\u6001\u4ee5\u6539\u8fdb\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u3002", "method": "1) \u7eb5\u5411\u5206\u6790NVFP4\u9884\u8bad\u7ec3\u4e2d\u7684\u5f02\u5e38\u503c\u52a8\u6001\uff0c\u5305\u62ec\u5b9a\u4f4d\u3001\u6210\u56e0\u548c\u6f14\u5316\uff1b2) \u53d1\u73b0Softmax Attention\u3001Linear Attention\u548cSwiGLU\u662f\u5f02\u5e38\u503c\u4e3b\u8981\u6765\u6e90\uff1b3) \u63d0\u51faHot-Channel Patch\u5728\u7ebf\u8865\u507f\u673a\u5236\uff0c\u8bc6\u522b\u70ed\u901a\u9053\u5e76\u91cd\u65b0\u6ce8\u5165\u6b8b\u5dee\uff1b4) \u5f00\u53d1CHON\u8bad\u7ec3\u914d\u65b9\uff0c\u7ed3\u5408HCP\u548c\u540eQK\u64cd\u4f5c\u4fdd\u62a4\u3002", "result": "\u5728GLA-1.3B\u6a21\u578b\u4e0a\u8bad\u7ec360B tokens\uff0cCHON\u5c06NVFP4\u4e0eBF16\u7684\u635f\u5931\u5dee\u8ddd\u4ece0.94%\u964d\u81f30.58%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\u3002\u5f02\u5e38\u503c\u4ece\u65e9\u671f\u8bad\u7ec3\u7684\u77ac\u65f6\u5c16\u5cf0\u6f14\u53d8\u4e3a\u540e\u671f\u5c11\u91cf\u6301\u4e45\u70ed\u901a\u9053\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790NVFP4\u8bad\u7ec3\u4e2d\u7684\u5f02\u5e38\u503c\u52a8\u6001\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u5f02\u5e38\u503c\u6765\u6e90\u7ec4\u4ef6\uff0c\u5e76\u63d0\u51fa\u7684Hot-Channel Patch\u5728\u7ebf\u8865\u507f\u673a\u5236\u6709\u6548\u51cf\u5c11\u4e86\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u7684\u635f\u5931\u5dee\u8ddd\uff0c\u4e3a\u9ad8\u65484\u4f4d\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02055", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02055", "abs": "https://arxiv.org/abs/2602.02055", "authors": ["Nan Qiao", "Sheng Yue"], "title": "FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification", "comment": "accetped by IEEE International Conference on Communications (ICC 2026)", "summary": "In Internet-of-Things systems, federated learning has advanced online reinforcement learning (RL) by enabling parallel policy training without sharing raw data. However, interacting with real environments online can be risky and costly, motivating offline federated RL (FRL), where local devices learn from fixed datasets. Despite its promise, offline FRL may break down under low-quality, heterogeneous data. Offline RL tends to get stuck in local optima, and in FRL, one device's suboptimal policy can degrade the aggregated model, i.e., policy pollution. We present FORLER, combining Q-ensemble aggregation on the server with actor rectification on devices. The server robustly merges device Q-functions to curb policy pollution and shift heavy computation off resource-constrained hardware without compromising privacy. Locally, actor rectification enriches policy gradients via a zeroth-order search for high-Q actions plus a bespoke regularizer that nudges the policy toward them. A $\u03b4$-periodic strategy further reduces local computation. We theoretically provide safe policy improvement performance guarantees. Extensive experiments show FORLER consistently outperforms strong baselines under varying data quality and heterogeneity.", "AI": {"tldr": "FORLER\uff1a\u4e00\u79cd\u7ed3\u5408\u670d\u52a1\u5668\u7aefQ-ensemble\u805a\u5408\u548c\u8bbe\u5907\u7aefactor rectification\u7684\u79bb\u7ebf\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u6570\u636e\u5f02\u6784\u6027\u548c\u4f4e\u8d28\u91cf\u6570\u636e\u5bfc\u81f4\u7684\u7b56\u7565\u6c61\u67d3\u95ee\u9898", "motivation": "\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\uff0c\u5728\u7ebf\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u5b58\u5728\u98ce\u9669\u548c\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u800c\u79bb\u7ebf\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u5728\u4f4e\u8d28\u91cf\u3001\u5f02\u6784\u6570\u636e\u4e0b\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u4e00\u4e2a\u8bbe\u5907\u7684\u6b21\u4f18\u7b56\u7565\u4f1a\u6c61\u67d3\u805a\u5408\u6a21\u578b\uff08\u7b56\u7565\u6c61\u67d3\uff09", "method": "1) \u670d\u52a1\u5668\u7aef\uff1aQ-ensemble\u805a\u5408\uff0c\u9c81\u68d2\u5408\u5e76\u8bbe\u5907Q\u51fd\u6570\u4ee5\u6291\u5236\u7b56\u7565\u6c61\u67d3\uff0c\u5c06\u8ba1\u7b97\u8d1f\u62c5\u4ece\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u8f6c\u79fb\uff1b2) \u8bbe\u5907\u7aef\uff1aactor rectification\uff0c\u901a\u8fc7\u96f6\u9636\u641c\u7d22\u5bfb\u627e\u9ad8Q\u503c\u52a8\u4f5c\uff0c\u52a0\u4e0a\u5b9a\u5236\u6b63\u5219\u5316\u5668\u5c06\u7b56\u7565\u63a8\u5411\u8fd9\u4e9b\u52a8\u4f5c\uff1b3) \u03b4-\u5468\u671f\u6027\u7b56\u7565\u8fdb\u4e00\u6b65\u51cf\u5c11\u672c\u5730\u8ba1\u7b97", "result": "\u7406\u8bba\u63d0\u4f9b\u4e86\u5b89\u5168\u7b56\u7565\u6539\u8fdb\u6027\u80fd\u4fdd\u8bc1\uff0c\u5927\u91cf\u5b9e\u9a8c\u8868\u660eFORLER\u5728\u4e0d\u540c\u6570\u636e\u8d28\u91cf\u548c\u5f02\u6784\u6027\u6761\u4ef6\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "FORLER\u901a\u8fc7\u521b\u65b0\u7684\u670d\u52a1\u5668-\u8bbe\u5907\u534f\u540c\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u7ebf\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7b56\u7565\u6c61\u67d3\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u6027\u80fd\u63d0\u5347"}}
{"id": "2602.02060", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02060", "abs": "https://arxiv.org/abs/2602.02060", "authors": ["Hyunsuk Chung", "Caren Han", "Yerin Choi", "Seungyeon Ji", "Jinwoo Kim", "Eun-Jung Holden", "Kyungreem Han"], "title": "FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance", "comment": null, "summary": "Multimodal foundation models integrate heterogeneous signals across modalities, yet it remains poorly understood how their predictions depend on specific internal feature groups and whether such reliance can be deliberately controlled. Existing studies of shortcut and spurious behavior largely rely on post hoc analyses or feature removal, offering limited insight into whether reliance can be modulated without altering task semantics. We introduce FiLoRA (Focus-and-Ignore LoRA), an instruction-conditioned, parameter-efficient adaptation framework that enables explicit control over internal feature reliance while keeping the predictive objective fixed. FiLoRA decomposes adaptation into feature group-aligned LoRA modules and applies instruction-conditioned gating, allowing natural language instructions to act as computation-level control signals rather than task redefinitions. Across text--image and audio--visual benchmarks, we show that instruction-conditioned gating induces consistent and causal shifts in internal computation, selectively amplifying or suppressing core and spurious feature groups without modifying the label space or training objective. Further analyses demonstrate that FiLoRA yields improved robustness under spurious feature interventions, revealing a principled mechanism to regulate reliance beyond correlation-driven learning.", "AI": {"tldr": "FiLoRA\uff1a\u4e00\u79cd\u6307\u4ee4\u6761\u4ef6\u5316\u7684\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u7279\u5f81\u7ec4\u5bf9\u9f50\u7684LoRA\u6a21\u5757\u548c\u5e94\u7528\u6307\u4ee4\u6761\u4ef6\u95e8\u63a7\uff0c\u5b9e\u73b0\u5bf9\u5185\u90e8\u7279\u5f81\u4f9d\u8d56\u7684\u663e\u5f0f\u63a7\u5236\uff0c\u800c\u4e0d\u6539\u53d8\u9884\u6d4b\u76ee\u6807\u3002", "motivation": "\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u6574\u5408\u4e86\u8de8\u6a21\u6001\u7684\u5f02\u6784\u4fe1\u53f7\uff0c\u4f46\u4eba\u4eec\u5bf9\u5176\u9884\u6d4b\u5982\u4f55\u4f9d\u8d56\u7279\u5b9a\u5185\u90e8\u7279\u5f81\u7ec4\u4ee5\u53ca\u8fd9\u79cd\u4f9d\u8d56\u662f\u5426\u53ef\u4ee5\u88ab\u6709\u610f\u63a7\u5236\u7684\u7406\u89e3\u4ecd\u7136\u4e0d\u8db3\u3002\u73b0\u6709\u5173\u4e8e\u6377\u5f84\u548c\u4f2a\u76f8\u5173\u884c\u4e3a\u7684\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u4e8b\u540e\u5206\u6790\u6216\u7279\u5f81\u79fb\u9664\uff0c\u5bf9\u4e8e\u662f\u5426\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u4efb\u52a1\u8bed\u4e49\u7684\u60c5\u51b5\u4e0b\u8c03\u8282\u4f9d\u8d56\u5173\u7cfb\u63d0\u4f9b\u6709\u9650\u89c1\u89e3\u3002", "method": "\u63d0\u51faFiLoRA\uff08Focus-and-Ignore LoRA\uff09\uff0c\u4e00\u4e2a\u6307\u4ee4\u6761\u4ef6\u5316\u7684\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u6846\u67b6\u3002\u5b83\u5c06\u9002\u5e94\u5206\u89e3\u4e3a\u7279\u5f81\u7ec4\u5bf9\u9f50\u7684LoRA\u6a21\u5757\uff0c\u5e76\u5e94\u7528\u6307\u4ee4\u6761\u4ef6\u95e8\u63a7\uff0c\u4f7f\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u4f5c\u4e3a\u8ba1\u7b97\u7ea7\u63a7\u5236\u4fe1\u53f7\u800c\u975e\u4efb\u52a1\u91cd\u5b9a\u4e49\u3002", "result": "\u5728\u6587\u672c-\u56fe\u50cf\u548c\u97f3\u9891-\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6307\u4ee4\u6761\u4ef6\u95e8\u63a7\u5728\u5185\u90e8\u8ba1\u7b97\u4e2d\u8bf1\u5bfc\u4e86\u4e00\u81f4\u4e14\u56e0\u679c\u7684\u8f6c\u53d8\uff0c\u9009\u62e9\u6027\u5730\u653e\u5927\u6216\u6291\u5236\u6838\u5fc3\u548c\u4f2a\u76f8\u5173\u7279\u5f81\u7ec4\uff0c\u800c\u4e0d\u4fee\u6539\u6807\u7b7e\u7a7a\u95f4\u6216\u8bad\u7ec3\u76ee\u6807\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8868\u660e\uff0cFiLoRA\u5728\u4f2a\u76f8\u5173\u7279\u5f81\u5e72\u9884\u4e0b\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u3002", "conclusion": "FiLoRA\u63ed\u793a\u4e86\u4e00\u79cd\u8d85\u8d8a\u76f8\u5173\u6027\u9a71\u52a8\u5b66\u4e60\u7684\u8c03\u8282\u4f9d\u8d56\u7684\u539f\u5219\u6027\u673a\u5236\uff0c\u80fd\u591f\u5728\u4e0d\u6539\u53d8\u9884\u6d4b\u76ee\u6807\u7684\u60c5\u51b5\u4e0b\u663e\u5f0f\u63a7\u5236\u5185\u90e8\u7279\u5f81\u4f9d\u8d56\uff0c\u4e3a\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u53ef\u63a7\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.02061", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02061", "abs": "https://arxiv.org/abs/2602.02061", "authors": ["Seoungbin Bae", "Junyoung Son", "Dabeen Lee"], "title": "Learning to Route and Schedule LLMs from User Retrials via Contextual Queueing Bandits", "comment": null, "summary": "Explosive demands for LLMs often cause user queries to accumulate in server queues, requiring efficient routing (query-LLM matching) and scheduling (query prioritization) mechanisms. Several online algorithms are being deployed, but they overlook the following two key challenges inherent to conversational LLM services: (1) unsatisfied users may retry queries, increasing the server backlog, and (2) requests for ``explicit\" feedback, such as ratings, degrade user experiences. In this paper, we develop a joint routing and scheduling algorithm that leverages ``implicit\" feedback inferred from user retrial behaviors. The key idea is to propose and study the framework of contextual queueing bandits with multinomial logit feedback (CQB-MNL). CQB-MNL models query retrials, as well as context-based learning for user preferences over LLMs. Our algorithm, anytime CQB (ACQB), achieves efficient learning while maintaining queue stability by combining Thompson sampling with forced exploration at a decaying rate. We show that ACQB simultaneously achieves a cumulative regret of $\\widetilde{\\mathcal{O}}(\\sqrt{t})$ for routing and a queue length regret of $\\widetilde{\\mathcal{O}}(t^{-1/4})$ for any large $t$. For experiments, we refine query embeddings via contrastive learning while adopting a disjoint parameter model to learn LLM-specific parameters. Experiments on SPROUT, EmbedLLM, and RouterBench datasets confirm that both algorithms consistently outperform baselines.", "AI": {"tldr": "\u63d0\u51faACQB\u7b97\u6cd5\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u961f\u5217\u8d4c\u535a\u673a\u4e0e\u591a\u9879\u903b\u8f91\u53cd\u9988\uff0c\u5229\u7528\u7528\u6237\u91cd\u8bd5\u884c\u4e3a\u4f5c\u4e3a\u9690\u5f0f\u53cd\u9988\uff0c\u540c\u65f6\u4f18\u5316LLM\u8def\u7531\u548c\u67e5\u8be2\u8c03\u5ea6\uff0c\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u548c\u961f\u5217\u7a33\u5b9a\u6027\u3002", "motivation": "LLM\u670d\u52a1\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u4e0d\u6ee1\u610f\u7684\u7528\u6237\u4f1a\u91cd\u8bd5\u67e5\u8be2\uff0c\u589e\u52a0\u670d\u52a1\u5668\u79ef\u538b\uff1b2) \u663e\u5f0f\u53cd\u9988\u8bf7\u6c42\uff08\u5982\u8bc4\u5206\uff09\u4f1a\u964d\u4f4e\u7528\u6237\u4f53\u9a8c\u3002\u73b0\u6709\u5728\u7ebf\u7b97\u6cd5\u5ffd\u7565\u4e86\u8fd9\u4e9b\u5bf9\u8bdd\u5f0fLLM\u670d\u52a1\u7684\u7279\u6027\u3002", "method": "\u63d0\u51faCQB-MNL\u6846\u67b6\uff08\u4e0a\u4e0b\u6587\u961f\u5217\u8d4c\u535a\u673a\u4e0e\u591a\u9879\u903b\u8f91\u53cd\u9988\uff09\uff0c\u5efa\u6a21\u67e5\u8be2\u91cd\u8bd5\u548c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u7528\u6237\u5bf9LLM\u504f\u597d\u5b66\u4e60\u3002\u5f00\u53d1ACQB\u7b97\u6cd5\uff0c\u7ed3\u5408Thompson\u91c7\u6837\u548c\u8870\u51cf\u7387\u7684\u5f3a\u5236\u63a2\u7d22\uff0c\u5728\u4fdd\u6301\u961f\u5217\u7a33\u5b9a\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u3002", "result": "ACQB\u7b97\u6cd5\u540c\u65f6\u5b9e\u73b0\u8def\u7531\u7684\u7d2f\u79ef\u9057\u61be$\\widetilde{\\mathcal{O}}(\\sqrt{t})$\u548c\u961f\u5217\u957f\u5ea6\u9057\u61be$\\widetilde{\\mathcal{O}}(t^{-1/4})$\u3002\u5728SPROUT\u3001EmbedLLM\u548cRouterBench\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7b97\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u7528\u6237\u91cd\u8bd5\u884c\u4e3a\u4f5c\u4e3a\u9690\u5f0f\u53cd\u9988\uff0cACQB\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3LLM\u670d\u52a1\u7684\u8def\u7531\u548c\u8c03\u5ea6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u961f\u5217\u7a33\u5b9a\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.02071", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02071", "abs": "https://arxiv.org/abs/2602.02071", "authors": ["Zisheng Ye", "Xiaoyu He", "Maoyuan Song", "Guoliang Qiu", "Chao Liao", "Chen Wu", "Yonggang Sun", "Zhichun Li", "Xiaoru Xie", "Yuanyong Luo", "Hu Liu", "Pinyan Lu", "Heng Liao"], "title": "BAPS: A Fine-Grained Low-Precision Scheme for Softmax in Attention via Block-Aware Precision reScaling", "comment": null, "summary": "As the performance gains from accelerating quantized matrix multiplication plateau, the softmax operation becomes the critical bottleneck in Transformer inference. This bottleneck stems from two hardware limitations: (1) limited data bandwidth between matrix and vector compute cores, and (2) the significant area cost of high-precision (FP32/16) exponentiation units (EXP2). To address these issues, we introduce a novel low-precision workflow that employs a specific 8-bit floating-point format (HiF8) and block-aware precision rescaling for softmax. Crucially, our algorithmic innovations make low-precision softmax feasible without the significant model accuracy loss that hampers direct low-precision approaches. Specifically, our design (i) halves the required data movement bandwidth by enabling matrix multiplication outputs constrained to 8-bit, and (ii) substantially reduces the EXP2 unit area by computing exponentiations in low (8-bit) precision. Extensive evaluation on language models and multi-modal models confirms the validity of our method. By alleviating the vector computation bottleneck, our work paves the way for doubling end-to-end inference throughput without increasing chip area, and offers a concrete co-design path for future low-precision hardware and software.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e8\u4f4d\u6d6e\u70b9\u683c\u5f0f\uff08HiF8\uff09\u548c\u5206\u5757\u7cbe\u5ea6\u91cd\u7f29\u653e\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u89e3\u51b3Transformer\u63a8\u7406\u4e2dsoftmax\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u7684\u95ee\u9898\uff0c\u53ef\u51cf\u5c11\u6570\u636e\u5e26\u5bbd\u9700\u6c42\u548c\u6307\u6570\u8fd0\u7b97\u5355\u5143\u9762\u79ef\uff0c\u5b9e\u73b0\u63a8\u7406\u541e\u5410\u91cf\u7ffb\u500d\u3002", "motivation": "\u968f\u7740\u91cf\u5316\u77e9\u9635\u4e58\u6cd5\u52a0\u901f\u7684\u6027\u80fd\u63d0\u5347\u8d8b\u4e8e\u5e73\u7f13\uff0csoftmax\u64cd\u4f5c\u6210\u4e3aTransformer\u63a8\u7406\u7684\u5173\u952e\u74f6\u9888\u3002\u8fd9\u6e90\u4e8e\u4e24\u4e2a\u786c\u4ef6\u9650\u5236\uff1a1\uff09\u77e9\u9635\u548c\u5411\u91cf\u8ba1\u7b97\u6838\u5fc3\u4e4b\u95f4\u7684\u6709\u9650\u6570\u636e\u5e26\u5bbd\uff1b2\uff09\u9ad8\u7cbe\u5ea6\uff08FP32/16\uff09\u6307\u6570\u8fd0\u7b97\u5355\u5143\uff08EXP2\uff09\u7684\u663e\u8457\u9762\u79ef\u6210\u672c\u3002", "method": "\u5f15\u5165\u65b0\u9896\u7684\u4f4e\u7cbe\u5ea6\u5de5\u4f5c\u6d41\uff0c\u91c7\u7528\u7279\u5b9a\u76848\u4f4d\u6d6e\u70b9\u683c\u5f0f\uff08HiF8\uff09\u548c\u5206\u5757\u611f\u77e5\u7cbe\u5ea6\u91cd\u7f29\u653e\u6280\u672f\u3002\u901a\u8fc7\u7b97\u6cd5\u521b\u65b0\u4f7f\u4f4e\u7cbe\u5ea6softmax\u53ef\u884c\uff0c\u907f\u514d\u76f4\u63a5\u4f4e\u7cbe\u5ea6\u65b9\u6cd5\u5bfc\u81f4\u7684\u663e\u8457\u6a21\u578b\u7cbe\u5ea6\u635f\u5931\u3002\u5177\u4f53\u8bbe\u8ba1\u5305\u62ec\uff1a1\uff09\u901a\u8fc7\u7ea6\u675f\u77e9\u9635\u4e58\u6cd5\u8f93\u51fa\u4e3a8\u4f4d\u6765\u51cf\u534a\u6240\u9700\u6570\u636e\u79fb\u52a8\u5e26\u5bbd\uff1b2\uff09\u5728\u4f4e\u7cbe\u5ea6\uff088\u4f4d\uff09\u4e0b\u8ba1\u7b97\u6307\u6570\u8fd0\u7b97\uff0c\u5927\u5e45\u51cf\u5c11EXP2\u5355\u5143\u9762\u79ef\u3002", "result": "\u5728\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u7f13\u89e3\u5411\u91cf\u8ba1\u7b97\u74f6\u9888\uff0c\u8be5\u5de5\u4f5c\u4e3a\u5728\u4e0d\u589e\u52a0\u82af\u7247\u9762\u79ef\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7aef\u5230\u7aef\u63a8\u7406\u541e\u5410\u91cf\u7ffb\u500d\u94fa\u5e73\u4e86\u9053\u8def\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u6761\u5177\u4f53\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u8def\u5f84\uff0c\u4e3a\u672a\u6765\u7684\u4f4e\u7cbe\u5ea6\u786c\u4ef6\u548c\u8f6f\u4ef6\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\uff0c\u89e3\u51b3\u4e86Transformer\u63a8\u7406\u4e2dsoftmax\u7684\u5173\u952e\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2602.02072", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02072", "abs": "https://arxiv.org/abs/2602.02072", "authors": ["Junyi Ji", "Derek Gloudemans", "Gergely Zach\u00e1r", "Matthew Nice", "William Barbour", "Daniel B. Work"], "title": "Calibrating Adaptive Smoothing Methods for Freeway Traffic Reconstruction", "comment": null, "summary": "The adaptive smoothing method (ASM) is a widely used approach for traffic state reconstruction. This article presents a Python implementation of ASM, featuring end-to-end calibration using real-world ground truth data. The calibration is formulated as a parameterized kernel optimization problem. The model is calibrated using data from a full-state observation testbed, with input from a sparse radar sensor network. The implementation is developed in PyTorch, enabling integration with various deep learning methods. We evaluate the results in terms of speed distribution, spatio-temporal error distribution, and spatial error to provide benchmark metrics for the traffic reconstruction problem. We further demonstrate the usability of the calibrated method across multiple freeways. Finally, we discuss the challenges of reproducibility in general traffic model calibration and the limitations of ASM. This article is reproducible and can serve as a benchmark for various freeway operation tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8ePyTorch\u7684Python\u5b9e\u73b0\u7684\u81ea\u9002\u5e94\u5e73\u6ed1\u65b9\u6cd5(ASM)\uff0c\u7528\u4e8e\u4ea4\u901a\u72b6\u6001\u91cd\u5efa\uff0c\u5305\u542b\u7aef\u5230\u7aef\u6821\u51c6\u529f\u80fd\uff0c\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u8fdb\u884c\u53c2\u6570\u5316\u6838\u4f18\u5316\uff0c\u5e76\u5728\u591a\u4e2a\u9ad8\u901f\u516c\u8def\u4e0a\u9a8c\u8bc1\u4e86\u5176\u53ef\u7528\u6027\u3002", "motivation": "\u81ea\u9002\u5e94\u5e73\u6ed1\u65b9\u6cd5(ASM)\u662f\u4ea4\u901a\u72b6\u6001\u91cd\u5efa\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u53ef\u590d\u73b0\u7684\u5b9e\u73b0\u548c\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u7684\u7aef\u5230\u7aef\u6821\u51c6\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u53ef\u590d\u73b0\u7684Python\u5b9e\u73b0\uff0c\u89e3\u51b3\u4ea4\u901a\u6a21\u578b\u6821\u51c6\u4e2d\u7684\u53ef\u590d\u73b0\u6027\u95ee\u9898\uff0c\u5e76\u4e3a\u5404\u79cd\u9ad8\u901f\u516c\u8def\u8fd0\u8425\u4efb\u52a1\u63d0\u4f9b\u57fa\u51c6\u3002", "method": "\u4f7f\u7528PyTorch\u5b9e\u73b0ASM\uff0c\u5c06\u6821\u51c6\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u53c2\u6570\u5316\u6838\u4f18\u5316\u95ee\u9898\u3002\u4f7f\u7528\u6765\u81ea\u7a00\u758f\u96f7\u8fbe\u4f20\u611f\u5668\u7f51\u7edc\u7684\u771f\u5b9e\u4e16\u754c\u5730\u9762\u5b9e\u51b5\u6570\u636e\u8fdb\u884c\u6821\u51c6\uff0c\u6570\u636e\u6765\u6e90\u4e8e\u5168\u72b6\u6001\u89c2\u6d4b\u6d4b\u8bd5\u5e73\u53f0\u3002\u8bc4\u4f30\u5305\u62ec\u901f\u5ea6\u5206\u5e03\u3001\u65f6\u7a7a\u8bef\u5dee\u5206\u5e03\u548c\u7a7a\u95f4\u8bef\u5dee\u5206\u6790\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u590d\u73b0\u7684ASM Python\u5b9e\u73b0\uff0c\u63d0\u4f9b\u4e86\u4ea4\u901a\u91cd\u5efa\u95ee\u9898\u7684\u57fa\u51c6\u6307\u6807\u3002\u5728\u591a\u4e2a\u9ad8\u901f\u516c\u8def\u4e0a\u9a8c\u8bc1\u4e86\u6821\u51c6\u65b9\u6cd5\u7684\u53ef\u7528\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u81ea\u9002\u5e94\u5e73\u6ed1\u65b9\u6cd5\u5b9e\u73b0\uff0c\u53ef\u4f5c\u4e3a\u5404\u79cd\u9ad8\u901f\u516c\u8def\u8fd0\u8425\u4efb\u52a1\u7684\u57fa\u51c6\u3002\u540c\u65f6\u8ba8\u8bba\u4e86\u901a\u7528\u4ea4\u901a\u6a21\u578b\u6821\u51c6\u4e2d\u7684\u53ef\u590d\u73b0\u6027\u6311\u6218\u548cASM\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2602.02079", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02079", "abs": "https://arxiv.org/abs/2602.02079", "authors": ["Daniil Orel", "Dilshod Azizov", "Indraneil Paul", "Yuxia Wang", "Iryna Gurevych", "Preslav Nakov"], "title": "AICD Bench: A Challenging Benchmark for AI-Generated Code Detection", "comment": null, "summary": "Large language models (LLMs) are increasingly capable of generating functional source code, raising concerns about authorship, accountability, and security. While detecting AI-generated code is critical, existing datasets and benchmarks are narrow, typically limited to binary human-machine classification under in-distribution settings. To bridge this gap, we introduce $\\emph{AICD Bench}$, the most comprehensive benchmark for AI-generated code detection. It spans $\\emph{2M examples}$, $\\emph{77 models}$ across $\\emph{11 families}$, and $\\emph{9 programming languages}$, including recent reasoning models. Beyond scale, AICD Bench introduces three realistic detection tasks: ($\\emph{i}$)~$\\emph{Robust Binary Classification}$ under distribution shifts in language and domain, ($\\emph{ii}$)~$\\emph{Model Family Attribution}$, grouping generators by architectural lineage, and ($\\emph{iii}$)~$\\emph{Fine-Grained Human-Machine Classification}$ across human, machine, hybrid, and adversarial code. Extensive evaluation on neural and classical detectors shows that performance remains far below practical usability, particularly under distribution shift and for hybrid or adversarial code. We release AICD Bench as a $\\emph{unified, challenging evaluation suite}$ to drive the next generation of robust approaches for AI-generated code detection. The data and the code are available at https://huggingface.co/AICD-bench}.", "AI": {"tldr": "AICD Bench\u662f\u4e00\u4e2a\u5168\u9762\u7684AI\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u57fa\u51c6\uff0c\u5305\u542b200\u4e07\u6837\u672c\u300177\u4e2a\u6a21\u578b\u300111\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c9\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u5f15\u5165\u4e86\u4e09\u79cd\u73b0\u5b9e\u68c0\u6d4b\u4efb\u52a1\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u68c0\u6d4b\u5668\u6027\u80fd\u8fdc\u672a\u8fbe\u5230\u5b9e\u7528\u6c34\u5e73\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u529f\u80fd\u6027\u6e90\u4ee3\u7801\u7684\u80fd\u529b\u589e\u5f3a\uff0c\u5f15\u53d1\u4e86\u5173\u4e8e\u4f5c\u8005\u8eab\u4efd\u3001\u8d23\u4efb\u548c\u5b89\u5168\u7684\u62c5\u5fe7\u3002\u73b0\u6709AI\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u8fc7\u4e8e\u72ed\u7a84\uff0c\u901a\u5e38\u4ec5\u9650\u4e8e\u540c\u5206\u5e03\u4e0b\u7684\u4e8c\u5143\u4eba\u673a\u5206\u7c7b\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6784\u5efa\u4e86AICD Bench\u57fa\u51c6\uff0c\u5305\u542b200\u4e07\u4e2a\u793a\u4f8b\u300177\u4e2a\u6a21\u578b\uff08\u6db5\u76d611\u4e2a\u6a21\u578b\u5bb6\u65cf\uff09\u30019\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u5e76\u5f15\u5165\u4e09\u79cd\u73b0\u5b9e\u68c0\u6d4b\u4efb\u52a1\uff1a\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u4e8c\u5143\u5206\u7c7b\u3001\u6a21\u578b\u5bb6\u65cf\u5f52\u5c5e\u3001\u7ec6\u7c92\u5ea6\u4eba\u673a\u5206\u7c7b\uff08\u4eba\u7c7b\u3001\u673a\u5668\u3001\u6df7\u5408\u3001\u5bf9\u6297\u4ee3\u7801\uff09\u3002", "result": "\u5bf9\u795e\u7ecf\u548c\u7ecf\u5178\u68c0\u6d4b\u5668\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0c\u6027\u80fd\u8fdc\u672a\u8fbe\u5230\u5b9e\u9645\u53ef\u7528\u6c34\u5e73\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u4ee5\u53ca\u5bf9\u4e8e\u6df7\u5408\u6216\u5bf9\u6297\u4ee3\u7801\u7684\u68c0\u6d4b\u6548\u679c\u8f83\u5dee\u3002", "conclusion": "AICD Bench\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u8bc4\u4f30\u5957\u4ef6\u53d1\u5e03\uff0c\u65e8\u5728\u63a8\u52a8\u4e0b\u4e00\u4ee3\u9c81\u68d2\u7684AI\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u65b9\u6cd5\u7684\u53d1\u5c55\u3002\u6570\u636e\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2602.02080", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02080", "abs": "https://arxiv.org/abs/2602.02080", "authors": ["Aryan Alavi Razavi Ravari", "Farnam Mansouri", "Yuxin Chen", "Valentio Iverson", "Adish Singla", "Sandra Zilles"], "title": "Learning Half-Spaces from Perturbed Contrastive Examples", "comment": null, "summary": "We study learning under a two-step contrastive example oracle, as introduced by Mansouri et. al. (2025), where each queried (or sampled) labeled example is paired with an additional contrastive example of opposite label. While Mansouri et al. assume an idealized setting, where the contrastive example is at minimum distance of the originally queried/sampled point, we introduce and analyze a mechanism, parameterized by a non-decreasing noise function $f$, under which this ideal contrastive example is perturbed. The amount of perturbation is controlled by $f(d)$, where $d$ is the distance of the queried/sampled point to the decision boundary. Intuitively, this results in higher-quality contrastive examples for points closer to the decision boundary. We study this model in two settings: (i) when the maximum perturbation magnitude is fixed, and (ii) when it is stochastic.\n  For one-dimensional thresholds and for half-spaces under the uniform distribution on a bounded domain, we characterize active and passive contrastive sample complexity in dependence on the function $f$. We show that, under certain conditions on $f$, the presence of contrastive examples speeds up learning in terms of asymptotic query complexity and asymptotic expected query complexity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5e26\u566a\u58f0\u7684\u5bf9\u6bd4\u793a\u4f8b\u5b66\u4e60\u6a21\u578b\uff0c\u5176\u4e2d\u5bf9\u6bd4\u793a\u4f8b\u7684\u6270\u52a8\u7a0b\u5ea6\u7531\u8ddd\u79bb\u51b3\u7b56\u8fb9\u754c\u7684\u8fdc\u8fd1\u63a7\u5236\uff0c\u5206\u6790\u4e86\u4e00\u7ef4\u9608\u503c\u548c\u534a\u7a7a\u95f4\u5206\u7c7b\u5668\u7684\u4e3b\u52a8/\u88ab\u52a8\u5b66\u4e60\u6837\u672c\u590d\u6742\u5ea6\u3002", "motivation": "Mansouri\u7b49\u4eba\u63d0\u51fa\u4e86\u7406\u60f3\u5316\u7684\u5bf9\u6bd4\u793a\u4f8b\u5b66\u4e60\u6a21\u578b\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u5bf9\u6bd4\u793a\u4f8b\u5f80\u5f80\u5b58\u5728\u566a\u58f0\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u5e26\u566a\u58f0\u7684\u5bf9\u6bd4\u793a\u4f8b\u5b66\u4e60\uff0c\u5176\u4e2d\u566a\u58f0\u5927\u5c0f\u4e0e\u6837\u672c\u70b9\u5230\u51b3\u7b56\u8fb9\u754c\u7684\u8ddd\u79bb\u76f8\u5173\uff0c\u66f4\u63a5\u8fd1\u8fb9\u754c\u7684\u70b9\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u5bf9\u6bd4\u793a\u4f8b\u3002", "method": "\u5f15\u5165\u53c2\u6570\u5316\u566a\u58f0\u51fd\u6570f\u7684\u673a\u5236\uff0c\u5bf9\u6bd4\u793a\u4f8b\u7684\u6270\u52a8\u7a0b\u5ea6\u7531f(d)\u63a7\u5236\uff0cd\u662f\u67e5\u8be2\u70b9\u5230\u51b3\u7b56\u8fb9\u754c\u7684\u8ddd\u79bb\u3002\u7814\u7a76\u4e24\u79cd\u8bbe\u7f6e\uff1a\u56fa\u5b9a\u6700\u5927\u6270\u52a8\u5e45\u5ea6\u548c\u968f\u673a\u6270\u52a8\u5e45\u5ea6\u3002\u5206\u6790\u4e00\u7ef4\u9608\u503c\u5206\u7c7b\u5668\u548c\u5747\u5300\u5206\u5e03\u6709\u754c\u57df\u4e0a\u534a\u7a7a\u95f4\u5206\u7c7b\u5668\u7684\u4e3b\u52a8\u548c\u88ab\u52a8\u5bf9\u6bd4\u6837\u672c\u590d\u6742\u5ea6\u3002", "result": "\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u5bf9\u6bd4\u793a\u4f8b\u7684\u5b58\u5728\u80fd\u591f\u52a0\u901f\u5b66\u4e60\u8fc7\u7a0b\uff0c\u964d\u4f4e\u6e10\u8fd1\u67e5\u8be2\u590d\u6742\u5ea6\u548c\u6e10\u8fd1\u671f\u671b\u67e5\u8be2\u590d\u6742\u5ea6\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u566a\u58f0\u51fd\u6570f\u5982\u4f55\u5f71\u54cd\u5b66\u4e60\u6548\u7387\u3002", "conclusion": "\u5e26\u566a\u58f0\u7684\u5bf9\u6bd4\u793a\u4f8b\u5b66\u4e60\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u4ef7\u503c\uff0c\u901a\u8fc7\u63a7\u5236\u566a\u58f0\u4e0e\u51b3\u7b56\u8fb9\u754c\u8ddd\u79bb\u7684\u5173\u7cfb\uff0c\u53ef\u4ee5\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\uff0c\u4e3a\u4e00\u7ef4\u9608\u503c\u548c\u534a\u7a7a\u95f4\u5206\u7c7b\u5668\u7684\u5bf9\u6bd4\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2602.02081", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02081", "abs": "https://arxiv.org/abs/2602.02081", "authors": ["Farnam Mansouri", "Sandra Zilles", "Shai Ben-David"], "title": "Active learning from positive and unlabeled examples", "comment": null, "summary": "Learning from positive and unlabeled data (PU learning) is a weakly supervised variant of binary classification in which the learner receives labels only for (some) positively labeled instances, while all other examples remain unlabeled. Motivated by applications such as advertising and anomaly detection, we study an active PU learning setting where the learner can adaptively query instances from an unlabeled pool, but a queried label is revealed only when the instance is positive and an independent coin flip succeeds; otherwise the learner receives no information. In this paper, we provide the first theoretical analysis of the label complexity of active PU learning.", "AI": {"tldr": "\u9996\u6b21\u5bf9\u4e3b\u52a8PU\u5b66\u4e60\u7684\u6807\u7b7e\u590d\u6742\u5ea6\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u5728\u53ea\u80fd\u89c2\u5bdf\u5230\u90e8\u5206\u6b63\u6837\u672c\u6807\u7b7e\u7684\u5f31\u76d1\u7763\u573a\u666f\u4e0b\u7684\u4e3b\u52a8\u5b66\u4e60\u95ee\u9898", "motivation": "\u53d7\u5e7f\u544a\u548c\u5f02\u5e38\u68c0\u6d4b\u7b49\u5e94\u7528\u9a71\u52a8\uff0c\u7814\u7a76\u4e3b\u52a8PU\u5b66\u4e60\u573a\u666f\uff0c\u5176\u4e2d\u5b66\u4e60\u8005\u53ef\u4ee5\u4ece\u65e0\u6807\u7b7e\u6c60\u4e2d\u81ea\u9002\u5e94\u67e5\u8be2\u5b9e\u4f8b\uff0c\u4f46\u53ea\u6709\u5f53\u5b9e\u4f8b\u4e3a\u6b63\u4e14\u72ec\u7acb\u786c\u5e01\u7ffb\u8f6c\u6210\u529f\u65f6\u624d\u4f1a\u663e\u793a\u6807\u7b7e\uff0c\u5426\u5219\u5b66\u4e60\u8005\u65e0\u6cd5\u83b7\u5f97\u4efb\u4f55\u4fe1\u606f", "method": "\u4e3b\u52a8PU\u5b66\u4e60\u6846\u67b6\uff0c\u5b66\u4e60\u8005\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u4ece\u65e0\u6807\u7b7e\u6c60\u4e2d\u67e5\u8be2\u5b9e\u4f8b\uff0c\u4f46\u6807\u7b7e\u53ea\u5728\u5b9e\u4f8b\u4e3a\u6b63\u4e14\u968f\u673a\u4e8b\u4ef6\u6210\u529f\u65f6\u663e\u793a\uff0c\u5426\u5219\u65e0\u4fe1\u606f\u53cd\u9988", "result": "\u9996\u6b21\u63d0\u4f9b\u4e86\u4e3b\u52a8PU\u5b66\u4e60\u7684\u6807\u7b7e\u590d\u6742\u5ea6\u7406\u8bba\u5206\u6790", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u4e3b\u52a8PU\u5b66\u4e60\u7406\u8bba\u5206\u6790\u7684\u7a7a\u767d\uff0c\u4e3a\u53ea\u80fd\u89c2\u5bdf\u5230\u90e8\u5206\u6b63\u6837\u672c\u6807\u7b7e\u7684\u5f31\u76d1\u7763\u573a\u666f\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840"}}
{"id": "2602.02087", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02087", "abs": "https://arxiv.org/abs/2602.02087", "authors": ["Andreas Kontogiannis", "Vasilis Pollatos", "Panayotis Mertikopoulos", "Ioannis Panageas"], "title": "Efficient Swap Regret Minimization in Combinatorial Bandits", "comment": "Accepted at AISTATS 2026", "summary": "This paper addresses the problem of designing efficient no-swap regret algorithms for combinatorial bandits, where the number of actions $N$ is exponentially large in the dimensionality of the problem. In this setting, designing efficient no-swap regret translates to sublinear -- in horizon $T$ -- swap regret with polylogarithmic dependence on $N$. In contrast to the weaker notion of external regret minimization - a problem which is fairly well understood in the literature - achieving no-swap regret with a polylogarithmic dependence on $N$ has remained elusive in combinatorial bandits. Our paper resolves this challenge, by introducing a no-swap-regret learning algorithm with regret that scales polylogarithmically in $N$ and is tight for the class of combinatorial bandits. To ground our results, we also demonstrate how to implement the proposed algorithm efficiently -- that is, with a per-iteration complexity that also scales polylogarithmically in $N$ -- across a wide range of well-studied applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u7ec4\u5408\u8d4c\u535a\u673a\u7684\u9ad8\u6548\u65e0\u4ea4\u6362\u9057\u61be\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u5728\u52a8\u4f5c\u6570\u91cfN\u6307\u6570\u7ea7\u589e\u957f\u65f6\u5b9e\u73b0polylog(N)\u4f9d\u8d56\u7684\u9057\u61be\u754c\u8fd9\u4e00\u957f\u671f\u96be\u9898\u3002", "motivation": "\u5728\u7ec4\u5408\u8d4c\u535a\u673a\u95ee\u9898\u4e2d\uff0c\u52a8\u4f5c\u6570\u91cfN\u76f8\u5bf9\u4e8e\u95ee\u9898\u7ef4\u5ea6\u5448\u6307\u6570\u7ea7\u589e\u957f\u3002\u867d\u7136\u5916\u90e8\u9057\u61be\u6700\u5c0f\u5316\u95ee\u9898\u5df2\u6709\u8f83\u597d\u7406\u89e3\uff0c\u4f46\u5b9e\u73b0polylog(N)\u4f9d\u8d56\u7684\u65e0\u4ea4\u6362\u9057\u61be\u7b97\u6cd5\u4e00\u76f4\u662f\u4e2a\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u8fbe\u5230\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u4ea4\u6362\u9057\u61be\u5b66\u4e60\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5b9e\u73b0polylog(N)\u7684\u9057\u61be\u7f29\u653e\u3002\u7b97\u6cd5\u8bbe\u8ba1\u8003\u8651\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u786e\u4fdd\u6bcf\u6b21\u8fed\u4ee3\u7684\u590d\u6742\u5ea6\u4e5f\u4ee5polylog(N)\u589e\u957f\u3002\u8bba\u6587\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u5728\u591a\u79cd\u7ecf\u5178\u5e94\u7528\u573a\u666f\u4e2d\u9ad8\u6548\u5b9e\u73b0\u8be5\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u7ec4\u5408\u8d4c\u535a\u673a\u7c7b\u4e2d\u5b9e\u73b0\u4e86\u7d27\u81f4\u7684\u9057\u61be\u754c\uff0c\u9057\u61be\u968fN\u4ee5polylogarithmic\u65b9\u5f0f\u7f29\u653e\uff0c\u4e14\u76f8\u5bf9\u4e8e\u65f6\u95f4\u8303\u56f4T\u662f\u6b21\u7ebf\u6027\u7684\u3002\u7b97\u6cd5\u5728\u591a\u79cd\u5e94\u7528\u573a\u666f\u4e2d\u90fd\u80fd\u9ad8\u6548\u5b9e\u73b0\uff0c\u6bcf\u6b21\u8fed\u4ee3\u590d\u6742\u5ea6\u540c\u6837\u4e3apolylog(N)\u3002", "conclusion": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u7ec4\u5408\u8d4c\u535a\u673a\u4e2d\u957f\u671f\u5b58\u5728\u7684\u65e0\u4ea4\u6362\u9057\u61be\u7b97\u6cd5\u8bbe\u8ba1\u96be\u9898\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86polylog(N)\u4f9d\u8d56\u7684\u9057\u61be\u754c\uff0c\u5e76\u4fdd\u8bc1\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u7ec4\u5408\u8d4c\u535a\u673a\u7684\u9ad8\u6548\u5b66\u4e60\u63d0\u4f9b\u4e86\u91cd\u8981\u7a81\u7834\u3002"}}
{"id": "2602.02098", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02098", "abs": "https://arxiv.org/abs/2602.02098", "authors": ["Yannik Schnitzer", "Mathias Jackermeier", "Alessandro Abate", "David Parker"], "title": "Probabilistic Performance Guarantees for Multi-Task Reinforcement Learning", "comment": null, "summary": "Multi-task reinforcement learning trains generalist policies that can execute multiple tasks. While recent years have seen significant progress, existing approaches rarely provide formal performance guarantees, which are indispensable when deploying policies in safety-critical settings. We present an approach for computing high-confidence guarantees on the performance of a multi-task policy on tasks not seen during training. Concretely, we introduce a new generalisation bound that composes (i) per-task lower confidence bounds from finitely many rollouts with (ii) task-level generalisation from finitely many sampled tasks, yielding a high-confidence guarantee for new tasks drawn from the same arbitrary and unknown distribution. Across state-of-the-art multi-task RL methods, we show that the guarantees are theoretically sound and informative at realistic sample sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e3a\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5728\u65b0\u4efb\u52a1\u4e0a\u63d0\u4f9b\u9ad8\u7f6e\u4fe1\u5ea6\u6027\u80fd\u4fdd\u8bc1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ec4\u5408\u4efb\u52a1\u5185\u548c\u4efb\u52a1\u95f4\u7684\u6cdb\u5316\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u5f62\u5f0f\u5316\u7684\u6027\u80fd\u4fdd\u8bc1\uff0c\u8fd9\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u3002\u9700\u8981\u4e3a\u8bad\u7ec3\u671f\u95f4\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u63d0\u4f9b\u53ef\u9760\u6027\u80fd\u4fdd\u8bc1\u3002", "method": "\u5f15\u5165\u65b0\u7684\u6cdb\u5316\u8fb9\u754c\uff0c\u7ec4\u5408\u4e24\u90e8\u5206\uff1a(1) \u4ece\u6709\u9650\u6b21rollout\u5f97\u5230\u7684\u6bcf\u4e2a\u4efb\u52a1\u7684\u7f6e\u4fe1\u4e0b\u754c\uff1b(2) \u4ece\u6709\u9650\u91c7\u6837\u4efb\u52a1\u5f97\u5230\u7684\u4efb\u52a1\u7ea7\u6cdb\u5316\uff0c\u4ece\u800c\u4e3a\u6765\u81ea\u76f8\u540c\u672a\u77e5\u5206\u5e03\u7684\u65b0\u4efb\u52a1\u63d0\u4f9b\u9ad8\u7f6e\u4fe1\u5ea6\u4fdd\u8bc1\u3002", "result": "\u5728\u5148\u8fdb\u7684\u591a\u4efb\u52a1RL\u65b9\u6cd5\u4e0a\u9a8c\u8bc1\uff0c\u8bc1\u660e\u8be5\u4fdd\u8bc1\u5728\u7406\u8bba\u4e0a\u662f\u53ef\u9760\u7684\uff0c\u5e76\u4e14\u5728\u73b0\u5b9e\u6837\u672c\u91cf\u4e0b\u5177\u6709\u4fe1\u606f\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5728\u65b0\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u4fdd\u8bc1\uff0c\u586b\u8865\u4e86\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u7406\u8bba\u7a7a\u767d\u3002"}}
{"id": "2602.02103", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02103", "abs": "https://arxiv.org/abs/2602.02103", "authors": ["Liyan Xu", "Mo Yu", "Fandong Meng", "Jie Zhou"], "title": "No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs", "comment": null, "summary": "This work stems from prior complementary observations on the dynamics of Chain-of-Thought (CoT): Large Language Models (LLMs) is shown latent planning of subsequent reasoning prior to CoT emergence, thereby diminishing the significance of explicit CoT; whereas CoT remains critical for tasks requiring multi-step reasoning. To deepen the understanding between LLM's internal states and its verbalized reasoning trajectories, we investigate the latent planning strength of LLMs, through our probing method, Tele-Lens, applying to hidden states across diverse task domains. Our empirical results indicate that LLMs exhibit a myopic horizon, primarily conducting incremental transitions without precise global planning. Leveraging this characteristic, we propose a hypothesis on enhancing uncertainty estimation of CoT, which we validate that a small subset of CoT positions can effectively represent the uncertainty of the entire path. We further underscore the significance of exploiting CoT dynamics, and demonstrate that automatic recognition of CoT bypass can be achieved without performance degradation. Our code, data and models are released at https://github.com/lxucs/tele-lens.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTele-Lens\u65b9\u6cd5\u63a2\u7a76LLM\u5185\u90e8\u72b6\u6001\u4e0e\u63a8\u7406\u8f68\u8ff9\u5173\u7cfb\uff0c\u53d1\u73b0LLM\u5177\u6709\u77ed\u89c6\u7279\u6027\uff0c\u4ec5\u8fdb\u884c\u589e\u91cf\u63a8\u7406\u800c\u975e\u5168\u5c40\u89c4\u5212\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u6539\u8fdbCoT\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u65b9\u6cd5\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u663e\u793aLLM\u5728CoT\u51fa\u73b0\u524d\u5df2\u6709\u6f5c\u5728\u89c4\u5212\uff0c\u8fd9\u524a\u5f31\u4e86\u663e\u5f0fCoT\u7684\u91cd\u8981\u6027\uff0c\u4f46CoT\u5bf9\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4ecd\u81f3\u5173\u91cd\u8981\u3002\u4e3a\u6df1\u5165\u7406\u89e3LLM\u5185\u90e8\u72b6\u6001\u4e0e\u663e\u5f0f\u63a8\u7406\u8f68\u8ff9\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u9700\u8981\u63a2\u7a76LLM\u7684\u6f5c\u5728\u89c4\u5212\u80fd\u529b\u3002", "method": "\u63d0\u51faTele-Lens\u63a2\u6d4b\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u4e0d\u540c\u4efb\u52a1\u9886\u57df\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5206\u6790LLM\u7684\u6f5c\u5728\u89c4\u5212\u5f3a\u5ea6\u3002\u57fa\u4e8e\u53d1\u73b0\u7684\u77ed\u89c6\u7279\u6027\uff0c\u63d0\u51fa\u6539\u8fdbCoT\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5c11\u91cfCoT\u4f4d\u7f6e\u80fd\u6709\u6548\u4ee3\u8868\u6574\u4e2a\u8def\u5f84\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660eLLM\u8868\u73b0\u51fa\u77ed\u89c6\u89c6\u91ce\uff0c\u4e3b\u8981\u8fdb\u884c\u589e\u91cf\u8f6c\u6362\u800c\u975e\u7cbe\u786e\u5168\u5c40\u89c4\u5212\u3002\u9a8c\u8bc1\u4e86\u5047\u8bbe\uff1a\u5c11\u91cfCoT\u4f4d\u7f6e\u80fd\u6709\u6548\u4ee3\u8868\u6574\u4e2a\u8def\u5f84\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8fdb\u4e00\u6b65\u8bc1\u660e\u53ef\u81ea\u52a8\u8bc6\u522bCoT\u7ed5\u8fc7\u800c\u4e0d\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "LLM\u5177\u6709\u77ed\u89c6\u63a8\u7406\u7279\u6027\uff0c\u8fd9\u4e3a\u6539\u8fdbCoT\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002\u5229\u7528CoT\u52a8\u6001\u7279\u6027\u53ef\u5b9e\u73b0\u81ea\u52a8\u8bc6\u522bCoT\u7ed5\u8fc7\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002\u5f3a\u8c03\u4e86\u5229\u7528CoT\u52a8\u6001\u7279\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.02110", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.02110", "abs": "https://arxiv.org/abs/2602.02110", "authors": ["Zhongqian Fu", "Tianyi Zhao", "Kai Han", "Hang Zhou", "Xinghao Chen", "Yunhe Wang"], "title": "An Empirical Study of World Model Quantization", "comment": null, "summary": "World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u4e16\u754c\u6a21\u578b\u7684\u91cf\u5316\u95ee\u9898\uff0c\u53d1\u73b0\u91cf\u5316\u5bf9\u4e16\u754c\u6a21\u578b\u7684\u5f71\u54cd\u8fdc\u8d85\u4f20\u7edf\u7cbe\u5ea6-\u6bd4\u7279\u6743\u8861\uff0c\u63ed\u793a\u4e86\u91cf\u5316\u5f15\u53d1\u7684\u72ec\u7279\u5931\u6548\u6a21\u5f0f\uff0c\u4e3a\u5728\u4e25\u683c\u8ba1\u7b97\u7ea6\u675f\u4e0b\u90e8\u7f72\u91cf\u5316\u4e16\u754c\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "motivation": "\u4e16\u754c\u6a21\u578b\u5728\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b66\u4e60\u73af\u5883\u52a8\u6001\u8868\u793a\uff0c\u652f\u6301\u89c4\u5212\u3001\u9884\u6d4b\u548c\u63a8\u7406\u7b49\u4efb\u52a1\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u548c\u5185\u5b58\u5360\u7528\u9ad8\uff0c\u9700\u8981\u91cf\u5316\u4ee5\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\u3002\u7136\u800c\uff0c\u540e\u8bad\u7ec3\u91cf\u5316\u5bf9\u4e16\u754c\u6a21\u578b\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u4f7f\u7528DINO-WM\u4f5c\u4e3a\u4ee3\u8868\u6027\u6848\u4f8b\uff0c\u7cfb\u7edf\u5b9e\u8bc1\u7814\u7a76\u4e16\u754c\u6a21\u578b\u91cf\u5316\uff0c\u8bc4\u4f30\u591a\u79cd\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff08\u4ec5\u6743\u91cd\u91cf\u5316\u548c\u8054\u5408\u6743\u91cd-\u6fc0\u6d3b\u91cf\u5316\uff09\uff0c\u5728\u4e0d\u540c\u89c6\u89c9\u89c4\u5212\u4efb\u52a1\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u6db5\u76d6\u591a\u79cd\u6bd4\u7279\u5bbd\u5ea6\u3001\u91cf\u5316\u7c92\u5ea6\u548c\u89c4\u5212\u65f6\u57df\uff08\u9ad8\u8fbe50\u6b21\u8fed\u4ee3\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u5206\u7ec4\u6743\u91cd\u91cf\u5316\u53ef\u7a33\u5b9a\u4f4e\u6bd4\u7279rollout\uff1b\u6fc0\u6d3b\u91cf\u5316\u7c92\u5ea6\u5e26\u6765\u4e0d\u4e00\u81f4\u7684\u6536\u76ca\uff1b\u7f16\u7801\u5668\u548c\u9884\u6d4b\u5668\u6a21\u5757\u7684\u91cf\u5316\u654f\u611f\u6027\u9ad8\u5ea6\u4e0d\u5bf9\u79f0\uff1b\u6fc0\u8fdb\u7684\u4f4e\u6bd4\u7279\u91cf\u5316\u663e\u8457\u964d\u4f4e\u89c4\u5212\u76ee\u6807\u4e0e\u4efb\u52a1\u6210\u529f\u4e4b\u95f4\u7684\u5bf9\u9f50\u5ea6\uff0c\u5bfc\u81f4\u65e0\u6cd5\u901a\u8fc7\u989d\u5916\u4f18\u5316\u4fee\u590d\u7684\u5931\u8d25\u3002", "conclusion": "\u91cf\u5316\u5728\u4e16\u754c\u6a21\u578b\u4e2d\u7684\u5f71\u54cd\u8d85\u8d8a\u4e86\u6807\u51c6\u7cbe\u5ea6-\u6bd4\u7279\u6743\u8861\uff0c\u63ed\u793a\u4e86\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u89c4\u5212\u4e2d\u91cf\u5316\u5f15\u53d1\u7684\u72ec\u7279\u5931\u6548\u6a21\u5f0f\uff0c\u4e3a\u5728\u4e25\u683c\u8ba1\u7b97\u7ea6\u675f\u4e0b\u90e8\u7f72\u91cf\u5316\u4e16\u754c\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.02112", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02112", "abs": "https://arxiv.org/abs/2602.02112", "authors": ["Chunsan Hong", "Sanghyun Lee", "Jong Chul Ye"], "title": "Unifying Masked Diffusion Models with Various Generation Orders and Beyond", "comment": "Preprint", "summary": "Masked diffusion models (MDMs) are a potential alternative to autoregressive models (ARMs) for language generation, but generation quality depends critically on the generation order. Prior work either hard-codes an ordering (e.g., blockwise left-to-right) or learns an ordering policy for a pretrained MDM, which incurs extra cost and can yield suboptimal solutions due to the two-stage optimization. Motivated by this, we propose order-expressive masked diffusion model (OeMDM) for a broad class of diffusion generative processes with various generation orders, enabling the interpretation of MDM, ARM, and block diffusion in a single framework. Furthermore, building on OeMDM, we introduce learnable-order masked diffusion model (LoMDM), which jointly learns the generation ordering and diffusion backbone through a single objective from scratch, enabling the diffusion model to generate text in context-dependent ordering. Empirically, we confirm that LoMDM outperforms various discrete diffusion models across multiple language modeling benchmarks.", "AI": {"tldr": "\u63d0\u51faOeMDM\u548cLoMDM\u4e24\u79cd\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u524d\u8005\u7edf\u4e00\u4e86\u591a\u79cd\u751f\u6210\u987a\u5e8f\u7684\u6269\u6563\u8fc7\u7a0b\uff0c\u540e\u8005\u901a\u8fc7\u5355\u9636\u6bb5\u4f18\u5316\u8054\u5408\u5b66\u4e60\u751f\u6210\u987a\u5e8f\u548c\u6269\u6563\u6a21\u578b\uff0c\u5728\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u79bb\u6563\u6269\u6563\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u63a9\u7801\u6269\u6563\u6a21\u578b(MDMs)\u7684\u751f\u6210\u8d28\u91cf\u4e25\u91cd\u4f9d\u8d56\u751f\u6210\u987a\u5e8f\uff0c\u5148\u524d\u5de5\u4f5c\u8981\u4e48\u786c\u7f16\u7801\u987a\u5e8f\uff0c\u8981\u4e48\u4e3a\u9884\u8bad\u7ec3MDM\u5b66\u4e60\u987a\u5e8f\u7b56\u7565\uff0c\u8fd9\u9700\u8981\u989d\u5916\u6210\u672c\u4e14\u53ef\u80fd\u56e0\u4e24\u9636\u6bb5\u4f18\u5316\u5bfc\u81f4\u6b21\u4f18\u89e3\u3002", "method": "1) \u63d0\u51faOeMDM\uff0c\u5c06MDM\u3001ARM\u548c\u5757\u6269\u6563\u7edf\u4e00\u5230\u5355\u4e00\u6846\u67b6\u4e2d\uff1b2) \u57fa\u4e8eOeMDM\u63d0\u51faLoMDM\uff0c\u901a\u8fc7\u5355\u4e00\u76ee\u6807\u4ece\u96f6\u5f00\u59cb\u8054\u5408\u5b66\u4e60\u751f\u6210\u987a\u5e8f\u548c\u6269\u6563\u4e3b\u5e72\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6839\u636e\u4e0a\u4e0b\u6587\u751f\u6210\u6587\u672c\u987a\u5e8f\u3002", "result": "LoMDM\u5728\u591a\u4e2a\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5404\u79cd\u79bb\u6563\u6269\u6563\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u548c\u8054\u5408\u5b66\u4e60\u65b9\u6cd5\uff0cLoMDM\u80fd\u591f\u6709\u6548\u5b66\u4e60\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u751f\u6210\u987a\u5e8f\uff0c\u5728\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e0a\u53d6\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.02117", "categories": ["cs.LG", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.02117", "abs": "https://arxiv.org/abs/2602.02117", "authors": ["Youqi Wu", "Farzan Farnia"], "title": "The Maximum von Neumann Entropy Principle: Theory and Applications in Machine Learning", "comment": null, "summary": "Von Neumann entropy (VNE) is a fundamental quantity in quantum information theory and has recently been adopted in machine learning as a spectral measure of diversity for kernel matrices and kernel covariance operators. While maximizing VNE under constraints is well known in quantum settings, a principled analogue of the classical maximum entropy framework, particularly its decision theoretic and game theoretic interpretation, has not been explicitly developed for VNE in data driven contexts. In this paper, we extend the minimax formulation of the maximum entropy principle due to Gr\u00fcnwald and Dawid to the setting of von Neumann entropy, providing a game-theoretic justification for VNE maximization over density matrices and trace-normalized positive semidefinite operators. This perspective yields a robust interpretation of maximum VNE solutions under partial information and clarifies their role as least committed inferences in spectral domains. We then illustrate how the resulting Maximum VNE principle applies to modern machine learning problems by considering two representative applications, selecting a kernel representation from multiple normalized embeddings via kernel-based VNE maximization, and completing kernel matrices from partially observed entries. These examples demonstrate how the proposed framework offers a unifying information-theoretic foundation for VNE-based methods in kernel learning.", "AI": {"tldr": "\u8bba\u6587\u5c06\u7ecf\u5178\u7684\u6700\u5927\u71b5\u539f\u7406\u6269\u5c55\u5230\u51af\u00b7\u8bfa\u4f9d\u66fc\u71b5\uff0c\u63d0\u4f9b\u4e86\u5bc6\u5ea6\u77e9\u9635\u548c\u8ff9\u5f52\u4e00\u5316\u534a\u6b63\u5b9a\u7b97\u5b50\u4e0aVNE\u6700\u5927\u5316\u7684\u535a\u5f08\u8bba\u89e3\u91ca\uff0c\u5e76\u5e94\u7528\u4e8e\u6838\u5b66\u4e60\u4e2d\u7684\u8868\u793a\u9009\u62e9\u548c\u77e9\u9635\u8865\u5168\u95ee\u9898\u3002", "motivation": "\u51af\u00b7\u8bfa\u4f9d\u66fc\u71b5\u5728\u91cf\u5b50\u4fe1\u606f\u8bba\u4e2d\u662f\u57fa\u672c\u91cf\uff0c\u6700\u8fd1\u88ab\u673a\u5668\u5b66\u4e60\u7528\u4f5c\u6838\u77e9\u9635\u548c\u6838\u534f\u65b9\u5dee\u7b97\u5b50\u7684\u8c31\u591a\u6837\u6027\u5ea6\u91cf\u3002\u867d\u7136\u7ea6\u675f\u4e0b\u6700\u5927\u5316VNE\u5728\u91cf\u5b50\u8bbe\u7f6e\u4e2d\u5df2\u77e5\uff0c\u4f46\u7ecf\u5178\u6700\u5927\u71b5\u6846\u67b6\u7684\u51b3\u7b56\u8bba\u548c\u535a\u5f08\u8bba\u89e3\u91ca\u5c1a\u672a\u5728\u6570\u636e\u9a71\u52a8\u80cc\u666f\u4e0b\u4e3aVNE\u660e\u786e\u53d1\u5c55\u3002", "method": "\u5c06Gr\u00fcnwald\u548cDawid\u7684\u6700\u5927\u71b5\u539f\u7406\u7684\u6781\u5c0f\u6781\u5927\u516c\u5f0f\u6269\u5c55\u5230\u51af\u00b7\u8bfa\u4f9d\u66fc\u71b5\u8bbe\u7f6e\uff0c\u4e3a\u5bc6\u5ea6\u77e9\u9635\u548c\u8ff9\u5f52\u4e00\u5316\u534a\u6b63\u5b9a\u7b97\u5b50\u7684VNE\u6700\u5927\u5316\u63d0\u4f9b\u535a\u5f08\u8bba\u8bc1\u660e\u3002\u7136\u540e\u901a\u8fc7\u4e24\u4e2a\u5e94\u7528\u5c55\u793a\u6700\u5927VNE\u539f\u7406\uff1a1)\u901a\u8fc7\u57fa\u4e8e\u6838\u7684VNE\u6700\u5927\u5316\u4ece\u591a\u4e2a\u5f52\u4e00\u5316\u5d4c\u5165\u4e2d\u9009\u62e9\u6838\u8868\u793a\uff1b2)\u4ece\u90e8\u5206\u89c2\u6d4b\u6761\u76ee\u8865\u5168\u6838\u77e9\u9635\u3002", "result": "\u8be5\u6846\u67b6\u4e3aVNE\u6700\u5927\u5316\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u89e3\u91ca\uff0c\u5c06\u6700\u5927VNE\u89e3\u89c6\u4e3a\u8c31\u57df\u4e2d\u6700\u4e0d\u627f\u8bfa\u7684\u63a8\u65ad\u3002\u63d0\u51fa\u7684\u6700\u5927VNE\u539f\u7406\u4e3a\u6838\u5b66\u4e60\u4e2d\u7684VNE\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u4fe1\u606f\u8bba\u57fa\u7840\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u5c06\u7ecf\u5178\u6700\u5927\u71b5\u539f\u7406\u6269\u5c55\u5230\u51af\u00b7\u8bfa\u4f9d\u66fc\u71b5\uff0c\u5efa\u7acb\u4e86VNE\u6700\u5927\u5316\u7684\u535a\u5f08\u8bba\u57fa\u7840\uff0c\u4e3a\u6838\u5b66\u4e60\u4e2d\u7684\u8c31\u591a\u6837\u6027\u5ea6\u91cf\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2602.02126", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02126", "abs": "https://arxiv.org/abs/2602.02126", "authors": ["Junhan Kim", "Gukryeol Lee", "Seungwoo Son", "Jeewook Kim", "Yongkweon Jeon"], "title": "Two-Stage Grid Optimization for Group-wise Quantization of LLMs", "comment": "ICASSP 2026", "summary": "Group-wise quantization is an effective strategy for mitigating accuracy degradation in low-bit quantization of large language models (LLMs). Among existing methods, GPTQ has been widely adopted due to its efficiency; however, it neglects input statistics and inter-group correlations when determining group scales, leading to a mismatch with its goal of minimizing layer-wise reconstruction loss. In this work, we propose a two-stage optimization framework for group scales that explicitly minimizes the layer-wise reconstruction loss. In the first stage, performed prior to GPTQ, we initialize each group scale to minimize the group-wise reconstruction loss, thereby incorporating input statistics. In the second stage, we freeze the integer weights obtained via GPTQ and refine the group scales to minimize the layer-wise reconstruction loss. To this end, we employ the coordinate descent algorithm and derive a closed-form update rule, which enables efficient refinement without costly numerical optimization. Notably, our derivation incorporates the quantization errors from preceding layers to prevent error accumulation. Experimental results demonstrate that our method consistently enhances group-wise quantization, achieving higher accuracy with negligible overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u4f18\u5316\u6846\u67b6\u6539\u8fdbLLM\u5206\u7ec4\u91cf\u5316\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5c42\u91cd\u6784\u635f\u5931\u63d0\u5347\u7cbe\u5ea6", "motivation": "GPTQ\u7b49\u73b0\u6709\u5206\u7ec4\u91cf\u5316\u65b9\u6cd5\u5ffd\u7565\u4e86\u8f93\u5165\u7edf\u8ba1\u548c\u7ec4\u95f4\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u4e0e\u6700\u5c0f\u5316\u5c42\u91cd\u6784\u635f\u5931\u7684\u76ee\u6807\u4e0d\u5339\u914d", "method": "\u4e24\u9636\u6bb5\u4f18\u5316\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728GPTQ\u524d\u521d\u59cb\u5316\u7ec4\u5c3a\u5ea6\u4ee5\u6700\u5c0f\u5316\u7ec4\u91cd\u6784\u635f\u5931\uff1b\u7b2c\u4e8c\u9636\u6bb5\u51bb\u7ed3GPTQ\u6574\u6570\u6743\u91cd\uff0c\u4f7f\u7528\u5750\u6807\u4e0b\u964d\u7b97\u6cd5\u548c\u95ed\u5f0f\u66f4\u65b0\u89c4\u5219\u4f18\u5316\u7ec4\u5c3a\u5ea6\u4ee5\u6700\u5c0f\u5316\u5c42\u91cd\u6784\u635f\u5931", "result": "\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u80fd\u6301\u7eed\u63d0\u5347\u5206\u7ec4\u91cf\u5316\u7cbe\u5ea6\uff0c\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\u4e14\u5f00\u9500\u53ef\u5ffd\u7565", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5206\u7ec4\u91cf\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u663e\u5f0f\u6700\u5c0f\u5316\u5c42\u91cd\u6784\u635f\u5931\u663e\u8457\u63d0\u5347\u4e86LLM\u4f4e\u6bd4\u7279\u91cf\u5316\u7684\u7cbe\u5ea6"}}
{"id": "2602.02128", "categories": ["cs.LG", "cs.AI", "physics.bio-ph", "q-bio.BM", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.02128", "abs": "https://arxiv.org/abs/2602.02128", "authors": ["Nima Shoghi", "Yuxuan Liu", "Yuning Shen", "Rob Brekelmans", "Pan Li", "Quanquan Gu"], "title": "Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics", "comment": "For associated project page, see https://bytedance-seed.github.io/ConfRover/starmd", "summary": "Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.", "AI": {"tldr": "STAR-MD\u662f\u4e00\u4e2aSE(3)-\u7b49\u53d8\u7684\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u8054\u5408\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\u751f\u6210\u5fae\u79d2\u7ea7\u86cb\u767d\u8d28\u8f68\u8ff9\uff0c\u5728ATLAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u6a21\u62df\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u8fbe\u5230\u751f\u7269\u5b66\u76f8\u5173\u7684\u65f6\u95f4\u5c3a\u5ea6\u3002\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u751f\u6210\u4e2d\u5b58\u5728\u67b6\u6784\u9650\u5236\u3001\u8bef\u5dee\u7d2f\u79ef\u548c\u65f6\u7a7a\u52a8\u6001\u5efa\u6a21\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSTAR-MD\uff1a\u4e00\u4e2a\u53ef\u6269\u5c55\u7684SE(3)-\u7b49\u53d8\u6269\u6563\u6a21\u578b\uff0c\u91c7\u7528\u56e0\u679c\u6269\u6563\u53d8\u6362\u5668\uff0c\u901a\u8fc7\u8054\u5408\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\u9ad8\u6548\u6355\u6349\u590d\u6742\u7684\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u907f\u514d\u73b0\u6709\u65b9\u6cd5\u7684\u5185\u5b58\u74f6\u9888\u3002", "result": "\u5728ATLAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTAR-MD\u5728\u6240\u6709\u6307\u6807\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u663e\u8457\u6539\u5584\u4e86\u6784\u8c61\u8986\u76d6\u5ea6\u3001\u7ed3\u6784\u6709\u6548\u6027\u548c\u52a8\u6001\u4fdd\u771f\u5ea6\u3002\u80fd\u591f\u6210\u529f\u5916\u63a8\u751f\u6210\u7a33\u5b9a\u7684\u5fae\u79d2\u7ea7\u8f68\u8ff9\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u5b8c\u5168\u5931\u8d25\u3002", "conclusion": "STAR-MD\u7684\u8054\u5408\u65f6\u7a7a\u5efa\u6a21\u80fd\u591f\u5728\u751f\u7269\u5b66\u76f8\u5173\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u5b9e\u73b0\u7a33\u5065\u7684\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u4e3a\u52a0\u901f\u63a2\u7d22\u86cb\u767d\u8d28\u529f\u80fd\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u751f\u6210\u4e2d\u7684\u4e25\u91cd\u5c40\u9650\u6027\u3002"}}
{"id": "2602.02137", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02137", "abs": "https://arxiv.org/abs/2602.02137", "authors": ["Minghao Li", "Ruihang Wang", "Rui Tan", "Yonggang Wen"], "title": "DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations", "comment": null, "summary": "Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence.", "AI": {"tldr": "DCoPilot\uff1a\u4e00\u4e2a\u7528\u4e8e\u52a8\u6001\u6570\u636e\u4e2d\u5fc3\u64cd\u4f5c\u7684\u6df7\u5408\u751f\u6210\u63a7\u5236\u7b56\u7565\u6846\u67b6\uff0c\u7ed3\u5408LLM\u7b26\u53f7\u751f\u6210\u7ed3\u6784\u5316\u5956\u52b1\u5f62\u5f0f\u548c\u8d85\u7f51\u7edc\u53c2\u6570\u751f\u6210\u7b56\u7565\u6743\u91cd\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u7b56\u7565\u751f\u6210\u4ee5\u5e94\u5bf9\u9891\u7e41\u7684\u52a8\u6001\u53d8\u5316\u548cSLA\u53d8\u66f4\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u4e2d\u5fc3\u8fd0\u884c\u5728\u9ad8\u529f\u7387\u5bc6\u5ea6\u548c\u5feb\u901f\u53d8\u5316\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u9700\u8981\u5206\u949f\u7ea7\u9002\u5e94\u4ee5\u786e\u4fdd\u5b89\u5168\u548c\u80fd\u6548\u3002\u4f20\u7edf\u624b\u52a8\u8bbe\u8ba1\u7684DRL\u4ee3\u7406\u65e0\u6cd5\u8ddf\u4e0a\u6570\u636e\u4e2d\u5fc3\u9891\u7e41\u7684\u52a8\u6001\u53d8\u5316\u548cSLA\u53d8\u66f4\uff0c\u5bfc\u81f4\u89c4\u8303\u5230\u7b56\u7565\u7684\u6ede\u540e\uff0c\u53ef\u80fd\u5f15\u53d1\u670d\u52a1\u4e2d\u65ad\u3002", "method": "DCoPilot\u7ed3\u5408\u4e24\u79cd\u751f\u6210\u8303\u5f0f\uff1a1\uff09LLM\u6267\u884c\u7ed3\u6784\u5316\u5956\u52b1\u5f62\u5f0f\u7684\u7b26\u53f7\u751f\u6210\uff1b2\uff09\u8d85\u7f51\u7edc\u6267\u884c\u7b56\u7565\u6743\u91cd\u7684\u53c2\u6570\u751f\u6210\u3002\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u6a21\u62df\u6269\u5c55\uff08\u5728\u591a\u6837\u5316\u573a\u666f\u4e2d\u538b\u529b\u6d4b\u8bd5\u5956\u52b1\u5019\u9009\uff09\u3001\u5143\u7b56\u7565\u84b8\u998f\uff08\u8bad\u7ec3\u8d85\u7f51\u7edc\u8f93\u51fa\u57fa\u4e8eSLA\u548c\u573a\u666f\u5d4c\u5165\u7684\u7b56\u7565\u6743\u91cd\uff09\u3001\u5728\u7ebf\u9002\u5e94\uff08\u5b9e\u73b0\u96f6\u6837\u672c\u7b56\u7565\u751f\u6210\uff09\u3002", "result": "\u5728\u4e94\u4e2a\u63a7\u5236\u4efb\u52a1\u65cf\uff08\u6db5\u76d6\u591a\u6837\u5316\u6570\u636e\u4e2d\u5fc3\u7ec4\u4ef6\uff09\u7684\u8bc4\u4f30\u4e2d\uff0cDCoPilot\u5b9e\u73b0\u63a5\u8fd1\u96f6\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u5e76\u5728\u6240\u6709\u89c4\u8303\u53d8\u5316\u4e2d\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u57fa\u4e8eLLM\u7684\u7edf\u4e00\u5956\u52b1\u751f\u6210\u5728\u5b9e\u73b0\u7a33\u5b9a\u8d85\u7f51\u7edc\u6536\u655b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "DCoPilot\u901a\u8fc7\u7ed3\u5408LLM\u7684\u7b26\u53f7\u751f\u6210\u80fd\u529b\u548c\u8d85\u7f51\u7edc\u7684\u53c2\u6570\u751f\u6210\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u6570\u636e\u4e2d\u5fc3\u73af\u5883\u4e2d\u89c4\u8303\u5230\u7b56\u7565\u7684\u6ede\u540e\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ca\u65f6\u6709\u6548\u7684\u63a7\u5236\u7b56\u7565\u751f\u6210\uff0c\u786e\u4fdd\u6570\u636e\u4e2d\u5fc3\u7684\u5b89\u5168\u548c\u80fd\u6548\u8fd0\u884c\u3002"}}
{"id": "2602.02139", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02139", "abs": "https://arxiv.org/abs/2602.02139", "authors": ["Pawel Batorski", "Paul Swoboda"], "title": "EvoMU: Evolutionary Machine Unlearning", "comment": null, "summary": "Machine unlearning aims to unlearn specified training data (e.g. sensitive or copyrighted material). A prominent approach is to fine-tune an existing model with an unlearning loss that retains overall utility. The space of suitable unlearning loss functions is vast, making the search for an optimal loss function daunting. Additionally, there might not even exist a universally optimal loss function: differences in the structure and overlap of the forget and retain data can cause a loss to work well in one setting but over-unlearn or under-unlearn in another. Our approach EvoMU tackles these two challenges simultaneously. An evolutionary search procedure automatically finds task-specific losses in the vast space of possible unlearning loss functions. This allows us to find dataset-specific losses that match or outperform existing losses from the literature, without the need for a human-in-the-loop. This work is therefore an instance of automatic scientific discovery, a.k.a. an AI co-scientist. In contrast to previous AI co-scientist works, we do so on a budget: We achieve SotA results using a small 4B parameter model (Qwen3-4B-Thinking), showing the potential of AI co-scientists with limited computational resources. Our experimental evaluation shows that we surpass previous loss-based unlearning formulations on TOFU-5%, TOFU-10%, MUSE and WMDP by synthesizing novel unlearning losses. Our code is available at https://github.com/Batorskq/EvoMU.", "AI": {"tldr": "EvoMU\u4f7f\u7528\u8fdb\u5316\u641c\u7d22\u81ea\u52a8\u53d1\u73b0\u7279\u5b9a\u4efb\u52a1\u7684\u9057\u5fd8\u635f\u5931\u51fd\u6570\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u673a\u5668\u9057\u5fd8\u6027\u80fd", "motivation": "\u673a\u5668\u9057\u5fd8\u9700\u8981\u627e\u5230\u5408\u9002\u7684\u635f\u5931\u51fd\u6570\uff0c\u4f46\u641c\u7d22\u7a7a\u95f4\u5de8\u5927\u4e14\u6ca1\u6709\u901a\u7528\u7684\u6700\u4f18\u635f\u5931\u51fd\u6570\uff0c\u4e0d\u540c\u6570\u636e\u96c6\u7ed3\u6784\u5dee\u5f02\u5bfc\u81f4\u73b0\u6709\u635f\u5931\u51fd\u6570\u6548\u679c\u4e0d\u4e00", "method": "\u91c7\u7528\u8fdb\u5316\u641c\u7d22\u7a0b\u5e8f\u81ea\u52a8\u5728\u53ef\u80fd\u7684\u9057\u5fd8\u635f\u5931\u51fd\u6570\u7a7a\u95f4\u4e2d\u5bfb\u627e\u4efb\u52a1\u7279\u5b9a\u7684\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u5c0f\u578b4B\u53c2\u6570\u6a21\u578b(Qwen3-4B-Thinking)\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0", "result": "\u5728TOFU-5%\u3001TOFU-10%\u3001MUSE\u548cWMDP\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u5148\u524d\u7684\u57fa\u4e8e\u635f\u5931\u7684\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u65b0\u9896\u7684\u9057\u5fd8\u635f\u5931\u51fd\u6570\u5b9e\u73b0\u6700\u5148\u8fdb\u7ed3\u679c", "conclusion": "EvoMU\u5c55\u793a\u4e86AI\u534f\u79d1\u5b66\u5bb6\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u7279\u5b9a\u6570\u636e\u96c6\u7684\u4f18\u5316\u635f\u5931\u51fd\u6570\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884"}}
{"id": "2602.02143", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02143", "abs": "https://arxiv.org/abs/2602.02143", "authors": ["Shubham Toshniwal", "Aleksander Ficek", "Siddhartha Jain", "Wei Du", "Vahid Noroozi", "Sadegh Mahdavi", "Somshubra Majumdar", "Igor Gitman"], "title": "Learning Generative Selection for Best-of-N", "comment": null, "summary": "Scaling test-time compute via parallel sampling can substantially improve LLM reasoning, but is often limited by Best-of-N selection quality. Generative selection methods, such as GenSelect, address this bottleneck, yet strong selection performance remains largely limited to large models. We show that small reasoning models can acquire strong GenSelect capabilities through targeted reinforcement learning. To this end, we synthesize selection tasks from large-scale math and code instruction datasets by filtering to instances with both correct and incorrect candidate solutions, and train 1.7B-parameter models with DAPO to reward correct selections. Across math (AIME24, AIME25, HMMT25) and code (LiveCodeBench) reasoning benchmarks, our models consistently outperform prompting and majority-voting baselines, often approaching or exceeding much larger models. Moreover, these gains generalize to selecting outputs from stronger models despite training only on outputs from weaker models. Overall, our results establish reinforcement learning as a scalable way to unlock strong generative selection in small models, enabling efficient test-time scaling.", "AI": {"tldr": "\u5c0f\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u83b7\u5f97\u5f3a\u5927\u7684\u751f\u6210\u9009\u62e9\u80fd\u529b\uff0c\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e2d\u8d85\u8d8a\u63d0\u793a\u548c\u591a\u6570\u6295\u7968\u57fa\u7ebf\uff0c\u63a5\u8fd1\u6216\u8d85\u8fc7\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u901a\u8fc7\u5e76\u884c\u91c7\u6837\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53ef\u4ee5\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u53d7\u9650\u4e8eBest-of-N\u9009\u62e9\u8d28\u91cf\u3002\u751f\u6210\u9009\u62e9\u65b9\u6cd5\u5982GenSelect\u867d\u7136\u89e3\u51b3\u4e86\u8fd9\u4e00\u74f6\u9888\uff0c\u4f46\u5f3a\u5927\u7684\u9009\u62e9\u6027\u80fd\u4e3b\u8981\u5c40\u9650\u4e8e\u5927\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5c0f\u578b\u63a8\u7406\u6a21\u578b\u662f\u5426\u4e5f\u80fd\u83b7\u5f97\u5f3a\u5927\u7684\u751f\u6210\u9009\u62e9\u80fd\u529b\u3002", "method": "\u4ece\u5927\u89c4\u6a21\u6570\u5b66\u548c\u4ee3\u7801\u6307\u4ee4\u6570\u636e\u96c6\u4e2d\u7b5b\u9009\u51fa\u540c\u65f6\u5305\u542b\u6b63\u786e\u548c\u9519\u8bef\u5019\u9009\u89e3\u51b3\u65b9\u6848\u7684\u5b9e\u4f8b\uff0c\u5408\u6210\u9009\u62e9\u4efb\u52a1\u3002\u4f7f\u7528DAPO\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec31.7B\u53c2\u6570\u6a21\u578b\uff0c\u5956\u52b1\u6b63\u786e\u7684\u9009\u62e9\u884c\u4e3a\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\uff08AIME24\u3001AIME25\u3001HMMT25\uff09\u548c\u4ee3\u7801\u63a8\u7406\uff08LiveCodeBench\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8bad\u7ec3\u7684\u5c0f\u6a21\u578b\u6301\u7eed\u4f18\u4e8e\u63d0\u793a\u548c\u591a\u6570\u6295\u7968\u57fa\u7ebf\uff0c\u901a\u5e38\u63a5\u8fd1\u6216\u8d85\u8fc7\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002\u8fd9\u4e9b\u589e\u76ca\u80fd\u591f\u6cdb\u5316\u5230\u9009\u62e9\u66f4\u5f3a\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u5c3d\u7ba1\u8bad\u7ec3\u65f6\u53ea\u4f7f\u7528\u4e86\u8f83\u5f31\u6a21\u578b\u7684\u8f93\u51fa\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u662f\u89e3\u9501\u5c0f\u578b\u6a21\u578b\u5f3a\u5927\u751f\u6210\u9009\u62e9\u80fd\u529b\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\u5728\u751f\u6210\u9009\u62e9\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2602.02146", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02146", "abs": "https://arxiv.org/abs/2602.02146", "authors": ["Sunho Kim", "Susik Yoon"], "title": "Back to the Future: Look-ahead Augmentation and Parallel Self-Refinement for Time Series Forecasting", "comment": "4 pages, Short paper accepted at The Web Conference (WWW) 2026", "summary": "Long-term time series forecasting (LTSF) remains challenging due to the trade-off between parallel efficiency and sequential modeling of temporal coherence. Direct multi-step forecasting (DMS) methods enable fast, parallel prediction of all future horizons but often lose temporal consistency across steps, while iterative multi-step forecasting (IMS) preserves temporal dependencies at the cost of error accumulation and slow inference. To bridge this gap, we propose Back to the Future (BTTF), a simple yet effective framework that enhances forecasting stability through look-ahead augmentation and self-corrective refinement. Rather than relying on complex model architectures, BTTF revisits the fundamental forecasting process and refines a base model by ensembling the second-stage models augmented with their initial predictions. Despite its simplicity, our approach consistently improves long-horizon accuracy and mitigates the instability of linear forecasting models, achieving accuracy gains of up to 58% and demonstrating stable improvements even when the first-stage model is trained under suboptimal conditions. These results suggest that leveraging model-generated forecasts as augmentation can be a simple yet powerful way to enhance long-term prediction, even without complex architectures.", "AI": {"tldr": "BTTF\u6846\u67b6\u901a\u8fc7\u524d\u77bb\u589e\u5f3a\u548c\u81ea\u6821\u6b63\u7cbe\u70bc\u63d0\u5347\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7a33\u5b9a\u6027\uff0c\u65e0\u9700\u590d\u6742\u67b6\u6784\u5373\u53ef\u663e\u8457\u6539\u5584\u9884\u6d4b\u7cbe\u5ea6", "motivation": "\u89e3\u51b3\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5e76\u884c\u6548\u7387\u4e0e\u65f6\u95f4\u4e00\u81f4\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002\u76f4\u63a5\u591a\u6b65\u9884\u6d4b\u65b9\u6cd5\u867d\u5feb\u4f46\u5931\u53bb\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u8fed\u4ee3\u591a\u6b65\u9884\u6d4b\u4fdd\u6301\u4f9d\u8d56\u5173\u7cfb\u4f46\u5b58\u5728\u8bef\u5dee\u7d2f\u79ef\u548c\u63a8\u7406\u6162\u7684\u95ee\u9898", "method": "\u63d0\u51faBack to the Future (BTTF)\u6846\u67b6\uff0c\u901a\u8fc7\u524d\u77bb\u589e\u5f3a\u548c\u81ea\u6821\u6b63\u7cbe\u70bc\u589e\u5f3a\u9884\u6d4b\u7a33\u5b9a\u6027\u3002\u4e0d\u4f9d\u8d56\u590d\u6742\u67b6\u6784\uff0c\u800c\u662f\u91cd\u65b0\u5ba1\u89c6\u57fa\u7840\u9884\u6d4b\u8fc7\u7a0b\uff0c\u901a\u8fc7\u96c6\u6210\u7b2c\u4e8c\u9636\u6bb5\u6a21\u578b\uff08\u7528\u5176\u521d\u59cb\u9884\u6d4b\u8fdb\u884c\u589e\u5f3a\uff09\u6765\u7cbe\u70bc\u57fa\u7840\u6a21\u578b", "result": "BTTF\u4e00\u81f4\u6539\u5584\u957f\u671f\u9884\u6d4b\u7cbe\u5ea6\uff0c\u7f13\u89e3\u7ebf\u6027\u9884\u6d4b\u6a21\u578b\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u5b9e\u73b0\u9ad8\u8fbe58%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5373\u4f7f\u5728\u6b21\u4f18\u6761\u4ef6\u4e0b\u8bad\u7ec3\u7684\u7b2c\u4e00\u9636\u6bb5\u6a21\u578b\u4e5f\u80fd\u7a33\u5b9a\u6539\u8fdb", "conclusion": "\u5229\u7528\u6a21\u578b\u751f\u6210\u7684\u9884\u6d4b\u4f5c\u4e3a\u589e\u5f3a\u53ef\u4ee5\u6210\u4e3a\u63d0\u5347\u957f\u671f\u9884\u6d4b\u7684\u7b80\u5355\u800c\u5f3a\u5927\u7684\u65b9\u6cd5\uff0c\u5373\u4f7f\u6ca1\u6709\u590d\u6742\u67b6\u6784\u4e5f\u80fd\u5b9e\u73b0\u663e\u8457\u6539\u8fdb"}}
{"id": "2602.02150", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02150", "abs": "https://arxiv.org/abs/2602.02150", "authors": ["Chu Zhao", "Enneng Yang", "Yuting Liu", "Jianzhe Zhao", "Guibing Guo"], "title": "ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning", "comment": "19 ppages", "summary": "Test-time reinforcement learning generates multiple candidate answers via repeated rollouts and performs online updates using pseudo-labels constructed by majority voting. To reduce overhead and improve exploration, prior work introduces tree structured rollouts, which share reasoning prefixes and branch at key nodes to improve sampling efficiency. However, this paradigm still faces two challenges: (1) high entropy branching can trigger rollout collapse, where the branching budget concentrates on a few trajectories with consecutive high-entropy segments, rapidly reducing the number of effective branches; (2) early pseudo-labels are noisy and biased, which can induce self-reinforcing overfitting, causing the policy to sharpen prematurely and suppress exploration. To address these issues, we propose Entropy Confidence Hybrid Group Relative Policy Optimization (ECHO). During rollout, ECHO jointly leverages local entropy and group level confidence to adaptively control branch width, and further introduces online confidence-based pruning to terminate persistently low confidence branches, avoiding high entropy traps and mitigating collapse. During policy updates, ECHO employs confidence adaptive clipping and an entropy confidence hybrid advantage shaping approach to enhance training robustness and mitigate early stage bias. Experiments demonstrate that ECHO achieves consistent gains on multiple mathematical and visual reasoning benchmarks, and generalizes more effectively under a limited rollout budget.", "AI": {"tldr": "\u63d0\u51fa\u4e86ECHO\u65b9\u6cd5\uff0c\u901a\u8fc7\u71b5-\u7f6e\u4fe1\u5ea6\u6df7\u5408\u5206\u652f\u63a7\u5236\u548c\u7f6e\u4fe1\u5ea6\u81ea\u9002\u5e94\u526a\u679d\u89e3\u51b3\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u652f\u5d29\u6e83\u548c\u65e9\u671f\u4f2a\u6807\u7b7e\u566a\u58f0\u95ee\u9898\uff0c\u5728\u6570\u5b66\u548c\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u91c7\u7528\u6811\u72b6\u7ed3\u6784rollout\u5171\u4eab\u63a8\u7406\u524d\u7f00\uff0c\u4f46\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a1\uff09\u9ad8\u71b5\u5206\u652f\u53ef\u80fd\u5bfc\u81f4rollout\u5d29\u6e83\uff0c\u5206\u652f\u9884\u7b97\u96c6\u4e2d\u5728\u5c11\u6570\u9ad8\u71b5\u8f68\u8ff9\u4e0a\uff1b2\uff09\u65e9\u671f\u4f2a\u6807\u7b7e\u566a\u58f0\u5927\u4e14\u5b58\u5728\u504f\u5dee\uff0c\u5bfc\u81f4\u7b56\u7565\u8fc7\u65e9\u9510\u5316\u5e76\u6291\u5236\u63a2\u7d22\u3002", "method": "\u63d0\u51faECHO\u65b9\u6cd5\uff1a1\uff09\u5728rollout\u9636\u6bb5\uff0c\u8054\u5408\u5229\u7528\u5c40\u90e8\u71b5\u548c\u7ec4\u7ea7\u7f6e\u4fe1\u5ea6\u81ea\u9002\u5e94\u63a7\u5236\u5206\u652f\u5bbd\u5ea6\uff0c\u5e76\u5f15\u5165\u5728\u7ebf\u7f6e\u4fe1\u5ea6\u526a\u679d\u7ec8\u6b62\u6301\u7eed\u4f4e\u7f6e\u4fe1\u5ea6\u5206\u652f\uff1b2\uff09\u5728\u7b56\u7565\u66f4\u65b0\u9636\u6bb5\uff0c\u91c7\u7528\u7f6e\u4fe1\u5ea6\u81ea\u9002\u5e94\u88c1\u526a\u548c\u71b5-\u7f6e\u4fe1\u5ea6\u6df7\u5408\u4f18\u52bf\u5851\u5f62\u65b9\u6cd5\u589e\u5f3a\u8bad\u7ec3\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cECHO\u5728\u591a\u4e2a\u6570\u5b66\u548c\u89c6\u89c9\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e00\u81f4\u6027\u80fd\u63d0\u5347\uff0c\u5728\u6709\u9650rollout\u9884\u7b97\u4e0b\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ECHO\u901a\u8fc7\u81ea\u9002\u5e94\u5206\u652f\u63a7\u5236\u548c\u9c81\u68d2\u7b56\u7565\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u652f\u5d29\u6e83\u548c\u65e9\u671f\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u91c7\u6837\u6548\u7387\u548c\u63a2\u7d22\u80fd\u529b\u3002"}}
{"id": "2602.02151", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02151", "abs": "https://arxiv.org/abs/2602.02151", "authors": ["Yuli Zhou", "Qingxuan Chen", "Luca Benini", "Guolei Sun", "Yawei Li"], "title": "Revisiting Adaptive Rounding with Vectorized Reparameterization for LLM Quantization", "comment": "17 pages, 6 figures, 14 tables", "summary": "Adaptive Rounding has emerged as an alternative to round-to-nearest (RTN) for post-training quantization by enabling cross-element error cancellation. Yet, dense and element-wise rounding matrices are prohibitively expensive for billion-parameter large language models (LLMs). We revisit adaptive rounding from an efficiency perspective and propose VQRound, a parameter-efficient optimization framework that reparameterizes the rounding matrix into a compact codebook. Unlike low-rank alternatives, VQRound minimizes the element-wise worst-case error under $L_\\infty$ norm, which is critical for handling heavy-tailed weight distributions in LLMs. Beyond reparameterization, we identify rounding initialization as a decisive factor and develop a lightweight end-to-end finetuning pipeline that optimizes codebooks across all layers using only 128 samples. Extensive experiments on OPT, LLaMA, LLaMA2, and Qwen3 models demonstrate that VQRound achieves better convergence than traditional adaptive rounding at the same number of steps while using as little as 0.2% of the trainable parameters. Our results show that adaptive rounding can be made both scalable and fast-fitting. The code is available at https://github.com/zhoustan/VQRound.", "AI": {"tldr": "VQRound\uff1a\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u91cf\u5316\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u820d\u5165\u77e9\u9635\u91cd\u65b0\u53c2\u6570\u5316\u4e3a\u7d27\u51d1\u7801\u672c\uff0c\u663e\u8457\u51cf\u5c11\u81ea\u9002\u5e94\u820d\u5165\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301LLM\u91cf\u5316\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u81ea\u9002\u5e94\u820d\u5165\u65b9\u6cd5\u9700\u8981\u5bc6\u96c6\u7684\u9010\u5143\u7d20\u820d\u5165\u77e9\u9635\uff0c\u5bf9\u4e8e\u5341\u4ebf\u53c2\u6570\u7ea7\u522b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u81ea\u9002\u5e94\u820d\u5165\u4f18\u52bf\uff08\u8de8\u5143\u7d20\u8bef\u5dee\u62b5\u6d88\uff09\u53c8\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faVQRound\u6846\u67b6\uff1a1) \u5c06\u820d\u5165\u77e9\u9635\u91cd\u65b0\u53c2\u6570\u5316\u4e3a\u7d27\u51d1\u7801\u672c\uff1b2) \u5728L\u221e\u8303\u6570\u4e0b\u6700\u5c0f\u5316\u9010\u5143\u7d20\u6700\u574f\u60c5\u51b5\u8bef\u5dee\uff1b3) \u8bc6\u522b\u820d\u5165\u521d\u59cb\u5316\u4f5c\u4e3a\u5173\u952e\u56e0\u7d20\uff1b4) \u5f00\u53d1\u8f7b\u91cf\u7ea7\u7aef\u5230\u7aef\u5fae\u8c03\u6d41\u7a0b\uff0c\u4ec5\u9700128\u4e2a\u6837\u672c\u4f18\u5316\u6240\u6709\u5c42\u7684\u7801\u672c\u3002", "result": "\u5728OPT\u3001LLaMA\u3001LLaMA2\u548cQwen3\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVQRound\u5728\u76f8\u540c\u6b65\u6570\u4e0b\u6bd4\u4f20\u7edf\u81ea\u9002\u5e94\u820d\u5165\u6536\u655b\u66f4\u597d\uff0c\u540c\u65f6\u4ec5\u4f7f\u75280.2%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u3002\u8bc1\u660e\u81ea\u9002\u5e94\u820d\u5165\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u548c\u5feb\u901f\u62df\u5408\u3002", "conclusion": "VQRound\u6210\u529f\u89e3\u51b3\u4e86\u81ea\u9002\u5e94\u820d\u5165\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u7801\u672c\u91cd\u65b0\u53c2\u6570\u5316\u548c\u8f7b\u91cf\u5fae\u8c03\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u91cf\u5316\uff0c\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02157", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02157", "abs": "https://arxiv.org/abs/2602.02157", "authors": ["Egor Serov", "Ilya Kuleshov", "Alexey Zaytsev"], "title": "Efficient Neural Controlled Differential Equations via Attentive Kernel Smoothing", "comment": null, "summary": "Neural Controlled Differential Equations (Neural CDEs) provide a powerful continuous-time framework for sequence modeling, yet the roughness of the driving control path often restricts their efficiency. Standard splines introduce high-frequency variations that force adaptive solvers to take excessively small steps, driving up the Number of Function Evaluations (NFE). We propose a novel approach to Neural CDE path construction that replaces exact interpolation with Kernel and Gaussian Process (GP) smoothing, enabling explicit control over trajectory regularity. To recover details lost during smoothing, we propose an attention-based Multi-View CDE (MV-CDE) and its convolutional extension (MVC-CDE), which employ learnable queries to inform path reconstruction. This framework allows the model to distribute representational capacity across multiple trajectories, each capturing distinct temporal patterns. Empirical results demonstrate that our method, MVC-CDE with GP, achieves state-of-the-art accuracy while significantly reducing NFEs and total inference time compared to spline-based baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u7684\u65b0\u578b\u8def\u5f84\u6784\u5efa\u65b9\u6cd5\uff0c\u7528\u6838\u548c\u9ad8\u65af\u8fc7\u7a0b\u5e73\u6ed1\u66ff\u4ee3\u7cbe\u786e\u63d2\u503c\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u89c6\u56feCDE\u6765\u6062\u590d\u5e73\u6ed1\u4e2d\u4e22\u5931\u7684\u7ec6\u8282\uff0c\u663e\u8457\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u548c\u63a8\u7406\u65f6\u95f4", "motivation": "\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\u5f88\u5f3a\u5927\uff0c\u4f46\u9a71\u52a8\u63a7\u5236\u8def\u5f84\u7684\u7c97\u7cd9\u6027\u9650\u5236\u4e86\u5176\u6548\u7387\u3002\u6807\u51c6\u6837\u6761\u63d2\u503c\u5f15\u5165\u9ad8\u9891\u53d8\u5316\uff0c\u8feb\u4f7f\u81ea\u9002\u5e94\u6c42\u89e3\u5668\u91c7\u53d6\u8fc7\u5c0f\u7684\u6b65\u957f\uff0c\u5bfc\u81f4\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u8fc7\u9ad8", "method": "1) \u7528\u6838\u548c\u9ad8\u65af\u8fc7\u7a0b\u5e73\u6ed1\u66ff\u4ee3\u7cbe\u786e\u63d2\u503c\uff0c\u663e\u5f0f\u63a7\u5236\u8f68\u8ff9\u6b63\u5219\u6027\uff1b2) \u63d0\u51fa\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u89c6\u56feCDE\u53ca\u5176\u5377\u79ef\u6269\u5c55\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u67e5\u8be2\u6765\u544a\u77e5\u8def\u5f84\u91cd\u5efa\uff1b3) \u5141\u8bb8\u6a21\u578b\u5728\u591a\u4e2a\u8f68\u8ff9\u95f4\u5206\u914d\u8868\u793a\u80fd\u529b\uff0c\u6bcf\u4e2a\u8f68\u8ff9\u6355\u83b7\u4e0d\u540c\u7684\u65f6\u95f4\u6a21\u5f0f", "result": "\u63d0\u51fa\u7684MVC-CDE with GP\u65b9\u6cd5\u5728\u8fbe\u5230\u6700\u5148\u8fdb\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u548c\u603b\u63a8\u7406\u65f6\u95f4\uff0c\u76f8\u6bd4\u57fa\u4e8e\u6837\u6761\u7684\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u8def\u5f84\u5e73\u6ed1\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u89c6\u56fe\u67b6\u6784\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u9ad8\u6548\u7684\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u8ba1\u7b97\u6548\u7387"}}
{"id": "2602.02161", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02161", "abs": "https://arxiv.org/abs/2602.02161", "authors": ["Aniq Ur Rahman", "Justin P. Coon"], "title": "Generating Causal Temporal Interaction Graphs for Counterfactual Validation of Temporal Link Prediction", "comment": null, "summary": "Temporal link prediction (TLP) models are commonly evaluated based on predictive accuracy, yet such evaluations do not assess whether these models capture the causal mechanisms that govern temporal interactions. In this work, we propose a framework for counterfactual validation of TLP models by generating causal temporal interaction graphs (CTIGs) with known ground-truth causal structure. We first introduce a structural equation model for continuous-time event sequences that supports both excitatory and inhibitory effects, and then extend this mechanism to temporal interaction graphs. To compare causal models, we propose a distance metric based on cross-model predictive error, and empirically validate the hypothesis that predictors trained on one causal model degrade when evaluated on sufficiently distant models. Finally, we instantiate counterfactual evaluation under (i) controlled causal shifts between generating models and (ii) timestamp shuffling as a stochastic distortion with measurable causal distance. Our framework provides a foundation for causality-aware benchmarking.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u6a21\u578b\u7684\u53cd\u4e8b\u5b9e\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5177\u6709\u5df2\u77e5\u56e0\u679c\u7ed3\u6784\u7684\u65f6\u95f4\u4ea4\u4e92\u56fe\u6765\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u6355\u6349\u5230\u56e0\u679c\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u9884\u6d4b\u51c6\u786e\u6027\u8bc4\u4f30\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u65e0\u6cd5\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u771f\u6b63\u6355\u6349\u5230\u65f6\u95f4\u4ea4\u4e92\u7684\u56e0\u679c\u673a\u5236\uff0c\u9700\u8981\u4e00\u79cd\u56e0\u679c\u611f\u77e5\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "1) \u63d0\u51fa\u652f\u6301\u5174\u594b\u548c\u6291\u5236\u6548\u5e94\u7684\u8fde\u7eed\u65f6\u95f4\u4e8b\u4ef6\u5e8f\u5217\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\uff1b2) \u5c06\u8be5\u673a\u5236\u6269\u5c55\u5230\u65f6\u95f4\u4ea4\u4e92\u56fe\uff1b3) \u63d0\u51fa\u57fa\u4e8e\u8de8\u6a21\u578b\u9884\u6d4b\u8bef\u5dee\u7684\u8ddd\u79bb\u5ea6\u91cf\uff1b4) \u5728\u4e24\u79cd\u573a\u666f\u4e0b\u5b9e\u4f8b\u5316\u53cd\u4e8b\u5b9e\u8bc4\u4f30\uff1a\u751f\u6210\u6a21\u578b\u95f4\u7684\u53d7\u63a7\u56e0\u679c\u504f\u79fb\u548c\u65f6\u95f4\u6233\u91cd\u6392\u4f5c\u4e3a\u53ef\u6d4b\u91cf\u56e0\u679c\u8ddd\u79bb\u7684\u968f\u673a\u5931\u771f\u3002", "result": "\u7ecf\u9a8c\u9a8c\u8bc1\u4e86\u5047\u8bbe\uff1a\u5728\u4e00\u4e2a\u56e0\u679c\u6a21\u578b\u4e0a\u8bad\u7ec3\u7684\u5206\u7c7b\u5668\u5728\u8bc4\u4f30\u8db3\u591f\u8fdc\u7684\u6a21\u578b\u65f6\u6027\u80fd\u4f1a\u4e0b\u964d\u3002\u8be5\u6846\u67b6\u4e3a\u56e0\u679c\u611f\u77e5\u57fa\u51c6\u6d4b\u8bd5\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u6a21\u578b\u53cd\u4e8b\u5b9e\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5177\u6709\u5df2\u77e5\u56e0\u679c\u7ed3\u6784\u7684\u56fe\u6765\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u6355\u6349\u5230\u56e0\u679c\u673a\u5236\uff0c\u4e3a\u56e0\u679c\u611f\u77e5\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.02162", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02162", "abs": "https://arxiv.org/abs/2602.02162", "authors": ["Ratmir Miftachov", "Bruno Charron", "Simon Valentin"], "title": "Interpretable Tabular Foundation Models via In-Context Kernel Regression", "comment": null, "summary": "Tabular foundation models like TabPFN and TabICL achieve state-of-the-art performance through in-context learning, yet their architectures remain fundamentally opaque. We introduce KernelICL, a framework to enhance tabular foundation models with quantifiable sample-based interpretability. Building on the insight that in-context learning is akin to kernel regression, we make this mechanism explicit by replacing the final prediction layer with kernel functions (Gaussian, dot-product, kNN) so that every prediction is a transparent weighted average of training labels. We introduce a two-dimensional taxonomy that formally unifies standard kernel methods, modern neighbor-based approaches, and attention mechanisms under a single framework, and quantify inspectability via the perplexity of the weight distribution over training samples. On 55 TALENT benchmark datasets, KernelICL achieves performance on par with existing tabular foundation models, demonstrating that explicit kernel constraints on the final layer enable inspectable predictions without sacrificing performance.", "AI": {"tldr": "KernelICL\u6846\u67b6\u901a\u8fc7\u5c06\u8868\u683c\u57fa\u7840\u6a21\u578b\u7684\u6700\u7ec8\u9884\u6d4b\u5c42\u66ff\u6362\u4e3a\u6838\u51fd\u6570\uff0c\u5b9e\u73b0\u53ef\u91cf\u5316\u7684\u57fa\u4e8e\u6837\u672c\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u900f\u660e\u9884\u6d4b\u3002", "motivation": "\u5c3d\u7ba1TabPFN\u548cTabICL\u7b49\u8868\u683c\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f46\u5176\u67b6\u6784\u672c\u8d28\u4e0a\u662f\u4e0d\u900f\u660e\u7684\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u589e\u5f3a\u8fd9\u4e9b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u6027\u80fd\u4f18\u52bf\u3002", "method": "\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7c7b\u4f3c\u4e8e\u6838\u56de\u5f52\u7684\u6d1e\u5bdf\uff0c\u5c06\u6700\u7ec8\u9884\u6d4b\u5c42\u66ff\u6362\u4e3a\u6838\u51fd\u6570\uff08\u9ad8\u65af\u6838\u3001\u70b9\u79ef\u6838\u3001k\u8fd1\u90bb\uff09\uff0c\u4f7f\u6bcf\u4e2a\u9884\u6d4b\u90fd\u6210\u4e3a\u8bad\u7ec3\u6807\u7b7e\u7684\u900f\u660e\u52a0\u6743\u5e73\u5747\u3002\u5f15\u5165\u4e8c\u7ef4\u5206\u7c7b\u6cd5\u7edf\u4e00\u6807\u51c6\u6838\u65b9\u6cd5\u3001\u73b0\u4ee3\u57fa\u4e8e\u90bb\u5c45\u7684\u65b9\u6cd5\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u6743\u91cd\u5206\u5e03\u7684\u56f0\u60d1\u5ea6\u91cf\u5316\u53ef\u68c0\u67e5\u6027\u3002", "result": "\u572855\u4e2aTALENT\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cKernelICL\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u8868\u683c\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u8868\u660e\u5bf9\u6700\u7ec8\u5c42\u65bd\u52a0\u663e\u5f0f\u6838\u7ea6\u675f\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u53ef\u68c0\u67e5\u7684\u9884\u6d4b\u3002", "conclusion": "KernelICL\u6846\u67b6\u6210\u529f\u5730\u5c06\u53ef\u89e3\u91ca\u6027\u5f15\u5165\u8868\u683c\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u6838\u51fd\u6570\u5b9e\u73b0\u900f\u660e\u9884\u6d4b\uff0c\u4e3a\u8868\u683c\u6570\u636e\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.02164", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02164", "abs": "https://arxiv.org/abs/2602.02164", "authors": ["Pengfei He", "Ash Fox", "Lesly Miculicich", "Stefan Friedli", "Daniel Fabian", "Burak Gokturk", "Jiliang Tang", "Chen-Yu Lee", "Tomas Pfister", "Long T. Le"], "title": "Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents", "comment": null, "summary": "Large language models (LLMs) have shown promise in assisting cybersecurity tasks, yet existing approaches struggle with automatic vulnerability discovery and exploitation due to limited interaction, weak execution grounding, and a lack of experience reuse. We propose Co-RedTeam, a security-aware multi-agent framework designed to mirror real-world red-teaming workflows by integrating security-domain knowledge, code-aware analysis, execution-grounded iterative reasoning, and long-term memory. Co-RedTeam decomposes vulnerability analysis into coordinated discovery and exploitation stages, enabling agents to plan, execute, validate, and refine actions based on real execution feedback while learning from prior trajectories. Extensive evaluations on challenging security benchmarks demonstrate that Co-RedTeam consistently outperforms strong baselines across diverse backbone models, achieving over 60% success rate in vulnerability exploitation and over 10% absolute improvement in vulnerability detection. Ablation and iteration studies further confirm the critical role of execution feedback, structured interaction, and memory for building robust and generalizable cybersecurity agents.", "AI": {"tldr": "Co-RedTeam\u662f\u4e00\u4e2a\u5b89\u5168\u611f\u77e5\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u5b89\u5168\u9886\u57df\u77e5\u8bc6\u3001\u4ee3\u7801\u611f\u77e5\u5206\u6790\u3001\u6267\u884c\u57fa\u7840\u8fed\u4ee3\u63a8\u7406\u548c\u957f\u671f\u8bb0\u5fc6\uff0c\u6a21\u62df\u771f\u5b9e\u7ea2\u961f\u5de5\u4f5c\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u6f0f\u6d1e\u53d1\u73b0\u548c\u5229\u7528\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4ea4\u4e92\u6709\u9650\u3001\u6267\u884c\u57fa\u7840\u8584\u5f31\u3001\u7f3a\u4e4f\u7ecf\u9a8c\u590d\u7528\uff0c\u96be\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u6f0f\u6d1e\u53d1\u73b0\u548c\u5229\u7528\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u7ea2\u961f\u5de5\u4f5c\u6d41\u7a0b\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faCo-RedTeam\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u6f0f\u6d1e\u5206\u6790\u5206\u89e3\u4e3a\u534f\u8c03\u7684\u53d1\u73b0\u548c\u5229\u7528\u9636\u6bb5\u3002\u667a\u80fd\u4f53\u80fd\u591f\u89c4\u5212\u3001\u6267\u884c\u3001\u9a8c\u8bc1\u548c\u57fa\u4e8e\u771f\u5b9e\u6267\u884c\u53cd\u9988\u4f18\u5316\u884c\u52a8\uff0c\u540c\u65f6\u4ece\u5148\u524d\u8f68\u8ff9\u4e2d\u5b66\u4e60\u3002\u6846\u67b6\u96c6\u6210\u4e86\u5b89\u5168\u9886\u57df\u77e5\u8bc6\u3001\u4ee3\u7801\u611f\u77e5\u5206\u6790\u3001\u6267\u884c\u57fa\u7840\u8fed\u4ee3\u63a8\u7406\u548c\u957f\u671f\u8bb0\u5fc6\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCo-RedTeam\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u6f0f\u6d1e\u5229\u7528\u65b9\u9762\u8fbe\u5230\u8d85\u8fc760%\u7684\u6210\u529f\u7387\uff0c\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u5b9e\u73b0\u8d85\u8fc710%\u7684\u7edd\u5bf9\u6539\u8fdb\u3002\u6d88\u878d\u548c\u8fed\u4ee3\u7814\u7a76\u8bc1\u5b9e\u4e86\u6267\u884c\u53cd\u9988\u3001\u7ed3\u6784\u5316\u4ea4\u4e92\u548c\u8bb0\u5fc6\u5bf9\u4e8e\u6784\u5efa\u9c81\u68d2\u4e14\u53ef\u6cdb\u5316\u7684\u7f51\u7edc\u5b89\u5168\u667a\u80fd\u4f53\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "Co-RedTeam\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u7ea2\u961f\u5de5\u4f5c\u6d41\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LLM\u5728\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6784\u5efa\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u548c\u5229\u7528\u6f0f\u6d1e\u7684\u9c81\u68d2\u7f51\u7edc\u5b89\u5168\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02173", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02173", "abs": "https://arxiv.org/abs/2602.02173", "authors": ["Jiancheng Tu", "Wenqi Fan", "Zhibin Wu"], "title": "Generalized Optimal Classification Trees: A Mixed-Integer Programming Approach", "comment": null, "summary": "Global optimization of decision trees is a long-standing challenge in combinatorial optimization, yet such models play an important role in interpretable machine learning. Although the problem has been investigated for several decades, only recent advances in discrete optimization have enabled practical algorithms for solving optimal classification tree problems on real-world datasets. Mixed-integer programming (MIP) offers a high degree of modeling flexibility, and we therefore propose a MIP-based framework for learning optimal classification trees under nonlinear performance metrics, such as the F1-score, that explicitly addresses class imbalance. To improve scalability, we develop problem-specific acceleration techniques, including a tailored branch-and-cut algorithm, an instance-reduction scheme, and warm-start strategies. We evaluate the proposed approach on 50 benchmark datasets. The computational results show that the framework can efficiently optimize nonlinear metrics while achieving strong predictive performance and reduced solution times compared with existing methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u975e\u7ebf\u6027\u6027\u80fd\u6307\u6807\uff08\u5982F1\u5206\u6570\uff09\u4e0b\u5b66\u4e60\u6700\u4f18\u5206\u7c7b\u6811\uff0c\u7279\u522b\u9488\u5bf9\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7279\u5b9a\u52a0\u901f\u6280\u672f\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u51b3\u7b56\u6811\u7684\u5168\u5c40\u4f18\u5316\u662f\u7ec4\u5408\u4f18\u5316\u4e2d\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\uff0c\u4f46\u5728\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u4f18\u5316\u975e\u7ebf\u6027\u6027\u80fd\u6307\u6807\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u65f6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u975e\u7ebf\u6027\u6027\u80fd\u6307\u6807\u4e0b\u5b66\u4e60\u6700\u4f18\u5206\u7c7b\u6811\u3002\u5f00\u53d1\u4e86\u95ee\u9898\u7279\u5b9a\u7684\u52a0\u901f\u6280\u672f\uff1a\u5b9a\u5236\u7684\u5206\u652f\u5207\u5272\u7b97\u6cd5\u3001\u5b9e\u4f8b\u7f29\u51cf\u65b9\u6848\u548c\u70ed\u542f\u52a8\u7b56\u7565\u3002", "result": "\u572850\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u80fd\u9ad8\u6548\u4f18\u5316\u975e\u7ebf\u6027\u6307\u6807\uff0c\u540c\u65f6\u5b9e\u73b0\u5f3a\u5927\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u51cf\u5c11\u4e86\u6c42\u89e3\u65f6\u95f4\u3002", "conclusion": "\u63d0\u51fa\u7684MIP\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6700\u4f18\u5206\u7c7b\u6811\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u975e\u7ebf\u6027\u6307\u6807\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u573a\u666f\u4e0b\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u52a0\u901f\u6280\u672f\u5b9e\u73b0\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.02179", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02179", "abs": "https://arxiv.org/abs/2602.02179", "authors": ["Marina Mastroleo", "Alberto Archetti", "Federico Mastroleo", "Matteo Matteucci"], "title": "SurvKAN: A Fully Parametric Survival Model Based on Kolmogorov-Arnold Networks", "comment": null, "summary": "Accurate prediction of time-to-event outcomes is critical for clinical decision-making, treatment planning, and resource allocation in modern healthcare. While classical survival models such as Cox remain widely adopted in standard practice, they rely on restrictive assumptions, including linear covariate relationships and proportional hazards over time, that often fail to capture real-world clinical dynamics. Recent deep learning approaches like DeepSurv and DeepHit offer improved expressivity but sacrifice interpretability, limiting clinical adoption where trust and transparency are paramount. Hybrid models incorporating Kolmogorov-Arnold Networks (KANs), such as CoxKAN, have begun to address this trade-off but remain constrained by the semi-parametric Cox framework. In this work we introduce SurvKAN, a fully parametric, time-continuous survival model based on KAN architectures that eliminates the proportional hazards constraint. SurvKAN treats time as an explicit input to a KAN that directly predicts the log-hazard function, enabling end-to-end training on the full survival likelihood. Our architecture preserves interpretability through learnable univariate functions that indicate how individual features influence risk over time. Extensive experiments on standard survival benchmarks demonstrate that SurvKAN achieves competitive or superior performance compared to classical and state-of-the-art baselines across concordance and calibration metrics. Additionally, interpretability analyses reveal clinically meaningful patterns that align with medical domain knowledge.", "AI": {"tldr": "SurvKAN\uff1a\u57fa\u4e8eKAN\u67b6\u6784\u7684\u5b8c\u5168\u53c2\u6570\u5316\u3001\u65f6\u95f4\u8fde\u7eed\u7684\u751f\u5b58\u5206\u6790\u6a21\u578b\uff0c\u6d88\u9664\u4e86\u6bd4\u4f8b\u98ce\u9669\u5047\u8bbe\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd", "motivation": "\u4f20\u7edfCox\u6a21\u578b\u4f9d\u8d56\u6bd4\u4f8b\u98ce\u9669\u7b49\u9650\u5236\u6027\u5047\u8bbe\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e34\u5e8a\u52a8\u6001\uff1b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5982DeepSurv\u548cDeepHit\u867d\u7136\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u4f46\u727a\u7272\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u91c7\u7528\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u53c8\u80fd\u6d88\u9664\u4f20\u7edf\u5047\u8bbe\u9650\u5236\u7684\u751f\u5b58\u5206\u6790\u6a21\u578b\u3002", "method": "\u63d0\u51faSurvKAN\u6a21\u578b\uff0c\u57fa\u4e8eKolmogorov-Arnold Networks\u67b6\u6784\uff0c\u5c06\u65f6\u95f4\u4f5c\u4e3a\u663e\u5f0f\u8f93\u5165\uff0c\u76f4\u63a5\u9884\u6d4b\u5bf9\u6570\u98ce\u9669\u51fd\u6570\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5355\u53d8\u91cf\u51fd\u6570\u5b9e\u73b0\u7aef\u5230\u7aef\u8bad\u7ec3\u3002\u6a21\u578b\u5b8c\u5168\u53c2\u6570\u5316\u4e14\u65f6\u95f4\u8fde\u7eed\uff0c\u6d88\u9664\u4e86\u6bd4\u4f8b\u98ce\u9669\u7ea6\u675f\u3002", "result": "\u5728\u6807\u51c6\u751f\u5b58\u5206\u6790\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSurvKAN\u5728\u4e00\u81f4\u6027\u6307\u6570\u548c\u6821\u51c6\u6307\u6807\u4e0a\u8fbe\u5230\u7ade\u4e89\u6027\u6216\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u57fa\u7ebf\u3002\u53ef\u89e3\u91ca\u6027\u5206\u6790\u63ed\u793a\u4e86\u4e0e\u533b\u5b66\u9886\u57df\u77e5\u8bc6\u4e00\u81f4\u7684\u4e34\u5e8a\u6709\u610f\u4e49\u6a21\u5f0f\u3002", "conclusion": "SurvKAN\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b8c\u5168\u53c2\u6570\u5316\u3001\u65f6\u95f4\u8fde\u7eed\u7684\u751f\u5b58\u5206\u6790\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u6d88\u9664\u4e86\u6bd4\u4f8b\u98ce\u9669\u5047\u8bbe\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u4e14\u53ef\u4fe1\u7684\u9884\u6d4b\u5de5\u5177\u3002"}}
{"id": "2602.02180", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02180", "abs": "https://arxiv.org/abs/2602.02180", "authors": ["Weikang Meng", "Liangyu Huo", "Yadan Luo", "Jiawen Guan", "Jingyi Zhang", "Yingjian Li", "Zheng Zhang"], "title": "STILL: Selecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMs", "comment": null, "summary": "Linearizing pretrained large language models (LLMs) primarily relies on intra-layer hybrid attention mechanisms to alleviate the quadratic complexity of standard softmax attention. Existing methods perform token routing based on sliding-window partitions, resulting in position-based selection and fails to capture token-specific global importance. Meanwhile, linear attention further suffers from distribution shift caused by learnable feature maps that distort pretrained feature magnitudes. Motivated by these limitations, we propose STILL, an intra-layer hybrid linearization framework for efficiently linearizing LLMs. STILL introduces a Self-Saliency Score with strong local-global consistency, enabling accurate token selection using sliding-window computation, and retains salient tokens for sparse softmax attention while summarizing the remaining context via linear attention. To preserve pretrained representations, we design a Norm-Preserved Feature Map (NP-Map) that decouples feature direction from magnitude and reinjects pretrained norms. We further adopt a unified training-inference architecture with chunk-wise parallelization and delayed selection to improve hardware efficiency. Experiments show that STILL matches or surpasses the original pretrained model on commonsense and general reasoning tasks, and achieves up to a 86.2% relative improvement over prior linearized attention methods on long-context benchmarks.", "AI": {"tldr": "STILL\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u7ebf\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u663e\u8457\u6027\u8bc4\u5206\u548c\u89c4\u8303\u4fdd\u6301\u7279\u5f81\u6620\u5c04\uff0c\u5728\u4fdd\u6301\u9884\u8bad\u7ec3\u8868\u793a\u7684\u540c\u65f6\u5b9e\u73b0\u7ebf\u6027\u6ce8\u610f\u529b\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u5316\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u5206\u533a\u7684\u6807\u8bb0\u8def\u7531\u65b9\u6cd5\u53ea\u80fd\u8fdb\u884c\u57fa\u4e8e\u4f4d\u7f6e\u7684\u9009\u62e9\uff0c\u65e0\u6cd5\u6355\u6349\u6807\u8bb0\u7279\u5b9a\u7684\u5168\u5c40\u91cd\u8981\u6027\uff1b2\uff09\u7ebf\u6027\u6ce8\u610f\u529b\u5b58\u5728\u7531\u53ef\u5b66\u4e60\u7279\u5f81\u6620\u5c04\u5f15\u8d77\u7684\u5206\u5e03\u504f\u79fb\uff0c\u8fd9\u4f1a\u626d\u66f2\u9884\u8bad\u7ec3\u7279\u5f81\u7684\u5927\u5c0f\u3002", "method": "STILL\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1\uff09\u5177\u6709\u5f3a\u5c40\u90e8-\u5168\u5c40\u4e00\u81f4\u6027\u7684\u81ea\u663e\u8457\u6027\u8bc4\u5206\uff0c\u7528\u4e8e\u51c6\u786e\u9009\u62e9\u6807\u8bb0\uff1b2\uff09\u89c4\u8303\u4fdd\u6301\u7279\u5f81\u6620\u5c04\uff08NP-Map\uff09\uff0c\u5c06\u7279\u5f81\u65b9\u5411\u4e0e\u5927\u5c0f\u89e3\u8026\u5e76\u91cd\u65b0\u6ce8\u5165\u9884\u8bad\u7ec3\u89c4\u8303\uff1b3\uff09\u7edf\u4e00\u7684\u8bad\u7ec3-\u63a8\u7406\u67b6\u6784\uff0c\u91c7\u7528\u5206\u5757\u5e76\u884c\u5316\u548c\u5ef6\u8fdf\u9009\u62e9\u4ee5\u63d0\u9ad8\u786c\u4ef6\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSTILL\u5728\u5e38\u8bc6\u548c\u4e00\u822c\u63a8\u7406\u4efb\u52a1\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u539f\u59cb\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u5148\u524d\u7684\u7ebf\u6027\u5316\u6ce8\u610f\u529b\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe86.2%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002", "conclusion": "STILL\u901a\u8fc7\u521b\u65b0\u7684\u81ea\u663e\u8457\u6027\u8bc4\u5206\u548c\u89c4\u8303\u4fdd\u6301\u7279\u5f81\u6620\u5c04\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7ebf\u6027\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u6548\u7387\u3002"}}
{"id": "2602.02195", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02195", "abs": "https://arxiv.org/abs/2602.02195", "authors": ["Ao Sun", "Hongtao Zhang", "Heng Zhou", "Yixuan Ma", "Yiran Qin", "Tongrui Su", "Yan Liu", "Zhanyu Ma", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "State Rank Dynamics in Linear Attention LLMs", "comment": null, "summary": "Linear Attention Large Language Models (LLMs) offer a compelling recurrent formulation that compresses context into a fixed-size state matrix, enabling constant-time inference. However, the internal dynamics of this compressed state remain largely opaque. In this work, we present a comprehensive study on the runtime state dynamics of state-of-the-art Linear Attention models. We uncover a fundamental phenomenon termed State Rank Stratification, characterized by a distinct spectral bifurcation among linear attention heads: while one group maintains an effective rank oscillating near zero, the other exhibits rapid growth that converges to an upper bound. Extensive experiments across diverse inference contexts reveal that these dynamics remain strikingly consistent, indicating that the identity of a head,whether low-rank or high-rank,is an intrinsic structural property acquired during pre-training, rather than a transient state dependent on the input data. Furthermore, our diagnostic probes reveal a surprising functional divergence: low-rank heads are indispensable for model reasoning, whereas high-rank heads exhibit significant redundancy. Leveraging this insight, we propose Joint Rank-Norm Pruning, a zero-shot strategy that achieves a 38.9\\% reduction in KV-cache overhead while largely maintaining model accuracy.", "AI": {"tldr": "\u7ebf\u6027\u6ce8\u610f\u529bLLM\u7684\u72b6\u6001\u77e9\u9635\u5b58\u5728\"\u72b6\u6001\u79e9\u5206\u5c42\"\u73b0\u8c61\uff1a\u90e8\u5206\u6ce8\u610f\u529b\u5934\u4fdd\u6301\u63a5\u8fd1\u96f6\u7684\u4f4e\u79e9\uff0c\u53e6\u4e00\u90e8\u5206\u5219\u6536\u655b\u5230\u9ad8\u79e9\u4e0a\u9650\uff1b\u4f4e\u79e9\u5934\u5bf9\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff0c\u9ad8\u79e9\u5934\u5197\u4f59\u53ef\u526a\u679d", "motivation": "\u7ebf\u6027\u6ce8\u610f\u529bLLM\u901a\u8fc7\u56fa\u5b9a\u5927\u5c0f\u7684\u72b6\u6001\u77e9\u9635\u538b\u7f29\u4e0a\u4e0b\u6587\u5b9e\u73b0\u5e38\u6570\u65f6\u95f4\u63a8\u7406\uff0c\u4f46\u5176\u5185\u90e8\u72b6\u6001\u52a8\u6001\u673a\u5236\u4e0d\u900f\u660e\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u72b6\u6001\u77e9\u9635\u7684\u8fd0\u884c\u7279\u6027", "method": "\u5bf9\u6700\u5148\u8fdb\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u8fdb\u884c\u8fd0\u884c\u65f6\u72b6\u6001\u52a8\u6001\u7814\u7a76\uff0c\u5206\u6790\u6ce8\u610f\u529b\u5934\u7684\u79e9\u53d8\u5316\u89c4\u5f8b\uff0c\u8bbe\u8ba1\u8bca\u65ad\u63a2\u9488\u8bc4\u4f30\u529f\u80fd\u5dee\u5f02\uff0c\u63d0\u51fa\u8054\u5408\u79e9-\u8303\u6570\u526a\u679d\u7b56\u7565", "result": "\u53d1\u73b0\u72b6\u6001\u79e9\u5206\u5c42\u73b0\u8c61\uff1a\u6ce8\u610f\u529b\u5934\u5206\u4e3a\u4f4e\u79e9\u548c\u9ad8\u79e9\u4e24\u7c7b\uff0c\u8fd9\u79cd\u5206\u5c42\u662f\u9884\u8bad\u7ec3\u83b7\u5f97\u7684\u5185\u5728\u7ed3\u6784\u5c5e\u6027\u800c\u975e\u8f93\u5165\u4f9d\u8d56\u7684\u6682\u6001\uff1b\u4f4e\u79e9\u5934\u5bf9\u63a8\u7406\u5fc5\u4e0d\u53ef\u5c11\uff0c\u9ad8\u79e9\u5934\u5197\u4f59\uff1b\u526a\u679d\u7b56\u7565\u53ef\u51cf\u5c1138.9%\u7684KV\u7f13\u5b58\u5f00\u9500", "conclusion": "\u7ebf\u6027\u6ce8\u610f\u529bLLM\u7684\u72b6\u6001\u52a8\u6001\u5177\u6709\u7a33\u5b9a\u7684\u5185\u5728\u7ed3\u6784\u6a21\u5f0f\uff0c\u57fa\u4e8e\u72b6\u6001\u79e9\u5206\u5c42\u7684\u526a\u679d\u7b56\u7565\u80fd\u6709\u6548\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2602.02197", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02197", "abs": "https://arxiv.org/abs/2602.02197", "authors": ["Xindian Ma", "Yidi Lu", "Peng Zhang", "Jing Zhang"], "title": "Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models", "comment": "10 oages, 3 figures", "summary": "The integration of visual information into Large Language Models (LLMs) has enabled Multimodal LLMs (MLLMs), but the quadratic memory and computational costs of Transformer architectures remain a bottleneck. Existing KV cache eviction strategies fail to address the heterogeneous attention distributions between visual and text tokens, leading to suboptimal efficiency or degraded performance. In this paper, we propose Hierarchical Adaptive Eviction (HAE), a KV cache eviction framework that optimizes text-visual token interaction in MLLMs by implementing Dual-Attention Pruning during pre-filling (leveraging visual token sparsity and attention variance) and a Dynamic Decoding Eviction Strategy (inspired by OS Recycle Bins) during decoding. HAE minimizes KV cache usage across layers, reduces computational overhead via index broadcasting, and theoretically ensures superior information integrity and lower error bounds compared to greedy strategies, enhancing efficiency in both comprehension and generation tasks. Empirically, HAE reduces KV-Cache memory by 41\\% with minimal accuracy loss (0.3\\% drop) in image understanding tasks and accelerates story generation inference by 1.5x while maintaining output quality on Phi3.5-Vision-Instruct model.", "AI": {"tldr": "HAE\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u81ea\u9002\u5e94KV\u7f13\u5b58\u9a71\u9010\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6ce8\u610f\u529b\u526a\u679d\u548c\u52a8\u6001\u89e3\u7801\u9a71\u9010\u7b56\u7565\uff0c\u4f18\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u89c6\u89c9\u4e0e\u6587\u672ctoken\u7684\u4ea4\u4e92\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u5e76\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u9a71\u9010\u7b56\u7565\u672a\u80fd\u89e3\u51b3\u89c6\u89c9\u4e0e\u6587\u672ctoken\u4e4b\u95f4\u7684\u5f02\u8d28\u6ce8\u610f\u529b\u5206\u5e03\u95ee\u9898\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u6216\u6027\u80fd\u4e0b\u964d\u3002Transformer\u67b6\u6784\u7684\u4e8c\u6b21\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u662f\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u8981\u74f6\u9888\u3002", "method": "HAE\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u9884\u586b\u5145\u9636\u6bb5\u7684\u53cc\u6ce8\u610f\u529b\u526a\u679d\uff0c\u5229\u7528\u89c6\u89c9token\u7a00\u758f\u6027\u548c\u6ce8\u610f\u529b\u65b9\u5dee\uff1b2) \u89e3\u7801\u9636\u6bb5\u7684\u52a8\u6001\u89e3\u7801\u9a71\u9010\u7b56\u7565\uff08\u53d7\u64cd\u4f5c\u7cfb\u7edf\u56de\u6536\u7ad9\u542f\u53d1\uff09\u3002\u901a\u8fc7\u8de8\u5c42\u6700\u5c0f\u5316KV\u7f13\u5b58\u4f7f\u7528\u548c\u7d22\u5f15\u5e7f\u64ad\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u56fe\u50cf\u7406\u89e3\u4efb\u52a1\u4e2d\u51cf\u5c1141%\u7684KV\u7f13\u5b58\u5185\u5b58\uff0c\u4ec5\u635f\u59310.3%\u7684\u51c6\u786e\u7387\uff1b\u5728Phi3.5-Vision-Instruct\u6a21\u578b\u4e0a\uff0c\u6545\u4e8b\u751f\u6210\u63a8\u7406\u901f\u5ea6\u63d0\u53471.5\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "HAE\u901a\u8fc7\u5206\u5c42\u81ea\u9002\u5e94\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u89c6\u89c9\u4e0e\u6587\u672ctoken\u4ea4\u4e92\u7684\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\uff0c\u4e3aMLLM\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02201", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02201", "abs": "https://arxiv.org/abs/2602.02201", "authors": ["Abhijit Gupta"], "title": "Cardinality-Preserving Structured Sparse Graph Transformers for Molecular Property Prediction", "comment": null, "summary": "Drug discovery motivates efficient molecular property prediction under limited labeled data. Chemical space is vast, often estimated at approximately 10^60 drug-like molecules, while only thousands of drugs have been approved. As a result, self-supervised pretraining on large unlabeled molecular corpora has become essential for data-efficient molecular representation learning. We introduce **CardinalGraphFormer**, a graph transformer that incorporates Graphormer-inspired structural biases, including shortest-path distance and centrality, as well as direct-bond edge bias, within a structured sparse attention regime limited to shortest-path distance <= 3. The model further augments this design with a cardinality-preserving unnormalized aggregation channel over the same support set. Pretraining combines contrastive graph-level alignment with masked attribute reconstruction. Under a fully matched evaluation protocol, CardinalGraphFormer improves mean performance across all 11 evaluated tasks and achieves statistically significant gains on 10 of 11 public benchmarks spanning MoleculeNet, OGB, and TDC ADMET tasks when compared to strong reproduced baselines.", "AI": {"tldr": "CardinalGraphFormer\u662f\u4e00\u79cd\u56feTransformer\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408Graphormer\u7684\u7ed3\u6784\u504f\u7f6e\u548c\u7ed3\u6784\u5316\u7a00\u758f\u6ce8\u610f\u529b\uff0c\u5728\u5206\u5b50\u8868\u793a\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u6570\u636e\u9ad8\u6548\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u836f\u7269\u53d1\u73b0\u9700\u8981\u9ad8\u6548\u7684\u5206\u5b50\u6027\u8d28\u9884\u6d4b\uff0c\u4f46\u5316\u5b66\u7a7a\u95f4\u5de8\u5927\uff08\u7ea610^60\u4e2a\u836f\u7269\u6837\u5206\u5b50\uff09\uff0c\u800c\u83b7\u6279\u836f\u7269\u4ec5\u6570\u5343\u79cd\u3002\u56e0\u6b64\uff0c\u5229\u7528\u5927\u89c4\u6a21\u672a\u6807\u8bb0\u5206\u5b50\u6570\u636e\u8fdb\u884c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5bf9\u4e8e\u6570\u636e\u9ad8\u6548\u7684\u5206\u5b50\u8868\u793a\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faCardinalGraphFormer\u56feTransformer\uff0c\u6574\u5408Graphormer\u7684\u7ed3\u6784\u504f\u7f6e\uff08\u6700\u77ed\u8def\u5f84\u8ddd\u79bb\u548c\u4e2d\u5fc3\u6027\uff09\u4ee5\u53ca\u76f4\u63a5\u952e\u8fb9\u504f\u7f6e\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff08\u9650\u5236\u6700\u77ed\u8def\u5f84\u8ddd\u79bb\u22643\uff09\uff0c\u5e76\u6dfb\u52a0\u57fa\u6570\u4fdd\u6301\u7684\u975e\u5f52\u4e00\u5316\u805a\u5408\u901a\u9053\u3002\u9884\u8bad\u7ec3\u7ed3\u5408\u5bf9\u6bd4\u56fe\u7ea7\u5bf9\u9f50\u548c\u63a9\u7801\u5c5e\u6027\u91cd\u5efa\u3002", "result": "\u5728\u5b8c\u5168\u5339\u914d\u7684\u8bc4\u4f30\u534f\u8bae\u4e0b\uff0cCardinalGraphFormer\u5728\u6240\u670911\u4e2a\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5e73\u5747\u6027\u80fd\u5747\u6709\u63d0\u5347\uff0c\u5728MoleculeNet\u3001OGB\u548cTDC ADMET\u4efb\u52a1\u768411\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c10\u4e2a\u4efb\u52a1\u5b9e\u73b0\u4e86\u7edf\u8ba1\u663e\u8457\u589e\u76ca\u3002", "conclusion": "CardinalGraphFormer\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u504f\u7f6e\u548c\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u5206\u5b50\u8868\u793a\u5b66\u4e60\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6027\u80fd\uff0c\u4e3a\u6570\u636e\u9ad8\u6548\u7684\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02206", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02206", "abs": "https://arxiv.org/abs/2602.02206", "authors": ["Tong Yang", "Yemin Wang", "Chaoning Zhang", "Aming Wu"], "title": "Fat-Cat: Document-Driven Metacognitive Multi-Agent System for Complex Reasoning", "comment": null, "summary": "The effectiveness of LLM-based agents is often limited not by model capacity alone, but by how efficiently contextual information is utilized at runtime. Existing agent frameworks rely on rigid, syntax-heavy state representations such as nested JSON, which require models to devote a substantial portion of their limited attention to syntactic processing rather than semantic reasoning. In this paper, we propose Fat-Cat, a document-driven agent architecture that improves the signal-to-noise ratio of state management. By integrating three key components: (1) a Semantic File System that represents agent state as Markdown documents aligned with common pre-training corpora, (2) a Textual Strategy Evolution module that accumulates task-solving knowledge without parameter updates, and (3) a Closed-Loop Watcher that monitors reasoning trajectories to reduce hallucinations. Extensive reasoning, retrieval, and coding benchmarks, Fat-Cat consistently improves agent performance. It enables the Kimi-k2 model to outperform the proprietary GPT-4o baseline on HotPotQA. Replacing the document-based state with JSON leads to performance drop, while empirically validating the critical necessity of document-driven state modeling over rigid syntax. The code is available at https://github.com/answeryt/Fat-Cat.", "AI": {"tldr": "Fat-Cat\u662f\u4e00\u4e2a\u6587\u6863\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7Markdown\u6587\u6863\u8868\u793a\u72b6\u6001\u3001\u6587\u672c\u7b56\u7565\u6f14\u5316\u548c\u95ed\u73af\u76d1\u63a7\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u7684\u63a8\u7406\u6548\u7387\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aGPT-4o\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u6846\u67b6\u4f9d\u8d56\u5d4c\u5957JSON\u7b49\u8bed\u6cd5\u7e41\u91cd\u7684\u72b6\u6001\u8868\u793a\uff0c\u8feb\u4f7f\u6a21\u578b\u5c06\u6709\u9650\u6ce8\u610f\u529b\u6d6a\u8d39\u5728\u8bed\u6cd5\u5904\u7406\u800c\u975e\u8bed\u4e49\u63a8\u7406\u4e0a\uff0c\u9650\u5236\u4e86LLM\u667a\u80fd\u4f53\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u8bed\u4e49\u6587\u4ef6\u7cfb\u7edf\uff0c\u7528Markdown\u6587\u6863\u8868\u793a\u667a\u80fd\u4f53\u72b6\u6001\uff1b2) \u6587\u672c\u7b56\u7565\u6f14\u5316\u6a21\u5757\uff0c\u79ef\u7d2f\u4efb\u52a1\u89e3\u51b3\u77e5\u8bc6\uff1b3) \u95ed\u73af\u76d1\u63a7\u5668\uff0c\u76d1\u63a7\u63a8\u7406\u8f68\u8ff9\u51cf\u5c11\u5e7b\u89c9\u3002", "result": "\u5728\u63a8\u7406\u3001\u68c0\u7d22\u548c\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f7fKimi-k2\u6a21\u578b\u5728HotPotQA\u4e0a\u8d85\u8d8aGPT-4o\u57fa\u7ebf\u3002\u5b9e\u9a8c\u8bc1\u660e\u6587\u6863\u9a71\u52a8\u72b6\u6001\u5efa\u6a21\u4f18\u4e8eJSON\u8868\u793a\u3002", "conclusion": "\u6587\u6863\u9a71\u52a8\u7684\u72b6\u6001\u7ba1\u7406\u80fd\u663e\u8457\u63d0\u5347LLM\u667a\u80fd\u4f53\u7684\u4fe1\u53f7\u566a\u58f0\u6bd4\uff0c\u901a\u8fc7\u66f4\u81ea\u7136\u7684\u6587\u672c\u8868\u793a\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u662f\u672a\u6765\u667a\u80fd\u4f53\u67b6\u6784\u7684\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2602.02213", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02213", "abs": "https://arxiv.org/abs/2602.02213", "authors": ["Gregory Barber", "Todd C. Henry", "Mulugeta A. Haile"], "title": "Generating Physically Sound Designs from Text and a Set of Physical Constraints", "comment": "NeurIPS 2025", "summary": "We present TIDES, a text informed design approach for generating physically sound designs based on a textual description and a set of physical constraints. TIDES jointly optimizes structural (topology) and visual properties. A pre-trained text-image model is used to measure the design's visual alignment with a text prompt and a differentiable physics simulator is used to measure its physical performance. We evaluate TIDES on a series of structural optimization problems operating under different load and support conditions, at different resolutions, and experimentally in the lab by performing the 3-point bending test on 2D beam designs that are extruded and 3D printed. We find that it can jointly optimize the two objectives and return designs that satisfy engineering design requirements (compliance and density) while utilizing features specified by text.", "AI": {"tldr": "TIDES\u662f\u4e00\u79cd\u6587\u672c\u5f15\u5bfc\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7ed3\u6784\u548c\u89c6\u89c9\u5c5e\u6027\uff0c\u57fa\u4e8e\u6587\u672c\u63cf\u8ff0\u548c\u7269\u7406\u7ea6\u675f\u751f\u6210\u7269\u7406\u5408\u7406\u7684\u8bbe\u8ba1\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8003\u8651\u7269\u7406\u6027\u80fd\u548c\u89c6\u89c9\u7279\u5f81\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4f7f\u8bbe\u8ba1\u65e2\u80fd\u6ee1\u8db3\u5de5\u7a0b\u8981\u6c42\u53c8\u80fd\u4f53\u73b0\u6587\u672c\u63cf\u8ff0\u7684\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6587\u672c-\u56fe\u50cf\u6a21\u578b\u8bc4\u4f30\u8bbe\u8ba1\u4e0e\u6587\u672c\u63d0\u793a\u7684\u89c6\u89c9\u5bf9\u9f50\u5ea6\uff0c\u7ed3\u5408\u53ef\u5fae\u5206\u7269\u7406\u6a21\u62df\u5668\u8bc4\u4f30\u7269\u7406\u6027\u80fd\uff0c\u8054\u5408\u4f18\u5316\u7ed3\u6784\u548c\u89c6\u89c9\u5c5e\u6027\u3002", "result": "\u5728\u4e0d\u540c\u8d1f\u8f7d\u548c\u652f\u6491\u6761\u4ef6\u4e0b\u7684\u7ed3\u6784\u4f18\u5316\u95ee\u9898\u4e2d\uff0cTIDES\u80fd\u591f\u540c\u65f6\u4f18\u5316\u4e24\u4e2a\u76ee\u6807\uff0c\u8fd4\u56de\u6ee1\u8db3\u5de5\u7a0b\u8bbe\u8ba1\u8981\u6c42\uff08\u67d4\u987a\u6027\u548c\u5bc6\u5ea6\uff09\u5e76\u5229\u7528\u6587\u672c\u6307\u5b9a\u7279\u5f81\u7684\u8bbe\u8ba1\u3002", "conclusion": "TIDES\u80fd\u591f\u6210\u529f\u751f\u6210\u65e2\u6ee1\u8db3\u7269\u7406\u7ea6\u675f\u53c8\u4f53\u73b0\u6587\u672c\u63cf\u8ff0\u7279\u5f81\u7684\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u5de5\u7a0b\u6027\u80fd\u4e0e\u89c6\u89c9\u7279\u5f81\u7684\u8054\u5408\u4f18\u5316\u3002"}}
{"id": "2602.02215", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02215", "abs": "https://arxiv.org/abs/2602.02215", "authors": ["Sebastian M\u00fcller", "Vanessa Toborek", "Eike Stadtl\u00e4nder", "Tam\u00e1s Horv\u00e1th", "Brendan Balcerak Jackson", "Christian Bauckhage"], "title": "Scientific Theory of a Black-Box: A Life Cycle-Scale XAI Framework Based on Constructive Empiricism", "comment": null, "summary": "Explainable AI (XAI) offers a growing number of algorithms that aim to answer specific questions about black-box models. What is missing is a principled way to consolidate explanatory information about a fixed black-box model into a persistent, auditable artefact, that accompanies the black-box throughout its life cycle. We address this gap by introducing the notion of a scientific theory of a black (SToBB). Grounded in Constructive Empiricism, a SToBB fulfils three obligations: (i) empirical adequacy with respect to all available observations of black-box behaviour, (ii) adaptability via explicit update commitments that restore adequacy when new observations arrive, and (iii) auditability through transparent documentation of assumptions, construction choices, and update behaviour. We operationalise these obligations as a general framework that specifies an extensible observation base, a traceable hypothesis class, algorithmic components for construction and revision, and documentation sufficient for third-party assessment. Explanations for concrete stakeholder needs are then obtained by querying the maintained record through interfaces, rather than by producing isolated method outputs. As a proof of concept, we instantiate a complete SToBB for a neural-network classifier on a tabular task and introduce the Constructive Box Theoriser (CoBoT) algorithm, an online procedure that constructs and maintains an empirically adequate rule-based surrogate as observations accumulate. Together, these contributions position SToBBs as a life cycle-scale, inspectable point of reference that supports consistent, reusable analyses and systematic external scrutiny.", "AI": {"tldr": "\u63d0\u51fa\"\u9ed1\u76d2\u79d1\u5b66\u7406\u8bba\"\uff08SToBB\uff09\u6846\u67b6\uff0c\u5c06\u53ef\u89e3\u91caAI\u7684\u96f6\u6563\u89e3\u91ca\u6574\u5408\u4e3a\u4f34\u968f\u9ed1\u76d2\u6a21\u578b\u5168\u751f\u547d\u5468\u671f\u7684\u53ef\u5ba1\u8ba1\u3001\u53ef\u66f4\u65b0\u7684\u6301\u4e45\u5316\u77e5\u8bc6\u5e93\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91caAI\u65b9\u6cd5\u591a\u4e3a\u5b64\u7acb\u7b97\u6cd5\uff0c\u7f3a\u4e4f\u5c06\u9ed1\u76d2\u6a21\u578b\u7684\u89e3\u91ca\u4fe1\u606f\u6574\u5408\u4e3a\u6301\u4e45\u5316\u3001\u53ef\u5ba1\u8ba1\u3001\u53ef\u4f34\u968f\u6a21\u578b\u5168\u751f\u547d\u5468\u671f\u66f4\u65b0\u7684\u7cfb\u7edf\u6027\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u5efa\u6784\u7ecf\u9a8c\u4e3b\u4e49\u63d0\u51faSToBB\u6982\u5ff5\uff0c\u8981\u6c42\u6ee1\u8db3\u4e09\u4e2a\u4e49\u52a1\uff1a\u7ecf\u9a8c\u5145\u5206\u6027\u3001\u901a\u8fc7\u660e\u786e\u66f4\u65b0\u627f\u8bfa\u5b9e\u73b0\u9002\u5e94\u6027\u3001\u901a\u8fc7\u900f\u660e\u6587\u6863\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u6027\u3002\u5177\u4f53\u5b9e\u73b0\u5305\u62ec\u53ef\u6269\u5c55\u7684\u89c2\u5bdf\u5e93\u3001\u53ef\u8ffd\u6eaf\u7684\u5047\u8bbe\u7c7b\u3001\u6784\u5efa\u548c\u4fee\u8ba2\u7684\u7b97\u6cd5\u7ec4\u4ef6\u4ee5\u53ca\u7b2c\u4e09\u65b9\u8bc4\u4f30\u6587\u6863\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684SToBB\u5b9e\u4f8b\u548cCoBoT\u7b97\u6cd5\uff0c\u4e3a\u8868\u683c\u4efb\u52a1\u7684\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\u6784\u5efa\u5e76\u7ef4\u62a4\u7ecf\u9a8c\u5145\u5206\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u652f\u6301\u5728\u7ebf\u66f4\u65b0\u3002", "conclusion": "SToBB\u6846\u67b6\u4e3a\u9ed1\u76d2\u6a21\u578b\u63d0\u4f9b\u4e86\u5168\u751f\u547d\u5468\u671f\u89c4\u6a21\u7684\u53ef\u68c0\u67e5\u53c2\u8003\u70b9\uff0c\u652f\u6301\u4e00\u81f4\u3001\u53ef\u91cd\u7528\u7684\u5206\u6790\u548c\u7cfb\u7edf\u6027\u5916\u90e8\u5ba1\u67e5\uff0c\u5c06\u96f6\u6563\u89e3\u91ca\u8f6c\u53d8\u4e3a\u7ed3\u6784\u5316\u77e5\u8bc6\u5e93\u3002"}}
{"id": "2602.02224", "categories": ["cs.LG", "cs.AI", "math.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02224", "abs": "https://arxiv.org/abs/2602.02224", "authors": ["Georgi Ivanov", "Narmeen Oozeer", "Shivam Raval", "Tasana Pejovic", "Shriyash Upadhyay", "Amir Abdullah"], "title": "Spectral Superposition: A Theory of Feature Geometry", "comment": null, "summary": "Neural networks represent more features than they have dimensions via superposition, forcing features to share representational space. Current methods decompose activations into sparse linear features but discard geometric structure. We develop a theory for studying the geometric structre of features by analyzing the spectra (eigenvalues, eigenspaces, etc.) of weight derived matrices. In particular, we introduce the frame operator $F = WW^\\top$, which gives us a spectral measure that describes how each feature allocates norm across eigenspaces. While previous tools could describe the pairwise interactions between features, spectral methods capture the global geometry (``how do all features interact?''). In toy models of superposition, we use this theory to prove that capacity saturation forces spectral localization: features collapse onto single eigenspaces, organize into tight frames, and admit discrete classification via association schemes, classifying all geometries from prior work (simplices, polygons, antiprisms). The spectral measure formalism applies to arbitrary weight matrices, enabling diagnosis of feature localization beyond toy settings. These results point toward a broader program: applying operator theory to interpretability.", "AI": {"tldr": "\u63d0\u51fa\u8c31\u5206\u6790\u65b9\u6cd5\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u51e0\u4f55\u7ed3\u6784\uff0c\u8bc1\u660e\u5bb9\u91cf\u9971\u548c\u5bfc\u81f4\u8c31\u5b9a\u4f4d\uff0c\u7279\u5f81\u7ec4\u7ec7\u6210\u7d27\u6846\u67b6\uff0c\u53ef\u7528\u5173\u8054\u65b9\u6848\u5206\u7c7b", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u6fc0\u6d3b\u5206\u89e3\u4e3a\u7a00\u758f\u7ebf\u6027\u7279\u5f81\u4f46\u4e22\u5f03\u51e0\u4f55\u7ed3\u6784\uff0c\u9700\u8981\u65b0\u7406\u8bba\u5206\u6790\u7279\u5f81\u51e0\u4f55\u7ed3\u6784", "method": "\u5f15\u5165\u6846\u67b6\u7b97\u5b50F=WW^\u22a4\uff0c\u901a\u8fc7\u8c31\u5206\u6790\uff08\u7279\u5f81\u503c\u3001\u7279\u5f81\u7a7a\u95f4\u7b49\uff09\u7814\u7a76\u7279\u5f81\u51e0\u4f55\u7ed3\u6784\uff0c\u5efa\u7acb\u8c31\u6d4b\u5ea6\u63cf\u8ff0\u7279\u5f81\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u8303\u6570\u5206\u914d", "result": "\u5728\u53e0\u52a0\u73a9\u5177\u6a21\u578b\u4e2d\u8bc1\u660e\u5bb9\u91cf\u9971\u548c\u5f3a\u5236\u8c31\u5b9a\u4f4d\uff1a\u7279\u5f81\u574d\u7f29\u5230\u5355\u4e2a\u7279\u5f81\u7a7a\u95f4\uff0c\u7ec4\u7ec7\u6210\u7d27\u6846\u67b6\uff0c\u53ef\u901a\u8fc7\u5173\u8054\u65b9\u6848\u8fdb\u884c\u79bb\u6563\u5206\u7c7b\uff0c\u6db5\u76d6\u5148\u524d\u6240\u6709\u51e0\u4f55\u7ed3\u6784\uff08\u5355\u7eaf\u5f62\u3001\u591a\u8fb9\u5f62\u3001\u53cd\u68f1\u67f1\uff09", "conclusion": "\u8c31\u6d4b\u5ea6\u5f62\u5f0f\u9002\u7528\u4e8e\u4efb\u610f\u6743\u91cd\u77e9\u9635\uff0c\u53ef\u8bca\u65ad\u7279\u5f81\u5b9a\u4f4d\uff0c\u4e3a\u5e94\u7528\u7b97\u5b50\u7406\u8bba\u5230\u53ef\u89e3\u91ca\u6027\u5f00\u8f9f\u65b0\u65b9\u5411"}}
{"id": "2602.02229", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.02229", "abs": "https://arxiv.org/abs/2602.02229", "authors": ["Guangyi Zhang", "Yunlong Cai", "Guanding Yu", "Osvaldo Simeone"], "title": "Prediction-Powered Risk Monitoring of Deployed Models for Detecting Harmful Distribution Shifts", "comment": null, "summary": "We study the problem of monitoring model performance in dynamic environments where labeled data are limited. To this end, we propose prediction-powered risk monitoring (PPRM), a semi-supervised risk-monitoring approach based on prediction-powered inference (PPI). PPRM constructs anytime-valid lower bounds on the running risk by combining synthetic labels with a small set of true labels. Harmful shifts are detected via a threshold-based comparison with an upper bound on the nominal risk, satisfying assumption-free finite-sample guarantees in the probability of false alarm. We demonstrate the effectiveness of PPRM through extensive experiments on image classification, large language model (LLM), and telecommunications monitoring tasks.", "AI": {"tldr": "\u63d0\u51fa\u9884\u6d4b\u9a71\u52a8\u7684\u98ce\u9669\u76d1\u63a7\uff08PPRM\uff09\uff0c\u4e00\u79cd\u57fa\u4e8e\u9884\u6d4b\u9a71\u52a8\u63a8\u7406\u7684\u534a\u76d1\u7763\u98ce\u9669\u76d1\u63a7\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u52a8\u6001\u73af\u5883\u4e2d\u76d1\u6d4b\u6a21\u578b\u6027\u80fd", "motivation": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\u76d1\u63a7\u6a21\u578b\u6027\u80fd\u65f6\uff0c\u6807\u6ce8\u6570\u636e\u901a\u5e38\u6709\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u6709\u9650\u6807\u6ce8\u4e0b\u6709\u6548\u76d1\u6d4b\u98ce\u9669\u7684\u65b9\u6cd5", "method": "\u57fa\u4e8e\u9884\u6d4b\u9a71\u52a8\u63a8\u7406\uff08PPI\uff09\uff0c\u901a\u8fc7\u7ed3\u5408\u5408\u6210\u6807\u7b7e\u548c\u5c11\u91cf\u771f\u5b9e\u6807\u7b7e\uff0c\u6784\u5efa\u8fd0\u884c\u98ce\u9669\u7684\u4efb\u610f\u65f6\u95f4\u6709\u6548\u4e0b\u754c\uff0c\u5e76\u901a\u8fc7\u4e0e\u540d\u4e49\u98ce\u9669\u4e0a\u754c\u7684\u9608\u503c\u6bd4\u8f83\u6765\u68c0\u6d4b\u6709\u5bb3\u504f\u79fb", "result": "PPRM\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7535\u4fe1\u76d1\u63a7\u4efb\u52a1\u4e0a\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6709\u6548\u6027\uff0c\u5177\u6709\u65e0\u5047\u8bbe\u7684\u6709\u9650\u6837\u672c\u8bef\u62a5\u6982\u7387\u4fdd\u8bc1", "conclusion": "PPRM\u4e3a\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6a21\u578b\u6027\u80fd\u76d1\u63a7\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u534a\u76d1\u7763\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2602.02230", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02230", "abs": "https://arxiv.org/abs/2602.02230", "authors": ["Ziyu Zhou", "Yuchen Fang", "Weilin Ruan", "Shiyu Wang", "James Kwok", "Yuxuan Liang"], "title": "SEDformer: Event-Synchronous Spiking Transformers for Irregular Telemetry Time Series Forecasting", "comment": "Under review", "summary": "Telemetry streams from large-scale Internet-connected systems (e.g., IoT deployments and online platforms) naturally form an irregular multivariate time series (IMTS) whose accurate forecasting is operationally vital. A closer examination reveals a defining Sparsity-Event Duality (SED) property of IMTS, i.e., long stretches with sparse or no observations are punctuated by short, dense bursts where most semantic events (observations) occur. However, existing Graph- and Transformer-based forecasters ignore SED: pre-alignment to uniform grids with heavy padding violates sparsity by inflating sequences and forcing computation at non-informative steps, while relational recasting weakens event semantics by disrupting local temporal continuity. These limitations motivate a more faithful and natural modeling paradigm for IMTS that aligns with its SED property. We find that Spiking Neural Networks meet this requirement, as they communicate via sparse binary spikes and update in an event-driven manner, aligning naturally with the SED nature of IMTS. Therefore, we present SEDformer, an SED-enhanced Spiking Transformer for telemetry IMTS forecasting that couples: (1) a SED-based Spike Encoder converts raw observations into event synchronous spikes using an Event-Aligned LIF neuron, (2) an Event-Preserving Temporal Downsampling module compresses long gaps while retaining salient firings and (3) a stack of SED-based Spike Transformer blocks enable intra-series dependency modeling with a membrane-based linear attention driven by EA-LIF spiking features. Experiments on public telemetry IMTS datasets show that SEDformer attains state-of-the-art forecasting accuracy while reducing energy and memory usage, providing a natural and efficient path for modeling IMTS.", "AI": {"tldr": "SEDformer\uff1a\u4e00\u79cd\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684SED\u589e\u5f3a\u578b\u8109\u51b2Transformer\uff0c\u7528\u4e8e\u4e0d\u89c4\u5219\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u901a\u8fc7\u4e8b\u4ef6\u9a71\u52a8\u7684\u65b9\u5f0f\u81ea\u7136\u5339\u914dIMTS\u7684\u7a00\u758f-\u4e8b\u4ef6\u5bf9\u5076\u7279\u6027\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u5927\u89c4\u6a21\u4e92\u8054\u7f51\u7cfb\u7edf\uff08\u5982\u7269\u8054\u7f51\u548c\u5728\u7ebf\u5e73\u53f0\uff09\u7684\u9065\u6d4b\u6570\u636e\u5f62\u6210\u4e0d\u89c4\u5219\u591a\u5143\u65f6\u95f4\u5e8f\u5217\uff08IMTS\uff09\uff0c\u5176\u51c6\u786e\u9884\u6d4b\u5bf9\u8fd0\u7ef4\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u57fa\u4e8e\u56fe\u548cTransformer\u7684\u9884\u6d4b\u65b9\u6cd5\u5ffd\u7565\u4e86IMTS\u7684\u7a00\u758f-\u4e8b\u4ef6\u5bf9\u5076\uff08SED\uff09\u7279\u6027\uff1a\u7edf\u4e00\u7f51\u683c\u5bf9\u9f50\u548c\u586b\u5145\u7834\u574f\u4e86\u7a00\u758f\u6027\uff0c\u5173\u7cfb\u91cd\u6784\u524a\u5f31\u4e86\u4e8b\u4ef6\u8bed\u4e49\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5fe0\u5b9e\u4e8eIMTS SED\u7279\u6027\u7684\u5efa\u6a21\u8303\u5f0f\u3002", "method": "\u63d0\u51faSEDformer\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09SED-based Spike Encoder\uff1a\u4f7f\u7528\u4e8b\u4ef6\u5bf9\u9f50LIF\u795e\u7ecf\u5143\u5c06\u539f\u59cb\u89c2\u6d4b\u8f6c\u6362\u4e3a\u4e8b\u4ef6\u540c\u6b65\u8109\u51b2\uff1b2\uff09Event-Preserving Temporal Downsampling\uff1a\u538b\u7f29\u957f\u95f4\u9694\u540c\u65f6\u4fdd\u7559\u663e\u8457\u8109\u51b2\uff1b3\uff09SED-based Spike Transformer blocks\uff1a\u57fa\u4e8e\u819c\u7535\u4f4d\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528EA-LIF\u8109\u51b2\u7279\u5f81\u5efa\u6a21\u5e8f\u5217\u5185\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u516c\u5171\u9065\u6d4bIMTS\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSEDformer\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u548c\u5185\u5b58\u4f7f\u7528\uff0c\u4e3aIMTS\u5efa\u6a21\u63d0\u4f9b\u4e86\u81ea\u7136\u4e14\u9ad8\u6548\u7684\u8def\u5f84\u3002", "conclusion": "\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u7a00\u758f\u4e8c\u8fdb\u5236\u8109\u51b2\u548c\u4e8b\u4ef6\u9a71\u52a8\u66f4\u65b0\uff0c\u81ea\u7136\u5339\u914dIMTS\u7684SED\u7279\u6027\u3002SEDformer\u901a\u8fc7\u5c06SED\u7279\u6027\u878d\u5165\u8109\u51b2Transformer\u67b6\u6784\uff0c\u4e3a\u4e0d\u89c4\u5219\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.02238", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02238", "abs": "https://arxiv.org/abs/2602.02238", "authors": ["Laura Yao", "Gengwei Zhang", "Moajjem Chowdhury", "Yunmei Liu", "Tianlong Chen"], "title": "Geometry- and Relation-Aware Diffusion for EEG Super-Resolution", "comment": null, "summary": "Recent electroencephalography (EEG) spatial super-resolution (SR) methods, while showing improved quality by either directly predicting missing signals from visible channels or adapting latent diffusion-based generative modeling to temporal data, often lack awareness of physiological spatial structure, thereby constraining spatial generation performance. To address this issue, we introduce TopoDiff, a geometry- and relation-aware diffusion model for EEG spatial super-resolution. Inspired by how human experts interpret spatial EEG patterns, TopoDiff incorporates topology-aware image embeddings derived from EEG topographic representations to provide global geometric context for spatial generation, together with a dynamic channel-relation graph that encodes inter-electrode relationships and evolves with temporal dynamics. This design yields a spatially grounded EEG spatial super-resolution framework with consistent performance improvements. Across multiple EEG datasets spanning diverse applications, including SEED/SEED-IV for emotion recognition, PhysioNet motor imagery (MI/MM), and TUSZ for seizure detection, our method achieves substantial gains in generation fidelity and leads to notable improvements in downstream EEG task performance.", "AI": {"tldr": "TopoDiff\uff1a\u4e00\u79cd\u7528\u4e8eEEG\u7a7a\u95f4\u8d85\u5206\u8fa8\u7387\u7684\u51e0\u4f55\u548c\u5173\u7cfb\u611f\u77e5\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u56fe\u50cf\u5d4c\u5165\u548c\u52a8\u6001\u901a\u9053\u5173\u7cfb\u56fe\u63d0\u5347\u7a7a\u95f4\u751f\u6210\u6027\u80fd", "motivation": "\u73b0\u6709EEG\u7a7a\u95f4\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u751f\u7406\u7a7a\u95f4\u7ed3\u6784\u7684\u8ba4\u77e5\uff0c\u9650\u5236\u4e86\u7a7a\u95f4\u751f\u6210\u6027\u80fd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7406\u89e3EEG\u7a7a\u95f4\u62d3\u6251\u7ed3\u6784\u548c\u7535\u6781\u95f4\u5173\u7cfb\u7684\u6a21\u578b", "method": "\u63d0\u51faTopoDiff\u6a21\u578b\uff0c\u7ed3\u5408EEG\u5730\u5f62\u56fe\u8868\u793a\u7684\u62d3\u6251\u611f\u77e5\u56fe\u50cf\u5d4c\u5165\u63d0\u4f9b\u5168\u5c40\u51e0\u4f55\u4e0a\u4e0b\u6587\uff0c\u4ee5\u53ca\u7f16\u7801\u7535\u6781\u95f4\u5173\u7cfb\u5e76\u968f\u65f6\u95f4\u52a8\u6001\u6f14\u5316\u7684\u52a8\u6001\u901a\u9053\u5173\u7cfb\u56fe", "result": "\u5728\u591a\u4e2aEEG\u6570\u636e\u96c6\uff08SEED/SEED-IV\u60c5\u611f\u8bc6\u522b\u3001PhysioNet\u8fd0\u52a8\u60f3\u8c61\u3001TUSZ\u766b\u75eb\u68c0\u6d4b\uff09\u4e0a\uff0c\u65b9\u6cd5\u5728\u751f\u6210\u4fdd\u771f\u5ea6\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u5747\u53d6\u5f97\u663e\u8457\u63d0\u5347", "conclusion": "TopoDiff\u901a\u8fc7\u6574\u5408\u7a7a\u95f4\u62d3\u6251\u7ed3\u6784\u548c\u52a8\u6001\u7535\u6781\u5173\u7cfb\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7a7a\u95f4\u57fa\u7840\u624e\u5b9e\u7684EEG\u8d85\u5206\u8fa8\u7387\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u7684\u6301\u7eed\u6539\u8fdb"}}
{"id": "2602.02239", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02239", "abs": "https://arxiv.org/abs/2602.02239", "authors": ["Giovanni De Felice", "Riccardo D'Elia", "Alberto Termine", "Pietro Barbiero", "Giuseppe Marra", "Silvia Santini"], "title": "Interpretability in Deep Time Series Models Demands Semantic Alignment", "comment": null, "summary": "Deep time series models continue to improve predictive performance, yet their deployment remains limited by their black-box nature. In response, existing interpretability approaches in the field keep focusing on explaining the internal model computations, without addressing whether they align or not with how a human would reason about the studied phenomenon. Instead, we state interpretability in deep time series models should pursue semantic alignment: predictions should be expressed in terms of variables that are meaningful to the end user, mediated by spatial and temporal mechanisms that admit user-dependent constraints. In this paper, we formalize this requirement and require that, once established, semantic alignment must be preserved under temporal evolution: a constraint with no analog in static settings. Provided with this definition, we outline a blueprint for semantically aligned deep time series models, identify properties that support trust, and discuss implications for model design.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u5e94\u8ffd\u6c42\u8bed\u4e49\u5bf9\u9f50\uff0c\u5373\u9884\u6d4b\u7ed3\u679c\u9700\u4ee5\u5bf9\u7528\u6237\u6709\u610f\u4e49\u7684\u53d8\u91cf\u8868\u8fbe\uff0c\u5e76\u901a\u8fc7\u53ef\u63a5\u53d7\u7528\u6237\u7ea6\u675f\u7684\u65f6\u7a7a\u673a\u5236\u5b9e\u73b0\uff0c\u4e14\u8fd9\u79cd\u5bf9\u9f50\u5fc5\u987b\u5728\u65f6\u95f4\u6f14\u5316\u4e2d\u4fdd\u6301\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u867d\u7136\u9884\u6d4b\u6027\u80fd\u4e0d\u65ad\u63d0\u5347\uff0c\u4f46\u5176\u9ed1\u76d2\u7279\u6027\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u73b0\u6709\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u89e3\u91ca\u6a21\u578b\u5185\u90e8\u8ba1\u7b97\uff0c\u800c\u6ca1\u6709\u89e3\u51b3\u8fd9\u4e9b\u89e3\u91ca\u662f\u5426\u4e0e\u4eba\u7c7b\u5bf9\u7814\u7a76\u73b0\u8c61\u7684\u63a8\u7406\u65b9\u5f0f\u76f8\u4e00\u81f4\u7684\u95ee\u9898\u3002", "method": "\u8bba\u6587\u5f62\u5f0f\u5316\u4e86\u8bed\u4e49\u5bf9\u9f50\u7684\u8981\u6c42\uff0c\u5f3a\u8c03\u9884\u6d4b\u5e94\u901a\u8fc7\u53ef\u63a5\u53d7\u7528\u6237\u7ea6\u675f\u7684\u65f6\u7a7a\u673a\u5236\uff0c\u4ee5\u5bf9\u7528\u6237\u6709\u610f\u4e49\u7684\u53d8\u91cf\u8868\u8fbe\uff0c\u5e76\u8981\u6c42\u8fd9\u79cd\u8bed\u4e49\u5bf9\u9f50\u5fc5\u987b\u5728\u65f6\u95f4\u6f14\u5316\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u7a33\u5b9a\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86\u8bed\u4e49\u5bf9\u9f50\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7684\u84dd\u56fe\uff0c\u8bc6\u522b\u4e86\u652f\u6301\u4fe1\u4efb\u7684\u5c5e\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u6a21\u578b\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u8bed\u4e49\u5bf9\u9f50\u7684\u6b63\u5f0f\u5b9a\u4e49\uff0c\u8fd9\u662f\u9759\u6001\u73af\u5883\u4e2d\u6ca1\u6709\u7c7b\u4f3c\u8981\u6c42\u7684\u7ea6\u675f\u3002\u901a\u8fc7\u8fd9\u4e00\u6846\u67b6\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u7684\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u8bbe\u8ba1\u6307\u5bfc\u3002", "conclusion": "\u6df1\u5ea6\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u5e94\u8f6c\u5411\u8bed\u4e49\u5bf9\u9f50\uff0c\u786e\u4fdd\u6a21\u578b\u9884\u6d4b\u4ee5\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u65b9\u5f0f\u8868\u8fbe\uff0c\u5e76\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u4fdd\u6301\u4e00\u81f4\uff0c\u8fd9\u662f\u6784\u5efa\u53ef\u4fe1AI\u7cfb\u7edf\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2602.02241", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02241", "abs": "https://arxiv.org/abs/2602.02241", "authors": ["Roman Dyachenko", "Nikita Gushchin", "Kirill Sokolov", "Petr Mokrov", "Evgeny Burnaev", "Alexander Korotin"], "title": "Variational Entropic Optimal Transport", "comment": null, "summary": "Entropic optimal transport (EOT) in continuous spaces with quadratic cost is a classical tool for solving the domain translation problem. In practice, recent approaches optimize a weak dual EOT objective depending on a single potential, but doing so is computationally not efficient due to the intractable log-partition term. Existing methods typically resolve this obstacle in one of two ways: by significantly restricting the transport family to obtain closed-form normalization (via Gaussian-mixture parameterizations), or by using general neural parameterizations that require simulation-based training procedures. We propose Variational Entropic Optimal Transport (VarEOT), based on an exact variational reformulation of the log-partition $\\log \\mathbb{E}[\\exp(\\cdot)]$ as a tractable minimization over an auxiliary positive normalizer. This yields a differentiable learning objective optimized with stochastic gradients and avoids the necessity of MCMC simulations during the training. We provide theoretical guarantees, including finite-sample generalization bounds and approximation results under universal function approximation. Experiments on synthetic data and unpaired image-to-image translation demonstrate competitive or improved translation quality, while comparisons within the solvers that use the same weak dual EOT objective support the benefit of the proposed optimization principle.", "AI": {"tldr": "\u63d0\u51faVarEOT\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5206\u91cd\u6784log-partition\u9879\uff0c\u907f\u514dMCMC\u6a21\u62df\uff0c\u5b9e\u73b0\u53ef\u5fae\u5b66\u4e60\u76ee\u6807", "motivation": "\u73b0\u6709EOT\u65b9\u6cd5\u5728\u4f18\u5316\u5f31\u5bf9\u5076\u76ee\u6807\u65f6\uff0c\u7531\u4e8elog-partition\u9879\u96be\u4ee5\u5904\u7406\uff0c\u8981\u4e48\u9650\u5236\u4f20\u8f93\u65cf\uff08\u9ad8\u65af\u6df7\u5408\u53c2\u6570\u5316\uff09\uff0c\u8981\u4e48\u9700\u8981\u6a21\u62df\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e", "method": "\u63d0\u51fa\u53d8\u5206\u71b5\u6700\u4f18\u4f20\u8f93(VarEOT)\uff0c\u5c06log-partition\u9879\u91cd\u6784\u4e3a\u5728\u8f85\u52a9\u6b63\u5f52\u4e00\u5316\u5668\u4e0a\u7684\u53ef\u5904\u7406\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5f97\u5230\u53ef\u5fae\u5b66\u4e60\u76ee\u6807\uff0c\u7528\u968f\u673a\u68af\u5ea6\u4f18\u5316", "result": "\u5728\u5408\u6210\u6570\u636e\u548c\u672a\u914d\u5bf9\u56fe\u50cf\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u7ade\u4e89\u6027\u6216\u6539\u8fdb\u7684\u7ffb\u8bd1\u8d28\u91cf\uff0c\u76f8\u6bd4\u4f7f\u7528\u76f8\u540c\u5f31\u5bf9\u5076EOT\u76ee\u6807\u7684\u6c42\u89e3\u5668\u6709\u4f18\u52bf", "conclusion": "VarEOT\u901a\u8fc7\u53d8\u5206\u91cd\u6784log-partition\u9879\uff0c\u907f\u514d\u4e86MCMC\u6a21\u62df\u9700\u6c42\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u5728\u57df\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02"}}
{"id": "2602.02244", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02244", "abs": "https://arxiv.org/abs/2602.02244", "authors": ["Hao Wang", "Hao Gu", "Hongming Piao", "Kaixiong Gong", "Yuxiao Ye", "Xiangyu Yue", "Sirui Han", "Yike Guo", "Dapeng Wu"], "title": "Learning While Staying Curious: Entropy-Preserving Supervised Fine-Tuning via Adaptive Self-Distillation for Large Reasoning Models", "comment": null, "summary": "The standard post-training recipe for large reasoning models, supervised fine-tuning followed by reinforcement learning (SFT-then-RL), may limit the benefits of the RL stage: while SFT imitates expert demonstrations, it often causes overconfidence and reduces generation diversity, leaving RL with a narrowed solution space to explore. Adding entropy regularization during SFT is not a cure-all; it tends to flatten token distributions toward uniformity, increasing entropy without improving meaningful exploration capability. In this paper, we propose CurioSFT, an entropy-preserving SFT method designed to enhance exploration capabilities through intrinsic curiosity. It consists of (a) Self-Exploratory Distillation, which distills the model toward a self-generated, temperature-scaled teacher to encourage exploration within its capability; and (b) Entropy-Guided Temperature Selection, which adaptively adjusts distillation strength to mitigate knowledge forgetting by amplifying exploration at reasoning tokens while stabilizing factual tokens. Extensive experiments on mathematical reasoning tasks demonstrate that, in SFT stage, CurioSFT outperforms the vanilla SFT by 2.5 points on in-distribution tasks and 2.9 points on out-of-distribution tasks. We also verify that exploration capabilities preserved during SFT successfully translate into concrete gains in RL stage, yielding an average improvement of 5.0 points.", "AI": {"tldr": "\u63d0\u51faCurioSFT\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fdd\u6301\u71b5\u548c\u5185\u5728\u597d\u5947\u5fc3\u589e\u5f3aSFT\u9636\u6bb5\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u4e3a\u540e\u7eedRL\u9636\u6bb5\u63d0\u4f9b\u66f4\u597d\u7684\u8d77\u70b9\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfSFT-then-RL\u6d41\u7a0b\u4e2d\uff0cSFT\u9636\u6bb5\u6a21\u4eff\u4e13\u5bb6\u6f14\u793a\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u548c\u751f\u6210\u591a\u6837\u6027\u964d\u4f4e\uff0c\u9650\u5236\u4e86RL\u9636\u6bb5\u7684\u63a2\u7d22\u7a7a\u95f4\u3002\u73b0\u6709\u71b5\u6b63\u5219\u5316\u65b9\u6cd5\u4f1a\u5747\u5300\u5316token\u5206\u5e03\uff0c\u65e0\u6cd5\u771f\u6b63\u63d0\u5347\u63a2\u7d22\u80fd\u529b\u3002", "method": "\u63d0\u51faCurioSFT\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u81ea\u63a2\u7d22\u84b8\u998f\uff1a\u5c06\u6a21\u578b\u84b8\u998f\u5230\u81ea\u751f\u6210\u7684\u6e29\u5ea6\u7f29\u653e\u6559\u5e08\u6a21\u578b\uff0c\u9f13\u52b1\u5728\u80fd\u529b\u8303\u56f4\u5185\u63a2\u7d22\uff1b2\uff09\u71b5\u5f15\u5bfc\u6e29\u5ea6\u9009\u62e9\uff1a\u81ea\u9002\u5e94\u8c03\u6574\u84b8\u998f\u5f3a\u5ea6\uff0c\u5728\u63a8\u7406token\u4e0a\u589e\u5f3a\u63a2\u7d22\uff0c\u5728\u4e8b\u5b9etoken\u4e0a\u4fdd\u6301\u7a33\u5b9a\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cCurioSFT\u5728SFT\u9636\u6bb5\u6bd4\u4f20\u7edfSFT\u63d0\u53472.5\u4e2a\u70b9\uff08\u5206\u5e03\u5185\u4efb\u52a1\uff09\u548c2.9\u4e2a\u70b9\uff08\u5206\u5e03\u5916\u4efb\u52a1\uff09\u3002\u63a2\u7d22\u80fd\u529b\u7684\u4fdd\u6301\u6210\u529f\u8f6c\u5316\u4e3aRL\u9636\u6bb55.0\u4e2a\u70b9\u7684\u5e73\u5747\u63d0\u5347\u3002", "conclusion": "CurioSFT\u901a\u8fc7\u4fdd\u6301\u71b5\u548c\u589e\u5f3a\u5185\u5728\u597d\u5947\u5fc3\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfSFT\u9650\u5236RL\u63a2\u7d22\u7a7a\u95f4\u7684\u95ee\u9898\uff0c\u4e3a\u63a8\u7406\u6a21\u578b\u7684\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u597d\u7684SFT\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6700\u7ec8\u6027\u80fd\u3002"}}
{"id": "2602.02258", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02258", "abs": "https://arxiv.org/abs/2602.02258", "authors": ["Gaurav Bhatt", "Aditya Chinchure", "Jiawei Zhou", "Leonid Sigal"], "title": "Alignment-Aware Model Adaptation via Feedback-Guided Optimization", "comment": null, "summary": "Fine-tuning is the primary mechanism for adapting foundation models to downstream tasks; however, standard approaches largely optimize task objectives in isolation and do not account for secondary yet critical alignment objectives (e.g., safety and hallucination avoidance). As a result, downstream fine-tuning can degrade alignment and fail to correct pre-existing misaligned behavior. We propose an alignment-aware fine-tuning framework that integrates feedback from an external alignment signal through policy-gradient-based regularization. Our method introduces an adaptive gating mechanism that dynamically balances supervised and alignment-driven gradients on a per-sample basis, prioritizing uncertain or misaligned cases while allowing well-aligned examples to follow standard supervised updates. The framework further learns abstention behavior for fully misaligned inputs, incorporating conservative responses directly into the fine-tuned model. Experiments on general and domain-specific instruction-tuning benchmarks demonstrate consistent reductions in harmful and hallucinated outputs without sacrificing downstream task performance. Additional analyses show robustness to adversarial fine-tuning, prompt-based attacks, and unsafe initializations, establishing adaptively gated alignment optimization as an effective approach for alignment-preserving and alignment-recovering model adaptation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5bf9\u9f50\u611f\u77e5\u7684\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u6b63\u5219\u5316\u6574\u5408\u5916\u90e8\u5bf9\u9f50\u4fe1\u53f7\uff0c\u52a8\u6001\u5e73\u8861\u76d1\u7763\u548c\u5bf9\u9f50\u68af\u5ea6\uff0c\u5b66\u4e60\u5bf9\u5b8c\u5168\u672a\u5bf9\u9f50\u8f93\u5165\u7684\u5f03\u6743\u884c\u4e3a\uff0c\u5728\u4fdd\u6301\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u6709\u5bb3\u548c\u5e7b\u89c9\u8f93\u51fa\u3002", "motivation": "\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u4e3b\u8981\u4f18\u5316\u4efb\u52a1\u76ee\u6807\uff0c\u5ffd\u7565\u4e86\u5b89\u5168\u6027\u548c\u907f\u514d\u5e7b\u89c9\u7b49\u5173\u952e\u5bf9\u9f50\u76ee\u6807\uff0c\u5bfc\u81f4\u5fae\u8c03\u53ef\u80fd\u964d\u4f4e\u5bf9\u9f50\u6027\u5e76\u65e0\u6cd5\u7ea0\u6b63\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u7684\u672a\u5bf9\u9f50\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u5bf9\u9f50\u611f\u77e5\u5fae\u8c03\u6846\u67b6\uff1a1) \u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u6b63\u5219\u5316\u6574\u5408\u5916\u90e8\u5bf9\u9f50\u4fe1\u53f7\u53cd\u9988\uff1b2) \u5f15\u5165\u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\uff0c\u5728\u6837\u672c\u7ea7\u522b\u52a8\u6001\u5e73\u8861\u76d1\u7763\u548c\u5bf9\u9f50\u9a71\u52a8\u68af\u5ea6\uff1b3) \u5b66\u4e60\u5bf9\u5b8c\u5168\u672a\u5bf9\u9f50\u8f93\u5165\u7684\u5f03\u6743\u884c\u4e3a\uff0c\u5c06\u4fdd\u5b88\u54cd\u5e94\u76f4\u63a5\u6574\u5408\u5230\u5fae\u8c03\u6a21\u578b\u4e2d\u3002", "result": "\u5728\u901a\u7528\u548c\u9886\u57df\u7279\u5b9a\u6307\u4ee4\u5fae\u8c03\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6301\u7eed\u51cf\u5c11\u6709\u5bb3\u548c\u5e7b\u89c9\u8f93\u51fa\u3002\u989d\u5916\u5206\u6790\u663e\u793a\u5bf9\u5bf9\u6297\u6027\u5fae\u8c03\u3001\u63d0\u793a\u653b\u51fb\u548c\u4e0d\u5b89\u5168\u521d\u59cb\u5316\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u81ea\u9002\u5e94\u95e8\u63a7\u5bf9\u9f50\u4f18\u5316\u662f\u4e00\u79cd\u6709\u6548\u7684\u5bf9\u9f50\u4fdd\u6301\u548c\u5bf9\u9f50\u6062\u590d\u6a21\u578b\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u540c\u65f6\u4f18\u5316\u4efb\u52a1\u6027\u80fd\u548c\u5bf9\u9f50\u76ee\u6807\u3002"}}
{"id": "2602.02259", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.02259", "abs": "https://arxiv.org/abs/2602.02259", "authors": ["Hamza Adnan", "Matthew T. Jackson", "Alexey Zakharov"], "title": "Segment to Focus: Guiding Latent Action Models in the Presence of Distractors", "comment": null, "summary": "Latent Action Models (LAMs) learn to extract action-relevant representations solely from raw observations, enabling reinforcement learning from unlabelled videos and significantly scaling available training data. However, LAMs face a critical challenge in disentangling action-relevant features from action-correlated noise (e.g., background motion). Failing to filter these distractors causes LAMs to capture spurious correlations and build sub-optimal latent action spaces. In this paper, we introduce MaskLAM -- a lightweight modification to LAM training to mitigate this issue by incorporating visual agent segmentation. MaskLAM utilises segmentation masks from pretrained foundation models to weight the LAM reconstruction loss, thereby prioritising salient information over background elements while requiring no architectural modifications. We demonstrate the effectiveness of our method on continuous-control MuJoCo tasks, modified with action-correlated background noise. Our approach yields up to a 4x increase in accrued rewards compared to standard baselines and a 3x improvement in the latent action quality, as evidenced by linear probe evaluation.", "AI": {"tldr": "MaskLAM\u901a\u8fc7\u5f15\u5165\u89c6\u89c9\u667a\u80fd\u4f53\u5206\u5272\u6765\u6539\u8fdb\u6f5c\u5728\u52a8\u4f5c\u6a21\u578b\uff0c\u6709\u6548\u8fc7\u6ee4\u52a8\u4f5c\u76f8\u5173\u566a\u58f0\uff0c\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u6027\u80fd", "motivation": "\u6f5c\u5728\u52a8\u4f5c\u6a21\u578b\uff08LAMs\uff09\u80fd\u4ece\u539f\u59cb\u89c2\u5bdf\u4e2d\u63d0\u53d6\u52a8\u4f5c\u76f8\u5173\u8868\u793a\uff0c\u4f46\u9762\u4e34\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff1a\u96be\u4ee5\u533a\u5206\u52a8\u4f5c\u76f8\u5173\u7279\u5f81\u4e0e\u52a8\u4f5c\u76f8\u5173\u566a\u58f0\uff08\u5982\u80cc\u666f\u8fd0\u52a8\uff09\u3002\u672a\u80fd\u8fc7\u6ee4\u8fd9\u4e9b\u5e72\u6270\u56e0\u7d20\u4f1a\u5bfc\u81f4LAMs\u6355\u6349\u865a\u5047\u76f8\u5173\u6027\u5e76\u6784\u5efa\u6b21\u4f18\u7684\u6f5c\u5728\u52a8\u4f5c\u7a7a\u95f4\u3002", "method": "MaskLAM\u662f\u4e00\u79cd\u5bf9LAM\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u4fee\u6539\uff0c\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u667a\u80fd\u4f53\u5206\u5272\u6765\u7f13\u89e3\u6b64\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684\u5206\u5272\u63a9\u7801\u6765\u52a0\u6743LAM\u91cd\u5efa\u635f\u5931\uff0c\u4ece\u800c\u4f18\u5148\u8003\u8651\u663e\u8457\u4fe1\u606f\u800c\u975e\u80cc\u666f\u5143\u7d20\uff0c\u4e14\u65e0\u9700\u67b6\u6784\u4fee\u6539\u3002", "result": "\u5728\u6dfb\u52a0\u4e86\u52a8\u4f5c\u76f8\u5173\u80cc\u666f\u566a\u58f0\u7684\u8fde\u7eed\u63a7\u5236MuJoCo\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u6807\u51c6\u57fa\u7ebf\u5b9e\u73b0\u4e86\u9ad8\u8fbe4\u500d\u7684\u7d2f\u79ef\u5956\u52b1\u63d0\u5347\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u63a2\u9488\u8bc4\u4f30\u663e\u793a\u6f5c\u5728\u52a8\u4f5c\u8d28\u91cf\u63d0\u9ad8\u4e863\u500d\u3002", "conclusion": "MaskLAM\u901a\u8fc7\u7b80\u5355\u800c\u6709\u6548\u7684\u5206\u5272\u63a9\u7801\u52a0\u6743\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f5c\u5728\u52a8\u4f5c\u6a21\u578b\u5728\u5b58\u5728\u52a8\u4f5c\u76f8\u5173\u566a\u58f0\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u4ece\u65e0\u6807\u7b7e\u89c6\u9891\u4e2d\u5b66\u4e60\u66f4\u9c81\u68d2\u7684\u52a8\u4f5c\u8868\u793a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02260", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02260", "abs": "https://arxiv.org/abs/2602.02260", "authors": ["Zhengjia Zhuo", "Anupam Gupta", "Viswanath Nagarajan"], "title": "Learning Markov Decision Processes under Fully Bandit Feedback", "comment": null, "summary": "A standard assumption in Reinforcement Learning is that the agent observes every visited state-action pair in the associated Markov Decision Process (MDP), along with the per-step rewards. Strong theoretical results are known in this setting, achieving nearly-tight $\u0398(\\sqrt{T})$-regret bounds. However, such detailed feedback can be unrealistic, and recent research has investigated more restricted settings such as trajectory feedback, where the agent observes all the visited state-action pairs, but only a single \\emph{aggregate} reward. In this paper, we consider a far more restrictive ``fully bandit'' feedback model for episodic MDPs, where the agent does not even observe the visited state-action pairs -- it only learns the aggregate reward. We provide the first efficient bandit learning algorithm for episodic MDPs with $\\widetilde{O}(\\sqrt{T})$ regret. Our regret has an exponential dependence on the horizon length $\\H$, which we show is necessary. We also obtain improved nearly-tight regret bounds for ``ordered'' MDPs; these can be used to model classical stochastic optimization problems such as $k$-item prophet inequality and sequential posted pricing. Finally, we evaluate the empirical performance of our algorithm for the setting of $k$-item prophet inequalities; despite the highly restricted feedback, our algorithm's performance is comparable to that of a state-of-art learning algorithm (UCB-VI) with detailed state-action feedback.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u9ad8\u6548\u7684\u5168bandit\u53cd\u9988\u6a21\u578b\u4e0bepisodic MDP\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b9e\u73b0$\\widetilde{O}(\\sqrt{T})$\u9057\u61be\u754c\uff0c\u5e76\u5728k-item\u5148\u77e5\u4e0d\u7b49\u5f0f\u7b49\u7ecf\u5178\u968f\u673a\u4f18\u5316\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5047\u8bbe\u667a\u80fd\u4f53\u80fd\u89c2\u5bdf\u5230\u6bcf\u4e2a\u8bbf\u95ee\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u53ca\u5373\u65f6\u5956\u52b1\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u8fd9\u79cd\u8be6\u7ec6\u53cd\u9988\u5f80\u5f80\u4e0d\u73b0\u5b9e\u3002\u672c\u6587\u7814\u7a76\u66f4\u53d7\u9650\u7684\"\u5168bandit\"\u53cd\u9988\u6a21\u578b\uff0c\u667a\u80fd\u4f53\u4ec5\u80fd\u89c2\u5bdf\u5230\u805a\u5408\u5956\u52b1\uff0c\u65e0\u6cd5\u770b\u5230\u8bbf\u95ee\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u8fd9\u66f4\u8d34\u8fd1\u73b0\u5b9e\u5e94\u7528\u573a\u666f\u3002", "method": "\u8bbe\u8ba1\u4e86\u9996\u4e2a\u9ad8\u6548\u7684\u5168bandit\u53cd\u9988\u4e0bepisodic MDP\u5b66\u4e60\u7b97\u6cd5\u3002\u7b97\u6cd5\u5904\u7406\u667a\u80fd\u4f53\u4ec5\u80fd\u89c2\u5bdf\u805a\u5408\u5956\u52b1\u7684\u6781\u7aef\u53d7\u9650\u53cd\u9988\u60c5\u51b5\uff0c\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\u5b9e\u73b0\u5b66\u4e60\u6548\u7387\u3002\u7279\u522b\u9488\u5bf9\"\u6709\u5e8f\"MDPs\u83b7\u5f97\u6539\u8fdb\u7684\u9057\u61be\u754c\uff0c\u53ef\u5e94\u7528\u4e8ek-item\u5148\u77e5\u4e0d\u7b49\u5f0f\u548c\u987a\u5e8f\u5b9a\u4ef7\u7b49\u7ecf\u5178\u968f\u673a\u4f18\u5316\u95ee\u9898\u3002", "result": "\u7b97\u6cd5\u5b9e\u73b0\u4e86$\\widetilde{O}(\\sqrt{T})$\u7684\u9057\u61be\u754c\uff0c\u9057\u61be\u5bf9horizon\u957f\u5ea6$\\H$\u6709\u6307\u6570\u4f9d\u8d56\uff08\u8bc1\u660e\u8fd9\u662f\u5fc5\u8981\u7684\uff09\u3002\u5728\u6709\u5e8fMDPs\u4e0a\u83b7\u5f97\u4e86\u6539\u8fdb\u7684\u63a5\u8fd1\u7d27\u81f4\u7684\u9057\u61be\u754c\u3002\u5728k-item\u5148\u77e5\u4e0d\u7b49\u5f0f\u5b9e\u9a8c\u4e2d\uff0c\u5c3d\u7ba1\u53cd\u9988\u9ad8\u5ea6\u53d7\u9650\uff0c\u7b97\u6cd5\u6027\u80fd\u4e0e\u5177\u6709\u8be6\u7ec6\u72b6\u6001-\u52a8\u4f5c\u53cd\u9988\u7684\u6700\u5148\u8fdb\u5b66\u4e60\u7b97\u6cd5\uff08UCB-VI\uff09\u76f8\u5f53\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5728\u5168bandit\u53cd\u9988\u6a21\u578b\u4e0b\u4e3aepisodic MDPs\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b66\u4e60\u7b97\u6cd5\uff0c\u586b\u8865\u4e86\u6781\u7aef\u53d7\u9650\u53cd\u9988\u73af\u5883\u4e0b\u5f3a\u5316\u5b66\u4e60\u7684\u7406\u8bba\u7a7a\u767d\u3002\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5efa\u6a21\u7ecf\u5178\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.02261", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02261", "abs": "https://arxiv.org/abs/2602.02261", "authors": ["Daniil Shlenskii", "Alexander Varlamov", "Nazar Buzun", "Alexander Korotin"], "title": "Unlocking the Duality between Flow and Field Matching", "comment": null, "summary": "Conditional Flow Matching (CFM) unifies conventional generative paradigms such as diffusion models and flow matching. Interaction Field Matching (IFM) is a newer framework that generalizes Electrostatic Field Matching (EFM) rooted in Poisson Flow Generative Models (PFGM). While both frameworks define generative dynamics, they start from different objects: CFM specifies a conditional probability path in data space, whereas IFM specifies a physics-inspired interaction field in an augmented data space. This raises a basic question: are CFM and IFM genuinely different, or are they two descriptions of the same underlying dynamics? We show that they coincide for a natural subclass of IFM that we call forward-only IFM. Specifically, we construct a bijection between CFM and forward-only IFM. We further show that general IFM is strictly more expressive: it includes EFM and other interaction fields that cannot be realized within the standard CFM formulation. Finally, we highlight how this duality can benefit both frameworks: it provides a probabilistic interpretation of forward-only IFM and yields novel, IFM-driven techniques for CFM.", "AI": {"tldr": "CFM\u548cIFM\u662f\u4e24\u79cd\u751f\u6210\u6a21\u578b\u6846\u67b6\uff0c\u672c\u6587\u8bc1\u660e\u5b83\u4eec\u5728\u524d\u5411IFM\u5b50\u7c7b\u4e2d\u5b8c\u5168\u7b49\u4ef7\uff0c\u4f46\u4e00\u822cIFM\u66f4\u5177\u8868\u8fbe\u529b\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u79cd\u5bf9\u5076\u6027\u5982\u4f55\u4e92\u60e0\u4e24\u79cd\u6846\u67b6\u3002", "motivation": "\u7814\u7a76CFM\u548cIFM\u8fd9\u4e24\u79cd\u751f\u6210\u6a21\u578b\u6846\u67b6\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a2\u8ba8\u5b83\u4eec\u662f\u672c\u8d28\u4e0d\u540c\u8fd8\u662f\u540c\u4e00\u52a8\u6001\u7684\u4e24\u79cd\u63cf\u8ff0\uff0c\u7406\u89e3\u5b83\u4eec\u7684\u5bf9\u5076\u6027\u5982\u4f55\u76f8\u4e92\u53d7\u76ca\u3002", "method": "1. \u8bc1\u660eCFM\u548c\u524d\u5411IFM\u4e4b\u95f4\u5b58\u5728\u53cc\u5c04\u5173\u7cfb\uff1b2. \u5c55\u793a\u4e00\u822cIFM\u6bd4\u6807\u51c6CFM\u66f4\u5177\u8868\u8fbe\u529b\uff1b3. \u5229\u7528\u5bf9\u5076\u6027\u4e3a\u4e24\u79cd\u6846\u67b6\u63d0\u4f9b\u65b0\u89c6\u89d2\u548c\u6280\u672f\u3002", "result": "1. \u5efa\u7acb\u4e86CFM\u548c\u524d\u5411IFM\u4e4b\u95f4\u7684\u7b49\u4ef7\u6027\uff1b2. \u8bc1\u660e\u4e00\u822cIFM\u5305\u542bEFM\u7b49\u65e0\u6cd5\u7528\u6807\u51c6CFM\u5b9e\u73b0\u7684\u4ea4\u4e92\u573a\uff1b3. \u4e3a\u524d\u5411IFM\u63d0\u4f9b\u4e86\u6982\u7387\u89e3\u91ca\uff0c\u5e76\u4e3aCFM\u5f00\u53d1\u4e86\u65b0\u7684IFM\u9a71\u52a8\u6280\u672f\u3002", "conclusion": "CFM\u548c\u524d\u5411IFM\u672c\u8d28\u4e0a\u662f\u540c\u4e00\u52a8\u6001\u7684\u4e24\u79cd\u63cf\u8ff0\uff0c\u800c\u4e00\u822cIFM\u66f4\u5177\u8868\u8fbe\u529b\u3002\u8fd9\u79cd\u5bf9\u5076\u6027\u4e3a\u4e24\u79cd\u6846\u67b6\u63d0\u4f9b\u4e86\u76f8\u4e92\u53d7\u76ca\u7684\u65b0\u89c6\u89d2\u548c\u6280\u672f\u521b\u65b0\u673a\u4f1a\u3002"}}
{"id": "2602.02264", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02264", "abs": "https://arxiv.org/abs/2602.02264", "authors": ["Paolo Marcandelli", "Natansh Mathur", "Stefano Markidis", "Martina Siena", "Stefano Mariani"], "title": "Unsupervised Physics-Informed Operator Learning through Multi-Stage Curriculum Training", "comment": "51 pages, 15 figures, 6 tables", "summary": "Solving partial differential equations remains a central challenge in scientific machine learning. Neural operators offer a promising route by learning mappings between function spaces and enabling resolution-independent inference, yet they typically require supervised data. Physics-informed neural networks address this limitation through unsupervised training with physical constraints but often suffer from unstable convergence and limited generalization capability. To overcome these issues, we introduce a multi-stage physics-informed training strategy that achieves convergence by progressively enforcing boundary conditions in the loss landscape and subsequently incorporating interior residuals. At each stage the optimizer is re-initialized, acting as a continuation mechanism that restores stability and prevents gradient stagnation. We further propose the Physics-Informed Spline Fourier Neural Operator (PhIS-FNO), combining Fourier layers with Hermite spline kernels for smooth residual evaluation. Across canonical benchmarks, PhIS-FNO attains a level of accuracy comparable to that of supervised learning, using labeled information only along a narrow boundary region, establishing staged, spline-based optimization as a robust paradigm for physics-informed operator learning.", "AI": {"tldr": "\u63d0\u51fa\u591a\u9636\u6bb5\u7269\u7406\u4fe1\u606f\u8bad\u7ec3\u7b56\u7565\u548cPhIS-FNO\u6a21\u578b\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8fb9\u754c\u6761\u4ef6\u7ea6\u675f\u548c\u6837\u6761\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff0c\u5b9e\u73b0\u65e0\u76d1\u7763\u7269\u7406\u7ea6\u675f\u5b66\u4e60\uff0c\u8fbe\u5230\u63a5\u8fd1\u76d1\u7763\u5b66\u4e60\u7684\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7b97\u5b50\u9700\u8981\u76d1\u7763\u6570\u636e\uff0c\u800c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u5b58\u5728\u6536\u655b\u4e0d\u7a33\u5b9a\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e2\u80fd\u5229\u7528\u7269\u7406\u7ea6\u675f\u8fdb\u884c\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u53c8\u80fd\u4fdd\u6301\u7a33\u5b9a\u6536\u655b\u548c\u826f\u597d\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u591a\u9636\u6bb5\u7269\u7406\u4fe1\u606f\u8bad\u7ec3\u7b56\u7565\uff1a1) \u6e10\u8fdb\u5f0f\u5728\u635f\u5931\u51fd\u6570\u4e2d\u5f3a\u5236\u8fb9\u754c\u6761\u4ef6\uff1b2) \u968f\u540e\u52a0\u5165\u5185\u90e8\u6b8b\u5dee\uff1b3) \u6bcf\u9636\u6bb5\u91cd\u65b0\u521d\u59cb\u5316\u4f18\u5316\u5668\u4f5c\u4e3a\u5ef6\u7eed\u673a\u5236\u3002\u540c\u65f6\u63d0\u51faPhIS-FNO\u6a21\u578b\uff0c\u7ed3\u5408\u5085\u91cc\u53f6\u5c42\u548cHermite\u6837\u6761\u6838\u8fdb\u884c\u5e73\u6ed1\u6b8b\u5dee\u8bc4\u4f30\u3002", "result": "\u5728\u7ecf\u5178\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPhIS-FNO\u4ec5\u4f7f\u7528\u8fb9\u754c\u533a\u57df\u7684\u6807\u7b7e\u4fe1\u606f\uff0c\u8fbe\u5230\u4e86\u4e0e\u76d1\u7763\u5b66\u4e60\u76f8\u5f53\u7684\u7cbe\u5ea6\u6c34\u5e73\uff0c\u8bc1\u660e\u4e86\u5206\u9636\u6bb5\u3001\u57fa\u4e8e\u6837\u6761\u7684\u4f18\u5316\u5728\u7269\u7406\u4fe1\u606f\u7b97\u5b50\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u591a\u9636\u6bb5\u7269\u7406\u4fe1\u606f\u8bad\u7ec3\u7b56\u7565\u548cPhIS-FNO\u6a21\u578b\u4e3a\u7269\u7406\u4fe1\u606f\u7b97\u5b50\u5b66\u4e60\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u8303\u5f0f\uff0c\u80fd\u591f\u5728\u65e0\u76d1\u7763\u6761\u4ef6\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u76d1\u7763\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6536\u655b\u4e0d\u7a33\u5b9a\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002"}}
{"id": "2602.02268", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02268", "abs": "https://arxiv.org/abs/2602.02268", "authors": ["Sanggeon Yun", "Raheeb Hassan", "Ryozo Masukawa", "Sungheon Jeong", "Mohsen Imani"], "title": "HopFormer: Sparse Graph Transformers with Explicit Receptive Field Control", "comment": null, "summary": "Graph Transformers typically rely on explicit positional or structural encodings and dense global attention to incorporate graph topology. In this work, we show that neither is essential. We introduce HopFormer, a graph Transformer that injects structure exclusively through head-specific n-hop masked sparse attention, without the use of positional encodings or architectural modifications. This design provides explicit and interpretable control over receptive fields while enabling genuinely sparse attention whose computational cost scales linearly with mask sparsity. Through extensive experiments on both node-level and graph-level benchmarks, we demonstrate that our approach achieves competitive or superior performance across diverse graph structures. Our results further reveal that dense global attention is often unnecessary: on graphs with strong small-world properties, localized attention yields more stable and consistently high performance, while on graphs with weaker small-world effects, global attention offers diminishing returns. Together, these findings challenge prevailing assumptions in graph Transformer design and highlight sparsity-controlled attention as a principled and efficient alternative.", "AI": {"tldr": "HopFormer\uff1a\u4e00\u79cd\u4ec5\u901a\u8fc7\u5934\u7279\u5b9a\u7684n\u8df3\u63a9\u7801\u7a00\u758f\u6ce8\u610f\u529b\u6ce8\u5165\u56fe\u7ed3\u6784\uff0c\u65e0\u9700\u4f4d\u7f6e\u7f16\u7801\u6216\u67b6\u6784\u4fee\u6539\u7684\u56feTransformer\uff0c\u5728\u8ba1\u7b97\u6210\u672c\u968f\u63a9\u7801\u7a00\u758f\u6027\u7ebf\u6027\u6269\u5c55\u7684\u540c\u65f6\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u56feTransformer\u4f9d\u8d56\u663e\u5f0f\u4f4d\u7f6e/\u7ed3\u6784\u7f16\u7801\u548c\u5bc6\u96c6\u5168\u5c40\u6ce8\u610f\u529b\u7684\u4e3b\u6d41\u5047\u8bbe\uff0c\u63a2\u7d22\u66f4\u7b80\u6d01\u9ad8\u6548\u7684\u7ed3\u6784\u6ce8\u5165\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u5934\u7279\u5b9a\u7684n\u8df3\u63a9\u7801\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u6ce8\u5165\u56fe\u62d3\u6251\u7ed3\u6784\uff0c\u4e0d\u4f7f\u7528\u4f4d\u7f6e\u7f16\u7801\u6216\u7279\u6b8a\u67b6\u6784\u4fee\u6539\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u63a5\u6536\u573a\u63a7\u5236\u548c\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u8282\u70b9\u7ea7\u548c\u56fe\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u7ade\u4e89\u6027\u6216\u66f4\u4f18\u6027\u80fd\uff0c\u53d1\u73b0\u5bc6\u96c6\u5168\u5c40\u6ce8\u610f\u529b\u5728\u5c0f\u4e16\u754c\u5c5e\u6027\u5f3a\u7684\u56fe\u4e2d\u4e0d\u5fc5\u8981\uff0c\u5c40\u90e8\u6ce8\u610f\u529b\u8868\u73b0\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u6311\u6218\u4e86\u56feTransformer\u8bbe\u8ba1\u7684\u73b0\u6709\u5047\u8bbe\uff0c\u8bc1\u660e\u7a00\u758f\u63a7\u5236\u6ce8\u610f\u529b\u662f\u539f\u5219\u6027\u4e14\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u56feTransformer\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.02281", "categories": ["cs.LG", "cs.AI", "cs.NE", "physics.class-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.02281", "abs": "https://arxiv.org/abs/2602.02281", "authors": ["Antonino Emanuele Scurria"], "title": "Backpropagation as Physical Relaxation: Exact Gradients in Finite Time", "comment": "15 pages, 8 figures", "summary": "Backpropagation, the foundational algorithm for training neural networks, is typically understood as a symbolic computation that recursively applies the chain rule. We show it emerges exactly as the finite-time relaxation of a physical dynamical system. By formulating feedforward inference as a continuous-time process and applying Lagrangian theory of non-conservative systems to handle asymmetric interactions, we derive a global energy functional on a doubled state space encoding both activations and sensitivities. The saddle-point dynamics of this energy perform inference and credit assignment simultaneously through local interactions. We term this framework ''Dyadic Backpropagation''. Crucially, we prove that unit-step Euler discretization, the natural timescale of layer transitions, recovers standard backpropagation exactly in precisely 2L steps for an L-layer network, with no approximations. Unlike prior energy-based methods requiring symmetric weights, asymptotic convergence, or vanishing perturbations, our framework guarantees exact gradients in finite time. This establishes backpropagation as the digitally optimized shadow of a continuous physical relaxation, providing a rigorous foundation for exact gradient computation in analog and neuromorphic substrates where continuous dynamics are native.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"Dyadic Backpropagation\"\u6846\u67b6\uff0c\u5c06\u53cd\u5411\u4f20\u64ad\u91cd\u65b0\u89e3\u91ca\u4e3a\u7269\u7406\u52a8\u529b\u7cfb\u7edf\u7684\u6709\u9650\u65f6\u95f4\u677e\u5f1b\u8fc7\u7a0b\uff0c\u8bc1\u660e\u901a\u8fc7\u6b27\u62c9\u79bb\u6563\u5316\u53ef\u57282L\u6b65\u5185\u7cbe\u786e\u6062\u590d\u6807\u51c6\u53cd\u5411\u4f20\u64ad\u3002", "motivation": "\u4f20\u7edf\u4e0a\u53cd\u5411\u4f20\u64ad\u88ab\u89c6\u4e3a\u7b26\u53f7\u8ba1\u7b97\uff0c\u4f46\u4f5c\u8005\u5e0c\u671b\u5c06\u5176\u7406\u89e3\u4e3a\u7269\u7406\u7cfb\u7edf\u7684\u81ea\u7136\u6d8c\u73b0\u8fc7\u7a0b\uff0c\u4e3a\u6a21\u62df\u548c\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5c06\u524d\u5411\u63a8\u7406\u5efa\u6a21\u4e3a\u8fde\u7eed\u65f6\u95f4\u8fc7\u7a0b\uff0c\u5e94\u7528\u975e\u4fdd\u5b88\u7cfb\u7edf\u7684\u62c9\u683c\u6717\u65e5\u7406\u8bba\u5904\u7406\u975e\u5bf9\u79f0\u4ea4\u4e92\uff0c\u5728\u5305\u542b\u6fc0\u6d3b\u503c\u548c\u654f\u611f\u5ea6\u7684\u53cc\u91cd\u72b6\u6001\u7a7a\u95f4\u4e0a\u6784\u5efa\u5168\u5c40\u80fd\u91cf\u51fd\u6570\uff0c\u901a\u8fc7\u8be5\u80fd\u91cf\u7684\u978d\u70b9\u52a8\u529b\u5b66\u5b9e\u73b0\u63a8\u7406\u548c\u4fe1\u7528\u5206\u914d\u3002", "result": "\u8bc1\u660e\u5355\u4f4d\u6b65\u957f\u6b27\u62c9\u79bb\u6563\u5316\u53ef\u57282L\u6b65\u5185\u7cbe\u786e\u6062\u590d\u6807\u51c6\u53cd\u5411\u4f20\u64ad\uff0c\u65e0\u9700\u8fd1\u4f3c\u3002\u4e0e\u9700\u8981\u5bf9\u79f0\u6743\u91cd\u3001\u6e10\u8fd1\u6536\u655b\u6216\u5fae\u5c0f\u6270\u52a8\u7684\u73b0\u6709\u65b9\u6cd5\u4e0d\u540c\uff0c\u8be5\u6846\u67b6\u4fdd\u8bc1\u6709\u9650\u65f6\u95f4\u5185\u83b7\u5f97\u7cbe\u786e\u68af\u5ea6\u3002", "conclusion": "\u53cd\u5411\u4f20\u64ad\u662f\u8fde\u7eed\u7269\u7406\u677e\u5f1b\u8fc7\u7a0b\u7684\u6570\u5b57\u4f18\u5316\u5f71\u5b50\uff0c\u4e3a\u6a21\u62df\u548c\u795e\u7ecf\u5f62\u6001\u57fa\u677f\u4e2d\u7684\u7cbe\u786e\u68af\u5ea6\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e25\u683c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.02282", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02282", "abs": "https://arxiv.org/abs/2602.02282", "authors": ["Susu Hu", "Stefanie Speidel"], "title": "MoLF: Mixture-of-Latent-Flow for Pan-Cancer Spatial Gene Expression Prediction from Histology", "comment": null, "summary": "Inferring spatial transcriptomics (ST) from histology enables scalable histogenomic profiling, yet current methods are largely restricted to single-tissue models. This fragmentation fails to leverage biological principles shared across cancer types and hinders application to data-scarce scenarios. While pan-cancer training offers a solution, the resulting heterogeneity challenges monolithic architectures. To bridge this gap, we introduce MoLF (Mixture-of-Latent-Flow), a generative model for pan-cancer histogenomic prediction. MoLF leverages a conditional Flow Matching objective to map noise to the gene latent manifold, parameterized by a Mixture-of-Experts (MoE) velocity field. By dynamically routing inputs to specialized sub-networks, this architecture effectively decouples the optimization of diverse tissue patterns. Our experiments demonstrate that MoLF establishes a new state-of-the-art, consistently outperforming both specialized and foundation model baselines on pan-cancer benchmarks. Furthermore, MoLF exhibits zero-shot generalization to cross-species data, suggesting it captures fundamental, conserved histo-molecular mechanisms.", "AI": {"tldr": "MoLF\u662f\u4e00\u79cd\u7528\u4e8e\u6cdb\u764c\u7ec4\u7ec7\u57fa\u56e0\u7ec4\u9884\u6d4b\u7684\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u6761\u4ef6\u6d41\u5339\u914d\u548c\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\uff0c\u5728\u6cdb\u764c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u80fd\u96f6\u6837\u672c\u6cdb\u5316\u5230\u8de8\u7269\u79cd\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u7684\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u63a8\u65ad\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u4e00\u7ec4\u7ec7\u6a21\u578b\uff0c\u8fd9\u79cd\u788e\u7247\u5316\u65e0\u6cd5\u5229\u7528\u8de8\u764c\u75c7\u7c7b\u578b\u7684\u5171\u4eab\u751f\u7269\u5b66\u539f\u7406\uff0c\u4e5f\u963b\u788d\u4e86\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684\u5e94\u7528\u3002\u867d\u7136\u6cdb\u764c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7531\u6b64\u4ea7\u751f\u7684\u5f02\u8d28\u6027\u5bf9\u5355\u4e00\u67b6\u6784\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "MoLF\uff08Mixture-of-Latent-Flow\uff09\u662f\u4e00\u79cd\u7528\u4e8e\u6cdb\u764c\u7ec4\u7ec7\u57fa\u56e0\u7ec4\u9884\u6d4b\u7684\u751f\u6210\u6a21\u578b\u3002\u5b83\u5229\u7528\u6761\u4ef6\u6d41\u5339\u914d\u76ee\u6807\u5c06\u566a\u58f0\u6620\u5c04\u5230\u57fa\u56e0\u6f5c\u5728\u6d41\u5f62\uff0c\u901a\u8fc7\u4e13\u5bb6\u6df7\u5408\u901f\u5ea6\u573a\u8fdb\u884c\u53c2\u6570\u5316\u3002\u8be5\u67b6\u6784\u901a\u8fc7\u52a8\u6001\u8def\u7531\u8f93\u5165\u5230\u4e13\u95e8\u7684\u5b50\u7f51\u7edc\uff0c\u6709\u6548\u89e3\u8026\u4e86\u4e0d\u540c\u7ec4\u7ec7\u6a21\u5f0f\u7684\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMoLF\u5728\u6cdb\u764c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u59cb\u7ec8\u4f18\u4e8e\u4e13\u4e1a\u6a21\u578b\u548c\u57fa\u7840\u6a21\u578b\u57fa\u7ebf\u3002\u6b64\u5916\uff0cMoLF\u8868\u73b0\u51fa\u5bf9\u8de8\u7269\u79cd\u6570\u636e\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u8868\u660e\u5b83\u6355\u6349\u5230\u4e86\u57fa\u672c\u4e14\u4fdd\u5b88\u7684\u7ec4\u7ec7\u5206\u5b50\u673a\u5236\u3002", "conclusion": "MoLF\u901a\u8fc7\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u6cdb\u764c\u7ec4\u7ec7\u57fa\u56e0\u7ec4\u9884\u6d4b\u4e2d\u7684\u5f02\u8d28\u6027\u6311\u6218\uff0c\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8fd8\u5c55\u793a\u4e86\u6355\u6349\u8de8\u7269\u79cd\u4fdd\u5b88\u751f\u7269\u5b66\u673a\u5236\u7684\u80fd\u529b\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u7ec4\u7ec7\u57fa\u56e0\u7ec4\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2602.02283", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02283", "abs": "https://arxiv.org/abs/2602.02283", "authors": ["Owen Shen", "Patrick Jaillet"], "title": "Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management", "comment": null, "summary": "We study reinforcement learning for revenue management with delayed feedback, where a substantial fraction of value is determined by customer cancellations and modifications observed days after booking. We propose \\emph{choice-model-assisted RL}: a calibrated discrete choice model is used as a fixed partial world model to impute the delayed component of the learning target at decision time. In the fixed-model deployment regime, we prove that tabular Q-learning with model-imputed targets converges to an $O(\\varepsilon/(1-\u03b3))$ neighborhood of the optimal Q-function, where $\\varepsilon$ summarizes partial-model error, with an additional $O(t^{-1/2})$ sampling term. Experiments in a simulator calibrated from 61{,}619 hotel bookings (1{,}088 independent runs) show: (i) no statistically detectable difference from a maturity-buffer DQN baseline in stationary settings; (ii) positive effects under in-family parameter shifts, with significant gains in 5 of 10 shift scenarios after Holm--Bonferroni correction (up to 12.4\\%); and (iii) consistent degradation under structural misspecification, where the choice model assumptions are violated (1.4--2.6\\% lower revenue). These results characterize when partial behavioral models improve robustness under shift and when they introduce harmful bias.", "AI": {"tldr": "\u63d0\u51fa\"\u9009\u62e9\u6a21\u578b\u8f85\u52a9\u5f3a\u5316\u5b66\u4e60\"\uff0c\u4f7f\u7528\u6821\u51c6\u7684\u79bb\u6563\u9009\u62e9\u6a21\u578b\u4f5c\u4e3a\u90e8\u5206\u4e16\u754c\u6a21\u578b\u6765\u4f30\u7b97\u5ef6\u8fdf\u53cd\u9988\uff0c\u5728\u6536\u5165\u7ba1\u7406\u4e2d\u5904\u7406\u5ba2\u6237\u53d6\u6d88\u548c\u4fee\u6539\u7684\u5ef6\u8fdf\u53cd\u9988\u95ee\u9898\u3002", "motivation": "\u6536\u5165\u7ba1\u7406\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u5ef6\u8fdf\u53cd\u9988\u6311\u6218\uff0c\u5927\u91cf\u4ef7\u503c\u7531\u5ba2\u6237\u53d6\u6d88\u548c\u4fee\u6539\u51b3\u5b9a\uff0c\u8fd9\u4e9b\u53cd\u9988\u5728\u9884\u8ba2\u540e\u6570\u5929\u624d\u89c2\u5bdf\u5230\uff0c\u9700\u8981\u6709\u6548\u5904\u7406\u5ef6\u8fdf\u53cd\u9988\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6821\u51c6\u7684\u79bb\u6563\u9009\u62e9\u6a21\u578b\u4f5c\u4e3a\u56fa\u5b9a\u7684\u90e8\u5206\u4e16\u754c\u6a21\u578b\uff0c\u5728\u51b3\u7b56\u65f6\u4f30\u7b97\u5b66\u4e60\u76ee\u6807\u7684\u5ef6\u8fdf\u90e8\u5206\uff0c\u7ed3\u5408\u8868\u683cQ\u5b66\u4e60\uff0c\u63d0\u51fa\u9009\u62e9\u6a21\u578b\u8f85\u52a9\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u6536\u655b\u5230\u6700\u4f18Q\u51fd\u6570\u7684\u90bb\u57df\uff0c\u5b9e\u9a8c\u663e\u793a\uff1a\u5728\u5e73\u7a33\u73af\u5883\u4e0b\u4e0e\u57fa\u7ebf\u65e0\u7edf\u8ba1\u5dee\u5f02\uff1b\u5728\u53c2\u6570\u504f\u79fb\u4e0b\u6709\u6b63\u5411\u6548\u679c\uff085/10\u573a\u666f\u663e\u8457\u63d0\u5347\u8fbe12.4%\uff09\uff1b\u5728\u7ed3\u6784\u8bef\u8bbe\u4e0b\u6709\u6027\u80fd\u4e0b\u964d\uff081.4-2.6%\u6536\u5165\u964d\u4f4e\uff09\u3002", "conclusion": "\u90e8\u5206\u884c\u4e3a\u6a21\u578b\u5728\u53c2\u6570\u504f\u79fb\u4e0b\u80fd\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u7ed3\u6784\u8bef\u8bbe\u65f6\u4f1a\u5f15\u5165\u6709\u5bb3\u504f\u5dee\uff0c\u660e\u786e\u4e86\u8be5\u65b9\u6cd5\u9002\u7528\u6761\u4ef6\u3002"}}
{"id": "2602.02285", "categories": ["cs.LG", "cs.CL", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.02285", "abs": "https://arxiv.org/abs/2602.02285", "authors": ["Yuanhe Zhang", "Jason D. Lee", "Fanghui Liu"], "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch", "comment": "19 pages, 2 figures. Comments are welcome", "summary": "We present the first comprehensive Lean 4 formalization of statistical learning theory (SLT) grounded in empirical process theory. Our end-to-end formal infrastructure implement the missing contents in latest Lean 4 Mathlib library, including a complete development of Gaussian Lipschitz concentration, the first formalization of Dudley's entropy integral theorem for sub-Gaussian processes, and an application to least-squares (sparse) regression with a sharp rate. The project was carried out using a human-AI collaborative workflow, in which humans design proof strategies and AI agents execute tactical proof construction, leading to the human-verified Lean 4 toolbox for SLT. Beyond implementation, the formalization process exposes and resolves implicit assumptions and missing details in standard SLT textbooks, enforcing a granular, line-by-line understanding of the theory. This work establishes a reusable formal foundation and opens the door for future developments in machine learning theory. The code is available at https://github.com/YuanheZ/lean-stat-learning-theory", "AI": {"tldr": "\u9996\u4e2a\u57fa\u4e8e\u7ecf\u9a8c\u8fc7\u7a0b\u7406\u8bba\u7684\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u5b8c\u6574Lean 4\u5f62\u5f0f\u5316\uff0c\u586b\u8865\u4e86Lean 4 Mathlib\u5e93\u7684\u7a7a\u767d\uff0c\u5305\u542b\u9ad8\u65afLipschitz\u96c6\u4e2d\u6027\u3001Dudley\u71b5\u79ef\u5206\u5b9a\u7406\u7b49\u5f62\u5f0f\u5316\uff0c\u5e94\u7528\u4e8e\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u5e76\u83b7\u5f97\u5c16\u9510\u901f\u7387\u3002", "motivation": "\u5efa\u7acb\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u7684\u4e25\u683c\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u586b\u8865Lean 4 Mathlib\u5e93\u5728\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u8fc7\u7a0b\u63ed\u793a\u548c\u89e3\u51b3\u6807\u51c6\u6559\u79d1\u4e66\u4e2d\u7684\u9690\u542b\u5047\u8bbe\u548c\u7f3a\u5931\u7ec6\u8282\u3002", "method": "\u91c7\u7528\u4eba\u673a\u534f\u4f5c\u5de5\u4f5c\u6d41\uff1a\u4eba\u7c7b\u8bbe\u8ba1\u8bc1\u660e\u7b56\u7565\uff0cAI\u4ee3\u7406\u6267\u884c\u6218\u672f\u8bc1\u660e\u6784\u9020\uff0c\u6700\u7ec8\u5f62\u6210\u4eba\u7c7b\u9a8c\u8bc1\u7684Lean 4\u5de5\u5177\u7bb1\u3002\u5b9e\u73b0\u4e86\u9ad8\u65afLipschitz\u96c6\u4e2d\u6027\u3001Dudley\u71b5\u79ef\u5206\u5b9a\u7406\u7b49\u5f62\u5f0f\u5316\uff0c\u5e76\u5e94\u7528\u4e8e\u6700\u5c0f\u4e8c\u4e58\uff08\u7a00\u758f\uff09\u56de\u5f52\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u9996\u4e2a\u57fa\u4e8e\u7ecf\u9a8c\u8fc7\u7a0b\u7406\u8bba\u7684\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u5b8c\u6574Lean 4\u5f62\u5f0f\u5316\u57fa\u7840\u8bbe\u65bd\uff0c\u586b\u8865\u4e86Lean 4 Mathlib\u5e93\u7684\u5173\u952e\u7a7a\u767d\uff0c\u83b7\u5f97\u4e86\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u7684\u5c16\u9510\u901f\u7387\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5efa\u7acb\u4e86\u53ef\u91cd\u7528\u7684\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u7406\u8bba\u7684\u672a\u6765\u53d1\u5c55\u6253\u5f00\u4e86\u5927\u95e8\uff0c\u540c\u65f6\u901a\u8fc7\u5f62\u5f0f\u5316\u8fc7\u7a0b\u52a0\u5f3a\u4e86\u5bf9\u7406\u8bba\u7684\u9010\u884c\u7c92\u5ea6\u7406\u89e3\u3002"}}
{"id": "2602.02288", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02288", "abs": "https://arxiv.org/abs/2602.02288", "authors": ["Zheng Li", "Jerry Cheng", "Huanying Gu"], "title": "An Optimization Method for Autoregressive Time Series Forecasting", "comment": "10 pages, 2 figures, 2 tables", "summary": "Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at https://github.com/LizhengMathAi/AROpt", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5236\u81ea\u56de\u5f52\u9884\u6d4b\u8bef\u5dee\u968f\u9884\u6d4b\u8303\u56f4\u589e\u52a0\u800c\u589e\u52a0\uff0c\u5e76\u5141\u8bb8\u6a21\u578b\u8fde\u63a5\u77ed\u671f\u9884\u6d4b\u5f62\u6210\u7075\u6d3b\u957f\u671f\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u4e3b\u8981\u901a\u8fc7\u6269\u5927\u6a21\u578b\u89c4\u6a21\u800c\u975e\u771f\u6b63\u7684\u81ea\u56de\u5f52\u6eda\u52a8\u6765\u5b9e\u73b0\u957f\u671f\u9884\u6d4b\uff0c\u4e14\u4f20\u7edf\u8bad\u7ec3\u8fc7\u7a0b\u5ffd\u7565\u4e86\u65f6\u95f4\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5f3a\u5236\u4e24\u4e2a\u5173\u952e\u5c5e\u6027\uff1a1\uff09\u81ea\u56de\u5f52\u9884\u6d4b\u8bef\u5dee\u5e94\u968f\u9884\u6d4b\u8303\u56f4\u589e\u52a0\u800c\u589e\u52a0\uff0c\u8fdd\u53cd\u6b64\u539f\u5219\u88ab\u89c6\u4e3a\u968f\u673a\u731c\u6d4b\u5e76\u5728\u635f\u5931\u51fd\u6570\u4e2d\u660e\u786e\u60e9\u7f5a\uff1b2\uff09\u4f7f\u6a21\u578b\u80fd\u591f\u8fde\u63a5\u77ed\u671f\u81ea\u56de\u5f52\u9884\u6d4b\u4ee5\u5f62\u6210\u7075\u6d3b\u7684\u957f\u671f\u9884\u6d4b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5efa\u7acb\u4e86\u65b0\u7684SOTA\uff0c\u76f8\u6bd4iTransformer\u7b49\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e86\u8d85\u8fc710%\u7684MSE\u964d\u4f4e\uff0c\u5e76\u4f7f\u77ed\u671f\u9884\u6d4b\u6a21\u578b\u80fd\u591f\u5728\u8d85\u8fc77.5\u500d\u957f\u7684\u8303\u56f4\u5185\u8fdb\u884c\u53ef\u9760\u7684\u957f\u671f\u9884\u6d4b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f3a\u5236\u65f6\u95f4\u56e0\u679c\u5173\u7cfb\u548c\u81ea\u56de\u5f52\u7279\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u4f7f\u77ed\u671f\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u53ef\u9760\u7684\u957f\u671f\u9884\u6d4b\u3002"}}
{"id": "2602.02295", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02295", "abs": "https://arxiv.org/abs/2602.02295", "authors": ["Shaima Ahmad Freja", "Ferhat Ozgur Catak", "Betul Yurdem", "Chunming Rong"], "title": "EvalQReason: A Framework for Step-Level Reasoning Evaluation in Large Language Models", "comment": "15 pages (including appendix), 11 figures", "summary": "Large Language Models (LLMs) are increasingly deployed in critical applications requiring reliable reasoning, yet their internal reasoning processes remain difficult to evaluate systematically. Existing methods focus on final-answer correctness, providing limited insight into how reasoning unfolds across intermediate steps. We present EvalQReason, a framework that quantifies LLM reasoning quality through step-level probability distribution analysis without requiring human annotation. The framework introduces two complementary algorithms: Consecutive Step Divergence (CSD), which measures local coherence between adjacent reasoning steps, and Step-to-Final Convergence (SFC), which assesses global alignment with final answers. Each algorithm employs five statistical metrics to capture reasoning dynamics. Experiments across mathematical and medical datasets with open-source 7B-parameter models demonstrate that CSD-based features achieve strong predictive performance for correctness classification, with classical machine learning models reaching F1=0.78 and ROC-AUC=0.82, and sequential neural models substantially improving performance (F1=0.88, ROC-AUC=0.97). CSD consistently outperforms SFC, and sequential architectures outperform classical machine learning approaches. Critically, reasoning dynamics prove domain-specific: mathematical reasoning exhibits clear divergence-based discrimination patterns between correct and incorrect solutions, while medical reasoning shows minimal discriminative signals, revealing fundamental differences in how LLMs process different reasoning types. EvalQReason enables scalable, process-aware evaluation of reasoning reliability, establishing probability-based divergence analysis as a principled approach for trustworthy AI deployment.", "AI": {"tldr": "EvalQReason\u6846\u67b6\u901a\u8fc7\u5206\u6790\u63a8\u7406\u6b65\u9aa4\u7684\u6982\u7387\u5206\u5e03\u6765\u91cf\u5316LLM\u63a8\u7406\u8d28\u91cf\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff0c\u5305\u542bCSD\u548cSFC\u4e24\u79cd\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793aCSD\u7279\u5f81\u5728\u6b63\u786e\u6027\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u63a8\u7406\u52a8\u6001\u5177\u6709\u9886\u57df\u7279\u5f02\u6027\u3002", "motivation": "LLM\u5728\u5173\u952e\u5e94\u7528\u4e2d\u9700\u8981\u53ef\u9760\u63a8\u7406\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u96be\u4ee5\u7cfb\u7edf\u8bc4\u4f30\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\uff0c\u7f3a\u4e4f\u5bf9\u4e2d\u95f4\u6b65\u9aa4\u63a8\u7406\u8d28\u91cf\u7684\u91cf\u5316\u5206\u6790\u3002", "method": "\u63d0\u51faEvalQReason\u6846\u67b6\uff0c\u901a\u8fc7\u6b65\u9aa4\u7ea7\u6982\u7387\u5206\u5e03\u5206\u6790\u91cf\u5316\u63a8\u7406\u8d28\u91cf\uff0c\u5305\u542b\u4e24\u79cd\u7b97\u6cd5\uff1aCSD\uff08\u6d4b\u91cf\u76f8\u90bb\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u5c40\u90e8\u8fde\u8d2f\u6027\uff09\u548cSFC\uff08\u8bc4\u4f30\u4e0e\u6700\u7ec8\u7b54\u6848\u7684\u5168\u5c40\u5bf9\u9f50\u6027\uff09\uff0c\u6bcf\u79cd\u7b97\u6cd5\u4f7f\u7528\u4e94\u79cd\u7edf\u8ba1\u6307\u6807\u6355\u6349\u63a8\u7406\u52a8\u6001\u3002", "result": "\u5728\u6570\u5b66\u548c\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff1aCSD\u7279\u5f81\u5728\u6b63\u786e\u6027\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fbe\u5230F1=0.78\u548cROC-AUC=0.82\uff0c\u5e8f\u5217\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u663e\u8457\u63d0\u5347\u6027\u80fd\uff08F1=0.88\uff0cROC-AUC=0.97\uff09\u3002CSD\u59cb\u7ec8\u4f18\u4e8eSFC\uff0c\u5e8f\u5217\u67b6\u6784\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u3002\u63a8\u7406\u52a8\u6001\u5177\u6709\u9886\u57df\u7279\u5f02\u6027\uff1a\u6570\u5b66\u63a8\u7406\u663e\u793a\u6e05\u6670\u7684\u5206\u6b67\u6a21\u5f0f\uff0c\u533b\u5b66\u63a8\u7406\u5219\u51e0\u4e4e\u6ca1\u6709\u5224\u522b\u4fe1\u53f7\u3002", "conclusion": "EvalQReason\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u8fc7\u7a0b\u611f\u77e5\u7684\u63a8\u7406\u53ef\u9760\u6027\u8bc4\u4f30\uff0c\u786e\u7acb\u4e86\u57fa\u4e8e\u6982\u7387\u7684\u5206\u6b67\u5206\u6790\u4f5c\u4e3a\u53ef\u4fe1AI\u90e8\u7f72\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86LLM\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u63a8\u7406\u7684\u57fa\u672c\u5dee\u5f02\u3002"}}
{"id": "2602.02296", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02296", "abs": "https://arxiv.org/abs/2602.02296", "authors": ["Xingli Fang", "Jung-Eun Kim"], "title": "Decoupling Generalizability and Membership Privacy Risks in Neural Networks", "comment": null, "summary": "A deep learning model usually has to sacrifice some utilities when it acquires some other abilities or characteristics. Privacy preservation has such trade-off relationships with utilities. The loss disparity between various defense approaches implies the potential to decouple generalizability and privacy risks to maximize privacy gain. In this paper, we identify that the model's generalization and privacy risks exist in different regions in deep neural network architectures. Based on the observations that we investigate, we propose Privacy-Preserving Training Principle (PPTP) to protect model components from privacy risks while minimizing the loss in generalizability. Through extensive evaluations, our approach shows significantly better maintenance in model generalizability while enhancing privacy preservation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u539f\u5219\uff08PPTP\uff09\uff0c\u901a\u8fc7\u8bc6\u522b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u6cdb\u5316\u80fd\u529b\u548c\u9690\u79c1\u98ce\u9669\u5b58\u5728\u4e8e\u4e0d\u540c\u533a\u57df\u7684\u7279\u70b9\uff0c\u5728\u6700\u5927\u5316\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\u6700\u5c0f\u5316\u6cdb\u5316\u80fd\u529b\u7684\u635f\u5931\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u83b7\u5f97\u67d0\u4e9b\u80fd\u529b\u6216\u7279\u6027\u65f6\u901a\u5e38\u9700\u8981\u727a\u7272\u5176\u4ed6\u6548\u7528\uff0c\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6548\u7528\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u5173\u7cfb\u3002\u4e0d\u540c\u9632\u5fa1\u65b9\u6cd5\u4e4b\u95f4\u7684\u635f\u5931\u5dee\u5f02\u8868\u660e\u5b58\u5728\u5c06\u6cdb\u5316\u80fd\u529b\u548c\u9690\u79c1\u98ce\u9669\u89e3\u8026\u4ee5\u6700\u5927\u5316\u9690\u79c1\u6536\u76ca\u7684\u6f5c\u529b\u3002", "method": "\u4f5c\u8005\u8bc6\u522b\u51fa\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9690\u79c1\u98ce\u9669\u5b58\u5728\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u4e0d\u540c\u533a\u57df\uff0c\u57fa\u4e8e\u8fd9\u4e00\u89c2\u5bdf\u63d0\u51fa\u4e86\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u539f\u5219\uff08PPTP\uff09\uff0c\u901a\u8fc7\u4fdd\u62a4\u6a21\u578b\u7ec4\u4ef6\u514d\u53d7\u9690\u79c1\u98ce\u9669\u7684\u540c\u65f6\u6700\u5c0f\u5316\u6cdb\u5316\u80fd\u529b\u7684\u635f\u5931\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\uff0c\u663e\u8457\u66f4\u597d\u5730\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6cdb\u5316\u80fd\u529b\u548c\u9690\u79c1\u98ce\u9669\u53ef\u4ee5\u89e3\u8026\uff0c\u63d0\u51fa\u7684PPTP\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.02366", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02366", "abs": "https://arxiv.org/abs/2602.02366", "authors": ["Sharut Gupta", "Phillip Isola", "Stefanie Jegelka", "David Lopez-Paz", "Kartik Ahuja", "Mark Ibrahim", "Mohammad Pezeshki"], "title": "ReasonCACHE: Teaching LLMs To Reason Without Weight Updates", "comment": "26 pages, 17 Figures", "summary": "Can Large language models (LLMs) learn to reason without any weight update and only through in-context learning (ICL)? ICL is strikingly sample-efficient, often learning from only a handful of demonstrations, but complex reasoning tasks typically demand many training examples to learn from. However, naively scaling ICL by adding more demonstrations breaks down at this scale: attention costs grow quadratically, performance saturates or degrades with longer contexts, and the approach remains a shallow form of learning. Due to these limitations, practitioners predominantly rely on in-weight learning (IWL) to induce reasoning. In this work, we show that by using Prefix Tuning, LLMs can learn to reason without overloading the context window and without any weight updates. We introduce $\\textbf{ReasonCACHE}$, an instantiation of this mechanism that distills demonstrations into a fixed key-value cache. Empirically, across challenging reasoning benchmarks, including GPQA-Diamond, ReasonCACHE outperforms standard ICL and matches or surpasses IWL approaches. Further, it achieves this all while being more efficient across three key axes: data, inference cost, and trainable parameters. We also theoretically prove that ReasonCACHE can be strictly more expressive than low-rank weight update since the latter ties expressivity to input rank, whereas ReasonCACHE bypasses this constraint by directly injecting key-values into the attention mechanism. Together, our findings identify ReasonCACHE as a middle path between in-context and in-weight learning, providing a scalable algorithm for learning reasoning skills beyond the context window without modifying parameters. Our project page: https://reasoncache.github.io/", "AI": {"tldr": "ReasonCACHE\u4f7f\u7528\u524d\u7f00\u8c03\u4f18\u5c06\u63a8\u7406\u6f14\u793a\u84b8\u998f\u5230\u56fa\u5b9a\u952e\u503c\u7f13\u5b58\u4e2d\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u9700\u6743\u91cd\u66f4\u65b0\u5373\u53ef\u5b66\u4e60\u63a8\u7406\uff0c\u5728\u6548\u7387\u4e0a\u4f18\u4e8e\u6807\u51c6\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u6027\u80fd\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u6743\u91cd\u5185\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u6807\u51c6\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u6ce8\u610f\u529b\u6210\u672c\u5448\u4e8c\u6b21\u589e\u957f\u3001\u957f\u4e0a\u4e0b\u6587\u4e0b\u6027\u80fd\u9971\u548c\u6216\u4e0b\u964d\u3001\u5b66\u4e60\u5f62\u5f0f\u6d45\u5c42\u3002\u800c\u6743\u91cd\u5185\u5b66\u4e60\u9700\u8981\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9ad8\u6548\u5b66\u4e60\u63a8\u7406\u6280\u80fd\u53c8\u65e0\u9700\u4fee\u6539\u53c2\u6570\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faReasonCACHE\uff0c\u57fa\u4e8e\u524d\u7f00\u8c03\u4f18\u673a\u5236\uff0c\u5c06\u63a8\u7406\u6f14\u793a\u84b8\u998f\u5230\u56fa\u5b9a\u7684\u952e\u503c\u7f13\u5b58\u4e2d\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u8d85\u8f7d\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u65e0\u9700\u6743\u91cd\u66f4\u65b0\uff0c\u76f4\u63a5\u5411\u6ce8\u610f\u529b\u673a\u5236\u6ce8\u5165\u952e\u503c\u5bf9\uff0c\u7ed5\u8fc7\u4f4e\u79e9\u6743\u91cd\u66f4\u65b0\u7684\u8868\u8fbe\u6027\u9650\u5236\u3002", "result": "\u5728\u5305\u62ecGPQA-Diamond\u5728\u5185\u7684\u591a\u4e2a\u6311\u6218\u6027\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReasonCACHE\u4f18\u4e8e\u6807\u51c6\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u6743\u91cd\u5185\u5b66\u4e60\u65b9\u6cd5\u3002\u540c\u65f6\u5728\u6570\u636e\u6548\u7387\u3001\u63a8\u7406\u6210\u672c\u548c\u53ef\u8bad\u7ec3\u53c2\u6570\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\u4e0a\u66f4\u52a0\u9ad8\u6548\u3002", "conclusion": "ReasonCACHE\u662f\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u6743\u91cd\u5185\u5b66\u4e60\u4e4b\u95f4\u7684\u4e2d\u95f4\u8def\u5f84\uff0c\u63d0\u4f9b\u4e86\u65e0\u9700\u4fee\u6539\u53c2\u6570\u5373\u53ef\u5b66\u4e60\u8d85\u51fa\u4e0a\u4e0b\u6587\u7a97\u53e3\u63a8\u7406\u6280\u80fd\u7684\u53ef\u6269\u5c55\u7b97\u6cd5\uff0c\u7406\u8bba\u4e0a\u6bd4\u4f4e\u79e9\u6743\u91cd\u66f4\u65b0\u66f4\u5177\u8868\u8fbe\u6027\u3002"}}
{"id": "2602.02371", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02371", "abs": "https://arxiv.org/abs/2602.02371", "authors": ["Jing Wang", "Jie Shen", "Qiaomin Xie", "Jeremy C Weiss"], "title": "C-kNN-LSH: A Nearest-Neighbor Algorithm for Sequential Counterfactual Inference", "comment": null, "summary": "Estimating causal effects from longitudinal trajectories is central to understanding the progression of complex conditions and optimizing clinical decision-making, such as comorbidities and long COVID recovery. We introduce \\emph{C-kNN--LSH}, a nearest-neighbor framework for sequential causal inference designed to handle such high-dimensional, confounded situations. By utilizing locality-sensitive hashing, we efficiently identify ``clinical twins'' with similar covariate histories, enabling local estimation of conditional treatment effects across evolving disease states. To mitigate bias from irregular sampling and shifting patient recovery profiles, we integrate neighborhood estimator with a doubly-robust correction.\n  Theoretical analysis guarantees our estimator is consistent and second-order robust to nuisance error.\n  Evaluated on a real-world Long COVID cohort with 13,511 participants, \\emph{C-kNN-LSH} demonstrates superior performance in capturing recovery heterogeneity and estimating policy values compared to existing baselines.", "AI": {"tldr": "C-kNN-LSH\uff1a\u57fa\u4e8e\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u7684\u6700\u8fd1\u90bb\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u7ef4\u6df7\u6742\u7684\u7eb5\u5411\u56e0\u679c\u63a8\u65ad\uff0c\u5728\u957f\u65b0\u51a0\u961f\u5217\u4e2d\u8868\u73b0\u4f18\u5f02", "motivation": "\u4ece\u7eb5\u5411\u8f68\u8ff9\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u5bf9\u4e8e\u7406\u89e3\u590d\u6742\u75be\u75c5\u8fdb\u5c55\u548c\u4f18\u5316\u4e34\u5e8a\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u5171\u75c5\u548c\u957f\u65b0\u51a0\u6062\u590d\u7b49\u573a\u666f\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u9ad8\u7ef4\u3001\u6df7\u6742\u7684\u7eb5\u5411\u6570\u636e\u3002", "method": "\u63d0\u51faC-kNN-LSH\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u9ad8\u6548\u8bc6\u522b\u5177\u6709\u76f8\u4f3c\u534f\u53d8\u91cf\u5386\u53f2\u7684\"\u4e34\u5e8a\u53cc\u80de\u80ce\"\uff1b2\uff09\u5728\u6f14\u53d8\u7684\u75be\u75c5\u72b6\u6001\u4e0b\u8fdb\u884c\u5c40\u90e8\u6761\u4ef6\u6cbb\u7597\u6548\u5e94\u4f30\u8ba1\uff1b3\uff09\u96c6\u6210\u90bb\u57df\u4f30\u8ba1\u5668\u548c\u53cc\u91cd\u7a33\u5065\u6821\u6b63\uff0c\u4ee5\u51cf\u8f7b\u4e0d\u89c4\u5219\u91c7\u6837\u548c\u60a3\u8005\u6062\u590d\u7279\u5f81\u53d8\u5316\u5e26\u6765\u7684\u504f\u5dee\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4f30\u8ba1\u91cf\u5177\u6709\u4e00\u81f4\u6027\u548c\u5bf9\u5e72\u6270\u8bef\u5dee\u7684\u4e8c\u9636\u7a33\u5065\u6027\u3002\u5728\u5305\u542b13,511\u540d\u53c2\u4e0e\u8005\u7684\u771f\u5b9e\u4e16\u754c\u957f\u65b0\u51a0\u961f\u5217\u8bc4\u4f30\u4e2d\uff0cC-kNN-LSH\u5728\u6355\u6349\u6062\u590d\u5f02\u8d28\u6027\u548c\u4f30\u8ba1\u7b56\u7565\u4ef7\u503c\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "C-kNN-LSH\u4e3a\u9ad8\u7ef4\u6df7\u6742\u7eb5\u5411\u6570\u636e\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u957f\u65b0\u51a0\u6062\u590d\u7b49\u590d\u6742\u4e34\u5e8a\u573a\u666f\uff0c\u80fd\u591f\u8bc6\u522b\u4e34\u5e8a\u53cc\u80de\u80ce\u5e76\u51c6\u786e\u4f30\u8ba1\u6cbb\u7597\u6548\u5e94\u3002"}}
{"id": "2602.02381", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02381", "abs": "https://arxiv.org/abs/2602.02381", "authors": ["Yipeng Zhang", "Hafez Ghaemi", "Jungyoon Lee", "Shahab Bakhtiari", "Eilif B. Muller", "Laurent Charlin"], "title": "Self-Supervised Learning from Structural Invariance", "comment": "ICLR 2026", "summary": "Joint-embedding self-supervised learning (SSL), the key paradigm for unsupervised representation learning from visual data, learns from invariances between semantically-related data pairs. We study the one-to-many mapping problem in SSL, where each datum may be mapped to multiple valid targets. This arises when data pairs come from naturally occurring generative processes, e.g., successive video frames. We show that existing methods struggle to flexibly capture this conditional uncertainty. As a remedy, we introduce a latent variable to account for this uncertainty and derive a variational lower bound on the mutual information between paired embeddings. Our derivation yields a simple regularization term for standard SSL objectives. The resulting method, which we call AdaSSL, applies to both contrastive and distillation-based SSL objectives, and we empirically show its versatility in causal representation learning, fine-grained image understanding, and world modeling on videos.", "AI": {"tldr": "\u63d0\u51faAdaSSL\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6f5c\u53d8\u91cf\u89e3\u51b3\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u4e00\u5bf9\u591a\u6620\u5c04\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u548c\u84b8\u998f\u65b9\u6cd5", "motivation": "\u73b0\u6709\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u7075\u6d3b\u6355\u6349\u6570\u636e\u5bf9\u4e2d\u7684\u6761\u4ef6\u4e0d\u786e\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5f53\u6570\u636e\u6765\u81ea\u81ea\u7136\u751f\u6210\u8fc7\u7a0b\uff08\u5982\u8fde\u7eed\u89c6\u9891\u5e27\uff09\u65f6\u5b58\u5728\u4e00\u5bf9\u591a\u6620\u5c04\u95ee\u9898", "method": "\u5f15\u5165\u6f5c\u53d8\u91cf\u6765\u5efa\u6a21\u6761\u4ef6\u4e0d\u786e\u5b9a\u6027\uff0c\u63a8\u5bfc\u51fa\u914d\u5bf9\u5d4c\u5165\u95f4\u4e92\u4fe1\u606f\u7684\u53d8\u5206\u4e0b\u754c\uff0c\u5f97\u5230\u53ef\u5e94\u7528\u4e8e\u6807\u51c6SSL\u76ee\u6807\u7684\u7b80\u5355\u6b63\u5219\u5316\u9879", "result": "AdaSSL\u65b9\u6cd5\u5728\u56e0\u679c\u8868\u793a\u5b66\u4e60\u3001\u7ec6\u7c92\u5ea6\u56fe\u50cf\u7406\u89e3\u548c\u89c6\u9891\u4e16\u754c\u5efa\u6a21\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u901a\u7528\u6027", "conclusion": "\u901a\u8fc7\u5efa\u6a21\u4e00\u5bf9\u591a\u6620\u5c04\u4e2d\u7684\u6761\u4ef6\u4e0d\u786e\u5b9a\u6027\uff0cAdaSSL\u80fd\u6709\u6548\u63d0\u5347\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u5404\u79cd\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u6027\u80fd"}}
{"id": "2602.02383", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02383", "abs": "https://arxiv.org/abs/2602.02383", "authors": ["Maksim Afanasyev", "Illarion Iov"], "title": "SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization", "comment": null, "summary": "Direct preference optimization methods have emerged as a computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) for aligning Large Language Models (LLMs). Latest approaches have streamlined the alignment process by deriving implicit reward functions, yet they often suffer from a critical objective mismatch: optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen response's absolute likelihood. This can lead to ``unlearning'', where the model degrades the probability of high-quality outputs to satisfy margin constraints, and ``formatting collapse'' caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), a reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates a three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) a stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) a dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to state-of-the-art baselines while maintaining higher generation stability.", "AI": {"tldr": "SLIME\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u53c2\u8003\u5bf9\u9f50\u76ee\u6807\uff0c\u901a\u8fc7\u89e3\u8026\u504f\u597d\u5b66\u4e60\u4e0e\u751f\u6210\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u76f4\u63a5\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u4e2d\u7684\"\u9057\u5fd8\"\u548c\"\u683c\u5f0f\u5316\u5d29\u6e83\"\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u76f4\u63a5\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u76ee\u6807\u4e0d\u5339\u914d\u95ee\u9898\uff1a\u4f18\u5316\u9009\u62e9\u4e0e\u62d2\u7edd\u54cd\u5e94\u4e4b\u95f4\u7684\u76f8\u5bf9\u8fb9\u754c\u4e0d\u80fd\u4fdd\u8bc1\u4fdd\u7559\u9009\u62e9\u54cd\u5e94\u7684\u7edd\u5bf9\u4f3c\u7136\uff0c\u5bfc\u81f4\"\u9057\u5fd8\"\uff08\u9ad8\u8d28\u91cf\u8f93\u51fa\u6982\u7387\u4e0b\u964d\uff09\u548c\"\u683c\u5f0f\u5316\u5d29\u6e83\"\uff08\u62d2\u7edd\u5e8f\u5217\u8fc7\u5ea6\u60e9\u7f5a\uff09\u3002", "method": "SLIME\u91c7\u7528\u4e09\u90e8\u5206\u76ee\u6807\uff1a(1)\u951a\u5b9a\u9879\u6700\u5927\u5316\u504f\u597d\u54cd\u5e94\u7684\u4f3c\u7136\uff1b(2)\u7a33\u5b9a\u60e9\u7f5a\u9632\u6b62\u62d2\u7edd\u4ee4\u724c\u6982\u7387\u5d29\u6e83\u4e3a\u96f6\uff1b(3)\u7ed3\u5408\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u7684\u53cc\u8fb9\u754c\u673a\u5236\u8fdb\u884c\u7cbe\u786e\u8fb9\u754c\u5851\u9020\u3002", "result": "SLIME\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u9ad8\u7684\u751f\u6210\u7a33\u5b9a\u6027\u3002", "conclusion": "SLIME\u901a\u8fc7\u89e3\u8026\u504f\u597d\u5b66\u4e60\u4e0e\u751f\u6210\u8d28\u91cf\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7a33\u5b9a\u6709\u6548\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u76f4\u63a5\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u7684\u5173\u952e\u9650\u5236\u3002"}}
{"id": "2602.02385", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02385", "abs": "https://arxiv.org/abs/2602.02385", "authors": ["Adam Shai", "Loren Amdahl-Culleton", "Casper L. Christensen", "Henry R. Bigelow", "Fernando E. Rosas", "Alexander B. Boyd", "Eric A. Alt", "Kyle J. Ray", "Paul M. Riechers"], "title": "Transformers learn factored representations", "comment": null, "summary": "Transformers pretrained via next token prediction learn to factor their world into parts, representing these factors in orthogonal subspaces of the residual stream. We formalize two representational hypotheses: (1) a representation in the product space of all factors, whose dimension grows exponentially with the number of parts, or (2) a factored representation in orthogonal subspaces, whose dimension grows linearly. The factored representation is lossless when factors are conditionally independent, but sacrifices predictive fidelity otherwise, creating a tradeoff between dimensional efficiency and accuracy. We derive precise predictions about the geometric structure of activations for each, including the number of subspaces, their dimensionality, and the arrangement of context embeddings within them. We test between these hypotheses on transformers trained on synthetic processes with known latent structure. Models learn factored representations when factors are conditionally independent, and continue to favor them early in training even when noise or hidden dependencies undermine conditional independence, reflecting an inductive bias toward factoring at the cost of fidelity. This provides a principled explanation for why transformers decompose the world into parts, and suggests that interpretable low dimensional structure may persist even in models trained on complex data.", "AI": {"tldr": "Transformer\u901a\u8fc7\u56e0\u5b50\u5206\u89e3\u5b66\u4e60\u4e16\u754c\u8868\u793a\uff0c\u5728\u6761\u4ef6\u72ec\u7acb\u65f6\u91c7\u7528\u6b63\u4ea4\u5b50\u7a7a\u95f4\u5206\u89e3\uff0c\u5426\u5219\u5728\u7ef4\u5ea6\u6548\u7387\u548c\u51c6\u786e\u6027\u95f4\u6743\u8861", "motivation": "\u7814\u7a76Transformer\u5982\u4f55\u901a\u8fc7\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u5b66\u4e60\u5c06\u4e16\u754c\u5206\u89e3\u4e3a\u56e0\u5b50\uff0c\u5e76\u63a2\u7d22\u5176\u8868\u793a\u5047\u8bbe\uff1a\u662f\u4e58\u79ef\u7a7a\u95f4\u8868\u793a\u8fd8\u662f\u56e0\u5b50\u5316\u6b63\u4ea4\u5b50\u7a7a\u95f4\u8868\u793a", "method": "\u63d0\u51fa\u4e24\u79cd\u8868\u793a\u5047\u8bbe\u7684\u51e0\u4f55\u7ed3\u6784\u9884\u6d4b\uff0c\u5728\u5177\u6709\u5df2\u77e5\u6f5c\u5728\u7ed3\u6784\u7684\u5408\u6210\u8fc7\u7a0b\u4e0a\u8bad\u7ec3Transformer\u8fdb\u884c\u6d4b\u8bd5", "result": "\u5f53\u56e0\u5b50\u6761\u4ef6\u72ec\u7acb\u65f6\uff0c\u6a21\u578b\u5b66\u4e60\u56e0\u5b50\u5316\u8868\u793a\uff1b\u5373\u4f7f\u5b58\u5728\u566a\u58f0\u6216\u9690\u85cf\u4f9d\u8d56\u7834\u574f\u6761\u4ef6\u72ec\u7acb\u6027\uff0c\u8bad\u7ec3\u65e9\u671f\u4ecd\u504f\u597d\u56e0\u5b50\u5316\uff0c\u8868\u660e\u5b58\u5728\u4ee5\u4fdd\u771f\u5ea6\u4e3a\u4ee3\u4ef7\u7684\u56e0\u5b50\u5206\u89e3\u5f52\u7eb3\u504f\u7f6e", "conclusion": "\u4e3aTransformer\u5c06\u4e16\u754c\u5206\u89e3\u4e3a\u90e8\u5206\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u89e3\u91ca\uff0c\u8868\u660e\u5373\u4f7f\u5728\u590d\u6742\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u53ef\u89e3\u91ca\u7684\u4f4e\u7ef4\u7ed3\u6784\u53ef\u80fd\u6301\u7eed\u5b58\u5728"}}
{"id": "2602.02395", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02395", "abs": "https://arxiv.org/abs/2602.02395", "authors": ["Samuel Nellessen", "Tal Kachman"], "title": "David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning", "comment": "Under review. 8 main pages, 2 figures, 2 tables. Appendix included", "summary": "The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary \"tags along\" on the trusted privileges of a safety-aligned Operator to induce prohibited tool use through conversation alone. To validate this threat, we present Slingshot, a 'cold-start' reinforcement learning framework that autonomously discovers emergent attack vectors, revealing a critical insight: in our setting, learned attacks tend to converge to short, instruction-like syntactic patterns rather than multi-turn persuasion. On held-out extreme-difficulty tasks, Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ Operator (vs. 1.7% baseline), reducing the expected attempts to first success (on solved tasks) from 52.3 to 1.3. Crucially, Slingshot transfers zero-shot to several model families, including closed-source models like Gemini 2.5 Flash (56.0% attack success rate) and defensive-fine-tuned open-source models like Meta-SecAlign-8B (39.2% attack success rate). Our work establishes Tag-Along Attacks as a first-class, verifiable threat model and shows that effective agentic attacks can be elicited from off-the-shelf open-weight models through environment interaction alone.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"Tag-Along Attacks\"\u5a01\u80c1\u6a21\u578b\uff1a\u65e0\u5de5\u5177\u6743\u9650\u7684\u653b\u51fb\u8005\u901a\u8fc7\u5bf9\u8bdd\u5229\u7528\u5b89\u5168\u5bf9\u9f50\u64cd\u4f5c\u5458\u7684\u5de5\u5177\u6743\u9650\uff0c\u5b9e\u73b0\u7981\u6b62\u7684\u5de5\u5177\u4f7f\u7528\u3002\u4f5c\u8005\u5f00\u53d1\u4e86Slingshot\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u53d1\u73b0\u653b\u51fb\u5411\u91cf\uff0c\u5728\u6781\u7aef\u56f0\u96be\u4efb\u52a1\u4e0a\u8fbe\u523067%\u6210\u529f\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5411\u81ea\u4e3b\u4ee3\u7406\u7684\u6f14\u8fdb\u5f15\u5165\u4e86\u5bf9\u6297\u6027\u5931\u6548\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u5229\u7528\u5408\u6cd5\u5de5\u5177\u6743\u9650\u3002\u4f20\u7edf\u5b89\u5168\u8bc4\u4f30\u5728\u5de5\u5177\u589e\u5f3a\u73af\u5883\u4e2d\u4ece\u4e3b\u89c2NLP\u4efb\u52a1\u8f6c\u53d8\u4e3a\u5ba2\u89c2\u63a7\u5236\u95ee\u9898\uff0c\u9700\u8981\u5f62\u5f0f\u5316\u8fd9\u79cd\u5a01\u80c1\u6a21\u578b\u3002", "method": "\u63d0\u51faTag-Along Attacks\u5a01\u80c1\u6a21\u578b\uff0c\u5f00\u53d1Slingshot\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4ece\"\u51b7\u542f\u52a8\"\u5f00\u59cb\u81ea\u4e3b\u53d1\u73b0\u653b\u51fb\u5411\u91cf\u3002\u6846\u67b6\u5728\u5de5\u5177\u589e\u5f3a\u73af\u5883\u4e2d\u8bad\u7ec3\u653b\u51fb\u8005\u6a21\u578b\uff0c\u901a\u8fc7\u73af\u5883\u4ea4\u4e92\u5b66\u4e60\u6709\u6548\u653b\u51fb\u7b56\u7565\u3002", "result": "Slingshot\u5728\u6781\u7aef\u56f0\u96be\u4efb\u52a1\u4e0a\u5bf9Qwen2.5-32B-Instruct-AWQ\u64cd\u4f5c\u5458\u8fbe\u523067.0%\u6210\u529f\u7387\uff08\u57fa\u7ebf\u4ec51.7%\uff09\uff0c\u9996\u6b21\u6210\u529f\u5c1d\u8bd5\u6b21\u6570\u4ece52.3\u964d\u81f31.3\u3002\u96f6\u6837\u672c\u8fc1\u79fb\u5230\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\uff0c\u5305\u62ecGemini 2.5 Flash\uff0856.0%\uff09\u548cMeta-SecAlign-8B\uff0839.2%\uff09\u3002", "conclusion": "Tag-Along Attacks\u662f\u53ef\u9a8c\u8bc1\u7684\u4e00\u7ea7\u5a01\u80c1\u6a21\u578b\uff0c\u8868\u660e\u6709\u6548\u7684\u4ee3\u7406\u653b\u51fb\u53ef\u4ee5\u901a\u8fc7\u73af\u5883\u4ea4\u4e92\u4ece\u73b0\u6210\u7684\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u4e2d\u5f15\u53d1\u3002\u653b\u51fb\u503e\u5411\u4e8e\u6536\u655b\u5230\u7b80\u77ed\u3001\u6307\u4ee4\u5f0f\u7684\u53e5\u6cd5\u6a21\u5f0f\u800c\u975e\u591a\u8f6e\u8bf4\u670d\u3002"}}
{"id": "2602.02400", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02400", "abs": "https://arxiv.org/abs/2602.02400", "authors": ["Qizhen Zhang", "Ankush Garg", "Jakob Foerster", "Niladri Chatterji", "Kshitiz Malik", "Mike Lewis"], "title": "An Empirical Study on Noisy Data and LLM Pretraining Loss Divergence", "comment": null, "summary": "Large-scale pretraining datasets drive the success of large language models (LLMs). However, these web-scale corpora inevitably contain large amounts of noisy data due to unregulated web content or randomness inherent in data. Although LLM pretrainers often speculate that such noise contributes to instabilities in large-scale LLM pretraining and, in the worst cases, loss divergence, this phenomenon remains poorly understood.In this work, we present a systematic empirical study of whether noisy data causes LLM pretraining divergences and how it does so. By injecting controlled synthetic uniformly random noise into otherwise clean datasets, we analyze training dynamics across model sizes ranging from 480M to 5.2B parameters. We show that noisy data indeed induces training loss divergence, and that the probability of divergence depends strongly on the noise type, amount of noise, and model scale. We further find that noise-induced divergences exhibit activation patterns distinct from those caused by high learning rates, and we provide diagnostics that differentiate these two failure modes. Together, these results provide a large-scale, controlled characterization of how noisy data affects loss divergence in LLM pretraining.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u566a\u58f0\u6570\u636e\u786e\u5b9e\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u635f\u5931\u53d1\u6563\uff0c\u4e14\u53d1\u6563\u6982\u7387\u53d7\u566a\u58f0\u7c7b\u578b\u3001\u566a\u58f0\u91cf\u548c\u6a21\u578b\u89c4\u6a21\u7684\u5f71\u54cd\u3002", "motivation": "\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u4e0d\u53ef\u907f\u514d\u5730\u5305\u542b\u5927\u91cf\u566a\u58f0\u6570\u636e\uff0c\u8fd9\u4e9b\u566a\u58f0\u88ab\u8ba4\u4e3a\u4f1a\u5bfc\u81f4LLM\u9884\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u751a\u81f3\u635f\u5931\u53d1\u6563\uff0c\u4f46\u8fd9\u4e00\u73b0\u8c61\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5728\u5e72\u51c0\u6570\u636e\u96c6\u4e2d\u6ce8\u5165\u53d7\u63a7\u7684\u5408\u6210\u5747\u5300\u968f\u673a\u566a\u58f0\uff0c\u5206\u6790\u4ece480M\u52305.2B\u53c2\u6570\u7684\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "result": "\u566a\u58f0\u6570\u636e\u786e\u5b9e\u4f1a\u5f15\u53d1\u8bad\u7ec3\u635f\u5931\u53d1\u6563\uff1b\u53d1\u6563\u6982\u7387\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u566a\u58f0\u7c7b\u578b\u3001\u566a\u58f0\u91cf\u548c\u6a21\u578b\u89c4\u6a21\uff1b\u566a\u58f0\u5f15\u53d1\u7684\u53d1\u6563\u8868\u73b0\u51fa\u4e0e\u9ad8\u5b66\u4e60\u7387\u4e0d\u540c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u566a\u58f0\u6570\u636e\u5982\u4f55\u5f71\u54cdLLM\u9884\u8bad\u7ec3\u635f\u5931\u53d1\u6563\u7684\u5927\u89c4\u6a21\u3001\u53d7\u63a7\u7279\u5f81\u63cf\u8ff0\uff0c\u5e76\u63d0\u4f9b\u4e86\u533a\u5206\u4e0d\u540c\u5931\u8d25\u6a21\u5f0f\u7684\u8bca\u65ad\u65b9\u6cd5\u3002"}}
{"id": "2602.02405", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02405", "abs": "https://arxiv.org/abs/2602.02405", "authors": ["Ethan Mendes", "Jungsoo Park", "Alan Ritter"], "title": "Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning", "comment": null, "summary": "Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model's ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization.", "AI": {"tldr": "DAIL\u65b9\u6cd5\u901a\u8fc7\u5c06\u4e13\u5bb6\u89e3\u51b3\u65b9\u6848\u8f6c\u5316\u4e3a\u8be6\u7ec6\u63a8\u7406\u8f68\u8ff9\u5e76\u5e94\u7528\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ec5\u7528\u5c11\u91cf\u4e13\u5bb6\u6570\u636e\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u80fd\u529b\u63d0\u5347\u901a\u5e38\u4f9d\u8d56\u6a21\u578b\u81ea\u8eab\u91c7\u6837\u6b63\u786e\u89e3\u6216\u66f4\u5f3a\u6a21\u578b\uff0c\u4f46\u8bb8\u591a\u96be\u9898\u5bf9\u524d\u6cbf\u6a21\u578b\u4ecd\u4e0d\u53ef\u89e3\u3002\u4e13\u5bb6\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u9ad8\u4f46\u5206\u5e03\u5916\uff0c\u4e14\u6210\u672c\u6602\u8d35\uff0c\u9700\u8981\u6837\u672c\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5", "method": "\u63d0\u51fa\u5206\u5e03\u5bf9\u9f50\u6a21\u4eff\u5b66\u4e60(DAIL)\uff1a1) \u5c06\u4e13\u5bb6\u89e3\u51b3\u65b9\u6848\u8f6c\u5316\u4e3a\u8be6\u7ec6\u3001\u5206\u5e03\u5185\u7684\u63a8\u7406\u8f68\u8ff9\uff1b2) \u5e94\u7528\u5bf9\u6bd4\u76ee\u6807\uff0c\u805a\u7126\u5b66\u4e60\u4e13\u5bb6\u89c1\u89e3\u548c\u65b9\u6cd5\u8bba", "result": "\u4ec5\u7528\u4e0d\u52301000\u4e2a\u9ad8\u8d28\u91cf\u4e13\u5bb6\u89e3\u51b3\u65b9\u6848\uff0c\u5728Qwen2.5-Instruct\u548cQwen3\u6a21\u578b\u4e0a\u5b9e\u73b010-25%\u7684pass@k\u63d0\u5347\uff0c\u63a8\u7406\u6548\u7387\u63d0\u9ad82-4\u500d\uff0c\u5e76\u5b9e\u73b0\u9886\u57df\u5916\u6cdb\u5316", "conclusion": "DAIL\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528\u5c11\u91cf\u4e13\u5bb6\u6570\u636e\u89e3\u51b3\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u548c\u6548\u7387\uff0c\u4e3a\u6837\u672c\u9ad8\u6548\u7684\u63a8\u7406\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.02415", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02415", "abs": "https://arxiv.org/abs/2602.02415", "authors": ["Vivienne Pelletier", "Daniel J. Rivera", "Obinna Nwokonkwo", "Steven A. Wilson", "Christopher L. Muhich"], "title": "Active Transfer Bagging: A New Approach for Accelerated Active Learning Acquisition of Data by Combined Transfer Learning and Bagging Based Models", "comment": null, "summary": "Modern machine learning has achieved remarkable success on many problems, but this success often depends on the existence of large, labeled datasets. While active learning can dramatically reduce labeling cost when annotations are expensive, early performance is frequently dominated by the initial seed set, typically chosen at random. In many applications, however, related or approximate datasets are readily available and can be leveraged to construct a better seed set. We introduce a new method for selecting the seed data set for active learning, Active-Transfer Bagging (ATBagging). ATBagging estimates the informativeness of candidate data point from a Bayesian interpretation of bagged ensemble models by comparing in-bag and out-of-bag predictive distributions from the labeled dataset, yielding an information-gain proxy. To avoid redundant selections, we impose feature-space diversity by sampling a determinantal point process (DPP) whose kernel uses Random Fourier Features and a quality-diversity factorization that incorporates the informativeness scores. This same blended method is used for selection of new data points to collect during the active learning phase. We evaluate ATBagging on four real-world datasets covering both target-transfer and feature-shift scenarios (QM9, ERA5, Forbes 2000, and Beijing PM2.5). Across seed sizes nseed = 10-100, ATBagging improves or ties early active learning and increases area under the learning-curve relative to alternative seed subset selection methodologies in almost all cases, with strongest benefits in low-data regimes. Thus, ATBagging provides a low-cost, high reward means to initiating active learning-based data collection.", "AI": {"tldr": "ATBagging\u662f\u4e00\u79cd\u65b0\u7684\u4e3b\u52a8\u5b66\u4e60\u79cd\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u96c6\u6210\u6a21\u578b\u4f30\u8ba1\u6570\u636e\u70b9\u4fe1\u606f\u91cf\uff0c\u7ed3\u5408DPP\u4fdd\u8bc1\u591a\u6837\u6027\uff0c\u5728\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u4e3b\u52a8\u5b66\u4e60\u65e9\u671f\u6027\u80fd\u3002", "motivation": "\u4e3b\u52a8\u5b66\u4e60\u867d\u7136\u80fd\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u4f46\u5176\u65e9\u671f\u6027\u80fd\u901a\u5e38\u53d7\u9650\u4e8e\u968f\u673a\u9009\u62e9\u7684\u521d\u59cb\u79cd\u5b50\u96c6\u3002\u8bb8\u591a\u5e94\u7528\u573a\u666f\u4e2d\u5b58\u5728\u76f8\u5173\u6216\u8fd1\u4f3c\u6570\u636e\u96c6\uff0c\u53ef\u7528\u4e8e\u6784\u5efa\u66f4\u597d\u7684\u79cd\u5b50\u96c6\uff0c\u4ece\u800c\u63d0\u5347\u4e3b\u52a8\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51faActive-Transfer Bagging (ATBagging)\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u888b\u88c5\u96c6\u6210\u6a21\u578b\u7684\u8d1d\u53f6\u65af\u89e3\u91ca\uff0c\u6bd4\u8f83\u888b\u5185\u548c\u888b\u5916\u9884\u6d4b\u5206\u5e03\u6765\u4f30\u8ba1\u5019\u9009\u6570\u636e\u70b9\u7684\u4fe1\u606f\u91cf\uff1b2) \u4f7f\u7528\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b(DPP)\u7ed3\u5408\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u548c\u8d28-\u91cf\u5206\u89e3\u6765\u4fdd\u8bc1\u7279\u5f81\u7a7a\u95f4\u591a\u6837\u6027\uff1b3) \u5c06\u540c\u4e00\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e3b\u52a8\u5b66\u4e60\u9636\u6bb5\u7684\u65b0\u6570\u636e\u70b9\u9009\u62e9\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6(QM9, ERA5, Forbes 2000, Beijing PM2.5)\u4e0a\u8bc4\u4f30\uff0c\u6db5\u76d6\u76ee\u6807\u8fc1\u79fb\u548c\u7279\u5f81\u504f\u79fb\u573a\u666f\u3002\u5728\u79cd\u5b50\u96c6\u5927\u5c0f10-100\u8303\u56f4\u5185\uff0cATBagging\u5728\u51e0\u4e4e\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u4f18\u4e8e\u6216\u6301\u5e73\u5176\u4ed6\u79cd\u5b50\u9009\u62e9\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u6548\u679c\u6700\u663e\u8457\uff0c\u63d0\u9ad8\u4e86\u5b66\u4e60\u66f2\u7ebf\u4e0b\u9762\u79ef\u3002", "conclusion": "ATBagging\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u9ad8\u56de\u62a5\u7684\u4e3b\u52a8\u5b66\u4e60\u6570\u636e\u6536\u96c6\u542f\u52a8\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u76f8\u5173\u6570\u636e\u96c6\u6784\u5efa\u66f4\u597d\u7684\u521d\u59cb\u79cd\u5b50\u96c6\uff0c\u663e\u8457\u63d0\u5347\u4e3b\u52a8\u5b66\u4e60\u7684\u65e9\u671f\u6027\u80fd\u3002"}}
{"id": "2602.02417", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02417", "abs": "https://arxiv.org/abs/2602.02417", "authors": ["Zekun Wang", "Anant Gupta", "Christopher J. MacLellan"], "title": "Trust Region Continual Learning as an Implicit Meta-Learner", "comment": "19 pages, 23 tables", "summary": "Continual learning aims to acquire tasks sequentially without catastrophic forgetting, yet standard strategies face a core tradeoff: regularization-based methods (e.g., EWC) can overconstrain updates when task optima are weakly overlapping, while replay-based methods can retain performance but drift due to imperfect replay. We study a hybrid perspective: \\emph{trust region continual learning} that combines generative replay with a Fisher-metric trust region constraint. We show that, under local approximations, the resulting update admits a MAML-style interpretation with a single implicit inner step: replay supplies an old-task gradient signal (query-like), while the Fisher-weighted penalty provides an efficient offline curvature shaping (support-like). This yields an emergent meta-learning property in continual learning: the model becomes an initialization that rapidly \\emph{re-converges} to prior task optima after each task transition, without explicitly optimizing a bilevel objective. Empirically, on task-incremental diffusion image generation and continual diffusion-policy control, trust region continual learning achieves the best final performance and retention, and consistently recovers early-task performance faster than EWC, replay, and continual meta-learning baselines.", "AI": {"tldr": "\u63d0\u51fa\u4fe1\u4efb\u533a\u57df\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u751f\u6210\u56de\u653e\u548cFisher\u5ea6\u91cf\u4fe1\u4efb\u533a\u57df\u7ea6\u675f\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u5b9e\u73b0\u7c7b\u4f3c\u5143\u5b66\u4e60\u7684\u5feb\u901f\u91cd\u6536\u655b\u7279\u6027", "motivation": "\u4f20\u7edf\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u6838\u5fc3\u6743\u8861\uff1a\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u65b9\u6cd5\uff08\u5982EWC\uff09\u5728\u4efb\u52a1\u6700\u4f18\u89e3\u91cd\u53e0\u5ea6\u4f4e\u65f6\u4f1a\u8fc7\u5ea6\u7ea6\u675f\u66f4\u65b0\uff0c\u800c\u57fa\u4e8e\u56de\u653e\u7684\u65b9\u6cd5\u867d\u7136\u80fd\u4fdd\u6301\u6027\u80fd\u4f46\u4f1a\u56e0\u4e0d\u5b8c\u7f8e\u56de\u653e\u800c\u6f02\u79fb\u3002\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4fe1\u4efb\u533a\u57df\u6301\u7eed\u5b66\u4e60\uff0c\u7ed3\u5408\u751f\u6210\u56de\u653e\u548cFisher\u5ea6\u91cf\u4fe1\u4efb\u533a\u57df\u7ea6\u675f\u3002\u5728\u5c40\u90e8\u8fd1\u4f3c\u4e0b\uff0c\u8be5\u66f4\u65b0\u5177\u6709MAML\u98ce\u683c\u89e3\u91ca\uff1a\u56de\u653e\u63d0\u4f9b\u65e7\u4efb\u52a1\u68af\u5ea6\u4fe1\u53f7\uff08\u7c7b\u4f3c\u67e5\u8be2\uff09\uff0cFisher\u52a0\u6743\u60e9\u7f5a\u63d0\u4f9b\u9ad8\u6548\u79bb\u7ebf\u66f2\u7387\u5851\u9020\uff08\u7c7b\u4f3c\u652f\u6301\uff09\u3002", "result": "\u5728\u4efb\u52a1\u589e\u91cf\u6269\u6563\u56fe\u50cf\u751f\u6210\u548c\u6301\u7eed\u6269\u6563\u7b56\u7565\u63a7\u5236\u4efb\u52a1\u4e0a\uff0c\u4fe1\u4efb\u533a\u57df\u6301\u7eed\u5b66\u4e60\u5b9e\u73b0\u4e86\u6700\u4f73\u6700\u7ec8\u6027\u80fd\u548c\u4fdd\u7559\u7387\uff0c\u5e76\u4e14\u6bd4EWC\u3001\u56de\u653e\u548c\u6301\u7eed\u5143\u5b66\u4e60\u57fa\u7ebf\u66f4\u5feb\u6062\u590d\u65e9\u671f\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u6d8c\u73b0\u7684\u5143\u5b66\u4e60\u7279\u6027\uff1a\u6a21\u578b\u6210\u4e3a\u521d\u59cb\u5316\uff0c\u5728\u6bcf\u6b21\u4efb\u52a1\u8f6c\u6362\u540e\u80fd\u5feb\u901f\u91cd\u65b0\u6536\u655b\u5230\u5148\u524d\u4efb\u52a1\u6700\u4f18\u89e3\uff0c\u800c\u65e0\u9700\u663e\u5f0f\u4f18\u5316\u53cc\u5c42\u76ee\u6807\u3002"}}
{"id": "2602.02422", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02422", "abs": "https://arxiv.org/abs/2602.02422", "authors": ["Sayak Chakrabarti", "Toniann Pitassi", "Josh Alman"], "title": "Poly-attention: a general scheme for higher-order self-attention", "comment": null, "summary": "The self-attention mechanism, at the heart of the Transformer model, is able to effectively model pairwise interactions between tokens. However, numerous recent works have shown that it is unable to perform basic tasks involving detecting triples of correlated tokens, or compositional tasks where multiple input tokens need to be referenced to generate a result. Some higher-dimensional alternatives to self-attention have been proposed to address this, including higher-order attention and Strassen attention, which can perform some of these polyadic tasks in exchange for slower, superquadratic running times.\n  In this work, we define a vast class of generalizations of self-attention, which we call poly-attention mechanisms. Our mechanisms can incorporate arbitrary higher-order (tensor) computations as well as arbitrary relationship structures between the input tokens, and they include the aforementioned alternatives as special cases. We then systematically study their computational complexity and representational strength, including giving new algorithms and matching complexity-theoretic lower bounds on the time complexity of computing the attention matrix exactly as well as approximately, and tightly determining which polyadic tasks they can each perform. Our results give interesting trade-offs between different desiderata for these mechanisms, including a tight relationship between how expressive a mechanism is, and how large the coefficients in the model may be so that the mechanism can be approximated in almost-linear time.\n  Notably, we give a new attention mechanism which can be computed exactly in quadratic time, and which can perform function composition for any fixed number of functions. Prior mechanisms, even for just composing two functions, could only be computed in superquadratic time, and our new lower bounds show that faster algorithms for them are not possible.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7c7b\u79f0\u4e3a\"\u591a\u6ce8\u610f\u529b\u673a\u5236\"\u7684\u81ea\u6ce8\u610f\u529b\u6cdb\u5316\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u9ad8\u9636\u5f20\u91cf\u8ba1\u7b97\u548c\u8f93\u5165\u6807\u8bb0\u95f4\u7684\u590d\u6742\u5173\u7cfb\u7ed3\u6784\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u4e8c\u6b21\u65f6\u95f4\u53ef\u8ba1\u7b97\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002", "motivation": "\u4f20\u7edf\u81ea\u6ce8\u610f\u529b\u673a\u5236\u867d\u7136\u80fd\u6709\u6548\u5efa\u6a21\u6807\u8bb0\u95f4\u7684\u6210\u5bf9\u4ea4\u4e92\uff0c\u4f46\u65e0\u6cd5\u5904\u7406\u6d89\u53ca\u4e09\u4e2a\u76f8\u5173\u6807\u8bb0\u7684\u57fa\u672c\u4efb\u52a1\u6216\u9700\u8981\u5f15\u7528\u591a\u4e2a\u8f93\u5165\u6807\u8bb0\u7684\u7ec4\u5408\u4efb\u52a1\u3002\u73b0\u6709\u9ad8\u9636\u6ce8\u610f\u529b\u66ff\u4ee3\u65b9\u6848\u867d\u7136\u80fd\u5904\u7406\u67d0\u4e9b\u591a\u5143\u4efb\u52a1\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff08\u8d85\u4e8c\u6b21\u65f6\u95f4\uff09\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u7c7b\u5e7f\u6cdb\u7684\u81ea\u6ce8\u610f\u529b\u6cdb\u5316\u6a21\u578b\u2014\u2014\u591a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u80fd\u591f\u6574\u5408\u4efb\u610f\u9ad8\u9636\u5f20\u91cf\u8ba1\u7b97\u548c\u4efb\u610f\u8f93\u5165\u6807\u8bb0\u5173\u7cfb\u7ed3\u6784\u3002\u7cfb\u7edf\u7814\u7a76\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u8868\u8fbe\u80fd\u529b\uff0c\u5305\u62ec\u7ed9\u51fa\u65b0\u7b97\u6cd5\u548c\u5339\u914d\u7684\u590d\u6742\u5ea6\u4e0b\u754c\uff0c\u5e76\u786e\u5b9a\u5404\u673a\u5236\u80fd\u6267\u884c\u7684\u591a\u5143\u4efb\u52a1\u3002", "result": "\u63d0\u51fa\u4e86\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u5728\u4e8c\u6b21\u65f6\u95f4\u5185\u7cbe\u786e\u8ba1\u7b97\uff0c\u5e76\u80fd\u6267\u884c\u4efb\u610f\u56fa\u5b9a\u6570\u91cf\u51fd\u6570\u7684\u51fd\u6570\u7ec4\u5408\u3002\u8bc1\u660e\u4e86\u5148\u524d\u673a\u5236\uff08\u5373\u4f7f\u4ec5\u7ec4\u5408\u4e24\u4e2a\u51fd\u6570\uff09\u53ea\u80fd\u5728\u8d85\u4e8c\u6b21\u65f6\u95f4\u5185\u8ba1\u7b97\uff0c\u4e14\u66f4\u5feb\u7684\u7b97\u6cd5\u4e0d\u53ef\u80fd\u5b58\u5728\u3002\u63ed\u793a\u4e86\u673a\u5236\u8868\u8fbe\u80fd\u529b\u4e0e\u6a21\u578b\u7cfb\u6570\u5927\u5c0f\u4e4b\u95f4\u7684\u7d27\u5bc6\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u591a\u6ce8\u610f\u529b\u673a\u5236\u4e3a\u81ea\u6ce8\u610f\u529b\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u6846\u67b6\uff0c\u5728\u8868\u8fbe\u80fd\u529b\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u5efa\u7acb\u4e86\u7cbe\u786e\u7684\u6743\u8861\u5173\u7cfb\u3002\u65b0\u63d0\u51fa\u7684\u673a\u5236\u5728\u4fdd\u6301\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u51fd\u6570\u7ec4\u5408\u80fd\u529b\uff0c\u4e3aTransformer\u6a21\u578b\u7684\u80fd\u529b\u6269\u5c55\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.02425", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.02425", "abs": "https://arxiv.org/abs/2602.02425", "authors": ["Amaru Caceres Arroyo", "Lea Bogensperger", "Ahmed Allam", "Michael Krauthammer", "Konrad Schindler", "Dominik Narnhofer"], "title": "Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization", "comment": null, "summary": "Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.", "AI": {"tldr": "CHASE\uff1a\u5229\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u5316\u77e5\u8bc6\uff0c\u901a\u8fc7\u538b\u7f29\u5d4c\u5165\u5230\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\uff0c\u7ed3\u5408\u6761\u4ef6\u6d41\u5339\u914d\u548c\u5206\u7c7b\u5668\u65e0\u6307\u5bfc\uff0c\u76f4\u63a5\u751f\u6210\u9ad8\u9002\u5e94\u6027\u86cb\u767d\u8d28\u53d8\u4f53\uff0c\u65e0\u9700\u9884\u6d4b\u5668\u6307\u5bfc\u7684ODE\u91c7\u6837\u6b65\u9aa4\u3002", "motivation": "\u86cb\u767d\u8d28\u9002\u5e94\u6027\u4f18\u5316\u9762\u4e34\u5de8\u5927\u7ec4\u5408\u7a7a\u95f4\u6311\u6218\uff0c\u9ad8\u9002\u5e94\u6027\u53d8\u4f53\u6781\u5176\u7a00\u758f\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u6027\u80fd\u4e0d\u8db3\uff0c\u8981\u4e48\u9700\u8981\u8ba1\u7b97\u6602\u8d35\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u91c7\u6837\u3002", "method": "CHASE\u6846\u67b6\u91cd\u65b0\u5229\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u5316\u77e5\u8bc6\uff0c\u5c06\u5176\u5d4c\u5165\u538b\u7f29\u5230\u7d27\u51d1\u6f5c\u5728\u7a7a\u95f4\u3002\u901a\u8fc7\u8bad\u7ec3\u5e26\u6709\u5206\u7c7b\u5668\u65e0\u6307\u5bfc\u7684\u6761\u4ef6\u6d41\u5339\u914d\u6a21\u578b\uff0c\u5728ODE\u91c7\u6837\u6b65\u9aa4\u4e2d\u65e0\u9700\u9884\u6d4b\u5668\u6307\u5bfc\u5373\u53ef\u76f4\u63a5\u751f\u6210\u9ad8\u9002\u5e94\u6027\u53d8\u4f53\u3002", "result": "CHASE\u5728AAV\u548cGFP\u86cb\u767d\u8d28\u8bbe\u8ba1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5728\u6570\u636e\u53d7\u9650\u8bbe\u7f6e\u4e2d\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u5f15\u5bfc\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "CHASE\u901a\u8fc7\u6709\u6548\u5229\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u5316\u77e5\u8bc6\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9ad8\u6027\u80fd\u7684\u86cb\u767d\u8d28\u9002\u5e94\u6027\u4f18\u5316\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2602.02427", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02427", "abs": "https://arxiv.org/abs/2602.02427", "authors": ["Qihao Wen", "Jiahao Wang", "Yang Nan", "Pengfei He", "Ravi Tandon", "Han Xu"], "title": "Embedding Perturbation may Better Reflect the Uncertainty in LLM Reasoning", "comment": null, "summary": "Large language Models (LLMs) have achieved significant breakthroughs across diverse domains; however, they can still produce unreliable or misleading outputs. For responsible LLM application, Uncertainty Quantification (UQ) techniques are used to estimate a model's uncertainty about its outputs, indicating the likelihood that those outputs may be problematic. For LLM reasoning tasks, it is essential to estimate the uncertainty not only for the final answer, but also for the intermediate steps of the reasoning, as this can enable more fine-grained and targeted interventions. In this study, we explore what UQ metrics better reflect the LLM's ``intermediate uncertainty''during reasoning. Our study reveals that an LLMs' incorrect reasoning steps tend to contain tokens which are highly sensitive to the perturbations on the preceding token embeddings. In this way, incorrect (uncertain) intermediate steps can be readily identified using this sensitivity score as guidance in practice. In our experiments, we show such perturbation-based metric achieves stronger uncertainty quantification performance compared with baseline methods such as token (generation) probability and token entropy. Besides, different from approaches that rely on multiple sampling, the perturbation-based metrics offer better simplicity and efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6270\u52a8\u654f\u611f\u6027\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4e2d\u95f4\u6b65\u9aa4\u9519\u8bef\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6548\u679c\u66f4\u597d\u4e14\u66f4\u9ad8\u6548\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u53d6\u5f97\u7a81\u7834\uff0c\u4f46\u4ecd\u4f1a\u4ea7\u751f\u4e0d\u53ef\u9760\u8f93\u51fa\u3002\u5bf9\u4e8e\u63a8\u7406\u4efb\u52a1\uff0c\u4e0d\u4ec5\u9700\u8981\u91cf\u5316\u6700\u7ec8\u7b54\u6848\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd8\u9700\u8981\u91cf\u5316\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u4fbf\u8fdb\u884c\u66f4\u7cbe\u7ec6\u7684\u5e72\u9884\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6270\u52a8\u654f\u611f\u6027\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6307\u6807\uff1a\u901a\u8fc7\u6270\u52a8\u524d\u4e00\u4e2atoken\u7684\u5d4c\u5165\u5411\u91cf\uff0c\u89c2\u5bdf\u540e\u7eedtoken\u7684\u654f\u611f\u6027\u53d8\u5316\u3002\u9519\u8bef\u7684\u63a8\u7406\u6b65\u9aa4\u4e2d\u7684token\u5bf9\u524d\u5e8ftoken\u5d4c\u5165\u7684\u6270\u52a8\u66f4\u52a0\u654f\u611f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u6270\u52a8\u7684\u6307\u6807\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff08\u5982token\u751f\u6210\u6982\u7387\u548ctoken\u71b5\uff09\u3002\u8be5\u65b9\u6cd5\u76f8\u6bd4\u9700\u8981\u591a\u6b21\u91c7\u6837\u7684\u65b9\u6cd5\u66f4\u7b80\u5355\u9ad8\u6548\u3002", "conclusion": "\u6270\u52a8\u654f\u611f\u6027\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u4e2d\u95f4\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6307\u6807\uff0c\u80fd\u591f\u53ef\u9760\u8bc6\u522b\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u6b65\u9aa4\uff0c\u4e3a\u66f4\u7cbe\u7ec6\u7684\u5e72\u9884\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2602.02432", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.02432", "abs": "https://arxiv.org/abs/2602.02432", "authors": ["Jack M. Buckingham", "Ivo Couckuyt", "Juergen Branke"], "title": "Maximizing Reliability with Bayesian Optimization", "comment": "25 pages, 9 figures", "summary": "Bayesian optimization (BO) is a popular, sample-efficient technique for expensive, black-box optimization. One such problem arising in manufacturing is that of maximizing the reliability, or equivalently minimizing the probability of a failure, of a design which is subject to random perturbations - a problem that can involve extremely rare failures ($P_\\mathrm{fail} = 10^{-6}-10^{-8}$). In this work, we propose two BO methods based on Thompson sampling and knowledge gradient, the latter approximating the one-step Bayes-optimal policy for minimizing the logarithm of the failure probability. Both methods incorporate importance sampling to target extremely small failure probabilities. Empirical results show the proposed methods outperform existing methods in both extreme and non-extreme regimes.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8eThompson\u91c7\u6837\u548c\u77e5\u8bc6\u68af\u5ea6\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u6781\u5c0f\u5931\u6548\u6982\u7387\uff0810^-6-10^-8\uff09\u7684\u53ef\u9760\u6027\u4f18\u5316\u95ee\u9898\uff0c\u7ed3\u5408\u91cd\u8981\u6027\u91c7\u6837\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u5728\u5236\u9020\u4e1a\u4e2d\uff0c\u9700\u8981\u4f18\u5316\u8bbe\u8ba1\u7684\u53ef\u9760\u6027\uff08\u6700\u5c0f\u5316\u5931\u6548\u6982\u7387\uff09\uff0c\u4f46\u5931\u6548\u6982\u7387\u6781\u4f4e\uff0810^-6-10^-8\uff09\uff0c\u4f20\u7edf\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u8fd9\u79cd\u6781\u7aef\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8eThompson\u91c7\u6837\u7684\u65b9\u6cd5\uff1b2\uff09\u57fa\u4e8e\u77e5\u8bc6\u68af\u5ea6\u7684\u65b9\u6cd5\uff0c\u540e\u8005\u8fd1\u4f3c\u6700\u5c0f\u5316\u5931\u6548\u6982\u7387\u5bf9\u6570\u7684\u4e00\u6b65\u8d1d\u53f6\u65af\u6700\u4f18\u7b56\u7565\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u7ed3\u5408\u4e86\u91cd\u8981\u6027\u91c7\u6837\u6765\u5904\u7406\u6781\u5c0f\u5931\u6548\u6982\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6781\u7aef\u548c\u975e\u6781\u7aef\u5931\u6548\u6982\u7387\u60c5\u51b5\u4e0b\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ed3\u5408\u91cd\u8981\u6027\u91c7\u6837\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u6781\u5c0f\u5931\u6548\u6982\u7387\u7684\u53ef\u9760\u6027\u4f18\u5316\u95ee\u9898\uff0c\u5728\u6781\u7aef\u548c\u975e\u6781\u7aef\u60c5\u51b5\u4e0b\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.02443", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02443", "abs": "https://arxiv.org/abs/2602.02443", "authors": ["Yuanteng Chen", "Peisong Wang", "Nanxin Zeng", "Yuantian Shao", "Gang Li", "Jing Liu", "Jian Cheng"], "title": "Certain Head, Uncertain Tail: Expert-Sample for Test-Time Scaling in Fine-Grained MoE", "comment": "24 pages, 13 figures", "summary": "Test-time scaling improves LLM performance by generating multiple candidate solutions, yet token-level sampling requires temperature tuning that trades off diversity against stability. Fine-grained MoE, featuring hundreds of well-trained experts per layer and multi-expert activation per token, offers an unexplored alternative through its rich routing space. We empirically characterize fine-grained MoE routing and uncover an informative pattern: router scores exhibit a certain head of high-confidence experts followed by an uncertain tail of low-confidence candidates. While single-run greedy accuracy remains stable when fewer experts are activated, multi-sample pass@n degrades significantly-suggesting that the certain head governs core reasoning capability while the uncertain tail correlates with reasoning diversity. Motivated by these findings, we propose Expert-Sample, a training-free method that preserves high-confidence selections while injecting controlled stochasticity into the uncertain tail, enabling diverse generation without destabilizing outputs. Evaluated on multiple fine-grained MoE models across math, knowledge reasoning, and code tasks, Expert-Sample consistently improves pass@n and verification-based accuracy. On Qwen3-30B-A3B-Instruct evaluated on GPQA-Diamond with 32 parallel samples, pass@32 rises from 85.4% to 91.9%, and accuracy improves from 59.1% to 62.6% with Best-of-N verification.", "AI": {"tldr": "Expert-Sample\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u9ad8\u7f6e\u4fe1\u5ea6\u4e13\u5bb6\u9009\u62e9\u57fa\u7840\u4e0a\u5bf9\u4e0d\u786e\u5b9a\u5c3e\u90e8\u6ce8\u5165\u53ef\u63a7\u968f\u673a\u6027\uff0c\u63d0\u5347\u7ec6\u7c92\u5ea6MoE\u6a21\u578b\u7684\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u9700\u8981\u6e29\u5ea6\u8c03\u4f18\u6765\u5e73\u8861\u591a\u6837\u6027\u4e0e\u7a33\u5b9a\u6027\uff0c\u800c\u7ec6\u7c92\u5ea6MoE\u7684\u4e30\u5bcc\u8def\u7531\u7a7a\u95f4\u63d0\u4f9b\u4e86\u672a\u63a2\u7d22\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7814\u7a76\u53d1\u73b0MoE\u8def\u7531\u6a21\u5f0f\u663e\u793a\u9ad8\u7f6e\u4fe1\u5ea6\u4e13\u5bb6\u5934\u90e8\u548c\u4f4e\u7f6e\u4fe1\u5ea6\u5019\u9009\u5c3e\u90e8\uff0c\u524d\u8005\u51b3\u5b9a\u6838\u5fc3\u63a8\u7406\u80fd\u529b\uff0c\u540e\u8005\u4e0e\u63a8\u7406\u591a\u6837\u6027\u76f8\u5173\u3002", "method": "\u63d0\u51faExpert-Sample\u65b9\u6cd5\uff1a\u4fdd\u7559\u9ad8\u7f6e\u4fe1\u5ea6\u4e13\u5bb6\u9009\u62e9\uff0c\u540c\u65f6\u5bf9\u4e0d\u786e\u5b9a\u5c3e\u90e8\u6ce8\u5165\u53ef\u63a7\u968f\u673a\u6027\uff0c\u5b9e\u73b0\u591a\u6837\u751f\u6210\u800c\u4e0d\u7834\u574f\u8f93\u51fa\u7a33\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u5229\u7528MoE\u8def\u7531\u7684\u7f6e\u4fe1\u5ea6\u6a21\u5f0f\u3002", "result": "\u5728\u591a\u4e2a\u7ec6\u7c92\u5ea6MoE\u6a21\u578b\u4e0a\u8bc4\u4f30\u6570\u5b66\u3001\u77e5\u8bc6\u63a8\u7406\u548c\u4ee3\u7801\u4efb\u52a1\uff0cExpert-Sample\u6301\u7eed\u63d0\u5347pass@n\u548c\u57fa\u4e8e\u9a8c\u8bc1\u7684\u51c6\u786e\u7387\u3002\u5728Qwen3-30B-A3B-Instruct\u6a21\u578b\u4e0a\uff0cGPQA-Diamond\u4efb\u52a1\u7684pass@32\u4ece85.4%\u63d0\u5347\u523091.9%\uff0cBest-of-N\u9a8c\u8bc1\u51c6\u786e\u7387\u4ece59.1%\u63d0\u5347\u523062.6%\u3002", "conclusion": "\u7ec6\u7c92\u5ea6MoE\u8def\u7531\u6a21\u5f0f\u63ed\u793a\u4e86\u7f6e\u4fe1\u5ea6\u7ed3\u6784\uff0cExpert-Sample\u65b9\u6cd5\u6709\u6548\u5229\u7528\u8fd9\u4e00\u6a21\u5f0f\u5b9e\u73b0\u591a\u6837\u4e14\u7a33\u5b9a\u7684\u751f\u6210\uff0c\u4e3aMoE\u6a21\u578b\u6d4b\u8bd5\u65f6\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.02445", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.02445", "abs": "https://arxiv.org/abs/2602.02445", "authors": ["Seo Taek Kong", "R. Srikant"], "title": "Finite-Sample Wasserstein Error Bounds and Concentration Inequalities for Nonlinear Stochastic Approximation", "comment": null, "summary": "This paper derives non-asymptotic error bounds for nonlinear stochastic approximation algorithms in the Wasserstein-$p$ distance. To obtain explicit finite-sample guarantees for the last iterate, we develop a coupling argument that compares the discrete-time process to a limiting Ornstein-Uhlenbeck process. Our analysis applies to algorithms driven by general noise conditions, including martingale differences and functions of ergodic Markov chains. Complementing this result, we handle the convergence rate of the Polyak-Ruppert average through a direct analysis that applies under the same general setting.\n  Assuming the driving noise satisfies a non-asymptotic central limit theorem, we show that the normalized last iterates converge to a Gaussian distribution in the $p$-Wasserstein distance at a rate of order $\u03b3_n^{1/6}$, where $\u03b3_n$ is the step size. Similarly, the Polyak-Ruppert average is shown to converge in the Wasserstein distance at a rate of order $n^{-1/6}$. These distributional guarantees imply high-probability concentration inequalities that improve upon those derived from moment bounds and Markov's inequality. We demonstrate the utility of this approach by considering two applications: (1) linear stochastic approximation, where we explicitly quantify the transition from heavy-tailed to Gaussian behavior of the iterates, thereby bridging the gap between recent finite-sample analyses and asymptotic theory and (2) stochastic gradient descent, where we establish rate of convergence to the central limit theorem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u975e\u7ebf\u6027\u968f\u673a\u903c\u8fd1\u7b97\u6cd5\u5728Wasserstein-p\u8ddd\u79bb\u4e0b\u63a8\u5bfc\u4e86\u975e\u6e10\u8fd1\u8bef\u5dee\u754c\uff0c\u5206\u6790\u4e86\u6700\u540e\u8fed\u4ee3\u548cPolyak-Ruppert\u5e73\u5747\u7684\u6536\u655b\u901f\u7387\uff0c\u5e76\u5e94\u7528\u4e8e\u7ebf\u6027\u968f\u673a\u903c\u8fd1\u548c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u3002", "motivation": "\u73b0\u6709\u968f\u673a\u903c\u8fd1\u7b97\u6cd5\u5206\u6790\u591a\u4e3a\u6e10\u8fd1\u7ed3\u679c\u6216\u57fa\u4e8e\u77e9\u754c\u548c\u9a6c\u5c14\u53ef\u592b\u4e0d\u7b49\u5f0f\u7684\u9ad8\u6982\u7387\u754c\uff0c\u7f3a\u4e4f\u975e\u6e10\u8fd1\u7684\u6709\u9650\u6837\u672c\u4fdd\u8bc1\u3002\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u4e3a\u6700\u540e\u8fed\u4ee3\u63d0\u4f9b\u663e\u5f0f\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u5e76\u7edf\u4e00\u5904\u7406\u4e0d\u540c\u566a\u58f0\u6761\u4ef6\u3002", "method": "\u5f00\u53d1\u8026\u5408\u8bba\u8bc1\u65b9\u6cd5\uff0c\u5c06\u79bb\u6563\u65f6\u95f4\u8fc7\u7a0b\u4e0e\u6781\u9650Ornstein-Uhlenbeck\u8fc7\u7a0b\u6bd4\u8f83\uff1b\u5728\u975e\u6e10\u8fd1\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\u5047\u8bbe\u4e0b\uff0c\u5206\u6790\u6700\u540e\u8fed\u4ee3\u548cPolyak-Ruppert\u5e73\u5747\u7684\u6536\u655b\u901f\u7387\uff1b\u5e94\u7528\u5305\u62ec\u7ebf\u6027\u968f\u673a\u903c\u8fd1\u548c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u3002", "result": "\u8bc1\u660e\u5f52\u4e00\u5316\u6700\u540e\u8fed\u4ee3\u4ee5\u03b3_n^{1/6}\u901f\u7387\u5728p-Wasserstein\u8ddd\u79bb\u4e0b\u6536\u655b\u5230\u9ad8\u65af\u5206\u5e03\uff1bPolyak-Ruppert\u5e73\u5747\u4ee5n^{-1/6}\u901f\u7387\u6536\u655b\uff1b\u83b7\u5f97\u7684\u9ad8\u6982\u7387\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u4f18\u4e8e\u57fa\u4e8e\u77e9\u754c\u548c\u9a6c\u5c14\u53ef\u592b\u4e0d\u7b49\u5f0f\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u975e\u7ebf\u6027\u968f\u673a\u903c\u8fd1\u7b97\u6cd5\u63d0\u4f9b\u4e86\u975e\u6e10\u8fd1\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u7edf\u4e00\u5904\u7406\u4e86\u5305\u62ec\u9785\u5dee\u548c\u904d\u5386\u9a6c\u5c14\u53ef\u592b\u94fe\u51fd\u6570\u5728\u5185\u7684\u5e7f\u6cdb\u566a\u58f0\u6761\u4ef6\uff0c\u586b\u8865\u4e86\u6709\u9650\u6837\u672c\u5206\u6790\u4e0e\u6e10\u8fd1\u7406\u8bba\u4e4b\u95f4\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.02451", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02451", "abs": "https://arxiv.org/abs/2602.02451", "authors": ["Patrick Cooper", "Alvaro Velasquez"], "title": "Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization", "comment": "9 pages, 5 figures", "summary": "Discovering causal relationships requires controlled experiments, but experimentalists face a sequential decision problem: each intervention reveals information that should inform what to try next. Traditional approaches such as random sampling, greedy information maximization, and round-robin coverage treat each decision in isolation, unable to learn adaptive strategies from experience. We propose Active Causal Experimentalist (ACE), which learns experimental design as a sequential policy. Our key insight is that while absolute information gains diminish as knowledge accumulates (making value-based RL unstable), relative comparisons between candidate interventions remain meaningful throughout. ACE exploits this via Direct Preference Optimization, learning from pairwise intervention comparisons rather than non-stationary reward magnitudes. Across synthetic benchmarks, physics simulations, and economic data, ACE achieves 70-71% improvement over baselines at equal intervention budgets (p < 0.001, Cohen's d ~ 2). Notably, the learned policy autonomously discovers that collider mechanisms require concentrated interventions on parent variables, a theoretically-grounded strategy that emerges purely from experience. This suggests preference-based learning can recover principled experimental strategies, complementing theory with learned domain adaptation.", "AI": {"tldr": "ACE\u4f7f\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u5b66\u4e60\u56e0\u679c\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u5e8f\u5217\u7b56\u7565\uff0c\u901a\u8fc7\u5e72\u9884\u6bd4\u8f83\u800c\u975e\u5956\u52b1\u5e45\u5ea6\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u73b070-71%\u7684\u6027\u80fd\u63d0\u5347", "motivation": "\u4f20\u7edf\u56e0\u679c\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u6cd5\uff08\u968f\u673a\u91c7\u6837\u3001\u8d2a\u5a6a\u4fe1\u606f\u6700\u5927\u5316\u3001\u8f6e\u8be2\u8986\u76d6\uff09\u5c06\u6bcf\u4e2a\u51b3\u7b56\u89c6\u4e3a\u72ec\u7acb\uff0c\u65e0\u6cd5\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u81ea\u9002\u5e94\u7b56\u7565\uff0c\u5bfc\u81f4\u5b9e\u9a8c\u6548\u7387\u4f4e\u4e0b", "method": "\u63d0\u51faActive Causal Experimentalist (ACE)\uff0c\u5c06\u5b9e\u9a8c\u8bbe\u8ba1\u5efa\u6a21\u4e3a\u5e8f\u5217\u7b56\u7565\u5b66\u4e60\u95ee\u9898\u3002\u5173\u952e\u6d1e\u5bdf\uff1a\u867d\u7136\u7edd\u5bf9\u4fe1\u606f\u589e\u76ca\u968f\u77e5\u8bc6\u79ef\u7d2f\u800c\u51cf\u5c11\uff0c\u4f46\u5019\u9009\u5e72\u9884\u7684\u76f8\u5bf9\u6bd4\u8f83\u59cb\u7ec8\u6709\u610f\u4e49\u3002\u4f7f\u7528Direct Preference Optimization\u4ece\u6210\u5bf9\u5e72\u9884\u6bd4\u8f83\u4e2d\u5b66\u4e60\uff0c\u907f\u514d\u57fa\u4e8e\u975e\u5e73\u7a33\u5956\u52b1\u5e45\u5ea6\u7684\u5f3a\u5316\u5b66\u4e60\u4e0d\u7a33\u5b9a\u95ee\u9898", "result": "\u5728\u5408\u6210\u57fa\u51c6\u3001\u7269\u7406\u6a21\u62df\u548c\u7ecf\u6d4e\u6570\u636e\u4e0a\uff0cACE\u5728\u76f8\u540c\u5e72\u9884\u9884\u7b97\u4e0b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad870-71%\uff08p < 0.001\uff0cCohen's d ~ 2\uff09\u3002\u5b66\u4e60\u5230\u7684\u7b56\u7565\u81ea\u4e3b\u53d1\u73b0\u4e86\u5bf9\u7236\u53d8\u91cf\u8fdb\u884c\u96c6\u4e2d\u5e72\u9884\u7684\u78b0\u649e\u5668\u673a\u5236\u7b56\u7565", "conclusion": "\u57fa\u4e8e\u504f\u597d\u7684\u5b66\u4e60\u80fd\u591f\u6062\u590d\u539f\u5219\u6027\u5b9e\u9a8c\u7b56\u7565\uff0c\u901a\u8fc7\u7ecf\u9a8c\u5b66\u4e60\u8865\u5145\u7406\u8bba\uff0c\u5b9e\u73b0\u9886\u57df\u81ea\u9002\u5e94\u3002\u8fd9\u8868\u660e\u504f\u597d\u5b66\u4e60\u53ef\u4ee5\u6355\u6349\u5230\u7406\u8bba\u57fa\u7840\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u539f\u5219"}}
{"id": "2602.02458", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.02458", "abs": "https://arxiv.org/abs/2602.02458", "authors": ["Mingwei Hong", "Zheng Lin", "Zehang Lin", "Lin Li", "Miao Yang", "Xia Du", "Zihan Fang", "Zhaolu Kang", "Dianxin Luan", "Shunzhi Zhu"], "title": "Conflict-Aware Client Selection for Multi-Server Federated Learning", "comment": "6 pages, 4 figures", "summary": "Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.", "AI": {"tldr": "\u63d0\u51faRL-CRP\u6846\u67b6\uff0c\u4f7f\u7528\u53bb\u4e2d\u5fc3\u5316\u5f3a\u5316\u5b66\u4e60\u548c\u51b2\u7a81\u98ce\u9669\u9884\u6d4b\u6765\u4f18\u5316\u591a\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u51cf\u5c11\u670d\u52a1\u5668\u95f4\u51b2\u7a81\u5e76\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u5355\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u5b58\u5728\u9ad8\u901a\u4fe1\u5ef6\u8fdf\u95ee\u9898\uff0c\u800c\u591a\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u5206\u5e03\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f46\u5ba2\u6237\u7aef\u8986\u76d6\u91cd\u53e0\u548c\u9009\u62e9\u4e0d\u534f\u8c03\u4f1a\u5bfc\u81f4\u8d44\u6e90\u7ade\u4e89\u3001\u5e26\u5bbd\u51b2\u7a81\u548c\u8bad\u7ec3\u5931\u8d25\u3002", "method": "\u63d0\u51faRL-CRP\u6846\u67b6\uff1a1) \u6bcf\u4e2a\u670d\u52a1\u5668\u4f7f\u7528\u57fa\u4e8e\u7a00\u758f\u5386\u53f2\u5ba2\u6237\u7aef\u9009\u62e9\u5e8f\u5217\u7684\u5206\u7c7b\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u9884\u6d4b\u5ba2\u6237\u7aef\u9009\u62e9\u51b2\u7a81\u53ef\u80fd\u6027\uff1b2) \u7ed3\u5408\u516c\u5e73\u611f\u77e5\u5956\u52b1\u673a\u5236\u4fc3\u8fdb\u5ba2\u6237\u7aef\u957f\u671f\u53c2\u4e0e\uff0c\u6700\u5c0f\u5316\u8bad\u7ec3\u5ef6\u8fdf\u548c\u8d44\u6e90\u7ade\u4e89\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cRL-CRP\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u670d\u52a1\u5668\u95f4\u51b2\u7a81\uff0c\u5728\u6536\u655b\u901f\u5ea6\u548c\u901a\u4fe1\u6210\u672c\u65b9\u9762\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "conclusion": "RL-CRP\u901a\u8fc7\u51b2\u7a81\u98ce\u9669\u9884\u6d4b\u548c\u516c\u5e73\u611f\u77e5\u5956\u52b1\u673a\u5236\uff0c\u4f18\u5316\u4e86\u591a\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u8d44\u6e90\u7ade\u4e89\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2602.02472", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02472", "abs": "https://arxiv.org/abs/2602.02472", "authors": ["Qifan Yu", "Xinyu Ma", "Zhijian Zhuo", "Minrui Wang", "Deyi Liu", "Shiyi Zhan", "Yiyuan Ma", "Liang Xiang", "Xingyan Bin", "Di He"], "title": "SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning", "comment": null, "summary": "Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under $2\\times$ width expansion.", "AI": {"tldr": "SPARKLING\u63d0\u51fa\u4e86\u4e00\u79cd\u4e2d\u9636\u6bb5\u5bbd\u5ea6\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7RMS\u5c3a\u5ea6\u4e00\u81f4\u6027\u548c\u975e\u5bf9\u79f0\u4f18\u5316\u5668\u72b6\u6001\u91cd\u7f6e\uff0c\u89e3\u51b3\u4e86\u5bbd\u5ea6\u6269\u5c55\u4e2d\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u76f8\u6bd4\u4ece\u5934\u8bad\u7ec3\u8282\u770135%\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u6e10\u8fdb\u5b66\u4e60\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u6765\u51cf\u5c11\u9884\u8bad\u7ec3\u8ba1\u7b97\u5f00\u9500\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u6df1\u5ea6\u6269\u5c55\uff0c\u5bbd\u5ea6\u6269\u5c55\u7814\u7a76\u4e0d\u8db3\u3002\u4e2d\u9636\u6bb5\u5bbd\u5ea6\u6269\u5c55\u5bf9\u6700\u5927\u5316\u8ba1\u7b97\u8282\u7701\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u4e25\u91cd\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5982\u6fc0\u6d3b\u7edf\u8ba1\u7834\u574f\u548c\u68af\u5ea6\u5bf9\u79f0\u6027\u5bfc\u81f4\u7684\u7279\u5f81\u591a\u6837\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faSPARKLING\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u901a\u8fc7RMS\u5c3a\u5ea6\u4e00\u81f4\u6027\u5b9e\u73b0\u4fe1\u53f7\u4fdd\u7559\uff0c\u7a33\u5b9a\u6269\u5c55\u65f6\u7684\u6fc0\u6d3b\u7edf\u8ba1\uff1b2) \u901a\u8fc7\u975e\u5bf9\u79f0\u4f18\u5316\u5668\u72b6\u6001\u91cd\u7f6e\u548c\u5b66\u4e60\u7387\u91cd\u65b0\u9884\u70ed\u5b9e\u73b0\u5bf9\u79f0\u6027\u7834\u574f\uff0c\u786e\u4fdd\u7279\u5f81\u591a\u6837\u6027\u3002", "result": "\u5728\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSPARKLING\u5728\u591a\u79cd\u5bbd\u5ea6\u8f74\u548c\u4f18\u5316\u5668\u5bb6\u65cf\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\uff0c\u57282\u500d\u5bbd\u5ea6\u6269\u5c55\u4e0b\u51cf\u5c11\u9ad8\u8fbe35%\u7684\u8bad\u7ec3\u6210\u672c\u3002", "conclusion": "SPARKLING\u6210\u529f\u89e3\u51b3\u4e86\u4e2d\u9636\u6bb5\u5bbd\u5ea6\u6269\u5c55\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4e3a\u6e10\u8fdb\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5bbd\u5ea6\u6269\u5c55\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5927\u89c4\u6a21\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2602.02482", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02482", "abs": "https://arxiv.org/abs/2602.02482", "authors": ["Yuda Song", "Lili Chen", "Fahim Tajwar", "Remi Munos", "Deepak Pathak", "J. Andrew Bagnell", "Aarti Singh", "Andrea Zanette"], "title": "Expanding the Capabilities of Reinforcement Learning via Text Feedback", "comment": "43 pages, 6 figures", "summary": "The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete demonstrations. Textual feedback is a natural mode of human interaction and is already abundant in many real-world settings, where users, annotators, and automated judges routinely critique LLM outputs. Towards leveraging text feedback at scale, we formalize a multi-turn RL setup, RL from Text Feedback (RLTF), where text feedback is available during training but not at inference. Therefore, models must learn to internalize the feedback in order to improve their test-time single-turn performance. To do this, we propose two methods: Self Distillation (RLTF-SD), which trains the single-turn policy to match its own feedback-conditioned second-turn generations; and Feedback Modeling (RLTF-FM), which predicts the feedback as an auxiliary objective. We provide theoretical analysis on both methods, and empirically evaluate on reasoning puzzles, competition math, and creative writing tasks. Our results show that both methods consistently outperform strong baselines across benchmarks, highlighting the potential of RL with an additional source of rich supervision at scale.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faRLTF\u6846\u67b6\uff0c\u5229\u7528\u6587\u672c\u53cd\u9988\u4f5c\u4e3a\u6bd4\u4e8c\u5143\u5956\u52b1\u66f4\u4e30\u5bcc\u3001\u6bd4\u5b8c\u6574\u6f14\u793a\u66f4\u4fbf\u5b9c\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u901a\u8fc7\u4e24\u79cd\u65b9\u6cd5\uff08\u81ea\u84b8\u998f\u548c\u53cd\u9988\u5efa\u6a21\uff09\u8ba9\u6a21\u578b\u5185\u5316\u53cd\u9988\u4ee5\u63d0\u5347\u5355\u8f6e\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5f53\u524dRL\u7528\u4e8eLLM\u540e\u8bad\u7ec3\u5b58\u5728\u76d1\u7763\u4fe1\u53f7\u4e0d\u8db3\u7684\u95ee\u9898\uff1a\u4e8c\u5143\u5956\u52b1\u6216\u504f\u597d\u6807\u7b7e\u4fe1\u606f\u91cf\u592a\u5c11\uff0c\u800c\u84b8\u998f\u9700\u8981\u6602\u8d35\u7684\u5b8c\u6574\u6f14\u793a\u3002\u6587\u672c\u53cd\u9988\u4f5c\u4e3a\u4e2d\u95f4\u4fe1\u53f7\uff0c\u65e2\u6bd4\u6807\u91cf\u5956\u52b1\u66f4\u4e30\u5bcc\uff0c\u53c8\u6bd4\u6f14\u793a\u66f4\u4fbf\u5b9c\uff0c\u4e14\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5929\u7136\u5b58\u5728\u3002", "method": "\u63d0\u51faRLTF\u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u6587\u672c\u53cd\u9988\u4f46\u63a8\u7406\u65f6\u4e0d\u4f9d\u8d56\u3002\u5f00\u53d1\u4e24\u79cd\u65b9\u6cd5\uff1a1) RLTF-SD\uff08\u81ea\u84b8\u998f\uff09\uff1a\u8bad\u7ec3\u5355\u8f6e\u7b56\u7565\u5339\u914d\u5176\u81ea\u8eab\u53cd\u9988\u6761\u4ef6\u4e0b\u7684\u7b2c\u4e8c\u8f6e\u751f\u6210\uff1b2) RLTF-FM\uff08\u53cd\u9988\u5efa\u6a21\uff09\uff1a\u5c06\u9884\u6d4b\u53cd\u9988\u4f5c\u4e3a\u8f85\u52a9\u76ee\u6807\u3002", "result": "\u5728\u63a8\u7406\u8c1c\u9898\u3001\u7ade\u8d5b\u6570\u5b66\u548c\u521b\u610f\u5199\u4f5c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u5747\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86\u5229\u7528\u4e30\u5bcc\u6587\u672c\u53cd\u9988\u8fdb\u884cRL\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6587\u672c\u53cd\u9988\u4f5c\u4e3aRL\u7684\u76d1\u7763\u4fe1\u53f7\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0cRLTF\u6846\u67b6\u53ca\u5176\u4e24\u79cd\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528\u8fd9\u79cd\u4e2d\u95f4\u4fe1\u53f7\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u5229\u7528\u6587\u672c\u53cd\u9988\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.02488", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02488", "abs": "https://arxiv.org/abs/2602.02488", "authors": ["Yinjie Wang", "Tianbao Xie", "Ke Shen", "Mengdi Wang", "Ling Yang"], "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System", "comment": "Code: https://github.com/Gen-Verse/Open-AgentRL", "summary": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL", "AI": {"tldr": "RLAnything\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u95ed\u73af\u4f18\u5316\u52a8\u6001\u6784\u5efa\u73af\u5883\u3001\u7b56\u7565\u548c\u5956\u52b1\u6a21\u578b\uff0c\u589e\u5f3aLLM\u548c\u667a\u80fd\u4f53\u573a\u666f\u7684\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728LLM\u548c\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u9762\u4e34\u5b66\u4e60\u4fe1\u53f7\u4e0d\u8db3\u3001\u7cfb\u7edf\u6574\u4f53\u4f18\u5316\u4e0d\u591f\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u8c03\u6574\u73af\u5883\u3001\u7b56\u7565\u548c\u5956\u52b1\u6a21\u578b\u7684\u7efc\u5408\u6846\u67b6\u6765\u589e\u5f3a\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51fa\u95ed\u73af\u4f18\u5316\u6846\u67b6\uff0c\u7b56\u7565\u6a21\u578b\u901a\u8fc7\u6b65\u8fdb\u4fe1\u53f7\u548c\u7ed3\u679c\u4fe1\u53f7\u7684\u96c6\u6210\u53cd\u9988\u8fdb\u884c\u8bad\u7ec3\uff0c\u5956\u52b1\u6a21\u578b\u901a\u8fc7\u4e00\u81f4\u6027\u53cd\u9988\u8054\u5408\u4f18\u5316\uff0c\u5e76\u57fa\u4e8e\u7406\u8bba\u52a8\u673a\u81ea\u52a8\u8c03\u6574\u73af\u5883\uff0c\u5229\u7528\u6279\u8bc4\u53cd\u9988\u6539\u8fdb\u5956\u52b1\u548c\u7b56\u7565\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u6bcf\u4e2a\u7ec4\u4ef6\u90fd\u6301\u7eed\u6539\u8fdb\u6574\u4f53\u7cfb\u7edf\u6027\u80fd\uff0cRLAnything\u5728\u591a\u4e2a\u4ee3\u8868\u6027LLM\u548c\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1aQwen3-VL-8B-Thinking\u5728OSWorld\u4e0a\u63d0\u53479.1%\uff0cQwen2.5-7B-Instruct\u5728AlfWorld\u548cLiveBench\u4e0a\u5206\u522b\u63d0\u534718.7%\u548c11.9%\u3002\u4f18\u5316\u7684\u5956\u52b1\u6a21\u578b\u4fe1\u53f7\u4f18\u4e8e\u4f9d\u8d56\u4eba\u5de5\u6807\u7b7e\u7684\u7ed3\u679c\u3002", "conclusion": "RLAnything\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u548c\u8054\u5408\u4f18\u5316\u73af\u5883\u3001\u7b56\u7565\u548c\u5956\u52b1\u6a21\u578b\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\uff0c\u4e3aLLM\u548c\u667a\u80fd\u4f53\u573a\u666f\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b66\u4e60\u6846\u67b6\u3002"}}
{"id": "2602.02494", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.02494", "abs": "https://arxiv.org/abs/2602.02494", "authors": ["Dulhan Jayalath", "Oiwi Parker Jones"], "title": "MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training", "comment": "19 pages, 8 figures, 5 tables", "summary": "Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose MEG-XL, a model pre-trained with 2.5 minutes of MEG context per sample, 5-300x longer than prior work, and equivalent to 191k tokens, capturing extended neural context. Fine-tuning on the task of word decoding from brain data, MEG-XL matches supervised performance with a fraction of the data (e.g. 1hr vs 50hrs) and outperforms brain foundation models. We find that models pre-trained with longer contexts learn representations that transfer better to word decoding. Our results indicate that long-context pre-training helps exploit extended neural context that other methods unnecessarily discard. Code, model weights, and instructions are available at https://github.com/neural-processing-lab/MEG-XL .", "AI": {"tldr": "MEG-XL\uff1a\u901a\u8fc72.5\u5206\u949f\u957f\u4e0a\u4e0b\u6587\u9884\u8bad\u7ec3\u7684\u8111\u78c1\u56fe\u6a21\u578b\uff0c\u5728\u5355\u8bcd\u89e3\u7801\u4efb\u52a1\u4e2d\u4ec5\u9700\u5c11\u91cf\u6570\u636e\u5373\u53ef\u8fbe\u5230\u76d1\u7763\u5b66\u4e60\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u8111\u57fa\u7840\u6a21\u578b", "motivation": "\u4e34\u5e8a\u8111-\u6587\u672c\u63a5\u53e3\u9700\u8981\u4e3a\u762b\u75ea\u60a3\u8005\u8bbe\u8ba1\uff0c\u8fd9\u4e9b\u60a3\u8005\u65e0\u6cd5\u63d0\u4f9b\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u3002\u73b0\u6709\u9884\u8bad\u7ec3\u65b9\u6cd5\u901a\u5e38\u53ea\u4f7f\u7528\u51e0\u79d2\u4e0a\u4e0b\u6587\uff0c\u4f46\u81ea\u7136\u8bed\u97f3\u53ef\u80fd\u6301\u7eed\u6570\u5206\u949f\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u957f\u7684\u795e\u7ecf\u4e0a\u4e0b\u6587\u6765\u5b66\u4e60\u66f4\u597d\u7684\u7edf\u8ba1\u5148\u9a8c\u3002", "method": "\u63d0\u51faMEG-XL\u6a21\u578b\uff0c\u4f7f\u7528\u6bcf\u4e2a\u6837\u672c2.5\u5206\u949f\u7684MEG\u4e0a\u4e0b\u6587\u8fdb\u884c\u9884\u8bad\u7ec3\uff08\u6bd4\u5148\u524d\u5de5\u4f5c\u957f5-300\u500d\uff0c\u76f8\u5f53\u4e8e191k\u4e2a\u6807\u8bb0\uff09\uff0c\u6355\u83b7\u6269\u5c55\u7684\u795e\u7ecf\u4e0a\u4e0b\u6587\u3002\u7136\u540e\u5728\u8111\u6570\u636e\u7684\u5355\u8bcd\u89e3\u7801\u4efb\u52a1\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002", "result": "MEG-XL\u5728\u5355\u8bcd\u89e3\u7801\u4efb\u52a1\u4e2d\u4ec5\u9700\u5c11\u91cf\u6570\u636e\u5373\u53ef\u5339\u914d\u76d1\u7763\u5b66\u4e60\u6027\u80fd\uff08\u59821\u5c0f\u65f6vs 50\u5c0f\u65f6\uff09\uff0c\u5e76\u4f18\u4e8e\u8111\u57fa\u7840\u6a21\u578b\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u66f4\u957f\u4e0a\u4e0b\u6587\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u5b66\u4e60\u5230\u7684\u8868\u793a\u80fd\u66f4\u597d\u5730\u8fc1\u79fb\u5230\u5355\u8bcd\u89e3\u7801\u4efb\u52a1\u3002", "conclusion": "\u957f\u4e0a\u4e0b\u6587\u9884\u8bad\u7ec3\u6709\u52a9\u4e8e\u5229\u7528\u6269\u5c55\u7684\u795e\u7ecf\u4e0a\u4e0b\u6587\uff0c\u800c\u5176\u4ed6\u65b9\u6cd5\u4e0d\u5fc5\u8981\u5730\u4e22\u5f03\u4e86\u8fd9\u4e9b\u4fe1\u606f\u3002\u8fd9\u4e3a\u4e34\u5e8a\u8111-\u6587\u672c\u63a5\u53e3\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u6570\u636e\u5229\u7528\u65b9\u6cd5\u3002"}}
