{"id": "2510.05109", "categories": ["cs.DC", "cs.AI", "cs.CL", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.05109", "abs": "https://arxiv.org/abs/2510.05109", "authors": ["Yilong Li", "Shuai Zhang", "Yijing Zeng", "Hao Zhang", "Xinmiao Xiong", "Jingyu Liu", "Pan Hu", "Suman Banerjee"], "title": "Tiny but Mighty: A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices", "comment": null, "summary": "Large Multimodal Models (LMMs) are inherently modular, consisting of vision\nand audio encoders, projectors, and large language models. Yet, they are almost\nalways executed monolithically, which underutilizes the heterogeneous\naccelerators (NPUs, GPUs, DSPs) in modern SoCs and leads to high end-to-end\nlatency. In this paper, we present NANOMIND, a hardware--software co-design\ninference framework for Large Multimodal Models (LMMs) that breaks large models\ninto modular ``bricks'' (vision, language, audio, etc.) and maps each to its\nideal accelerator. The key insight is that large models can be broken into\nmodular components and scheduled to run on the most appropriate compute units.\nIt performs module-level dynamic offloading across accelerators on\nunified-memory SoCs. By combining customized hardware design, system-level\nscheduling, and optimized low-bit computation kernels, we demonstrate our\nframework with a compact, battery-powered device capable of running LMMs\nentirely on device. This prototype functions as a self-contained intelligent\nassistant that requires no network connectivity, while achieving higher\nthroughput and superior power efficiency under strict resource constraints. The\ndesign further bypasses CPU bottlenecks and reduces redundant memory usage\nthrough token-aware buffer management and module-level coordination. Our system\noutperforms existing implementations in resource efficiency, cutting energy\nconsumption by 42.3\\% and GPU memory usage by 11.2\\%. This enables a\nbattery-powered device to run LLaVA-OneVision with a camera for nearly half a\nday and LLaMA-3-8B for voice interactions up to almost 20.8 hours.", "AI": {"tldr": "NANOMIND\u662f\u4e00\u4e2a\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u5927\u6a21\u578b\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5927\u6a21\u578b\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u7ec4\u4ef6\u5e76\u5728\u5f02\u6784\u52a0\u901f\u5668\u4e0a\u52a8\u6001\u8c03\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6548\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u901a\u5e38\u4ee5\u6574\u4f53\u65b9\u5f0f\u8fd0\u884c\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u73b0\u4ee3SoC\u4e2d\u7684\u5f02\u6784\u52a0\u901f\u5668\uff08NPU\u3001GPU\u3001DSP\u7b49\uff09\uff0c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u4f4e\u80fd\u6548\u3002", "method": "\u5c06\u5927\u6a21\u578b\u5206\u89e3\u4e3a\u89c6\u89c9\u3001\u8bed\u8a00\u3001\u97f3\u9891\u7b49\u6a21\u5757\u5316\"\u7816\u5757\"\uff0c\u901a\u8fc7\u6a21\u5757\u7ea7\u52a8\u6001\u5378\u8f7d\u6280\u672f\u5c06\u5404\u7ec4\u4ef6\u6620\u5c04\u5230\u6700\u9002\u5408\u7684\u52a0\u901f\u5668\u4e0a\u8fd0\u884c\uff0c\u7ed3\u5408\u5b9a\u5236\u786c\u4ef6\u8bbe\u8ba1\u3001\u7cfb\u7edf\u7ea7\u8c03\u5ea6\u548c\u4f18\u5316\u7684\u4f4e\u6bd4\u7279\u8ba1\u7b97\u5185\u6838\u3002", "result": "\u7cfb\u7edf\u5728\u8d44\u6e90\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u5b9e\u73b0\uff0c\u80fd\u8017\u964d\u4f4e42.3%\uff0cGPU\u5185\u5b58\u4f7f\u7528\u51cf\u5c1111.2%\uff0c\u7535\u6c60\u4f9b\u7535\u8bbe\u5907\u53ef\u8fd0\u884cLLaVA-OneVision\u8fd1\u534a\u5929\uff0cLLaMA-3-8B\u8bed\u97f3\u4ea4\u4e92\u8fbe20.8\u5c0f\u65f6\u3002", "conclusion": "NANOMIND\u6846\u67b6\u901a\u8fc7\u6a21\u5757\u5316\u5206\u89e3\u548c\u5f02\u6784\u52a0\u901f\u5668\u8c03\u5ea6\uff0c\u5b9e\u73b0\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u9ad8\u6548\u8fd0\u884c\u5927\u6a21\u578b\uff0c\u4e3a\u8fb9\u7f18\u667a\u80fd\u8bbe\u5907\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05111", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.05111", "abs": "https://arxiv.org/abs/2510.05111", "authors": ["Ian McDougall", "Noah Scott", "Joon Huh", "Kirthevasan Kandasamy", "Karthikeyan Sankaralingam"], "title": "Agora: Bridging the GPU Cloud Resource-Price Disconnect", "comment": "15 pages, 6 figures", "summary": "The historic trend of Moore's Law, which predicted exponential growth in\ncomputational performance per dollar, has diverged for modern Graphics\nProcessing Units (GPUs). While Floating Point Operations per Second (FLOPs)\ncapabilities have continued to scale economically, memory bandwidth has not,\ncreating a significant price-performance disconnect. This paper argues that the\nprevailing time-based pricing models for cloud GPUs are economically\ninefficient for bandwidth-bound workloads. These models fail to account for the\nrising marginal cost of memory bandwidth, leading to market distortions and\nsuboptimal hardware allocation. To address this, we propose a novel\nfeature-based pricing framework that directly links cost to resource\nconsumption, including but not limited to memory bandwidth. We provide a robust\neconomic and algorithmic definition of this framework and introduce Agora, a\npractical and secure system architecture for its implementation. Our\nimplementation of Agora shows that a 50us sampling provides nearly perfect\npricing as what ideal sampling would provide - losing only 5\\% of revenue. 10us\nsampling is even better result in 2.4\\% loss. Modern telemetry systems can\nalready provide this rate of measurement, and our prototype implementation\nshows the system design for feature-based pricing is buildable. Our evaluation\nacross diverse GPU applications and hardware generations empirically validates\nthe effectiveness of our approach in creating a more transparent and efficient\nmarket for cloud GPU resources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u7684\u65b0\u578bGPU\u4e91\u5b9a\u4ef7\u6846\u67b6\uff0c\u76f4\u63a5\u6839\u636e\u5185\u5b58\u5e26\u5bbd\u7b49\u8d44\u6e90\u6d88\u8017\u6765\u5b9a\u4ef7\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u57fa\u4e8e\u65f6\u95f4\u5b9a\u4ef7\u6a21\u578b\u5bf9\u5e26\u5bbd\u53d7\u9650\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7ecf\u6d4e\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u6469\u5c14\u5b9a\u5f8b\u5728\u73b0\u4ee3GPU\u4e0a\u51fa\u73b0\u5206\u6b67\uff1a\u867d\u7136FLOPs\u6301\u7eed\u7ecf\u6d4e\u6269\u5c55\uff0c\u4f46\u5185\u5b58\u5e26\u5bbd\u672a\u80fd\u540c\u6b65\u589e\u957f\uff0c\u5bfc\u81f4\u4ef7\u683c\u6027\u80fd\u8131\u8282\u3002\u4f20\u7edf\u57fa\u4e8e\u65f6\u95f4\u7684\u4e91GPU\u5b9a\u4ef7\u6a21\u578b\u672a\u80fd\u8003\u8651\u5185\u5b58\u5e26\u5bbd\u7684\u8fb9\u9645\u6210\u672c\u4e0a\u5347\uff0c\u9020\u6210\u5e02\u573a\u626d\u66f2\u548c\u786c\u4ef6\u5206\u914d\u4f4e\u6548\u3002", "method": "\u63d0\u51fa\u4e86\u7279\u5f81\u5b9a\u4ef7\u6846\u67b6\uff0c\u5c06\u6210\u672c\u76f4\u63a5\u4e0e\u8d44\u6e90\u6d88\u8017\uff08\u5305\u62ec\u5185\u5b58\u5e26\u5bbd\uff09\u6302\u94a9\u3002\u8bbe\u8ba1\u4e86Agora\u7cfb\u7edf\u67b6\u6784\u6765\u5b9e\u73b0\u8be5\u6846\u67b6\uff0c\u901a\u8fc750\u5fae\u79d2\u621610\u5fae\u79d2\u7684\u91c7\u6837\u5468\u671f\u6765\u7cbe\u786e\u6d4b\u91cf\u8d44\u6e90\u4f7f\u7528\u3002", "result": "50\u5fae\u79d2\u91c7\u6837\u53ef\u5b9e\u73b0\u8fd1\u4e4e\u7406\u60f3\u7684\u5b9a\u4ef7\u6548\u679c\uff0c\u4ec5\u635f\u59315%\u6536\u5165\uff1b10\u5fae\u79d2\u91c7\u6837\u6548\u679c\u66f4\u597d\uff0c\u4ec5\u635f\u59312.4%\u6536\u5165\u3002\u73b0\u4ee3\u9065\u6d4b\u7cfb\u7edf\u5df2\u80fd\u63d0\u4f9b\u8fd9\u79cd\u6d4b\u91cf\u9891\u7387\uff0c\u539f\u578b\u5b9e\u73b0\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u7279\u5f81\u5b9a\u4ef7\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u540cGPU\u5e94\u7528\u548c\u786c\u4ef6\u4ee3\u9645\u4e0a\u521b\u5efa\u66f4\u900f\u660e\u9ad8\u6548\u7684\u4e91GPU\u8d44\u6e90\u5e02\u573a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5b9a\u4ef7\u6a21\u578b\u7684\u7ecf\u6d4e\u4f4e\u6548\u95ee\u9898\u3002"}}
{"id": "2510.05112", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.05112", "abs": "https://arxiv.org/abs/2510.05112", "authors": ["Lijuan Jiang", "Xingjian Qian", "Zhenxiang Ma", "Zan Zong", "Hengjie Li", "Chao Yang", "Jidong Zhai"], "title": "A Flexible Programmable Pipeline Parallelism Framework for Efficient DNN Training", "comment": null, "summary": "Pipeline parallelism is an essential distributed parallelism method.\nIncreasingly complex and diverse DNN models necessitate meticulously customized\npipeline schedules for performance. However, existing practices typically rely\non predefined schedules, each with strengths, but fail to adapt automatically\nto the emerging model architectures. Exploring novel high-efficiency schedules\nis daunting due to the enormous and varying schedule space. Besides, manually\nimplementing schedules can be challenging due to the onerous coding burdens and\nconstantly changing needs. Unfortunately, existing frameworks have limitations\nin automated schedule exploration and lack flexibility and controllability.\n  This paper presents FlexPipe, a programmable pipeline parallelism framework\nwith enhanced productivity, programmability, debuggability, and ease of tuning.\nFlexPipe has two main components: a succinct domain-specific language (DSL) and\nan automated scheduler. FlexPipe enables automated schedule exploration for\nvarious parallel scenarios within a broad spectrum of schedule types at a small\nsearch cost. Besides, users can swiftly develop and customize schedules using\nthe FlexPipe DSL, which embodies flexible controllability in the pipeline order\nof micro-batch computations over stages. It also provides convenient mechanisms\nto include new operations in schedules to meet changing demands. Our evaluation\nresults demonstrate that FlexPipe achieves up to 2.28X performance speedup\ncompared to the popular large-scale parallel framework Megtron-LM, and gains up\nto 1.49X performance speedup compared to the state-of-the-art automated\npipeline parallelism framework.", "AI": {"tldr": "FlexPipe\u662f\u4e00\u4e2a\u53ef\u7f16\u7a0b\u7684\u6d41\u6c34\u7ebf\u5e76\u884c\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u81ea\u52a8\u8c03\u5ea6\u5668\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6d41\u6c34\u7ebf\u8c03\u5ea6\u81ea\u52a8\u63a2\u7d22\u548c\u7075\u6d3b\u5b9a\u5236\u3002", "motivation": "\u73b0\u6709\u6d41\u6c34\u7ebf\u5e76\u884c\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u8c03\u5ea6\u7b56\u7565\uff0c\u65e0\u6cd5\u81ea\u52a8\u9002\u5e94\u65b0\u5174\u6a21\u578b\u67b6\u6784\uff0c\u4e14\u624b\u52a8\u5b9e\u73b0\u8c03\u5ea6\u9762\u4e34\u5de8\u5927\u7f16\u7801\u8d1f\u62c5\u548c\u4e0d\u65ad\u53d8\u5316\u7684\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86FlexPipe\u6846\u67b6\uff0c\u5305\u542b\u7b80\u6d01\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u81ea\u52a8\u8c03\u5ea6\u5668\uff0c\u652f\u6301\u5e7f\u6cdb\u7684\u8c03\u5ea6\u7c7b\u578b\u81ea\u52a8\u63a2\u7d22\u548c\u7528\u6237\u81ea\u5b9a\u4e49\u8c03\u5ea6\u3002", "result": "\u76f8\u6bd4\u4e3b\u6d41\u5927\u89c4\u6a21\u5e76\u884c\u6846\u67b6Megtron-LM\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe2.28\u500d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u6d41\u6c34\u7ebf\u5e76\u884c\u6846\u67b6\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe1.49\u500d\u3002", "conclusion": "FlexPipe\u5728\u751f\u4ea7\u529b\u3001\u53ef\u7f16\u7a0b\u6027\u3001\u53ef\u8c03\u8bd5\u6027\u548c\u8c03\u4f18\u4fbf\u5229\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u6d41\u6c34\u7ebf\u5e76\u884c\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05118", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.05118", "abs": "https://arxiv.org/abs/2510.05118", "authors": ["Cynthia Marcelino", "Noah Krennmair", "Thomas Pusztai", "Stefan Nastic"], "title": "Lumos: Performance Characterization of WebAssembly as a Serverless Runtime in the Edge-Cloud Continuum", "comment": null, "summary": "WebAssembly has emerged as a lightweight and portable runtime to execute\nserverless functions, particularly in heterogeneous and resource-constrained\nenvironments such as the Edge Cloud Continuum. However, the performance\nbenefits versus trade-offs remain insufficiently understood. This paper\npresents Lumos, a performance model and benchmarking tool for characterizing\nserverless runtimes. Lumos identifies workload, system, and environment-level\nperformance drivers in the Edge-Cloud Continuum. We benchmark state-of-the-art\ncontainers and the Wasm runtime in interpreted mode and with ahead-of-time\ncompilation. Our performance characterization shows that AoT-compiled Wasm\nimages are up to 30x smaller and decrease cold-start latency by up to 16%\ncompared to containers, while interpreted Wasm suffers up to 55x higher warm\nlatency and up to 10x I/O-serialization overhead.", "AI": {"tldr": "Lumos\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u65e0\u670d\u52a1\u5668\u8fd0\u884c\u65f6\u6027\u80fd\u7684\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u7279\u522b\u5173\u6ce8\u8fb9\u7f18\u4e91\u8fde\u7eed\u4f53\u4e2d\u7684WebAssembly\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0AoT\u7f16\u8bd1\u7684Wasm\u955c\u50cf\u6bd4\u5bb9\u5668\u5c0f30\u500d\uff0c\u51b7\u542f\u52a8\u5ef6\u8fdf\u964d\u4f4e16%\uff0c\u4f46\u89e3\u91ca\u578bWasm\u7684\u5ef6\u8fdf\u9ad855\u500d\u4e14I/O\u5e8f\u5217\u5316\u5f00\u9500\u592710\u500d\u3002", "motivation": "WebAssembly\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u53ef\u79fb\u690d\u8fd0\u884c\u65f6\u5728\u8fb9\u7f18\u4e91\u8fde\u7eed\u4f53\u4e2d\u6267\u884c\u65e0\u670d\u52a1\u5668\u51fd\u6570\uff0c\u4f46\u5176\u6027\u80fd\u4f18\u52bf\u4e0e\u6743\u8861\u5c1a\u672a\u5145\u5206\u7406\u89e3\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u6027\u80fd\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u5f00\u53d1Lumos\u6027\u80fd\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u8bc6\u522b\u5de5\u4f5c\u8d1f\u8f7d\u3001\u7cfb\u7edf\u548c\u73af\u5883\u7ea7\u6027\u80fd\u9a71\u52a8\u56e0\u7d20\uff0c\u5bf9\u6700\u5148\u8fdb\u7684\u5bb9\u5668\u548cWasm\u8fd0\u884c\u65f6\uff08\u89e3\u91ca\u6a21\u5f0f\u548cAoT\u7f16\u8bd1\u6a21\u5f0f\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "AoT\u7f16\u8bd1\u7684Wasm\u955c\u50cf\u6bd4\u5bb9\u5668\u5c0f30\u500d\uff0c\u51b7\u542f\u52a8\u5ef6\u8fdf\u964d\u4f4e16%\uff1b\u89e3\u91ca\u578bWasm\u7684\u5ef6\u8fdf\u9ad855\u500d\uff0cI/O\u5e8f\u5217\u5316\u5f00\u9500\u592710\u500d\u3002", "conclusion": "AoT\u7f16\u8bd1\u7684Wasm\u5728\u8fb9\u7f18\u4e91\u8fde\u7eed\u4f53\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u662f\u955c\u50cf\u5927\u5c0f\u548c\u51b7\u542f\u52a8\u6027\u80fd\uff0c\u4f46\u89e3\u91ca\u578bWasm\u6027\u80fd\u8f83\u5dee\uff0c\u9700\u8981\u6743\u8861\u9009\u62e9\u3002"}}
{"id": "2510.05245", "categories": ["cs.AR", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05245", "abs": "https://arxiv.org/abs/2510.05245", "authors": ["Yue Pan", "Zihan Xia", "Po-Kai Hsu", "Lanxiang Hu", "Hyungyo Kim", "Janak Sharda", "Minxuan Zhou", "Nam Sung Kim", "Shimeng Yu", "Tajana Rosing", "Mingu Kang"], "title": "Stratum: System-Hardware Co-Design with Tiered Monolithic 3D-Stackable DRAM for Efficient MoE Serving", "comment": null, "summary": "As Large Language Models (LLMs) continue to evolve, Mixture of Experts (MoE)\narchitecture has emerged as a prevailing design for achieving state-of-the-art\nperformance across a wide range of tasks. MoE models use sparse gating to\nactivate only a handful of expert sub-networks per input, achieving\nbillion-parameter capacity with inference costs akin to much smaller models.\nHowever, such models often pose challenges for hardware deployment due to the\nmassive data volume introduced by the MoE layers. To address the challenges of\nserving MoE models, we propose Stratum, a system-hardware co-design approach\nthat combines the novel memory technology Monolithic 3D-Stackable DRAM (Mono3D\nDRAM), near-memory processing (NMP), and GPU acceleration. The logic and Mono3D\nDRAM dies are connected through hybrid bonding, whereas the Mono3D DRAM stack\nand GPU are interconnected via silicon interposer. Mono3D DRAM offers higher\ninternal bandwidth than HBM thanks to the dense vertical interconnect pitch\nenabled by its monolithic structure, which supports implementations of\nhigher-performance near-memory processing. Furthermore, we tackle the latency\ndifferences introduced by aggressive vertical scaling of Mono3D DRAM along the\nz-dimension by constructing internal memory tiers and assigning data across\nlayers based on access likelihood, guided by topic-based expert usage\nprediction to boost NMP throughput. The Stratum system achieves up to 8.29x\nimprovement in decoding throughput and 7.66x better energy efficiency across\nvarious benchmarks compared to GPU baselines.", "AI": {"tldr": "Stratum\u662f\u4e00\u4e2a\u7cfb\u7edf-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u5355\u72473D\u5806\u53e0DRAM\u3001\u8fd1\u5185\u5b58\u5904\u7406\u548cGPU\u52a0\u901f\uff0c\u4e13\u95e8\u7528\u4e8e\u4f18\u5316MoE\u6a21\u578b\u7684\u90e8\u7f72\u6027\u80fd\u3002", "motivation": "MoE\u6a21\u578b\u867d\u7136\u5177\u6709\u6570\u5341\u4ebf\u53c2\u6570\u5bb9\u91cf\u4e14\u63a8\u7406\u6210\u672c\u8f83\u4f4e\uff0c\u4f46\u7531\u4e8eMoE\u5c42\u5f15\u5165\u7684\u5927\u91cf\u6570\u636e\u91cf\uff0c\u5728\u786c\u4ef6\u90e8\u7f72\u4e0a\u5b58\u5728\u6311\u6218\u3002", "method": "\u91c7\u7528\u5355\u72473D\u5806\u53e0DRAM\u6280\u672f\uff0c\u901a\u8fc7\u6df7\u5408\u952e\u5408\u8fde\u63a5\u903b\u8f91\u548cDRAM\u82af\u7247\uff0c\u5229\u7528\u7845\u4e2d\u4ecb\u5c42\u8fde\u63a5DRAM\u5806\u6808\u548cGPU\u3002\u901a\u8fc7\u6784\u5efa\u5185\u90e8\u5185\u5b58\u5c42\u7ea7\u548c\u57fa\u4e8e\u4e13\u5bb6\u4f7f\u7528\u9884\u6d4b\u7684\u6570\u636e\u5206\u914d\u6765\u4f18\u5316NMP\u541e\u5410\u91cf\u3002", "result": "\u4e0eGPU\u57fa\u7ebf\u76f8\u6bd4\uff0cStratum\u7cfb\u7edf\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad88.29\u500d\u7684\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\u548c7.66\u500d\u7684\u80fd\u6548\u63d0\u5347\u3002", "conclusion": "Stratum\u901a\u8fc7\u521b\u65b0\u7684\u7cfb\u7edf-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6210\u529f\u89e3\u51b3\u4e86MoE\u6a21\u578b\u90e8\u7f72\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2510.05120", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05120", "abs": "https://arxiv.org/abs/2510.05120", "authors": ["Farjana Yesmin", "Nusrat Shirmin"], "title": "A Fuzzy Logic-Based Framework for Explainable Machine Learning in Big Data Analytics", "comment": "8 pages", "summary": "The growing complexity of machine learning (ML) models in big data analytics,\nespecially in domains such as environmental monitoring, highlights the critical\nneed for interpretability and explainability to promote trust, ethical\nconsiderations, and regulatory adherence (e.g., GDPR). Traditional \"black-box\"\nmodels obstruct transparency, whereas post-hoc explainable AI (XAI) techniques\nlike LIME and SHAP frequently compromise accuracy or fail to deliver inherent\ninsights. This paper presents a novel framework that combines type-2 fuzzy\nsets, granular computing, and clustering to boost explainability and fairness\nin big data environments. When applied to the UCI Air Quality dataset, the\nframework effectively manages uncertainty in noisy sensor data, produces\nlinguistic rules, and assesses fairness using silhouette scores and entropy.\nKey contributions encompass: (1) A type-2 fuzzy clustering approach that\nenhances cohesion by about 4% compared to type-1 methods (silhouette 0.365 vs.\n0.349) and improves fairness (entropy 0.918); (2) Incorporation of fairness\nmeasures to mitigate biases in unsupervised scenarios; (3) A rule-based\ncomponent for intrinsic XAI, achieving an average coverage of 0.65; (4)\nScalable assessments showing linear runtime (roughly 0.005 seconds for sampled\nbig data sizes). Experimental outcomes reveal superior performance relative to\nbaselines such as DBSCAN and Agglomerative Clustering in terms of\ninterpretability, fairness, and efficiency. Notably, the proposed method\nachieves a 4% improvement in silhouette score over type-1 fuzzy clustering and\noutperforms baselines in fairness (entropy reduction by up to 1%) and\nefficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7c7b\u578b2\u6a21\u7cca\u96c6\u3001\u7c92\u8ba1\u7b97\u548c\u805a\u7c7b\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u5927\u6570\u636e\u73af\u5883\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u516c\u5e73\u6027\uff0c\u5728\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e\u57fa\u7ebf\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u73af\u5883\u76d1\u6d4b\u7b49\u9886\u57df\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u8981\u53ef\u89e3\u91ca\u6027\u548c\u516c\u5e73\u6027\u6765\u4fc3\u8fdb\u4fe1\u4efb\u3001\u4f26\u7406\u8003\u91cf\u548c\u6cd5\u89c4\u9075\u4ece\u3002\u4f20\u7edf\u9ed1\u76d2\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u800c\u4e8b\u540eXAI\u6280\u672f\u5e38\u5e38\u727a\u7272\u51c6\u786e\u6027\u6216\u65e0\u6cd5\u63d0\u4f9b\u5185\u5728\u6d1e\u5bdf\u3002", "method": "\u7ed3\u5408\u7c7b\u578b2\u6a21\u7cca\u96c6\u3001\u7c92\u8ba1\u7b97\u548c\u805a\u7c7b\u7684\u65b0\u6846\u67b6\uff0c\u5305\u542b\u7c7b\u578b2\u6a21\u7cca\u805a\u7c7b\u65b9\u6cd5\u3001\u516c\u5e73\u6027\u5ea6\u91cf\u96c6\u6210\u548c\u57fa\u4e8e\u89c4\u5219\u7684XAI\u7ec4\u4ef6\u3002", "result": "\u5728UCI\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\uff0c\u7c7b\u578b2\u6a21\u7cca\u805a\u7c7b\u76f8\u6bd4\u7c7b\u578b1\u65b9\u6cd5\u63d0\u5347\u7ea64%\u7684\u51dd\u805a\u5ea6\uff08\u8f6e\u5ed3\u7cfb\u65700.365 vs 0.349\uff09\uff0c\u6539\u5584\u516c\u5e73\u6027\uff08\u71b50.918\uff09\uff0c\u89c4\u5219\u8986\u76d6\u7387\u8fbe0.65\uff0c\u8fd0\u884c\u65f6\u95f4\u7ebf\u6027\u589e\u957f\uff08\u7ea60.005\u79d2\uff09\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u6027\u3001\u516c\u5e73\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8eDBSCAN\u548c\u51dd\u805a\u805a\u7c7b\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e864%\u7684\u8f6e\u5ed3\u7cfb\u6570\u63d0\u5347\u548c\u9ad8\u8fbe1%\u7684\u71b5\u51cf\u5c11\u3002"}}
{"id": "2510.05127", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05127", "abs": "https://arxiv.org/abs/2510.05127", "authors": ["Harshit Goyal"], "title": "Artificial Intelligence for Cost-Aware Resource Prediction in Big Data Pipelines", "comment": "14 pages, 3 figures", "summary": "Efficient resource allocation is a key challenge in modern cloud computing.\nOver-provisioning leads to unnecessary costs, while under-provisioning risks\nperformance degradation and SLA violations. This work presents an artificial\nintelligence approach to predict resource utilization in big data pipelines\nusing Random Forest regression. We preprocess the Google Borg cluster traces to\nclean, transform, and extract relevant features (CPU, memory, usage\ndistributions). The model achieves high predictive accuracy (R Square = 0.99,\nMAE = 0.0048, RMSE = 0.137), capturing non-linear relationships between\nworkload characteristics and resource utilization. Error analysis reveals\nimpressive performance on small-to-medium jobs, with higher variance in rare\nlarge-scale jobs. These results demonstrate the potential of AI-driven\nprediction for cost-aware autoscaling in cloud environments, reducing\nunnecessary provisioning while safeguarding service quality.", "AI": {"tldr": "\u4f7f\u7528\u968f\u673a\u68ee\u6797\u56de\u5f52\u9884\u6d4b\u5927\u6570\u636e\u6d41\u6c34\u7ebf\u8d44\u6e90\u5229\u7528\u7387\u7684AI\u65b9\u6cd5\uff0c\u5728Google Borg\u96c6\u7fa4\u6570\u636e\u4e0a\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u4e3a\u4e91\u73af\u5883\u6210\u672c\u611f\u77e5\u81ea\u52a8\u6269\u7f29\u5bb9\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u4e91\u8ba1\u7b97\u4e2d\u8d44\u6e90\u5206\u914d\u9762\u4e34\u6311\u6218\uff1a\u8fc7\u5ea6\u914d\u7f6e\u5bfc\u81f4\u4e0d\u5fc5\u8981\u6210\u672c\uff0c\u914d\u7f6e\u4e0d\u8db3\u5219\u5e26\u6765\u6027\u80fd\u4e0b\u964d\u548cSLA\u8fdd\u89c4\u98ce\u9669\u3002\u9700\u8981\u667a\u80fd\u65b9\u6cd5\u6765\u4f18\u5316\u8d44\u6e90\u5229\u7528\u7387\u3002", "method": "\u9884\u5904\u7406Google Borg\u96c6\u7fa4\u8ddf\u8e2a\u6570\u636e\uff0c\u6e05\u7406\u3001\u8f6c\u6362\u5e76\u63d0\u53d6\u76f8\u5173\u7279\u5f81\uff08CPU\u3001\u5185\u5b58\u3001\u4f7f\u7528\u5206\u5e03\uff09\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u8d44\u6e90\u5229\u7528\u7387\u3002", "result": "\u6a21\u578b\u8fbe\u5230\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff08R\u5e73\u65b9=0.99\uff0cMAE=0.0048\uff0cRMSE=0.137\uff09\uff0c\u80fd\u6355\u6349\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u4e0e\u8d44\u6e90\u5229\u7528\u7387\u4e4b\u95f4\u7684\u975e\u7ebf\u6027\u5173\u7cfb\u3002\u5728\u4e2d\u5c0f\u578b\u4f5c\u4e1a\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5927\u578b\u4f5c\u4e1a\u65b9\u5dee\u8f83\u9ad8\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u9884\u6d4b\u65b9\u6cd5\u5728\u4e91\u73af\u5883\u4e2d\u5177\u6709\u6210\u672c\u611f\u77e5\u81ea\u52a8\u6269\u7f29\u5bb9\u7684\u6f5c\u529b\uff0c\u53ef\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u8d44\u6e90\u914d\u7f6e\u540c\u65f6\u4fdd\u969c\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2510.05327", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05327", "abs": "https://arxiv.org/abs/2510.05327", "authors": ["Zahin Ibnat", "Paul E. Calzada", "Rasin Mohammed Ihtemam", "Sujan Kumar Saha", "Jingbo Zhou", "Farimah Farahmandi", "Mark Tehranipoor"], "title": "DeepV: A Model-Agnostic Retrieval-Augmented Framework for Verilog Code Generation with a High-Quality Knowledge Base", "comment": "22 pages, 6 figures", "summary": "As large language models (LLMs) continue to be integrated into modern\ntechnology, there has been an increased push towards code generation\napplications, which also naturally extends to hardware design automation.\nLLM-based solutions for register transfer level (RTL) code generation for\nintellectual property (IP) designs have grown, especially with fine-tuned LLMs,\nprompt engineering, and agentic approaches becoming popular in literature.\nHowever, a gap has been exposed in these techniques, as they fail to integrate\nnovel IPs into the model's knowledge base, subsequently resulting in poorly\ngenerated code. Additionally, as general-purpose LLMs continue to improve,\nfine-tuned methods on older models will not be able to compete to produce more\naccurate and efficient designs. Although some retrieval augmented generation\n(RAG) techniques exist to mitigate challenges presented in fine-tuning\napproaches, works tend to leverage low-quality codebases, incorporate\ncomputationally expensive fine-tuning in the frameworks, or do not use RAG\ndirectly in the RTL generation step. In this work, we introduce DeepV: a\nmodel-agnostic RAG framework to generate RTL designs by enhancing context\nthrough a large, high-quality dataset without any RTL-specific training. Our\nframework benefits the latest commercial LLM, OpenAI's GPT-5, with a near 17%\nincrease in performance on the VerilogEval benchmark. We host DeepV for use by\nthe community in a Hugging Face (HF) Space:\nhttps://huggingface.co/spaces/FICS-LLM/DeepV.", "AI": {"tldr": "DeepV\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684RAG\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210RTL\u8bbe\u8ba1\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u589e\u5f3a\u4e0a\u4e0b\u6587\uff0c\u65e0\u9700RTL\u7279\u5b9a\u8bad\u7ec3\uff0c\u5728VerilogEval\u57fa\u51c6\u4e0a\u6027\u80fd\u63d0\u5347\u8fd117%\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u4e2d\u5b58\u5728\u7f3a\u9677\uff1a\u65e0\u6cd5\u6574\u5408\u65b0IP\u5230\u77e5\u8bc6\u5e93\u5bfc\u81f4\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u5dee\uff0c\u4e14\u57fa\u4e8e\u65e7\u6a21\u578b\u7684\u5fae\u8c03\u65b9\u6cd5\u65e0\u6cd5\u4e0e\u6539\u8fdb\u7684\u901a\u7528LLM\u7ade\u4e89\u3002\u73b0\u6709RAG\u6280\u672f\u5b58\u5728\u4ee3\u7801\u5e93\u8d28\u91cf\u4f4e\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u672a\u76f4\u63a5\u7528\u4e8eRTL\u751f\u6210\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faDeepV\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u589e\u5f3a\u4e0a\u4e0b\u6587\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u65b9\u6cd5\uff0c\u65e0\u9700RTL\u7279\u5b9a\u8bad\u7ec3\uff0c\u6a21\u578b\u65e0\u5173\u4e14\u517c\u5bb9\u6700\u65b0\u5546\u4e1aLLM\u5982GPT-5\u3002", "result": "\u5728VerilogEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepV\u6846\u67b6\u4f7fGPT-5\u6027\u80fd\u63d0\u5347\u8fd117%\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8RTL\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "DeepV\u6846\u67b6\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u548cRAG\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709LLM\u5728RTL\u751f\u6210\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u5728Hugging Face\u4e0a\u5f00\u6e90\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2510.05140", "categories": ["cs.LG", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.05140", "abs": "https://arxiv.org/abs/2510.05140", "authors": ["Armin Gerami", "Ramani Duraiswami"], "title": "Auditing Algorithmic Bias in Transformer-Based Trading", "comment": null, "summary": "Transformer models have become increasingly popular in financial\napplications, yet their potential risk making and biases remain under-explored.\nThe purpose of this work is to audit the reliance of the model on volatile data\nfor decision-making, and quantify how the frequency of price movements affects\nthe model's prediction confidence. We employ a transformer model for\nprediction, and introduce a metric based on Partial Information Decomposition\n(PID) to measure the influence of each asset on the model's decision making.\nOur analysis reveals two key observations: first, the model disregards data\nvolatility entirely, and second, it is biased toward data with lower-frequency\nprice movements.", "AI": {"tldr": "\u672c\u6587\u5ba1\u8ba1\u4e86Transformer\u6a21\u578b\u5728\u91d1\u878d\u5e94\u7528\u4e2d\u5bf9\u6ce2\u52a8\u6027\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u53d1\u73b0\u6a21\u578b\u5b8c\u5168\u5ffd\u7565\u6570\u636e\u6ce2\u52a8\u6027\uff0c\u4e14\u504f\u5411\u4f4e\u9891\u4ef7\u683c\u53d8\u52a8\u6570\u636e\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u91d1\u878d\u5e94\u7528\u4e2d\u65e5\u76ca\u6d41\u884c\uff0c\u4f46\u5176\u98ce\u9669\u51b3\u7b56\u548c\u504f\u89c1\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u5ba1\u8ba1\u6a21\u578b\u5bf9\u6ce2\u52a8\u6027\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5e76\u91cf\u5316\u4ef7\u683c\u53d8\u52a8\u9891\u7387\u5bf9\u6a21\u578b\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528Transformer\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u504f\u4fe1\u606f\u5206\u89e3(PID)\u7684\u6307\u6807\u6765\u8861\u91cf\u6bcf\u4e2a\u8d44\u4ea7\u5bf9\u6a21\u578b\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e24\u4e2a\u5173\u952e\u53d1\u73b0\uff1a\u6a21\u578b\u5b8c\u5168\u5ffd\u7565\u6570\u636e\u6ce2\u52a8\u6027\uff0c\u4e14\u504f\u5411\u4f4e\u9891\u4ef7\u683c\u53d8\u52a8\u6570\u636e\u3002", "conclusion": "Transformer\u6a21\u578b\u5728\u91d1\u878d\u9884\u6d4b\u4e2d\u5b58\u5728\u5bf9\u6570\u636e\u6ce2\u52a8\u6027\u4e0d\u654f\u611f\u548c\u9891\u7387\u504f\u89c1\u7684\u98ce\u9669\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u5173\u6ce8\u548c\u4f18\u5316\u3002"}}
{"id": "2510.05145", "categories": ["cs.DC", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.05145", "abs": "https://arxiv.org/abs/2510.05145", "authors": ["Lunyiu Nie", "Nedim Lipka", "Ryan A. Rossi", "Swarat Chaudhuri"], "title": "FlashResearch: Real-time Agent Orchestration for Efficient Deep Research", "comment": null, "summary": "Deep research agents, which synthesize information across diverse sources,\nare significantly constrained by their sequential reasoning processes. This\narchitectural bottleneck results in high latency, poor runtime adaptability,\nand inefficient resource allocation, making them impractical for interactive\napplications. To overcome this, we introduce FlashResearch, a novel framework\nfor efficient deep research that transforms sequential processing into\nparallel, runtime orchestration by dynamically decomposing complex queries into\ntree-structured sub-tasks. Our core contributions are threefold: (1) an\nadaptive planner that dynamically allocates computational resources by\ndetermining research breadth and depth based on query complexity; (2) a\nreal-time orchestration layer that monitors research progress and prunes\nredundant paths to reallocate resources and optimize efficiency; and (3) a\nmulti-dimensional parallelization framework that enables concurrency across\nboth research breadth and depth. Experiments show that FlashResearch\nconsistently improves final report quality within fixed time budgets, and can\ndeliver up to a 5x speedup while maintaining comparable quality.", "AI": {"tldr": "FlashResearch\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u987a\u5e8f\u63a8\u7406\u8f6c\u6362\u4e3a\u5e76\u884c\u3001\u8fd0\u884c\u65f6\u7f16\u6392\u6765\u89e3\u51b3\u4f20\u7edf\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u5ef6\u8fdf\u548c\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u987a\u5e8f\u63a8\u7406\u8fc7\u7a0b\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u3001\u8fd0\u884c\u65f6\u9002\u5e94\u6027\u5dee\u548c\u8d44\u6e90\u5206\u914d\u6548\u7387\u4f4e\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4ea4\u4e92\u5f0f\u5e94\u7528\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u89c4\u5212\u5668\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u5b9e\u65f6\u7f16\u6392\u5c42\u76d1\u63a7\u7814\u7a76\u8fdb\u5ea6\u5e76\u526a\u679d\u5197\u4f59\u8def\u5f84\uff0c\u4ee5\u53ca\u591a\u7ef4\u5ea6\u5e76\u884c\u5316\u6846\u67b6\u5b9e\u73b0\u7814\u7a76\u5e7f\u5ea6\u548c\u6df1\u5ea6\u7684\u5e76\u53d1\u3002", "result": "\u5b9e\u9a8c\u663e\u793aFlashResearch\u5728\u56fa\u5b9a\u65f6\u95f4\u9884\u7b97\u5185\u6301\u7eed\u63d0\u5347\u6700\u7ec8\u62a5\u544a\u8d28\u91cf\uff0c\u5728\u4fdd\u6301\u53ef\u6bd4\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8fbe5\u500d\u7684\u52a0\u901f\u3002", "conclusion": "FlashResearch\u901a\u8fc7\u5e76\u884c\u5316\u548c\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\u6709\u6548\u89e3\u51b3\u4e86\u6df1\u5ea6\u7814\u7a76\u4e2d\u7684\u6548\u7387\u74f6\u9888\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u7814\u7a76\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05632", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05632", "abs": "https://arxiv.org/abs/2510.05632", "authors": ["Tianhao Zhu", "Dahu Feng", "Erhu Feng", "Yubin Xia"], "title": "From Principles to Practice: A Systematic Study of LLM Serving on Multi-core NPUs", "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs), the demand for\nhigh-performance LLM inference services continues to grow. To meet this demand,\na growing number of AI accelerators have been proposed, such as Google TPU,\nHuawei NPU, Graphcore IPU, and Cerebras WSE, etc. Most of these accelerators\nadopt multi-core architectures to achieve enhanced scalability, but lack the\nflexibility of SIMT architectures. Therefore, without careful configuration of\nthe hardware architecture, as well as deliberate design of tensor parallelism\nand core placement strategies, computational resources may be underutilized,\nresulting in suboptimal inference performance.\n  To address these challenges, we first present a multi-level simulation\nframework with both transaction-level and performance-model-based simulation\nfor multi-core NPUs. Using this simulator, we conduct a systematic analysis and\nfurther propose the optimal solutions for tensor parallelism strategies, core\nplacement policies, memory management methods, as well as the selection between\nPD-disaggregation and PD-fusion on multi-core NPUs. We conduct comprehensive\nexperiments on representative LLMs and various NPU configurations. The\nevaluation results demonstrate that, our solution can achieve 1.32x-6.03x\nspeedup compared to SOTA designs for multi-core NPUs across different hardware\nconfigurations. As for LLM serving, our work offers guidance on designing\noptimal hardware architectures and serving strategies for multi-core NPUs\nacross various LLM workloads.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u6838NPU\u7684\u591a\u7ea7\u4eff\u771f\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u5f20\u91cf\u5e76\u884c\u7b56\u7565\u3001\u6838\u5fc3\u653e\u7f6e\u7b56\u7565\u548c\u5185\u5b58\u7ba1\u7406\uff0c\u5728LLM\u63a8\u7406\u670d\u52a1\u4e2d\u5b9e\u73b0\u4e861.32x-6.03x\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u9ad8\u6027\u80fd\u63a8\u7406\u670d\u52a1\u7684\u9700\u6c42\u4e0d\u65ad\u589e\u957f\u3002\u73b0\u6709\u7684\u591a\u6838AI\u52a0\u901f\u5668\u867d\u7136\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u7f3a\u4e4fSIMT\u67b6\u6784\u7684\u7075\u6d3b\u6027\uff0c\u5bb9\u6613\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\u7387\u4e0d\u8db3\u548c\u63a8\u7406\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u4e8b\u52a1\u7ea7\u548c\u6027\u80fd\u6a21\u578b\u4eff\u771f\u7684\u591a\u7ea7\u4eff\u771f\u6846\u67b6\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u5f20\u91cf\u5e76\u884c\u7b56\u7565\u3001\u6838\u5fc3\u653e\u7f6e\u7b56\u7565\u3001\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\u4ee5\u53caPD\u89e3\u805a\u4e0ePD\u878d\u5408\u7684\u9009\u62e9\u3002", "result": "\u5728\u4e0d\u540c\u786c\u4ef6\u914d\u7f6e\u4e0b\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u591a\u6838NPU\u8bbe\u8ba1\uff0c\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u4e861.32\u500d\u52306.03\u500d\u7684\u52a0\u901f\u6bd4\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u6838NPU\u5728\u5404\u79cdLLM\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8bbe\u8ba1\u6700\u4f18\u786c\u4ef6\u67b6\u6784\u548c\u670d\u52a1\u7b56\u7565\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.05157", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.05157", "abs": "https://arxiv.org/abs/2510.05157", "authors": ["Abrar Shahid", "Ibteeker Mahir Ishum", "AKM Tahmidul Haque", "M Sohel Rahman", "A. B. M. Alim Al Islam"], "title": "Adversarial Reinforcement Learning for Offensive and Defensive Agents in a Simulated Zero-Sum Network Environment", "comment": "8 pages, 5 tables, 5 figures. 12th International Conference on Next\n  Generation Computing, Communication, Systems and Security", "summary": "This paper presents a controlled study of adversarial reinforcement learning\nin network security through a custom OpenAI Gym environment that models\nbrute-force attacks and reactive defenses on multi-port services. The\nenvironment captures realistic security trade-offs including background traffic\nnoise, progressive exploitation mechanics, IP-based evasion tactics, honeypot\ntraps, and multi-level rate-limiting defenses. Competing attacker and defender\nagents are trained using Deep Q-Networks (DQN) within a zero-sum reward\nframework, where successful exploits yield large terminal rewards while\nincremental actions incur small costs. Through systematic evaluation across\nmultiple configurations (varying trap detection probabilities, exploitation\ndifficulty thresholds, and training regimens), the results demonstrate that\ndefender observability and trap effectiveness create substantial barriers to\nsuccessful attacks. The experiments reveal that reward shaping and careful\ntraining scheduling are critical for learning stability in this adversarial\nsetting. The defender consistently maintains strategic advantage across 50,000+\ntraining episodes, with performance gains amplifying when exposed to complex\ndefensive strategies including adaptive IP blocking and port-specific controls.\nComplete implementation details, reproducible hyperparameter configurations,\nand architectural guidelines are provided to support future research in\nadversarial RL for cybersecurity. The zero-sum formulation and realistic\noperational constraints make this environment suitable for studying autonomous\ndefense systems, attacker-defender co-evolution, and transfer learning to\nreal-world network security scenarios.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u81ea\u5b9a\u4e49OpenAI Gym\u73af\u5883\u7814\u7a76\u7f51\u7edc\u5b89\u5168\u7684\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\uff0c\u5c55\u793a\u4e86\u9632\u5fa1\u8005\u5728\u53ef\u89c2\u6d4b\u6027\u548c\u9677\u9631\u6709\u6548\u6027\u65b9\u9762\u7684\u6218\u7565\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u7f51\u7edc\u73af\u5883\u4e2d\u653b\u51fb\u8005\u4e0e\u9632\u5fa1\u8005\u4e4b\u95f4\u7684\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\uff0c\u6a21\u62df\u771f\u5b9e\u7684\u7f51\u7edc\u5b89\u5168\u6743\u8861\uff0c\u5305\u62ec\u80cc\u666f\u6d41\u91cf\u566a\u58f0\u3001\u6e10\u8fdb\u5f0f\u5229\u7528\u673a\u5236\u548c\u871c\u7f50\u9677\u9631\u7b49\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6Q\u7f51\u7edc(DQN)\u5728\u96f6\u548c\u5956\u52b1\u6846\u67b6\u4e0b\u8bad\u7ec3\u7ade\u4e89\u6027\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u914d\u7f6e\uff08\u9677\u9631\u68c0\u6d4b\u6982\u7387\u3001\u5229\u7528\u96be\u5ea6\u9608\u503c\u7b49\uff09\u6765\u7814\u7a76\u5bf9\u6297\u6027\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u9632\u5fa1\u8005\u59cb\u7ec8\u572850,000+\u8bad\u7ec3\u56de\u5408\u4e2d\u4fdd\u6301\u6218\u7565\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u9632\u5fa1\u7b56\u7565\uff08\u81ea\u9002\u5e94IP\u963b\u65ad\u548c\u7aef\u53e3\u7279\u5b9a\u63a7\u5236\uff09\u4e0b\u6027\u80fd\u589e\u76ca\u66f4\u52a0\u660e\u663e\u3002", "conclusion": "\u96f6\u548c\u516c\u5f0f\u548c\u771f\u5b9e\u64cd\u4f5c\u7ea6\u675f\u4f7f\u8be5\u73af\u5883\u9002\u7528\u4e8e\u7814\u7a76\u81ea\u4e3b\u9632\u5fa1\u7cfb\u7edf\u3001\u653b\u51fb\u8005-\u9632\u5fa1\u8005\u5171\u540c\u8fdb\u5316\u4ee5\u53ca\u5411\u73b0\u5b9e\u7f51\u7edc\u5b89\u5168\u573a\u666f\u7684\u8fc1\u79fb\u5b66\u4e60\u3002"}}
{"id": "2510.05149", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05149", "abs": "https://arxiv.org/abs/2510.05149", "authors": ["Clarisse Sousa", "Tiago Fonseca", "Luis Lino Ferreira", "Ricardo Ven\u00e2ncio", "Ricardo Severino"], "title": "Percepta: High Performance Stream Processing at the Edge", "comment": null, "summary": "The rise of real-time data and the proliferation of Internet of Things (IoT)\ndevices have highlighted the limitations of cloud-centric solutions,\nparticularly regarding latency, bandwidth, and privacy. These challenges have\ndriven the growth of Edge Computing. Associated with IoT appears a set of other\nproblems, like: data rate harmonization between multiple sources, protocol\nconversion, handling the loss of data and the integration with Artificial\nIntelligence (AI) models. This paper presents Percepta, a lightweight Data\nStream Processing (DSP) system tailored to support AI workloads at the edge,\nwith a particular focus on such as Reinforcement Learning (RL). It introduces\nspecialized features such as reward function computation, data storage for\nmodel retraining, and real-time data preparation to support continuous\ndecision-making. Additional functionalities include data normalization,\nharmonization across heterogeneous protocols and sampling rates, and robust\nhandling of missing or incomplete data, making it well suited for the\nchallenges of edge-based AI deployment.", "AI": {"tldr": "Percepta\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6570\u636e\u6d41\u5904\u7406\u7cfb\u7edf\uff0c\u4e13\u4e3a\u652f\u6301\u8fb9\u7f18AI\u5de5\u4f5c\u8d1f\u8f7d\u800c\u8bbe\u8ba1\uff0c\u7279\u522b\u5173\u6ce8\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\uff0c\u63d0\u4f9b\u5956\u52b1\u51fd\u6570\u8ba1\u7b97\u3001\u6a21\u578b\u91cd\u8bad\u7ec3\u6570\u636e\u5b58\u50a8\u548c\u5b9e\u65f6\u6570\u636e\u51c6\u5907\u7b49\u529f\u80fd\u3002", "motivation": "\u5b9e\u65f6\u6570\u636e\u548c\u7269\u8054\u7f51\u8bbe\u5907\u7684\u666e\u53ca\u66b4\u9732\u4e86\u4e91\u4e2d\u5fc3\u89e3\u51b3\u65b9\u6848\u5728\u5ef6\u8fdf\u3001\u5e26\u5bbd\u548c\u9690\u79c1\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u63a8\u52a8\u4e86\u8fb9\u7f18\u8ba1\u7b97\u7684\u53d1\u5c55\u3002\u7269\u8054\u7f51\u5e26\u6765\u7684\u6570\u636e\u901f\u7387\u534f\u8c03\u3001\u534f\u8bae\u8f6c\u6362\u3001\u6570\u636e\u4e22\u5931\u5904\u7406\u4ee5\u53ca\u4e0eAI\u6a21\u578b\u96c6\u6210\u7b49\u95ee\u9898\u9700\u8981\u4e13\u95e8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1Percepta\u8f7b\u91cf\u7ea7\u6570\u636e\u6d41\u5904\u7406\u7cfb\u7edf\uff0c\u5177\u5907\u4e13\u95e8\u529f\u80fd\u5982\u5956\u52b1\u51fd\u6570\u8ba1\u7b97\u3001\u6a21\u578b\u91cd\u8bad\u7ec3\u6570\u636e\u5b58\u50a8\u3001\u5b9e\u65f6\u6570\u636e\u51c6\u5907\u3001\u6570\u636e\u5f52\u4e00\u5316\u3001\u5f02\u6784\u534f\u8bae\u548c\u91c7\u6837\u7387\u534f\u8c03\uff0c\u4ee5\u53ca\u9c81\u68d2\u7684\u6570\u636e\u4e22\u5931\u5904\u7406\u80fd\u529b\u3002", "result": "Percepta\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u652f\u6301\u8fb9\u7f18AI\u90e8\u7f72\uff0c\u7279\u522b\u662f\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\uff0c\u901a\u8fc7\u4e13\u95e8\u529f\u80fd\u89e3\u51b3\u4e86\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u6570\u636e\u534f\u8c03\u3001\u534f\u8bae\u8f6c\u6362\u548c\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7b49\u6311\u6218\u3002", "conclusion": "Percepta\u4e3a\u8fb9\u7f18AI\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e13\u95e8\u4f18\u5316\u7684\u8f7b\u91cf\u7ea7\u6570\u636e\u6d41\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u5904\u7406\u5f3a\u5316\u5b66\u4e60\u7b49\u9700\u8981\u8fde\u7eed\u51b3\u7b56\u7684AI\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u89e3\u51b3\u4e86\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2510.05787", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.05787", "abs": "https://arxiv.org/abs/2510.05787", "authors": ["Panagiota Nikolaou", "Freddy Gabbay", "Jawad Haj-Yahya", "Yiannakis Sazeides"], "title": "An opportunity to improve Data Center Efficiency: Optimizing the Server's Upgrade Cycle", "comment": "This work was has been submitted and presented at the 1st\n  International Workshop on Data Center Energy Efficiency (DCEE-2025) at\n  ISCA-2025, June 21, 2025, Tokyo, Japan", "summary": "This work aims to improve a data center's efficiency by optimizing the server\nupgrade plan: determine the optimal timing for replacing old servers with new\nones. The opportunity presented by this approach is demonstrated through a\nstudy based on historical server data. The study establishes a significant\nopportunity to increase the QPS/(TCOxCO2) metric by formulating a global\nupgrade plan at the data center's design time covering its entire life cycle.\nThis plan leverages information, such as server entry year, performance, and\nactive power consumption for both existing and future servers. Our findings\nreveal that an optimal global upgrade plan, may involve upgrades at non fixed\ntime periods and outperforms local upgrade plans. Local upgrade plans follow a\nfixed, equal-length cycle and make decisions based only on currently available\nserver models. These local plans select the best available server at each\nupgrade cycle without accounting for future server releases.", "AI": {"tldr": "\u901a\u8fc7\u4f18\u5316\u670d\u52a1\u5668\u5347\u7ea7\u8ba1\u5212\u6765\u63d0\u9ad8\u6570\u636e\u4e2d\u5fc3\u6548\u7387\uff0c\u7814\u7a76\u53d1\u73b0\u5168\u5c40\u5347\u7ea7\u8ba1\u5212\u6bd4\u5c40\u90e8\u5347\u7ea7\u8ba1\u5212\u8868\u73b0\u66f4\u597d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347QPS/(TCOxCO2)\u6307\u6807\u3002", "motivation": "\u63d0\u9ad8\u6570\u636e\u4e2d\u5fc3\u6548\u7387\uff0c\u901a\u8fc7\u786e\u5b9a\u66ff\u6362\u65e7\u670d\u52a1\u5668\u7684\u6700\u4f73\u65f6\u673a\u6765\u4f18\u5316\u670d\u52a1\u5668\u5347\u7ea7\u8ba1\u5212\u3002", "method": "\u57fa\u4e8e\u5386\u53f2\u670d\u52a1\u5668\u6570\u636e\u7684\u7814\u7a76\uff0c\u5236\u5b9a\u8986\u76d6\u6570\u636e\u4e2d\u5fc3\u6574\u4e2a\u751f\u547d\u5468\u671f\u7684\u5168\u5c40\u5347\u7ea7\u8ba1\u5212\uff0c\u5229\u7528\u670d\u52a1\u5668\u8fdb\u5165\u5e74\u4efd\u3001\u6027\u80fd\u548c\u529f\u8017\u7b49\u4fe1\u606f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6700\u4f18\u5168\u5c40\u5347\u7ea7\u8ba1\u5212\u53ef\u80fd\u6d89\u53ca\u975e\u56fa\u5b9a\u65f6\u95f4\u6bb5\u7684\u5347\u7ea7\uff0c\u4e14\u4f18\u4e8e\u5c40\u90e8\u5347\u7ea7\u8ba1\u5212\u3002\u5168\u5c40\u8ba1\u5212\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8QPS/(TCOxCO2)\u6307\u6807\u3002", "conclusion": "\u5168\u5c40\u5347\u7ea7\u8ba1\u5212\u5728\u6570\u636e\u4e2d\u5fc3\u6548\u7387\u4f18\u5316\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u5c40\u90e8\u5347\u7ea7\u65b9\u6cd5\uff0c\u5e94\u8003\u8651\u672a\u6765\u670d\u52a1\u5668\u53d1\u5e03\u4fe1\u606f\u6765\u5236\u5b9a\u66f4\u6709\u6548\u7684\u5347\u7ea7\u7b56\u7565\u3002"}}
{"id": "2510.05160", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05160", "abs": "https://arxiv.org/abs/2510.05160", "authors": ["Muhammad Arif Hakimi Zamrai"], "title": "Generative Inverse Design: From Single Point Optimization to a Diverse Design Portfolio via Conditional Variational Autoencoders", "comment": null, "summary": "Inverse design, which seeks to find optimal parameters for a target output,\nis a central challenge in engineering. Surrogate-based optimization (SBO) has\nbecome a standard approach, yet it is fundamentally structured to converge to a\nsingle-point solution, thereby limiting design space exploration and ignoring\npotentially valuable alternative topologies. This paper presents a paradigm\nshift from single-point optimization to generative inverse design. We introduce\na framework based on a Conditional Variational Autoencoder (CVAE) that learns a\nprobabilistic mapping between a system's design parameters and its performance,\nenabling the generation of a diverse portfolio of high-performing candidates\nconditioned on a specific performance objective. We apply this methodology to\nthe complex, non-linear problem of minimizing airfoil self-noise, using a\nhigh-performing SBO method from a prior benchmark study as a rigorous baseline.\nThe CVAE framework successfully generated 256 novel designs with a 94.1\\%\nvalidity rate. A subsequent surrogate-based evaluation revealed that 77.2\\% of\nthese valid designs achieved superior performance compared to the single\noptimal design found by the SBO baseline. This work demonstrates that the\ngenerative approach not only discovers higher-quality solutions but also\nprovides a rich portfolio of diverse candidates, fundamentally enhancing the\nengineering design process by enabling multi-criteria decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u5355\u70b9\u4f18\u5316\u8f6c\u5411\u751f\u6210\u5f0f\u9006\u8bbe\u8ba1\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u751f\u6210\u591a\u6837\u5316\u9ad8\u6027\u80fd\u8bbe\u8ba1\u7ec4\u5408\uff0c\u5728\u7ffc\u578b\u81ea\u566a\u58f0\u6700\u5c0f\u5316\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u65b9\u6cd5\u53ea\u80fd\u6536\u655b\u5230\u5355\u70b9\u89e3\uff0c\u9650\u5236\u4e86\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u5e76\u5ffd\u7565\u4e86\u6709\u4ef7\u503c\u7684\u66ff\u4ee3\u62d3\u6251\u7ed3\u6784\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u751f\u6210\u591a\u6837\u5316\u9ad8\u6027\u80fd\u8bbe\u8ba1\u7ec4\u5408\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u6846\u67b6\uff0c\u5b66\u4e60\u8bbe\u8ba1\u53c2\u6570\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6982\u7387\u6620\u5c04\uff0c\u80fd\u591f\u6839\u636e\u7279\u5b9a\u6027\u80fd\u76ee\u6807\u751f\u6210\u591a\u6837\u5316\u7684\u9ad8\u6027\u80fd\u5019\u9009\u8bbe\u8ba1\u3002", "result": "\u6210\u529f\u751f\u6210256\u4e2a\u65b0\u9896\u8bbe\u8ba1\uff0c\u6709\u6548\u7387\u4e3a94.1%\uff0c\u5176\u4e2d77.2%\u7684\u6709\u6548\u8bbe\u8ba1\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u627e\u5230\u7684\u5355\u70b9\u6700\u4f18\u89e3\u3002", "conclusion": "\u751f\u6210\u5f0f\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u53d1\u73b0\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u591a\u6837\u5316\u5019\u9009\u8bbe\u8ba1\u7ec4\u5408\uff0c\u4ece\u6839\u672c\u4e0a\u589e\u5f3a\u4e86\u5de5\u7a0b\u8bbe\u8ba1\u8fc7\u7a0b\uff0c\u652f\u6301\u591a\u6807\u51c6\u51b3\u7b56\u3002"}}
{"id": "2510.05164", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05164", "abs": "https://arxiv.org/abs/2510.05164", "authors": ["Yuanzhe Shen", "Yide Liu", "Zisu Huang", "Ruicheng Yin", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "SATER: A Self-Aware and Token-Efficient Approach to Routing and Cascading", "comment": "Accepted to EMNLP 2025 Main", "summary": "Large language models (LLMs) demonstrate remarkable performance across\ndiverse tasks, yet their effectiveness frequently depends on costly commercial\nAPIs or cloud services. Model selection thus entails a critical trade-off\nbetween performance and cost: high-performing LLMs typically incur substantial\nexpenses, whereas budget-friendly small language models (SLMs) are constrained\nby limited capabilities. Current research primarily proposes two routing\nstrategies: pre-generation routing and cascade routing. Both approaches have\ndistinct characteristics, with cascade routing typically offering superior\ncost-effectiveness and accuracy despite its higher latency. To further address\nthe limitations of both approaches, we introduce SATER, a dual-mode compatible\napproach that fine-tunes models through shortest-response preference\noptimization and a confidence-aware rejection mechanism. SATER significantly\nreduces redundant outputs and response times, while improving both the\nperformance of pre-generation routing and the efficiency of cascade routing.\nExperiments across three SLMs and six datasets, varying in type and complexity,\ndemonstrate that SATER achieves comparable performance while consistently\nreducing computational costs by over 50\\% and cascade latency by over 80\\%.", "AI": {"tldr": "SATER\u662f\u4e00\u79cd\u53cc\u6a21\u5f0f\u517c\u5bb9\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u77ed\u54cd\u5e94\u504f\u597d\u4f18\u5316\u548c\u7f6e\u4fe1\u5ea6\u611f\u77e5\u62d2\u7edd\u673a\u5236\u6765\u5fae\u8c03\u6a21\u578b\uff0c\u663e\u8457\u51cf\u5c11\u5197\u4f59\u8f93\u51fa\u548c\u54cd\u5e94\u65f6\u95f4\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u7ea7\u8054\u5ef6\u8fdf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u4f18\u5f02\u4f46\u6210\u672c\u9ad8\u6602\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6210\u672c\u4f4e\u4f46\u80fd\u529b\u6709\u9650\u3002\u73b0\u6709\u8def\u7531\u7b56\u7565\u5404\u6709\u4f18\u7f3a\u70b9\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u89e3\u51b3\u9884\u751f\u6210\u8def\u7531\u548c\u7ea7\u8054\u8def\u7531\u5c40\u9650\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSATER\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u77ed\u54cd\u5e94\u504f\u597d\u4f18\u5316\u548c\u7f6e\u4fe1\u5ea6\u611f\u77e5\u62d2\u7edd\u673a\u5236\u6765\u5fae\u8c03\u6a21\u578b\uff0c\u5b9e\u73b0\u9884\u751f\u6210\u8def\u7531\u548c\u7ea7\u8054\u8def\u7531\u7684\u53cc\u6a21\u5f0f\u517c\u5bb9\u3002", "result": "\u5728\u4e09\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u548c\u516d\u4e2a\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cSATER\u5728\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd\u7684\u540c\u65f6\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u8d85\u8fc750%\uff0c\u7ea7\u8054\u5ef6\u8fdf\u964d\u4f4e\u8d85\u8fc780%\u3002", "conclusion": "SATER\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u4e2d\u7684\u6027\u80fd\u4e0e\u6210\u672c\u6743\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8def\u7531\u7b56\u7565\u7684\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05476", "categories": ["cs.DC", "cs.AR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.05476", "abs": "https://arxiv.org/abs/2510.05476", "authors": ["Xi Wang", "Bin Ma", "Jongryool Kim", "Byungil Koh", "Hoshik Kim", "Dong Li"], "title": "cMPI: Using CXL Memory Sharing for MPI One-Sided and Two-Sided Inter-Node Communications", "comment": null, "summary": "Message Passing Interface (MPI) is a foundational programming model for\nhigh-performance computing. MPI libraries traditionally employ network\ninterconnects (e.g., Ethernet and InfiniBand) and network protocols (e.g., TCP\nand RoCE) with complex software stacks for cross-node communication. We present\ncMPI, the first work to optimize MPI point-to-point communication (both\none-sided and two-sided) using CXL memory sharing on a real CXL platform,\ntransforming cross-node communication into memory transactions and data copies\nwithin CXL memory, bypassing traditional network protocols. We analyze\nperformance across various interconnects and find that CXL memory sharing\nachieves 7.2x-8.1x lower latency than TCP-based interconnects deployed in\nsmall- and medium-scale clusters. We address challenges of CXL memory sharing\nfor MPI communication, including data object management over the dax\nrepresentation [50], cache coherence, and atomic operations. Overall, cMPI\noutperforms TCP over standard Ethernet NIC and high-end SmartNIC by up to 49x\nand 72x in latency and bandwidth, respectively, for small messages.", "AI": {"tldr": "cMPI\u662f\u9996\u4e2a\u5728\u771f\u5b9eCXL\u5e73\u53f0\u4e0a\u4f7f\u7528CXL\u5185\u5b58\u5171\u4eab\u4f18\u5316MPI\u70b9\u5bf9\u70b9\u901a\u4fe1\u7684\u5de5\u4f5c\uff0c\u5c06\u8de8\u8282\u70b9\u901a\u4fe1\u8f6c\u6362\u4e3aCXL\u5185\u5b58\u5185\u7684\u5185\u5b58\u4e8b\u52a1\u548c\u6570\u636e\u62f7\u8d1d\uff0c\u7ed5\u8fc7\u4f20\u7edf\u7f51\u7edc\u534f\u8bae\u3002", "motivation": "\u4f20\u7edfMPI\u5e93\u4f7f\u7528\u590d\u6742\u7684\u7f51\u7edc\u4e92\u8fde\u548c\u534f\u8bae\u6808\u8fdb\u884c\u8de8\u8282\u70b9\u901a\u4fe1\uff0c\u800cCXL\u5185\u5b58\u5171\u4eab\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u901a\u4fe1\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5229\u7528CXL\u5185\u5b58\u5171\u4eab\u6280\u672f\uff0c\u5c06MPI\u901a\u4fe1\u8f6c\u6362\u4e3a\u5185\u5b58\u4e8b\u52a1\uff0c\u89e3\u51b3CXL\u5185\u5b58\u5171\u4eab\u5728MPI\u901a\u4fe1\u4e2d\u7684\u6570\u636e\u5bf9\u8c61\u7ba1\u7406\u3001\u7f13\u5b58\u4e00\u81f4\u6027\u548c\u539f\u5b50\u64cd\u4f5c\u7b49\u6311\u6218\u3002", "result": "CXL\u5185\u5b58\u5171\u4eab\u6bd4\u57fa\u4e8eTCP\u7684\u4e92\u8fde\u5ef6\u8fdf\u964d\u4f4e7.2-8.1\u500d\uff0c\u5728\u5c0f\u578b\u6d88\u606f\u4f20\u8f93\u4e2d\uff0ccMPI\u5728\u5ef6\u8fdf\u548c\u5e26\u5bbd\u4e0a\u5206\u522b\u6bd4\u6807\u51c6\u4ee5\u592a\u7f51NIC\u548c\u9ad8\u6027\u80fdSmartNIC\u9ad8\u51fa49\u500d\u548c72\u500d\u3002", "conclusion": "cMPI\u8bc1\u660e\u4e86CXL\u5185\u5b58\u5171\u4eab\u5728\u4f18\u5316MPI\u901a\u4fe1\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u7b80\u5316\u901a\u4fe1\u534f\u8bae\u6808\u3002"}}
{"id": "2510.05167", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05167", "abs": "https://arxiv.org/abs/2510.05167", "authors": ["Md Zahin Hossain George", "Md Khorshed Alam", "Md Tarek Hasan"], "title": "Machine learning for fraud detection in digital banking: a systematic literature review REVIEW", "comment": null, "summary": "This systematic literature review examines the role of machine learning in\nfraud detection within digital banking, synthesizing evidence from 118\npeer-reviewed studies and institutional reports. Following the PRISMA\nguidelines, the review applied a structured identification, screening,\neligibility, and inclusion process to ensure methodological rigor and\ntransparency. The findings reveal that supervised learning methods, such as\ndecision trees, logistic regression, and support vector machines, remain the\ndominant paradigm due to their interpretability and established performance,\nwhile unsupervised anomaly detection approaches are increasingly adopted to\naddress novel fraud patterns in highly imbalanced datasets. Deep learning\narchitectures, particularly recurrent and convolutional neural networks, have\nemerged as transformative tools capable of modeling sequential transaction data\nand detecting complex fraud typologies, though challenges of interpretability\nand real-time deployment persist. Hybrid models that combine supervised,\nunsupervised, and deep learning strategies demonstrate superior adaptability\nand detection accuracy, highlighting their potential as convergent solutions.", "AI": {"tldr": "\u8be5\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e86\u673a\u5668\u5b66\u4e60\u5728\u6570\u5b57\u94f6\u884c\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4ecd\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u7528\u4e8e\u5904\u7406\u4e0d\u5e73\u8861\u6570\u636e\uff0c\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u80fd\u68c0\u6d4b\u590d\u6742\u6b3a\u8bc8\u6a21\u5f0f\uff0c\u6df7\u5408\u6a21\u578b\u5c55\u73b0\u51fa\u6700\u4f73\u9002\u5e94\u6027\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u94f6\u884c\u4e1a\u52a1\u589e\u957f\uff0c\u6b3a\u8bc8\u68c0\u6d4b\u9762\u4e34\u65b0\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5e94\u5bf9\u4e0d\u540c\u7c7b\u578b\u6b3a\u8bc8\u6a21\u5f0f\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u9075\u5faaPRISMA\u6307\u5357\uff0c\u5bf9118\u7bc7\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u548c\u673a\u6784\u62a5\u544a\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u8bc6\u522b\u3001\u7b5b\u9009\u3001\u8d44\u683c\u8bc4\u4f30\u548c\u7eb3\u5165\u6d41\u7a0b\u3002", "result": "\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff08\u51b3\u7b56\u6811\u3001\u903b\u8f91\u56de\u5f52\u3001\u652f\u6301\u5411\u91cf\u673a\uff09\u56e0\u53ef\u89e3\u91ca\u6027\u548c\u7a33\u5b9a\u6027\u80fd\u4ecd\u5360\u4e3b\u5bfc\uff1b\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u80fd\u5904\u7406\u65b0\u578b\u6b3a\u8bc8\u6a21\u5f0f\uff1b\u6df1\u5ea6\u5b66\u4e60\u80fd\u5efa\u6a21\u5e8f\u5217\u4ea4\u6613\u6570\u636e\uff1b\u6df7\u5408\u6a21\u578b\u5177\u6709\u6700\u4f73\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u5728\u6570\u5b57\u94f6\u884c\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u6df7\u5408\u6a21\u578b\u7ed3\u5408\u591a\u79cd\u5b66\u4e60\u7b56\u7565\u662f\u6700\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u65f6\u90e8\u7f72\u4ecd\u662f\u6311\u6218\u3002"}}
{"id": "2510.05186", "categories": ["cs.DC", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.05186", "abs": "https://arxiv.org/abs/2510.05186", "authors": ["Hongpei Li", "Han Zhang", "Huikang Liu", "Dongdong Ge", "Yinyu Ye"], "title": "OptPipe: Memory- and Scheduling-Optimized Pipeline Parallelism for LLM Training", "comment": "Use Mathematical Programming to model Pipeline Parallelism with\n  Offloading to balance efficiency and memory requirement", "summary": "Pipeline parallelism (PP) has become a standard technique for scaling large\nlanguage model (LLM) training across multiple devices. However, despite recent\nprogress in reducing memory consumption through activation offloading, existing\napproaches remain largely heuristic and coarse-grained, often overlooking the\nfine-grained trade-offs between memory, computation, and scheduling latency. In\nthis work, we revisit the pipeline scheduling problem from a principled\noptimization perspective. We observe that prevailing strategies either rely on\nstatic rules or aggressively offload activations without fully leveraging the\ninteraction between memory constraints and scheduling efficiency. To address\nthis, we formulate scheduling as a constrained optimization problem that\njointly accounts for memory capacity, activation reuse, and pipeline bubble\nminimization. Solving this model yields fine-grained schedules that reduce\npipeline bubbles while adhering to strict memory budgets. Our approach\ncomplements existing offloading techniques: whereas prior approaches trade\nmemory for time in a fixed pattern, we dynamically optimize the tradeoff with\nrespect to model structure and hardware configuration. Experimental results\ndemonstrate that our method consistently improves both throughput and memory\nutilization. In particular, we reduce idle pipeline time by up to 50% under the\nsame per-device memory limit, and in some cases, enable the training of larger\nmodels within limited memory budgets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u89c6\u89d2\u7684\u6d41\u6c34\u7ebf\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u8003\u8651\u5185\u5b58\u5bb9\u91cf\u3001\u6fc0\u6d3b\u91cd\u7528\u548c\u6d41\u6c34\u7ebf\u6c14\u6ce1\u6700\u5c0f\u5316\uff0c\u52a8\u6001\u4f18\u5316\u5185\u5b58\u4e0e\u65f6\u95f4\u7684\u6743\u8861\uff0c\u76f8\u6bd4\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u548c\u5185\u5b58\u5229\u7528\u7387\u3002", "motivation": "\u73b0\u6709\u6d41\u6c34\u7ebf\u5e76\u884c\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u5ffd\u89c6\u4e86\u5185\u5b58\u3001\u8ba1\u7b97\u548c\u8c03\u5ea6\u5ef6\u8fdf\u4e4b\u95f4\u7684\u7ec6\u7c92\u5ea6\u6743\u8861\uff0c\u9700\u8981\u4ece\u4f18\u5316\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u6d41\u6c34\u7ebf\u8c03\u5ea6\u95ee\u9898\u3002", "method": "\u5c06\u8c03\u5ea6\u95ee\u9898\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u8054\u5408\u8003\u8651\u5185\u5b58\u5bb9\u91cf\u3001\u6fc0\u6d3b\u91cd\u7528\u548c\u6d41\u6c34\u7ebf\u6c14\u6ce1\u6700\u5c0f\u5316\uff0c\u52a8\u6001\u4f18\u5316\u5185\u5b58\u4e0e\u65f6\u95f4\u7684\u6743\u8861\uff0c\u751f\u6210\u7ec6\u7c92\u5ea6\u8c03\u5ea6\u7b56\u7565\u3002", "result": "\u5728\u76f8\u540c\u8bbe\u5907\u5185\u5b58\u9650\u5236\u4e0b\uff0c\u6d41\u6c34\u7ebf\u7a7a\u95f2\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe50%\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u80fd\u591f\u5728\u6709\u9650\u5185\u5b58\u9884\u7b97\u5185\u8bad\u7ec3\u66f4\u5927\u6a21\u578b\uff0c\u541e\u5410\u91cf\u548c\u5185\u5b58\u5229\u7528\u7387\u5747\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u6d41\u6c34\u7ebf\u8c03\u5ea6\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5e73\u8861\u5185\u5b58\u4e0e\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u5e76\u884c\u7b56\u7565\u3002"}}
{"id": "2510.05497", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05497", "abs": "https://arxiv.org/abs/2510.05497", "authors": ["Zhongkai Yu", "Yue Guan", "Zihao Yu", "Chenyang Zhou", "Shuyi Pei", "Yangwook Kang", "Yufei Ding", "Po-An Tsai"], "title": "Orders in Chaos: Enhancing Large-Scale MoE LLM Serving with Data Movement Forecasting", "comment": null, "summary": "Large Language Models (LLMs) with Mixture of Experts (MoE) architectures\nachieve remarkable performance improvements, but their random expert selection\nmechanism introduces significant data movement overhead that becomes the\ndominant bottleneck in multi-unit serving systems. To forecast the patterns\nunderlying this data movement, we conduct comprehensive data-movement-centric\nprofiling across three state-of-the-art large-scale MoE models (200B- 671B)\nusing over 24,000 requests spanning diverse workloads. With the resulting\n150GB+ trace files, we perform systematic analysis from both temporal and\nspatial perspectives and distill six key insights to guide the design of\ndiverse future serving systems. Taking wafer-scale GPUs as a case study, we\ndemonstrate that minor architectural modifications leveraging our insights\nachieve substantial performance gains, delivering 6.3X and 4.0X average\nspeedups on DeepSeek V3 and Qwen3, respectively. Our work provides the first\ncomprehensive data-centric analysis of MoE models at scale. Our profiling\ntraces and analysis results are publicly available at\n{https://huggingface.co/datasets/core12345/MoE_expert_selection_trace. We will\nalso release our simulation framework shortly to facilitate future research in\nthis area.", "AI": {"tldr": "\u672c\u6587\u5bf9MoE\u67b6\u6784LLM\u7684\u6570\u636e\u79fb\u52a8\u74f6\u9888\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u6d4b\u8bd5\u53d1\u73b0\u4e13\u5bb6\u9009\u62e9\u673a\u5236\u662f\u4e3b\u8981\u6027\u80fd\u74f6\u9888\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u65b9\u6848\u5728DeepSeek V3\u548cQwen3\u4e0a\u5206\u522b\u5b9e\u73b06.3\u500d\u548c4.0\u500d\u52a0\u901f\u3002", "motivation": "MoE\u67b6\u6784LLM\u867d\u7136\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5176\u968f\u673a\u4e13\u5bb6\u9009\u62e9\u673a\u5236\u5728\u591a\u5355\u5143\u670d\u52a1\u7cfb\u7edf\u4e2d\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u6570\u636e\u79fb\u52a8\u5f00\u9500\uff0c\u6210\u4e3a\u4e3b\u8981\u6027\u80fd\u74f6\u9888\u3002", "method": "\u5bf9\u4e09\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u89c4\u6a21MoE\u6a21\u578b\uff08200B-671B\uff09\u8fdb\u884c\u6570\u636e\u79fb\u52a8\u4e3a\u4e2d\u5fc3\u7684\u6027\u80fd\u5206\u6790\uff0c\u4f7f\u7528\u8d85\u8fc724,000\u4e2a\u8bf7\u6c42\uff0c\u751f\u6210150GB+\u7684\u8ddf\u8e2a\u6587\u4ef6\uff0c\u4ece\u65f6\u95f4\u548c\u7a7a\u95f4\u89d2\u5ea6\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\u3002", "result": "\u63d0\u70bc\u51fa\u516d\u4e2a\u5173\u952e\u6d1e\u5bdf\u6307\u5bfc\u672a\u6765\u670d\u52a1\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4ee5\u6676\u5706\u7ea7GPU\u4e3a\u4f8b\uff0c\u901a\u8fc7\u57fa\u4e8e\u6d1e\u5bdf\u7684\u67b6\u6784\u4fee\u6539\u5728DeepSeek V3\u548cQwen3\u4e0a\u5206\u522b\u5b9e\u73b06.3\u500d\u548c4.0\u500d\u5e73\u5747\u52a0\u901f\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5927\u89c4\u6a21MoE\u6a21\u578b\u7684\u6570\u636e\u4e2d\u5fc3\u5206\u6790\u5de5\u4f5c\uff0c\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6570\u636e\u79fb\u52a8\u5206\u6790\u6846\u67b6\u548c\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.05168", "categories": ["cs.LG", "cs.CV", "I.2"], "pdf": "https://arxiv.org/pdf/2510.05168", "abs": "https://arxiv.org/abs/2510.05168", "authors": ["Eric Jahns", "Davi Moreno", "Milan Stojkov", "Michel A. Kinsy"], "title": "Discretized Quadratic Integrate-and-Fire Neuron Model for Deep Spiking Neural Networks", "comment": "18 pages, 2 figures", "summary": "Spiking Neural Networks (SNNs) have emerged as energy-efficient alternatives\nto traditional artificial neural networks, leveraging asynchronous and\nbiologically inspired neuron dynamics. Among existing neuron models, the Leaky\nIntegrate-and-Fire (LIF) neuron has become widely adopted in deep SNNs due to\nits simplicity and computational efficiency. However, this efficiency comes at\nthe expense of expressiveness, as LIF dynamics are constrained to linear decay\nat each timestep. In contrast, more complex models, such as the Quadratic\nIntegrate-and-Fire (QIF) neuron, exhibit richer, nonlinear dynamics but have\nseen limited adoption due to their training instability. On that note, we\npropose the first discretization of the QIF neuron model tailored for\nhigh-performance deep spiking neural networks and provide an in-depth analysis\nof its dynamics. To ensure training stability, we derive an analytical\nformulation for surrogate gradient windows directly from our discretizations'\nparameter set, minimizing gradient mismatch. We evaluate our method on\nCIFAR-10, CIFAR-100, ImageNet, and CIFAR-10 DVS, demonstrating its ability to\noutperform state-of-the-art LIF-based methods. These results establish our\ndiscretization of the QIF neuron as a compelling alternative to LIF neurons for\ndeep SNNs, combining richer dynamics with practical scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u9ad8\u6027\u80fd\u6df1\u5ea6\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684QIF\u795e\u7ecf\u5143\u6a21\u578b\u79bb\u6563\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5176\u52a8\u529b\u5b66\u7279\u6027\u5e76\u63a8\u5bfc\u51fa\u7a33\u5b9a\u7684\u8bad\u7ec3\u68af\u5ea6\u7a97\u53e3\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u57fa\u4e8eLIF\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "LIF\u795e\u7ecf\u5143\u867d\u7136\u8ba1\u7b97\u6548\u7387\u9ad8\u4f46\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u800cQIF\u7b49\u590d\u6742\u6a21\u578b\u5177\u6709\u66f4\u4e30\u5bcc\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7279\u6027\uff0c\u4f46\u7531\u4e8e\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u800c\u5e94\u7528\u53d7\u9650\u3002", "method": "\u5f00\u53d1\u4e86QIF\u795e\u7ecf\u5143\u6a21\u578b\u7684\u79bb\u6563\u5316\u7248\u672c\uff0c\u901a\u8fc7\u5206\u6790\u52a8\u529b\u5b66\u7279\u6027\u63a8\u5bfc\u51fa\u57fa\u4e8e\u53c2\u6570\u96c6\u7684\u4ee3\u7406\u68af\u5ea6\u7a97\u53e3\uff0c\u4ee5\u6700\u5c0f\u5316\u68af\u5ea6\u5931\u914d\u5e76\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u5728CIFAR-10\u3001CIFAR-100\u3001ImageNet\u548cCIFAR-10 DVS\u7b49\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u8d85\u8d8a\u57fa\u4e8eLIF\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "QIF\u795e\u7ecf\u5143\u7684\u79bb\u6563\u5316\u7248\u672c\u4e3a\u6df1\u5ea6SNN\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684LIF\u66ff\u4ee3\u65b9\u6848\uff0c\u7ed3\u5408\u4e86\u66f4\u4e30\u5bcc\u7684\u52a8\u529b\u5b66\u7279\u6027\u548c\u5b9e\u9645\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.05254", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.05254", "abs": "https://arxiv.org/abs/2510.05254", "authors": ["Filipp Sporykhin", "Holger Homann"], "title": "Performance of a high-order MPI-Kokkos accelerated fluid solver", "comment": "12 pages, 16 figures. submitted to Computer Physics Communications", "summary": "This work discusses the performance of a modern numerical scheme for fluid\ndynamical problems on modern high-performance computing architectures. Our code\nimplements a spatial nodal discontinuous Galerkin scheme that we test up to an\norder of convergence of eight. It is temporally coupled to a set of Runge-Kutta\nmethods of orders up to six. The code integrates the linear advection equations\nas well as the isothermal Euler equations in one, two, and three dimensions. In\norder to target modern hardware involving many-core Central Processing Units\nand accelerators such as Graphic Processing Units we use the Kokkos library in\nconjunction with the Message Passing Interface to run our single source code on\nvarious GPU systems. We find that the higher the order the faster is the code.\nEighth-order simulations attain a given global error with much less computing\ntime than third- or fourth-order simulations. The RK scheme has a smaller\nimpact on the code performance and a classical fourth-order scheme seems to\ngenerally be a good choice. The code performs very well on all considered GPUs.\nThe many-CPU performance is also very good and perfect weak scaling is observed\nup to many hundreds of CPU cores using MPI. We note that small grid-size\nsimulations are faster on CPUs than on GPUs while GPUs win significantly over\nCPUs for simulations involving more than $10^7$ degrees of freedom ($\\approx\n3100^2$ grid points). When it comes to the environmental impact of numerical\nsimulations we estimate that GPUs consume less energy than CPUs for large\ngrid-size simulations but more energy on small grids. We observe a tendency\nthat the more modern is the GPU the larger needs to be the grid in order to use\nit efficiently. This yields a rebound effect because larger simulations need\nlonger computing times and in turn more energy that is not compensated by the\nenergy efficiency gain of the newer GPUs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u9ad8\u9636\u95f4\u65adGalerkin\u65b9\u6cd5\u5728\u73b0\u4ee3\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0\u516b\u9636\u65b9\u6cd5\u5728\u8fbe\u5230\u76f8\u540c\u5168\u5c40\u8bef\u5dee\u65f6\u6bd4\u4f4e\u9636\u65b9\u6cd5\u66f4\u5feb\uff0cGPU\u5728\u5927\u89c4\u6a21\u6a21\u62df\u4e2d\u8868\u73b0\u4f18\u4e8eCPU\u4f46\u80fd\u8017\u4f18\u52bf\u5b58\u5728\u53cd\u5f39\u6548\u5e94\u3002", "motivation": "\u7814\u7a76\u73b0\u4ee3\u6570\u503c\u65b9\u6cd5\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\uff08\u5305\u62ec\u591a\u6838CPU\u548cGPU\uff09\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7279\u522b\u5173\u6ce8\u9ad8\u9636\u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u548c\u80fd\u8017\u7279\u6027\u3002", "method": "\u4f7f\u7528Kokkos\u5e93\u548cMPI\u5b9e\u73b0\u5355\u6e90\u4ee3\u7801\uff0c\u5728\u591a\u79cdGPU\u7cfb\u7edf\u4e0a\u8fd0\u884c\u7a7a\u95f4\u8282\u70b9\u95f4\u65adGalerkin\u65b9\u6cd5\uff08\u6700\u9ad8\u516b\u9636\uff09\u548c\u65f6\u95f4Runge-Kutta\u65b9\u6cd5\uff08\u6700\u9ad8\u516d\u9636\uff09\uff0c\u6c42\u89e3\u7ebf\u6027\u5bf9\u6d41\u65b9\u7a0b\u548c\u7b49\u6e29\u6b27\u62c9\u65b9\u7a0b\u3002", "result": "\u9ad8\u9636\u65b9\u6cd5\u8ba1\u7b97\u66f4\u5feb\uff0c\u516b\u9636\u6a21\u62df\u6bd4\u4e09\u3001\u56db\u9636\u5feb\uff1bGPU\u5728\u5927\u89c4\u6a21\u6a21\u62df\uff08\u8d85\u8fc710^7\u81ea\u7531\u5ea6\uff09\u4e2d\u663e\u8457\u4f18\u4e8eCPU\uff1b\u65b0GPU\u9700\u8981\u66f4\u5927\u7f51\u683c\u624d\u80fd\u9ad8\u6548\u4f7f\u7528\uff0c\u5bfc\u81f4\u80fd\u8017\u53cd\u5f39\u6548\u5e94\u3002", "conclusion": "\u9ad8\u9636\u95f4\u65adGalerkin\u65b9\u6cd5\u5728\u73b0\u4ee3\u786c\u4ef6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46GPU\u7684\u80fd\u8017\u4f18\u52bf\u53d7\u5230\u7f51\u683c\u89c4\u6a21\u5f71\u54cd\uff0c\u65b0GPU\u9700\u8981\u66f4\u5927\u6a21\u62df\u89c4\u6a21\u624d\u80fd\u53d1\u6325\u6548\u7387\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u80fd\u8017\u53cd\u5f39\u3002"}}
{"id": "2510.05171", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.05171", "abs": "https://arxiv.org/abs/2510.05171", "authors": ["Haijin Xie", "Gongquan Zhang"], "title": "Carbon Emission Prediction in China Considering New Quality Productive Forces Using a Deep & Corss Learning Modeling Framework", "comment": null, "summary": "New quality productive forces (NQPF), digital economy advancement, and\nartificial intelligence (AI) technologies are becoming crucial for promoting\nsustainable urban development. This study proposes a Multi-head Attention Deep\n& Cross Network (MADCN) framework, combining feature interaction modeling and\nattention mechanisms, to predict urban carbon emissions and investigate the\nimpacts of technological factors. The framework incorporates an interpretable\nlearning phase using SHapley Additive exPlanations (SHAP) to assess the\ncontributions of different features. A panel dataset covering 275 Chinese\ncities is utilized to test the MADCN model. Experimental results demonstrate\nthat the MADCN model achieves superior predictive performance compared to\ntraditional machine learning and deep learning baselines, with a Mean Squared\nError (MSE) of 406,151.063, a Mean Absolute Error (MAE) of 612.304, and an\nR-squared value of 0.991 on the test set. SHAP analysis highlights that\npopulation, city size, urbanization rate, and GDP are among the most\ninfluential factors on carbon emissions, while NQPF, digital economy index, and\nAI technology level also show meaningful but relatively moderate effects.\nAdvancing NQPF, strengthening the digital economy, and accelerating AI\ntechnology development can significantly contribute to reducing urban carbon\nemissions. Policymakers should prioritize integrating technological innovation\ninto carbon reduction strategies, particularly by promoting intelligent\ninfrastructure and enhancing digitalization across sectors, to effectively\nachieve dual-carbon goals.", "AI": {"tldr": "\u63d0\u51faMADCN\u6846\u67b6\u9884\u6d4b\u57ce\u5e02\u78b3\u6392\u653e\uff0c\u7ed3\u5408\u591a\u5934\u6ce8\u610f\u529b\u548c\u6df1\u5ea6\u4ea4\u53c9\u7f51\u7edc\uff0c\u4f7f\u7528SHAP\u89e3\u91ca\u6a21\u578b\uff0c\u53d1\u73b0\u4eba\u53e3\u3001\u57ce\u5e02\u89c4\u6a21\u7b49\u662f\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u65b0\u8d28\u751f\u4ea7\u529b\u3001\u6570\u5b57\u7ecf\u6d4e\u548cAI\u6280\u672f\u4e5f\u6709\u663e\u8457\u51cf\u6392\u4f5c\u7528\u3002", "motivation": "\u65b0\u8d28\u751f\u4ea7\u529b\u3001\u6570\u5b57\u7ecf\u6d4e\u548c\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5bf9\u4fc3\u8fdb\u57ce\u5e02\u53ef\u6301\u7eed\u53d1\u5c55\u65e5\u76ca\u91cd\u8981\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u4e9b\u6280\u672f\u56e0\u7d20\u5bf9\u78b3\u6392\u653e\u7684\u5f71\u54cd\u673a\u5236\u3002", "method": "\u63d0\u51fa\u591a\u5934\u6ce8\u610f\u529b\u6df1\u5ea6\u4ea4\u53c9\u7f51\u7edc(MADCN)\u6846\u67b6\uff0c\u7ed3\u5408\u7279\u5f81\u4ea4\u4e92\u5efa\u6a21\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f7f\u7528SHAP\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u57fa\u4e8e275\u4e2a\u4e2d\u56fd\u57ce\u5e02\u7684\u9762\u677f\u6570\u636e\u3002", "result": "MADCN\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02(MSE=406,151.063, MAE=612.304, R\u00b2=0.991)\uff0cSHAP\u5206\u6790\u663e\u793a\u4eba\u53e3\u3001\u57ce\u5e02\u89c4\u6a21\u3001\u57ce\u9547\u5316\u7387\u548cGDP\u5f71\u54cd\u6700\u5927\uff0c\u65b0\u8d28\u751f\u4ea7\u529b\u3001\u6570\u5b57\u7ecf\u6d4e\u548cAI\u6280\u672f\u4e5f\u6709\u663e\u8457\u51cf\u6392\u6548\u679c\u3002", "conclusion": "\u63a8\u8fdb\u65b0\u8d28\u751f\u4ea7\u529b\u53d1\u5c55\u3001\u52a0\u5f3a\u6570\u5b57\u7ecf\u6d4e\u548c\u52a0\u901fAI\u6280\u672f\u5f00\u53d1\u80fd\u663e\u8457\u51cf\u5c11\u57ce\u5e02\u78b3\u6392\u653e\uff0c\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u5c06\u6280\u672f\u521b\u65b0\u878d\u5165\u78b3\u51cf\u6392\u6218\u7565\uff0c\u7279\u522b\u662f\u63a8\u5e7f\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u548c\u90e8\u95e8\u6570\u5b57\u5316\u3002"}}
{"id": "2510.05172", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05172", "abs": "https://arxiv.org/abs/2510.05172", "authors": ["Anushiya Arunan", "Yan Qin", "Xiaoli Li", "U-Xuan Tan", "H. Vincent Poor", "Chau Yuen"], "title": "Learning More with Less: A Generalizable, Self-Supervised Framework for Privacy-Preserving Capacity Estimation with EV Charging Data", "comment": "Accepted in IEEE Transactions on Industrial Informatics", "summary": "Accurate battery capacity estimation is key to alleviating consumer concerns\nabout battery performance and reliability of electric vehicles (EVs). However,\npractical data limitations imposed by stringent privacy regulations and labeled\ndata shortages hamper the development of generalizable capacity estimation\nmodels that remain robust to real-world data distribution shifts. While\nself-supervised learning can leverage unlabeled data, existing techniques are\nnot particularly designed to learn effectively from challenging field data --\nlet alone from privacy-friendly data, which are often less feature-rich and\nnoisier. In this work, we propose a first-of-its-kind capacity estimation model\nbased on self-supervised pre-training, developed on a large-scale dataset of\nprivacy-friendly charging data snippets from real-world EV operations. Our\npre-training framework, snippet similarity-weighted masked input\nreconstruction, is designed to learn rich, generalizable representations even\nfrom less feature-rich and fragmented privacy-friendly data. Our key innovation\nlies in harnessing contrastive learning to first capture high-level\nsimilarities among fragmented snippets that otherwise lack meaningful context.\nWith our snippet-wise contrastive learning and subsequent similarity-weighted\nmasked reconstruction, we are able to learn rich representations of both\ngranular charging patterns within individual snippets and high-level\nassociative relationships across different snippets. Bolstered by this rich\nrepresentation learning, our model consistently outperforms state-of-the-art\nbaselines, achieving 31.9% lower test error than the best-performing benchmark,\neven under challenging domain-shifted settings affected by both manufacturer\nand age-induced distribution shifts.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7684\u7535\u6c60\u5bb9\u91cf\u4f30\u8ba1\u6a21\u578b\uff0c\u4f7f\u7528\u9690\u79c1\u53cb\u597d\u7684\u5145\u7535\u6570\u636e\u7247\u6bb5\uff0c\u901a\u8fc7\u7247\u6bb5\u76f8\u4f3c\u6027\u52a0\u6743\u63a9\u7801\u8f93\u5165\u91cd\u6784\u5b66\u4e60\u901a\u7528\u8868\u793a\uff0c\u5728\u9886\u57df\u504f\u79fb\u573a\u666f\u4e0b\u6bd4\u6700\u4f73\u57fa\u51c6\u6a21\u578b\u964d\u4f4e31.9%\u6d4b\u8bd5\u8bef\u5dee\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u7535\u6c60\u5bb9\u91cf\u51c6\u786e\u4f30\u8ba1\u5bf9\u7f13\u89e3\u6d88\u8d39\u8005\u62c5\u5fe7\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9690\u79c1\u6cd5\u89c4\u548c\u6807\u6ce8\u6570\u636e\u77ed\u7f3a\u9650\u5236\u4e86\u901a\u7528\u5316\u6a21\u578b\u7684\u5f00\u53d1\uff0c\u73b0\u6709\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u4ece\u9690\u79c1\u53cb\u597d\u6570\u636e\u4e2d\u6709\u6548\u5b66\u4e60\u3002", "method": "\u4f7f\u7528\u7247\u6bb5\u76f8\u4f3c\u6027\u52a0\u6743\u63a9\u7801\u8f93\u5165\u91cd\u6784\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u6355\u83b7\u7247\u6bb5\u95f4\u9ad8\u5c42\u76f8\u4f3c\u6027\uff0c\u7136\u540e\u8fdb\u884c\u76f8\u4f3c\u6027\u52a0\u6743\u63a9\u7801\u91cd\u6784\uff0c\u5b66\u4e60\u7ec6\u7c92\u5ea6\u5145\u7535\u6a21\u5f0f\u548c\u9ad8\u5c42\u5173\u8054\u5173\u7cfb\u3002", "result": "\u6a21\u578b\u5728\u5236\u9020\u5546\u548c\u8001\u5316\u5f15\u8d77\u7684\u5206\u5e03\u504f\u79fb\u7b49\u6311\u6218\u6027\u9886\u57df\u504f\u79fb\u8bbe\u7f6e\u4e0b\uff0c\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u51c6\uff0c\u6d4b\u8bd5\u8bef\u5dee\u6bd4\u6700\u4f73\u57fa\u51c6\u964d\u4f4e31.9%\u3002", "conclusion": "\u8be5\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\u80fd\u591f\u4ece\u7279\u5f81\u8f83\u5c11\u4e14\u5608\u6742\u7684\u9690\u79c1\u53cb\u597d\u6570\u636e\u4e2d\u5b66\u4e60\u4e30\u5bcc\u8868\u793a\uff0c\u4e3a\u7535\u6c60\u5bb9\u91cf\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05175", "categories": ["cs.LG", "cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.05175", "abs": "https://arxiv.org/abs/2510.05175", "authors": ["Dmitry Rybin", "Yushun Zhang", "Ding Tian", "Zhihang Lin", "Ruoyu Sun", "Zhi-Quan Luo"], "title": "Exact Causal Attention with 10% Fewer Operations", "comment": null, "summary": "We present Fast Causal Attention (FCA), an algorithm that computes exact\nCausal Attention using 10\\% fewer operations. FCA accelerates a special class\nof matrix multiplications where either one operand or the output matrix is\nupper- or lower-triangular. This includes all operations in forward and\nbackward pass of Causal Attention, such as masked product\n$\\mathrm{Mask}(QK^{T})$. For these matrix multiplications on GPU, FCA reaches\nnoticeable accelerations over the default PyTorch implementations and Triton\ncompiled kernels. FCA is built upon algebraic identities discovered via machine\nlearning and combinatorial search.", "AI": {"tldr": "\u63d0\u51fa\u4e86Fast Causal Attention (FCA)\u7b97\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c1110%\u7684\u64cd\u4f5c\u6765\u8ba1\u7b97\u7cbe\u786e\u7684\u56e0\u679c\u6ce8\u610f\u529b\uff0c\u52a0\u901f\u4e86GPU\u4e0a\u7279\u6b8a\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97\u3002", "motivation": "\u56e0\u679c\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u5b58\u5728\u5927\u91cf\u4e0a\u4e09\u89d2\u6216\u4e0b\u4e09\u89d2\u77e9\u9635\u8fd0\u7b97\uff0c\u8fd9\u4e9b\u8fd0\u7b97\u5728GPU\u4e0a\u7684\u9ed8\u8ba4\u5b9e\u73b0\u6548\u7387\u4e0d\u9ad8\uff0c\u9700\u8981\u66f4\u4f18\u5316\u7684\u7b97\u6cd5\u6765\u52a0\u901f\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u7ec4\u5408\u641c\u7d22\u53d1\u73b0\u7684\u4ee3\u6570\u6052\u7b49\u5f0f\uff0c\u6784\u5efa\u4e86FCA\u7b97\u6cd5\uff0c\u4e13\u95e8\u4f18\u5316\u4e00\u7c7b\u7279\u6b8a\u77e9\u9635\u4e58\u6cd5\uff08\u5176\u4e2d\u4e00\u4e2a\u64cd\u4f5c\u6570\u6216\u8f93\u51fa\u77e9\u9635\u662f\u4e0a\u4e09\u89d2\u6216\u4e0b\u4e09\u89d2\u77e9\u9635\uff09\u3002", "result": "\u5728GPU\u4e0a\uff0cFCA\u76f8\u6bd4\u9ed8\u8ba4PyTorch\u5b9e\u73b0\u548cTriton\u7f16\u8bd1\u5185\u6838\u5b9e\u73b0\u4e86\u663e\u8457\u52a0\u901f\uff0c\u7279\u522b\u662f\u5728\u56e0\u679c\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u7684\u63a9\u7801\u4e58\u79ef\u7b49\u64cd\u4f5c\u4e0a\u3002", "conclusion": "FCA\u4e3a\u56e0\u679c\u6ce8\u610f\u529b\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7cbe\u786e\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ee3\u6570\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86GPU\u4e0a\u7684\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2510.05556", "categories": ["cs.DC", "cs.OS"], "pdf": "https://arxiv.org/pdf/2510.05556", "abs": "https://arxiv.org/abs/2510.05556", "authors": ["Jiakai Xu", "Tianle Zhou", "Eugene Wu", "Kostis Kaffes"], "title": "Toward Systems Foundations for Agentic Exploration", "comment": null, "summary": "Agentic exploration, letting LLM-powered agents branch, backtrack, and search\nacross many execution paths, demands systems support well beyond today's\npass-at-k resets. Our benchmark of six snapshot/restore mechanisms shows that\ngeneric tools such as CRIU or container commits are not fast enough even in\nisolated testbeds, and they crumble entirely in real deployments where agents\nshare files, sockets, and cloud APIs with other agents and human users. In this\ntalk, we pinpoint three open fundamental challenges: fork semantics, which\nconcerns how branches reveal or hide tentative updates; external side-effects,\nwhere fork awareness must be added to services or their calls intercepted; and\nnative forking, which requires cloning databases and runtimes in microseconds\nwithout bulk copying.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u5f53\u524d\u5feb\u7167/\u6062\u590d\u673a\u5236\u5728\u652f\u6301LLM\u667a\u80fd\u4f53\u63a2\u7d22\u65f6\u7684\u4e0d\u8db3\uff0c\u6307\u51fa\u4e86\u4e09\u4e2a\u6839\u672c\u6027\u6311\u6218\uff1a\u5206\u652f\u8bed\u4e49\u3001\u5916\u90e8\u526f\u4f5c\u7528\u548c\u539f\u751f\u5206\u53c9\u3002", "motivation": "\u73b0\u6709\u7684\u901a\u7528\u5feb\u7167/\u6062\u590d\u5de5\u5177\uff08\u5982CRIU\u6216\u5bb9\u5668\u63d0\u4ea4\uff09\u5728\u652f\u6301LLM\u667a\u80fd\u4f53\u7684\u5206\u652f\u3001\u56de\u6eaf\u548c\u591a\u8def\u5f84\u641c\u7d22\u65f6\u6027\u80fd\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u771f\u5b9e\u90e8\u7f72\u73af\u5883\u4e2d\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u548c\u7528\u6237\u5171\u4eab\u8d44\u6e90\u65f6\u8868\u73b0\u66f4\u5dee\u3002", "method": "\u901a\u8fc7\u5bf9\u516d\u79cd\u5feb\u7167/\u6062\u590d\u673a\u5236\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u9694\u79bb\u6d4b\u8bd5\u73af\u5883\u548c\u771f\u5b9e\u90e8\u7f72\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\u901a\u7528\u5de5\u5177\u5373\u4f7f\u5728\u9694\u79bb\u73af\u5883\u4e2d\u4e5f\u4e0d\u591f\u5feb\uff0c\u5728\u771f\u5b9e\u90e8\u7f72\u73af\u5883\u4e2d\u5b8c\u5168\u5931\u6548\uff0c\u65e0\u6cd5\u6709\u6548\u652f\u6301\u667a\u80fd\u4f53\u63a2\u7d22\u3002", "conclusion": "\u9700\u8981\u89e3\u51b3\u4e09\u4e2a\u6839\u672c\u6311\u6218\uff1a\u5206\u652f\u8bed\u4e49\uff08\u5982\u4f55\u5904\u7406\u6682\u5b9a\u66f4\u65b0\uff09\u3001\u5916\u90e8\u526f\u4f5c\u7528\uff08\u5982\u4f55\u4f7f\u670d\u52a1\u652f\u6301\u5206\u53c9\u611f\u77e5\uff09\u3001\u539f\u751f\u5206\u53c9\uff08\u5982\u4f55\u5728\u5fae\u79d2\u7ea7\u514b\u9686\u6570\u636e\u5e93\u548c\u8fd0\u884c\u65f6\u800c\u4e0d\u8fdb\u884c\u6279\u91cf\u590d\u5236\uff09\u3002"}}
{"id": "2510.05176", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05176", "abs": "https://arxiv.org/abs/2510.05176", "authors": ["Ji Zhang", "Yiwei Li", "Shaoxiong Feng", "Peiwen Yuan", "Xinglin Wang", "Jiayi Shi", "Yueqi Zhang", "Chuyi Tan", "Boyuan Pan", "Yao Hu", "Kan Li"], "title": "PatternKV: Flattening KV Representation Expands Quantization Headroom", "comment": null, "summary": "KV cache in autoregressive LLMs eliminates redundant recomputation but has\nemerged as the dominant memory and bandwidth bottleneck during inference,\nnotably with long contexts and test-time scaling. KV quantization is a key\nlever for reducing cache cost, but accuracy drops sharply as the native KV\ndistribution lacks flatness and thus maintains a wide quantization range. Prior\nwork focuses on isolating outliers, which caps their error but fails to flatten\nthe overall distribution, leaving performance fragile under low-bit settings.\nIn this work, we show that the K cache maintains a stable structure that\nevolves gradually with context, while the V cache carries latent semantic\nregularities. Building on these insights, we propose PatternKV, a\npattern-aligned residual quantization scheme. It mines representative pattern\nvectors online, aligns each KV vector to its nearest pattern, and quantizes\nonly the residual. This reshaping of the KV distribution flattens the\nquantization target and narrows its range, thereby improving the fidelity of\nlow-bit KV quantization. Across long-context and test-time scaling settings on\nmultiple backbones, PatternKV delivers consistent 2-bit gains, with a 0.08%\naverage 4-bit drop relative to FP16, improves test-time scaling accuracy by 10%\non average, and raises throughput by 1.4x while supporting 1.25x larger\nbatches.", "AI": {"tldr": "PatternKV\u662f\u4e00\u79cd\u6a21\u5f0f\u5bf9\u9f50\u6b8b\u5dee\u91cf\u5316\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u7ebf\u6316\u6398\u4ee3\u8868\u6027\u6a21\u5f0f\u5411\u91cf\u3001\u5bf9\u9f50KV\u5411\u91cf\u5e76\u91cf\u5316\u6b8b\u5dee\uff0c\u6709\u6548\u6539\u5584\u4f4e\u6bd4\u7279KV\u91cf\u5316\u7684\u4fdd\u771f\u5ea6\u3002", "motivation": "KV\u7f13\u5b58\u5df2\u6210\u4e3aLLM\u63a8\u7406\u4e2d\u7684\u4e3b\u8981\u5185\u5b58\u548c\u5e26\u5bbd\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u957f\u4e0a\u4e0b\u6587\u548c\u6d4b\u8bd5\u65f6\u6269\u5c55\u573a\u666f\u4e0b\u3002\u73b0\u6709KV\u91cf\u5316\u65b9\u6cd5\u56e0\u539f\u751fKV\u5206\u5e03\u4e0d\u5e73\u5766\u800c\u6027\u80fd\u8106\u5f31\u3002", "method": "\u5229\u7528K\u7f13\u5b58\u7684\u7a33\u5b9a\u7ed3\u6784\u548cV\u7f13\u5b58\u7684\u8bed\u4e49\u89c4\u5f8b\u6027\uff0c\u63d0\u51fa\u6a21\u5f0f\u5bf9\u9f50\u6b8b\u5dee\u91cf\u5316\uff1a\u5728\u7ebf\u6316\u6398\u6a21\u5f0f\u5411\u91cf\uff0c\u5bf9\u9f50KV\u5411\u91cf\u5230\u6700\u8fd1\u6a21\u5f0f\uff0c\u4ec5\u91cf\u5316\u6b8b\u5dee\u90e8\u5206\u3002", "result": "\u5728\u591a\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\uff0cPatternKV\u57282\u6bd4\u7279\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u589e\u76ca\uff0c4\u6bd4\u7279\u4e0b\u4ec50.08%\u5e73\u5747\u7cbe\u5ea6\u635f\u5931\uff0c\u6d4b\u8bd5\u65f6\u6269\u5c55\u7cbe\u5ea6\u63d0\u534710%\uff0c\u541e\u5410\u91cf\u63d0\u9ad81.4\u500d\uff0c\u652f\u63011.25\u500d\u66f4\u5927\u6279\u6b21\u3002", "conclusion": "PatternKV\u901a\u8fc7\u91cd\u5851KV\u5206\u5e03\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f4e\u6bd4\u7279KV\u91cf\u5316\u7684\u6311\u6218\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2510.05621", "categories": ["cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.05621", "abs": "https://arxiv.org/abs/2510.05621", "authors": ["Zhiyuan Ren", "Tao Zhang", "Wenchi Chen"], "title": "Decoupling Correctness from Policy: A Deterministic Causal Structure for Multi-Agent Systems", "comment": null, "summary": "In distributed multi-agent systems, correctness is often entangled with\noperational policies such as scheduling, batching, or routing, which makes\nsystems brittle since performance-driven policy evolution may break integrity\nguarantees. This paper introduces the Deterministic Causal Structure (DCS), a\nformal foundation that decouples correctness from policy. We develop a minimal\naxiomatic theory and prove four results: existence and uniqueness,\npolicy-agnostic invariance, observational equivalence, and axiom minimality.\nThese results show that DCS resolves causal ambiguities that value-centric\nconvergence models such as CRDTs cannot address, and that removing any axiom\ncollapses determinism into ambiguity. DCS thus emerges as a boundary principle\nof asynchronous computation, analogous to CAP and FLP: correctness is preserved\nonly within the expressive power of a join-semilattice. All guarantees are\nestablished by axioms and proofs, with only minimal illustrative constructions\nincluded to aid intuition. This work establishes correctness as a fixed,\npolicy-agnostic substrate, a Correctness-as-a-Chassis paradigm, on which\ndistributed intelligent systems can be built modularly, safely, and evolvably.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u786e\u5b9a\u6027\u56e0\u679c\u7ed3\u6784(DCS)\uff0c\u8fd9\u662f\u4e00\u4e2a\u5c06\u6b63\u786e\u6027\u4e0e\u7b56\u7565\u89e3\u8026\u7684\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u6027\u80fd\u9a71\u52a8\u7b56\u7565\u6f14\u8fdb\u53ef\u80fd\u7834\u574f\u5b8c\u6574\u6027\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u6b63\u786e\u6027\u5e38\u4e0e\u8c03\u5ea6\u3001\u6279\u5904\u7406\u3001\u8def\u7531\u7b49\u64cd\u4f5c\u7b56\u7565\u7ea0\u7f20\u5728\u4e00\u8d77\uff0c\u5bfc\u81f4\u7cfb\u7edf\u8106\u5f31\uff0c\u56e0\u4e3a\u6027\u80fd\u9a71\u52a8\u7684\u7b56\u7565\u6f14\u8fdb\u53ef\u80fd\u7834\u574f\u5b8c\u6574\u6027\u4fdd\u8bc1\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6700\u5c0f\u5316\u7684\u516c\u7406\u7406\u8bba\uff0c\u8bc1\u660e\u4e86\u56db\u4e2a\u7ed3\u679c\uff1a\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\u3001\u7b56\u7565\u65e0\u5173\u4e0d\u53d8\u6027\u3001\u89c2\u6d4b\u7b49\u4ef7\u6027\u548c\u516c\u7406\u6700\u5c0f\u6027\u3002", "result": "DCS\u89e3\u51b3\u4e86\u57fa\u4e8e\u503c\u7684\u6536\u655b\u6a21\u578b(\u5982CRDTs)\u65e0\u6cd5\u5904\u7406\u7684\u56e0\u679c\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u5e76\u8868\u660e\u79fb\u9664\u4efb\u4f55\u516c\u7406\u90fd\u4f1a\u4f7f\u786e\u5b9a\u6027\u5d29\u6e83\u4e3a\u6a21\u7cca\u6027\u3002", "conclusion": "DCS\u4f5c\u4e3a\u5f02\u6b65\u8ba1\u7b97\u7684\u8fb9\u754c\u539f\u5219\uff0c\u786e\u7acb\u4e86\u6b63\u786e\u6027\u4f5c\u4e3a\u56fa\u5b9a\u3001\u7b56\u7565\u65e0\u5173\u7684\u5e95\u5c42\u57fa\u7840\uff0c\u5f62\u6210\u4e86\"\u6b63\u786e\u6027\u5373\u5e95\u76d8\"\u7684\u8303\u5f0f\uff0c\u53ef\u5728\u5176\u4e0a\u6a21\u5757\u5316\u3001\u5b89\u5168\u4e14\u53ef\u6f14\u8fdb\u5730\u6784\u5efa\u5206\u5e03\u5f0f\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2510.05178", "categories": ["cs.LG", "cs.AI", "cs.SC"], "pdf": "https://arxiv.org/pdf/2510.05178", "abs": "https://arxiv.org/abs/2510.05178", "authors": ["Ou Deng", "Ruichen Cong", "Jianting Xu", "Shoji Nishimura", "Atsushi Ogihara", "Qun Jin"], "title": "Logistic-Gated Operators Enable Auditable Unit-Aware Thresholds in Symbolic Regression", "comment": null, "summary": "Symbolic regression promises readable equations but struggles to encode\nunit-aware thresholds and conditional logic. We propose logistic-gated\noperators (LGO) -- differentiable gates with learnable location and steepness\n-- embedded as typed primitives and mapped back to physical units for audit.\nAcross two primary health datasets (ICU, NHANES), the hard-gate variant\nrecovers clinically plausible cut-points: 71% (5/7) of assessed thresholds fall\nwithin 10% of guideline anchors and 100% within 20%, while using far fewer\ngates than the soft variant (ICU median 4.0 vs 10.0; NHANES 5.0 vs 12.5), and\nremaining within the competitive accuracy envelope of strong SR baselines. On\npredominantly smooth tasks, gates are pruned, preserving parsimony. The result\nis compact symbolic equations with explicit, unit-aware thresholds that can be\naudited against clinical anchors -- turning interpretability from a post-hoc\nexplanation into a modeling constraint and equipping symbolic regression with a\npractical calculus for regime switching and governance-ready deployment.", "AI": {"tldr": "\u63d0\u51fa\u903b\u8f91\u95e8\u63a7\u7b97\u5b50(LGO)\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u548c\u9661\u5ea6\u53c2\u6570\uff0c\u5728\u7b26\u53f7\u56de\u5f52\u4e2d\u5b9e\u73b0\u53ef\u5fae\u5206\u7684\u9608\u503c\u95e8\u63a7\uff0c\u751f\u6210\u5177\u6709\u660e\u786e\u5355\u4f4d\u611f\u77e5\u9608\u503c\u7684\u7d27\u51d1\u7b26\u53f7\u65b9\u7a0b\u3002", "motivation": "\u7b26\u53f7\u56de\u5f52\u867d\u7136\u80fd\u751f\u6210\u53ef\u8bfb\u65b9\u7a0b\uff0c\u4f46\u96be\u4ee5\u7f16\u7801\u5355\u4f4d\u611f\u77e5\u7684\u9608\u503c\u548c\u6761\u4ef6\u903b\u8f91\uff0c\u9650\u5236\u4e86\u5728\u4e34\u5e8a\u7b49\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u903b\u8f91\u95e8\u63a7\u7b97\u5b50(LGO)\u4f5c\u4e3a\u7c7b\u578b\u5316\u539f\u8bed\uff0c\u5305\u542b\u786c\u95e8\u63a7\u548c\u8f6f\u95e8\u63a7\u53d8\u4f53\uff0c\u53ef\u5b66\u4e60\u9608\u503c\u4f4d\u7f6e\u548c\u9661\u5ea6\uff0c\u5e76\u6620\u5c04\u56de\u7269\u7406\u5355\u4f4d\u8fdb\u884c\u5ba1\u8ba1\u3002", "result": "\u5728\u4e24\u4e2a\u5065\u5eb7\u6570\u636e\u96c6(ICU\u3001NHANES)\u4e0a\uff0c\u786c\u95e8\u63a7\u53d8\u4f53\u6062\u590d\u4e86\u4e34\u5e8a\u5408\u7406\u7684\u5207\u70b9\uff1a71%\u7684\u8bc4\u4f30\u9608\u503c\u5728\u6307\u5357\u951a\u70b9\u768410%\u8303\u56f4\u5185\uff0c100%\u572820%\u8303\u56f4\u5185\uff0c\u4e14\u4f7f\u7528\u66f4\u5c11\u7684\u95e8\u63a7(ICU\u4e2d\u4f4d\u65704.0 vs 10.0\uff1bNHANES 5.0 vs 12.5)\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u53ef\u89e3\u91ca\u6027\u4ece\u540e\u9a8c\u89e3\u91ca\u8f6c\u53d8\u4e3a\u5efa\u6a21\u7ea6\u675f\uff0c\u4e3a\u7b26\u53f7\u56de\u5f52\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u673a\u5236\u5207\u6362\u8ba1\u7b97\u6846\u67b6\uff0c\u9002\u5408\u6cbb\u7406\u5c31\u7eea\u7684\u90e8\u7f72\u3002"}}
{"id": "2510.05711", "categories": ["cs.DC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.05711", "abs": "https://arxiv.org/abs/2510.05711", "authors": ["Ailiya Borjigin", "Cong He"], "title": "Intertemporal Pricing of Time-Bound Stablecoins: Measuring and Controlling the Liquidity-of-Time Premium", "comment": "23 pages, 5 figures", "summary": "Time-bound stablecoins are DeFi assets that temporarily tokenize traditional\nsecurities during market off-hours, enabling continuous cross-market liquidity.\nWe introduce the Liquidity-of-Time Premium (TLP): the extra return or cost of\nproviding liquidity when the primary market is closed. We build a no-arbitrage\npricing model that yields a band for fair values over different expiries, and a\ndynamic risk-control mechanism that adjusts loan-to-value (LTV) ratios in real\ntime to keep TLP within a target range. Our analysis blends financial\nengineering (no-arbitrage conditions, option-style pricing) with empirical\nfinance (event studies on cross-listed stocks and futures) to measure TLP under\ntime-zone frictions. We define TLP formally, derive closed-form expressions for\nits term structure under idealized assumptions, and simulate scenarios that\nvary volatility and collateralization. We then propose an LTV policy that\nraises or lowers collateral to expand or curtail time-bound stablecoin supply,\nanalogous to a central bank adjusting rates to defend a peg. We outline\nempirical proxies for TLP, including ADR premiums, overseas index futures\nversus cash index divergence, and pre-market versus official close gaps.\nResults show that TLP grows with closure length and volatility, yet can be\ncontained by adaptive LTV. We provide backtests and figures (term-structure\ncurves, capital-efficiency versus tail-risk trade-offs, time-liquidity\nheatmaps) and discuss protocol design (vault structure, closing-price oracles,\non-chain auction liquidations). The findings position time-bound stablecoins as\na tool to reduce temporal market inefficiencies and inform future research and\ndeployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65f6\u95f4\u6d41\u52a8\u6027\u6ea2\u4ef7(TLP)\u6982\u5ff5\uff0c\u4e3a\u65f6\u95f4\u7ed1\u5b9a\u7a33\u5b9a\u5e01\u5efa\u7acb\u65e0\u5957\u5229\u5b9a\u4ef7\u6a21\u578b\u548c\u52a8\u6001\u98ce\u9669\u63a7\u5236\u673a\u5236\uff0c\u901a\u8fc7\u8c03\u6574LTV\u6bd4\u7387\u6765\u7ba1\u7406\u8de8\u5e02\u573a\u6d41\u52a8\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8bc1\u5238\u5e02\u573a\u95ed\u5e02\u671f\u95f4\u7684\u6d41\u52a8\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u65f6\u95f4\u7ed1\u5b9a\u7a33\u5b9a\u5e01\u5b9e\u73b0\u8de8\u5e02\u573a\u8fde\u7eed\u6d41\u52a8\u6027\uff0c\u51cf\u5c11\u65f6\u95f4\u7ef4\u5ea6\u7684\u5e02\u573a\u4f4e\u6548\u7387\u3002", "method": "\u7ed3\u5408\u91d1\u878d\u5de5\u7a0b\uff08\u65e0\u5957\u5229\u6761\u4ef6\u3001\u671f\u6743\u5f0f\u5b9a\u4ef7\uff09\u548c\u5b9e\u8bc1\u91d1\u878d\uff08\u4ea4\u53c9\u4e0a\u5e02\u80a1\u7968\u548c\u671f\u8d27\u7684\u4e8b\u4ef6\u7814\u7a76\uff09\uff0c\u5efa\u7acb\u5b9a\u4ef7\u6a21\u578b\u548c\u52a8\u6001LTV\u8c03\u6574\u673a\u5236\u3002", "result": "TLP\u968f\u95ed\u5e02\u65f6\u95f4\u548c\u6ce2\u52a8\u7387\u589e\u52a0\u800c\u589e\u957f\uff0c\u4f46\u53ef\u901a\u8fc7\u81ea\u9002\u5e94LTV\u63a7\u5236\uff1b\u63d0\u4f9b\u4e86\u56de\u6d4b\u7ed3\u679c\u548c\u53ef\u89c6\u5316\u5206\u6790\u3002", "conclusion": "\u65f6\u95f4\u7ed1\u5b9a\u7a33\u5b9a\u5e01\u662f\u51cf\u5c11\u65f6\u95f4\u7ef4\u5ea6\u5e02\u573a\u4f4e\u6548\u7684\u6709\u6548\u5de5\u5177\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2510.05180", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.05180", "abs": "https://arxiv.org/abs/2510.05180", "authors": ["Saida Elouardi", "Mohammed Jouhari", "Anas Motii"], "title": "OptiFLIDS: Optimized Federated Learning for Energy-Efficient Intrusion Detection in IoT", "comment": "12 pages, 15 figures", "summary": "In critical IoT environments, such as smart homes and industrial systems,\neffective Intrusion Detection Systems (IDS) are essential for ensuring\nsecurity. However, developing robust IDS solutions remains a significant\nchallenge. Traditional machine learning-based IDS models typically require\nlarge datasets, but data sharing is often limited due to privacy and security\nconcerns. Federated Learning (FL) presents a promising alternative by enabling\ncollaborative model training without sharing raw data. Despite its advantages,\nFL still faces key challenges, such as data heterogeneity (non-IID data) and\nhigh energy and computation costs, particularly for resource constrained IoT\ndevices. To address these issues, this paper proposes OptiFLIDS, a novel\napproach that applies pruning techniques during local training to reduce model\ncomplexity and energy consumption. It also incorporates a customized\naggregation method to better handle pruned models that differ due to non-IID\ndata distributions. Experiments conducted on three recent IoT IDS datasets,\nTON_IoT, X-IIoTID, and IDSIoT2024, demonstrate that OptiFLIDS maintains strong\ndetection performance while improving energy efficiency, making it well-suited\nfor deployment in real-world IoT environments.", "AI": {"tldr": "\u63d0\u51faOptiFLIDS\u65b9\u6cd5\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5e94\u7528\u526a\u679d\u6280\u672f\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u548c\u80fd\u8017\uff0c\u5e76\u91c7\u7528\u5b9a\u5236\u5316\u805a\u5408\u65b9\u6cd5\u5904\u7406\u975eIID\u6570\u636e\u4e0b\u7684\u526a\u679d\u6a21\u578b\u5dee\u5f02\u3002", "motivation": "\u5728\u5173\u952eIoT\u73af\u5883\u4e2d\uff0c\u4f20\u7edfIDS\u9700\u8981\u5927\u91cf\u6570\u636e\u4f46\u9762\u4e34\u9690\u79c1\u9650\u5236\uff0c\u8054\u90a6\u5b66\u4e60\u867d\u80fd\u4fdd\u62a4\u9690\u79c1\u4f46\u4ecd\u9762\u4e34\u6570\u636e\u5f02\u6784\u6027\u548c\u9ad8\u80fd\u8017\u95ee\u9898\u3002", "method": "\u5728\u672c\u5730\u8bad\u7ec3\u4e2d\u5e94\u7528\u526a\u679d\u6280\u672f\u51cf\u5c11\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u5e76\u8bbe\u8ba1\u5b9a\u5236\u5316\u805a\u5408\u65b9\u6cd5\u5904\u7406\u975eIID\u6570\u636e\u5bfc\u81f4\u7684\u526a\u679d\u6a21\u578b\u5dee\u5f02\u3002", "result": "\u5728TON_IoT\u3001X-IIoTID\u548cIDSIoT2024\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOptiFLIDS\u5728\u4fdd\u6301\u5f3a\u68c0\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u80fd\u6548\u3002", "conclusion": "OptiFLIDS\u9002\u5408\u5728\u771f\u5b9eIoT\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u5e73\u8861\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u80fd\u6e90\u6548\u7387\u3002"}}
{"id": "2510.05738", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.05738", "abs": "https://arxiv.org/abs/2510.05738", "authors": ["Ritesh Chandra", "Sonali Agarwal", "Navjot Singh", "Sadhana Tiwari"], "title": "A Review of Ontology-Driven Big Data Analytics in Healthcare: Challenges, Tools, and Applications", "comment": null, "summary": "Exponential growth in heterogeneous healthcare data arising from electronic\nhealth records (EHRs), medical imaging, wearable sensors, and biomedical\nresearch has accelerated the adoption of data lakes and centralized\narchitectures capable of handling the Volume, Variety, and Velocity of Big Data\nfor advanced analytics. However, without effective governance, these\nrepositories risk devolving into disorganized data swamps. Ontology-driven\nsemantic data management offers a robust solution by linking metadata to\nhealthcare knowledge graphs, thereby enhancing semantic interoperability,\nimproving data discoverability, and enabling expressive, domain-aware access.\nThis review adopts a systematic research strategy, formulating key research\nquestions and conducting a structured literature search across major academic\ndatabases, with selected studies analyzed and classified into six categories of\nontology-driven healthcare analytics: (i) ontology-driven integration\nframeworks, (ii) semantic modeling for metadata enrichment, (iii)\nontology-based data access (OBDA), (iv) basic semantic data management, (v)\nontology-based reasoning for decision support, and (vi) semantic annotation for\nunstructured data. We further examine the integration of ontology technologies\nwith Big Data frameworks such as Hadoop, Spark, Kafka, and so on, highlighting\ntheir combined potential to deliver scalable and intelligent healthcare\nanalytics. For each category, recent techniques, representative case studies,\ntechnical and organizational challenges, and emerging trends such as artificial\nintelligence, machine learning, the Internet of Things (IoT), and real-time\nanalytics are reviewed to guide the development of sustainable, interoperable,\nand high-performance healthcare data ecosystems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u672c\u4f53\u9a71\u52a8\u8bed\u4e49\u6570\u636e\u7ba1\u7406\u5728\u533b\u7597\u5927\u6570\u636e\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u516d\u7c7b\u672c\u4f53\u9a71\u52a8\u533b\u7597\u5206\u6790\u6280\u672f\u53ca\u5176\u4e0e\u5927\u6570\u636e\u6846\u67b6\u7684\u96c6\u6210\uff0c\u65e8\u5728\u89e3\u51b3\u5f02\u6784\u533b\u7597\u6570\u636e\u6cbb\u7406\u6311\u6218\u3002", "motivation": "\u533b\u7597\u5927\u6570\u636e\u5feb\u901f\u589e\u957f\u5e26\u6765\u4e86\u6570\u636e\u6cbb\u7406\u6311\u6218\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0f\u67b6\u6784\u5bb9\u6613\u5f62\u6210\u6570\u636e\u6cbc\u6cfd\uff0c\u9700\u8981\u6709\u6548\u7684\u8bed\u4e49\u6570\u636e\u7ba1\u7406\u65b9\u6cd5\u6765\u63d0\u5347\u4e92\u64cd\u4f5c\u6027\u548c\u6570\u636e\u53ef\u53d1\u73b0\u6027\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u7814\u7a76\u7b56\u7565\uff0c\u5236\u5b9a\u5173\u952e\u7814\u7a76\u95ee\u9898\uff0c\u5728\u4e3b\u8981\u5b66\u672f\u6570\u636e\u5e93\u8fdb\u884c\u7ed3\u6784\u5316\u6587\u732e\u68c0\u7d22\uff0c\u5c06\u9009\u5b9a\u7814\u7a76\u5206\u6790\u5e76\u5206\u7c7b\u4e3a\u516d\u7c7b\u672c\u4f53\u9a71\u52a8\u533b\u7597\u5206\u6790\u6280\u672f\u3002", "result": "\u8bc6\u522b\u51fa\u516d\u7c7b\u672c\u4f53\u9a71\u52a8\u533b\u7597\u5206\u6790\u6280\u672f\uff1a\u672c\u4f53\u9a71\u52a8\u96c6\u6210\u6846\u67b6\u3001\u8bed\u4e49\u5143\u6570\u636e\u5efa\u6a21\u3001\u57fa\u4e8e\u672c\u4f53\u7684\u6570\u636e\u8bbf\u95ee\u3001\u57fa\u7840\u8bed\u4e49\u6570\u636e\u7ba1\u7406\u3001\u57fa\u4e8e\u672c\u4f53\u7684\u51b3\u7b56\u652f\u6301\u63a8\u7406\u3001\u975e\u7ed3\u6784\u5316\u6570\u636e\u8bed\u4e49\u6807\u6ce8\u3002", "conclusion": "\u672c\u4f53\u6280\u672f\u4e0e\u5927\u6570\u636e\u6846\u67b6\u7ed3\u5408\u80fd\u591f\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u667a\u80fd\u533b\u7597\u5206\u6790\uff0c\u4e3a\u6784\u5efa\u53ef\u6301\u7eed\u3001\u4e92\u64cd\u4f5c\u3001\u9ad8\u6027\u80fd\u7684\u533b\u7597\u6570\u636e\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.05205", "categories": ["cs.LG", "astro-ph.CO"], "pdf": "https://arxiv.org/pdf/2510.05205", "abs": "https://arxiv.org/abs/2510.05205", "authors": ["Sebastian Wagner-Carena", "Aizhan Akhmetzhanova", "Sydney Erickson"], "title": "A Data-Driven Prism: Multi-View Source Separation with Diffusion Model Priors", "comment": "Accepted to main conference of NeurIPS 2025. Code available at\n  https://github.com/swagnercarena/ddprism", "summary": "A common challenge in the natural sciences is to disentangle distinct,\nunknown sources from observations. Examples of this source separation task\ninclude deblending galaxies in a crowded field, distinguishing the activity of\nindividual neurons from overlapping signals, and separating seismic events from\nan ambient background. Traditional analyses often rely on simplified source\nmodels that fail to accurately reproduce the data. Recent advances have shown\nthat diffusion models can directly learn complex prior distributions from\nnoisy, incomplete data. In this work, we show that diffusion models can solve\nthe source separation problem without explicit assumptions about the source.\nOur method relies only on multiple views, or the property that different sets\nof observations contain different linear transformations of the unknown\nsources. We show that our method succeeds even when no source is individually\nobserved and the observations are noisy, incomplete, and vary in resolution.\nThe learned diffusion models enable us to sample from the source priors,\nevaluate the probability of candidate sources, and draw from the joint\nposterior of the source distribution given an observation. We demonstrate the\neffectiveness of our method on a range of synthetic problems as well as\nreal-world galaxy observations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6e90\u5206\u79bb\u65b9\u6cd5\uff0c\u65e0\u9700\u5bf9\u6e90\u8fdb\u884c\u663e\u5f0f\u5047\u8bbe\uff0c\u4ec5\u5229\u7528\u591a\u89c6\u56fe\u89c2\u6d4b\u6570\u636e\u5373\u53ef\u89e3\u51b3\u6e90\u5206\u79bb\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6e90\u5206\u79bb\u65b9\u6cd5\u4f9d\u8d56\u7b80\u5316\u7684\u6e90\u6a21\u578b\uff0c\u65e0\u6cd5\u51c6\u786e\u590d\u73b0\u6570\u636e\u3002\u6269\u6563\u6a21\u578b\u53ef\u4ee5\u76f4\u63a5\u4ece\u566a\u58f0\u3001\u4e0d\u5b8c\u6574\u6570\u636e\u4e2d\u5b66\u4e60\u590d\u6742\u5148\u9a8c\u5206\u5e03\uff0c\u4e3a\u6e90\u5206\u79bb\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\uff0c\u4ec5\u4f9d\u8d56\u591a\u89c6\u56fe\u89c2\u6d4b\u6570\u636e\uff08\u4e0d\u540c\u89c2\u6d4b\u5305\u542b\u672a\u77e5\u6e90\u7684\u4e0d\u540c\u7ebf\u6027\u53d8\u6362\uff09\uff0c\u65e0\u9700\u5bf9\u6e90\u8fdb\u884c\u663e\u5f0f\u5047\u8bbe\u3002\u65b9\u6cd5\u5728\u6e90\u672a\u88ab\u5355\u72ec\u89c2\u6d4b\u3001\u89c2\u6d4b\u5b58\u5728\u566a\u58f0\u3001\u4e0d\u5b8c\u6574\u548c\u5206\u8fa8\u7387\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5de5\u4f5c\u3002", "result": "\u65b9\u6cd5\u5728\u5408\u6210\u95ee\u9898\u548c\u771f\u5b9e\u661f\u7cfb\u89c2\u6d4b\u4e2d\u5747\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u80fd\u591f\u4ece\u6e90\u5148\u9a8c\u4e2d\u91c7\u6837\u3001\u8bc4\u4f30\u5019\u9009\u6e90\u6982\u7387\uff0c\u4ee5\u53ca\u4ece\u7ed9\u5b9a\u89c2\u6d4b\u7684\u6e90\u5206\u5e03\u8054\u5408\u540e\u9a8c\u4e2d\u91c7\u6837\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u80fd\u591f\u6210\u529f\u89e3\u51b3\u6e90\u5206\u79bb\u95ee\u9898\uff0c\u65e0\u9700\u5bf9\u6e90\u8fdb\u884c\u663e\u5f0f\u5047\u8bbe\uff0c\u4e14\u5728\u5404\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u89c2\u6d4b\u6761\u4ef6\u4e0b\u90fd\u80fd\u5de5\u4f5c\u3002"}}
{"id": "2510.05943", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05943", "abs": "https://arxiv.org/abs/2510.05943", "authors": ["Zheyue Tan", "Mustapha Abdullahi", "Tuo Shi", "Huining Yuan", "Zelai Xu", "Chao Yu", "Boxun Li", "Bo Zhao"], "title": "EARL: Efficient Agentic Reinforcement Learning Systems for Large Language Models", "comment": null, "summary": "Reinforcement learning (RL) has become a pivotal component of large language\nmodel (LLM) post-training, and agentic RL extends this paradigm to operate as\nagents through multi-turn interaction and tool use. Scaling such systems\nexposes two practical bottlenecks: (1) context length grows rapidly during\ntraining, inflating memory usage and latency, and triggering out-of-memory\n(OOM) failures; and (2) intermediate tensors accumulate with context length,\nmaking cross-device data movement a major system bottleneck.\n  We present EARL, a scalable system for efficient agentic RL. EARL designs a\nparallelism selector that dynamically adapts model and training parallelism\nacross RL stages based on sequence length and system load, and a data\ndispatcher that performs layout-aware, decentralized exchange of intermediate\ndata batches. Together, these components increase throughput, reduce\nlong-context failures, and enable stable large-scale training of agentic LLMs\nwithout relying on hard limits or penalties of context length.", "AI": {"tldr": "EARL\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u5e76\u884c\u5ea6\u9009\u62e9\u548c\u5e03\u5c40\u611f\u77e5\u7684\u6570\u636e\u5206\u53d1\u6765\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u4e2d\u7684\u5185\u5b58\u548c\u5ef6\u8fdf\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u5728LLM\u540e\u8bad\u7ec3\u4e2d\u9762\u4e34\u4e24\u4e2a\u5b9e\u9645\u74f6\u9888\uff1a\u4e0a\u4e0b\u6587\u957f\u5ea6\u5feb\u901f\u589e\u957f\u5bfc\u81f4\u5185\u5b58\u4f7f\u7528\u589e\u52a0\u548c\u5ef6\u8fdf\uff0c\u4ee5\u53ca\u4e2d\u95f4\u5f20\u91cf\u79ef\u7d2f\u5bfc\u81f4\u8de8\u8bbe\u5907\u6570\u636e\u79fb\u52a8\u6210\u4e3a\u7cfb\u7edf\u74f6\u9888\u3002", "method": "EARL\u8bbe\u8ba1\u4e86\u5e76\u884c\u5ea6\u9009\u62e9\u5668\uff0c\u6839\u636e\u5e8f\u5217\u957f\u5ea6\u548c\u7cfb\u7edf\u8d1f\u8f7d\u52a8\u6001\u8c03\u6574\u6a21\u578b\u548c\u8bad\u7ec3\u5e76\u884c\u5ea6\uff0c\u4ee5\u53ca\u6570\u636e\u5206\u53d1\u5668\u6267\u884c\u5e03\u5c40\u611f\u77e5\u7684\u5206\u6563\u5f0f\u4e2d\u95f4\u6570\u636e\u6279\u6b21\u4ea4\u6362\u3002", "result": "\u8be5\u7cfb\u7edf\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u51cf\u5c11\u4e86\u957f\u4e0a\u4e0b\u6587\u5931\u8d25\uff0c\u5e76\u5b9e\u73b0\u4e86\u4ee3\u7406LLM\u7684\u7a33\u5b9a\u5927\u89c4\u6a21\u8bad\u7ec3\uff0c\u65e0\u9700\u4f9d\u8d56\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u786c\u9650\u5236\u6216\u60e9\u7f5a\u3002", "conclusion": "EARL\u901a\u8fc7\u521b\u65b0\u7684\u5e76\u884c\u5ea6\u9009\u62e9\u548c\u6570\u636e\u5206\u53d1\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u4ee3\u7406LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u7a33\u5b9a\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05218", "categories": ["cs.LG", "cs.AI", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.05218", "abs": "https://arxiv.org/abs/2510.05218", "authors": ["Edward Hirst", "Sanjaye Ramgoolam"], "title": "Approximate Gaussianity Beyond Initialisation in Neural Networks", "comment": "26+34 pages, 15 figures, 12 tables", "summary": "Ensembles of neural network weight matrices are studied through the training\nprocess for the MNIST classification problem, testing the efficacy of matrix\nmodels for representing their distributions, under assumptions of Gaussianity\nand permutation-symmetry. The general 13-parameter permutation invariant\nGaussian matrix models are found to be effective models for the correlated\nGaussianity in the weight matrices, beyond the range of applicability of the\nsimple Gaussian with independent identically distributed matrix variables, and\nnotably well beyond the initialisation step. The representation theoretic model\nparameters, and the graph-theoretic characterisation of the permutation\ninvariant matrix observables give an interpretable framework for the best-fit\nmodel and for small departures from Gaussianity. Additionally, the Wasserstein\ndistance is calculated for this class of models and used to quantify the\nmovement of the distributions over training. Throughout the work, the effects\nof varied initialisation regimes, regularisation, layer depth, and layer width\nare tested for this formalism, identifying limits where particular departures\nfrom Gaussianity are enhanced and how more general, yet still\nhighly-interpretable, models can be developed.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u77e9\u9635\u96c6\u5408\u5728MNIST\u5206\u7c7b\u4efb\u52a1\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5206\u5e03\u7279\u6027\uff0c\u4f7f\u7528\u5177\u6709\u7f6e\u6362\u5bf9\u79f0\u6027\u7684\u9ad8\u65af\u77e9\u9635\u6a21\u578b\u6765\u5efa\u6a21\u6743\u91cd\u5206\u5e03\uff0c\u53d1\u73b013\u53c2\u6570\u7f6e\u6362\u4e0d\u53d8\u9ad8\u65af\u77e9\u9635\u6a21\u578b\u80fd\u6709\u6548\u63cf\u8ff0\u6743\u91cd\u76f8\u5173\u6027\uff0c\u5e76\u5206\u6790\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5206\u5e03\u7684\u53d8\u5316\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u77e9\u9635\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5206\u5e03\u7279\u6027\uff0c\u6d4b\u8bd5\u9ad8\u65af\u6027\u548c\u7f6e\u6362\u5bf9\u79f0\u6027\u5047\u8bbe\u4e0b\u7684\u77e9\u9635\u6a21\u578b\u5bf9\u6743\u91cd\u5206\u5e03\u7684\u8868\u5f81\u80fd\u529b\uff0c\u63a2\u7d22\u66f4\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u6846\u67b6\u3002", "method": "\u4f7f\u752813\u53c2\u6570\u7f6e\u6362\u4e0d\u53d8\u9ad8\u65af\u77e9\u9635\u6a21\u578b\u6765\u5efa\u6a21\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u77e9\u9635\u7684\u5206\u5e03\uff0c\u901a\u8fc7\u8868\u793a\u8bba\u6a21\u578b\u53c2\u6570\u548c\u56fe\u8bba\u7279\u5f81\u5316\u7f6e\u6362\u4e0d\u53d8\u77e9\u9635\u53ef\u89c2\u6d4b\u91cf\uff0c\u8ba1\u7b97Wasserstein\u8ddd\u79bb\u91cf\u5316\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5206\u5e03\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u7f6e\u6362\u4e0d\u53d8\u9ad8\u65af\u77e9\u9635\u6a21\u578b\u80fd\u6709\u6548\u63cf\u8ff0\u6743\u91cd\u77e9\u9635\u7684\u76f8\u5173\u9ad8\u65af\u6027\uff0c\u8fdc\u8d85\u7b80\u5355\u72ec\u7acb\u540c\u5206\u5e03\u9ad8\u65af\u6a21\u578b\u7684\u9002\u7528\u8303\u56f4\uff0c\u7279\u522b\u662f\u5728\u521d\u59cb\u5316\u9636\u6bb5\u4e4b\u540e\u3002\u6a21\u578b\u53c2\u6570\u548c\u53ef\u89c2\u6d4b\u91cf\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u6765\u7406\u89e3\u6700\u4f73\u62df\u5408\u6a21\u578b\u548c\u4e0e\u9ad8\u65af\u6027\u7684\u5c0f\u504f\u5dee\u3002", "conclusion": "\u7f6e\u6362\u4e0d\u53d8\u9ad8\u65af\u77e9\u9635\u6a21\u578b\u4e3a\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u5206\u5e03\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u6355\u6349\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5206\u5e03\u53d8\u5316\uff0c\u5e76\u4e3a\u5f00\u53d1\u66f4\u901a\u7528\u4e14\u9ad8\u5ea6\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2405.14209", "categories": ["cs.PF", "cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2405.14209", "abs": "https://arxiv.org/abs/2405.14209", "authors": ["Xi Wang", "Jie Liu", "Jianbo Wu", "Shuangyan Yang", "Jie Ren", "Bhanu Shankar", "Dong Li"], "title": "Exploring and Evaluating Real-world CXL: Use Cases and System Adoption", "comment": null, "summary": "Compute eXpress Link (CXL) is emerging as a promising memory interface\ntechnology. However, its performance characteristics remain largely unclear due\nto the limited availability of production hardware. Key questions include: What\nare the use cases for the CXL memory? What are the impacts of the CXL memory on\napplication performance? How to use the CXL memory in combination with existing\nmemory components? In this work, we study the performance of three genuine CXL\nmemory-expansion cards from different vendors. We characterize the basic\nperformance of the CXL memory, study how HPC applications and large language\nmodels (LLM) can benefit from the CXL memory, and study the interplay between\nmemory tiering and page interleaving. We also propose a novel data object-level\ninterleaving policy to match the interleaving policy with memory access\npatterns. Our findings reveal the challenges and opportunities of using the CXL\nmemory.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4e09\u79cd\u4e0d\u540c\u5382\u5546\u7684CXL\u5185\u5b58\u6269\u5c55\u5361\u6027\u80fd\uff0c\u7814\u7a76\u4e86CXL\u5185\u5b58\u5bf9HPC\u5e94\u7528\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u6570\u636e\u5bf9\u8c61\u7ea7\u4ea4\u9519\u7b56\u7565\u6765\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u3002", "motivation": "CXL\u4f5c\u4e3a\u65b0\u5174\u5185\u5b58\u63a5\u53e3\u6280\u672f\uff0c\u5176\u6027\u80fd\u7279\u6027\u56e0\u751f\u4ea7\u786c\u4ef6\u6709\u9650\u800c\u5c1a\u4e0d\u660e\u786e\u3002\u9700\u8981\u4e86\u89e3CXL\u5185\u5b58\u7684\u4f7f\u7528\u573a\u666f\u3001\u5bf9\u5e94\u7528\u6027\u80fd\u7684\u5f71\u54cd\u4ee5\u53ca\u5982\u4f55\u4e0e\u73b0\u6709\u5185\u5b58\u7ec4\u4ef6\u7ed3\u5408\u4f7f\u7528\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u4e0d\u540c\u5382\u5546\u7684CXL\u5185\u5b58\u6269\u5c55\u5361\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\uff0c\u5305\u62ec\u57fa\u7840\u6027\u80fd\u8868\u5f81\u3001HPC\u5e94\u7528\u548cLLM\u6027\u80fd\u8bc4\u4f30\u3001\u5185\u5b58\u5206\u5c42\u4e0e\u9875\u9762\u4ea4\u9519\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u6570\u636e\u5bf9\u8c61\u7ea7\u4ea4\u9519\u7b56\u7565\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u4f7f\u7528CXL\u5185\u5b58\u9762\u4e34\u7684\u6311\u6218\u548c\u673a\u9047\uff0c\u5c55\u793a\u4e86CXL\u5185\u5b58\u5bf9\u5e94\u7528\u6027\u80fd\u7684\u5177\u4f53\u5f71\u54cd\u4ee5\u53ca\u5185\u5b58\u5206\u5c42\u4e0e\u4ea4\u9519\u7b56\u7565\u7684\u6548\u679c\u3002", "conclusion": "CXL\u5185\u5b58\u6280\u672f\u5177\u6709\u91cd\u8981\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u5177\u4f53\u4f7f\u7528\u573a\u666f\u4f18\u5316\u5185\u5b58\u7ba1\u7406\u7b56\u7565\uff0c\u6570\u636e\u5bf9\u8c61\u7ea7\u4ea4\u9519\u7b56\u7565\u80fd\u591f\u6709\u6548\u5339\u914d\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u3002"}}
{"id": "2510.05228", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05228", "abs": "https://arxiv.org/abs/2510.05228", "authors": ["Haining Pan", "James V. Roggeveen", "Erez Berg", "Juan Carrasquilla", "Debanjan Chowdhury", "Surya Ganguli", "Federico Ghimenti", "Juraj Hasik", "Henry Hunt", "Hong-Chen Jiang", "Mason Kamb", "Ying-Jer Kao", "Ehsan Khatami", "Michael J. Lawler", "Di Luo", "Titus Neupert", "Xiaoliang Qi", "Michael P. Brenner", "Eun-Ah Kim"], "title": "CMT-Benchmark: A Benchmark for Condensed Matter Theory Built by Expert Researchers", "comment": "19 pages, 3 figures", "summary": "Large language models (LLMs) have shown remarkable progress in coding and\nmath problem-solving, but evaluation on advanced research-level problems in\nhard sciences remains scarce. To fill this gap, we present CMT-Benchmark, a\ndataset of 50 problems covering condensed matter theory (CMT) at the level of\nan expert researcher. Topics span analytical and computational approaches in\nquantum many-body, and classical statistical mechanics. The dataset was\ndesigned and verified by a panel of expert researchers from around the world.\nWe built the dataset through a collaborative environment that challenges the\npanel to write and refine problems they would want a research assistant to\nsolve, including Hartree-Fock, exact diagonalization, quantum/variational Monte\nCarlo, density matrix renormalization group (DMRG), quantum/classical\nstatistical mechanics, and model building. We evaluate LLMs by programmatically\nchecking solutions against expert-supplied ground truth. We developed\nmachine-grading, including symbolic handling of non-commuting operators via\nnormal ordering. They generalize across tasks too. Our evaluations show that\nfrontier models struggle with all of the problems in the dataset, highlighting\na gap in the physical reasoning skills of current LLMs. Notably, experts\nidentified strategies for creating increasingly difficult problems by\ninteracting with the LLMs and exploiting common failure modes. The best model,\nGPT5, solves 30\\% of the problems; average across 17 models (GPT, Gemini,\nClaude, DeepSeek, Llama) is 11.4$\\pm$2.1\\%. Moreover, 18 problems are solved by\nnone of the 17 models, and 26 by at most one. These unsolved problems span\nQuantum Monte Carlo, Variational Monte Carlo, and DMRG. Answers sometimes\nviolate fundamental symmetries or have unphysical scaling dimensions. We\nbelieve this benchmark will guide development toward capable AI research\nassistants and tutors.", "AI": {"tldr": "CMT-Benchmark\u662f\u4e00\u4e2a\u5305\u542b50\u4e2a\u51dd\u805a\u6001\u7406\u8bba\u4e13\u5bb6\u7ea7\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u9ad8\u7ea7\u7814\u7a76\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u8868\u660e\u524d\u6cbf\u6a21\u578b\u5728\u6240\u6709\u95ee\u9898\u4e0a\u90fd\u8868\u73b0\u4e0d\u4f73\uff0c\u6700\u4f73\u6a21\u578bGPT5\u4ec5\u89e3\u51b330%\u7684\u95ee\u9898\uff0c\u5e73\u5747\u51c6\u786e\u7387\u4e3a11.4%\uff0c\u51f8\u663e\u4e86\u5f53\u524dLLMs\u5728\u7269\u7406\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u7f16\u7a0b\u548c\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u786c\u79d1\u5b66\u9886\u57df\u7684\u9ad8\u7ea7\u7814\u7a76\u7ea7\u95ee\u9898\u8bc4\u4f30\u4ecd\u7136\u7a00\u7f3a\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u521b\u5efa\u4e13\u5bb6\u7ea7\u96be\u5ea6\u7684\u57fa\u51c6\u6570\u636e\u96c6\u6765\u8bc4\u4f30LLMs\u7684\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5168\u7403\u4e13\u5bb6\u5c0f\u7ec4\u534f\u4f5c\u8bbe\u8ba150\u4e2a\u51dd\u805a\u6001\u7406\u8bba\u95ee\u9898\uff0c\u6db5\u76d6\u91cf\u5b50\u591a\u4f53\u548c\u7ecf\u5178\u7edf\u8ba1\u529b\u5b66\u7684\u5206\u6790\u548c\u8ba1\u7b97\u65b9\u6cd5\u3002\u5f00\u53d1\u4e86\u673a\u5668\u8bc4\u5206\u7cfb\u7edf\uff0c\u5305\u62ec\u901a\u8fc7\u6b63\u89c4\u6392\u5e8f\u5904\u7406\u975e\u5bf9\u6613\u7b97\u5b50\u7684\u7b26\u53f7\u5904\u7406\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5728\u6240\u6709\u95ee\u9898\u4e0a\u90fd\u8868\u73b0\u6323\u624e\uff0c\u6700\u4f73\u6a21\u578bGPT5\u4ec5\u89e3\u51b330%\u7684\u95ee\u9898\uff0c17\u4e2a\u6a21\u578b\u7684\u5e73\u5747\u51c6\u786e\u7387\u4e3a11.4\u00b12.1%\u300218\u4e2a\u95ee\u9898\u6ca1\u6709\u88ab\u4efb\u4f55\u6a21\u578b\u89e3\u51b3\uff0c26\u4e2a\u95ee\u9898\u6700\u591a\u88ab\u4e00\u4e2a\u6a21\u578b\u89e3\u51b3\u3002\u672a\u89e3\u51b3\u7684\u95ee\u9898\u4e3b\u8981\u6d89\u53ca\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u3001\u53d8\u5206\u8499\u7279\u5361\u6d1b\u548cDMRG\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u7269\u7406\u63a8\u7406\u6280\u80fd\u4e0a\u7684\u663e\u8457\u5dee\u8ddd\uff0c\u7b54\u6848\u6709\u65f6\u8fdd\u53cd\u57fa\u672c\u5bf9\u79f0\u6027\u6216\u5177\u6709\u975e\u7269\u7406\u6807\u5ea6\u7ef4\u5ea6\u3002\u8be5\u57fa\u51c6\u5c06\u6307\u5bfc\u5f00\u53d1\u66f4\u5f3a\u5927\u7684AI\u7814\u7a76\u52a9\u624b\u548c\u5bfc\u5e08\u3002"}}
{"id": "2510.05583", "categories": ["cs.LG", "cs.DC", "68T07, 68T09", "I.2.6; I.2.8; I.2.10; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.05583", "abs": "https://arxiv.org/abs/2510.05583", "authors": ["Arindam Chowdhury", "Massimiliano Lupo Pasini"], "title": "When Does Global Attention Help? A Unified Empirical Study on Atomistic Graph Learning", "comment": "40 pages, 8 figures, 18 tables", "summary": "Graph neural networks (GNNs) are widely used as surrogates for costly\nexperiments and first-principles simulations to study the behavior of compounds\nat atomistic scale, and their architectural complexity is constantly increasing\nto enable the modeling of complex physics. While most recent GNNs combine more\ntraditional message passing neural networks (MPNNs) layers to model short-range\ninteractions with more advanced graph transformers (GTs) with global attention\nmechanisms to model long-range interactions, it is still unclear when global\nattention mechanisms provide real benefits over well-tuned MPNN layers due to\ninconsistent implementations, features, or hyperparameter tuning. We introduce\nthe first unified, reproducible benchmarking framework - built on HydraGNN -\nthat enables seamless switching among four controlled model classes: MPNN, MPNN\nwith chemistry/topology encoders, GPS-style hybrids of MPNN with global\nattention, and fully fused local - global models with encoders. Using seven\ndiverse open-source datasets for benchmarking across regression and\nclassification tasks, we systematically isolate the contributions of message\npassing, global attention, and encoder-based feature augmentation. Our study\nshows that encoder-augmented MPNNs form a robust baseline, while fused\nlocal-global models yield the clearest benefits for properties governed by\nlong-range interaction effects. We further quantify the accuracy - compute\ntrade-offs of attention, reporting its overhead in memory. Together, these\nresults establish the first controlled evaluation of global attention in\natomistic graph learning and provide a reproducible testbed for future model\ndevelopment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u6d88\u606f\u4f20\u9012\u4e0e\u5168\u5c40\u6ce8\u610f\u529b\u673a\u5236\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u53d1\u73b0\u5728\u539f\u5b50\u56fe\u5b66\u4e60\u4e2d\uff0c\u7f16\u7801\u5668\u589e\u5f3a\u7684MPNN\u5f62\u6210\u4e86\u7a33\u5065\u57fa\u7ebf\uff0c\u800c\u878d\u5408\u5c40\u90e8-\u5168\u5c40\u6a21\u578b\u5728\u957f\u7a0b\u4ea4\u4e92\u6548\u5e94\u4e3b\u5bfc\u7684\u5c5e\u6027\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5f53\u524d\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u4f46\u5168\u5c40\u6ce8\u610f\u529b\u673a\u5236\u76f8\u5bf9\u4e8e\u7cbe\u5fc3\u8c03\u4f18\u7684\u6d88\u606f\u4f20\u9012\u5c42\u7684\u5b9e\u9645\u4f18\u52bf\u5c1a\u4e0d\u660e\u786e\uff0c\u4e3b\u8981\u7531\u4e8e\u5b9e\u73b0\u3001\u7279\u5f81\u6216\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "method": "\u57fa\u4e8eHydraGNN\u6784\u5efa\u4e86\u9996\u4e2a\u7edf\u4e00\u3001\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u652f\u6301\u5728\u56db\u79cd\u53d7\u63a7\u6a21\u578b\u7c7b\u4e4b\u95f4\u65e0\u7f1d\u5207\u6362\uff1aMPNN\u3001\u5e26\u5316\u5b66/\u62d3\u6251\u7f16\u7801\u5668\u7684MPNN\u3001MPNN\u4e0e\u5168\u5c40\u6ce8\u610f\u529b\u6df7\u5408\u7684GPS\u98ce\u683c\u6a21\u578b\u3001\u4ee5\u53ca\u5e26\u7f16\u7801\u5668\u7684\u5b8c\u5168\u878d\u5408\u5c40\u90e8-\u5168\u5c40\u6a21\u578b\u3002", "result": "\u4f7f\u7528\u4e03\u4e2a\u4e0d\u540c\u7684\u5f00\u6e90\u6570\u636e\u96c6\u8fdb\u884c\u56de\u5f52\u548c\u5206\u7c7b\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u5206\u79bb\u4e86\u6d88\u606f\u4f20\u9012\u3001\u5168\u5c40\u6ce8\u610f\u529b\u548c\u7f16\u7801\u5668\u7279\u5f81\u589e\u5f3a\u7684\u8d21\u732e\u3002\u7f16\u7801\u5668\u589e\u5f3a\u7684MPNN\u5f62\u6210\u4e86\u7a33\u5065\u57fa\u7ebf\uff0c\u800c\u878d\u5408\u5c40\u90e8-\u5168\u5c40\u6a21\u578b\u5728\u957f\u7a0b\u4ea4\u4e92\u6548\u5e94\u4e3b\u5bfc\u7684\u5c5e\u6027\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u8fd9\u662f\u5bf9\u539f\u5b50\u56fe\u5b66\u4e60\u4e2d\u5168\u5c40\u6ce8\u610f\u529b\u7684\u9996\u6b21\u53d7\u63a7\u8bc4\u4f30\uff0c\u5efa\u7acb\u4e86\u6ce8\u610f\u529b\u7cbe\u5ea6-\u8ba1\u7b97\u6743\u8861\u7684\u91cf\u5316\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u672a\u6765\u6a21\u578b\u5f00\u53d1\u7684\u53ef\u590d\u73b0\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2510.05241", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.05241", "abs": "https://arxiv.org/abs/2510.05241", "authors": ["Mohammad Mahdi Ahmadi", "Erfan Yazdandoost Hamedani"], "title": "Simultaneous Learning and Optimization via Misspecified Saddle Point Problems", "comment": null, "summary": "We study a class of misspecified saddle point (SP) problems, where the\noptimization objective depends on an unknown parameter that must be learned\nconcurrently from data. Unlike existing studies that assume parameters are\nfully known or pre-estimated, our framework integrates optimization and\nlearning into a unified formulation, enabling a more flexible problem class. To\naddress this setting, we propose two algorithms based on the accelerated\nprimal-dual (APD) by Hamedani & Aybat 2021. In particular, we first analyze the\nnaive extension of the APD method by directly substituting the evolving\nparameter estimates into the primal-dual updates; then, we design a new\nlearning-aware variant of the APD method that explicitly accounts for parameter\ndynamics by adjusting the momentum updates. Both methods achieve a provable\nconvergence rate of $\\mathcal{O}(\\log K / K)$, while the learning-aware\napproach attains a tighter $\\mathcal{O}(1)$ constant and further benefits from\nan adaptive step-size selection enabled by a backtracking strategy.\nFurthermore, we extend the framework to problems where the learning problem\nadmits multiple optimal solutions, showing that our modified algorithm for a\nstructured setting achieves an $\\mathcal{O}(1/\\sqrt{K})$ rate. To demonstrate\npractical impact, we evaluate our methods on a misspecified portfolio\noptimization problem and show superior empirical performance compared to\nstate-of-the-art algorithms.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53c2\u6570\u9519\u914d\u7684\u978d\u70b9\u95ee\u9898\uff0c\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u52a0\u901f\u539f\u59cb\u5bf9\u5076\u65b9\u6cd5\u7684\u7b97\u6cd5\uff0c\u5c06\u4f18\u5316\u548c\u5b66\u4e60\u7edf\u4e00\u5230\u4e00\u4e2a\u6846\u67b6\u4e2d\uff0c\u6536\u655b\u901f\u7387\u4e3aO(logK/K)\uff0c\u5b66\u4e60\u611f\u77e5\u7248\u672c\u5177\u6709\u66f4\u7d27\u7684\u5e38\u6570\u9879\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5047\u8bbe\u53c2\u6570\u5b8c\u5168\u5df2\u77e5\u6216\u9884\u4f30\u8ba1\uff0c\u4f46\u5b9e\u9645\u4e2d\u53c2\u6570\u9700\u8981\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u3002\u672c\u6587\u65e8\u5728\u5c06\u4f18\u5316\u548c\u5b66\u4e60\u96c6\u6210\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\uff0c\u5904\u7406\u66f4\u7075\u6d3b\u7684\u95ee\u9898\u7c7b\u522b\u3002", "method": "\u57fa\u4e8eHamedani & Aybat 2021\u7684\u52a0\u901f\u539f\u59cb\u5bf9\u5076\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e24\u79cd\u7b97\u6cd5\uff1a1) \u76f4\u63a5\u5c06\u6f14\u5316\u53c2\u6570\u4f30\u8ba1\u4ee3\u5165\u539f\u59cb\u5bf9\u5076\u66f4\u65b0\u7684\u6734\u7d20\u6269\u5c55\uff1b2) \u901a\u8fc7\u8c03\u6574\u52a8\u91cf\u66f4\u65b0\u663e\u5f0f\u8003\u8651\u53c2\u6570\u52a8\u6001\u7684\u5b66\u4e60\u611f\u77e5\u53d8\u4f53\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u90fd\u5b9e\u73b0\u4e86O(logK/K)\u7684\u6536\u655b\u901f\u7387\uff0c\u5b66\u4e60\u611f\u77e5\u65b9\u6cd5\u83b7\u5f97\u66f4\u7d27\u7684O(1)\u5e38\u6570\u9879\uff0c\u5e76\u901a\u8fc7\u56de\u6eaf\u7b56\u7565\u5b9e\u73b0\u81ea\u9002\u5e94\u6b65\u957f\u9009\u62e9\u3002\u5728\u7ed3\u6784\u5316\u8bbe\u7f6e\u4e2d\uff0c\u6539\u8fdb\u7b97\u6cd5\u8fbe\u5230O(1/\u221aK)\u901f\u7387\u3002", "conclusion": "\u5728\u9519\u914d\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u7b97\u6cd5\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u5b9e\u8bc1\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u7edf\u4e00\u4f18\u5316\u5b66\u4e60\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.05261", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05261", "abs": "https://arxiv.org/abs/2510.05261", "authors": ["Yuezhu Xu", "S. Sivaranjani"], "title": "ECLipsE-Gen-Local: Efficient Compositional Local Lipschitz Estimates for Deep Neural Networks", "comment": null, "summary": "The Lipschitz constant is a key measure for certifying the robustness of\nneural networks to input perturbations. However, computing the exact constant\nis NP-hard, and standard approaches to estimate the Lipschitz constant involve\nsolving a large matrix semidefinite program (SDP) that scales poorly with\nnetwork size. Further, there is a potential to efficiently leverage local\ninformation on the input region to provide tighter Lipschitz estimates. We\naddress this problem here by proposing a compositional framework that yields\ntight yet scalable Lipschitz estimates for deep feedforward neural networks.\nSpecifically, we begin by developing a generalized SDP framework that is highly\nflexible, accommodating heterogeneous activation function slope, and allowing\nLipschitz estimates with respect to arbitrary input-output pairs and arbitrary\nchoices of sub-networks of consecutive layers. We then decompose this\ngeneralized SDP into a sequence of small sub-problems, with computational\ncomplexity that scales linearly with respect to the network depth. We also\ndevelop a variant that achieves near-instantaneous computation through\nclosed-form solutions to each sub-problem. All our algorithms are accompanied\nby theoretical guarantees on feasibility and validity. Next, we develop a\nseries of algorithms, termed as ECLipsE-Gen-Local, that effectively incorporate\nlocal information on the input. Our experiments demonstrate that our algorithms\nachieve substantial speedups over a multitude of benchmarks while producing\nsignificantly tighter Lipschitz bounds than global approaches. Moreover, we\nshow that our algorithms provide strict upper bounds for the Lipschitz constant\nwith values approaching the exact Jacobian from autodiff when the input region\nis small enough. Finally, we demonstrate the practical utility of our approach\nby showing that our Lipschitz estimates closely align with network robustness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ec4\u5408\u5f0f\u6846\u67b6\u6765\u8ba1\u7b97\u6df1\u5ea6\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684Lipschitz\u5e38\u6570\uff0c\u901a\u8fc7\u5206\u89e3\u5927\u578bSDP\u4e3a\u5c0f\u89c4\u6a21\u5b50\u95ee\u9898\u5b9e\u73b0\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u5e76\u5f00\u53d1\u4e86\u7ed3\u5408\u5c40\u90e8\u4fe1\u606f\u7684\u7b97\u6cd5\u4ee5\u83b7\u5f97\u66f4\u7d27\u7684Lipschitz\u8fb9\u754c\u3002", "motivation": "Lipschitz\u5e38\u6570\u662f\u8861\u91cf\u795e\u7ecf\u7f51\u7edc\u5bf9\u8f93\u5165\u6270\u52a8\u9c81\u68d2\u6027\u7684\u5173\u952e\u6307\u6807\uff0c\u4f46\u7cbe\u786e\u8ba1\u7b97\u662fNP\u96be\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u5229\u7528\u5c40\u90e8\u4fe1\u606f\u83b7\u5f97\u66f4\u7d27\u7684\u8fb9\u754c\u3002", "method": "\u5f00\u53d1\u4e86\u5e7f\u4e49SDP\u6846\u67b6\uff0c\u652f\u6301\u5f02\u8d28\u6fc0\u6d3b\u51fd\u6570\u548c\u4efb\u610f\u5b50\u7f51\u7edc\u9009\u62e9\uff1b\u5c06\u8be5SDP\u5206\u89e3\u4e3a\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u5c0f\u5b50\u95ee\u9898\u5e8f\u5217\uff1b\u5f00\u53d1\u4e86\u57fa\u4e8e\u95ed\u5f0f\u89e3\u7684\u5feb\u901f\u8ba1\u7b97\u53d8\u4f53\uff1b\u63d0\u51fa\u4e86\u7ed3\u5408\u5c40\u90e8\u4fe1\u606f\u7684ECLipsE-Gen-Local\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7b97\u6cd5\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u52a0\u901f\uff0c\u4ea7\u751f\u7684Lipschitz\u8fb9\u754c\u6bd4\u5168\u5c40\u65b9\u6cd5\u66f4\u7d27\uff0c\u5f53\u8f93\u5165\u533a\u57df\u8db3\u591f\u5c0f\u65f6\u80fd\u63a5\u8fd1\u81ea\u52a8\u5fae\u5206\u7684\u7cbe\u786eJacobian\u503c\uff0c\u4e14Lipschitz\u4f30\u8ba1\u4e0e\u7f51\u7edc\u9c81\u68d2\u6027\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ec4\u5408\u5f0f\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7d27\u7684Lipschitz\u4f30\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u9c81\u68d2\u6027\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.05278", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05278", "abs": "https://arxiv.org/abs/2510.05278", "authors": ["Paloma Garc\u00eda-de-Herreros", "Philipp Slusallek", "Dietrich Klakow", "Vagrant Gautam"], "title": "Decoding Partial Differential Equations: Cross-Modal Adaptation of Decoder-only Models to PDEs", "comment": null, "summary": "Large language models have shown great success on natural language tasks in\nrecent years, but they have also shown great promise when adapted to new\nmodalities, e.g., for scientific machine learning tasks. Even though\ndecoder-only models are more popular within NLP and scale exceedingly well at\ngenerating natural language, most proposed approaches for cross-modal\nadaptation focus on encoder-only models, raising the question of how model\narchitecture affects these approaches. In this paper, we therefore perform a\nseries of ablation studies to answer this question, systematically comparing\nencoder-only and decoder-only models on cross-modal adaptation for\ntime-dependent simulation tasks based on partial differential equations (PDEs).\nWe find that decoder-only models are far worse than encoder-only models, when\nexisting approaches are applied unmodified. In contrast to several other\ndomains, scaling decoder-only models also does not help. To harness the\npotential of decoder-only models in this context, we introduce two novel\napproaches, Parallel Flipping and Sequence Doubling, attempting to mimic\nbidirectionality in autoregressive models. Both our methods improve overall\nperformance using decoder-only models for all tasks and all cross-model\nadaptation methods, closing the gap to encoder-only model performance. We hope\nthat our findings broaden the spectrum of models used on cross-modal adaptation\ntasks to further scientific ML.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u6bd4\u8f83\u4e86\u7f16\u7801\u5668\u4e13\u7528\u548c\u89e3\u7801\u5668\u4e13\u7528\u6a21\u578b\u5728\u8de8\u6a21\u6001\u9002\u5e94\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u89e3\u7801\u5668\u6a21\u578b\u8868\u73b0\u8f83\u5dee\u4e14\u6269\u5c55\u65e0\u76ca\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u65b9\u6cd5\uff08\u5e76\u884c\u7ffb\u8f6c\u548c\u5e8f\u5217\u52a0\u500d\uff09\u6765\u6539\u5584\u89e3\u7801\u5668\u6a21\u578b\u6027\u80fd\uff0c\u7f29\u5c0f\u4e86\u4e0e\u7f16\u7801\u5668\u6a21\u578b\u7684\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1\u89e3\u7801\u5668\u4e13\u7528\u6a21\u578b\u5728NLP\u9886\u57df\u8868\u73b0\u4f18\u5f02\u4e14\u6269\u5c55\u6027\u597d\uff0c\u4f46\u5927\u591a\u6570\u8de8\u6a21\u6001\u9002\u5e94\u65b9\u6cd5\u90fd\u4e13\u6ce8\u4e8e\u7f16\u7801\u5668\u4e13\u7528\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u6a21\u578b\u67b6\u6784\u5982\u4f55\u5f71\u54cd\u8de8\u6a21\u6001\u9002\u5e94\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u57fa\u4e8e\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u65f6\u95f4\u76f8\u5173\u6a21\u62df\u4efb\u52a1\u3002", "method": "\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u6d88\u878d\u7814\u7a76\uff0c\u7cfb\u7edf\u6bd4\u8f83\u7f16\u7801\u5668\u4e13\u7528\u548c\u89e3\u7801\u5668\u4e13\u7528\u6a21\u578b\u5728\u8de8\u6a21\u6001\u9002\u5e94\u4e2d\u7684\u8868\u73b0\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u65b9\u6cd5\uff1a\u5e76\u884c\u7ffb\u8f6c\u548c\u5e8f\u5217\u52a0\u500d\uff0c\u8bd5\u56fe\u5728\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u6a21\u62df\u53cc\u5411\u6027\u3002", "result": "\u53d1\u73b0\u5f53\u73b0\u6709\u65b9\u6cd5\u672a\u7ecf\u4fee\u6539\u65f6\uff0c\u89e3\u7801\u5668\u4e13\u7528\u6a21\u578b\u7684\u8868\u73b0\u8fdc\u4e0d\u5982\u7f16\u7801\u5668\u4e13\u7528\u6a21\u578b\u3002\u4e0e\u591a\u4e2a\u5176\u4ed6\u9886\u57df\u4e0d\u540c\uff0c\u6269\u5c55\u89e3\u7801\u5668\u6a21\u578b\u4e5f\u65e0\u6d4e\u4e8e\u4e8b\u3002\u63d0\u51fa\u7684\u4e24\u79cd\u65b0\u65b9\u6cd5\u5728\u6240\u6709\u4efb\u52a1\u548c\u6240\u6709\u8de8\u6a21\u578b\u9002\u5e94\u65b9\u6cd5\u4e2d\u90fd\u63d0\u9ad8\u4e86\u89e3\u7801\u5668\u4e13\u7528\u6a21\u578b\u7684\u6574\u4f53\u6027\u80fd\uff0c\u7f29\u5c0f\u4e86\u4e0e\u7f16\u7801\u5668\u4e13\u7528\u6a21\u578b\u6027\u80fd\u7684\u5dee\u8ddd\u3002", "conclusion": "\u672c\u6587\u7684\u7814\u7a76\u53d1\u73b0\u62d3\u5bbd\u4e86\u7528\u4e8e\u8de8\u6a21\u6001\u9002\u5e94\u4efb\u52a1\u7684\u6a21\u578b\u8303\u56f4\uff0c\u6709\u671b\u8fdb\u4e00\u6b65\u63a8\u52a8\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u6539\u5584\u4e86\u89e3\u7801\u5668\u6a21\u578b\u5728\u8de8\u6a21\u6001\u9002\u5e94\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2510.05285", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05285", "abs": "https://arxiv.org/abs/2510.05285", "authors": ["Rui Lin", "Yiwen Zhang", "Zhicheng Peng", "Minghao Lyu"], "title": "Adjusting the Output of Decision Transformer with Action Gradient", "comment": null, "summary": "Decision Transformer (DT), which integrates reinforcement learning (RL) with\nthe transformer model, introduces a novel approach to offline RL. Unlike\nclassical algorithms that take maximizing cumulative discounted rewards as\nobjective, DT instead maximizes the likelihood of actions. This paradigm shift,\nhowever, presents two key challenges: stitching trajectories and extrapolation\nof action. Existing methods, such as substituting specific tokens with\npredictive values and integrating the Policy Gradient (PG) method, address\nthese challenges individually but fail to improve performance stably when\ncombined due to inherent instability. To address this, we propose Action\nGradient (AG), an innovative methodology that directly adjusts actions to\nfulfill a function analogous to that of PG, while also facilitating efficient\nintegration with token prediction techniques. AG utilizes the gradient of the\nQ-value with respect to the action to optimize the action. The empirical\nresults demonstrate that our method can significantly enhance the performance\nof DT-based algorithms, with some results achieving state-of-the-art levels.", "AI": {"tldr": "\u63d0\u51faAction Gradient\u65b9\u6cd5\u6765\u89e3\u51b3Decision Transformer\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8f68\u8ff9\u62fc\u63a5\u548c\u52a8\u4f5c\u5916\u63a8\u95ee\u9898\uff0c\u901a\u8fc7\u76f4\u63a5\u8c03\u6574\u52a8\u4f5c\u6765\u66ff\u4ee3\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347DT\u7b97\u6cd5\u6027\u80fd\u3002", "motivation": "Decision Transformer\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0eTransformer\u7ed3\u5408\uff0c\u4f46\u9762\u4e34\u8f68\u8ff9\u62fc\u63a5\u548c\u52a8\u4f5c\u5916\u63a8\u4e24\u5927\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5355\u72ec\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u4f46\u7ec4\u5408\u65f6\u6027\u80fd\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faAction Gradient\u65b9\u6cd5\uff0c\u5229\u7528Q\u503c\u5bf9\u52a8\u4f5c\u7684\u68af\u5ea6\u6765\u4f18\u5316\u52a8\u4f5c\uff0c\u5b9e\u73b0\u4e0e\u7b56\u7565\u68af\u5ea6\u7c7b\u4f3c\u7684\u529f\u80fd\uff0c\u5e76\u80fd\u4e0etoken\u9884\u6d4b\u6280\u672f\u9ad8\u6548\u96c6\u6210\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347DT\u57fa\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u90e8\u5206\u7ed3\u679c\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "Action Gradient\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86DT\u7684\u6311\u6218\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u7a33\u5b9a\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05286", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.05286", "abs": "https://arxiv.org/abs/2510.05286", "authors": ["Joel Wendin", "Erik G. Larsson", "Claudio Altafini"], "title": "Computing frustration and near-monotonicity in deep neural networks", "comment": null, "summary": "For the signed graph associated to a deep neural network, one can compute the\nfrustration level, i.e., test how close or distant the graph is to structural\nbalance. For all the pretrained deep convolutional neural networks we consider,\nwe find that the frustration is always less than expected from null models.\nFrom a statistical physics point of view, and in particular in reference to an\nIsing spin glass model, the reduced frustration indicates that the amount of\ndisorder encoded in the network is less than in the null models. From a\nfunctional point of view, low frustration (i.e., proximity to structural\nbalance) means that the function representing the network behaves\nnear-monotonically, i.e., more similarly to a monotone function than in the\nnull models. Evidence of near-monotonic behavior along the partial order\ndetermined by frustration is observed for all networks we consider. This\nconfirms that the class of deep convolutional neural networks tends to have a\nmore ordered behavior than expected from null models, and suggests a novel form\nof implicit regularization.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6bd4\u96f6\u6a21\u578b\u5177\u6709\u66f4\u4f4e\u7684\u632b\u6298\u6c34\u5e73\uff0c\u8868\u660e\u7f51\u7edc\u66f4\u63a5\u8fd1\u7ed3\u6784\u5e73\u8861\uff0c\u8868\u73b0\u51fa\u8fd1\u5355\u8c03\u884c\u4e3a\uff0c\u8fd9\u63ed\u793a\u4e86\u4e00\u79cd\u65b0\u7684\u9690\u5f0f\u6b63\u5219\u5316\u5f62\u5f0f\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u56fe\u7ed3\u6784\u7684\u632b\u6298\u6c34\u5e73\uff0c\u4ee5\u4e86\u89e3\u7f51\u7edc\u7684\u7ed3\u6784\u5e73\u8861\u7a0b\u5ea6\u548c\u529f\u80fd\u884c\u4e3a\u7279\u5f81\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5bf9\u5e94\u7b26\u53f7\u56fe\u7684\u632b\u6298\u6c34\u5e73\uff0c\u5e76\u4e0e\u96f6\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u6240\u6709\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u90fd\u663e\u793a\u51fa\u6bd4\u96f6\u6a21\u578b\u66f4\u4f4e\u7684\u632b\u6298\u6c34\u5e73\uff0c\u8868\u660e\u7f51\u7edc\u66f4\u6709\u5e8f\uff0c\u8868\u73b0\u51fa\u8fd1\u5355\u8c03\u884c\u4e3a\u3002", "conclusion": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u503e\u5411\u4e8e\u8868\u73b0\u51fa\u6bd4\u9884\u671f\u66f4\u6709\u5e8f\u7684\u884c\u4e3a\uff0c\u8fd9\u6697\u793a\u4e86\u4e00\u79cd\u65b0\u7684\u9690\u5f0f\u6b63\u5219\u5316\u673a\u5236\u3002"}}
{"id": "2510.05288", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.05288", "abs": "https://arxiv.org/abs/2510.05288", "authors": ["Ruoxing Yang"], "title": "DP-Adam-AC: Privacy-preserving Fine-Tuning of Localizable Language Models Using Adam Optimization with Adaptive Clipping", "comment": null, "summary": "Large language models (LLMs) such as ChatGPT have evolved into powerful and\nubiquitous tools. Fine-tuning on small datasets allows LLMs to acquire\nspecialized skills for specific tasks efficiently. Although LLMs provide great\nutility in both general and task-specific use cases, they are limited by two\nsecurity-related concerns. First, traditional LLM hardware requirements make\nthem infeasible to run locally on consumer-grade devices. A remote network\nconnection with the LLM provider's server is usually required, making the\nsystem vulnerable to network attacks. Second, fine-tuning an LLM for a\nsensitive task may involve sensitive data. Non-private fine-tuning algorithms\nproduce models vulnerable to training data reproduction attacks. Our work\naddresses these security concerns by enhancing differentially private\noptimization algorithms and applying them to fine-tune localizable language\nmodels. We introduce adaptable gradient clipping along with other engineering\nenhancements to the standard DP-Adam optimizer to create DP-Adam-AC. We use our\noptimizer to fine-tune examples of two localizable LLM designs, small language\nmodel (Qwen2.5-0.5B) and 1.58 bit quantization (Bitnet-b1.58-2B). We\ndemonstrate promising improvements in loss through experimentation with two\nsynthetic datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u5dee\u5206\u9690\u79c1\u4f18\u5316\u7b97\u6cd5DP-Adam-AC\uff0c\u7528\u4e8e\u5728\u672c\u5730\u5316\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u5b89\u5168\u5fae\u8c03\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfLLM\u7684\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e24\u4e2a\u5b89\u5168\u5173\u5207\uff1a1\uff09\u4f20\u7edfLLM\u786c\u4ef6\u8981\u6c42\u9ad8\uff0c\u65e0\u6cd5\u5728\u6d88\u8d39\u7ea7\u8bbe\u5907\u672c\u5730\u8fd0\u884c\uff0c\u4f9d\u8d56\u8fdc\u7a0b\u8fde\u63a5\u6613\u53d7\u7f51\u7edc\u653b\u51fb\uff1b2\uff09\u654f\u611f\u4efb\u52a1\u5fae\u8c03\u6d89\u53ca\u654f\u611f\u6570\u636e\uff0c\u975e\u79c1\u6709\u5fae\u8c03\u7b97\u6cd5\u6613\u53d7\u8bad\u7ec3\u6570\u636e\u518d\u73b0\u653b\u51fb\u3002", "method": "\u5f15\u5165\u53ef\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u548c\u5176\u4ed6\u5de5\u7a0b\u589e\u5f3a\u5230\u6807\u51c6DP-Adam\u4f18\u5316\u5668\uff0c\u521b\u5efaDP-Adam-AC\u4f18\u5316\u5668\uff0c\u7528\u4e8e\u5fae\u8c03\u4e24\u79cd\u672c\u5730\u5316LLM\u8bbe\u8ba1\uff1a\u5c0f\u8bed\u8a00\u6a21\u578b(Qwen2.5-0.5B)\u548c1.58\u4f4d\u91cf\u5316\u6a21\u578b(Bitnet-b1.58-2B)\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u5408\u6210\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u5728\u635f\u5931\u51fd\u6570\u65b9\u9762\u7684\u6709\u524d\u666f\u7684\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u589e\u5f3a\u5dee\u5206\u9690\u79c1\u4f18\u5316\u7b97\u6cd5\u548c\u672c\u5730\u5316\u8bed\u8a00\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u7684\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u9690\u79c1\u5b89\u5168\u95ee\u9898\uff0c\u4e3a\u5b89\u5168\u654f\u611f\u573a\u666f\u4e0b\u7684LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.05309", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05309", "abs": "https://arxiv.org/abs/2510.05309", "authors": ["Kevin Player"], "title": "Gamma Mixture Modeling for Cosine Similarity in Small Language Models", "comment": "16 pages, 8 figures", "summary": "We study the cosine similarity of sentence transformer embeddings and observe\nthat they are well modeled by gamma mixtures. From a fixed corpus, we measure\nsimilarities between all document embeddings and a reference query embedding.\nEmpirically we find that these distributions are often well captured by a gamma\ndistribution shifted and truncated to [-1,1], and in many cases, by a gamma\nmixture. We propose a heuristic model in which a hierarchical clustering of\ntopics naturally leads to a gamma-mixture structure in the similarity scores.\nFinally, we outline an expectation-maximization algorithm for fitting shifted\ngamma mixtures, which provides a practical tool for modeling similarity\ndistributions.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u53e5\u5b50Transformer\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u9075\u5faa\u4f3d\u9a6c\u6df7\u5408\u5206\u5e03\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684\u542f\u53d1\u5f0f\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u4e86\u62df\u5408\u79fb\u4f4d\u4f3d\u9a6c\u6df7\u5408\u7684EM\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u53e5\u5b50Transformer\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5206\u5e03\u7279\u6027\uff0c\u63a2\u7d22\u5176\u7edf\u8ba1\u89c4\u5f8b\uff0c\u4e3a\u76f8\u4f3c\u5ea6\u5efa\u6a21\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u6587\u6863\u5d4c\u5165\u4e0e\u67e5\u8be2\u5d4c\u5165\u4e4b\u95f4\u7684\u6240\u6709\u76f8\u4f3c\u5ea6\uff0c\u5206\u6790\u5176\u5206\u5e03\u7279\u5f81\uff1b\u63d0\u51fa\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7684\u542f\u53d1\u5f0f\u6a21\u578b\uff1b\u5f00\u53d1\u62df\u5408\u79fb\u4f4d\u4f3d\u9a6c\u6df7\u5408\u7684\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u3002", "result": "\u53d1\u73b0\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5206\u5e03\u901a\u5e38\u80fd\u88ab\u79fb\u4f4d\u5e76\u622a\u65ad\u5230[-1,1]\u7684\u4f3d\u9a6c\u5206\u5e03\u5f88\u597d\u5730\u5efa\u6a21\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u4f3d\u9a6c\u6df7\u5408\u6a21\u578b\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u53e5\u5b50Transformer\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u9075\u5faa\u4f3d\u9a6c\u6df7\u5408\u5206\u5e03\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u548c\u7b97\u6cd5\u4e3a\u76f8\u4f3c\u5ea6\u5206\u5e03\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.05317", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.05317", "abs": "https://arxiv.org/abs/2510.05317", "authors": ["Zhenyu Liu", "Varun Ojha"], "title": "RegMix: Adversarial Mutual and Generalization Regularization for Enhancing DNN Robustness", "comment": null, "summary": "Adversarial training is the most effective defense against adversarial\nattacks. The effectiveness of the adversarial attacks has been on the design of\nits loss function and regularization term. The most widely used loss function\nin adversarial training is cross-entropy and mean squared error (MSE) as its\nregularization objective. However, MSE enforces overly uniform optimization\nbetween two output distributions during training, which limits its robustness\nin adversarial training scenarios. To address this issue, we revisit the idea\nof mutual learning (originally designed for knowledge distillation) and propose\ntwo novel regularization strategies tailored for adversarial training: (i)\nweighted adversarial mutual regularization and (ii) adversarial generalization\nregularization. In the former, we formulate a decomposed adversarial mutual\nKullback-Leibler divergence (KL-divergence) loss, which allows flexible control\nover the optimization process by assigning unequal weights to the main and\nauxiliary objectives. In the latter, we introduce an additional clean target\ndistribution into the adversarial training objective, improving generalization\nand enhancing model robustness. Extensive experiments demonstrate that our\nproposed methods significantly improve adversarial robustness compared to\nexisting regularization-based approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u65b0\u9896\u7684\u6b63\u5219\u5316\u7b56\u7565\u6765\u6539\u8fdb\u5bf9\u6297\u8bad\u7ec3\uff1a\u52a0\u6743\u5bf9\u6297\u4e92\u6b63\u5219\u5316\u548c\u5bf9\u6297\u6cdb\u5316\u6b63\u5219\u5316\uff0c\u901a\u8fc7\u5206\u89e3KL\u6563\u5ea6\u635f\u5931\u548c\u5f15\u5165\u5e72\u51c0\u76ee\u6807\u5206\u5e03\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u5bf9\u6297\u8bad\u7ec3\u4e2d\u4f7f\u7528\u7684\u5747\u65b9\u8bef\u5dee\u6b63\u5219\u5316\u5f3a\u5236\u4e24\u4e2a\u8f93\u51fa\u5206\u5e03\u5747\u5300\u4f18\u5316\uff0c\u9650\u5236\u4e86\u9c81\u68d2\u6027\u3002\u9700\u8981\u66f4\u7075\u6d3b\u7684\u4f18\u5316\u65b9\u6cd5\u6765\u63d0\u5347\u5bf9\u6297\u8bad\u7ec3\u6548\u679c\u3002", "method": "1. \u52a0\u6743\u5bf9\u6297\u4e92\u6b63\u5219\u5316\uff1a\u5236\u5b9a\u5206\u89e3\u7684\u5bf9\u6297\u4e92KL\u6563\u5ea6\u635f\u5931\uff0c\u4e3a\u4e3b\u76ee\u6807\u548c\u8f85\u52a9\u76ee\u6807\u5206\u914d\u4e0d\u7b49\u6743\u91cd\uff1b2. \u5bf9\u6297\u6cdb\u5316\u6b63\u5219\u5316\uff1a\u5728\u5bf9\u6297\u8bad\u7ec3\u76ee\u6807\u4e2d\u5f15\u5165\u989d\u5916\u7684\u5e72\u51c0\u76ee\u6807\u5206\u5e03\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u6b63\u5219\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u79cd\u6b63\u5219\u5316\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5bf9\u6297\u8bad\u7ec3\u4e2dMSE\u6b63\u5219\u5316\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u66f4\u7075\u6d3b\u7684\u4f18\u5316\u63a7\u5236\u548c\u5f15\u5165\u5e72\u51c0\u76ee\u6807\u5206\u5e03\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.05329", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.05329", "abs": "https://arxiv.org/abs/2510.05329", "authors": ["Qian Wang", "Mohammad N. Bisheh", "Kamran Paynabar"], "title": "Tensor-on-tensor Regression Neural Networks for Process Modeling with High-dimensional Data", "comment": null, "summary": "Modern sensing and metrology systems now stream terabytes of heterogeneous,\nhigh-dimensional (HD) data profiles, images, and dense point clouds, whose\nnatural representation is multi-way tensors. Understanding such data requires\nregression models that preserve tensor geometry, yet remain expressive enough\nto capture the pronounced nonlinear interactions that dominate many industrial\nand mechanical processes. Existing tensor-based regressors meet the first\nrequirement but remain essentially linear. Conversely, conventional neural\nnetworks offer nonlinearity only after flattening, thereby discarding spatial\nstructure and incurring prohibitive parameter counts. This paper introduces a\nTensor-on-Tensor Regression Neural Network (TRNN) that unifies these two\nparadigms.", "AI": {"tldr": "\u63d0\u51fa\u4e86TRNN\u6a21\u578b\uff0c\u5c06\u5f20\u91cf\u56de\u5f52\u4e0e\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u5f20\u91cf\u51e0\u4f55\u7ed3\u6784\u7684\u540c\u65f6\u5b9e\u73b0\u975e\u7ebf\u6027\u5efa\u6a21", "motivation": "\u73b0\u4ee3\u4f20\u611f\u7cfb\u7edf\u4ea7\u751f\u9ad8\u7ef4\u5f20\u91cf\u6570\u636e\uff0c\u9700\u8981\u65e2\u80fd\u4fdd\u6301\u5f20\u91cf\u51e0\u4f55\u7ed3\u6784\u53c8\u80fd\u6355\u6349\u975e\u7ebf\u6027\u4ea4\u4e92\u7684\u56de\u5f52\u6a21\u578b\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u7ebf\u6027\u8981\u4e48\u7834\u574f\u7ed3\u6784", "method": "\u5f00\u53d1\u4e86\u5f20\u91cf\u5bf9\u5f20\u91cf\u56de\u5f52\u795e\u7ecf\u7f51\u7edc(TRNN)\uff0c\u7edf\u4e00\u4e86\u5f20\u91cf\u56de\u5f52\u548c\u795e\u7ecf\u7f51\u7edc\u4e24\u79cd\u8303\u5f0f", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e", "conclusion": "TRNN\u6a21\u578b\u6210\u529f\u7edf\u4e00\u4e86\u5f20\u91cf\u51e0\u4f55\u4fdd\u6301\u548c\u975e\u7ebf\u6027\u5efa\u6a21\u4e24\u4e2a\u5173\u952e\u9700\u6c42"}}
{"id": "2510.05342", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05342", "abs": "https://arxiv.org/abs/2510.05342", "authors": ["Hyung Gyu Rho"], "title": "Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization", "comment": null, "summary": "Direct Preference Optimization (DPO) has emerged as a simple and effective\nmethod for aligning large language models. However, its reliance on a fixed\ntemperature parameter leads to suboptimal training on diverse preference data,\ncausing overfitting on easy examples and under-learning from informative ones.\nRecent methods have emerged to counter this. While IPO addresses general\noverfitting, its uniform regularization can be overly conservative. The more\ntargeted approach of $\\beta$-DPO suffers from its own limitations: its\nbatch-level adaptation applies a single, compromised temperature to\nmixed-margin pairs, its linear update rule can produce unstable negative\n$\\beta$ values, and its filtering mechanism discards potentially useful\ntraining signals. In this work, we introduce Margin-Adaptive Direct Preference\nOptimization (MADPO), a method that provides a stable, data-preserving, and\ninstance-level solution. MADPO employs a practical two-step approach: it first\ntrains a reward model to estimate preference margins and then uses these\nmargins to apply a continuous, adaptive weight to the DPO loss for each\nindividual training sample. This re-weighting scheme creates an effective\ntarget margin that is amplified for hard pairs and dampened for easy pairs,\nallowing for granular control over the learning signal. We provide a\ncomprehensive theoretical analysis, proving that MADPO has a well-behaved\noptimization landscape and is robust to reward model estimation errors. We\nvalidate our theory with experiments on a sentiment generation task, where\nMADPO consistently and significantly outperforms strong baselines across\ndatasets of varying quality. It achieves performance gains of up to +33.3\\% on\nHigh Quality data and +10.5\\% on Low Quality data over the next-best method.\nOur results establish MADPO as a more robust and principled approach to\npreference alignment.", "AI": {"tldr": "MADPO\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u4f8b\u7ea7\u7684\u81ea\u9002\u5e94\u6743\u91cd\u89e3\u51b3DPO\u56fa\u5b9a\u6e29\u5ea6\u53c2\u6570\u7684\u95ee\u9898\uff0c\u5728\u60c5\u611f\u751f\u6210\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfDPO\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u6e29\u5ea6\u53c2\u6570\uff0c\u5bfc\u81f4\u5728\u591a\u6837\u5316\u504f\u597d\u6570\u636e\u4e0a\u8bad\u7ec3\u6548\u679c\u4e0d\u4f73\u2014\u2014\u5bb9\u6613\u6837\u672c\u8fc7\u62df\u5408\uff0c\u800c\u4fe1\u606f\u91cf\u5927\u7684\u6837\u672c\u5b66\u4e60\u4e0d\u8db3\u3002\u73b0\u6709\u6539\u8fdb\u65b9\u6cd5\u5982IPO\u548c\u03b2-DPO\u5404\u6709\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u9996\u5148\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u4f30\u8ba1\u504f\u597d\u8fb9\u754c\uff0c\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u8fb9\u754c\u4e3a\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u7684DPO\u635f\u5931\u5e94\u7528\u8fde\u7eed\u81ea\u9002\u5e94\u6743\u91cd\u3002\u8fd9\u79cd\u91cd\u52a0\u6743\u65b9\u6848\u5bf9\u56f0\u96be\u6837\u672c\u653e\u5927\u5b66\u4e60\u4fe1\u53f7\uff0c\u5bf9\u5bb9\u6613\u6837\u672c\u51cf\u5f31\u4fe1\u53f7\u3002", "result": "\u5728\u60c5\u611f\u751f\u6210\u4efb\u52a1\u4e2d\uff0cMADPO\u5728\u4e0d\u540c\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9ad8\u8d28\u91cf\u6570\u636e\u4e0a\u6027\u80fd\u63d0\u5347\u8fbe+33.3%\uff0c\u5728\u4f4e\u8d28\u91cf\u6570\u636e\u4e0a\u63d0\u5347+10.5%\u3002", "conclusion": "MADPO\u4e3a\u504f\u597d\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7a33\u5065\u548c\u539f\u5219\u6027\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u4f18\u5316\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u5bf9\u5956\u52b1\u6a21\u578b\u4f30\u8ba1\u8bef\u5dee\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.05351", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05351", "abs": "https://arxiv.org/abs/2510.05351", "authors": ["Jinghao Cao", "Qin Li", "Mengnan Du", "Haimin Wang", "Bo Shen"], "title": "Physics-informed Attention-enhanced Fourier Neural Operator for Solar Magnetic Field Extrapolations", "comment": "10 pages; accepted as workshop paper in ICDM 2025;\n  https://github.com/Autumnstar-cjh/PIANO", "summary": "We propose Physics-informed Attention-enhanced Fourier Neural Operator\n(PIANO) to solve the Nonlinear Force-Free Field (NLFFF) problem in solar\nphysics. Unlike conventional approaches that rely on iterative numerical\nmethods, our proposed PIANO directly learns the 3D magnetic field structure\nfrom 2D boundary conditions. Specifically, PIANO integrates Efficient Channel\nAttention (ECA) mechanisms with Dilated Convolutions (DC), which enhances the\nmodel's ability to capture multimodal input by prioritizing critical channels\nrelevant to the magnetic field's variations. Furthermore, we apply\nphysics-informed loss by enforcing the force-free and divergence-free\nconditions in the training process so that our prediction is consistent with\nunderlying physics with high accuracy. Experimental results on the ISEE NLFFF\ndataset show that our PIANO not only outperforms state-of-the-art neural\noperators in terms of accuracy but also shows strong consistency with the\nphysical characteristics of NLFFF data across magnetic fields reconstructed\nfrom various solar active regions. The GitHub of this project is available\nhttps://github.com/Autumnstar-cjh/PIANO", "AI": {"tldr": "\u63d0\u51fa\u4e86PIANO\u6a21\u578b\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u589e\u5f3a\u7684\u6ce8\u610f\u529b\u673a\u5236\u76f4\u63a5\u5b66\u4e60\u4ece2D\u8fb9\u754c\u6761\u4ef6\u52303D\u78c1\u573a\u7ed3\u6784\u7684\u6620\u5c04\uff0c\u89e3\u51b3\u4e86\u592a\u9633\u7269\u7406\u4e2d\u7684\u975e\u7ebf\u6027\u65e0\u529b\u573a\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u8fed\u4ee3\u6570\u503c\u65b9\u6cd5\u6c42\u89e3\u975e\u7ebf\u6027\u65e0\u529b\u573a\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u4e14\u7b26\u5408\u7269\u7406\u7ea6\u675f\u7684\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u9ad8\u6548\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u548c\u6269\u5f20\u5377\u79ef\uff0c\u589e\u5f3a\u6a21\u578b\u6355\u6349\u591a\u6a21\u6001\u8f93\u5165\u7684\u80fd\u529b\uff1b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u65e0\u529b\u573a\u548c\u65e0\u6563\u5ea6\u6761\u4ef6\u7684\u7269\u7406\u4fe1\u606f\u635f\u5931\u6765\u4fdd\u8bc1\u9884\u6d4b\u7ed3\u679c\u7b26\u5408\u7269\u7406\u89c4\u5f8b\u3002", "result": "\u5728ISEE NLFFF\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPIANO\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u7b97\u5b50\uff0c\u5e76\u5728\u91cd\u5efa\u5404\u79cd\u592a\u9633\u6d3b\u52a8\u533a\u78c1\u573a\u65f6\u5c55\u73b0\u51fa\u4e0eNLFFF\u6570\u636e\u7269\u7406\u7279\u6027\u7684\u5f3a\u4e00\u81f4\u6027\u3002", "conclusion": "PIANO\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7269\u7406\u4e00\u81f4\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u76f4\u63a5\u4ece2D\u8fb9\u754c\u6761\u4ef6\u51c6\u786e\u91cd\u5efa3D\u78c1\u573a\u7ed3\u6784\uff0c\u5728\u592a\u9633\u7269\u7406\u7814\u7a76\u4e2d\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.05361", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05361", "abs": "https://arxiv.org/abs/2510.05361", "authors": ["Alex Iacob", "Andrej Jovanovic", "Mher Safaryan", "Meghdad Kurmanji", "Lorenzo Sani", "Samuel Horv\u00e1th", "William F. Shen", "Xinchi Qiu", "Nicholas D. Lane"], "title": "MT-DAO: Multi-Timescale Distributed Adaptive Optimizers with Local Updates", "comment": "Submitted to the ICLR 2026 Conference", "summary": "Training large models with distributed data parallelism (DDP) requires\nfrequent communication of gradients across workers, which can saturate\nbandwidth. Infrequent communication strategies (e.g., Local SGD) reduce this\noverhead but, when applied to adaptive optimizers, often suffer a performance\ngap relative to fully synchronous DDP. We trace this gap to a time-scale\nmismatch: the optimizer's fast-moving momentum, tuned for frequent updates,\ndecays too quickly to smooth gradients over long intervals, leading to\nnoise-dominated optimization. To address this, we propose MT-DAO, a family of\noptimizers that employs multiple slow- and fast-moving first momenta or the\ngradient to track update dynamics across different time scales, for which we\nprovide the first convergence guarantees. Empirically, for language-model\npre-training, this eliminates the performance gap with DDP, outperforming\ninfrequent-communication baselines in perplexity and reducing iso-token\nwall-clock time by 6-27% on Ethernet interconnects. At the 720M scale, MT-DAO\nreaches a target perplexity in 24% fewer steps and 35% less time than the\nsingle-momentum DDP baseline. MT-DAO enables effective cross-datacenter\ntraining and training over wide geographic areas.", "AI": {"tldr": "\u63d0\u51fa\u4e86MT-DAO\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u4f7f\u7528\u591a\u4e2a\u5feb\u6162\u52a8\u91cf\u6765\u89e3\u51b3\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u4e0d\u9891\u7e41\u901a\u4fe1\u5bfc\u81f4\u7684\u6027\u80fd\u5dee\u8ddd\u95ee\u9898", "motivation": "\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u4e2d\u9891\u7e41\u7684\u68af\u5ea6\u901a\u4fe1\u4f1a\u9971\u548c\u5e26\u5bbd\uff0c\u4e0d\u9891\u7e41\u901a\u4fe1\u7b56\u7565(\u5982Local SGD)\u5728\u81ea\u9002\u5e94\u4f18\u5316\u5668\u4e0a\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u8fd9\u6e90\u4e8e\u4f18\u5316\u5668\u52a8\u91cf\u4e0e\u66f4\u65b0\u9891\u7387\u7684\u65f6\u95f4\u5c3a\u5ea6\u4e0d\u5339\u914d", "method": "MT-DAO\u4f18\u5316\u5668\u91c7\u7528\u591a\u4e2a\u5feb\u6162\u79fb\u52a8\u7684\u4e00\u9636\u52a8\u91cf\u6216\u68af\u5ea6\u6765\u8ddf\u8e2a\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u66f4\u65b0\u52a8\u6001\uff0c\u5e76\u63d0\u4f9b\u4e86\u9996\u4e2a\u6536\u655b\u4fdd\u8bc1", "result": "\u5728\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u6d88\u9664\u4e86\u4e0eDDP\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5728\u4ee5\u592a\u7f51\u4e92\u8fde\u4e0a\u51cf\u5c11\u4e866-27%\u7684\u7b49\u4ee4\u724c\u5899\u949f\u65f6\u95f4\uff0c720M\u89c4\u6a21\u4e0b\u8fbe\u5230\u76ee\u6807\u56f0\u60d1\u5ea6\u6240\u9700\u7684\u6b65\u9aa4\u51cf\u5c1124%\uff0c\u65f6\u95f4\u51cf\u5c1135%", "conclusion": "MT-DAO\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u8de8\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u548c\u5e7f\u57df\u5730\u7406\u8303\u56f4\u5185\u7684\u8bad\u7ec3"}}
{"id": "2510.05373", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05373", "abs": "https://arxiv.org/abs/2510.05373", "authors": ["Utkarsh Saxena", "Kaushik Roy"], "title": "KVLinC : KV Cache Quantization with Hadamard Rotation and Linear Correction", "comment": "14 pages, 7 figures, 6 tables", "summary": "Quantizing the key-value (KV) cache is a promising strategy for improving the\ninference efficiency of large language models (LLMs). However, aggressive\nquantization to very low precision (e.g., 2 bits) introduces significant errors\nin the stored key and value tensors, which propagate through the dot-product\nattention mechanism and ultimately degrade generation quality. To address this,\nwe propose KVLinC, a framework to mitigate attention errors introduced by KV\ncache quantization in the extreme low-precision regime. KVLinC combines a\nHadamard rotation, which reduces quantization error in values, with lightweight\nlinear correction adapters that explicitly compensate for errors introduced by\nquantized keys. Across extensive evaluations on the LLaMA, Qwen2.5, and Qwen3\nmodel families, KVLinC consistently matches or surpasses strong baselines while\nachieving higher KV-cache compression. Furthermore, we implement a custom\nattention kernel that results in upto 2.55x faster inference compared to Flash\nAttention baseline, enabling efficient long-context LLM inference.", "AI": {"tldr": "KVLinC\u662f\u4e00\u4e2a\u7528\u4e8e\u7f13\u89e3\u6781\u4f4e\u7cbe\u5ea6KV\u7f13\u5b58\u91cf\u5316\u5f15\u8d77\u6ce8\u610f\u529b\u8bef\u5dee\u7684\u6846\u67b6\uff0c\u901a\u8fc7Hadamard\u65cb\u8f6c\u548c\u7ebf\u6027\u6821\u6b63\u9002\u914d\u5668\uff0c\u5728\u4fdd\u6301\u9ad8\u538b\u7f29\u7387\u7684\u540c\u65f6\u63d0\u5347\u751f\u6210\u8d28\u91cf\u3002", "motivation": "KV\u7f13\u5b58\u91cf\u5316\u662f\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u7684\u6709\u6548\u7b56\u7565\uff0c\u4f46\u6781\u4f4e\u7cbe\u5ea6\u91cf\u5316\uff08\u59822\u4f4d\uff09\u4f1a\u5728\u952e\u503c\u5f20\u91cf\u4e2d\u5f15\u5165\u663e\u8457\u8bef\u5dee\uff0c\u8fd9\u4e9b\u8bef\u5dee\u901a\u8fc7\u70b9\u79ef\u6ce8\u610f\u529b\u673a\u5236\u4f20\u64ad\uff0c\u6700\u7ec8\u964d\u4f4e\u751f\u6210\u8d28\u91cf\u3002", "method": "KVLinC\u7ed3\u5408Hadamard\u65cb\u8f6c\uff08\u51cf\u5c11\u503c\u91cf\u5316\u8bef\u5dee\uff09\u548c\u8f7b\u91cf\u7ea7\u7ebf\u6027\u6821\u6b63\u9002\u914d\u5668\uff08\u663e\u5f0f\u8865\u507f\u91cf\u5316\u952e\u5f15\u5165\u7684\u8bef\u5dee\uff09\uff0c\u5e76\u5b9e\u73b0\u81ea\u5b9a\u4e49\u6ce8\u610f\u529b\u5185\u6838\u3002", "result": "\u5728LLaMA\u3001Qwen2.5\u548cQwen3\u6a21\u578b\u5bb6\u65cf\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cKVLinC\u59cb\u7ec8\u5339\u914d\u6216\u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u9ad8\u7684KV\u7f13\u5b58\u538b\u7f29\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4Flash Attention\u57fa\u7ebf\u5feb\u8fbe2.55\u500d\u3002", "conclusion": "KVLinC\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6781\u4f4e\u7cbe\u5ea6KV\u7f13\u5b58\u91cf\u5316\u5e26\u6765\u7684\u6ce8\u610f\u529b\u8bef\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u957f\u671f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u3002"}}
{"id": "2510.05385", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.05385", "abs": "https://arxiv.org/abs/2510.05385", "authors": ["Rohan Arni", "Carlos Blanco"], "title": "Physics-Informed Neural Networks with Fourier Features and Attention-Driven Decoding", "comment": "16 pages, 6 figures. Accepted at NeurIPS 2025 AI4Science workshop", "summary": "Physics-Informed Neural Networks (PINNs) are a useful framework for\napproximating partial differential equation solutions using deep learning\nmethods. In this paper, we propose a principled redesign of the PINNsformer, a\nTransformer-based PINN architecture. We present the Spectral PINNSformer\n(S-Pformer), a refinement of encoder-decoder PINNSformers that addresses two\nkey issues; 1. the redundancy (i.e. increased parameter count) of the encoder,\nand 2. the mitigation of spectral bias. We find that the encoder is unnecessary\nfor capturing spatiotemporal correlations when relying solely on\nself-attention, thereby reducing parameter count. Further, we integrate Fourier\nfeature embeddings to explicitly mitigate spectral bias, enabling adaptive\nencoding of multiscale behaviors in the frequency domain. Our model outperforms\nencoder-decoder PINNSformer architectures across all benchmarks, achieving or\noutperforming MLP performance while reducing parameter count significantly.", "AI": {"tldr": "\u63d0\u51fa\u4e86Spectral PINNSformer (S-Pformer)\uff0c\u4e00\u79cd\u6539\u8fdb\u7684Transformer-based PINN\u67b6\u6784\uff0c\u901a\u8fc7\u6d88\u9664\u5197\u4f59\u7f16\u7801\u5668\u548c\u96c6\u6210\u5085\u91cc\u53f6\u7279\u5f81\u5d4c\u5165\u6765\u89e3\u51b3\u53c2\u6570\u5197\u4f59\u548c\u9891\u8c31\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709PINNSformer\u67b6\u6784\u4e2d\u7f16\u7801\u5668\u5197\u4f59\u5bfc\u81f4\u7684\u53c2\u6570\u589e\u52a0\u95ee\u9898\uff0c\u4ee5\u53ca\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u9891\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8PINN\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1PINNSformer\u67b6\u6784\uff0c\u79fb\u9664\u5197\u4f59\u7f16\u7801\u5668\uff0c\u4ec5\u4f9d\u8d56\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6355\u83b7\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u5e76\u96c6\u6210\u5085\u91cc\u53f6\u7279\u5f81\u5d4c\u5165\u6765\u663e\u5f0f\u7f13\u89e3\u9891\u8c31\u504f\u5dee\uff0c\u5b9e\u73b0\u9891\u57df\u4e2d\u591a\u5c3a\u5ea6\u884c\u4e3a\u7684\u81ea\u9002\u5e94\u7f16\u7801\u3002", "result": "S-Pformer\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668PINNSformer\u67b6\u6784\uff0c\u8fbe\u5230\u6216\u8d85\u8fc7MLP\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002", "conclusion": "S-Pformer\u901a\u8fc7\u6d88\u9664\u7f16\u7801\u5668\u5197\u4f59\u548c\u96c6\u6210\u5085\u91cc\u53f6\u7279\u5f81\u5d4c\u5165\uff0c\u6709\u6548\u89e3\u51b3\u4e86PINNSformer\u7684\u53c2\u6570\u5197\u4f59\u548c\u9891\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u3002"}}
{"id": "2510.05386", "categories": ["cs.LG", "cs.IT", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.05386", "abs": "https://arxiv.org/abs/2510.05386", "authors": ["Mikil Foss", "Andrew Lamperski"], "title": "A Neural Network Algorithm for KL Divergence Estimation with Quantitative Error Bounds", "comment": "Under Review for AISTATS 2026", "summary": "Estimating the Kullback-Leibler (KL) divergence between random variables is a\nfundamental problem in statistical analysis. For continuous random variables,\ntraditional information-theoretic estimators scale poorly with dimension and/or\nsample size. To mitigate this challenge, a variety of methods have been\nproposed to estimate KL divergences and related quantities, such as mutual\ninformation, using neural networks. The existing theoretical analyses show that\nneural network parameters achieving low error exist. However, since they rely\non non-constructive neural network approximation theorems, they do not\nguarantee that the existing algorithms actually achieve low error. In this\npaper, we propose a KL divergence estimation algorithm using a shallow neural\nnetwork with randomized hidden weights and biases (i.e. a random feature\nmethod). We show that with high probability, the algorithm achieves a KL\ndivergence estimation error of $O(m^{-1/2}+T^{-1/3})$, where $m$ is the number\nof neurons and $T$ is both the number of steps of the algorithm and the number\nof samples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u6d45\u5c42\u968f\u673a\u7279\u5f81\u795e\u7ecf\u7f51\u7edc\u7684KL\u6563\u5ea6\u4f30\u8ba1\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86O(m^{-1/2}+T^{-1/3})\u7684\u4f30\u8ba1\u8bef\u5dee\uff0c\u5176\u4e2dm\u662f\u795e\u7ecf\u5143\u6570\u91cf\uff0cT\u662f\u7b97\u6cd5\u6b65\u6570\u548c\u6837\u672c\u6570\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u8bba\u4f30\u8ba1\u5668\u5728\u9ad8\u7ef4\u548c/\u6216\u5927\u6837\u672c\u60c5\u51b5\u4e0b\u6027\u80fd\u4e0d\u4f73\uff0c\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u867d\u7136\u7406\u8bba\u4e0a\u5b58\u5728\u4f4e\u8bef\u5dee\u53c2\u6570\uff0c\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u5b9e\u9645\u7b97\u6cd5\u80fd\u8fbe\u5230\u4f4e\u8bef\u5dee\u3002", "method": "\u4f7f\u7528\u5177\u6709\u968f\u673a\u9690\u85cf\u6743\u91cd\u548c\u504f\u7f6e\u7684\u6d45\u5c42\u795e\u7ecf\u7f51\u7edc\uff08\u968f\u673a\u7279\u5f81\u65b9\u6cd5\uff09\u6765\u4f30\u8ba1KL\u6563\u5ea6\u3002", "result": "\u7b97\u6cd5\u4ee5\u9ad8\u6982\u7387\u5b9e\u73b0KL\u6563\u5ea6\u4f30\u8ba1\u8bef\u5dee\u4e3aO(m^{-1/2}+T^{-1/3})\uff0c\u5176\u4e2dm\u662f\u795e\u7ecf\u5143\u6570\u91cf\uff0cT\u662f\u7b97\u6cd5\u6b65\u6570\u548c\u6837\u672c\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u968f\u673a\u7279\u5f81\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4f30\u8ba1KL\u6563\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u7684\u5b9e\u9645\u7b97\u6cd5\u6027\u80fd\u3002"}}
{"id": "2510.05394", "categories": ["cs.LG", "cs.AI", "I.2.6; I.6.5"], "pdf": "https://arxiv.org/pdf/2510.05394", "abs": "https://arxiv.org/abs/2510.05394", "authors": ["Ahmad Alsheikh", "Andreas Fischer"], "title": "Fusion-Based Neural Generalization for Predicting Temperature Fields in Industrial PET Preform Heating", "comment": "Workshop paper, AIP2025: Second Workshop on AI in Production (2025).\n  Licensed under CC BY 4.0", "summary": "Accurate and efficient temperature prediction is critical for optimizing the\npreheating process of PET preforms in industrial microwave systems prior to\nblow molding. We propose a novel deep learning framework for generalized\ntemperature prediction. Unlike traditional models that require extensive\nretraining for each material or design variation, our method introduces a\ndata-efficient neural architecture that leverages transfer learning and model\nfusion to generalize across unseen scenarios. By pretraining specialized neural\nregressor on distinct conditions such as recycled PET heat capacities or\nvarying preform geometries and integrating their representations into a unified\nglobal model, we create a system capable of learning shared thermal dynamics\nacross heterogeneous inputs. The architecture incorporates skip connections to\nenhance stability and prediction accuracy. Our approach reduces the need for\nlarge simulation datasets while achieving superior performance compared to\nmodels trained from scratch. Experimental validation on two case studies\nmaterial variability and geometric diversity demonstrates significant\nimprovements in generalization, establishing a scalable ML-based solution for\nintelligent thermal control in manufacturing environments. Moreover, the\napproach highlights how data-efficient generalization strategies can extend to\nother industrial applications involving complex physical modeling with limited\ndata.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8ePET\u9884\u6210\u578b\u4ef6\u5fae\u6ce2\u9884\u70ed\u6e29\u5ea6\u9884\u6d4b\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u548c\u6a21\u578b\u878d\u5408\u5b9e\u73b0\u8de8\u6750\u6599\u4e0e\u51e0\u4f55\u53d8\u5316\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u51cf\u5c11\u5bf9\u5927\u91cf\u4eff\u771f\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u5de5\u4e1a\u5fae\u6ce2\u7cfb\u7edf\u4e2dPET\u9884\u6210\u578b\u4ef6\u9884\u70ed\u8fc7\u7a0b\u7684\u7cbe\u786e\u6e29\u5ea6\u9884\u6d4b\u5bf9\u4f18\u5316\u5439\u5851\u5de5\u827a\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u6a21\u578b\u9700\u8981\u4e3a\u6bcf\u4e2a\u6750\u6599\u6216\u8bbe\u8ba1\u53d8\u5316\u8fdb\u884c\u5927\u91cf\u91cd\u65b0\u8bad\u7ec3\uff0c\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u6570\u636e\u9ad8\u6548\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u9884\u8bad\u7ec3\u4e13\u95e8\u9488\u5bf9\u4e0d\u540c\u6761\u4ef6\uff08\u5982\u56de\u6536PET\u70ed\u5bb9\u3001\u4e0d\u540c\u9884\u6210\u578b\u4ef6\u51e0\u4f55\u5f62\u72b6\uff09\u7684\u795e\u7ecf\u56de\u5f52\u5668\uff0c\u5e76\u5c06\u5176\u8868\u793a\u96c6\u6210\u5230\u7edf\u4e00\u5168\u5c40\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u8df3\u8dc3\u8fde\u63a5\u589e\u5f3a\u7a33\u5b9a\u6027\u548c\u9884\u6d4b\u7cbe\u5ea6\u3002", "result": "\u5728\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u6750\u6599\u53d8\u5f02\u6027\u548c\u51e0\u4f55\u591a\u6837\u6027\uff09\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u76f8\u6bd4\u4ece\u5934\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5236\u9020\u73af\u5883\u4e2d\u7684\u667a\u80fd\u70ed\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u6570\u636e\u9ad8\u6548\u6cdb\u5316\u7b56\u7565\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u6d89\u53ca\u590d\u6742\u7269\u7406\u5efa\u6a21\u4e14\u6570\u636e\u6709\u9650\u7684\u5de5\u4e1a\u5e94\u7528\u3002"}}
{"id": "2510.05399", "categories": ["cs.LG", "astro-ph.SR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05399", "abs": "https://arxiv.org/abs/2510.05399", "authors": ["Kangwoo Yi", "Bo Shen", "Qin Li", "Haimin Wang", "Yong-Jae Moon", "Jaewon Lee", "Hwanhee Lee"], "title": "Comparing LSTM-Based Sequence-to-Sequence Forecasting Strategies for 24-Hour Solar Proton Flux Profiles Using GOES Data", "comment": "7 pages; accepted as a workshop paper at ICDM 2025", "summary": "Solar Proton Events (SPEs) cause significant radiation hazards to satellites,\nastronauts, and technological systems. Accurate forecasting of their proton\nflux time profiles is crucial for early warnings and mitigation. This paper\nexplores deep learning sequence-to-sequence (seq2seq) models based on Long\nShort-Term Memory networks to predict 24-hour proton flux profiles following\nSPE onsets. We used a dataset of 40 well-connected SPEs (1997-2017) observed by\nNOAA GOES, each associated with a >=M-class western-hemisphere solar flare and\nundisturbed proton flux profiles. Using 4-fold stratified cross-validation, we\nevaluate seq2seq model configurations (varying hidden units and embedding\ndimensions) under multiple forecasting scenarios: (i) proton-only input vs.\ncombined proton+X-ray input, (ii) original flux data vs. trend-smoothed data,\nand (iii) autoregressive vs. one-shot forecasting. Our major results are as\nfollows: First, one-shot forecasting consistently yields lower error than\nautoregressive prediction, avoiding the error accumulation seen in iterative\napproaches. Second, on the original data, proton-only models outperform\nproton+X-ray models. However, with trend-smoothed data, this gap narrows or\nreverses in proton+X-ray models. Third, trend-smoothing significantly enhances\nthe performance of proton+X-ray models by mitigating fluctuations in the X-ray\nchannel. Fourth, while models trained on trendsmoothed data perform best on\naverage, the best-performing model was trained on original data, suggesting\nthat architectural choices can sometimes outweigh the benefits of data\npreprocessing.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u57fa\u4e8eLSTM\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6765\u9884\u6d4b\u592a\u9633\u8d28\u5b50\u4e8b\u4ef6\u53d1\u751f\u540e24\u5c0f\u65f6\u7684\u8d28\u5b50\u901a\u91cf\u65f6\u95f4\u5256\u9762\uff0c\u901a\u8fc7\u591a\u79cd\u9884\u6d4b\u573a\u666f\u6bd4\u8f83\u53d1\u73b0\uff1a\u4e00\u6b21\u6027\u9884\u6d4b\u4f18\u4e8e\u81ea\u56de\u5f52\u9884\u6d4b\uff0c\u8d8b\u52bf\u5e73\u6ed1\u6570\u636e\u80fd\u63d0\u5347\u8d28\u5b50+X\u5c04\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u592a\u9633\u8d28\u5b50\u4e8b\u4ef6\u5bf9\u536b\u661f\u3001\u5b87\u822a\u5458\u548c\u6280\u672f\u7cfb\u7edf\u6784\u6210\u91cd\u5927\u8f90\u5c04\u5371\u5bb3\uff0c\u51c6\u786e\u9884\u6d4b\u8d28\u5b50\u901a\u91cf\u65f6\u95f4\u5256\u9762\u5bf9\u4e8e\u65e9\u671f\u9884\u8b66\u548c\u7f13\u89e3\u63aa\u65bd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u752840\u4e2a\u592a\u9633\u8d28\u5b50\u4e8b\u4ef6\u6570\u636e\u96c6\uff0c\u57fa\u4e8eLSTM\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\uff0c\u901a\u8fc74\u6298\u5206\u5c42\u4ea4\u53c9\u9a8c\u8bc1\u8bc4\u4f30\u4e0d\u540c\u914d\u7f6e\uff0c\u5305\u62ec\u8d28\u5b50\u8f93\u5165vs\u8d28\u5b50+X\u5c04\u7ebf\u8f93\u5165\u3001\u539f\u59cb\u901a\u91cf\u6570\u636evs\u8d8b\u52bf\u5e73\u6ed1\u6570\u636e\u3001\u81ea\u56de\u5f52vs\u4e00\u6b21\u6027\u9884\u6d4b\u3002", "result": "\u4e00\u6b21\u6027\u9884\u6d4b\u6bd4\u81ea\u56de\u5f52\u9884\u6d4b\u8bef\u5dee\u66f4\u4f4e\uff1b\u5728\u539f\u59cb\u6570\u636e\u4e0a\u8d28\u5b50\u6a21\u578b\u4f18\u4e8e\u8d28\u5b50+X\u5c04\u7ebf\u6a21\u578b\uff0c\u4f46\u8d8b\u52bf\u5e73\u6ed1\u540e\u5dee\u8ddd\u7f29\u5c0f\u6216\u9006\u8f6c\uff1b\u8d8b\u52bf\u5e73\u6ed1\u663e\u8457\u63d0\u5347\u8d28\u5b50+X\u5c04\u7ebf\u6a21\u578b\u6027\u80fd\uff1b\u8d8b\u52bf\u5e73\u6ed1\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u5e73\u5747\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6700\u4f73\u6a21\u578b\u6765\u81ea\u539f\u59cb\u6570\u636e\u8bad\u7ec3\u3002", "conclusion": "LSTM\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u80fd\u6709\u6548\u9884\u6d4b\u592a\u9633\u8d28\u5b50\u4e8b\u4ef6\u8d28\u5b50\u901a\u91cf\uff0c\u4e00\u6b21\u6027\u9884\u6d4b\u7b56\u7565\u548c\u9002\u5f53\u7684\u6570\u636e\u9884\u5904\u7406\u80fd\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u4f46\u6a21\u578b\u67b6\u6784\u9009\u62e9\u6709\u65f6\u6bd4\u6570\u636e\u9884\u5904\u7406\u66f4\u91cd\u8981\u3002"}}
{"id": "2510.05416", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05416", "abs": "https://arxiv.org/abs/2510.05416", "authors": ["Xin Gu", "Yingtai Xiao", "Guanlin He", "Jiamu Bai", "Daniel Kifer", "Kiwan Maeng"], "title": "Correlating Cross-Iteration Noise for DP-SGD using Model Curvature", "comment": null, "summary": "Differentially private stochastic gradient descent (DP-SGD) offers the\npromise of training deep learning models while mitigating many privacy risks.\nHowever, there is currently a large accuracy gap between DP-SGD and normal SGD\ntraining. This has resulted in different lines of research investigating\northogonal ways of improving privacy-preserving training. One such line of\nwork, known as DP-MF, correlates the privacy noise across different iterations\nof stochastic gradient descent -- allowing later iterations to cancel out some\nof the noise added to earlier iterations. In this paper, we study how to\nimprove this noise correlation. We propose a technique called NoiseCurve that\nuses model curvature, estimated from public unlabeled data, to improve the\nquality of this cross-iteration noise correlation. Our experiments on various\ndatasets, models, and privacy parameters show that the noise correlations\ncomputed by NoiseCurve offer consistent and significant improvements in\naccuracy over the correlation scheme used by DP-MF.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNoiseCurve\u7684\u6280\u672f\uff0c\u5229\u7528\u516c\u5f00\u65e0\u6807\u7b7e\u6570\u636e\u4f30\u8ba1\u7684\u6a21\u578b\u66f2\u7387\u6765\u6539\u8fdbDP-SGD\u4e2d\u7684\u8de8\u8fed\u4ee3\u566a\u58f0\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524dDP-SGD\u4e0e\u666e\u901aSGD\u8bad\u7ec3\u5b58\u5728\u8f83\u5927\u7684\u51c6\u786e\u6027\u5dee\u8ddd\uff0c\u9700\u8981\u6539\u8fdb\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u65b9\u6cd5\u3002DP-MF\u65b9\u6cd5\u901a\u8fc7\u5173\u8054\u4e0d\u540c\u8fed\u4ee3\u7684\u9690\u79c1\u566a\u58f0\u6765\u62b5\u6d88\u90e8\u5206\u566a\u58f0\uff0c\u4f46\u566a\u58f0\u76f8\u5173\u6027\u8d28\u91cf\u6709\u5f85\u63d0\u5347\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u65e0\u6807\u7b7e\u6570\u636e\u4f30\u8ba1\u6a21\u578b\u66f2\u7387\uff0c\u57fa\u4e8e\u6b64\u6539\u8fdbDP-MF\u4e2d\u7684\u8de8\u8fed\u4ee3\u566a\u58f0\u76f8\u5173\u6027\uff0c\u63d0\u51faNoiseCurve\u6280\u672f\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u3001\u6a21\u578b\u548c\u9690\u79c1\u53c2\u6570\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNoiseCurve\u8ba1\u7b97\u7684\u566a\u58f0\u76f8\u5173\u6027\u76f8\u6bd4DP-MF\u7684\u76f8\u5173\u65b9\u6848\u5e26\u6765\u4e86\u6301\u7eed\u4e14\u663e\u8457\u7684\u51c6\u786e\u6027\u63d0\u5347\u3002", "conclusion": "NoiseCurve\u6280\u672f\u901a\u8fc7\u5229\u7528\u6a21\u578b\u66f2\u7387\u4fe1\u606f\u6539\u8fdb\u566a\u58f0\u76f8\u5173\u6027\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u51c6\u786e\u6027\u8868\u73b0\u3002"}}
{"id": "2510.05421", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05421", "abs": "https://arxiv.org/abs/2510.05421", "authors": ["Shrenik Bhansali", "Larry Heck"], "title": "Draft, Verify, and Improve: Toward Training-Aware Speculative Decoding", "comment": null, "summary": "Autoregressive (AR) decoding is a major latency bottleneck for large language\nmodels. Speculative decoding (SD) accelerates AR by letting a drafter propose\nmulti-token blocks that a verifier accepts or rejects. However, many SD systems\nrequire heavy offline training or extra components. These choices raise\ndata/compute cost and can yield brittle drafters under distribution drift. We\nintroduce \\emph{Draft, Verify, \\& Improve (DVI)}, a training-aware\nself-speculative framework that combines inference with continual online\nlearning. We partition an LLM into a drafter and a verifier, and during\ngeneration, verifier accept/reject decisions are converted into supervision\nsignals and used to update the drafter head. A simple \\emph{KL$\\rightarrow$RL}\nschedule bootstraps calibration via online distillation and then adds\nreward-masked cross-entropy with a on-policy policy-gradient term, preserving\nlossless, single model deployment. On Spec-Bench, DVI achieves a $2.16\\times$\nwall-time speedup, on par with SoTA approaches like EAGLE-2, while orders of\nmagnitude less data for training, and ablations show that DVI outperforms\nKL-only online distillation. DVI demonstrates that \\emph{training-aware}\nself-speculation can deliver state-of-the-art, lossless speedups with minimal\ntraining overhead.", "AI": {"tldr": "DVI\u662f\u4e00\u79cd\u8bad\u7ec3\u611f\u77e5\u7684\u81ea\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5c06LLM\u5212\u5206\u4e3a\u8349\u7a3f\u5668\u548c\u9a8c\u8bc1\u5668\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u6301\u7eed\u5728\u7ebf\u5b66\u4e60\uff0c\u5b9e\u73b0\u65e0\u635f\u52a0\u901f\u3002", "motivation": "\u81ea\u56de\u5f52\u89e3\u7801\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u8981\u5ef6\u8fdf\u74f6\u9888\u3002\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u7cfb\u7edf\u9700\u8981\u5927\u91cf\u79bb\u7ebf\u8bad\u7ec3\u6216\u989d\u5916\u7ec4\u4ef6\uff0c\u589e\u52a0\u4e86\u6570\u636e/\u8ba1\u7b97\u6210\u672c\uff0c\u4e14\u5728\u5206\u5e03\u6f02\u79fb\u4e0b\u53ef\u80fd\u5bfc\u81f4\u8106\u5f31\u7684\u8349\u7a3f\u5668\u3002", "method": "\u5c06LLM\u5212\u5206\u4e3a\u8349\u7a3f\u5668\u548c\u9a8c\u8bc1\u5668\uff0c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5c06\u9a8c\u8bc1\u5668\u7684\u63a5\u53d7/\u62d2\u7edd\u51b3\u7b56\u8f6c\u5316\u4e3a\u76d1\u7763\u4fe1\u53f7\u6765\u66f4\u65b0\u8349\u7a3f\u5668\u5934\u3002\u91c7\u7528KL\u2192RL\u8c03\u5ea6\uff0c\u901a\u8fc7\u5728\u7ebf\u84b8\u998f\u5f15\u5bfc\u6821\u51c6\uff0c\u7136\u540e\u6dfb\u52a0\u5956\u52b1\u63a9\u7801\u4ea4\u53c9\u71b5\u548c\u5728\u7ebf\u7b56\u7565\u68af\u5ea6\u9879\u3002", "result": "\u5728Spec-Bench\u4e0a\u5b9e\u73b02.16\u500d\u5b9e\u65f6\u52a0\u901f\uff0c\u4e0eEAGLE-2\u7b49\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u4f46\u8bad\u7ec3\u6570\u636e\u91cf\u5c11\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793aDVI\u4f18\u4e8e\u4ec5\u4f7f\u7528KL\u7684\u5728\u7ebf\u84b8\u998f\u3002", "conclusion": "\u8bad\u7ec3\u611f\u77e5\u7684\u81ea\u63a8\u6d4b\u53ef\u4ee5\u5728\u6700\u5c0f\u8bad\u7ec3\u5f00\u9500\u4e0b\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u65e0\u635f\u52a0\u901f\u3002"}}
{"id": "2510.05433", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.05433", "abs": "https://arxiv.org/abs/2510.05433", "authors": ["Nazanin Ahmadi", "Qianying Cao", "Jay D. Humphrey", "George Em Karniadakis"], "title": "Physics-Informed Machine Learning in Biomedical Science and Engineering", "comment": "Accepted for publication in the Annual Review of Biomedical\n  Engineering on October 2, 2025", "summary": "Physics-informed machine learning (PIML) is emerging as a potentially\ntransformative paradigm for modeling complex biomedical systems by integrating\nparameterized physical laws with data-driven methods. Here, we review three\nmain classes of PIML frameworks: physics-informed neural networks (PINNs),\nneural ordinary differential equations (NODEs), and neural operators (NOs),\nhighlighting their growing role in biomedical science and engineering. We begin\nwith PINNs, which embed governing equations into deep learning models and have\nbeen successfully applied to biosolid and biofluid mechanics, mechanobiology,\nand medical imaging among other areas. We then review NODEs, which offer\ncontinuous-time modeling, especially suited to dynamic physiological systems,\npharmacokinetics, and cell signaling. Finally, we discuss deep NOs as powerful\ntools for learning mappings between function spaces, enabling efficient\nsimulations across multiscale and spatially heterogeneous biological domains.\nThroughout, we emphasize applications where physical interpretability, data\nscarcity, or system complexity make conventional black-box learning\ninsufficient. We conclude by identifying open challenges and future directions\nfor advancing PIML in biomedical science and engineering, including issues of\nuncertainty quantification, generalization, and integration of PIML and large\nlanguage models.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u7684\u4e09\u5927\u6846\u67b6\uff1a\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u3001\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u548c\u795e\u7ecf\u7b97\u5b50\uff0c\u5f3a\u8c03\u5b83\u4eec\u5728\u5904\u7406\u7269\u7406\u53ef\u89e3\u91ca\u6027\u3001\u6570\u636e\u7a00\u7f3a\u548c\u7cfb\u7edf\u590d\u6742\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u9ed1\u76d2\u5b66\u4e60\u65b9\u6cd5\u5728\u751f\u7269\u533b\u5b66\u7cfb\u7edf\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u6574\u5408\u53c2\u6570\u5316\u7269\u7406\u5b9a\u5f8b\u4e0e\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u7269\u7406\u53ef\u89e3\u91ca\u6027\u3001\u6570\u636e\u7a00\u7f3a\u548c\u7cfb\u7edf\u590d\u6742\u6027\u7b49\u6311\u6218\u3002", "method": "\u56de\u987e\u4e09\u7c7b\u4e3b\u8981PIML\u6846\u67b6\uff1a1) \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff0c\u5c06\u63a7\u5236\u65b9\u7a0b\u5d4c\u5165\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff1b2) \u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\uff0c\u63d0\u4f9b\u8fde\u7eed\u65f6\u95f4\u5efa\u6a21\uff1b3) \u795e\u7ecf\u7b97\u5b50\uff0c\u5b66\u4e60\u51fd\u6570\u7a7a\u95f4\u4e4b\u95f4\u7684\u6620\u5c04\u3002", "result": "\u8fd9\u4e9b\u6846\u67b6\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u751f\u7269\u56fa\u4f53\u548c\u751f\u7269\u6d41\u4f53\u529b\u5b66\u3001\u529b\u5b66\u751f\u7269\u5b66\u3001\u533b\u5b66\u6210\u50cf\u3001\u751f\u7406\u7cfb\u7edf\u52a8\u529b\u5b66\u3001\u836f\u4ee3\u52a8\u529b\u5b66\u3001\u7ec6\u80de\u4fe1\u53f7\u4f20\u5bfc\u4ee5\u53ca\u591a\u5c3a\u5ea6\u548c\u7a7a\u95f4\u5f02\u8d28\u751f\u7269\u9886\u57df\u7684\u9ad8\u6548\u6a21\u62df\u3002", "conclusion": "\u63d0\u51fa\u4e86PIML\u5728\u751f\u7269\u533b\u5b66\u79d1\u5b66\u548c\u5de5\u7a0b\u4e2d\u9762\u4e34\u7684\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u5305\u62ec\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u6cdb\u5316\u80fd\u529b\u4ee5\u53caPIML\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u96c6\u6210\u95ee\u9898\u3002"}}
{"id": "2510.05442", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05442", "abs": "https://arxiv.org/abs/2510.05442", "authors": ["Zizhao Wang", "Dingcheng Li", "Vaishakh Keshava", "Phillip Wallis", "Ananth Balashankar", "Peter Stone", "Lukas Rutishauser"], "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "comment": null, "summary": "Large Language Model (LLM) agents can leverage tools such as Google Search to\ncomplete complex tasks. However, this tool usage introduces the risk of\nindirect prompt injections, where malicious instructions hidden in tool outputs\ncan manipulate the agent, posing security risks like data leakage. Current\ndefense strategies typically rely on fine-tuning LLM agents on datasets of\nknown attacks. However, the generation of these datasets relies on manually\ncrafted attack patterns, which limits their diversity and leaves agents\nvulnerable to novel prompt injections. To address this limitation, we propose\nAdversarial Reinforcement Learning for Agent Safety (ARLAS), a novel framework\nthat leverages adversarial reinforcement learning (RL) by formulating the\nproblem as a two-player zero-sum game. ARLAS co-trains two LLMs: an attacker\nthat learns to autonomously generate diverse prompt injections and an agent\nthat learns to defend against them while completing its assigned tasks. To\nensure robustness against a wide range of attacks and to prevent cyclic\nlearning, we employ a population-based learning framework that trains the agent\nto defend against all previous attacker checkpoints. Evaluated on BrowserGym\nand AgentDojo, agents fine-tuned with ARLAS achieve a significantly lower\nattack success rate than the original model while also improving their task\nsuccess rate. Our analysis further confirms that the adversarial process\ngenerates a diverse and challenging set of attacks, leading to a more robust\nagent compared to the base model.", "AI": {"tldr": "ARLAS\u6846\u67b6\u901a\u8fc7\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLM\u4ee3\u7406\uff0c\u4f7f\u5176\u80fd\u9632\u5fa1\u591a\u6837\u5316\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u540c\u65f6\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u6784\u5efa\u7684\u653b\u51fb\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u65e0\u6cd5\u5e94\u5bf9\u65b0\u578b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u53cc\u4eba\u96f6\u548c\u535a\u5f08\uff0c\u540c\u65f6\u8bad\u7ec3\u653b\u51fb\u8005\u751f\u6210\u591a\u6837\u5316\u63d0\u793a\u6ce8\u5165\u548c\u4ee3\u7406\u9632\u5fa1\u8fd9\u4e9b\u653b\u51fb\u3002", "result": "\u5728BrowserGym\u548cAgentDojo\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cARLAS\u8bad\u7ec3\u7684\u4ee3\u7406\u653b\u51fb\u6210\u529f\u7387\u663e\u8457\u964d\u4f4e\uff0c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u9ad8\u3002", "conclusion": "\u5bf9\u6297\u6027\u8fc7\u7a0b\u751f\u6210\u591a\u6837\u5316\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u653b\u51fb\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u4ea7\u751f\u66f4\u9c81\u68d2\u7684\u4ee3\u7406\u3002"}}
{"id": "2510.05446", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.05446", "abs": "https://arxiv.org/abs/2510.05446", "authors": ["Runlin Zhou", "Chixiang Chen", "Elynn Chen"], "title": "Prior-Aligned Meta-RL: Thompson Sampling with Learned Priors and Guarantees in Finite-Horizon MDPs", "comment": null, "summary": "We study meta-reinforcement learning in finite-horizon MDPs where related\ntasks share similar structures in their optimal action-value functions.\nSpecifically, we posit a linear representation\n$Q^*_h(s,a)=\\Phi_h(s,a)\\,\\theta^{(k)}_h$ and place a Gaussian meta-prior $\n\\mathcal{N}(\\theta^*_h,\\Sigma^*_h)$ over the task-specific parameters\n$\\theta^{(k)}_h$. Building on randomized value functions, we propose two\nThompson-style algorithms: (i) MTSRL, which learns only the prior mean and\nperforms posterior sampling with the learned mean and known covariance; and\n(ii) $\\text{MTSRL}^{+}$, which additionally estimates the covariance and\nemploys prior widening to control finite-sample estimation error. Further, we\ndevelop a prior-alignment technique that couples the posterior under the\nlearned prior with a meta-oracle that knows the true prior, yielding\nmeta-regret guarantees: we match prior-independent Thompson sampling in the\nsmall-task regime and strictly improve with more tasks once the prior is\nlearned. Concretely, for known covariance we obtain\n$\\tilde{O}(H^{4}S^{3/2}\\sqrt{ANK})$ meta-regret, and with learned covariance\n$\\tilde{O}(H^{4}S^{3/2}\\sqrt{AN^3K})$; both recover a better behavior than\nprior-independent after $K \\gtrsim \\tilde{O}(H^2)$ and $K \\gtrsim\n\\tilde{O}(N^2H^2)$, respectively. Simulations on a stateful recommendation\nenvironment (with feature and prior misspecification) show that after brief\nexploration, MTSRL/MTSRL\\(^+\\) track the meta-oracle and substantially\noutperform prior-independent RL and bandit-only meta-baselines. Our results\ngive the first meta-regret guarantees for Thompson-style RL with learned\nQ-priors, and provide practical recipes (warm-start via RLSVI, OLS aggregation,\ncovariance widening) for experiment-rich settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5143\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8eThompson\u91c7\u6837\u7684\u7b97\u6cd5MTSRL\u548cMTSRL\u207a\uff0c\u901a\u8fc7\u7ebf\u6027\u4ef7\u503c\u51fd\u6570\u8868\u793a\u548c\u9ad8\u65af\u5143\u5148\u9a8c\uff0c\u5728\u4efb\u52a1\u95f4\u5171\u4eab\u7ed3\u6784\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u4f18\u4e8e\u72ec\u7acb\u4efb\u52a1\u5b66\u4e60\u7684\u5143\u9057\u61be\u4fdd\u8bc1\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u5229\u7528\u76f8\u5173\u4efb\u52a1\u95f4\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\u6765\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u4efb\u52a1\u7279\u5b9a\u7684\u6700\u4f18\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\u5177\u6709\u7ebf\u6027\u8868\u793a\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u5171\u4eab\u77e5\u8bc6\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) MTSRL\u7b97\u6cd5\uff0c\u4ec5\u5b66\u4e60\u5148\u9a8c\u5747\u503c\u5e76\u4f7f\u7528\u5df2\u77e5\u534f\u65b9\u5dee\u8fdb\u884c\u540e\u9a8c\u91c7\u6837\uff1b2) MTSRL\u207a\u7b97\u6cd5\uff0c\u989d\u5916\u4f30\u8ba1\u534f\u65b9\u5dee\u5e76\u4f7f\u7528\u5148\u9a8c\u6269\u5c55\u63a7\u5236\u6709\u9650\u6837\u672c\u4f30\u8ba1\u8bef\u5dee\uff1b3) \u5148\u9a8c\u5bf9\u9f50\u6280\u672f\uff0c\u5c06\u5b66\u4e60\u5230\u7684\u5148\u9a8c\u540e\u9a8c\u4e0e\u77e5\u9053\u771f\u5b9e\u5148\u9a8c\u7684\u5143\u9884\u8a00\u673a\u8026\u5408\u3002", "result": "\u7ed3\u679c\uff1a\u5728\u5df2\u77e5\u534f\u65b9\u5dee\u60c5\u51b5\u4e0b\u83b7\u5f97\u00d5(H\u2074S\u00b3/\u00b2\u221a(ANK))\u5143\u9057\u61be\uff0c\u5728\u5b66\u4e60\u534f\u65b9\u5dee\u60c5\u51b5\u4e0b\u83b7\u5f97\u00d5(H\u2074S\u00b3/\u00b2\u221a(AN\u00b3K))\u5143\u9057\u61be\uff1b\u5f53\u4efb\u52a1\u6570\u91cfK\u8db3\u591f\u5927\u65f6\uff0c\u4e24\u79cd\u7b97\u6cd5\u90fd\u4f18\u4e8e\u72ec\u7acb\u4efb\u52a1\u5b66\u4e60\u3002\u6a21\u62df\u5b9e\u9a8c\u663e\u793aMTSRL/MTSRL\u207a\u5728\u77ed\u6682\u63a2\u7d22\u540e\u80fd\u8ddf\u8e2a\u5143\u9884\u8a00\u673a\u5e76\u663e\u8457\u4f18\u4e8e\u72ec\u7acbRL\u548c\u4ec5\u5143bandit\u57fa\u7ebf\u3002", "conclusion": "\u7ed3\u8bba\uff1a\u8fd9\u662f\u9996\u4e2a\u4e3a\u5177\u6709\u5b66\u4e60Q\u5148\u9a8c\u7684Thompson\u98ce\u683cRL\u63d0\u4f9b\u5143\u9057\u61be\u4fdd\u8bc1\u7684\u5de5\u4f5c\uff0c\u4e3a\u5b9e\u9a8c\u4e30\u5bcc\u7684\u73af\u5883\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\uff08\u901a\u8fc7RLSVI\u9884\u70ed\u542f\u52a8\u3001OLS\u805a\u5408\u3001\u534f\u65b9\u5dee\u6269\u5c55\uff09\u3002"}}
{"id": "2510.05453", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05453", "abs": "https://arxiv.org/abs/2510.05453", "authors": ["Arpit Kapoor", "Rohitash Chandra"], "title": "QDeepGR4J: Quantile-based ensemble of deep learning and GR4J hybrid rainfall-runoff models for extreme flow prediction with uncertainty quantification", "comment": null, "summary": "Conceptual rainfall-runoff models aid hydrologists and climate scientists in\nmodelling streamflow to inform water management practices. Recent advances in\ndeep learning have unravelled the potential for combining hydrological models\nwith deep learning models for better interpretability and improved predictive\nperformance. In our previous work, we introduced DeepGR4J, which enhanced the\nGR4J conceptual rainfall-runoff model using a deep learning model to serve as a\nsurrogate for the routing component. DeepGR4J had an improved rainfall-runoff\nprediction accuracy, particularly in arid catchments. Quantile regression\nmodels have been extensively used for quantifying uncertainty while aiding\nextreme value forecasting. In this paper, we extend DeepGR4J using a quantile\nregression-based ensemble learning framework to quantify uncertainty in\nstreamflow prediction. We also leverage the uncertainty bounds to identify\nextreme flow events potentially leading to flooding. We further extend the\nmodel to multi-step streamflow predictions for uncertainty bounds. We design\nexperiments for a detailed evaluation of the proposed framework using the\nCAMELS-Aus dataset. The results show that our proposed Quantile DeepGR4J\nframework improves the predictive accuracy and uncertainty interval quality\n(interval score) compared to baseline deep learning models. Furthermore, we\ncarry out flood risk evaluation using Quantile DeepGR4J, and the results\ndemonstrate its suitability as an early warning system.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Quantile DeepGR4J\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u56de\u5f52\u96c6\u6210\u5b66\u4e60\u6269\u5c55\u4e86DeepGR4J\u6a21\u578b\uff0c\u7528\u4e8e\u91cf\u5316\u5f84\u6d41\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u8fb9\u754c\u8bc6\u522b\u53ef\u80fd\u5bfc\u81f4\u6d2a\u6c34\u7684\u6781\u7aef\u6d41\u91cf\u4e8b\u4ef6\u3002", "motivation": "\u7ed3\u5408\u6c34\u6587\u6a21\u578b\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ee5\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u5229\u7528\u5206\u4f4d\u6570\u56de\u5f52\u6a21\u578b\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u8f85\u52a9\u6781\u7aef\u503c\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u5206\u4f4d\u6570\u56de\u5f52\u96c6\u6210\u5b66\u4e60\u6846\u67b6\u6269\u5c55DeepGR4J\u6a21\u578b\uff0c\u91cf\u5316\u5f84\u6d41\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u8fdb\u4e00\u6b65\u6269\u5c55\u5230\u591a\u6b65\u5f84\u6d41\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u8fb9\u754c\u3002", "result": "\u5728CAMELS-Aus\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cQuantile DeepGR4J\u6846\u67b6\u76f8\u6bd4\u57fa\u7ebf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u533a\u95f4\u8d28\u91cf\uff08\u533a\u95f4\u5f97\u5206\uff09\uff0c\u5e76\u8bc1\u660e\u5176\u9002\u5408\u4f5c\u4e3a\u6d2a\u6c34\u9884\u8b66\u7cfb\u7edf\u3002", "conclusion": "Quantile DeepGR4J\u6846\u67b6\u5728\u5f84\u6d41\u9884\u6d4b\u7cbe\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u6d2a\u6c34\u98ce\u9669\u9884\u8b66\u5de5\u5177\u3002"}}
{"id": "2510.05468", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05468", "abs": "https://arxiv.org/abs/2510.05468", "authors": ["Yurun Song", "Zhuoyi Yang", "Ian G. Harris", "Sangeetha Abdu Jyothi"], "title": "AMAQ: Adaptive Mixed-bit Activation Quantization for Collaborative Parameter Efficient Fine-tuning", "comment": "14 pages", "summary": "Large Language Models (LLMs) are scaling rapidly, creating significant\nchallenges for collaborative server client distributed training, particularly\nin terms of communication efficiency and computational overheads. To address\nthese challenges, we implement Parameter-efficient Split Learning, which\neffectively balances efficiency and performance for collaborative training on\nlow-resource devices.\n  To reduce communication overhead in collaborative training, we introduce\nAdaptive Mixed bit Activation Quantization (AMAQ), a strategy that\nprogressively compresses activations and gradients from high precision (6 to 8\nbits) to low precision (3 to 4 bits). AMAQ achieves this by effectively\nallocating bit budgets across channels based on feature wise and layer wise\nimportance using bit regularization.\n  Under the same bit budgets, AMAQ outperforms fixed-precision approaches,\ndelivering about 2.5% higher generation accuracy and about 1.3% better\nclassification accuracy for models like LLaMA3 8B and Qwen2.5 7B. In addition,\nit significantly enhances training stability and reducing ultra-low bit\nrepresentation collapse during the training.\n  Experiments demonstrate that AMAQ integrates effectively into practical\nmulti-machine collaborative training setups, offering superior inference\naccuracy with only a modest communication overhead for bits adaptation during\ntraining. This trade off makes AMAQ a practical and effective solution for\ncollaborative training with minimal communication cost.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u6df7\u5408\u4f4d\u6fc0\u6d3b\u91cf\u5316(AMAQ)\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u538b\u7f29\u6fc0\u6d3b\u503c\u548c\u68af\u5ea6\uff0c\u5728\u534f\u4f5c\u8bad\u7ec3\u4e2d\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u5feb\u901f\u589e\u957f\uff0c\u7ed9\u670d\u52a1\u5668-\u5ba2\u6237\u7aef\u5206\u5e03\u5f0f\u534f\u4f5c\u8bad\u7ec3\u5e26\u6765\u901a\u4fe1\u6548\u7387\u548c\u8ba1\u7b97\u5f00\u9500\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bbe\u5907\u4e0a\u3002", "method": "\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u7684\u5206\u5272\u5b66\u4e60\uff0c\u5f15\u5165AMAQ\u7b56\u7565\uff0c\u57fa\u4e8e\u7279\u5f81\u548c\u5c42\u7ea7\u91cd\u8981\u6027\u901a\u8fc7\u4f4d\u6b63\u5219\u5316\u5728\u901a\u9053\u95f4\u5206\u914d\u4f4d\u9884\u7b97\uff0c\u5c06\u6fc0\u6d3b\u548c\u68af\u5ea6\u4ece\u9ad8\u7cbe\u5ea6(6-8\u4f4d)\u6e10\u8fdb\u538b\u7f29\u5230\u4f4e\u7cbe\u5ea6(3-4\u4f4d)\u3002", "result": "\u5728\u76f8\u540c\u4f4d\u9884\u7b97\u4e0b\uff0cAMAQ\u76f8\u6bd4\u56fa\u5b9a\u7cbe\u5ea6\u65b9\u6cd5\u5728LLaMA3 8B\u548cQwen2.5 7B\u7b49\u6a21\u578b\u4e0a\u83b7\u5f97\u7ea62.5%\u7684\u751f\u6210\u51c6\u786e\u7387\u548c1.3%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u5347\uff0c\u663e\u8457\u589e\u5f3a\u8bad\u7ec3\u7a33\u5b9a\u6027\u5e76\u51cf\u5c11\u8d85\u4f4e\u4f4d\u8868\u793a\u5d29\u6e83\u3002", "conclusion": "AMAQ\u80fd\u6709\u6548\u96c6\u6210\u5230\u5b9e\u9645\u591a\u673a\u534f\u4f5c\u8bad\u7ec3\u4e2d\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u4ec5\u9700\u9002\u5ea6\u7684\u901a\u4fe1\u5f00\u9500\u5373\u53ef\u63d0\u4f9b\u4f18\u8d8a\u7684\u63a8\u7406\u51c6\u786e\u7387\uff0c\u662f\u901a\u4fe1\u6210\u672c\u6700\u5c0f\u5316\u7684\u5b9e\u7528\u534f\u4f5c\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05482", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05482", "abs": "https://arxiv.org/abs/2510.05482", "authors": ["Luke Thompson", "Davy Guan", "Dai Shi", "Slade Matthews", "Junbin Gao", "Andi Han"], "title": "ATOM: A Pretrained Neural Operator for Multitask Molecular Dynamics", "comment": null, "summary": "Molecular dynamics (MD) simulations underpin modern computational drug dis-\ncovery, materials science, and biochemistry. Recent machine learning models\nprovide high-fidelity MD predictions without the need to repeatedly solve\nquantum mechanical forces, enabling significant speedups over conventional\npipelines. Yet many such methods typically enforce strict equivariance and rely\non sequential rollouts, thus limiting their flexibility and simulation\nefficiency. They are also com- monly single-task, trained on individual\nmolecules and fixed timeframes, which restricts generalization to unseen\ncompounds and extended timesteps. To address these issues, we propose Atomistic\nTransformer Operator for Molecules (ATOM), a pretrained transformer neural\noperator for multitask molecular dynamics. ATOM adopts a quasi-equivariant\ndesign that requires no explicit molecular graph and employs a temporal\nattention mechanism, allowing for the accurate parallel decod- ing of multiple\nfuture states. To support operator pretraining across chemicals and timescales,\nwe curate TG80, a large, diverse, and numerically stable MD dataset with over\n2.5 million femtoseconds of trajectories across 80 compounds. ATOM achieves\nstate-of-the-art performance on established single-task benchmarks, such as\nMD17, RMD17 and MD22. After multitask pretraining on TG80, ATOM shows\nexceptional zero-shot generalization to unseen molecules across varying time\nhori- zons. We believe ATOM represents a significant step toward accurate,\nefficient, and transferable molecular dynamics models", "AI": {"tldr": "\u63d0\u51fa\u4e86ATOM\uff08\u539f\u5b50\u5206\u5b50\u53d8\u6362\u7b97\u5b50\uff09\uff0c\u4e00\u79cd\u7528\u4e8e\u591a\u4efb\u52a1\u5206\u5b50\u52a8\u529b\u5b66\u7684\u9884\u8bad\u7ec3\u53d8\u6362\u5668\u795e\u7ecf\u7b97\u5b50\uff0c\u901a\u8fc7\u51c6\u7b49\u53d8\u8bbe\u8ba1\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u591a\u672a\u6765\u72b6\u6001\u7684\u5e76\u884c\u89e3\u7801\uff0c\u5728TG80\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u540e\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u65b9\u6cd5\u901a\u5e38\u5f3a\u5236\u4e25\u683c\u7b49\u53d8\u6027\u3001\u4f9d\u8d56\u987a\u5e8f\u5c55\u5f00\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u6a21\u62df\u6548\u7387\uff0c\u4e14\u591a\u4e3a\u5355\u4efb\u52a1\u8bad\u7ec3\uff0c\u65e0\u6cd5\u6cdb\u5316\u5230\u672a\u89c1\u5316\u5408\u7269\u548c\u6269\u5c55\u65f6\u95f4\u6b65\u3002", "method": "\u91c7\u7528\u51c6\u7b49\u53d8\u8bbe\u8ba1\uff08\u65e0\u9700\u663e\u5f0f\u5206\u5b50\u56fe\uff09\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5141\u8bb8\u5e76\u884c\u89e3\u7801\u591a\u4e2a\u672a\u6765\u72b6\u6001\uff1b\u5728TG80\u6570\u636e\u96c6\uff08\u5305\u542b80\u79cd\u5316\u5408\u7269\u7684250\u4e07\u98de\u79d2\u8f68\u8ff9\uff09\u4e0a\u8fdb\u884c\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\u3002", "result": "\u5728MD17\u3001RMD17\u548cMD22\u7b49\u5355\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1b\u5728TG80\u4e0a\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\u540e\uff0c\u5bf9\u672a\u89c1\u5206\u5b50\u5728\u4e0d\u540c\u65f6\u95f4\u8303\u56f4\u5185\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ATOM\u4ee3\u8868\u4e86\u5411\u51c6\u786e\u3001\u9ad8\u6548\u548c\u53ef\u8fc1\u79fb\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u578b\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.05489", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.05489", "abs": "https://arxiv.org/abs/2510.05489", "authors": ["Reza T. Batley", "Sourav Saha"], "title": "The Method of Infinite Descent", "comment": null, "summary": "Training - the optimisation of complex models - is traditionally performed\nthrough small, local, iterative updates [D. E. Rumelhart, G. E. Hinton, R. J.\nWilliams, Nature 323, 533-536 (1986)]. Approximating solutions through\ntruncated gradients is a paradigm dating back to Cauchy [A.-L. Cauchy, Comptes\nRendus Math\\'ematique 25, 536-538 (1847)] and Newton [I. Newton, The Method of\nFluxions and Infinite Series (Henry Woodfall, London, 1736)]. This work\nintroduces the Method of Infinite Descent, a semi-analytic optimisation\nparadigm that reformulates training as the direct solution to the first-order\noptimality condition. By analytical resummation of its Taylor expansion, this\nmethod yields an exact, algebraic equation for the update step. Realisation of\nthe infinite Taylor tower's cascading resummation is formally derived, and an\nexploitative algorithm for the direct solve step is proposed.\n  This principle is demonstrated with the herein-introduced AION (Analytic,\nInfinitely-Optimisable Network) architecture. AION is a model designed\nexpressly to satisfy the algebraic closure required by Infinite Descent. In a\nsimple test problem, AION reaches the optimum in a single descent step.\nTogether, this optimiser-model pair exemplify how analytic structure enables\nexact, non-iterative convergence. Infinite Descent extends beyond this example,\napplying to any appropriately closed architecture. This suggests a new class of\nsemi-analytically optimisable models: the \\emph{Infinity Class}; sufficient\nconditions for class membership are discussed. This offers a pathway toward\nnon-iterative learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65e0\u9650\u4e0b\u964d\u6cd5\uff0c\u4e00\u79cd\u534a\u89e3\u6790\u4f18\u5316\u8303\u5f0f\uff0c\u5c06\u8bad\u7ec3\u91cd\u65b0\u8868\u8ff0\u4e3a\u76f4\u63a5\u6c42\u89e3\u4e00\u9636\u6700\u4f18\u6027\u6761\u4ef6\u3002\u901a\u8fc7\u89e3\u6790\u91cd\u6c42\u548c\u6cf0\u52d2\u5c55\u5f00\uff0c\u8be5\u65b9\u6cd5\u4e3a\u66f4\u65b0\u6b65\u9aa4\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u4ee3\u6570\u65b9\u7a0b\u3002", "motivation": "\u4f20\u7edf\u8bad\u7ec3\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5c0f\u7684\u3001\u5c40\u90e8\u7684\u8fed\u4ee3\u66f4\u65b0\uff0c\u8fd9\u53ef\u4ee5\u8ffd\u6eaf\u5230\u67ef\u897f\u548c\u725b\u987f\u7684\u5de5\u4f5c\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u534a\u89e3\u6790\u4f18\u5316\u8303\u5f0f\u6765\u8d85\u8d8a\u8fd9\u79cd\u8fed\u4ee3\u8303\u5f0f\uff0c\u5b9e\u73b0\u975e\u8fed\u4ee3\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u4e86\u65e0\u9650\u4e0b\u964d\u6cd5\uff0c\u901a\u8fc7\u89e3\u6790\u91cd\u6c42\u548c\u6cf0\u52d2\u5c55\u5f00\u6765\u76f4\u63a5\u6c42\u89e3\u4e00\u9636\u6700\u4f18\u6027\u6761\u4ef6\u3002\u540c\u65f6\u5f15\u5165\u4e86AION\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u4e13\u95e8\u8bbe\u8ba1\u4ee5\u6ee1\u8db3\u65e0\u9650\u4e0b\u964d\u6cd5\u6240\u9700\u7684\u4ee3\u6570\u95ed\u5305\u8981\u6c42\u3002", "result": "\u5728\u7b80\u5355\u6d4b\u8bd5\u95ee\u9898\u4e2d\uff0cAION\u901a\u8fc7\u5355\u6b21\u4e0b\u964d\u6b65\u9aa4\u8fbe\u5230\u6700\u4f18\u89e3\u3002\u4f18\u5316\u5668-\u6a21\u578b\u5bf9\u5c55\u793a\u4e86\u5206\u6790\u7ed3\u6784\u5982\u4f55\u5b9e\u73b0\u7cbe\u786e\u7684\u975e\u8fed\u4ee3\u6536\u655b\u3002", "conclusion": "\u65e0\u9650\u4e0b\u964d\u6cd5\u6269\u5c55\u4e86\u53ef\u5e94\u7528\u7684\u8303\u56f4\uff0c\u63d0\u51fa\u4e86\u65e0\u9650\u7c7b\u6a21\u578b\u7684\u6982\u5ff5\uff0c\u4e3a\u901a\u5411\u975e\u8fed\u4ee3\u5b66\u4e60\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2510.05491", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05491", "abs": "https://arxiv.org/abs/2510.05491", "authors": ["Zichong Li", "Liming Liu", "Chen Liang", "Weizhu Chen", "Tuo Zhao"], "title": "NorMuon: Making Muon more efficient and scalable", "comment": null, "summary": "The choice of optimizer significantly impacts the training efficiency and\ncomputational costs of large language models (LLMs). Recently, the Muon\noptimizer has demonstrated promising results by orthogonalizing parameter\nupdates, improving optimization geometry through better conditioning. Despite\nMuon's emergence as a candidate successor to Adam, the potential for jointly\nleveraging their strengths has not been systematically explored. In this work,\nwe bridge this gap by proposing NorMuon (Neuron-wise Normalized Muon), an\noptimizer that synergistically combines orthogonalization with neuron-level\nadaptive learning rates. Our analysis reveals that while Muon effectively\nreduces condition numbers, the resulting updates exhibit highly non-uniform\nneuron norms, causing certain neurons to dominate the optimization process.\nNorMuon addresses this imbalance by maintaining second-order momentum\nstatistics for each neuron and applying row-wise normalization after\northogonalization, ensuring balanced parameter utilization while preserving\nMuon's conditioning benefits. To enable practical deployment at scale, we\ndevelop an efficient distributed implementation under the FSDP2 framework that\nstrategically distributes orthogonalization computations across devices.\nExperiments across multiple model scales demonstrate that NorMuon consistently\noutperforms both Adam and Muon, achieving 21.74% better training efficiency\nthan Adam and 11.31% improvement over Muon on 1.1 B pretraining setting, while\nmaintaining a comparable memory footprint to Muon. Our findings suggest that\northogonalization and adaptive learning rates are complementary rather than\ncompeting approaches, opening new avenues for optimizer design in large-scale\ndeep learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86NorMuon\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u7ed3\u5408\u6b63\u4ea4\u5316\u548c\u795e\u7ecf\u5143\u7ea7\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u89e3\u51b3\u4e86Muon\u4f18\u5316\u5668\u4e2d\u795e\u7ecf\u5143\u66f4\u65b0\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301Muon\u6761\u4ef6\u6570\u6539\u5584\u4f18\u52bf\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u5747\u8861\u7684\u53c2\u6570\u5229\u7528\u3002", "motivation": "Muon\u4f18\u5316\u5668\u867d\u7136\u901a\u8fc7\u6b63\u4ea4\u5316\u6539\u5584\u4e86\u4f18\u5316\u51e0\u4f55\u6761\u4ef6\uff0c\u4f46\u5bfc\u81f4\u795e\u7ecf\u5143\u66f4\u65b0\u9ad8\u5ea6\u4e0d\u5747\u5300\uff0c\u67d0\u4e9b\u795e\u7ecf\u5143\u4e3b\u5bfc\u4f18\u5316\u8fc7\u7a0b\u3002\u9700\u8981\u7ed3\u5408Adam\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u4f18\u52bf\u6765\u5e73\u8861\u53c2\u6570\u5229\u7528\u3002", "method": "NorMuon\u5728\u6b63\u4ea4\u5316\u540e\u7ef4\u62a4\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u4e8c\u9636\u52a8\u91cf\u7edf\u8ba1\u5e76\u5e94\u7528\u884c\u7ea7\u5f52\u4e00\u5316\uff0c\u786e\u4fdd\u5e73\u8861\u7684\u53c2\u6570\u5229\u7528\u3002\u5f00\u53d1\u4e86\u57fa\u4e8eFSDP2\u6846\u67b6\u7684\u9ad8\u6548\u5206\u5e03\u5f0f\u5b9e\u73b0\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNorMuon\u4e00\u81f4\u4f18\u4e8eAdam\u548cMuon\uff0c\u57281.1B\u9884\u8bad\u7ec3\u8bbe\u7f6e\u4e2d\u6bd4Adam\u63d0\u534721.74%\u8bad\u7ec3\u6548\u7387\uff0c\u6bd4Muon\u63d0\u534711.31%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eMuon\u76f8\u5f53\u7684\u5185\u5b58\u5360\u7528\u3002", "conclusion": "\u6b63\u4ea4\u5316\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u662f\u4e92\u8865\u800c\u975e\u7ade\u4e89\u7684\u65b9\u6cd5\uff0c\u4e3a\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4f18\u5316\u5668\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.05492", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05492", "abs": "https://arxiv.org/abs/2510.05492", "authors": ["Zhuoyi Huang", "Nutan Sahoo", "Anamika Kumari", "Girish Kumar", "Kexuan Cai", "Shixing Cao", "Yue Kang", "Tian Xia", "Somya Chatterjee", "Nicholas Hausman", "Aidan Jay", "Eric S. Rosenthal", "Soundar Srinivasan", "Sadid Hasan", "Alex Fedorov", "Sulaiman Vesal", "Soundar Srinivasan", "Sadid Hasan", "Alex Fedorov", "Sulaiman Vesal"], "title": "High-Fidelity Synthetic ECG Generation via Mel-Spectrogram Informed Diffusion Training", "comment": null, "summary": "The development of machine learning for cardiac care is severely hampered by\nprivacy restrictions on sharing real patient electrocardiogram (ECG) data.\nAlthough generative AI offers a promising solution, the real-world use of\nexisting model-synthesized ECGs is limited by persistent gaps in\ntrustworthiness and clinical utility. In this work, we address two major\nshortcomings of current generative ECG methods: insufficient morphological\nfidelity and the inability to generate personalized, patient-specific\nphysiological signals. To address these gaps, we build on a conditional\ndiffusion-based Structured State Space Model (SSSD-ECG) with two principled\ninnovations: (1) MIDT-ECG (Mel-Spectrogram Informed Diffusion Training), a\nnovel training paradigm with time-frequency domain supervision to enforce\nphysiological structural realism, and (2) multi-modal demographic conditioning\nto enable patient-specific synthesis. We comprehensively evaluate our approach\non the PTB-XL dataset, assessing the synthesized ECG signals on fidelity,\nclinical coherence, privacy preservation, and downstream task utility. MIDT-ECG\nachieves substantial gains: it improves morphological coherence, preserves\nstrong privacy guarantees with all metrics evaluated exceeding the baseline by\n4-8%, and notably reduces the interlead correlation error by an average of 74%,\nwhile demographic conditioning enhances signal-to-noise ratio and\npersonalization. In critical low-data regimes, a classifier trained on datasets\nsupplemented with our synthetic ECGs achieves performance comparable to a\nclassifier trained solely on real data. Together, we demonstrate that ECG\nsynthesizers, trained with the proposed time-frequency structural\nregularization scheme, can serve as personalized, high-fidelity,\nprivacy-preserving surrogates when real data are scarce, advancing the\nresponsible use of generative AI in healthcare.", "AI": {"tldr": "\u63d0\u51faMIDT-ECG\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u9891\u57df\u76d1\u7763\u548c\u591a\u6a21\u6001\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6\u5316\uff0c\u89e3\u51b3\u73b0\u6709\u751f\u6210\u5f0fECG\u6a21\u578b\u5f62\u6001\u4fdd\u771f\u5ea6\u4e0d\u8db3\u548c\u65e0\u6cd5\u751f\u6210\u4e2a\u6027\u5316\u4fe1\u53f7\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "motivation": "\u533b\u7597\u9886\u57df\u673a\u5668\u5b66\u4e60\u53d1\u5c55\u53d7\u9650\u4e8e\u60a3\u8005ECG\u6570\u636e\u7684\u9690\u79c1\u9650\u5236\uff0c\u73b0\u6709\u751f\u6210\u5f0fAI\u65b9\u6cd5\u5728\u53ef\u4fe1\u5ea6\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5f62\u6001\u4fdd\u771f\u5ea6\u4e0d\u591f\u548c\u65e0\u6cd5\u751f\u6210\u4e2a\u6027\u5316\u751f\u7406\u4fe1\u53f7\u3002", "method": "\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u7684\u7ed3\u6784\u5316\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u63d0\u51faMIDT-ECG\u8bad\u7ec3\u8303\u5f0f\uff08\u65f6\u9891\u57df\u76d1\u7763\uff09\u548c\u591a\u6a21\u6001\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6\u5316\uff0c\u901a\u8fc7\u6885\u5c14\u9891\u8c31\u56fe\u76d1\u7763\u786e\u4fdd\u751f\u7406\u7ed3\u6784\u771f\u5b9e\u6027\uff0c\u5b9e\u73b0\u60a3\u8005\u7279\u5f02\u6027\u5408\u6210\u3002", "result": "\u5728PTB-XL\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cMIDT-ECG\u663e\u8457\u63d0\u5347\u5f62\u6001\u4e00\u81f4\u6027\uff0c\u9690\u79c1\u4fdd\u62a4\u6307\u6807\u6bd4\u57fa\u7ebf\u63d0\u9ad84-8%\uff0c\u5bfc\u8054\u95f4\u76f8\u5173\u8bef\u5dee\u5e73\u5747\u964d\u4f4e74%\uff0c\u4eba\u53e3\u7edf\u8ba1\u6761\u4ef6\u5316\u589e\u5f3a\u4fe1\u566a\u6bd4\u548c\u4e2a\u6027\u5316\u3002\u5728\u4f4e\u6570\u636e\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u5408\u6210ECG\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u4ec5\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u7684\u6a21\u578b\u3002", "conclusion": "\u91c7\u7528\u65f6\u9891\u7ed3\u6784\u6b63\u5219\u5316\u65b9\u6848\u8bad\u7ec3\u7684ECG\u5408\u6210\u5668\u53ef\u4f5c\u4e3a\u4e2a\u6027\u5316\u3001\u9ad8\u4fdd\u771f\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u771f\u5b9e\u6570\u636e\u7a00\u7f3a\u65f6\u63a8\u8fdb\u751f\u6210\u5f0fAI\u5728\u533b\u7597\u9886\u57df\u7684\u8d1f\u8d23\u4efb\u4f7f\u7528\u3002"}}
{"id": "2510.05494", "categories": ["cs.LG", "cs.CC"], "pdf": "https://arxiv.org/pdf/2510.05494", "abs": "https://arxiv.org/abs/2510.05494", "authors": ["Yang Cao", "Zhao Song", "Jiahao Zhang", "Jiale Zhao"], "title": "Fundamental Limits of Crystalline Equivariant Graph Neural Networks: A Circuit Complexity Perspective", "comment": null, "summary": "Graph neural networks (GNNs) have become a core paradigm for learning on\nrelational data. In materials science, equivariant GNNs (EGNNs) have emerged as\na compelling backbone for crystalline-structure prediction, owing to their\nability to respect Euclidean symmetries and periodic boundary conditions.\nDespite strong empirical performance, their expressive power in periodic,\nsymmetry-constrained settings remains poorly understood. This work\ncharacterizes the intrinsic computational and expressive limits of EGNNs for\ncrystalline-structure prediction through a circuit-complexity lens. We analyze\nthe computations carried out by EGNN layers acting on node features, atomic\ncoordinates, and lattice matrices, and prove that, under polynomial precision,\nembedding width $d=O(n)$ for $n$ nodes, $O(1)$ layers, and $O(1)$-depth,\n$O(n)$-width MLP instantiations of the message/update/readout maps, these\nmodels admit a simulation by a uniform $\\mathsf{TC}^0$ threshold-circuit family\nof polynomial size (with an explicit constant-depth bound). Situating EGNNs\nwithin $\\mathsf{TC}^0$ provides a concrete ceiling on the decision and\nprediction problems solvable by such architectures under realistic resource\nconstraints and clarifies which architectural modifications (e.g., increased\ndepth, richer geometric primitives, or wider layers) are required to transcend\nthis regime. The analysis complements Weisfeiler-Lehman style results that do\nnot directly transfer to periodic crystals, and offers a complexity-theoretic\nfoundation for symmetry-aware graph learning on crystalline systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u7535\u8def\u590d\u6742\u6027\u89c6\u89d2\u5206\u6790\u4e86\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6676\u4f53\u7ed3\u6784\u9884\u6d4b\u4e2d\u7684\u8ba1\u7b97\u548c\u8868\u8fbe\u80fd\u529b\u6781\u9650\uff0c\u8bc1\u660e\u5728\u591a\u9879\u5f0f\u7cbe\u5ea6\u4e0bEGNN\u53ef\u88abTC^0\u9608\u503c\u7535\u8def\u65cf\u6a21\u62df\u3002", "motivation": "\u5c3d\u7ba1\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6750\u6599\u79d1\u5b66\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u7ecf\u9a8c\u6027\u80fd\uff0c\u4f46\u5176\u5728\u5468\u671f\u6027\u3001\u5bf9\u79f0\u6027\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u8868\u8fbe\u80fd\u529b\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u9700\u8981\u4ece\u8ba1\u7b97\u590d\u6742\u6027\u89d2\u5ea6\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "method": "\u91c7\u7528\u7535\u8def\u590d\u6742\u6027\u7406\u8bba\uff0c\u5206\u6790EGNN\u5c42\u5728\u8282\u70b9\u7279\u5f81\u3001\u539f\u5b50\u5750\u6807\u548c\u6676\u683c\u77e9\u9635\u4e0a\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u8bc1\u660e\u5728\u7279\u5b9a\u8d44\u6e90\u7ea6\u675f\u4e0bEGNN\u53ef\u88abTC^0\u7535\u8def\u65cf\u6a21\u62df\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u591a\u9879\u5f0f\u7cbe\u5ea6\u3001O(n)\u5d4c\u5165\u5bbd\u5ea6\u3001O(1)\u5c42\u6570\u548cO(1)\u6df1\u5ea6\u7b49\u6761\u4ef6\u4e0b\uff0cEGNN\u53ef\u88ab\u591a\u9879\u5f0f\u5927\u5c0f\u7684\u5747\u5300TC^0\u9608\u503c\u7535\u8def\u65cf\u6a21\u62df\uff0c\u5e76\u7ed9\u51fa\u4e86\u660e\u786e\u7684\u5e38\u6570\u6df1\u5ea6\u754c\u9650\u3002", "conclusion": "\u5c06EGNN\u7f6e\u4e8eTC^0\u590d\u6742\u6027\u7c7b\u4e2d\u4e3a\u5bf9\u79f0\u611f\u77e5\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u590d\u6742\u6027\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u5728\u73b0\u5b9e\u8d44\u6e90\u7ea6\u675f\u4e0b\u6b64\u7c7b\u67b6\u6784\u53ef\u89e3\u51b3\u95ee\u9898\u7684\u5177\u4f53\u4e0a\u9650\uff0c\u5e76\u6307\u660e\u4e86\u8d85\u8d8a\u8be5\u9650\u5236\u6240\u9700\u7684\u67b6\u6784\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2510.05511", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05511", "abs": "https://arxiv.org/abs/2510.05511", "authors": ["Aavid Mathrawala", "Dhruv Kurup", "Josie Lau"], "title": "EEG-Based Acute Pain Classification: Machine Learning Model Comparison and Real-Time Clinical Feasibility", "comment": null, "summary": "Current pain assessment within hospitals often relies on self-reporting or\nnon-specific EKG vital signs. This system leaves critically ill, sedated, and\ncognitively impaired patients vulnerable to undertreated pain and opioid\noveruse. Electroencephalography (EEG) offers a noninvasive method of measuring\nbrain activity. This technology could potentially be applied as an assistive\ntool to highlight nociceptive processing in order to mitigate this issue. In\nthis study, we compared machine learning models for classifying high-pain\nversus low/no-pain EEG epochs using data from fifty-two healthy adults exposed\nto laser-evoked pain at three intensities (low, medium, high). Each four-second\nepoch was transformed into a 537-feature vector spanning spectral power, band\nratios, Hjorth parameters, entropy measures, coherence, wavelet energies, and\npeak-frequency metrics. Nine traditional machine learning models were evaluated\nwith leave-one-participant-out cross-validation. A support vector machine with\nradial basis function kernel achieved the best offline performance with 88.9%\naccuracy and sub-millisecond inference time (1.02 ms). Our Feature importance\nanalysis was consistent with current canonical pain physiology, showing\ncontralateral alpha suppression, midline theta/alpha enhancement, and frontal\ngamma bursts. The real-time XGBoost model maintained an end-to-end latency of\nabout 4 ms and 94.2% accuracy, demonstrating that an EEG-based pain monitor is\ntechnically feasible within a clinical setting and provides a pathway towards\nclinical validation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u8111\u7535\u56fe(EEG)\u7684\u75bc\u75db\u76d1\u6d4b\u7cfb\u7edf\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u9ad8\u75bc\u75db\u4e0e\u4f4e/\u65e0\u75bc\u75db\u72b6\u6001\u8fdb\u884c\u5206\u7c7b\uff0c\u5728\u79bb\u7ebf\u6d4b\u8bd5\u4e2d\u8fbe\u523088.9%\u7684\u51c6\u786e\u7387\uff0c\u5b9e\u65f6\u6a21\u578b\u8fbe\u523094.2%\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u5e94\u7528\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u533b\u9662\u75bc\u75db\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u60a3\u8005\u81ea\u8ff0\u6216\u975e\u7279\u5f02\u6027\u5fc3\u7535\u56fe\u751f\u547d\u4f53\u5f81\uff0c\u8fd9\u4f7f\u5f97\u5371\u91cd\u3001\u9547\u9759\u548c\u8ba4\u77e5\u969c\u788d\u60a3\u8005\u9762\u4e34\u75bc\u75db\u6cbb\u7597\u4e0d\u8db3\u6216\u963f\u7247\u7c7b\u836f\u7269\u8fc7\u5ea6\u4f7f\u7528\u7684\u98ce\u9669\u3002", "method": "\u4f7f\u752852\u540d\u5065\u5eb7\u6210\u5e74\u4eba\u5728\u4e09\u79cd\u6fc0\u5149\u8bf1\u53d1\u75bc\u75db\u5f3a\u5ea6\u4e0b\u7684EEG\u6570\u636e\uff0c\u5c064\u79d2\u65f6\u6bb5\u8f6c\u6362\u4e3a537\u4e2a\u7279\u5f81\u5411\u91cf\uff0c\u8bc4\u4f30\u4e869\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u91c7\u7528\u7559\u4e00\u4ea4\u53c9\u9a8c\u8bc1\u3002", "result": "\u652f\u6301\u5411\u91cf\u673a(RBF\u6838)\u5728\u79bb\u7ebf\u6d4b\u8bd5\u4e2d\u8fbe\u523088.9%\u51c6\u786e\u7387\u548c\u4e9a\u6beb\u79d2\u63a8\u7406\u65f6\u95f4(1.02ms)\uff1b\u5b9e\u65f6XGBoost\u6a21\u578b\u4fdd\u6301\u7ea64ms\u7aef\u5230\u7aef\u5ef6\u8fdf\u548c94.2%\u51c6\u786e\u7387\u3002", "conclusion": "\u57fa\u4e8eEEG\u7684\u75bc\u75db\u76d1\u6d4b\u5668\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u6280\u672f\u4e0a\u53ef\u884c\uff0c\u4e3a\u4e34\u5e8a\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9014\u5f84\uff0c\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u4e0e\u5f53\u524d\u7ecf\u5178\u75bc\u75db\u751f\u7406\u5b66\u4e00\u81f4\u3002"}}
{"id": "2510.05516", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.05516", "abs": "https://arxiv.org/abs/2510.05516", "authors": ["Wei-Ting Tang", "Akshay Kudva", "Joel A. Paulson"], "title": "NeST-BO: Fast Local Bayesian Optimization via Newton-Step Targeting of Gradient and Hessian Information", "comment": null, "summary": "Bayesian optimization (BO) is effective for expensive black-box problems but\nremains challenging in high dimensions. We propose NeST-BO, a local BO method\nthat targets the Newton step by jointly learning gradient and Hessian\ninformation with Gaussian process surrogates, and selecting evaluations via a\none-step lookahead bound on Newton-step error. We show that this bound (and\nhence the step error) contracts with batch size, so NeST-BO directly inherits\ninexact-Newton convergence: global progress under mild stability assumptions\nand quadratic local rates once steps are sufficiently accurate. To scale, we\noptimize the acquisition in low-dimensional subspaces (e.g., random embeddings\nor learned sparse subspaces), reducing the dominant cost of learning curvature\nfrom $O(d^2)$ to $O(m^2)$ with $m \\ll d$ while preserving step targeting.\nAcross high-dimensional synthetic and real-world problems, including cases with\nthousands of variables and unknown active subspaces, NeST-BO consistently\nyields faster convergence and lower regret than state-of-the-art local and\nhigh-dimensional BO baselines.", "AI": {"tldr": "NeST-BO\u662f\u4e00\u79cd\u9488\u5bf9\u9ad8\u7ef4\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u5c40\u90e8\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u68af\u5ea6\u548c\u6d77\u68ee\u77e9\u9635\u4fe1\u606f\u6765\u903c\u8fd1\u725b\u987f\u6b65\uff0c\u5e76\u5229\u7528\u524d\u77bb\u8bef\u5dee\u754c\u9009\u62e9\u8bc4\u4f30\u70b9\uff0c\u5b9e\u73b0\u4e86\u5728\u968f\u673a\u5d4c\u5165\u6216\u7a00\u758f\u5b50\u7a7a\u95f4\u4e2d\u7684\u9ad8\u6548\u6269\u5c55\u3002", "motivation": "\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u9ad8\u7ef4\u95ee\u9898\u4e0a\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faNeST-BO\u65b9\u6cd5\uff0c\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\u8054\u5408\u5b66\u4e60\u68af\u5ea6\u548c\u6d77\u68ee\u77e9\u9635\u4fe1\u606f\uff0c\u901a\u8fc7\u4e00\u6b65\u524d\u77bb\u725b\u987f\u6b65\u8bef\u5dee\u754c\u9009\u62e9\u8bc4\u4f30\u70b9\uff0c\u5e76\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u4f18\u5316\u83b7\u53d6\u51fd\u6570\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728\u5305\u62ec\u6570\u5343\u4e2a\u53d8\u91cf\u548c\u672a\u77e5\u6d3b\u52a8\u5b50\u7a7a\u95f4\u7684\u9ad8\u7ef4\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u4e0a\uff0cNeST-BO\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5c40\u90e8\u548c\u9ad8\u7ef4\u8d1d\u53f6\u65af\u4f18\u5316\u57fa\u7ebf\u65b9\u6cd5\uff0c\u59cb\u7ec8\u8868\u73b0\u51fa\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u4f4e\u7684\u9057\u61be\u503c\u3002", "conclusion": "NeST-BO\u901a\u8fc7\u6709\u6548\u903c\u8fd1\u725b\u987f\u6b65\u5e76\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u9ad8\u7ef4\u8d1d\u53f6\u65af\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05526", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05526", "abs": "https://arxiv.org/abs/2510.05526", "authors": ["Ziyi Chen", "Junyi Li", "Peiran Yu", "Heng Huang"], "title": "Provably Mitigating Corruption, Overoptimization, and Verbosity Simultaneously in Offline and Online RLHF/DPO Alignment", "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) and direct preference\noptimization (DPO) are important techniques to align large language models\n(LLM) with human preference. However, the quality of RLHF and DPO training is\nseriously compromised by \\textit{\\textbf{C}orrupted} preference, reward\n\\textit{\\textbf{O}veroptimization}, and bias towards\n\\textit{\\textbf{V}erbosity}. To our knowledge, most existing works tackle only\none of these important issues, and the few other works require much computation\nto estimate multiple reward models and lack theoretical guarantee of\ngeneralization ability. In this work, we propose RLHF-\\textbf{COV} and\nDPO-\\textbf{COV} algorithms that can simultaneously mitigate these three\nissues, in both offline and online settings. This ability is theoretically\ndemonstrated by obtaining length-regularized generalization error rates for our\nDPO-COV algorithms trained on corrupted data, which match the best-known rates\nfor simpler cases with clean data and without length regularization. Moreover,\nour DPO-COV algorithm is simple to implement without reward estimation, and is\nproved to be equivalent to our RLHF-COV algorithm, which directly implies the\nequivalence between the vanilla RLHF and DPO algorithms. Experiments\ndemonstrate the effectiveness of our DPO-COV algorithms under both offline and\nonline settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86RLHF-COV\u548cDPO-COV\u7b97\u6cd5\uff0c\u540c\u65f6\u89e3\u51b3\u504f\u597d\u6570\u636e\u6c61\u67d3\u3001\u5956\u52b1\u8fc7\u4f18\u5316\u548c\u5197\u957f\u6027\u504f\u5dee\u4e09\u4e2a\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8bc1\u660e\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684RLHF\u548cDPO\u65b9\u6cd5\u5b58\u5728\u504f\u597d\u6570\u636e\u6c61\u67d3\u3001\u5956\u52b1\u8fc7\u4f18\u5316\u548c\u5197\u957f\u6027\u504f\u5dee\u4e09\u4e2a\u4e25\u91cd\u95ee\u9898\uff0c\u5927\u591a\u6570\u5de5\u4f5c\u53ea\u89e3\u51b3\u5176\u4e2d\u4e00\u4e2a\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86RLHF-COV\u548cDPO-COV\u7b97\u6cd5\uff0c\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u8bbe\u7f6e\u4e0b\u540c\u65f6\u89e3\u51b3\u4e09\u4e2a\u95ee\u9898\uff0cDPO-COV\u65e0\u9700\u5956\u52b1\u4f30\u8ba1\u4e14\u5b9e\u73b0\u7b80\u5355\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86DPO-COV\u5728\u6c61\u67d3\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u8bef\u5dee\u7387\u4e0e\u5e72\u51c0\u6570\u636e\u60c5\u51b5\u4e0b\u7684\u6700\u4f18\u5df2\u77e5\u7387\u5339\u914d\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u8bbe\u7f6e\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "RLHF-COV\u548cDPO-COV\u80fd\u540c\u65f6\u89e3\u51b3\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u7406\u8bba\u4e0a\u6709\u4fdd\u969c\uff0c\u5b9e\u9a8c\u6709\u6548\uff0c\u4e14\u8bc1\u660e\u4e86RLHF\u4e0eDPO\u7684\u7b49\u4ef7\u6027\u3002"}}
{"id": "2510.05527", "categories": ["cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.05527", "abs": "https://arxiv.org/abs/2510.05527", "authors": ["Yuyao Wang", "Yu-Hung Cheng", "Debarghya Mukherjee", "Huimin Cheng"], "title": "Transfer Learning on Edge Connecting Probability Estimation under Graphon Model", "comment": null, "summary": "Graphon models provide a flexible nonparametric framework for estimating\nlatent connectivity probabilities in networks, enabling a range of downstream\napplications such as link prediction and data augmentation. However, accurate\ngraphon estimation typically requires a large graph, whereas in practice, one\noften only observes a small-sized network. One approach to addressing this\nissue is to adopt a transfer learning framework, which aims to improve\nestimation in a small target graph by leveraging structural information from a\nlarger, related source graph. In this paper, we propose a novel method, namely\nGTRANS, a transfer learning framework that integrates neighborhood smoothing\nand Gromov-Wasserstein optimal transport to align and transfer structural\npatterns between graphs. To prevent negative transfer, GTRANS includes an\nadaptive debiasing mechanism that identifies and corrects for target-specific\ndeviations via residual smoothing. We provide theoretical guarantees on the\nstability of the estimated alignment matrix and demonstrate the effectiveness\nof GTRANS in improving the accuracy of target graph estimation through\nextensive synthetic and real data experiments. These improvements translate\ndirectly to enhanced performance in downstream applications, such as the graph\nclassification task and the link prediction task.", "AI": {"tldr": "\u63d0\u51fa\u4e86GTRANS\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u90bb\u57df\u5e73\u6ed1\u548cGromov-Wasserstein\u6700\u4f18\u4f20\u8f93\u5728\u76f8\u5173\u56fe\u4e4b\u95f4\u5bf9\u9f50\u548c\u4f20\u9012\u7ed3\u6784\u6a21\u5f0f\uff0c\u89e3\u51b3\u5c0f\u56fe\u7f51\u7edc\u4e2d\u7684\u56fe\u5143\u4f30\u8ba1\u95ee\u9898\u3002", "motivation": "\u56fe\u5143\u6a21\u578b\u9700\u8981\u5927\u56fe\u8fdb\u884c\u51c6\u786e\u4f30\u8ba1\uff0c\u4f46\u5b9e\u8df5\u4e2d\u5e38\u9047\u5230\u5c0f\u89c4\u6a21\u7f51\u7edc\u3002\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\u53ef\u5229\u7528\u76f8\u5173\u5927\u56fe\u7684\u7ed3\u4fe1\u606f\u63d0\u5347\u5c0f\u76ee\u6807\u56fe\u7684\u4f30\u8ba1\u7cbe\u5ea6\u3002", "method": "GTRANS\u7ed3\u5408\u90bb\u57df\u5e73\u6ed1\u548cGromov-Wasserstein\u6700\u4f18\u4f20\u8f93\u6765\u5bf9\u9f50\u56fe\u7ed3\u6784\uff0c\u5305\u542b\u81ea\u9002\u5e94\u53bb\u504f\u673a\u5236\u901a\u8fc7\u6b8b\u5dee\u5e73\u6ed1\u8bc6\u522b\u548c\u6821\u6b63\u76ee\u6807\u7279\u5b9a\u504f\u5dee\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u5bf9\u9f50\u77e9\u9635\u7684\u7a33\u5b9a\u6027\uff0c\u5b9e\u9a8c\u663e\u793aGTRANS\u80fd\u663e\u8457\u63d0\u9ad8\u76ee\u6807\u56fe\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u5e76\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u5982\u56fe\u5206\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u7684\u6027\u80fd\u3002", "conclusion": "GTRANS\u662f\u4e00\u4e2a\u6709\u6548\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u6210\u529f\u5229\u7528\u6e90\u56fe\u4fe1\u606f\u6539\u5584\u5c0f\u76ee\u6807\u56fe\u7684\u56fe\u5143\u4f30\u8ba1\uff0c\u9632\u6b62\u8d1f\u8fc1\u79fb\u5e76\u63d0\u5347\u4e0b\u6e38\u5e94\u7528\u6027\u80fd\u3002"}}
{"id": "2510.05528", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05528", "abs": "https://arxiv.org/abs/2510.05528", "authors": ["Lawrence Liu", "Alexander Liu", "Mengdi Wang", "Tuo Zhao", "Lin F. Yang"], "title": "ARMOR: High-Performance Semi-Structured Pruning via Adaptive Matrix Factorization", "comment": null, "summary": "Large language models (LLMs) present significant deployment challenges due to\ntheir immense computational and memory requirements. While semi-structured\npruning, particularly 2:4 sparsity, offers a path to practical hardware\nacceleration, existing methods often incur substantial performance degradation.\nTo bridge this gap, we introduce ARMOR: (Adaptive Representation with\nMatrix-factORization), a novel one-shot post-training pruning algorithm.\nInstead of directly pruning weights, ARMOR factorizes each weight matrix into a\n2:4 sparse core wrapped by two low-overhead, block diagonal matrices. These\nwrappers act as efficient pre and post-transformation error correctors,\noffering greater flexibility to preserve model quality compared to conventional\n2:4 pruning techniques. The sparse core and block diagonal wrappers are chosen\nthrough a block coordinate descent algorithm that minimizes a layer-wise proxy\nloss. We theoretically prove this optimization is guaranteed to converge to a\nsolution with a proxy loss less than or equal to state-of-the-art pruning\nalgorithms. Experiments on Llama (Touvron et al., 2023; Dubey et al., 2024) and\nQwen (Yang et al., 2025) model families demonstrate that ARMOR consistently and\nsignificantly outperforms state-of-the-art 2:4 pruning methods across a wide\nrange of downstream tasks and perplexity evaluations. ARMOR achieves this\nsuperior performance while retaining the inference speedups and substantial\nmemory usage reductions of 2:4 pruning, establishing a more effective trade-off\nbetween model compression and task accuracy", "AI": {"tldr": "ARMOR\u662f\u4e00\u79cd\u65b0\u578b\u7684\u4e00\u6b21\u6027\u8bad\u7ec3\u540e\u526a\u679d\u7b97\u6cd5\uff0c\u901a\u8fc7\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u5b9e\u73b02:4\u7a00\u758f\u5316\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u52a0\u901f\u548c\u5185\u5b58\u51cf\u5c11\u7684\u540c\u65f6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u67092:4\u526a\u679d\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u9762\u4e34\u5de8\u5927\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u6311\u6218\uff0c\u73b0\u67092:4\u7a00\u758f\u5316\u65b9\u6cd5\u901a\u5e38\u5bfc\u81f4\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u526a\u679d\u6280\u672f\u6765\u5e73\u8861\u6a21\u578b\u538b\u7f29\u548c\u4efb\u52a1\u7cbe\u5ea6\u3002", "method": "ARMOR\u5c06\u6bcf\u4e2a\u6743\u91cd\u77e9\u9635\u5206\u89e3\u4e3a2:4\u7a00\u758f\u6838\u5fc3\u548c\u4e24\u4e2a\u4f4e\u5f00\u9500\u7684\u5757\u5bf9\u89d2\u77e9\u9635\u5305\u88c5\u5668\uff0c\u901a\u8fc7\u5757\u5750\u6807\u4e0b\u964d\u7b97\u6cd5\u6700\u5c0f\u5316\u5c42\u95f4\u4ee3\u7406\u635f\u5931\u6765\u9009\u62e9\u7a00\u758f\u6838\u5fc3\u548c\u5757\u5bf9\u89d2\u5305\u88c5\u5668\u3002", "result": "\u5728Llama\u548cQwen\u6a21\u578b\u7cfb\u5217\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cARMOR\u5728\u4e0b\u6e38\u4efb\u52a1\u548c\u56f0\u60d1\u5ea6\u8bc4\u4f30\u4e2d\u6301\u7eed\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u76842:4\u526a\u679d\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u52a0\u901f\u548c\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u3002", "conclusion": "ARMOR\u5728\u6a21\u578b\u538b\u7f29\u548c\u4efb\u52a1\u7cbe\u5ea6\u4e4b\u95f4\u5efa\u7acb\u4e86\u66f4\u6709\u6548\u7684\u6743\u8861\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u7528\u786c\u4ef6\u52a0\u901f\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05530", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05530", "abs": "https://arxiv.org/abs/2510.05530", "authors": ["Harshil Vejendla"], "title": "LATTA: Langevin-Anchored Test-Time Adaptation for Enhanced Robustness and Stability", "comment": "MIT URTC 2025 Technical Paper (Oral), 5 pages, 3 figures", "summary": "Test-time adaptation (TTA) aims to adapt a pretrained model to distribution\nshifts using only unlabeled test data. While promising, existing methods like\nTent suffer from instability and can catastrophically forget the source\nknowledge, especially with small batch sizes or challenging corruptions. We\nargue that this arises from overly deterministic updates on a complex loss\nsurface. In this paper, we introduce Langevin-Anchored Test-Time Adaptation\n(LATTA), a novel approach that regularizes adaptation through two key\nmechanisms: (1) a noisy weight perturbation inspired by Stochastic Gradient\nLangevin Dynamics (SGLD) to explore the local parameter space and escape poor\nlocal minima, and (2) a stable weight anchor that prevents the model from\ndiverging from its robust source pre-training. This combination allows LATTA to\nadapt effectively without sacrificing stability. Unlike prior Bayesian TTA\nmethods, LATTA requires no architectural changes or expensive Monte Carlo\npasses. We conduct extensive experiments on standard benchmarks, including\nRotated-MNIST and the more challenging CIFAR-10-C. Our results demonstrate that\nLATTA significantly outperforms existing methods, including Tent, CoTTA, and\nEATA, setting a new state of the art for self-supervised TTA by improving\naverage accuracy on CIFAR-10-C by over 2% while simultaneously reducing\nperformance variance.", "AI": {"tldr": "LATTA\u662f\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u566a\u58f0\u6270\u52a8\u548c\u7a33\u5b9a\u6743\u91cd\u951a\u70b9\u673a\u5236\uff0c\u5728\u4fdd\u6301\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u6709\u6548\u9002\u5e94\u5206\u5e03\u504f\u79fb\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff08\u5982Tent\uff09\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u548c\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5c0f\u6279\u91cf\u6216\u6311\u6218\u6027\u6570\u636e\u635f\u574f\u60c5\u51b5\u4e0b\uff0c\u8fd9\u6e90\u4e8e\u5728\u590d\u6742\u635f\u5931\u8868\u9762\u4e0a\u8fc7\u4e8e\u786e\u5b9a\u6027\u7684\u66f4\u65b0\u3002", "method": "\u63d0\u51faLangevin-Anchored\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94(LATTA)\uff1a1) \u53d7\u968f\u673a\u68af\u5ea6\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u542f\u53d1\u7684\u566a\u58f0\u6743\u91cd\u6270\u52a8\uff0c\u63a2\u7d22\u5c40\u90e8\u53c2\u6570\u7a7a\u95f4\u5e76\u9003\u79bb\u4e0d\u826f\u5c40\u90e8\u6700\u5c0f\u503c\uff1b2) \u7a33\u5b9a\u6743\u91cd\u951a\u70b9\u9632\u6b62\u6a21\u578b\u504f\u79bb\u5176\u9c81\u68d2\u7684\u6e90\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\uff08Rotated-MNIST\u548cCIFAR-10-C\uff09\u4e0a\uff0cLATTA\u663e\u8457\u4f18\u4e8eTent\u3001CoTTA\u548cEATA\u7b49\u65b9\u6cd5\uff0c\u5728CIFAR-10-C\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u8d85\u8fc72%\uff0c\u540c\u65f6\u964d\u4f4e\u6027\u80fd\u65b9\u5dee\uff0c\u521b\u4e0b\u81ea\u76d1\u7763TTA\u7684\u65b0\u6700\u4f18\u6c34\u5e73\u3002", "conclusion": "LATTA\u901a\u8fc7\u7ed3\u5408\u566a\u58f0\u63a2\u7d22\u548c\u7a33\u5b9a\u951a\u70b9\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u4e14\u7a33\u5b9a\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\uff0c\u65e0\u9700\u67b6\u6784\u66f4\u6539\u6216\u6602\u8d35\u7684\u8499\u7279\u5361\u6d1b\u8ba1\u7b97\uff0c\u4e3a\u5904\u7406\u5206\u5e03\u504f\u79fb\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05535", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05535", "abs": "https://arxiv.org/abs/2510.05535", "authors": ["Rui Liu", "Tao Zhe", "Yanjie Fu", "Feng Xia", "Ted Senator", "Dongjie Wang"], "title": "Permutation-Invariant Representation Learning for Robust and Privacy-Preserving Feature Selection", "comment": null, "summary": "Feature selection eliminates redundancy among features to improve downstream\ntask performance while reducing computational overhead. Existing methods often\nstruggle to capture intricate feature interactions and adapt across diverse\napplication scenarios. Recent advances employ generative intelligence to\nalleviate these drawbacks. However, these methods remain constrained by\npermutation sensitivity in embedding and reliance on convexity assumptions in\ngradient-based search. To address these limitations, our initial work\nintroduces a novel framework that integrates permutation-invariant embedding\nwith policy-guided search. Although effective, it still left opportunities to\nadapt to realistic distributed scenarios. In practice, data across local\nclients is highly imbalanced, heterogeneous and constrained by strict privacy\nregulations, limiting direct sharing. These challenges highlight the need for a\nframework that can integrate feature selection knowledge across clients without\nexposing sensitive information. In this extended journal version, we advance\nthe framework from two perspectives: 1) developing a privacy-preserving\nknowledge fusion strategy to derive a unified representation space without\nsharing sensitive raw data. 2) incorporating a sample-aware weighting strategy\nto address distributional imbalance among heterogeneous local clients.\nExtensive experiments validate the effectiveness, robustness, and efficiency of\nour framework. The results further demonstrate its strong generalization\nability in federated learning scenarios. The code and data are publicly\navailable: https://anonymous.4open.science/r/FedCAPS-08BF.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u878d\u5408\u548c\u6837\u672c\u611f\u77e5\u52a0\u6743\u7b56\u7565\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u548c\u9690\u79c1\u95ee\u9898", "motivation": "\u73b0\u6709\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u590d\u6742\u7279\u5f81\u4ea4\u4e92\u4e14\u4e0d\u9002\u5e94\u5206\u5e03\u5f0f\u573a\u666f\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u4e0d\u5e73\u8861\u3001\u5f02\u6784\u548c\u9690\u79c1\u7ea6\u675f\u7684\u73b0\u5b9e\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d", "method": "\u96c6\u6210\u7f6e\u6362\u4e0d\u53d8\u5d4c\u5165\u4e0e\u7b56\u7565\u5f15\u5bfc\u641c\u7d22\uff0c\u5f00\u53d1\u9690\u79c1\u4fdd\u62a4\u77e5\u8bc6\u878d\u5408\u7b56\u7565\u548c\u6837\u672c\u611f\u77e5\u52a0\u6743\u7b56\u7565\u6765\u5904\u7406\u6570\u636e\u5f02\u6784\u6027", "result": "\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u7684\u7279\u5f81\u9009\u62e9\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u7684\u77e5\u8bc6\u878d\u5408\u548c\u5206\u5e03\u4e0d\u5e73\u8861\u5904\u7406"}}
{"id": "2510.05554", "categories": ["cs.LG", "cs.AI", "cs.DM", "math.CA"], "pdf": "https://arxiv.org/pdf/2510.05554", "abs": "https://arxiv.org/abs/2510.05554", "authors": ["Shi Chen", "Zhengjiang Lin", "Yury Polyanskiy", "Philippe Rigollet"], "title": "Critical attention scaling in long-context transformers", "comment": "29 pages, 2 figures", "summary": "As large language models scale to longer contexts, attention layers suffer\nfrom a fundamental pathology: attention scores collapse toward uniformity as\ncontext length $n$ increases, causing tokens to cluster excessively, a\nphenomenon known as rank-collapse. While $\\textit{attention scaling}$\neffectively addresses this deficiency by rescaling attention scores with a\npolylogarithmic factor $\\beta_n$, theoretical justification for this approach\nremains lacking.\n  We analyze a simplified yet tractable model that magnifies the effect of\nattention scaling. In this model, attention exhibits a phase transition\ngoverned by the scaling factor $\\beta_n$: insufficient scaling collapses all\ntokens to a single direction, while excessive scaling reduces attention to\nidentity, thereby eliminating meaningful interactions between tokens. Our main\nresult identifies the critical scaling $\\beta_n \\asymp \\log n$ and provides a\nrigorous justification for attention scaling in YaRN and Qwen, clarifying why\nlogarithmic scaling maintains sparse, content-adaptive attention at large\ncontext lengths.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u957f\u4e0a\u4e0b\u6587\u4e0b\u6ce8\u610f\u529b\u673a\u5236\u7684\u75c5\u7406\u73b0\u8c61\u2014\u2014\u6ce8\u610f\u529b\u5206\u6570\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u800c\u8d8b\u4e8e\u5747\u5300\u5316\uff08rank-collapse\uff09\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u6ce8\u610f\u529b\u7f29\u653e\u7684\u5fc5\u8981\u6027\uff0c\u53d1\u73b0\u4e34\u754c\u7f29\u653e\u56e0\u5b50\u4e3a\u03b2_n \u221d log n\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\uff0c\u6ce8\u610f\u529b\u5c42\u51fa\u73b0\u6839\u672c\u6027\u75c5\u7406\uff1a\u6ce8\u610f\u529b\u5206\u6570\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u800c\u5d29\u6e83\u4e3a\u5747\u5300\u5206\u5e03\uff0c\u5bfc\u81f4token\u8fc7\u5ea6\u805a\u7c7b\u3002\u867d\u7136\u6ce8\u610f\u529b\u7f29\u653e\u901a\u8fc7\u591a\u5bf9\u6570\u56e0\u5b50\u03b2_n\u91cd\u65b0\u7f29\u653e\u6ce8\u610f\u529b\u5206\u6570\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u8be5\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86\u4e00\u4e2a\u7b80\u5316\u4f46\u53ef\u5904\u7406\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u653e\u5927\u4e86\u6ce8\u610f\u529b\u7f29\u653e\u7684\u6548\u679c\u3002\u5728\u8be5\u6a21\u578b\u4e2d\uff0c\u6ce8\u610f\u529b\u8868\u73b0\u51fa\u7531\u7f29\u653e\u56e0\u5b50\u03b2_n\u63a7\u5236\u7684\u76f8\u53d8\uff1a\u7f29\u653e\u4e0d\u8db3\u4f1a\u4f7f\u6240\u6709token\u574d\u7f29\u5230\u5355\u4e00\u65b9\u5411\uff0c\u800c\u8fc7\u5ea6\u7f29\u653e\u5219\u4f7f\u6ce8\u610f\u529b\u9000\u5316\u4e3a\u6052\u7b49\u53d8\u6362\uff0c\u6d88\u9664token\u95f4\u7684\u6709\u610f\u4e49\u7684\u4ea4\u4e92\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u786e\u5b9a\u4e86\u4e34\u754c\u7f29\u653e\u03b2_n \u221d log n\uff0c\u5e76\u4e3aYaRN\u548cQwen\u4e2d\u7684\u6ce8\u610f\u529b\u7f29\u653e\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u4f9d\u636e\uff0c\u9610\u660e\u4e86\u4e3a\u4ec0\u4e48\u5bf9\u6570\u7f29\u653e\u80fd\u5728\u957f\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u4fdd\u6301\u7a00\u758f\u3001\u5185\u5bb9\u81ea\u9002\u5e94\u7684\u6ce8\u610f\u529b\u3002", "conclusion": "\u7814\u7a76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u6ce8\u610f\u529b\u7f29\u653e\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u5fc5\u8981\u6027\uff0c\u786e\u5b9a\u4e86\u4e34\u754c\u7f29\u653e\u56e0\u5b50\u4e3a\u5bf9\u6570\u5c3a\u5ea6\uff0c\u4e3a\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6491\uff0c\u5e76\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u5bf9\u6570\u7f29\u653e\u80fd\u6709\u6548\u7ef4\u6301\u6ce8\u610f\u529b\u7684\u7a00\u758f\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2510.05562", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05562", "abs": "https://arxiv.org/abs/2510.05562", "authors": ["Sheng Xiang", "Yidong Jiang", "Yunting Chen", "Dawei Cheng", "Guoping Zhao", "Changjun Jiang"], "title": "Generative Dynamic Graph Representation Learning for Conspiracy Spoofing Detection", "comment": "10 pages, 5 figures, ACM the web conference 2025", "summary": "Spoofing detection in financial trading is crucial, especially for\nidentifying complex behaviors such as conspiracy spoofing. Traditional\nmachine-learning approaches primarily focus on isolated node features, often\noverlooking the broader context of interconnected nodes. Graph-based\ntechniques, particularly Graph Neural Networks (GNNs), have advanced the field\nby leveraging relational information effectively. However, in real-world\nspoofing detection datasets, trading behaviors exhibit dynamic, irregular\npatterns. Existing spoofing detection methods, though effective in some\nscenarios, struggle to capture the complexity of dynamic and diverse, evolving\ninter-node relationships. To address these challenges, we propose a novel\nframework called the Generative Dynamic Graph Model (GDGM), which models\ndynamic trading behaviors and the relationships among nodes to learn\nrepresentations for conspiracy spoofing detection. Specifically, our approach\nincorporates the generative dynamic latent space to capture the temporal\npatterns and evolving market conditions. Raw trading data is first converted\ninto time-stamped sequences. Then we model trading behaviors using the neural\nordinary differential equations and gated recurrent units, to generate the\nrepresentation incorporating temporal dynamics of spoofing patterns.\nFurthermore, pseudo-label generation and heterogeneous aggregation techniques\nare employed to gather relevant information and enhance the detection\nperformance for conspiratorial spoofing behaviors. Experiments conducted on\nspoofing detection datasets demonstrate that our approach outperforms\nstate-of-the-art models in detection accuracy. Additionally, our spoofing\ndetection system has been successfully deployed in one of the largest global\ntrading markets, further validating the practical applicability and performance\nof the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGDGM\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u91d1\u878d\u4ea4\u6613\u4e2d\u7684\u5408\u8c0b\u6b3a\u9a97\u68c0\u6d4b\uff0c\u901a\u8fc7\u751f\u6210\u52a8\u6001\u56fe\u6a21\u578b\u6355\u6349\u52a8\u6001\u4ea4\u6613\u884c\u4e3a\u548c\u8282\u70b9\u95f4\u5173\u7cfb\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u8282\u70b9\u7279\u5f81\uff0c\u5ffd\u7565\u4e86\u8282\u70b9\u95f4\u7684\u5173\u8054\uff1b\u73b0\u6709\u6b3a\u9a97\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u52a8\u6001\u3001\u591a\u6837\u5316\u7684\u8282\u70b9\u95f4\u5173\u7cfb\u6f14\u5316\u3002", "method": "\u4f7f\u7528\u751f\u6210\u52a8\u6001\u6f5c\u5728\u7a7a\u95f4\u6355\u6349\u65f6\u95f4\u6a21\u5f0f\u548c\u6f14\u5316\u5e02\u573a\u6761\u4ef6\uff0c\u5c06\u539f\u59cb\u4ea4\u6613\u6570\u636e\u8f6c\u6362\u4e3a\u65f6\u95f4\u6233\u5e8f\u5217\uff0c\u901a\u8fc7\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\u5efa\u6a21\u4ea4\u6613\u884c\u4e3a\uff0c\u5e76\u91c7\u7528\u4f2a\u6807\u7b7e\u751f\u6210\u548c\u5f02\u8d28\u805a\u5408\u6280\u672f\u589e\u5f3a\u68c0\u6d4b\u6027\u80fd\u3002", "result": "\u5728\u6b3a\u9a97\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u5df2\u6210\u529f\u90e8\u7f72\u4e8e\u5168\u7403\u6700\u5927\u7684\u4ea4\u6613\u5e02\u573a\u4e4b\u4e00\u3002", "conclusion": "GDGM\u6846\u67b6\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5408\u8c0b\u6b3a\u9a97\u884c\u4e3a\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u548c\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.05569", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05569", "abs": "https://arxiv.org/abs/2510.05569", "authors": ["Sheng Xiang", "Chenhao Xu", "Dawei Cheng", "Xiaoyang Wang", "Ying Zhang"], "title": "Efficient Learning-based Graph Simulation for Temporal Graphs", "comment": "14 pages, 6 figures, IEEE ICDE 2025", "summary": "Graph simulation has recently received a surge of attention in graph\nprocessing and analytics. In real-life applications, e.g. social science,\nbiology, and chemistry, many graphs are composed of a series of evolving graphs\n(i.e., temporal graphs). While most of the existing graph generators focus on\nstatic graphs, the temporal information of the graphs is ignored. In this\npaper, we focus on simulating temporal graphs, which aim to reproduce the\nstructural and temporal properties of the observed real-life temporal graphs.\nIn this paper, we first give an overview of the existing temporal graph\ngenerators, including recently emerged learning-based approaches. Most of these\nlearning-based methods suffer from one of the limitations: low efficiency in\ntraining or slow generating, especially for temporal random walk-based methods.\nTherefore, we propose an efficient learning-based approach to generate graph\nsnapshots, namely temporal graph autoencoder (TGAE). Specifically, we propose\nan attention-based graph encoder to encode temporal and structural\ncharacteristics on sampled ego-graphs. And we proposed an ego-graph decoder\nthat can achieve a good trade-off between simulation quality and efficiency in\ntemporal graph generation. Finally, the experimental evaluation is conducted\namong our proposed TGAE and representative temporal graph generators on\nreal-life temporal graphs and synthesized graphs. It is reported that our\nproposed approach outperforms the state-of-the-art temporal graph generators by\nmeans of simulation quality and efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u65f6\u5e8f\u56fe\u751f\u6210\u65b9\u6cd5TGAE\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u56fe\u7f16\u7801\u5668\u548c\u81ea\u6211\u56fe\u89e3\u7801\u5668\uff0c\u5728\u6a21\u62df\u8d28\u91cf\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u4f18\u4e8e\u73b0\u6709\u65f6\u5e8f\u56fe\u751f\u6210\u5668\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u8bb8\u591a\u56fe\u662f\u65f6\u5e8f\u6f14\u5316\u7684\uff0c\u4f46\u73b0\u6709\u56fe\u751f\u6210\u5668\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u56fe\uff0c\u5ffd\u7565\u4e86\u65f6\u5e8f\u4fe1\u606f\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u5b58\u5728\u8bad\u7ec3\u6548\u7387\u4f4e\u6216\u751f\u6210\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65f6\u5e8f\u56fe\u81ea\u7f16\u7801\u5668(TGAE)\uff0c\u4f7f\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u56fe\u7f16\u7801\u5668\u5728\u91c7\u6837\u7684\u81ea\u6211\u56fe\u4e0a\u7f16\u7801\u65f6\u5e8f\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u4ee5\u53ca\u81ea\u6211\u56fe\u89e3\u7801\u5668\u6765\u5b9e\u73b0\u9ad8\u6548\u7684\u65f6\u5e8f\u56fe\u751f\u6210\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u65f6\u5e8f\u56fe\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTGAE\u5728\u6a21\u62df\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65f6\u5e8f\u56fe\u751f\u6210\u5668\u3002", "conclusion": "TGAE\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6a21\u62df\u65f6\u5e8f\u56fe\u7684\u7ed3\u6784\u548c\u65f6\u5e8f\u7279\u6027\uff0c\u5728\u8d28\u91cf\u548c\u6548\u7387\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2510.05581", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.05581", "abs": "https://arxiv.org/abs/2510.05581", "authors": ["Praneeth Vepakomma", "Kaustubh Ponkshe"], "title": "Power Mechanism: Private Tabular Representation Release for Model Agnostic Consumption", "comment": null, "summary": "Traditional collaborative learning approaches are based on sharing of model\nweights between clients and a server. However, there are advantages to resource\nefficiency through schemes based on sharing of embeddings (activations) created\nfrom the data. Several differentially private methods were developed for\nsharing of weights while such mechanisms do not exist so far for sharing of\nembeddings. We propose Ours to learn a privacy encoding network in conjunction\nwith a small utility generation network such that the final embeddings\ngenerated from it are equipped with formal differential privacy guarantees.\nThese privatized embeddings are then shared with a more powerful server, that\nlearns a post-processing that results in a higher accuracy for machine learning\ntasks. We show that our co-design of collaborative and private learning results\nin requiring only one round of privatized communication and lesser compute on\nthe client than traditional methods. The privatized embeddings that we share\nfrom the client are agnostic to the type of model (deep learning, random\nforests or XGBoost) used on the server in order to process these activations to\ncomplete a task.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u5171\u4eab\u7684\u5dee\u5206\u9690\u79c1\u534f\u4f5c\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u9690\u79c1\u7f16\u7801\u7f51\u7edc\u548c\u6548\u7528\u751f\u6210\u7f51\u7edc\u751f\u6210\u5177\u6709\u6b63\u5f0f\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u7684\u5d4c\u5165\uff0c\u53ea\u9700\u4e00\u8f6e\u79c1\u6709\u5316\u901a\u4fe1\u4e14\u5ba2\u6237\u7aef\u8ba1\u7b97\u91cf\u66f4\u5c11\u3002", "motivation": "\u4f20\u7edf\u7684\u534f\u4f5c\u5b66\u4e60\u57fa\u4e8e\u6a21\u578b\u6743\u91cd\u5171\u4eab\uff0c\u4f46\u57fa\u4e8e\u5d4c\u5165\u5171\u4eab\u7684\u65b9\u6848\u5728\u8d44\u6e90\u6548\u7387\u65b9\u9762\u6709\u4f18\u52bf\u3002\u76ee\u524d\u5b58\u5728\u6743\u91cd\u5171\u4eab\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u5d4c\u5165\u5171\u4eab\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u9690\u79c1\u7f16\u7801\u7f51\u7edc\u548c\u6548\u7528\u751f\u6210\u7f51\u7edc\uff0c\u751f\u6210\u5177\u6709\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u7684\u5d4c\u5165\u3002\u8fd9\u4e9b\u79c1\u6709\u5316\u5d4c\u5165\u4e0e\u66f4\u5f3a\u5927\u7684\u670d\u52a1\u5668\u5171\u4eab\uff0c\u670d\u52a1\u5668\u5b66\u4e60\u540e\u5904\u7406\u4ee5\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u53ea\u9700\u4e00\u8f6e\u79c1\u6709\u5316\u901a\u4fe1\uff0c\u5ba2\u6237\u7aef\u8ba1\u7b97\u91cf\u5c11\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u79c1\u6709\u5316\u5d4c\u5165\u4e0e\u670d\u52a1\u5668\u6a21\u578b\u7c7b\u578b\u65e0\u5173\uff08\u6df1\u5ea6\u5b66\u4e60\u3001\u968f\u673a\u68ee\u6797\u6216XGBoost\u5747\u53ef\u4f7f\u7528\uff09\u3002", "conclusion": "\u901a\u8fc7\u534f\u4f5c\u5b66\u4e60\u548c\u9690\u79c1\u5b66\u4e60\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5dee\u5206\u9690\u79c1\u5d4c\u5165\u5171\u4eab\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8d44\u6e90\u6548\u7387\u3002"}}
{"id": "2510.05582", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05582", "abs": "https://arxiv.org/abs/2510.05582", "authors": ["Jiashu Tao", "Reza Shokri"], "title": "(Token-Level) \\textbf{InfoRMIA}: Stronger Membership Inference and Memorization Assessment for LLMs", "comment": null, "summary": "Machine learning models are known to leak sensitive information, as they\ninevitably memorize (parts of) their training data. More alarmingly, large\nlanguage models (LLMs) are now trained on nearly all available data, which\namplifies the magnitude of information leakage and raises serious privacy\nrisks. Hence, it is more crucial than ever to quantify privacy risk before the\nrelease of LLMs. The standard method to quantify privacy is via membership\ninference attacks, where the state-of-the-art approach is the Robust Membership\nInference Attack (RMIA). In this paper, we present InfoRMIA, a principled\ninformation-theoretic formulation of membership inference. Our method\nconsistently outperforms RMIA across benchmarks while also offering improved\ncomputational efficiency.\n  In the second part of the paper, we identify the limitations of treating\nsequence-level membership inference as the gold standard for measuring leakage.\nWe propose a new perspective for studying membership and memorization in LLMs:\ntoken-level signals and analyses. We show that a simple token-based InfoRMIA\ncan pinpoint which tokens are memorized within generated outputs, thereby\nlocalizing leakage from the sequence level down to individual tokens, while\nachieving stronger sequence-level inference power on LLMs. This new scope\nrethinks privacy in LLMs and can lead to more targeted mitigation, such as\nexact unlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e86InfoRMIA\uff0c\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165token\u7ea7\u5206\u6790\u6765\u7cbe\u786e\u5b9a\u4f4dLLM\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\uff0c\u5bfc\u81f4\u4e25\u91cd\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faInfoRMIA\u4fe1\u606f\u8bba\u6210\u5458\u63a8\u7406\u653b\u51fb\u6846\u67b6\uff0c\u5305\u62ec\u5e8f\u5217\u7ea7\u548ctoken\u7ea7\u4e24\u4e2a\u5c42\u9762\u7684\u5206\u6790\uff0c\u80fd\u591f\u7cbe\u786e\u5b9a\u4f4d\u6cc4\u9732\u7684\u5177\u4f53token\u3002", "result": "InfoRMIA\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5RMIA\uff0c\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff0ctoken\u7ea7\u5206\u6790\u80fd\u6709\u6548\u5b9a\u4f4d\u5177\u4f53\u6cc4\u9732\u5185\u5bb9\u3002", "conclusion": "token\u7ea7\u6210\u5458\u63a8\u7406\u4e3aLLM\u9690\u79c1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u9488\u5bf9\u6027\u7f13\u89e3\u63aa\u65bd\u5982\u7cbe\u786e\u9057\u5fd8\u3002"}}
{"id": "2510.05589", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05589", "abs": "https://arxiv.org/abs/2510.05589", "authors": ["Kangjia Yan", "Chenxi Liu", "Hao Miao", "Xinle Wu", "Yan Zhao", "Chenjuan Guo", "Bin Yang"], "title": "Deciphering Invariant Feature Decoupling in Source-free Time Series Forecasting with Proxy Denoising", "comment": null, "summary": "The proliferation of mobile devices generates a massive volume of time series\nacross various domains, where effective time series forecasting enables a\nvariety of real-world applications. This study focuses on a new problem of\nsource-free domain adaptation for time series forecasting. It aims to adapt a\npretrained model from sufficient source time series to the sparse target time\nseries domain without access to the source data, embracing data protection\nregulations. To achieve this, we propose TimePD, the first source-free time\nseries forecasting framework with proxy denoising, where large language models\n(LLMs) are employed to benefit from their generalization capabilities.\nSpecifically, TimePD consists of three key components: (1) dual-branch\ninvariant disentangled feature learning that enforces representation- and\ngradient-wise invariance by means of season-trend decomposition; (2)\nlightweight, parameter-free proxy denoising that dynamically calibrates\nsystematic biases of LLMs; and (3) knowledge distillation that bidirectionally\naligns the denoised prediction and the original target prediction. Extensive\nexperiments on real-world datasets offer insight into the effectiveness of the\nproposed TimePD, outperforming SOTA baselines by 9.3% on average.", "AI": {"tldr": "TimePD\u662f\u9996\u4e2a\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6e90\u81ea\u7531\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7406\u53bb\u566a\u548cLLM\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u65e0\u6cd5\u8bbf\u95ee\u6e90\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u4ece\u5145\u8db3\u6e90\u65f6\u95f4\u5e8f\u5217\u9002\u914d\u5230\u7a00\u758f\u76ee\u6807\u65f6\u95f4\u5e8f\u5217\u3002", "motivation": "\u79fb\u52a8\u8bbe\u5907\u4ea7\u751f\u5927\u91cf\u8de8\u9886\u57df\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u9700\u8981\u5728\u4e0d\u8fdd\u53cd\u6570\u636e\u4fdd\u62a4\u6cd5\u89c4\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u4ece\u6e90\u57df\u9002\u914d\u5230\u76ee\u6807\u57df\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "method": "\u63d0\u51faTimePD\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u53cc\u5206\u652f\u4e0d\u53d8\u89e3\u8026\u7279\u5f81\u5b66\u4e60\uff08\u57fa\u4e8e\u5b63\u8282\u8d8b\u52bf\u5206\u89e3\uff09\u3001\u8f7b\u91cf\u7ea7\u65e0\u53c2\u6570\u4ee3\u7406\u53bb\u566a\uff08\u52a8\u6001\u6821\u51c6LLM\u7cfb\u7edf\u504f\u5dee\uff09\u3001\u53cc\u5411\u77e5\u8bc6\u84b8\u998f\uff08\u5bf9\u9f50\u53bb\u566a\u9884\u6d4b\u548c\u539f\u59cb\u76ee\u6807\u9884\u6d4b\uff09\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTimePD\u5e73\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd59.3%\u3002", "conclusion": "TimePD\u901a\u8fc7\u7ed3\u5408LLM\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4ee3\u7406\u53bb\u566a\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6e90\u81ea\u7531\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u57df\u81ea\u9002\u5e94\u95ee\u9898\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.05606", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05606", "abs": "https://arxiv.org/abs/2510.05606", "authors": ["Andrew Ly", "Pulin Gong"], "title": "Riddled basin geometry sets fundamental limits to predictability and reproducibility in deep learning", "comment": null, "summary": "Fundamental limits to predictability are central to our understanding of many\nphysical and computational systems. Here we show that, despite its remarkable\ncapabilities, deep learning exhibits such fundamental limits rooted in the\nfractal, riddled geometry of its basins of attraction: any initialization that\nleads to one solution lies arbitrarily close to another that leads to a\ndifferent one. We derive sufficient conditions for the emergence of riddled\nbasins by analytically linking features widely observed in deep learning,\nincluding chaotic learning dynamics and symmetry-induced invariant subspaces,\nto reveal a general route to riddling in realistic deep networks. The resulting\nbasins of attraction possess an infinitely fine-scale fractal structure\ncharacterized by an uncertainty exponent near zero, so that even large\nincreases in the precision of initial conditions yield only marginal gains in\noutcome predictability. Riddling thus imposes a fundamental limit on the\npredictability and hence reproducibility of neural network training, providing\na unified account of many empirical observations. These results reveal a\ngeneral organizing principle of deep learning with important implications for\noptimization and the safe deployment of artificial intelligence.", "AI": {"tldr": "\u6df1\u5ea6\u5b66\u4e60\u5b58\u5728\u6839\u672c\u7684\u53ef\u9884\u6d4b\u6027\u9650\u5236\uff0c\u6e90\u4e8e\u5176\u5438\u5f15\u76c6\u7684\u788e\u5f62\u51e0\u4f55\u7ed3\u6784\uff1a\u4efb\u4f55\u5bfc\u81f4\u4e00\u4e2a\u89e3\u7684\u521d\u59cb\u5316\u90fd\u65e0\u9650\u63a5\u8fd1\u53e6\u4e00\u4e2a\u5bfc\u81f4\u4e0d\u540c\u89e3\u7684\u521d\u59cb\u5316\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6839\u672c\u53ef\u9884\u6d4b\u6027\u9650\u5236\uff0c\u63ed\u793a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7ed3\u679c\u96be\u4ee5\u9884\u6d4b\u548c\u590d\u73b0\u7684\u6df1\u5c42\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u89c2\u5bdf\u5230\u7684\u7279\u5f81\uff08\u5305\u62ec\u6df7\u6c8c\u5b66\u4e60\u52a8\u6001\u548c\u5bf9\u79f0\u6027\u8bf1\u5bfc\u7684\u4e0d\u53d8\u5b50\u7a7a\u95f4\uff09\uff0c\u63a8\u5bfc\u51fa\u788e\u5f62\u5438\u5f15\u76c6\u51fa\u73b0\u7684\u5145\u5206\u6761\u4ef6\u3002", "result": "\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u5438\u5f15\u76c6\u5177\u6709\u65e0\u9650\u7cbe\u7ec6\u7684\u788e\u5f62\u7ed3\u6784\uff0c\u4e0d\u786e\u5b9a\u6027\u6307\u6570\u63a5\u8fd1\u96f6\uff0c\u5373\u4f7f\u5927\u5e45\u63d0\u9ad8\u521d\u59cb\u6761\u4ef6\u7cbe\u5ea6\u4e5f\u53ea\u80fd\u7565\u5fae\u6539\u5584\u7ed3\u679c\u53ef\u9884\u6d4b\u6027\u3002", "conclusion": "\u788e\u5f62\u5438\u5f15\u76c6\u5bf9\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u53ef\u9884\u6d4b\u6027\u548c\u53ef\u590d\u73b0\u6027\u65bd\u52a0\u4e86\u6839\u672c\u9650\u5236\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u7ec4\u7ec7\u539f\u5219\uff0c\u5bf9\u4f18\u5316\u548cAI\u5b89\u5168\u90e8\u7f72\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.05620", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.05620", "abs": "https://arxiv.org/abs/2510.05620", "authors": ["Salah Eddine Choutri", "Prajwal Chauhan", "Othmane Mazhar", "Saif Eddin Jabari"], "title": "Monte Carlo-Type Neural Operator for Differential Equations", "comment": null, "summary": "The Monte Carlo-type Neural Operator (MCNO) introduces a framework for\nlearning solution operators of one-dimensional partial differential equations\n(PDEs) by directly learning the kernel function and approximating the\nassociated integral operator using a Monte Carlo-type approach. Unlike Fourier\nNeural Operators (FNOs), which rely on spectral representations and assume\ntranslation-invariant kernels, MCNO makes no such assumptions. The kernel is\nrepresented as a learnable tensor over sampled input-output pairs, and sampling\nis performed once, uniformly at random from a discretized grid. This design\nenables generalization across multiple grid resolutions without relying on\nfixed global basis functions or repeated sampling during training, while an\ninterpolation step maps between arbitrary input and output grids to further\nenhance flexibility. Experiments on standard 1D PDE benchmarks show that MCNO\nachieves competitive accuracy with efficient computational cost. We also\nprovide a theoretical analysis proving that the Monte Carlo estimator yields a\nbounded bias and variance under mild regularity assumptions. This result holds\nin any spatial dimension, suggesting that MCNO may extend naturally beyond\none-dimensional problems. More broadly, this work explores how Monte Carlo-type\nintegration can be incorporated into neural operator frameworks for\ncontinuous-domain PDEs, providing a theoretically supported alternative to\nspectral methods (such as FNO) and to graph-based Monte Carlo approaches (such\nas the Graph Kernel Neural Operator, GNO).", "AI": {"tldr": "MCNO\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u4e00\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\u89e3\u7b97\u5b50\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u6838\u51fd\u6570\u5e76\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u8fd1\u4f3c\u76f8\u5173\u79ef\u5206\u7b97\u5b50\uff0c\u65e0\u9700\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u7684\u5e73\u79fb\u4e0d\u53d8\u6027\u5047\u8bbe\u3002", "motivation": "\u4e3a\u504f\u5fae\u5206\u65b9\u7a0b\u63d0\u4f9b\u4e00\u79cd\u4e0d\u4f9d\u8d56\u8c31\u8868\u793a\u6216\u5e73\u79fb\u4e0d\u53d8\u6027\u5047\u8bbe\u7684\u795e\u7ecf\u7b97\u5b50\u6846\u67b6\uff0c\u63a2\u7d22\u8499\u7279\u5361\u6d1b\u79ef\u5206\u5728\u8fde\u7eed\u57dfPDE\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5c06\u6838\u51fd\u6570\u8868\u793a\u4e3a\u53ef\u5b66\u4e60\u5f20\u91cf\uff0c\u5728\u79bb\u6563\u7f51\u683c\u4e0a\u5747\u5300\u968f\u673a\u91c7\u6837\u4e00\u6b21\uff0c\u901a\u8fc7\u63d2\u503c\u6b65\u9aa4\u5728\u4e0d\u540c\u7f51\u683c\u95f4\u6620\u5c04\uff0c\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\u8fd1\u4f3c\u79ef\u5206\u7b97\u5b50\u3002", "result": "\u5728\u6807\u51c61D PDE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u7ade\u4e89\u6027\u7cbe\u5ea6\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u7406\u8bba\u5206\u6790\u8bc1\u660e\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\u5728\u6e29\u548c\u6b63\u5219\u6027\u5047\u8bbe\u4e0b\u5177\u6709\u6709\u754c\u504f\u5dee\u548c\u65b9\u5dee\u3002", "conclusion": "MCNO\u4e3a\u8c31\u65b9\u6cd5\uff08\u5982FNO\uff09\u548c\u56fe\u57fa\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\uff08\u5982GNO\uff09\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u81ea\u7136\u6269\u5c55\u5230\u591a\u7ef4\u95ee\u9898\u3002"}}
{"id": "2510.05635", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.05635", "abs": "https://arxiv.org/abs/2510.05635", "authors": ["Alexander Murphy", "Michal Danilowski", "Soumyajit Chatterjee", "Abhirup Ghosh"], "title": "NEO: No-Optimization Test-Time Adaptation through Latent Re-Centering", "comment": null, "summary": "Test-Time Adaptation (TTA) methods are often computationally expensive,\nrequire a large amount of data for effective adaptation, or are brittle to\nhyperparameters. Based on a theoretical foundation of the geometry of the\nlatent space, we are able to significantly improve the alignment between source\nand distribution-shifted samples by re-centering target data embeddings at the\norigin. This insight motivates NEO -- a hyperparameter-free fully TTA method,\nthat adds no significant compute compared to vanilla inference. NEO is able to\nimprove the classification accuracy of ViT-Base on ImageNet-C from 55.6% to\n59.2% after adapting on just one batch of 64 samples. When adapting on 512\nsamples NEO beats all 7 TTA methods we compare against on ImageNet-C,\nImageNet-R and ImageNet-S and beats 6/7 on CIFAR-10-C, while using the least\namount of compute. NEO performs well on model calibration metrics and\nadditionally is able to adapt from 1 class to improve accuracy on 999 other\nclasses in ImageNet-C. On Raspberry Pi and Jetson Orin Nano devices, NEO\nreduces inference time by 63% and memory usage by 9% compared to baselines. Our\nresults based on 3 ViT architectures and 4 datasets show that NEO can be used\nefficiently and effectively for TTA.", "AI": {"tldr": "NEO\u662f\u4e00\u79cd\u65e0\u9700\u8d85\u53c2\u6570\u3001\u8ba1\u7b97\u6210\u672c\u6781\u4f4e\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u65b0\u4e2d\u5fc3\u5316\u76ee\u6807\u6570\u636e\u5d4c\u5165\u6765\u6539\u5584\u6e90\u57df\u4e0e\u5206\u5e03\u504f\u79fb\u6837\u672c\u7684\u5bf9\u9f50\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u901a\u5e38\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u9700\u8981\u5927\u91cf\u6570\u636e\u6216\u5bf9\u8d85\u53c2\u6570\u654f\u611f\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u6f5c\u5728\u7a7a\u95f4\u51e0\u4f55\u7406\u8bba\uff0c\u901a\u8fc7\u5c06\u76ee\u6807\u6570\u636e\u5d4c\u5165\u91cd\u65b0\u4e2d\u5fc3\u5316\u5230\u539f\u70b9\u6765\u6539\u5584\u6e90\u57df\u4e0e\u5206\u5e03\u504f\u79fb\u6837\u672c\u7684\u5bf9\u9f50\uff0c\u63d0\u51fa\u65e0\u9700\u8d85\u53c2\u6570\u7684NEO\u65b9\u6cd5\u3002", "result": "\u5728ImageNet-C\u4e0a\uff0cNEO\u5c06ViT-Base\u7684\u51c6\u786e\u7387\u4ece55.6%\u63d0\u5347\u523059.2%\uff1b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e7\u79cd\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u8ba1\u7b97\u6210\u672c\u6700\u4f4e\uff1b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u51cf\u5c1163%\u63a8\u7406\u65f6\u95f4\u548c9%\u5185\u5b58\u4f7f\u7528\u3002", "conclusion": "NEO\u662f\u4e00\u79cd\u9ad8\u6548\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5404\u79cdViT\u67b6\u6784\u548c\u6570\u636e\u96c6\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002"}}
{"id": "2510.05670", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05670", "abs": "https://arxiv.org/abs/2510.05670", "authors": ["David Debot", "Giuseppe Marra"], "title": "Quantifying the Accuracy-Interpretability Trade-Off in Concept-Based Sidechannel Models", "comment": null, "summary": "Concept Bottleneck Models (CBNMs) are deep learning models that provide\ninterpretability by enforcing a bottleneck layer where predictions are based\nexclusively on human-understandable concepts. However, this constraint also\nrestricts information flow and often results in reduced predictive accuracy.\nConcept Sidechannel Models (CSMs) address this limitation by introducing a\nsidechannel that bypasses the bottleneck and carry additional task-relevant\ninformation. While this improves accuracy, it simultaneously compromises\ninterpretability, as predictions may rely on uninterpretable representations\ntransmitted through sidechannels. Currently, there exists no principled\ntechnique to control this fundamental trade-off. In this paper, we close this\ngap. First, we present a unified probabilistic concept sidechannel meta-model\nthat subsumes existing CSMs as special cases. Building on this framework, we\nintroduce the Sidechannel Independence Score (SIS), a metric that quantifies a\nCSM's reliance on its sidechannel by contrasting predictions made with and\nwithout sidechannel information. We propose SIS regularization, which\nexplicitly penalizes sidechannel reliance to improve interpretability. Finally,\nwe analyze how the expressivity of the predictor and the reliance of the\nsidechannel jointly shape interpretability, revealing inherent trade-offs\nacross different CSM architectures. Empirical results show that\nstate-of-the-art CSMs, when trained solely for accuracy, exhibit low\nrepresentation interpretability, and that SIS regularization substantially\nimproves their interpretability, intervenability, and the quality of learned\ninterpretable task predictors. Our work provides both theoretical and practical\ntools for developing CSMs that balance accuracy and interpretability in a\nprincipled manner.", "AI": {"tldr": "\u63d0\u51fa\u4e86Sidechannel Independence Score (SIS)\u548cSIS\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6982\u5ff5\u4fa7\u4fe1\u9053\u6a21\u578b\u4e2d\u5e73\u8861\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6982\u5ff5\u4fa7\u4fe1\u9053\u6a21\u578b(CSMs)\u901a\u8fc7\u5f15\u5165\u4fa7\u4fe1\u9053\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u635f\u5bb3\u4e86\u53ef\u89e3\u91ca\u6027\u3002\u76ee\u524d\u7f3a\u4e4f\u63a7\u5236\u8fd9\u79cd\u6743\u8861\u7684\u539f\u5219\u6027\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u6982\u7387\u6982\u5ff5\u4fa7\u4fe1\u9053\u5143\u6a21\u578b\uff0c\u5f15\u5165SIS\u5ea6\u91cf\u4fa7\u4fe1\u9053\u4f9d\u8d56\u5ea6\uff0c\u5e76\u63d0\u51faSIS\u6b63\u5219\u5316\u6765\u60e9\u7f5a\u4fa7\u4fe1\u9053\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u8ffd\u6c42\u51c6\u786e\u6027\u7684CSMs\u53ef\u89e3\u91ca\u6027\u8f83\u4f4e\uff0cSIS\u6b63\u5219\u5316\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u5e72\u9884\u6027\u548c\u5b66\u4e60\u5230\u7684\u53ef\u89e3\u91ca\u4efb\u52a1\u9884\u6d4b\u5668\u8d28\u91cf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5f00\u53d1\u5e73\u8861\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684CSMs\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u5de5\u5177\u3002"}}
{"id": "2510.05676", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.05676", "abs": "https://arxiv.org/abs/2510.05676", "authors": ["F\u00e9lix Vandervorst", "Bruno Deprez", "Wouter Verbeke", "Tim Verdonck"], "title": "Inductive inference of gradient-boosted decision trees on graphs for insurance fraud detection", "comment": null, "summary": "Graph-based methods are becoming increasingly popular in machine learning due\nto their ability to model complex data and relations. Insurance fraud is a\nprime use case, since false claims are often the result of organised criminals\nthat stage accidents or the same persons filing erroneous claims on multiple\npolicies. One challenge is that graph-based approaches struggle to find\nmeaningful representations of the data because of the high class imbalance\npresent in fraud data. Another is that insurance networks are heterogeneous and\ndynamic, given the changing relations among people, companies and policies.\nThat is why gradient boosted tree approaches on tabular data still dominate the\nfield. Therefore, we present a novel inductive graph gradient boosting machine\n(G-GBM) for supervised learning on heterogeneous and dynamic graphs. We show\nthat our estimator competes with popular graph neural network approaches in an\nexperiment using a variety of simulated random graphs. We demonstrate the power\nof G-GBM for insurance fraud detection using an open-source and a real-world,\nproprietary dataset. Given that the backbone model is a gradient boosting\nforest, we apply established explainability methods to gain better insights\ninto the predictions made by G-GBM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u56fe\u68af\u5ea6\u63d0\u5347\u673a\uff08G-GBM\uff09\u7528\u4e8e\u5f02\u6784\u52a8\u6001\u56fe\u4e0a\u7684\u76d1\u7763\u5b66\u4e60\uff0c\u5728\u4fdd\u9669\u6b3a\u8bc8\u68c0\u6d4b\u4efb\u52a1\u4e2d\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\u7ade\u4e89\uff0c\u5e76\u5229\u7528\u68af\u5ea6\u63d0\u5347\u7684\u53ef\u89e3\u91ca\u6027\u4f18\u52bf\u3002", "motivation": "\u4fdd\u9669\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\uff0c\u56fe\u65b9\u6cd5\u9762\u4e34\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u5f02\u6784\u52a8\u6001\u7f51\u7edc\u7ed3\u6784\u7684\u6311\u6218\uff0c\u800c\u4f20\u7edf\u68af\u5ea6\u63d0\u5347\u6811\u65b9\u6cd5\u4ecd\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002", "method": "\u5f00\u53d1\u4e86\u5f52\u7eb3\u5f0f\u56fe\u68af\u5ea6\u63d0\u5347\u673a\uff08G-GBM\uff09\uff0c\u7ed3\u5408\u56fe\u7ed3\u6784\u548c\u68af\u5ea6\u63d0\u5347\u6280\u672f\uff0c\u7528\u4e8e\u5f02\u6784\u52a8\u6001\u56fe\u7684\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u5728\u6a21\u62df\u968f\u673a\u56fe\u5b9e\u9a8c\u4e2d\u4e0e\u6d41\u884c\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u7ade\u4e89\uff0c\u5728\u5f00\u6e90\u548c\u4e13\u6709\u4fdd\u9669\u6b3a\u8bc8\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5f3a\u5927\u6027\u80fd\u3002", "conclusion": "G-GBM\u5728\u4fdd\u6301\u68af\u5ea6\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u56fe\u6570\u636e\u7684\u590d\u6742\u5173\u7cfb\uff0c\u4e3a\u4fdd\u9669\u6b3a\u8bc8\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05683", "categories": ["cs.LG", "cs.AI", "68T05, 68T07, 68Q12", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.05683", "abs": "https://arxiv.org/abs/2510.05683", "authors": ["Haribandhu Jena", "Jyotirmaya Shivottam", "Subhankar Mishra"], "title": "QGraphLIME - Explaining Quantum Graph Neural Networks", "comment": null, "summary": "Quantum graph neural networks offer a powerful paradigm for learning on\ngraph-structured data, yet their explainability is complicated by\nmeasurement-induced stochasticity and the combinatorial nature of graph\nstructure. In this paper, we introduce QuantumGraphLIME (QGraphLIME), a\nmodel-agnostic, post-hoc framework that treats model explanations as\ndistributions over local surrogates fit on structure-preserving perturbations\nof a graph. By aggregating surrogate attributions together with their\ndispersion, QGraphLIME yields uncertainty-aware node and edge importance\nrankings for quantum graph models. The framework further provides a\ndistribution-free, finite-sample guarantee on the size of the surrogate\nensemble: a Dvoretzky-Kiefer-Wolfowitz bound ensures uniform approximation of\nthe induced distribution of a binary class probability at target accuracy and\nconfidence under standard independence assumptions. Empirical studies on\ncontrolled synthetic graphs with known ground truth demonstrate accurate and\nstable explanations, with ablations showing clear benefits of nonlinear\nsurrogate modeling and highlighting sensitivity to perturbation design.\nCollectively, these results establish a principled, uncertainty-aware, and\nstructure-sensitive approach to explaining quantum graph neural networks, and\nlay the groundwork for scaling to broader architectures and real-world\ndatasets, as quantum resources mature. Code is available at\nhttps://github.com/smlab-niser/qglime.", "AI": {"tldr": "\u63d0\u51faQGraphLIME\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u4ee3\u7406\u6a21\u578b\u5206\u5e03\u548c\u7ed3\u6784\u4fdd\u6301\u6270\u52a8\uff0c\u4e3a\u91cf\u5b50\u56fe\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u89e3\u91ca\u65b9\u6cd5", "motivation": "\u91cf\u5b50\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89e3\u91ca\u6027\u9762\u4e34\u6d4b\u91cf\u8bf1\u5bfc\u7684\u968f\u673a\u6027\u548c\u56fe\u7ed3\u6784\u7ec4\u5408\u6027\u8d28\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u89e3\u91ca\u65b9\u6cd5", "method": "\u6a21\u578b\u65e0\u5173\u7684\u540e\u5904\u7406\u6846\u67b6\uff0c\u5c06\u6a21\u578b\u89e3\u91ca\u89c6\u4e3a\u5728\u7ed3\u6784\u4fdd\u6301\u6270\u52a8\u56fe\u4e0a\u62df\u5408\u7684\u5c40\u90e8\u4ee3\u7406\u6a21\u578b\u5206\u5e03\uff0c\u901a\u8fc7\u805a\u5408\u4ee3\u7406\u5f52\u56e0\u53ca\u5176\u79bb\u6563\u5ea6\u83b7\u5f97\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u91cd\u8981\u6027\u6392\u5e8f", "result": "\u5728\u5df2\u77e5\u771f\u5b9e\u503c\u7684\u5408\u6210\u56fe\u4e0a\u9a8c\u8bc1\u4e86\u51c6\u786e\u7a33\u5b9a\u7684\u89e3\u91ca\uff0c\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\u975e\u7ebf\u6027\u4ee3\u7406\u5efa\u6a21\u7684\u4f18\u52bf\u548c\u5bf9\u6270\u52a8\u8bbe\u8ba1\u7684\u654f\u611f\u6027", "conclusion": "\u5efa\u7acb\u4e86\u539f\u5219\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u548c\u7ed3\u6784\u654f\u611f\u7684\u91cf\u5b50\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u91ca\u65b9\u6cd5\uff0c\u4e3a\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u67b6\u6784\u548c\u771f\u5b9e\u6570\u636e\u96c6\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2510.05688", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05688", "abs": "https://arxiv.org/abs/2510.05688", "authors": ["Aditya Desai", "Kumar Krishna Agrawal", "Shuo Yang", "Alejandro Cuadron", "Luis Gaspar Schroeder", "Matei Zaharia", "Joseph E. Gonzalez", "Ion Stoica"], "title": "vAttention: Verified Sparse Attention", "comment": null, "summary": "State-of-the-art sparse attention methods for reducing decoding latency fall\ninto two main categories: approximate top-$k$ (and its extension, top-$p$) and\nrecently introduced sampling-based estimation. However, these approaches are\nfundamentally limited in their ability to approximate full attention: they fail\nto provide consistent approximations across heads and query vectors and, most\ncritically, lack guarantees on approximation quality, limiting their practical\ndeployment. We observe that top-$k$ and random sampling are complementary:\ntop-$k$ performs well when attention scores are dominated by a few tokens,\nwhereas random sampling provides better estimates when attention scores are\nrelatively uniform. Building on this insight and leveraging the statistical\nguarantees of sampling, we introduce vAttention, the first practical sparse\nattention mechanism with user-specified $(\\epsilon, \\delta)$ guarantees on\napproximation accuracy (thus, verified). These guarantees make vAttention a\ncompelling step toward practical, reliable deployment of sparse attention at\nscale. By unifying top-k and sampling, vAttention outperforms both\nindividually, delivering a superior quality-efficiency trade-off. Our\nexperiments show that vAttention significantly improves the quality of sparse\nattention (e.g., $\\sim$4.5 percentage points for Llama-3.1-8B-Inst and\nDeepseek-R1-Distill-Llama-8B on RULER-HARD), and effectively bridges the gap\nbetween full and sparse attention (e.g., across datasets, it matches full model\nquality with upto 20x sparsity). We also demonstrate that it can be deployed in\nreasoning scenarios to achieve fast decoding without compromising model quality\n(e.g., vAttention achieves full model quality on AIME2024 at 10x sparsity with\nup to 32K token generations). Code is open-sourced at\nhttps://github.com/xAlg-ai/sparse-attention-hub.", "AI": {"tldr": "vAttention\u662f\u4e00\u79cd\u7ed3\u5408top-k\u548c\u968f\u673a\u91c7\u6837\u7684\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u4f9b\u7528\u6237\u6307\u5b9a\u7684(\u03b5,\u03b4)\u8fd1\u4f3c\u7cbe\u5ea6\u4fdd\u8bc1\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8fbe20\u500d\u7684\u7a00\u758f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff08top-k\u548c\u91c7\u6837\u4f30\u8ba1\uff09\u5b58\u5728\u6839\u672c\u5c40\u9650\u6027\uff1a\u65e0\u6cd5\u63d0\u4f9b\u8de8\u5934\u548c\u67e5\u8be2\u5411\u91cf\u7684\u4e00\u81f4\u8fd1\u4f3c\uff0c\u4e14\u7f3a\u4e4f\u8fd1\u4f3c\u8d28\u91cf\u4fdd\u8bc1\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u7ed3\u5408top-k\u548c\u968f\u673a\u91c7\u6837\u7684\u4e92\u8865\u4f18\u52bf\uff1atop-k\u5728\u6ce8\u610f\u529b\u5206\u6570\u7531\u5c11\u6570token\u4e3b\u5bfc\u65f6\u8868\u73b0\u597d\uff0c\u968f\u673a\u91c7\u6837\u5728\u6ce8\u610f\u529b\u5206\u6570\u76f8\u5bf9\u5747\u5300\u65f6\u63d0\u4f9b\u66f4\u597d\u4f30\u8ba1\u3002\u5229\u7528\u91c7\u6837\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u5f00\u53d1\u5177\u6709(\u03b5,\u03b4)\u7cbe\u5ea6\u4fdd\u8bc1\u7684vAttention\u673a\u5236\u3002", "result": "vAttention\u663e\u8457\u63d0\u5347\u7a00\u758f\u6ce8\u610f\u529b\u8d28\u91cf\uff08Llama-3.1-8B-Inst\u548cDeepseek-R1-Distill-Llama-8B\u5728RULER-HARD\u4e0a\u63d0\u5347\u7ea64.5\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u5728\u63a8\u7406\u573a\u666f\u4e2d\u5b9e\u73b0\u5feb\u901f\u89e3\u7801\u800c\u4e0d\u5f71\u54cd\u6a21\u578b\u8d28\u91cf\uff08\u5728AIME2024\u4e0a\u4ee510\u500d\u7a00\u758f\u5ea6\u8fbe\u5230\u5b8c\u6574\u6a21\u578b\u8d28\u91cf\uff09\u3002", "conclusion": "vAttention\u662f\u9996\u4e2a\u5177\u6709\u7528\u6237\u6307\u5b9a\u7cbe\u5ea6\u4fdd\u8bc1\u7684\u5b9e\u7528\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7edf\u4e00\u4e86top-k\u548c\u91c7\u6837\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u4f18\u7684\u8d28\u91cf-\u6548\u7387\u6743\u8861\uff0c\u662f\u5411\u5927\u89c4\u6a21\u53ef\u9760\u90e8\u7f72\u7a00\u758f\u6ce8\u610f\u529b\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.05703", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05703", "abs": "https://arxiv.org/abs/2510.05703", "authors": ["Yihan Du", "Seo Taek Kong", "R. Srikant"], "title": "Primal-Dual Direct Preference Optimization for Constrained LLM Alignment", "comment": null, "summary": "The widespread application of Large Language Models (LLMs) imposes increasing\ndemands on safety, such as reducing harmful content and fake information, and\navoiding certain forbidden tokens due to rules and laws. While there have been\nseveral recent works studying safe alignment of LLMs, these works either\nrequire the training of reward and cost models and incur high memory and\ncomputational costs, or need prior knowledge about the optimal solution.\nMotivated by this fact, we study the problem of constrained alignment in LLMs,\ni.e., maximizing the output reward while restricting the cost due to\npotentially unsafe content to stay below a threshold. For this problem, we\npropose a novel primal-dual DPO approach, which first trains a model using\nstandard DPO on reward preference data to provide reward information, and then\nadopts a rearranged Lagrangian DPO objective utilizing the provided reward\ninformation to fine-tune LLMs on cost preference data. Our approach\nsignificantly reduces memory and computational costs, and does not require\nextra prior knowledge. Moreover, we establish rigorous theoretical guarantees\non the suboptimality and constraint violation of the output policy. We also\nextend our approach to an online data setting by incorporating exploration\nbonuses, which enables our approach to explore uncovered prompt-response space,\nand then provide theoretical results that get rid of the dependence on\npreference data coverage. Experimental results on the widely-used preference\ndataset PKU-SafeRLHF demonstrate the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u539f\u5bf9\u5076DPO\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728LLMs\u4e2d\u8fdb\u884c\u7ea6\u675f\u5bf9\u9f50\uff0c\u5728\u6700\u5927\u5316\u8f93\u51fa\u5956\u52b1\u7684\u540c\u65f6\u5c06\u4e0d\u5b89\u5168\u5185\u5bb9\u7684\u6210\u672c\u9650\u5236\u5728\u9608\u503c\u4ee5\u4e0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709LLMs\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u8bad\u7ec3\u5956\u52b1\u548c\u6210\u672c\u6a21\u578b\u5bfc\u81f4\u9ad8\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u8981\u4e48\u9700\u8981\u5173\u4e8e\u6700\u4f18\u89e3\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u65e0\u9700\u989d\u5916\u77e5\u8bc6\u7684\u7ea6\u675f\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u4f7f\u7528\u6807\u51c6DPO\u5728\u5956\u52b1\u504f\u597d\u6570\u636e\u4e0a\u8bad\u7ec3\u6a21\u578b\u4ee5\u63d0\u4f9b\u5956\u52b1\u4fe1\u606f\uff0c\u7136\u540e\u91c7\u7528\u91cd\u65b0\u6392\u5217\u7684\u62c9\u683c\u6717\u65e5DPO\u76ee\u6807\u5229\u7528\u63d0\u4f9b\u7684\u5956\u52b1\u4fe1\u606f\u5728\u6210\u672c\u504f\u597d\u6570\u636e\u4e0a\u5fae\u8c03LLMs\u3002", "result": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u504f\u597d\u6570\u636e\u96c6PKU-SafeRLHF\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u5efa\u7acb\u4e86\u5173\u4e8e\u8f93\u51fa\u7b56\u7565\u6b21\u4f18\u6027\u548c\u7ea6\u675f\u8fdd\u53cd\u7684\u4e25\u683c\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u65e0\u9700\u989d\u5916\u5148\u9a8c\u77e5\u8bc6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u53ef\u6269\u5c55\u5230\u5728\u7ebf\u6570\u636e\u8bbe\u7f6e\u3002"}}
{"id": "2510.05717", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05717", "abs": "https://arxiv.org/abs/2510.05717", "authors": ["Hedi Zisling", "Ilan Naiman", "Nimrod Berman", "Supasorn Suwajanakorn", "Omri Azencot"], "title": "DiffSDA: Unsupervised Diffusion Sequential Disentanglement Across Modalities", "comment": null, "summary": "Unsupervised representation learning, particularly sequential\ndisentanglement, aims to separate static and dynamic factors of variation in\ndata without relying on labels. This remains a challenging problem, as existing\napproaches based on variational autoencoders and generative adversarial\nnetworks often rely on multiple loss terms, complicating the optimization\nprocess. Furthermore, sequential disentanglement methods face challenges when\napplied to real-world data, and there is currently no established evaluation\nprotocol for assessing their performance in such settings. Recently, diffusion\nmodels have emerged as state-of-the-art generative models, but no theoretical\nformalization exists for their application to sequential disentanglement. In\nthis work, we introduce the Diffusion Sequential Disentanglement Autoencoder\n(DiffSDA), a novel, modal-agnostic framework effective across diverse\nreal-world data modalities, including time series, video, and audio. DiffSDA\nleverages a new probabilistic modeling, latent diffusion, and efficient\nsamplers, while incorporating a challenging evaluation protocol for rigorous\ntesting. Our experiments on diverse real-world benchmarks demonstrate that\nDiffSDA outperforms recent state-of-the-art methods in sequential\ndisentanglement.", "AI": {"tldr": "\u63d0\u51faDiffSDA\u6846\u67b6\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u5e8f\u5217\u89e3\u7f20\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u3001\u89c6\u9891\u548c\u97f3\u9891\u7b49\u591a\u79cd\u6a21\u6001\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02", "motivation": "\u73b0\u6709\u57fa\u4e8eVAE\u548cGAN\u7684\u65e0\u76d1\u7763\u5e8f\u5217\u89e3\u7f20\u65b9\u6cd5\u4f9d\u8d56\u591a\u4e2a\u635f\u5931\u9879\uff0c\u4f18\u5316\u590d\u6742\uff0c\u4e14\u7f3a\u4e4f\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u8bc4\u4f30\u534f\u8bae\u3002\u6269\u6563\u6a21\u578b\u867d\u662f\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\uff0c\u4f46\u5c1a\u672a\u7406\u8bba\u5316\u5e94\u7528\u4e8e\u5e8f\u5217\u89e3\u7f20", "method": "DiffSDA\u7ed3\u5408\u6982\u7387\u5efa\u6a21\u3001\u6f5c\u5728\u6269\u6563\u548c\u9ad8\u6548\u91c7\u6837\u5668\uff0c\u6784\u5efa\u6a21\u6001\u65e0\u5173\u7684\u5e8f\u5217\u89e3\u7f20\u6846\u67b6", "result": "\u5728\u591a\u79cd\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDiffSDA\u5728\u5e8f\u5217\u89e3\u7f20\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5", "conclusion": "DiffSDA\u4e3a\u5e8f\u5217\u89e3\u7f20\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6a21\u6001\u65e0\u5173\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u4e25\u683c\u7684\u8bc4\u4f30\u534f\u8bae\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2510.05719", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.05719", "abs": "https://arxiv.org/abs/2510.05719", "authors": ["S. Peng", "L. Hu", "W. Zhang", "B. Jie", "Y. Luo"], "title": "Neighborhood-Adaptive Generalized Linear Graph Embedding with Latent Pattern Mining", "comment": null, "summary": "Graph embedding has been widely applied in areas such as network analysis,\nsocial network mining, recommendation systems, and bioinformatics. However,\ncurrent graph construction methods often require the prior definition of\nneighborhood size, limiting the effective revelation of potential structural\ncorrelations in the data. Additionally, graph embedding methods using linear\nprojection heavily rely on a singular pattern mining approach, resulting in\nrelative weaknesses in adapting to different scenarios. To address these\nchallenges, we propose a novel model, Neighborhood-Adaptive Generalized Linear\nGraph Embedding (NGLGE), grounded in latent pattern mining. This model\nintroduces an adaptive graph learning method tailored to the neighborhood,\neffectively revealing intrinsic data correlations. Simultaneously, leveraging a\nreconstructed low-rank representation and imposing $\\ell_{2,0}$ norm constraint\non the projection matrix allows for flexible exploration of additional pattern\ninformation. Besides, an efficient iterative solving algorithm is derived for\nthe proposed model. Comparative evaluations on datasets from diverse scenarios\ndemonstrate the superior performance of our model compared to state-of-the-art\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u6a21\u5f0f\u6316\u6398\u7684\u90bb\u57df\u81ea\u9002\u5e94\u5e7f\u4e49\u7ebf\u6027\u56fe\u5d4c\u5165\u6a21\u578b(NGLGE)\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\u548c\u4f4e\u79e9\u8868\u793a\u91cd\u6784\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u9884\u5b9a\u4e49\u90bb\u57df\u5927\u5c0f\u548c\u5355\u4e00\u6a21\u5f0f\u6316\u6398\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u56fe\u6784\u5efa\u65b9\u6cd5\u9700\u8981\u9884\u5b9a\u4e49\u90bb\u57df\u5927\u5c0f\uff0c\u9650\u5236\u4e86\u6570\u636e\u6f5c\u5728\u7ed3\u6784\u76f8\u5173\u6027\u7684\u6709\u6548\u63ed\u793a\uff1b\u540c\u65f6\u57fa\u4e8e\u7ebf\u6027\u6295\u5f71\u7684\u56fe\u5d4c\u5165\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u6a21\u5f0f\u6316\u6398\uff0c\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u9002\u5e94\u6027\u8f83\u5f31\u3002", "method": "\u63d0\u51fa\u4e86NGLGE\u6a21\u578b\uff0c\u5305\u542b\u90bb\u57df\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\u65b9\u6cd5\u3001\u91cd\u6784\u7684\u4f4e\u79e9\u8868\u793a\uff0c\u4ee5\u53ca\u5bf9\u6295\u5f71\u77e9\u9635\u65bd\u52a0\u21132,0\u8303\u6570\u7ea6\u675f\u4ee5\u7075\u6d3b\u63a2\u7d22\u989d\u5916\u6a21\u5f0f\u4fe1\u606f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684\u8fed\u4ee3\u6c42\u89e3\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u573a\u666f\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u6bd4\u8f83\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6a21\u578b\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "NGLGE\u6a21\u578b\u901a\u8fc7\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\u548c\u591a\u6a21\u5f0f\u6316\u6398\u673a\u5236\uff0c\u80fd\u591f\u66f4\u597d\u5730\u63ed\u793a\u6570\u636e\u5185\u5728\u76f8\u5173\u6027\uff0c\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.05725", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.05725", "abs": "https://arxiv.org/abs/2510.05725", "authors": ["Chunsan Hong", "Seonho An", "Min-Soo Kim", "Jong Chul Ye"], "title": "Improving Discrete Diffusion Unmasking Policies Beyond Explicit Reference Policies", "comment": "Preprint", "summary": "Masked diffusion models (MDMs) have recently emerged as a novel framework for\nlanguage modeling. MDMs generate sentences by iteratively denoising masked\nsequences, filling in [MASK] tokens step by step. Although MDMs support\nany-order sampling, performance is highly sensitive to the choice of which\nposition to unmask next. Prior work typically relies on rule-based schedules\n(e.g., max-confidence, max-margin), which provide ad hoc improvements. In\ncontrast, we replace these heuristics with a learned scheduler. Specifically,\nwe cast denoising as a KL-regularized Markov decision process (MDP) with an\nexplicit reference policy and optimize a regularized objective that admits\npolicy improvement and convergence guarantees under standard assumptions. We\nprove that the optimized policy under this framework generates samples that\nmore closely match the data distribution than heuristic schedules. Empirically,\nacross four benchmarks, our learned policy consistently outperforms\nmax-confidence: for example, on SUDOKU, where unmasking order is critical, it\nyields a 20.1% gain over random and a 11.2% gain over max-confidence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u578b\u8c03\u5ea6\u5668\u6765\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u8c03\u5ea6\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u53bb\u566a\u8fc7\u7a0b\u5efa\u6a21\u4e3aKL\u6b63\u5219\u5316\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f18\u5316\u751f\u6210\u6837\u672c\u4e0e\u6570\u636e\u5206\u5e03\u7684\u5339\u914d\u5ea6\u3002", "motivation": "\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u5bf9\u89e3\u63a9\u7801\u987a\u5e8f\u9ad8\u5ea6\u654f\u611f\uff0c\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u8c03\u5ea6\u7b56\u7565\uff08\u5982\u6700\u5927\u7f6e\u4fe1\u5ea6\u3001\u6700\u5927\u8fb9\u9645\uff09\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u8c03\u5ea6\u65b9\u6cd5\u3002", "method": "\u5c06\u53bb\u566a\u8fc7\u7a0b\u5efa\u6a21\u4e3aKL\u6b63\u5219\u5316\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u663e\u5f0f\u53c2\u8003\u7b56\u7565\uff0c\u4f18\u5316\u5177\u6709\u7b56\u7565\u6539\u8fdb\u548c\u6536\u655b\u4fdd\u8bc1\u7684\u6b63\u5219\u5316\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b66\u4e60\u578b\u8c03\u5ea6\u5668\u59cb\u7ec8\u4f18\u4e8e\u6700\u5927\u7f6e\u4fe1\u5ea6\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728SUDOKU\u4efb\u52a1\u4e0a\uff0c\u76f8\u6bd4\u968f\u673a\u7b56\u7565\u63d0\u534720.1%\uff0c\u76f8\u6bd4\u6700\u5927\u7f6e\u4fe1\u5ea6\u7b56\u7565\u63d0\u534711.2%\u3002", "conclusion": "\u5b66\u4e60\u578b\u8c03\u5ea6\u5668\u80fd\u591f\u751f\u6210\u66f4\u63a5\u8fd1\u6570\u636e\u5206\u5e03\u7684\u6837\u672c\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u542f\u53d1\u5f0f\u8c03\u5ea6\u7b56\u7565\uff0c\u4e3a\u63a9\u7801\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u63a9\u7801\u987a\u5e8f\u51b3\u7b56\u65b9\u6cd5\u3002"}}
{"id": "2510.05748", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05748", "abs": "https://arxiv.org/abs/2510.05748", "authors": ["Hachem Madmoun", "Salem Lahlou"], "title": "Communication Enables Cooperation in LLM Agents: A Comparison with Curriculum-Based Approaches", "comment": null, "summary": "Eliciting cooperation in multi-agent LLM systems is critical for AI\nalignment. We investigate two approaches: direct communication and curriculum\nlearning. In a 4-player Stag Hunt, a one-word \"cheap talk\" channel increases\ncooperation from 0% to 48.3%, demonstrating communication as a robust\ncoordination mechanism. In contrast, we find that curriculum learning is highly\nsensitive to design choices: our pedagogical curriculum through progressively\ncomplex games reduced agent payoffs by 27.4% in an Iterated Public Goods Game\nwith Punishment. Qualitative analysis reveals that curricula emphasizing\ndefection-equilibrium games can induce \"learned pessimism\" in agents. These\nfindings suggest that for coordination problems, simple communication protocols\nmay be more reliable than experience-based training, and that curriculum design\nfor social dilemmas requires careful attention to the strategic lessons\nembedded in game sequences.", "AI": {"tldr": "\u57284\u4eba\u730e\u9e7f\u6e38\u620f\u4e2d\uff0c\u7b80\u5355\u7684\u5355\u8bcd\u901a\u4fe1\u5c06\u5408\u4f5c\u7387\u4ece0%\u63d0\u5347\u523048.3%\uff0c\u800c\u8bfe\u7a0b\u5b66\u4e60\u5728\u8fed\u4ee3\u516c\u5171\u7269\u54c1\u60e9\u7f5a\u6e38\u620f\u4e2d\u53cd\u800c\u964d\u4f4e\u4e8627.4%\u7684\u6536\u76ca\uff0c\u8868\u660e\u5f3a\u8c03\u80cc\u53db\u5747\u8861\u7684\u8bfe\u7a0b\u4f1a\u5bfc\u81f4\u667a\u80fd\u4f53\u4ea7\u751f\"\u4e60\u5f97\u6027\u60b2\u89c2\"\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4e2d\u7684\u5408\u4f5c\u8bf1\u5bfc\u65b9\u6cd5\uff0c\u63a2\u7d22\u76f4\u63a5\u901a\u4fe1\u548c\u8bfe\u7a0b\u5b66\u4e60\u5bf9AI\u5bf9\u9f50\u7684\u5f71\u54cd\u3002", "method": "\u5728\u730e\u9e7f\u6e38\u620f\u4e2d\u6d4b\u8bd5\u5355\u8bcd\"\u5ec9\u4ef7\u8c08\u8bdd\"\u901a\u4fe1\u673a\u5236\uff0c\u5728\u8fed\u4ee3\u516c\u5171\u7269\u54c1\u60e9\u7f5a\u6e38\u620f\u4e2d\u5b9e\u65bd\u6e10\u8fdb\u590d\u6742\u6e38\u620f\u7684\u6559\u5b66\u8bfe\u7a0b\u3002", "result": "\u901a\u4fe1\u673a\u5236\u663e\u8457\u63d0\u5347\u5408\u4f5c\u7387\uff080%\u219248.3%\uff09\uff0c\u800c\u8bfe\u7a0b\u5b66\u4e60\u964d\u4f4e\u6536\u76ca27.4%\uff0c\u5b9a\u6027\u5206\u6790\u663e\u793a\u8bfe\u7a0b\u8bbe\u8ba1\u4f1a\u5f15\u53d1\"\u4e60\u5f97\u6027\u60b2\u89c2\"\u3002", "conclusion": "\u5bf9\u4e8e\u534f\u8c03\u95ee\u9898\uff0c\u7b80\u5355\u901a\u4fe1\u534f\u8bae\u6bd4\u57fa\u4e8e\u7ecf\u9a8c\u7684\u8bad\u7ec3\u66f4\u53ef\u9760\uff0c\u793e\u4f1a\u56f0\u5883\u7684\u8bfe\u7a0b\u8bbe\u8ba1\u9700\u8981\u8c28\u614e\u8003\u8651\u6e38\u620f\u5e8f\u5217\u4e2d\u5d4c\u5165\u7684\u6218\u7565\u6559\u8bad\u3002"}}
{"id": "2510.05750", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05750", "abs": "https://arxiv.org/abs/2510.05750", "authors": ["Xiao Yang", "Xuejiao Zhao", "Zhiqi Shen"], "title": "Are Heterogeneous Graph Neural Networks Truly Effective? A Causal Perspective", "comment": null, "summary": "Graph neural networks (GNNs) have achieved remarkable success in node\nclassification. Building on this progress, heterogeneous graph neural networks\n(HGNNs) integrate relation types and node and edge semantics to leverage\nheterogeneous information. Causal analysis for HGNNs is advancing rapidly,\naiming to separate genuine causal effects from spurious correlations. However,\nwhether HGNNs are intrinsically effective remains underexamined, and most\nstudies implicitly assume rather than establish this effectiveness. In this\nwork, we examine HGNNs from two perspectives: model architecture and\nheterogeneous information. We conduct a systematic reproduction across 21\ndatasets and 20 baselines, complemented by comprehensive hyperparameter\nretuning. To further disentangle the source of performance gains, we develop a\ncausal effect estimation framework that constructs and evaluates candidate\nfactors under standard assumptions through factual and counterfactual analyses,\nwith robustness validated via minimal sufficient adjustment sets, cross-method\nconsistency checks, and sensitivity analyses. Our results lead to two\nconclusions. First, model architecture and complexity have no causal effect on\nperformance. Second, heterogeneous information exerts a positive causal effect\nby increasing homophily and local-global distribution discrepancy, which makes\nnode classes more distinguishable. The implementation is publicly available at\nhttps://github.com/YXNTU/CausalHGNN.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u590d\u73b0\u548c\u56e0\u679c\u6548\u5e94\u5206\u6790\uff0c\u53d1\u73b0\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc(HGNNs)\u7684\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u5f02\u8d28\u4fe1\u606f\u800c\u975e\u6a21\u578b\u67b6\u6784\uff0c\u5f02\u8d28\u4fe1\u606f\u901a\u8fc7\u589e\u52a0\u540c\u8d28\u6027\u548c\u5c40\u90e8-\u5168\u5c40\u5206\u5e03\u5dee\u5f02\u6765\u63d0\u9ad8\u8282\u70b9\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5927\u591a\u5047\u8bbeHGNNs\u5185\u5728\u6709\u6548\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u771f\u6b63\u6709\u6548\u6027\u6765\u6e90\u7684\u7cfb\u7edf\u9a8c\u8bc1\uff0c\u7279\u522b\u662f\u6a21\u578b\u67b6\u6784\u548c\u5f02\u8d28\u4fe1\u606f\u5404\u81ea\u8d21\u732e\u7684\u56e0\u679c\u6548\u5e94\u5206\u6790\u3002", "method": "\u572821\u4e2a\u6570\u636e\u96c6\u548c20\u4e2a\u57fa\u7ebf\u6a21\u578b\u4e0a\u8fdb\u884c\u7cfb\u7edf\u590d\u73b0\u548c\u8d85\u53c2\u6570\u91cd\u8c03\u4f18\uff0c\u5f00\u53d1\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4e8b\u5b9e\u548c\u53cd\u4e8b\u5b9e\u5206\u6790\u8bc4\u4f30\u5019\u9009\u56e0\u7d20\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u5145\u5206\u8c03\u6574\u96c6\u3001\u8de8\u65b9\u6cd5\u4e00\u81f4\u6027\u68c0\u9a8c\u548c\u654f\u611f\u6027\u5206\u6790\u9a8c\u8bc1\u9c81\u68d2\u6027\u3002", "result": "\u6a21\u578b\u67b6\u6784\u548c\u590d\u6742\u5ea6\u5bf9\u6027\u80fd\u6ca1\u6709\u56e0\u679c\u6548\u5e94\uff1b\u5f02\u8d28\u4fe1\u606f\u901a\u8fc7\u589e\u52a0\u540c\u8d28\u6027\u548c\u5c40\u90e8-\u5168\u5c40\u5206\u5e03\u5dee\u5f02\u4ea7\u751f\u6b63\u5411\u56e0\u679c\u6548\u5e94\uff0c\u4f7f\u8282\u70b9\u7c7b\u522b\u66f4\u6613\u533a\u5206\u3002", "conclusion": "HGNNs\u7684\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6e90\u4e8e\u5f02\u8d28\u4fe1\u606f\u800c\u975e\u6a21\u578b\u67b6\u6784\u8bbe\u8ba1\uff0c\u8fd9\u4e3a\u672a\u6765\u56fe\u795e\u7ecf\u7f51\u7edc\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.05753", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.05753", "abs": "https://arxiv.org/abs/2510.05753", "authors": ["Yuxuan Bai", "Gauri Pradhan", "Marlon Tobaben", "Antti Honkela"], "title": "Empirical Comparison of Membership Inference Attacks in Deep Transfer Learning", "comment": "30 pages, 13 figures, published in TMLR\n  https://openreview.net/forum?id=UligTUCgdt", "summary": "With the emergence of powerful large-scale foundation models, the training\nparadigm is increasingly shifting from from-scratch training to transfer\nlearning. This enables high utility training with small, domain-specific\ndatasets typical in sensitive applications.Membership inference attacks (MIAs)\nprovide an empirical estimate of the privacy leakage by machine learning\nmodels. Yet, prior assessments of MIAs against models fine-tuned with transfer\nlearning rely on a small subset of possible attacks. We address this by\ncomparing performance of diverse MIAs in transfer learning settings to help\npractitioners identify the most efficient attacks for privacy risk evaluation.\nWe find that attack efficacy decreases with the increase in training data for\nscore-based MIAs. We find that there is no one MIA which captures all privacy\nrisks in models trained with transfer learning. While the Likelihood Ratio\nAttack (LiRA) demonstrates superior performance across most experimental\nscenarios, the Inverse Hessian Attack (IHA) proves to be more effective against\nmodels fine-tuned on PatchCamelyon dataset in high data regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6bd4\u8f83\u4e86\u5728\u8fc1\u79fb\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u591a\u79cd\u6210\u5458\u63a8\u7406\u653b\u51fb(MIAs)\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u653b\u51fb\u6548\u679c\u968f\u8bad\u7ec3\u6570\u636e\u589e\u52a0\u800c\u964d\u4f4e\uff0c\u4e14\u6ca1\u6709\u5355\u4e00MIA\u80fd\u6355\u6349\u6240\u6709\u9690\u79c1\u98ce\u9669\u3002LiRA\u5728\u5927\u591a\u6570\u573a\u666f\u8868\u73b0\u6700\u4f73\uff0c\u800cIHA\u5728PatchCamelyon\u6570\u636e\u96c6\u7684\u9ad8\u6570\u636e\u91cf\u60c5\u51b5\u4e0b\u66f4\u6709\u6548\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u57fa\u7840\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u8bad\u7ec3\u8303\u5f0f\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u8f6c\u5411\u8fc1\u79fb\u5b66\u4e60\uff0c\u8fd9\u4f7f\u5f97\u5728\u654f\u611f\u5e94\u7528\u4e2d\u4f7f\u7528\u5c0f\u578b\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u8fdb\u884c\u9ad8\u6548\u8bad\u7ec3\u6210\u4e3a\u53ef\u80fd\u3002\u9700\u8981\u8bc4\u4f30\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u6bd4\u8f83\u5728\u8fc1\u79fb\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u591a\u79cd\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u6027\u80fd\uff0c\u5305\u62ec\u57fa\u4e8e\u5206\u6570\u7684MIAs\u3001\u4f3c\u7136\u6bd4\u653b\u51fb(LiRA)\u548c\u9006Hessian\u653b\u51fb(IHA)\uff0c\u5e2e\u52a9\u5b9e\u8df5\u8005\u8bc6\u522b\u6700\u6709\u6548\u7684\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u653b\u51fb\u3002", "result": "\u653b\u51fb\u6548\u679c\u968f\u8bad\u7ec3\u6570\u636e\u589e\u52a0\u800c\u964d\u4f4e\uff1b\u6ca1\u6709\u5355\u4e00MIA\u80fd\u6355\u6349\u6240\u6709\u9690\u79c1\u98ce\u9669\uff1bLiRA\u5728\u5927\u591a\u6570\u5b9e\u9a8c\u573a\u666f\u8868\u73b0\u6700\u4f18\uff1bIHA\u5728PatchCamelyon\u6570\u636e\u96c6\u7684\u9ad8\u6570\u636e\u91cf\u60c5\u51b5\u4e0b\u66f4\u6709\u6548\u3002", "conclusion": "\u5728\u8fc1\u79fb\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u9700\u8981\u91c7\u7528\u591a\u79cdMIA\u65b9\u6cd5\u6765\u5168\u9762\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\uff0cLiRA\u662f\u901a\u7528\u6027\u6700\u597d\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u4f46\u5728\u7279\u5b9a\u6570\u636e\u96c6\u548c\u6761\u4ef6\u4e0bIHA\u53ef\u80fd\u66f4\u6709\u6548\u3002"}}
{"id": "2510.05777", "categories": ["cs.LG", "cs.CR", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2510.05777", "abs": "https://arxiv.org/abs/2510.05777", "authors": ["Shadi Rahimian", "Mario Fritz"], "title": "DP-SNP-TIHMM: Differentially Private, Time-Inhomogeneous Hidden Markov Models for Synthesizing Genome-Wide Association Datasets", "comment": null, "summary": "Single nucleotide polymorphism (SNP) datasets are fundamental to genetic\nstudies but pose significant privacy risks when shared. The correlation of SNPs\nwith each other makes strong adversarial attacks such as masked-value\nreconstruction, kin, and membership inference attacks possible. Existing\nprivacy-preserving approaches either apply differential privacy to statistical\nsummaries of these datasets or offer complex methods that require\npost-processing and the usage of a publicly available dataset to suppress or\nselectively share SNPs.\n  In this study, we introduce an innovative framework for generating synthetic\nSNP sequence datasets using samples derived from time-inhomogeneous hidden\nMarkov models (TIHMMs). To preserve the privacy of the training data, we ensure\nthat each SNP sequence contributes only a bounded influence during training,\nenabling strong differential privacy guarantees. Crucially, by operating on\nfull SNP sequences and bounding their gradient contributions, our method\ndirectly addresses the privacy risks introduced by their inherent correlations.\n  Through experiments conducted on the real-world 1000 Genomes dataset, we\ndemonstrate the efficacy of our method using privacy budgets of $\\varepsilon\n\\in [1, 10]$ at $\\delta=10^{-4}$. Notably, by allowing the transition models of\nthe HMM to be dependent on the location in the sequence, we significantly\nenhance performance, enabling the synthetic datasets to closely replicate the\nstatistical properties of non-private datasets. This framework facilitates the\nprivate sharing of genomic data while offering researchers exceptional\nflexibility and utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u975e\u9f50\u6b21\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b(TIHMMs)\u7684\u5408\u6210SNP\u5e8f\u5217\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u9650\u5236\u6bcf\u4e2aSNP\u5e8f\u5217\u5728\u8bad\u7ec3\u4e2d\u7684\u5f71\u54cd\u6765\u63d0\u4f9b\u5f3a\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\uff0c\u89e3\u51b3\u4e86SNP\u6570\u636e\u5171\u4eab\u4e2d\u7684\u9690\u79c1\u98ce\u9669\u3002", "motivation": "SNP\u6570\u636e\u96c6\u5bf9\u9057\u4f20\u5b66\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8eSNP\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5b58\u5728\u63a9\u7801\u503c\u91cd\u5efa\u3001\u4eb2\u5c5e\u5173\u7cfb\u548c\u6210\u5458\u63a8\u65ad\u7b49\u5f3a\u5bf9\u6297\u653b\u51fb\u98ce\u9669\u3002\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u8981\u4e48\u5bf9\u7edf\u8ba1\u6458\u8981\u5e94\u7528\u5dee\u5206\u9690\u79c1\uff0c\u8981\u4e48\u9700\u8981\u590d\u6742\u540e\u5904\u7406\u548c\u4f7f\u7528\u516c\u5171\u6570\u636e\u96c6\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u975e\u9f50\u6b21\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u751f\u6210\u5408\u6210SNP\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u9650\u5236\u6bcf\u4e2aSNP\u5e8f\u5217\u7684\u68af\u5ea6\u8d21\u732e\u6765\u786e\u4fdd\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\uff0c\u76f4\u63a5\u5904\u7406SNP\u5185\u5728\u76f8\u5173\u6027\u5f15\u5165\u7684\u9690\u79c1\u98ce\u9669\u3002", "result": "\u57281000 Genomes\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u03b5\u2208[1,10]\u548c\u03b4=10^{-4}\u7684\u9690\u79c1\u9884\u7b97\u4e0b\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u5408\u6210\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5141\u8bb8HMM\u8f6c\u79fb\u6a21\u578b\u4f9d\u8d56\u4e8e\u5e8f\u5217\u4f4d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f7f\u5408\u6210\u6570\u636e\u96c6\u80fd\u7d27\u5bc6\u590d\u5236\u975e\u79c1\u6709\u6570\u636e\u96c6\u7684\u7edf\u8ba1\u7279\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u62a4\u57fa\u56e0\u7ec4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5353\u8d8a\u7684\u7075\u6d3b\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4fc3\u8fdb\u4e86\u57fa\u56e0\u7ec4\u6570\u636e\u7684\u79c1\u6709\u5171\u4eab\u3002"}}
{"id": "2510.05805", "categories": ["cs.LG", "cs.CV", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.05805", "abs": "https://arxiv.org/abs/2510.05805", "authors": ["Pafue Christy Nganjimi", "Andrew Soltan", "Danielle Belgrave", "Lei Clifton", "David A. Clifton", "Anshul Thakur"], "title": "Improving Clinical Dataset Condensation with Mode Connectivity-based Trajectory Surrogates", "comment": "20 pages, 4 figures, Submitted to AISTATS 2026", "summary": "Dataset condensation (DC) enables the creation of compact, privacy-preserving\nsynthetic datasets that can match the utility of real patient records,\nsupporting democratised access to highly regulated clinical data for developing\ndownstream clinical models. State-of-the-art DC methods supervise synthetic\ndata by aligning the training dynamics of models trained on real and those\ntrained on synthetic data, typically using full stochastic gradient descent\n(SGD) trajectories as alignment targets; however, these trajectories are often\nnoisy, high-curvature, and storage-intensive, leading to unstable gradients,\nslow convergence, and substantial memory overhead. We address these limitations\nby replacing full SGD trajectories with smooth, low-loss parametric surrogates,\nspecifically quadratic B\\'ezier curves that connect the initial and final model\nstates from real training trajectories. These mode-connected paths provide\nnoise-free, low-curvature supervision signals that stabilise gradients,\naccelerate convergence, and eliminate the need for dense trajectory storage. We\ntheoretically justify B\\'ezier-mode connections as effective surrogates for SGD\npaths and empirically show that the proposed method outperforms\nstate-of-the-art condensation approaches across five clinical datasets,\nyielding condensed datasets that enable clinically effective model development.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u8d1d\u585e\u5c14\u66f2\u7ebf\u66ff\u4ee3\u5b8c\u6574SGD\u8f68\u8ff9\u7684\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u6ed1\u7684\u6a21\u578b\u8fde\u63a5\u8def\u5f84\u63d0\u4f9b\u65e0\u566a\u58f0\u76d1\u7763\u4fe1\u53f7\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u68af\u5ea6\u4e0d\u7a33\u5b9a\u3001\u6536\u655b\u6162\u548c\u5b58\u50a8\u5f00\u9500\u5927\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\u4f7f\u7528\u5b8c\u6574\u7684SGD\u8f68\u8ff9\u4f5c\u4e3a\u5bf9\u9f50\u76ee\u6807\uff0c\u4f46\u8fd9\u4e9b\u8f68\u8ff9\u901a\u5e38\u566a\u58f0\u5927\u3001\u66f2\u7387\u9ad8\u4e14\u5b58\u50a8\u5bc6\u96c6\uff0c\u5bfc\u81f4\u68af\u5ea6\u4e0d\u7a33\u5b9a\u3001\u6536\u655b\u7f13\u6162\u548c\u5185\u5b58\u5f00\u9500\u5927\u3002", "method": "\u7528\u5e73\u6ed1\u7684\u4f4e\u635f\u5931\u53c2\u6570\u5316\u66ff\u4ee3\u7269\uff08\u7279\u522b\u662f\u8fde\u63a5\u521d\u59cb\u548c\u6700\u7ec8\u6a21\u578b\u72b6\u6001\u7684\u4e8c\u6b21\u8d1d\u585e\u5c14\u66f2\u7ebf\uff09\u66ff\u4ee3\u5b8c\u6574SGD\u8f68\u8ff9\uff0c\u8fd9\u4e9b\u6a21\u578b\u8fde\u63a5\u8def\u5f84\u63d0\u4f9b\u65e0\u566a\u58f0\u3001\u4f4e\u66f2\u7387\u7684\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u5728\u4e94\u4e2a\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u538b\u7f29\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u538b\u7f29\u6570\u636e\u96c6\u80fd\u591f\u652f\u6301\u6709\u6548\u7684\u4e34\u5e8a\u6a21\u578b\u5f00\u53d1\u3002", "conclusion": "\u8d1d\u585e\u5c14\u6a21\u5f0f\u8fde\u63a5\u4f5c\u4e3aSGD\u8def\u5f84\u7684\u6709\u6548\u66ff\u4ee3\u7269\uff0c\u80fd\u591f\u7a33\u5b9a\u68af\u5ea6\u3001\u52a0\u901f\u6536\u655b\u5e76\u6d88\u9664\u5bc6\u96c6\u8f68\u8ff9\u5b58\u50a8\u9700\u6c42\u3002"}}
{"id": "2510.05825", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.05825", "abs": "https://arxiv.org/abs/2510.05825", "authors": ["Giorgio Giannone", "Guangxuan Xu", "Nikhil Shivakumar Nayak", "Rohan Mahesh Awhad", "Shivchander Sudalairaj", "Kai Xu", "Akash Srivastava"], "title": "Mitigating Premature Exploitation in Particle-based Monte Carlo for Inference-Time Scaling", "comment": null, "summary": "Inference-Time Scaling (ITS) improves language models by allocating more\ncomputation at generation time. Particle Filtering (PF) has emerged as a strong\nITS method for complex mathematical reasoning tasks, but it is vulnerable when\nguided by process reward models, which often assign overconfident scores early\nin the reasoning process. This causes PF to suffer from premature exploitation:\nit myopically commits to locally promising trajectories, prunes potentially\ncorrect hypotheses, and converges to suboptimal solutions. This failure mode,\nknown as particle impoverishment, is especially severe under constrained\ncomputational budgets. To address this, we analyze the problem and identify two\nroot causes: a lack of diversity in the particle set due to overconfident\nresampling and consequent inability to assess the potential of a reasoning\npath. We introduce Entropic Particle Filtering (ePF), an algorithm that\nintegrates two new techniques to solve these issues. The first technique,\nEntropic Annealing (EA), directly mitigates particle impoverishment by\nmonitoring search diversity via entropy; when diversity drops, it intervenes by\ndynamically annealing the resampling distribution to preserve exploration. The\nsecond, an enhancement called Look-ahead Modulation (LaM), adds a predictive\nguide to evaluate a state's potential based on its successors. On several\nchallenging math benchmarks, ePF significantly outperforms strong baselines and\nachieves up to a 50 % relative improvement in task reward. Together, these\nmethods improve PF's resilience by balancing the exploration of diverse\nsolution spaces with the exploitation of high-reward regions, ultimately\nleading to higher-quality solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u71b5\u7c92\u5b50\u6ee4\u6ce2(ePF)\u65b9\u6cd5\uff0c\u901a\u8fc7\u71b5\u9000\u706b\u548c\u524d\u77bb\u8c03\u5236\u6280\u672f\u89e3\u51b3\u7c92\u5b50\u6ee4\u6ce2\u5728\u63a8\u7406\u65f6\u95f4\u7f29\u653e\u4e2d\u7684\u8fc7\u65e9\u5229\u7528\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u7c92\u5b50\u6ee4\u6ce2\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8fc7\u5ea6\u81ea\u4fe1\u8bc4\u5206\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u8fc7\u65e9\u5229\u7528\u3001\u7c92\u5b50\u8d2b\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u9884\u7b97\u53d7\u9650\u65f6\u66f4\u4e3a\u4e25\u91cd\u3002", "method": "\u5f15\u5165\u71b5\u7c92\u5b50\u6ee4\u6ce2(ePF)\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u6280\u672f\uff1a1) \u71b5\u9000\u706b(EA) - \u901a\u8fc7\u76d1\u63a7\u641c\u7d22\u591a\u6837\u6027\uff0c\u5728\u591a\u6837\u6027\u4e0b\u964d\u65f6\u52a8\u6001\u9000\u706b\u91cd\u91c7\u6837\u5206\u5e03\uff1b2) \u524d\u77bb\u8c03\u5236(LaM) - \u57fa\u4e8e\u540e\u7ee7\u72b6\u6001\u8bc4\u4f30\u72b6\u6001\u6f5c\u529b\u3002", "result": "\u5728\u591a\u4e2a\u6311\u6218\u6027\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cePF\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4efb\u52a1\u5956\u52b1\u76f8\u5bf9\u63d0\u5347\u9ad8\u8fbe50%\u3002", "conclusion": "ePF\u901a\u8fc7\u5e73\u8861\u591a\u6837\u5316\u89e3\u7a7a\u95f4\u7684\u63a2\u7d22\u548c\u9ad8\u5956\u52b1\u533a\u57df\u7684\u5229\u7528\uff0c\u63d0\u9ad8\u4e86\u7c92\u5b50\u6ee4\u6ce2\u7684\u9c81\u68d2\u6027\uff0c\u6700\u7ec8\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05840", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05840", "abs": "https://arxiv.org/abs/2510.05840", "authors": ["Zhi Liu", "Xuyuan Hu", "Xiao Han", "Zhehao Dai", "Zhaolin Deng", "Guojiang Shen", "Xiangjie Kong"], "title": "Multimodal Trajectory Representation Learning for Travel Time Estimation", "comment": null, "summary": "Accurate travel time estimation (TTE) plays a crucial role in intelligent\ntransportation systems. However, it remains challenging due to heterogeneous\ndata sources and complex traffic dynamics. Moreover, conventional approaches\ntypically convert trajectories into fixed-length representations, neglecting\nthe inherent variability of real-world trajectories, which often leads to\ninformation loss or feature redundancy. To address these challenges, this paper\nintroduces the Multimodal Dynamic Trajectory Integration (MDTI) framework--a\nnovel multimodal trajectory representation learning approach that integrates\nGPS sequences, grid trajectories, and road network constraints to enhance TTE\naccuracy. MDTI employs modality-specific encoders and a cross-modal interaction\nmodule to capture complementary spatial, temporal, and topological semantics,\nwhile a dynamic trajectory modeling mechanism adaptively regulates information\ndensity for trajectories of varying lengths. Two self-supervised pretraining\nobjectives, named contrastive alignment and masked language modeling, further\nstrengthen multimodal consistency and contextual understanding. Extensive\nexperiments on three real-world datasets demonstrate that MDTI consistently\noutperforms state-of-the-art baselines, confirming its robustness and strong\ngeneralization abilities. The code is publicly available at:\nhttps://github.com/freshhxy/MDTI/", "AI": {"tldr": "\u63d0\u51faMDTI\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u8f68\u8ff9\u8868\u793a\u5b66\u4e60\u6574\u5408GPS\u5e8f\u5217\u3001\u7f51\u683c\u8f68\u8ff9\u548c\u9053\u8def\u7f51\u7edc\u7ea6\u675f\uff0c\u63d0\u5347\u65c5\u884c\u65f6\u95f4\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u8f68\u8ff9\u8f6c\u6362\u4e3a\u56fa\u5b9a\u957f\u5ea6\u8868\u793a\uff0c\u5ffd\u7565\u4e86\u771f\u5b9e\u8f68\u8ff9\u7684\u53ef\u53d8\u6027\uff0c\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\u6216\u7279\u5f81\u5197\u4f59\u3002", "method": "\u4f7f\u7528\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u6a21\u5757\u6355\u6349\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u62d3\u6251\u8bed\u4e49\uff0c\u52a8\u6001\u8f68\u8ff9\u5efa\u6a21\u673a\u5236\u81ea\u9002\u5e94\u8c03\u8282\u4e0d\u540c\u957f\u5ea6\u8f68\u8ff9\u7684\u4fe1\u606f\u5bc6\u5ea6\uff0c\u91c7\u7528\u5bf9\u6bd4\u5bf9\u9f50\u548c\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u4e24\u79cd\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u76ee\u6807\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMDTI\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u4e86\u5176\u9c81\u68d2\u6027\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MDTI\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u8f68\u8ff9\u6574\u5408\u548c\u52a8\u6001\u5efa\u6a21\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65c5\u884c\u65f6\u95f4\u4f30\u8ba1\u4e2d\u7684\u6311\u6218\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.05849", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.05849", "abs": "https://arxiv.org/abs/2510.05849", "authors": ["Adhithyan Kalaivanan", "Zheng Zhao", "Jens Sj\u00f6lund", "Fredrik Lindsten"], "title": "ESS-Flow: Training-free guidance of flow-based models as inference in source space", "comment": "14 pages, 12 figures. Code will be made available after publication", "summary": "Guiding pretrained flow-based generative models for conditional generation or\nto produce samples with desired target properties enables solving diverse tasks\nwithout retraining on paired data. We present ESS-Flow, a gradient-free method\nthat leverages the typically Gaussian prior of the source distribution in\nflow-based models to perform Bayesian inference directly in the source space\nusing Elliptical Slice Sampling. ESS-Flow only requires forward passes through\nthe generative model and observation process, no gradient or Jacobian\ncomputations, and is applicable even when gradients are unreliable or\nunavailable, such as with simulation-based observations or quantization in the\ngeneration or observation process. We demonstrate its effectiveness on\ndesigning materials with desired target properties and predicting protein\nstructures from sparse inter-residue distance measurements.", "AI": {"tldr": "ESS-Flow\u662f\u4e00\u79cd\u65e0\u9700\u68af\u5ea6\u7684\u6761\u4ef6\u751f\u6210\u65b9\u6cd5\uff0c\u5229\u7528\u6d41\u6a21\u578b\u7684\u5148\u9a8c\u5206\u5e03\u901a\u8fc7\u692d\u5706\u5207\u7247\u91c7\u6837\u8fdb\u884c\u8d1d\u53f6\u65af\u63a8\u65ad\uff0c\u9002\u7528\u4e8e\u6750\u6599\u8bbe\u8ba1\u548c\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u7b49\u4efb\u52a1\u3002", "motivation": "\u9884\u8bad\u7ec3\u7684\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\u5728\u6761\u4ef6\u751f\u6210\u6216\u4ea7\u751f\u5177\u6709\u76ee\u6807\u5c5e\u6027\u7684\u6837\u672c\u65f6\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6210\u5bf9\u6570\u636e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u68af\u5ea6\u8ba1\u7b97\uff0c\u9650\u5236\u4e86\u5728\u68af\u5ea6\u4e0d\u53ef\u9760\u6216\u4e0d\u53ef\u7528\u573a\u666f\u4e0b\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faESS-Flow\u65b9\u6cd5\uff0c\u5229\u7528\u6d41\u6a21\u578b\u901a\u5e38\u5177\u6709\u9ad8\u65af\u5148\u9a8c\u7684\u7279\u70b9\uff0c\u5728\u6e90\u7a7a\u95f4\u4e2d\u4f7f\u7528\u692d\u5706\u5207\u7247\u91c7\u6837\u8fdb\u884c\u8d1d\u53f6\u65af\u63a8\u65ad\uff0c\u4ec5\u9700\u524d\u5411\u901a\u8fc7\u751f\u6210\u6a21\u578b\u548c\u89c2\u6d4b\u8fc7\u7a0b\uff0c\u65e0\u9700\u68af\u5ea6\u6216\u96c5\u53ef\u6bd4\u8ba1\u7b97\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6750\u6599\u8bbe\u8ba1\u548c\u4ece\u7a00\u758f\u6b8b\u57fa\u95f4\u8ddd\u79bb\u6d4b\u91cf\u9884\u6d4b\u86cb\u767d\u8d28\u7ed3\u6784\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u57fa\u4e8e\u6a21\u62df\u7684\u89c2\u6d4b\u6216\u751f\u6210/\u89c2\u6d4b\u8fc7\u7a0b\u4e2d\u7684\u91cf\u5316\u7b49\u68af\u5ea6\u4e0d\u53ef\u9760\u573a\u666f\u3002", "conclusion": "ESS-Flow\u4e3a\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u68af\u5ea6\u7684\u6761\u4ef6\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u8fd9\u7c7b\u6a21\u578b\u5728\u68af\u5ea6\u4e0d\u53ef\u7528\u573a\u666f\u4e0b\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2510.05856", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05856", "abs": "https://arxiv.org/abs/2510.05856", "authors": ["Egor Surkov", "Dmitry Osin", "Evgeny Burnaev", "Egor Shvetsov"], "title": "How to model Human Actions distribution with Event Sequence Data", "comment": "9 pages main text + 2 pages references + 6 pages appendix, 10\n  figures, 3 tables. Preprint version", "summary": "This paper studies forecasting of the future distribution of events in human\naction sequences, a task essential in domains like retail, finance, healthcare,\nand recommendation systems where the precise temporal order is often less\ncritical than the set of outcomes. We challenge the dominant autoregressive\nparadigm and investigate whether explicitly modeling the future distribution or\norder-invariant multi-token approaches outperform order-preserving methods. We\nanalyze local order invariance and introduce a KL-based metric to quantify\ntemporal drift. We find that a simple explicit distribution forecasting\nobjective consistently surpasses complex implicit baselines. We further\ndemonstrate that mode collapse of predicted categories is primarily driven by\ndistributional imbalance. This work provides a principled framework for\nselecting modeling strategies and offers practical guidance for building more\naccurate and robust forecasting systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4eba\u7c7b\u884c\u4e3a\u5e8f\u5217\u4e2d\u4e8b\u4ef6\u672a\u6765\u5206\u5e03\u7684\u9884\u6d4b\uff0c\u6311\u6218\u4e86\u4e3b\u6d41\u81ea\u56de\u5f52\u8303\u5f0f\uff0c\u53d1\u73b0\u663e\u5f0f\u5206\u5e03\u9884\u6d4b\u76ee\u6807\u4f18\u4e8e\u9690\u5f0f\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5728\u96f6\u552e\u3001\u91d1\u878d\u3001\u533b\u7597\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u9886\u57df\uff0c\u4e8b\u4ef6\u53d1\u751f\u7684\u7cbe\u786e\u65f6\u95f4\u987a\u5e8f\u5f80\u5f80\u4e0d\u5982\u7ed3\u679c\u96c6\u5408\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u8d85\u8d8a\u81ea\u56de\u5f52\u8303\u5f0f\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u672a\u6765\u4e8b\u4ef6\u5206\u5e03\u3002", "method": "\u5206\u6790\u4e86\u5c40\u90e8\u987a\u5e8f\u4e0d\u53d8\u6027\uff0c\u5f15\u5165\u4e86\u57fa\u4e8eKL\u6563\u5ea6\u7684\u6307\u6807\u6765\u91cf\u5316\u65f6\u95f4\u6f02\u79fb\uff0c\u6bd4\u8f83\u4e86\u663e\u5f0f\u5206\u5e03\u9884\u6d4b\u4e0e\u9690\u5f0f\u591a\u6807\u8bb0\u65b9\u6cd5\u3002", "result": "\u7b80\u5355\u7684\u663e\u5f0f\u5206\u5e03\u9884\u6d4b\u76ee\u6807\u59cb\u7ec8\u4f18\u4e8e\u590d\u6742\u7684\u9690\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9884\u6d4b\u7c7b\u522b\u6a21\u5f0f\u5d29\u6e83\u4e3b\u8981\u7531\u5206\u5e03\u4e0d\u5e73\u8861\u9a71\u52a8\u3002", "conclusion": "\u4e3a\u9009\u62e9\u5efa\u6a21\u7b56\u7565\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u51c6\u786e\u548c\u9c81\u68d2\u7684\u9884\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2510.05874", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05874", "abs": "https://arxiv.org/abs/2510.05874", "authors": ["Philipp Dahlinger", "Tai Hoang", "Denis Blessing", "Niklas Freymuth", "Gerhard Neumann"], "title": "MaNGO - Adaptable Graph Network Simulators via Meta-Learning", "comment": "19 pages including appendix. NeurIPS 2025 (preprint version)", "summary": "Accurately simulating physics is crucial across scientific domains, with\napplications spanning from robotics to materials science. While traditional\nmesh-based simulations are precise, they are often computationally expensive\nand require knowledge of physical parameters, such as material properties. In\ncontrast, data-driven approaches like Graph Network Simulators (GNSs) offer\nfaster inference but suffer from two key limitations: Firstly, they must be\nretrained from scratch for even minor variations in physical parameters, and\nsecondly they require labor-intensive data collection for each new parameter\nsetting. This is inefficient, as simulations with varying parameters often\nshare a common underlying latent structure. In this work, we address these\nchallenges by learning this shared structure through meta-learning, enabling\nfast adaptation to new physical parameters without retraining. To this end, we\npropose a novel architecture that generates a latent representation by encoding\ngraph trajectories using conditional neural processes (CNPs). To mitigate error\naccumulation over time, we combine CNPs with a novel neural operator\narchitecture. We validate our approach, Meta Neural Graph Operator (MaNGO), on\nseveral dynamics prediction tasks with varying material properties,\ndemonstrating superior performance over existing GNS methods. Notably, MaNGO\nachieves accuracy on unseen material properties close to that of an oracle\nmodel.", "AI": {"tldr": "\u63d0\u51faMeta Neural Graph Operator (MaNGO)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u89e3\u51b3\u56fe\u7f51\u7edc\u6a21\u62df\u5668\u9700\u8981\u4e3a\u4e0d\u540c\u7269\u7406\u53c2\u6570\u91cd\u65b0\u8bad\u7ec3\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\u65b0\u53c2\u6570\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u4f20\u7edf\u7f51\u683c\u6a21\u62df\u7cbe\u786e\u4f46\u8ba1\u7b97\u6602\u8d35\uff0c\u6570\u636e\u9a71\u52a8\u7684\u56fe\u7f51\u7edc\u6a21\u62df\u5668\u63a8\u7406\u5feb\u4f46\u9700\u4e3a\u6bcf\u4e2a\u65b0\u53c2\u6570\u8bbe\u7f6e\u91cd\u65b0\u8bad\u7ec3\u548c\u6536\u96c6\u6570\u636e\uff0c\u6548\u7387\u4f4e\u4e0b\u3002\u4e0d\u540c\u53c2\u6570\u7684\u6a21\u62df\u901a\u5e38\u5171\u4eab\u6f5c\u5728\u7ed3\u6784\u3002", "method": "\u4f7f\u7528\u5143\u5b66\u4e60\u5b66\u4e60\u5171\u4eab\u7ed3\u6784\uff0c\u7ed3\u5408\u6761\u4ef6\u795e\u7ecf\u8fc7\u7a0b(CNPs)\u7f16\u7801\u56fe\u8f68\u8ff9\u751f\u6210\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u8bbe\u8ba1\u65b0\u7684\u795e\u7ecf\u7b97\u5b50\u67b6\u6784\u6765\u51cf\u8f7b\u65f6\u95f4\u4e0a\u7684\u8bef\u5dee\u7d2f\u79ef\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u53d8\u5316\u6750\u6599\u5c5e\u6027\u7684\u52a8\u529b\u5b66\u9884\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0cMaNGO\u5728\u672a\u89c1\u6750\u6599\u5c5e\u6027\u4e0a\u8fbe\u5230\u63a5\u8fd1oracle\u6a21\u578b\u7684\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709GNS\u65b9\u6cd5\u3002", "conclusion": "MaNGO\u901a\u8fc7\u5143\u5b66\u4e60\u548c\u6761\u4ef6\u795e\u7ecf\u8fc7\u7a0b\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u7f51\u7edc\u6a21\u62df\u5668\u7684\u53c2\u6570\u9002\u5e94\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5bf9\u65b0\u7269\u7406\u53c2\u6570\u7684\u5feb\u901f\u9002\u5e94\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002"}}
{"id": "2510.05879", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05879", "abs": "https://arxiv.org/abs/2510.05879", "authors": ["Julia Moska", "Oleksii Furman", "Kacper Kozaczko", "Szymon Leszkiewicz", "Jakub Polczyk", "Piotr Gramacki", "Piotr Szyma\u0144ski"], "title": "OBSR: Open Benchmark for Spatial Representations", "comment": "ACM SIGSPATIAL 2025 Full Paper", "summary": "GeoAI is evolving rapidly, fueled by diverse geospatial datasets like traffic\npatterns, environmental data, and crowdsourced OpenStreetMap (OSM) information.\nWhile sophisticated AI models are being developed, existing benchmarks are\noften concentrated on single tasks and restricted to a single modality. As\nsuch, progress in GeoAI is limited by the lack of a standardized, multi-task,\nmodality-agnostic benchmark for their systematic evaluation. This paper\nintroduces a novel benchmark designed to assess the performance, accuracy, and\nefficiency of geospatial embedders. Our benchmark is modality-agnostic and\ncomprises 7 distinct datasets from diverse cities across three continents,\nensuring generalizability and mitigating demographic biases. It allows for the\nevaluation of GeoAI embedders on various phenomena that exhibit underlying\ngeographic processes. Furthermore, we establish a simple and intuitive\ntask-oriented model baselines, providing a crucial reference point for\ncomparing more complex solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684GeoAI\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5730\u7406\u7a7a\u95f4\u5d4c\u5165\u5668\u7684\u6027\u80fd\u3001\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u8be5\u57fa\u51c6\u5177\u6709\u6a21\u6001\u65e0\u5173\u6027\uff0c\u5305\u542b\u6765\u81ea\u4e09\u5927\u6d327\u4e2a\u4e0d\u540c\u57ce\u5e02\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5efa\u7acb\u4e86\u4efb\u52a1\u5bfc\u5411\u7684\u6a21\u578b\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684GeoAI\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u96c6\u4e2d\u5728\u5355\u4e00\u4efb\u52a1\u548c\u5355\u4e00\u6a21\u6001\u4e0a\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u3001\u591a\u4efb\u52a1\u3001\u6a21\u6001\u65e0\u5173\u7684\u57fa\u51c6\u6765\u7cfb\u7edf\u8bc4\u4f30GeoAI\u6a21\u578b\uff0c\u8fd9\u9650\u5236\u4e86GeoAI\u7684\u53d1\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6a21\u6001\u65e0\u5173\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u6765\u81ea\u4e09\u5927\u6d327\u4e2a\u4e0d\u540c\u57ce\u5e02\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u786e\u4fdd\u6cdb\u5316\u6027\u548c\u51cf\u5c11\u4eba\u53e3\u7edf\u8ba1\u504f\u5dee\uff0c\u5e76\u5efa\u7acb\u4e86\u7b80\u5355\u76f4\u89c2\u7684\u4efb\u52a1\u5bfc\u5411\u6a21\u578b\u57fa\u7ebf\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684GeoAI\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u8bc4\u4f30\u5730\u7406\u7a7a\u95f4\u5d4c\u5165\u5668\u5728\u5404\u79cd\u8868\u73b0\u57fa\u7840\u5730\u7406\u8fc7\u7a0b\u7684\u73b0\u8c61\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e3aGeoAI\u6a21\u578b\u7684\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5de5\u5177\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u3001\u591a\u6a21\u6001\u7684\u8bbe\u8ba1\u4fc3\u8fdb\u4e86GeoAI\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2510.05901", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05901", "abs": "https://arxiv.org/abs/2510.05901", "authors": ["Martin Benfeghoul", "Teresa Delgado", "Adnan Oomerjee", "Haitham Bou Ammar", "Jun Wang", "Zafeirios Fountas"], "title": "Paying Attention to Hybrid Attention: Untangling the Issues with Conversion Methods", "comment": null, "summary": "Transformers' quadratic computational complexity limits their scalability\ndespite remarkable performance. While linear attention reduces this to linear\ncomplexity, pre-training such models from scratch remains, in most cases,\nprohibitively expensive. Recent post-training linearisation methods convert\npre-trained Transformers to linear models efficiently, often using hybrid\napproaches that combine linear attention with sliding-window softmax. We\nidentify a critical flaw: existing hybrid methods inadvertently bypass the\nlinear component, relying almost entirely on SWA. Component-level diagnostics\nreveal this previously undetected behaviour stems from overlooked evaluation\npractices on common-sense benchmarks. We propose three solutions to ensure\nbalanced component usage: (i) inference-time hybridisation of linear-only\nconversions with sliding-window softmax; (ii) HedgeCATs, combining\nattention-weight transfer with targeted LoRA fine-tuning; and (iii) Scheduled\nSliding-window Dropout (SSD), which stochastically suppresses the softmax\nbranch during training to prevent component collapse. Our methods maintain\ncomputational efficiency while recovering most base model performance and\nensuring genuine linear attention adoption, restoring the validity of\nperformance attributions in hybrid conversions.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u73b0\u6709Transformer\u7ebf\u6027\u5316\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u89e3\u51b3\u65b9\u6848\u6765\u786e\u4fdd\u7ebf\u6027\u6ce8\u610f\u529b\u7ec4\u4ef6\u7684\u6709\u6548\u4f7f\u7528\uff0c\u907f\u514d\u8f6fmax\u7ec4\u4ef6\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002", "motivation": "\u73b0\u6709\u540e\u8bad\u7ec3\u7ebf\u6027\u5316\u65b9\u6cd5\u5b58\u5728\u5173\u952e\u7f3a\u9677\uff1a\u6df7\u5408\u65b9\u6cd5\u65e0\u610f\u4e2d\u7ed5\u8fc7\u4e86\u7ebf\u6027\u7ec4\u4ef6\uff0c\u51e0\u4e4e\u5b8c\u5168\u4f9d\u8d56\u6ed1\u52a8\u7a97\u53e3softmax\uff0c\u5bfc\u81f4\u6027\u80fd\u5f52\u56e0\u5931\u6548\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u89e3\u51b3\u65b9\u6848\uff1a(1) \u63a8\u7406\u65f6\u6df7\u5408\u7ebf\u6027\u8f6c\u6362\u4e0e\u6ed1\u52a8\u7a97\u53e3softmax\uff1b(2) HedgeCATs\u65b9\u6cd5\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u6743\u91cd\u8f6c\u79fb\u548c\u9488\u5bf9\u6027LoRA\u5fae\u8c03\uff1b(3) \u8ba1\u5212\u6ed1\u52a8\u7a97\u53e3dropout(SSD)\uff0c\u5728\u8bad\u7ec3\u4e2d\u968f\u673a\u6291\u5236softmax\u5206\u652f\u4ee5\u9632\u6b62\u7ec4\u4ef6\u5d29\u6e83\u3002", "result": "\u65b9\u6cd5\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u6062\u590d\u4e86\u5927\u90e8\u5206\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u786e\u4fdd\u771f\u6b63\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u91c7\u7528\uff0c\u6062\u590d\u4e86\u6df7\u5408\u8f6c\u6362\u4e2d\u6027\u80fd\u5f52\u56e0\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5e73\u8861\u7ec4\u4ef6\u4f7f\u7528\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u7ebf\u6027\u5316\u65b9\u6cd5\u4e2d\u7ebf\u6027\u7ec4\u4ef6\u88ab\u7ed5\u8fc7\u7684\u95ee\u9898\uff0c\u4e3aTransformer\u7ebf\u6027\u5316\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05919", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05919", "abs": "https://arxiv.org/abs/2510.05919", "authors": ["Marc Garreta Basora", "Mehmet Oguz Mulayim"], "title": "An Attention-Augmented VAE-BiLSTM Framework for Anomaly Detection in 12-Lead ECG Signals", "comment": "14 pages, 11 figures", "summary": "Anomaly detection in 12-lead electrocardiograms (ECGs) is critical for\nidentifying deviations associated with cardiovascular disease. This work\npresents a comparative analysis of three autoencoder-based architectures:\nconvolutional autoencoder (CAE), variational autoencoder with bidirectional\nlong short-term memory (VAE-BiLSTM), and VAE-BiLSTM with multi-head attention\n(VAE-BiLSTM-MHA), for unsupervised anomaly detection in ECGs. To the best of\nour knowledge, this study reports the first application of a VAE-BiLSTM-MHA\narchitecture to ECG anomaly detection. All models are trained on normal ECG\nsamples to reconstruct non-anomalous cardiac morphology and detect deviations\nindicative of disease. Using a unified preprocessing and evaluation pipeline on\nthe public China Physiological Signal Challenge (CPSC) dataset, the\nattention-augmented VAE achieves the best performance, with an AUPRC of 0.81\nand a recall of 0.85 on the held-out test set, outperforming the other\narchitectures. To support clinical triage, this model is further integrated\ninto an interactive dashboard that visualizes anomaly localization. In\naddition, a performance comparison with baseline models from the literature is\nprovided.", "AI": {"tldr": "\u6bd4\u8f83\u4e09\u79cd\u81ea\u7f16\u7801\u5668\u67b6\u6784\u572812\u5bfc\u8054\u5fc3\u7535\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u5176\u4e2d\u5e26\u591a\u5934\u6ce8\u610f\u529b\u7684VAE-BiLSTM-MHA\u67b6\u6784\u8868\u73b0\u6700\u4f73\uff0cAUPRC\u8fbe0.81\uff0c\u53ec\u56de\u73870.85", "motivation": "\u5fc3\u7535\u56fe\u5f02\u5e38\u68c0\u6d4b\u5bf9\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5", "method": "\u4f7f\u7528CAE\u3001VAE-BiLSTM\u548cVAE-BiLSTM-MHA\u4e09\u79cd\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5728\u6b63\u5e38ECG\u6837\u672c\u4e0a\u8bad\u7ec3\u4ee5\u91cd\u5efa\u6b63\u5e38\u5fc3\u810f\u5f62\u6001\uff0c\u68c0\u6d4b\u75be\u75c5\u76f8\u5173\u7684\u504f\u5dee", "result": "\u6ce8\u610f\u529b\u589e\u5f3a\u7684VAE-BiLSTM-MHA\u8868\u73b0\u6700\u4f73\uff0c\u5728CPSC\u6570\u636e\u96c6\u4e0aAUPRC\u4e3a0.81\uff0c\u53ec\u56de\u7387\u4e3a0.85\uff0c\u4f18\u4e8e\u5176\u4ed6\u67b6\u6784", "conclusion": "VAE-BiLSTM-MHA\u67b6\u6784\u5728ECG\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u96c6\u6210\u5230\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u4e2d\u652f\u6301\u4e34\u5e8a\u5206\u8bca"}}
{"id": "2510.05930", "categories": ["cs.LG", "cs.AI", "math.DG"], "pdf": "https://arxiv.org/pdf/2510.05930", "abs": "https://arxiv.org/abs/2510.05930", "authors": ["Jacob Bamberger", "Iolo Jones", "Dennis Duncan", "Michael M. Bronstein", "Pierre Vandergheynst", "Adam Gosztolai"], "title": "Carr\u00e9 du champ flow matching: better quality-generalisation tradeoff in generative models", "comment": null, "summary": "Deep generative models often face a fundamental tradeoff: high sample quality\ncan come at the cost of memorisation, where the model reproduces training data\nrather than generalising across the underlying data geometry. We introduce\nCarr\\'e du champ flow matching (CDC-FM), a generalisation of flow matching\n(FM), that improves the quality-generalisation tradeoff by regularising the\nprobability path with a geometry-aware noise. Our method replaces the\nhomogeneous, isotropic noise in FM with a spatially varying, anisotropic\nGaussian noise whose covariance captures the local geometry of the latent data\nmanifold. We prove that this geometric noise can be optimally estimated from\nthe data and is scalable to large data. Further, we provide an extensive\nexperimental evaluation on diverse datasets (synthetic manifolds, point clouds,\nsingle-cell genomics, animal motion capture, and images) as well as various\nneural network architectures (MLPs, CNNs, and transformers). We demonstrate\nthat CDC-FM consistently offers a better quality-generalisation tradeoff. We\nobserve significant improvements over standard FM in data-scarce regimes and in\nhighly non-uniformly sampled datasets, which are often encountered in AI for\nscience applications. Our work provides a mathematical framework for studying\nthe interplay between data geometry, generalisation and memorisation in\ngenerative models, as well as a robust and scalable algorithm that can be\nreadily integrated into existing flow matching pipelines.", "AI": {"tldr": "CDC-FM\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u6d41\u5339\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u51e0\u4f55\u611f\u77e5\u566a\u58f0\u6765\u6539\u5584\u751f\u6210\u6a21\u578b\u7684\u8d28\u91cf\u4e0e\u6cdb\u5316\u6743\u8861\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u548c\u975e\u5747\u5300\u91c7\u6837\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u4e2d\u6837\u672c\u8d28\u91cf\u4e0e\u8bb0\u5fc6\u5316\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u8d28\u91cf\u6837\u672c\u751f\u6210\u65f6\u5bb9\u6613\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u800c\u975e\u6cdb\u5316\u5230\u6570\u636e\u51e0\u4f55\u7ed3\u6784\u3002", "method": "\u63d0\u51faCarr\u00e9 du champ\u6d41\u5339\u914d(CDC-FM)\uff0c\u7528\u6355\u6349\u6f5c\u5728\u6570\u636e\u6d41\u5f62\u5c40\u90e8\u51e0\u4f55\u7684\u7a7a\u95f4\u53d8\u5316\u3001\u5404\u5411\u5f02\u6027\u9ad8\u65af\u566a\u58f0\u66ff\u6362\u4f20\u7edf\u6d41\u5339\u914d\u4e2d\u7684\u5747\u5300\u5404\u5411\u540c\u6027\u566a\u58f0\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCDC-FM\u59cb\u7ec8\u63d0\u4f9b\u66f4\u597d\u7684\u8d28\u91cf-\u6cdb\u5316\u6743\u8861\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u548c\u975e\u5747\u5300\u91c7\u6837\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u6d41\u5339\u914d\u3002", "conclusion": "CDC-FM\u4e3a\u7814\u7a76\u751f\u6210\u6a21\u578b\u4e2d\u6570\u636e\u51e0\u4f55\u3001\u6cdb\u5316\u548c\u8bb0\u5fc6\u5316\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u4e86\u6570\u5b66\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709\u6d41\u5339\u914d\u6d41\u7a0b\u4e2d\u7684\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u7b97\u6cd5\u3002"}}
{"id": "2510.05935", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05935", "abs": "https://arxiv.org/abs/2510.05935", "authors": ["Mohamed Bal-Ghaoui", "Fayssal Sabri"], "title": "LLM-FS-Agent: A Deliberative Role-based Large Language Model Architecture for Transparent Feature Selection", "comment": null, "summary": "High-dimensional data remains a pervasive challenge in machine learning,\noften undermining model interpretability and computational efficiency. While\nLarge Language Models (LLMs) have shown promise for dimensionality reduction\nthrough feature selection, existing LLM-based approaches frequently lack\nstructured reasoning and transparent justification for their decisions. This\npaper introduces LLM-FS-Agent, a novel multi-agent architecture designed for\ninterpretable and robust feature selection. The system orchestrates a\ndeliberative \"debate\" among multiple LLM agents, each assigned a specific role,\nenabling collective evaluation of feature relevance and generation of detailed\njustifications. We evaluate LLM-FS-Agent in the cybersecurity domain using the\nCIC-DIAD 2024 IoT intrusion detection dataset and compare its performance\nagainst strong baselines, including LLM-Select and traditional methods such as\nPCA. Experimental results demonstrate that LLM-FS-Agent consistently achieves\nsuperior or comparable classification performance while reducing downstream\ntraining time by an average of 46% (statistically significant improvement, p =\n0.028 for XGBoost). These findings highlight that the proposed deliberative\narchitecture enhances both decision transparency and computational efficiency,\nestablishing LLM-FS-Agent as a practical and reliable solution for real-world\napplications.", "AI": {"tldr": "\u63d0\u51faLLM-FS-Agent\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u95f4\u7684\"\u8fa9\u8bba\"\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u9009\u62e9\uff0c\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u663e\u8457\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u5e76\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\u6311\u6218\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u73b0\u6709LLM\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u548c\u900f\u660e\u51b3\u7b56\u4f9d\u636e\u3002", "method": "\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u8ba9\u591a\u4e2aLLM\u667a\u80fd\u4f53\u626e\u6f14\u4e0d\u540c\u89d2\u8272\u8fdb\u884c\"\u8fa9\u8bba\"\uff0c\u96c6\u4f53\u8bc4\u4f30\u7279\u5f81\u76f8\u5173\u6027\u5e76\u751f\u6210\u8be6\u7ec6\u89e3\u91ca\u3002", "result": "\u5728CIC-DIAD 2024\u7269\u8054\u7f51\u5165\u4fb5\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\uff0cLLM-FS-Agent\u8fbe\u5230\u4f18\u4e8e\u6216\u53ef\u6bd4\u5206\u7c7b\u6027\u80fd\uff0c\u5e73\u5747\u51cf\u5c11\u4e0b\u6e38\u8bad\u7ec3\u65f6\u95f446%\uff08XGBoost p=0.028\uff09\u3002", "conclusion": "\u8be5\u5ba1\u8bae\u67b6\u6784\u589e\u5f3a\u4e86\u51b3\u7b56\u900f\u660e\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4f7fLLM-FS-Agent\u6210\u4e3a\u5b9e\u9645\u5e94\u7528\u7684\u5b9e\u7528\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05949", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.05949", "abs": "https://arxiv.org/abs/2510.05949", "authors": ["Randall Balestriero", "Nicolas Ballas", "Mike Rabbat", "Yann LeCun"], "title": "Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density", "comment": null, "summary": "Joint Embedding Predictive Architectures (JEPAs) learn representations able\nto solve numerous downstream tasks out-of-the-box. JEPAs combine two\nobjectives: (i) a latent-space prediction term, i.e., the representation of a\nslightly perturbed sample must be predictable from the original sample's\nrepresentation, and (ii) an anti-collapse term, i.e., not all samples should\nhave the same representation. While (ii) is often considered as an obvious\nremedy to representation collapse, we uncover that JEPAs' anti-collapse term\ndoes much more--it provably estimates the data density. In short, any\nsuccessfully trained JEPA can be used to get sample probabilities, e.g., for\ndata curation, outlier detection, or simply for density estimation. Our\ntheoretical finding is agnostic of the dataset and architecture used--in any\ncase one can compute the learned probabilities of sample $x$ efficiently and in\nclosed-form using the model's Jacobian matrix at $x$. Our findings are\nempirically validated across datasets (synthetic, controlled, and Imagenet) and\nacross different Self Supervised Learning methods falling under the JEPA family\n(I-JEPA and DINOv2) and on multimodal models, such as MetaCLIP. We denote the\nmethod extracting the JEPA learned density as {\\bf JEPA-SCORE}.", "AI": {"tldr": "JEPAs\u7684\u9632\u574d\u584c\u9879\u4e0d\u4ec5\u9632\u6b62\u8868\u793a\u574d\u584c\uff0c\u8fd8\u8bc1\u660e\u4e86\u80fd\u591f\u4f30\u8ba1\u6570\u636e\u5bc6\u5ea6\uff0c\u53ef\u7528\u4e8e\u6570\u636e\u7b5b\u9009\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u5bc6\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u63ed\u793aJEPAs\u4e2d\u9632\u574d\u584c\u9879\u7684\u6df1\u5c42\u4f5c\u7528\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u4f30\u8ba1\u6570\u636e\u5bc6\u5ea6\uff0c\u6269\u5c55JEPAs\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660eJEPAs\u7684\u9632\u574d\u584c\u9879\u4e0e\u6570\u636e\u5bc6\u5ea6\u4f30\u8ba1\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u63d0\u51fa\u4f7f\u7528\u6a21\u578b\u5728\u6837\u672c\u5904\u7684Jacobian\u77e9\u9635\u9ad8\u6548\u8ba1\u7b97\u5b66\u4e60\u6982\u7387\u7684JEPA-SCORE\u65b9\u6cd5\u3002", "result": "\u5728\u5408\u6210\u3001\u53d7\u63a7\u548cImagenet\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86JEPA-SCORE\u7684\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8eI-JEPA\u3001DINOv2\u7b49JEPA\u5bb6\u65cf\u65b9\u6cd5\u548cMetaCLIP\u7b49\u591a\u6a21\u6001\u6a21\u578b\u3002", "conclusion": "JEPAs\u4e0d\u4ec5\u5b66\u4e60\u4e0b\u6e38\u4efb\u52a1\u8868\u793a\uff0c\u8fd8\u80fd\u63d0\u4f9b\u6570\u636e\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u4e3a\u6570\u636e\u7ba1\u7406\u3001\u5f02\u5e38\u68c0\u6d4b\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2510.05987", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05987", "abs": "https://arxiv.org/abs/2510.05987", "authors": ["Xueyan Li", "Guinan Su", "Mrinmaya Sachan", "Jonas Geiping"], "title": "Sample Smart, Not Hard: Correctness-First Decoding for Better Reasoning in LLMs", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied to complex tasks that\nrequire extended reasoning. In such settings, models often benefit from diverse\nchains-of-thought to arrive at multiple candidate solutions. This requires two\ncompeting objectives: to inject enough stochasticity to explore multiple\nreasoning chains, and to ensure sufficient accuracy and quality in each path.\nExisting works pursue the first objective by increasing exploration at highly\nuncertain steps with higher temperature or larger candidate token sets, while\nothers improve reliability by rejecting samples with low confidence\npost-generation, implying that low confidence correlates with low answer\nquality. These two lines of thought are in conflict, as they conflate different\nsources of uncertainty. To resolve this, we argue that the decoding rule should\nbe calibrated by correctness, not confidence alone. We should sample from\ntokens with higher estimated correctness, and reduce sampling where expected\ncorrectness is low. We propose simple strategies that achieve this goal:\nGreedy-Threshold makes sampling greedy at very low confidence steps.\nCalibrated-TopK and Calibrated-epsilon set truncation threshold based on\nestimated rank-wise correctness. Together, our findings challenge prevailing\nheuristics about decoding under uncertainty and show gains across math and\ngeneral reasoning benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u786e\u6027\u800c\u975e\u7f6e\u4fe1\u5ea6\u7684\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7Greedy-Threshold\u3001Calibrated-TopK\u548cCalibrated-epsilon\u7b49\u65b9\u6cd5\uff0c\u5728\u5927\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5e73\u8861\u63a2\u7d22\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6269\u5c55\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u77db\u76fe\uff1a\u4e00\u65b9\u9762\u9700\u8981\u589e\u52a0\u968f\u673a\u6027\u6765\u63a2\u7d22\u591a\u79cd\u63a8\u7406\u8def\u5f84\uff0c\u53e6\u4e00\u65b9\u9762\u53c8\u8981\u786e\u4fdd\u6bcf\u6761\u8def\u5f84\u7684\u8d28\u91cf\u3002\u4f20\u7edf\u65b9\u6cd5\u5c06\u7f6e\u4fe1\u5ea6\u4e0e\u7b54\u6848\u8d28\u91cf\u7b49\u540c\uff0c\u4f46\u5b9e\u9645\u4e0a\u7f6e\u4fe1\u5ea6\u548c\u6b63\u786e\u6027\u662f\u4e0d\u540c\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6b63\u786e\u6027\u6821\u51c6\u7684\u89e3\u7801\u89c4\u5219\uff1a\u5728\u4f30\u8ba1\u6b63\u786e\u6027\u9ad8\u7684token\u4e0a\u91c7\u6837\uff0c\u5728\u9884\u671f\u6b63\u786e\u6027\u4f4e\u7684\u5730\u65b9\u51cf\u5c11\u91c7\u6837\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1aGreedy-Threshold\uff08\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u6b65\u9aa4\u8fdb\u884c\u8d2a\u5a6a\u91c7\u6837\uff09\u3001Calibrated-TopK\u548cCalibrated-epsilon\uff08\u57fa\u4e8e\u4f30\u8ba1\u7684\u6309\u6392\u540d\u6b63\u786e\u6027\u8bbe\u7f6e\u622a\u65ad\u9608\u503c\uff09\u3002", "result": "\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u6027\u80fd\u63d0\u5347\uff0c\u6311\u6218\u4e86\u5173\u4e8e\u4e0d\u786e\u5b9a\u6027\u4e0b\u89e3\u7801\u7684\u666e\u904d\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u89e3\u7801\u7b56\u7565\u5e94\u8be5\u57fa\u4e8e\u6b63\u786e\u6027\u800c\u975e\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u6821\u51c6\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u5e73\u8861\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u63a2\u7d22\u6027\u548c\u51c6\u786e\u6027\u9700\u6c42\u3002"}}
{"id": "2510.06007", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06007", "abs": "https://arxiv.org/abs/2510.06007", "authors": ["Hans Weytjens", "Wouter Verbeke"], "title": "Uncertainty in Machine Learning", "comment": "Authored by Hans Weytjens. Wouter Verbeke provided proofreading and\n  served as the chief editor of the book in which this chapter appears", "summary": "This book chapter introduces the principles and practical applications of\nuncertainty quantification in machine learning. It explains how to identify and\ndistinguish between different types of uncertainty and presents methods for\nquantifying uncertainty in predictive models, including linear regression,\nrandom forests, and neural networks. The chapter also covers conformal\nprediction as a framework for generating predictions with predefined confidence\nintervals. Finally, it explores how uncertainty estimation can be leveraged to\nimprove business decision-making, enhance model reliability, and support\nrisk-aware strategies.", "AI": {"tldr": "\u672c\u7ae0\u4ecb\u7ecd\u673a\u5668\u5b66\u4e60\u4e2d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u539f\u7406\u548c\u5e94\u7528\uff0c\u6db5\u76d6\u4e0d\u540c\u7c7b\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u8bc6\u522b\u4e0e\u533a\u5206\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5728\u9884\u6d4b\u6a21\u578b\u4e2d\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u6280\u672f\uff0c\u5305\u62ec\u7ebf\u6027\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u548c\u795e\u7ecf\u7f51\u7edc\u3002\u8fd8\u8ba8\u8bba\u4e86\u4f7f\u7528\u4fdd\u5f62\u9884\u6d4b\u751f\u6210\u9884\u5b9a\u4e49\u7f6e\u4fe1\u533a\u95f4\u7684\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5982\u4f55\u6539\u5584\u5546\u4e1a\u51b3\u7b56\u3001\u589e\u5f3a\u6a21\u578b\u53ef\u9760\u6027\u548c\u652f\u6301\u98ce\u9669\u611f\u77e5\u7b56\u7565\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\uff0c\u51c6\u786e\u91cf\u5316\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u63d0\u9ad8\u51b3\u7b56\u8d28\u91cf\u3001\u589e\u5f3a\u6a21\u578b\u53ef\u9760\u6027\u548c\u5b9e\u65bd\u98ce\u9669\u611f\u77e5\u7b56\u7565\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f80\u5f80\u53ea\u63d0\u4f9b\u70b9\u4f30\u8ba1\uff0c\u7f3a\u4e4f\u5bf9\u9884\u6d4b\u53ef\u4fe1\u5ea6\u7684\u8bc4\u4f30\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\u3002", "method": "\u4ecb\u7ecd\u4e86\u591a\u79cd\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff1a1\uff09\u5728\u4f20\u7edf\u6a21\u578b\uff08\u7ebf\u6027\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\uff09\u4e2d\u96c6\u6210\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff1b2\uff09\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e94\u7528\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\uff1b3\uff09\u4f7f\u7528\u4fdd\u5f62\u9884\u6d4b\u6846\u67b6\u751f\u6210\u5177\u6709\u9884\u5b9a\u4e49\u7f6e\u4fe1\u533a\u95f4\u7684\u9884\u6d4b\uff1b4\uff09\u533a\u5206\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6280\u672f\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u9884\u6d4b\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u4f7f\u51b3\u7b56\u8005\u80fd\u591f\u8bc4\u4f30\u9884\u6d4b\u7684\u53ef\u4fe1\u5ea6\u3002\u8fd9\u6709\u52a9\u4e8e\u5728\u5546\u4e1a\u51b3\u7b56\u4e2d\u66f4\u597d\u5730\u6743\u8861\u98ce\u9669\u4e0e\u6536\u76ca\uff0c\u63d0\u9ad8\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u662f\u673a\u5668\u5b66\u4e60\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5173\u952e\u73af\u8282\uff0c\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\uff0c\u8fd8\u4e3a\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002\u5c06\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u6574\u5408\u5230\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.06020", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06020", "abs": "https://arxiv.org/abs/2510.06020", "authors": ["Sai Karthikeya Vemuri", "Adithya Ashok Chalain Valapil", "Tim B\u00fcchner", "Joachim Denzler"], "title": "RamPINN: Recovering Raman Spectra From Coherent Anti-Stokes Spectra Using Embedded Physics", "comment": null, "summary": "Transferring the recent advancements in deep learning into scientific\ndisciplines is hindered by the lack of the required large-scale datasets for\ntraining. We argue that in these knowledge-rich domains, the established body\nof scientific theory provides reliable inductive biases in the form of\ngoverning physical laws. We address the ill-posed inverse problem of recovering\nRaman spectra from noisy Coherent Anti-Stokes Raman Scattering (CARS)\nmeasurements, as the true Raman signal here is suppressed by a dominating\nnon-resonant background. We propose RamPINN, a model that learns to recover\nRaman spectra from given CARS spectra. Our core methodological contribution is\na physics-informed neural network that utilizes a dual-decoder architecture to\ndisentangle resonant and non-resonant signals. This is done by enforcing the\nKramers-Kronig causality relations via a differentiable Hilbert transform loss\non the resonant and a smoothness prior on the non-resonant part of the signal.\nTrained entirely on synthetic data, RamPINN demonstrates strong zero-shot\ngeneralization to real-world experimental data, explicitly closing this gap and\nsignificantly outperforming existing baselines. Furthermore, we show that\ntraining with these physics-based losses alone, without access to any\nground-truth Raman spectra, still yields competitive results. This work\nhighlights a broader concept: formal scientific rules can act as a potent\ninductive bias, enabling robust, self-supervised learning in data-limited\nscientific domains.", "AI": {"tldr": "\u63d0\u51faRamPINN\u6a21\u578b\uff0c\u5229\u7528\u7269\u7406\u77e5\u8bc6\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u4ece\u566a\u58f0CARS\u6d4b\u91cf\u4e2d\u6062\u590d\u62c9\u66fc\u5149\u8c31\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u8bad\u7ec3", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u79d1\u5b66\u9886\u57df\u5e94\u7528\u53d7\u9650\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u79d1\u5b66\u7406\u8bba\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7269\u7406\u5b9a\u5f8b\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e", "method": "\u91c7\u7528\u53cc\u89e3\u7801\u5668\u67b6\u6784\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u5e0c\u5c14\u4f2f\u7279\u53d8\u6362\u635f\u5931\u5f3a\u5236Kramers-Kronig\u56e0\u679c\u5173\u7cfb\uff0c\u5bf9\u5171\u632f\u548c\u975e\u5171\u632f\u4fe1\u53f7\u5206\u522b\u65bd\u52a0\u5e73\u6ed1\u5148\u9a8c", "result": "\u4ec5\u4f7f\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3\uff0c\u5728\u771f\u5b9e\u5b9e\u9a8c\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u6b63\u5f0f\u79d1\u5b66\u89c4\u5219\u53ef\u4f5c\u4e3a\u5f3a\u5927\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u5728\u6570\u636e\u53d7\u9650\u7684\u79d1\u5b66\u9886\u57df\u5b9e\u73b0\u9c81\u68d2\u7684\u81ea\u76d1\u7763\u5b66\u4e60"}}
{"id": "2510.06025", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.06025", "abs": "https://arxiv.org/abs/2510.06025", "authors": ["Kevin Raina", "Tanya Schmah"], "title": "Out-of-Distribution Detection from Small Training Sets using Bayesian Neural Network Classifiers", "comment": "British Machine Vision Conference (BMVC) 2025; 18 pages, 6 figures, 3\n  tables", "summary": "Out-of-Distribution (OOD) detection is critical to AI reliability and safety,\nyet in many practical settings, only a limited amount of training data is\navailable. Bayesian Neural Networks (BNNs) are a promising class of model on\nwhich to base OOD detection, because they explicitly represent epistemic (i.e.\nmodel) uncertainty. In the small training data regime, BNNs are especially\nvaluable because they can incorporate prior model information. We introduce a\nnew family of Bayesian posthoc OOD scores based on expected logit vectors, and\ncompare 5 Bayesian and 4 deterministic posthoc OOD scores. Experiments on MNIST\nand CIFAR-10 In-Distributions, with 5000 training samples or less, show that\nthe Bayesian methods outperform corresponding deterministic methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9884\u671flogit\u5411\u91cf\u7684\u8d1d\u53f6\u65af\u540e\u9a8cOOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u5c0f\u6837\u672c\u8bad\u7ec3\u573a\u666f\u4e0b\u4f18\u4e8e\u786e\u5b9a\u6027\u65b9\u6cd5", "motivation": "OOD\u68c0\u6d4b\u5bf9AI\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u8bad\u7ec3\u6570\u636e\u6709\u9650\u3002\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u80fd\u663e\u5f0f\u8868\u793a\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5c0f\u6837\u672c\u573a\u666f\u4e0b\u5c24\u5176\u6709\u4ef7\u503c", "method": "\u5f15\u5165\u57fa\u4e8e\u9884\u671flogit\u5411\u91cf\u7684\u8d1d\u53f6\u65af\u540e\u9a8cOOD\u8bc4\u5206\u5bb6\u65cf\uff0c\u6bd4\u8f835\u79cd\u8d1d\u53f6\u65af\u548c4\u79cd\u786e\u5b9a\u6027\u540e\u9a8cOOD\u8bc4\u5206\u65b9\u6cd5", "result": "\u5728MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u75285000\u4e2a\u6216\u66f4\u5c11\u8bad\u7ec3\u6837\u672c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8d1d\u53f6\u65af\u65b9\u6cd5\u4f18\u4e8e\u76f8\u5e94\u7684\u786e\u5b9a\u6027\u65b9\u6cd5", "conclusion": "\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728\u5c0f\u6837\u672cOOD\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18"}}
{"id": "2510.06028", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.06028", "abs": "https://arxiv.org/abs/2510.06028", "authors": ["Andreas Maurer", "Erfan Mirzaei", "Massimiliano Pontil"], "title": "Generalization of Gibbs and Langevin Monte Carlo Algorithms in the Interpolation Regime", "comment": null, "summary": "The paper provides data-dependent bounds on the test error of the Gibbs\nalgorithm in the overparameterized interpolation regime, where low training\nerrors are also obtained for impossible data, such as random labels in\nclassification. The bounds are stable under approximation with Langevin Monte\nCarlo algorithms. Experiments on the MNIST and CIFAR-10 datasets verify that\nthe bounds yield nontrivial predictions on true labeled data and correctly\nupper bound the test error for random labels. Our method indicates that\ngeneralization in the low-temperature, interpolation regime is already signaled\nby small training errors in the more classical high temperature regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u8fc7\u53c2\u6570\u5316\u63d2\u503c\u673a\u5236\u4e0b\u7684Gibbs\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6570\u636e\u4f9d\u8d56\u7684\u6d4b\u8bd5\u8bef\u5dee\u754c\u9650\uff0c\u5e76\u5728MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u754c\u9650\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u5728\u8fc7\u53c2\u6570\u5316\u63d2\u503c\u673a\u5236\u4e0b\uff0c\u5373\u4f7f\u5bf9\u4e8e\u968f\u673a\u6807\u7b7e\u7b49\u4e0d\u53ef\u80fd\u6570\u636e\u4e5f\u80fd\u83b7\u5f97\u4f4e\u8bad\u7ec3\u8bef\u5dee\u65f6\uff0cGibbs\u7b97\u6cd5\u7684\u6cdb\u5316\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u6570\u636e\u4f9d\u8d56\u7684\u754c\u9650\u6765\u5206\u6790Gibbs\u7b97\u6cd5\u5728\u8fc7\u53c2\u6570\u5316\u63d2\u503c\u673a\u5236\u4e0b\u7684\u6d4b\u8bd5\u8bef\u5dee\uff0c\u5e76\u901a\u8fc7Langevin Monte Carlo\u7b97\u6cd5\u8fdb\u884c\u8fd1\u4f3c\u7a33\u5b9a\u6027\u5206\u6790\u3002", "result": "\u5728MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u754c\u9650\u80fd\u591f\u5bf9\u771f\u5b9e\u6807\u8bb0\u6570\u636e\u4ea7\u751f\u975e\u5e73\u51e1\u9884\u6d4b\uff0c\u5e76\u6b63\u786e\u4e0a\u754c\u968f\u673a\u6807\u7b7e\u7684\u6d4b\u8bd5\u8bef\u5dee\u3002", "conclusion": "\u5728\u4f4e\u6e29\u5ea6\u63d2\u503c\u673a\u5236\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u5df2\u7ecf\u53ef\u4ee5\u901a\u8fc7\u66f4\u7ecf\u5178\u7684\u9ad8\u6e29\u5ea6\u673a\u5236\u4e2d\u7684\u5c0f\u8bad\u7ec3\u8bef\u5dee\u6765\u9884\u793a\u3002"}}
{"id": "2510.06029", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06029", "abs": "https://arxiv.org/abs/2510.06029", "authors": ["Guillaume Godin"], "title": "Fast Leave-One-Out Approximation from Fragment-Target Prevalence Vectors (molFTP) : From Dummy Masking to Key-LOO for Leakage-Free Feature Construction", "comment": "28 pages, 21 figures, 3 tables", "summary": "We introduce molFTP (molecular fragment-target prevalence), a compact\nrepresentation that delivers strong predictive performance. To prevent feature\nleakage across cross-validation folds, we implement a dummy-masking procedure\nthat removes information about fragments present in the held-out molecules. We\nfurther show that key leave-one-out (key-loo) closely approximates true\nmolecule-level leave-one-out (LOO), with deviation below 8% on our datasets.\nThis enables near full data training while preserving unbiased cross-validation\nestimates of model performance. Overall, molFTP provides a fast,\nleakage-resistant fragment-target prevalence vectorization with practical\nsafeguards (dummy masking or key-LOO) that approximate LOO at a fraction of its\ncost.", "AI": {"tldr": "molFTP\u662f\u4e00\u79cd\u7d27\u51d1\u7684\u5206\u5b50\u7247\u6bb5-\u9776\u6807\u6d41\u884c\u5ea6\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u865a\u62df\u63a9\u7801\u9632\u6b62\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\u7684\u7279\u5f81\u6cc4\u9732\uff0c\u5e76\u4f7f\u7528key-loo\u8fd1\u4f3c\u5206\u5b50\u7ea7\u7559\u4e00\u6cd5\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u9ad8\u6548\u65e0\u504f\u7684\u6027\u80fd\u8bc4\u4f30\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5206\u5b50\u8868\u793a\u65b9\u6cd5\u5728\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u7279\u5f81\u6cc4\u9732\u95ee\u9898\uff0c\u5e76\u964d\u4f4e\u7559\u4e00\u6cd5\u9a8c\u8bc1\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5f00\u53d1\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u80fd\u4fdd\u6301\u65e0\u504f\u6027\u80fd\u8bc4\u4f30\u7684\u5206\u5b50\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51famolFTP\u8868\u793a\u65b9\u6cd5\uff0c\u91c7\u7528\u865a\u62df\u63a9\u7801\u7a0b\u5e8f\u79fb\u9664\u4fdd\u7559\u5206\u5b50\u4e2d\u7247\u6bb5\u7684\u4fe1\u606f\u4ee5\u9632\u6b62\u7279\u5f81\u6cc4\u9732\uff0c\u5e76\u4f7f\u7528key-loo\u65b9\u6cd5\u8fd1\u4f3c\u5206\u5b50\u7ea7\u7559\u4e00\u6cd5\u9a8c\u8bc1\u3002", "result": "molFTP\u5177\u6709\u5f3a\u5927\u7684\u9884\u6d4b\u6027\u80fd\uff0ckey-loo\u4e0e\u771f\u5b9e\u5206\u5b50\u7ea7\u7559\u4e00\u6cd5\u7684\u504f\u5dee\u4f4e\u4e8e8%\uff0c\u80fd\u591f\u5b9e\u73b0\u8fd1\u4e4e\u5168\u6570\u636e\u8bad\u7ec3\u540c\u65f6\u4fdd\u6301\u65e0\u504f\u7684\u4ea4\u53c9\u9a8c\u8bc1\u6027\u80fd\u4f30\u8ba1\u3002", "conclusion": "molFTP\u63d0\u4f9b\u4e86\u4e00\u79cd\u5feb\u901f\u3001\u9632\u6cc4\u9732\u7684\u7247\u6bb5-\u9776\u6807\u6d41\u884c\u5ea6\u5411\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u865a\u62df\u63a9\u7801\u6216key-loo\u7b49\u5b9e\u7528\u4fdd\u62a4\u63aa\u65bd\uff0c\u4ee5\u8f83\u4f4e\u6210\u672c\u8fd1\u4f3c\u7559\u4e00\u6cd5\u9a8c\u8bc1\u6548\u679c\u3002"}}
{"id": "2510.06038", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06038", "abs": "https://arxiv.org/abs/2510.06038", "authors": ["Li Zeqiao", "Wang Yijing", "Wang Haoyu", "Li Zheng", "Li Peng", "Liu Wenfei", "Zuo Zhiqiang"], "title": "From Learning to Mastery: Achieving Safe and Efficient Real-World Autonomous Driving with Human-In-The-Loop Reinforcement Learning", "comment": null, "summary": "Autonomous driving with reinforcement learning (RL) has significant\npotential. However, applying RL in real-world settings remains challenging due\nto the need for safe, efficient, and robust learning. Incorporating human\nexpertise into the learning process can help overcome these challenges by\nreducing risky exploration and improving sample efficiency. In this work, we\npropose a reward-free, active human-in-the-loop learning method called\nHuman-Guided Distributional Soft Actor-Critic (H-DSAC). Our method combines\nProxy Value Propagation (PVP) and Distributional Soft Actor-Critic (DSAC) to\nenable efficient and safe training in real-world environments. The key\ninnovation is the construction of a distributed proxy value function within the\nDSAC framework. This function encodes human intent by assigning higher expected\nreturns to expert demonstrations and penalizing actions that require human\nintervention. By extrapolating these labels to unlabeled states, the policy is\neffectively guided toward expert-like behavior. With a well-designed state\nspace, our method achieves real-world driving policy learning within practical\ntraining times. Results from both simulation and real-world experiments\ndemonstrate that our framework enables safe, robust, and sample-efficient\nlearning for autonomous driving.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u5956\u52b1\u3001\u4e3b\u52a8\u7684\u4eba\u7c7b\u5728\u73af\u5b66\u4e60\u65b9\u6cd5H-DSAC\uff0c\u7ed3\u5408\u4ee3\u7406\u4ef7\u503c\u4f20\u64ad\u548c\u5206\u5e03\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff0c\u7528\u4e8e\u5b9e\u73b0\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u5b89\u5168\u81ea\u52a8\u9a7e\u9a76\u7b56\u7565\u5b66\u4e60\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u9762\u4e34\u5b89\u5168\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u6311\u6218\u3002\u901a\u8fc7\u878d\u5165\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u53ef\u4ee5\u51cf\u5c11\u98ce\u9669\u63a2\u7d22\u5e76\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "method": "\u5728DSAC\u6846\u67b6\u5185\u6784\u5efa\u5206\u5e03\u5f0f\u4ee3\u7406\u4ef7\u503c\u51fd\u6570\uff0c\u901a\u8fc7\u4e3a\u4e13\u5bb6\u6f14\u793a\u5206\u914d\u66f4\u9ad8\u671f\u671b\u56de\u62a5\u5e76\u5bf9\u9700\u8981\u4eba\u7c7b\u5e72\u9884\u7684\u884c\u4e3a\u8fdb\u884c\u60e9\u7f5a\u6765\u7f16\u7801\u4eba\u7c7b\u610f\u56fe\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6807\u7b7e\u5916\u63a8\u5230\u672a\u6807\u8bb0\u72b6\u6001\u4ee5\u5f15\u5bfc\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u5b89\u5168\u3001\u9c81\u68d2\u4e14\u6837\u672c\u9ad8\u6548\u7684\u81ea\u52a8\u9a7e\u9a76\u5b66\u4e60\uff0c\u5728\u5b9e\u7528\u8bad\u7ec3\u65f6\u95f4\u5185\u5b8c\u6210\u771f\u5b9e\u4e16\u754c\u9a7e\u9a76\u7b56\u7565\u5b66\u4e60\u3002", "conclusion": "H-DSAC\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u4eba\u7c7b\u6307\u5bfc\u878d\u5165\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4e3a\u771f\u5b9e\u4e16\u754c\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u5b89\u5168\u6709\u6548\u7684\u5b66\u4e60\u65b9\u6848\u3002"}}
{"id": "2510.06048", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06048", "abs": "https://arxiv.org/abs/2510.06048", "authors": ["Jie Hao", "Rui Yu", "Wei Zhang", "Huixia Wang", "Jie Xu", "Mingrui Liu"], "title": "BLISS: A Lightweight Bilevel Influence Scoring Method for Data Selection in Language Model Pretraining", "comment": null, "summary": "Effective data selection is essential for pretraining large language models\n(LLMs), enhancing efficiency and improving generalization to downstream tasks.\nHowever, existing approaches often require leveraging external pretrained\nmodels, making it difficult to disentangle the effects of data selection from\nthose of the external pretrained models. In addition, they often overlook the\nlong-term impact of selected data if the model is trained to convergence,\nprimarily due to the prohibitive cost of full-scale LLM pretraining. In this\npaper, we introduce BLISS (\\textbf{B}ileve\\textbf{L} \\textbf{I}nfluence\n\\textbf{S}coring method for data \\textbf{S}election): a lightweight data\nselection method that operates entirely \\emph{from scratch}, without relying on\nany external pretrained oracle models, while explicitly accounting for the\nlong-term impact of selected data. BLISS leverages a small proxy model as a\nsurrogate for the LLM and employs a score model to estimate the long-term\ninfluence of training samples if the proxy model is trained to convergence. We\nformulate data selection as a bilevel optimization problem, where the\nupper-level objective optimizes the score model to assign importance weights to\ntraining samples, ensuring that minimizing the lower-level objective (i.e.,\ntraining the proxy model over the weighted training loss until convergence)\nleads to best validation performance. Once optimized, the trained score model\npredicts influence scores for the dataset, enabling efficient selection of\nhigh-quality samples for LLM pretraining. We validate BLISS by pretraining\n410M/1B/2.8B Pythia and LLaMA-0.5B models on selected subsets of the C4\ndataset. Notably, under the 1B model setting, BLISS achieves $1.7\\times$\nspeedup in reaching the same performance as the state-of-the-art method,\ndemonstrating superior performance across multiple downstream tasks.", "AI": {"tldr": "BLISS\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u4f30\u8ba1\u8bad\u7ec3\u6837\u672c\u7684\u957f\u671f\u5f71\u54cd\uff0c\u4ece\u800c\u4e3aLLM\u9884\u8bad\u7ec3\u9009\u62e9\u9ad8\u8d28\u91cf\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5916\u90e8\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u96be\u4ee5\u5206\u79bb\u6570\u636e\u9009\u62e9\u6548\u679c\u4e0e\u5916\u90e8\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u4e14\u5ffd\u89c6\u4e86\u6570\u636e\u5728\u6a21\u578b\u5b8c\u5168\u6536\u655b\u65f6\u7684\u957f\u671f\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u5c0f\u578b\u4ee3\u7406\u6a21\u578b\u4f5c\u4e3aLLM\u66ff\u4ee3\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u8bad\u7ec3\u8bc4\u5206\u6a21\u578b\uff1a\u4e0a\u5c42\u4f18\u5316\u8bc4\u5206\u6a21\u578b\u4e3a\u8bad\u7ec3\u6837\u672c\u5206\u914d\u6743\u91cd\uff0c\u4e0b\u5c42\u4f18\u5316\u4ee3\u7406\u6a21\u578b\u5728\u52a0\u6743\u635f\u5931\u4e0a\u8bad\u7ec3\u81f3\u6536\u655b\uff0c\u786e\u4fdd\u6700\u4f73\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "\u5728410M/1B/2.8B Pythia\u548cLLaMA-0.5B\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c1B\u6a21\u578b\u8bbe\u7f6e\u4e0b\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u5feb1.7\u500d\u8fbe\u5230\u76f8\u540c\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "BLISS\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u6a21\u578b\u7684\u6709\u6548\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3\u6548\u7387\uff0c\u4e3aLLM\u6570\u636e\u9009\u62e9\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.06050", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06050", "abs": "https://arxiv.org/abs/2510.06050", "authors": ["David L\u00fcdke", "Marten Lienen", "Marcel Kollovieh", "Stephan G\u00fcnnemann"], "title": "Edit-Based Flow Matching for Temporal Point Processes", "comment": null, "summary": "Temporal point processes (TPPs) are a fundamental tool for modeling event\nsequences in continuous time, but most existing approaches rely on\nautoregressive parameterizations that are limited by their sequential sampling.\nRecent non-autoregressive, diffusion-style models mitigate these issues by\njointly interpolating between noise and data through event insertions and\ndeletions in a discrete Markov chain. In this work, we generalize this\nperspective and introduce an Edit Flow process for TPPs that transports noise\nto data via insert, delete, and substitute edit operations. By learning the\ninstantaneous edit rates within a continuous-time Markov chain framework, we\nattain a flexible and efficient model that effectively reduces the total number\nof necessary edit operations during generation. Empirical results demonstrate\nthe generative flexibility of our unconditionally trained model in a wide range\nof unconditional and conditional generation tasks on benchmark TPPs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65f6\u95f4\u70b9\u8fc7\u7a0b\u7684\u7f16\u8f91\u6d41\u8fc7\u7a0b\uff0c\u901a\u8fc7\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\u64cd\u4f5c\u5728\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u6846\u67b6\u4e2d\u4f20\u8f93\u566a\u58f0\u5230\u6570\u636e\uff0c\u51cf\u5c11\u4e86\u751f\u6210\u6240\u9700\u7684\u7f16\u8f91\u64cd\u4f5c\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u81ea\u56de\u5f52\u53c2\u6570\u5316\u65b9\u6cd5\u53d7\u9650\u4e8e\u987a\u5e8f\u91c7\u6837\uff0c\u800c\u6700\u8fd1\u7684\u6269\u6563\u5f0f\u6a21\u578b\u901a\u8fc7\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u94fe\u8054\u5408\u63d2\u503c\u566a\u58f0\u548c\u6570\u636e\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u3002", "method": "\u5728\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u6846\u67b6\u4e2d\u5b66\u4e60\u77ac\u65f6\u7f16\u8f91\u7387\uff0c\u901a\u8fc7\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\u7f16\u8f91\u64cd\u4f5c\u5b9e\u73b0\u566a\u58f0\u5230\u6570\u636e\u7684\u4f20\u8f93\u3002", "result": "\u5728\u57fa\u51c6TPP\u4e0a\u7684\u65e0\u6761\u4ef6\u751f\u6210\u548c\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u7684\u751f\u6210\u7075\u6d3b\u6027\u3002", "conclusion": "\u7f16\u8f91\u6d41\u8fc7\u7a0b\u4e3a\u65f6\u95f4\u70b9\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684\u751f\u6210\u6a21\u578b\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u751f\u6210\u6240\u9700\u7684\u7f16\u8f91\u64cd\u4f5c\u6570\u91cf\u3002"}}
{"id": "2510.06066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06066", "abs": "https://arxiv.org/abs/2510.06066", "authors": ["Dimitrios Kelesis", "Dimitris Fotakis", "Georgios Paliouras"], "title": "Analyzing the Effect of Embedding Norms and Singular Values to Oversmoothing in Graph Neural Networks", "comment": null, "summary": "In this paper, we study the factors that contribute to the effect of\noversmoothing in deep Graph Neural Networks (GNNs). Specifically, our analysis\nis based on a new metric (Mean Average Squared Distance - $MASED$) to quantify\nthe extent of oversmoothing. We derive layer-wise bounds on $MASED$, which\naggregate to yield global upper and lower distance bounds. Based on this\nquantification of oversmoothing, we further analyze the importance of two\ndifferent properties of the model; namely the norms of the generated node\nembeddings, along with the largest and smallest singular values of the weight\nmatrices. Building on the insights drawn from the theoretical analysis, we show\nthat oversmoothing increases as the number of trainable weight matrices and the\nnumber of adjacency matrices increases. We also use the derived layer-wise\nbounds on $MASED$ to form a proposal for decoupling the number of hops (i.e.,\nadjacency depth) from the number of weight matrices. In particular, we\nintroduce G-Reg, a regularization scheme that increases the bounds, and\ndemonstrate through extensive experiments that by doing so node classification\naccuracy increases, achieving robustness at large depths. We further show that\nby reducing oversmoothing in deep networks, we can achieve better results in\nsome tasks than using shallow ones. Specifically, we experiment with a ``cold\nstart\" scenario, i.e., when there is no feature information for the unlabeled\nnodes. Finally, we show empirically the trade-off between receptive field size\n(i.e., number of weight matrices) and performance, using the $MASED$ bounds.\nThis is achieved by distributing adjacency hops across a small number of\ntrainable layers, avoiding the extremes of under- or over-parameterization of\nthe GNN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMASED\u6307\u6807\u91cf\u5316GNN\u4e2d\u7684\u8fc7\u5e73\u6ed1\u73b0\u8c61\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u53d1\u73b0\u8fc7\u5e73\u6ed1\u7a0b\u5ea6\u4e0e\u6743\u91cd\u77e9\u9635\u6570\u91cf\u548c\u90bb\u63a5\u77e9\u9635\u6df1\u5ea6\u6b63\u76f8\u5173\uff0c\u5e76\u63d0\u51fa\u4e86G-Reg\u6b63\u5219\u5316\u65b9\u6cd5\u6765\u7f13\u89e3\u8fc7\u5e73\u6ed1\uff0c\u5728\u6df1\u5ea6\u7f51\u7edc\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u8282\u70b9\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u5bfc\u81f4\u8fc7\u5e73\u6ed1\u73b0\u8c61\u7684\u56e0\u7d20\uff0c\u901a\u8fc7\u91cf\u5316\u5206\u6790\u6765\u7406\u89e3\u8fc7\u5e73\u6ed1\u7684\u673a\u5236\uff0c\u5e76\u627e\u5230\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMASED\u6307\u6807\u91cf\u5316\u8fc7\u5e73\u6ed1\u7a0b\u5ea6\uff0c\u63a8\u5bfc\u5c42\u95f4\u8fb9\u754c\u6761\u4ef6\uff0c\u5206\u6790\u6743\u91cd\u77e9\u9635\u5947\u5f02\u503c\u548c\u8282\u70b9\u5d4c\u5165\u8303\u6570\u7684\u5f71\u54cd\uff0c\u63d0\u51faG-Reg\u6b63\u5219\u5316\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660eG-Reg\u80fd\u63d0\u9ad8\u8282\u70b9\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5728\u6df1\u5ea6\u7f51\u7edc\u4e2d\u5b9e\u73b0\u9c81\u68d2\u6027\uff0c\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u6d45\u5c42\u7f51\u7edc\uff0c\u5e76\u9a8c\u8bc1\u4e86\u611f\u53d7\u91ce\u5927\u5c0f\u4e0e\u6027\u80fd\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u63a7\u5236\u8fc7\u5e73\u6ed1\u7a0b\u5ea6\uff0c\u6df1\u5ea6GNN\u53ef\u4ee5\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u8d85\u8d8a\u6d45\u5c42\u7f51\u7edc\uff0cG-Reg\u6b63\u5219\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u7f51\u7edc\u6df1\u5ea6\u548c\u6027\u80fd\u3002"}}
{"id": "2510.06071", "categories": ["cs.LG", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.06071", "abs": "https://arxiv.org/abs/2510.06071", "authors": ["Jo\u00e3o Palmeiro", "Diogo Duarte", "Rita Costa", "Pedro Bizarro"], "title": "Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks", "comment": "9 pages, 3 figures, short paper accepted at VISxGenAI: 1st Workshop\n  on GenAI, Agents, and the Future of VIS (IEEE VIS 2025)", "summary": "AI models are increasingly used for data analysis and visualization, yet\nbenchmarks rarely address scatterplot-specific tasks, limiting insight into\nperformance. To address this gap for one of the most common chart types, we\nintroduce a synthetic, annotated dataset of over 18,000 scatterplots from six\ndata generators and 17 chart designs, and a benchmark based on it. We evaluate\nproprietary models from OpenAI and Google using N-shot prompting on five\ndistinct tasks derived from annotations of cluster bounding boxes, their center\ncoordinates, and outlier coordinates. OpenAI models and Gemini 2.5 Flash,\nespecially when prompted with examples, are viable options for counting\nclusters and, in Flash's case, outliers (90%+ Accuracy). However, the results\nfor localization-related tasks are unsatisfactory: Precision and Recall are\nnear or below 50%, except for Flash in outlier identification (65.01%).\nFurthermore, the impact of chart design on performance appears to be a\nsecondary factor, but it is advisable to avoid scatterplots with wide aspect\nratios (16:9 and 21:9) or those colored randomly. Supplementary materials are\navailable at https://github.com/feedzai/biy-paper.", "AI": {"tldr": "\u8be5\u8bba\u6587\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b18,000\u591a\u4e2a\u6563\u70b9\u56fe\u7684\u5408\u6210\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86OpenAI\u548cGoogle\u6a21\u578b\u5728\u4e94\u4e2a\u6563\u70b9\u56fe\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u5728\u8ba1\u6570\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5b9a\u4f4d\u76f8\u5173\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u5f88\u5c11\u9488\u5bf9\u6563\u70b9\u56fe\u7279\u5b9a\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u5bf9\u5176\u6027\u80fd\u7684\u6df1\u5165\u4e86\u89e3\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4f5c\u8005\u5f00\u53d1\u4e86\u4e13\u95e8\u7684\u6563\u70b9\u56fe\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u4f7f\u7528\u516d\u4e2a\u6570\u636e\u751f\u6210\u5668\u548c17\u79cd\u56fe\u8868\u8bbe\u8ba1\u521b\u5efa\u4e86\u8d85\u8fc718,000\u4e2a\u5e26\u6ce8\u91ca\u7684\u5408\u6210\u6563\u70b9\u56fe\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\u3002\u4f7f\u7528N-shot\u63d0\u793a\u6cd5\u8bc4\u4f30OpenAI\u548cGoogle\u7684\u4e13\u6709\u6a21\u578b\u5728\u4e94\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "OpenAI\u6a21\u578b\u548cGemini 2.5 Flash\u5728\u8ba1\u6570\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff08\u51c6\u786e\u738790%+\uff09\uff0c\u4f46\u5728\u5b9a\u4f4d\u76f8\u5173\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff08\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u63a5\u8fd1\u6216\u4f4e\u4e8e50%\uff09\u3002\u56fe\u8868\u8bbe\u8ba1\u5bf9\u6027\u80fd\u5f71\u54cd\u8f83\u5c0f\uff0c\u4f46\u5e94\u907f\u514d\u5bbd\u9ad8\u6bd4\u6563\u70b9\u56fe\uff0816:9\u548c21:9\uff09\u6216\u968f\u673a\u7740\u8272\u7684\u6563\u70b9\u56fe\u3002", "conclusion": "\u5f53\u524dAI\u6a21\u578b\u5728\u6563\u70b9\u56fe\u5206\u6790\u4e2d\u9002\u7528\u4e8e\u8ba1\u6570\u4efb\u52a1\uff0c\u4f46\u4e0d\u9002\u7528\u4e8e\u5b9a\u4f4d\u4efb\u52a1\u3002\u5efa\u8bae\u907f\u514d\u4f7f\u7528\u5bbd\u9ad8\u6bd4\u6563\u70b9\u56fe\u6216\u968f\u673a\u7740\u8272\u7684\u6563\u70b9\u56fe\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.06091", "categories": ["cs.LG", "cs.SY", "eess.SY", "q-bio.NC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.06091", "abs": "https://arxiv.org/abs/2510.06091", "authors": ["Lulu Gong", "Shreya Saxena"], "title": "Learning Mixtures of Linear Dynamical Systems (MoLDS) via Hybrid Tensor-EM Method", "comment": "20 pages, 7 figures", "summary": "Mixtures of linear dynamical systems (MoLDS) provide a path to model\ntime-series data that exhibit diverse temporal dynamics across trajectories.\nHowever, its application remains challenging in complex and noisy settings,\nlimiting its effectiveness for neural data analysis. Tensor-based moment\nmethods can provide global identifiability guarantees for MoLDS, but their\nperformance degrades under noise and complexity. Commonly used\nexpectation-maximization (EM) methods offer flexibility in fitting latent\nmodels but are highly sensitive to initialization and prone to poor local\nminima. Here, we propose a tensor-based method that provides identifiability\nguarantees for learning MoLDS, which is followed by EM updates to combine the\nstrengths of both approaches. The novelty in our approach lies in the\nconstruction of moment tensors using the input-output data to recover globally\nconsistent estimates of mixture weights and system parameters. These estimates\ncan then be refined through a Kalman EM algorithm, with closed-form updates for\nall LDS parameters. We validate our framework on synthetic benchmarks and\nreal-world datasets. On synthetic data, the proposed Tensor-EM method achieves\nmore reliable recovery and improved robustness compared to either pure tensor\nor randomly initialized EM methods. We then analyze neural recordings from the\nprimate somatosensory cortex while a non-human primate performs reaches in\ndifferent directions. Our method successfully models and clusters different\nconditions as separate subsystems, consistent with supervised single-LDS fits\nfor each condition. Finally, we apply this approach to another neural dataset\nwhere monkeys perform a sequential reaching task. These results demonstrate\nthat MoLDS provides an effective framework for modeling complex neural data,\nand that Tensor-EM is a reliable approach to MoLDS learning for these\napplications.", "AI": {"tldr": "\u63d0\u51faTensor-EM\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f20\u91cf\u65b9\u6cd5\u548cEM\u7b97\u6cd5\u7684\u4f18\u52bf\uff0c\u7528\u4e8e\u5b66\u4e60\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u6df7\u5408\u6a21\u578b\uff0c\u5728\u795e\u7ecf\u6570\u636e\u5206\u6790\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u6df7\u5408\u6a21\u578b\u5728\u590d\u6742\u566a\u58f0\u73af\u5883\u4e0b\u7684\u5e94\u7528\u53d7\u9650\uff0c\u73b0\u6709\u5f20\u91cf\u65b9\u6cd5\u5bf9\u566a\u58f0\u654f\u611f\uff0cEM\u65b9\u6cd5\u5bf9\u521d\u59cb\u5316\u654f\u611f\u4e14\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3002", "method": "\u4f7f\u7528\u8f93\u5165\u8f93\u51fa\u6570\u636e\u6784\u5efa\u77e9\u5f20\u91cf\u6765\u6062\u590d\u6df7\u5408\u6743\u91cd\u548c\u7cfb\u7edf\u53c2\u6570\u7684\u5168\u5c40\u4e00\u81f4\u4f30\u8ba1\uff0c\u7136\u540e\u901a\u8fc7\u5361\u5c14\u66fcEM\u7b97\u6cd5\u8fdb\u884c\u7ec6\u5316\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e0a\u6bd4\u7eaf\u5f20\u91cf\u6216\u968f\u673a\u521d\u59cb\u5316EM\u65b9\u6cd5\u66f4\u53ef\u9760\uff1b\u5728\u771f\u5b9e\u795e\u7ecf\u6570\u636e\u4e2d\u6210\u529f\u5efa\u6a21\u548c\u805a\u7c7b\u4e0d\u540c\u6761\u4ef6\u4e3a\u72ec\u7acb\u5b50\u7cfb\u7edf\u3002", "conclusion": "MoLDS\u662f\u5efa\u6a21\u590d\u6742\u795e\u7ecf\u6570\u636e\u7684\u6709\u6548\u6846\u67b6\uff0cTensor-EM\u662f\u5b66\u4e60MoLDS\u7684\u53ef\u9760\u65b9\u6cd5\u3002"}}
{"id": "2510.06092", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06092", "abs": "https://arxiv.org/abs/2510.06092", "authors": ["Nyal Patel", "Matthieu Bou", "Arjun Jagota", "Satyapriya Krishna", "Sonali Parbhoo"], "title": "Learning from Failures: Understanding LLM Alignment through Failure-Aware Inverse RL", "comment": "Preprint", "summary": "Reinforcement Learning from Human Feedback (RLHF) aligns Large Language\nModels (LLMs) with human preferences, yet the underlying reward signals they\ninternalize remain hidden, posing a critical challenge for interpretability and\nsafety. Existing approaches attempt to extract these latent incentives using\nInverse Reinforcement Learning (IRL), but treat all preference pairs equally,\noften overlooking the most informative signals: those examples the extracted\nreward model misclassifies or assigns nearly equal scores, which we term\n\\emph{failures}. We introduce a novel \\emph{failure-aware} IRL algorithm that\nfocuses on misclassified or difficult examples to recover the latent rewards\ndefining model behaviors. By learning from these failures, our failure-aware\nIRL extracts reward functions that better reflect the true objectives behind\nRLHF. We demonstrate that failure-aware IRL outperforms existing IRL baselines\nacross multiple metrics when applied to LLM detoxification, without requiring\nexternal classifiers or supervision. Crucially, failure-aware IRL yields\nrewards that better capture the true incentives learned during RLHF, enabling\nmore effective re-RLHF training than standard IRL. This establishes\nfailure-aware IRL as a robust, scalable method for auditing model alignment and\nreducing ambiguity in the IRL process.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5931\u8d25\u611f\u77e5\u7684\u9006\u5411\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u88ab\u9519\u8bef\u5206\u7c7b\u6216\u96be\u4ee5\u5224\u65ad\u7684\u6837\u672c\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u63d0\u53d6RLHF\u4e2d\u7684\u6f5c\u5728\u5956\u52b1\u4fe1\u53f7\u3002", "motivation": "RLHF\u867d\u7136\u80fd\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\uff0c\u4f46\u5176\u5185\u90e8\u5b66\u4e60\u7684\u5956\u52b1\u4fe1\u53f7\u96be\u4ee5\u89e3\u91ca\uff0c\u73b0\u6709IRL\u65b9\u6cd5\u5bf9\u6240\u6709\u504f\u597d\u5bf9\u4e00\u89c6\u540c\u4ec1\uff0c\u5ffd\u7565\u4e86\u6700\u5177\u4fe1\u606f\u91cf\u7684\u5931\u8d25\u6837\u672c\u3002", "method": "\u5f00\u53d1\u5931\u8d25\u611f\u77e5IRL\u7b97\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u88ab\u63d0\u53d6\u7684\u5956\u52b1\u6a21\u578b\u9519\u8bef\u5206\u7c7b\u6216\u8bc4\u5206\u63a5\u8fd1\u7684\u6837\u672c\uff0c\u901a\u8fc7\u8fd9\u4e9b\u5931\u8d25\u6837\u672c\u6765\u6062\u590d\u5b9a\u4e49\u6a21\u578b\u884c\u4e3a\u7684\u6f5c\u5728\u5956\u52b1\u3002", "result": "\u5728LLM\u53bb\u6bd2\u4efb\u52a1\u4e2d\uff0c\u5931\u8d25\u611f\u77e5IRL\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709IRL\u57fa\u7ebf\uff0c\u65e0\u9700\u5916\u90e8\u5206\u7c7b\u5668\u6216\u76d1\u7763\uff0c\u63d0\u53d6\u7684\u5956\u52b1\u80fd\u66f4\u597d\u5730\u53cd\u6620RLHF\u7684\u771f\u5b9e\u76ee\u6807\u3002", "conclusion": "\u5931\u8d25\u611f\u77e5IRL\u662f\u5ba1\u6838\u6a21\u578b\u5bf9\u9f50\u548c\u51cf\u5c11IRL\u8fc7\u7a0b\u6a21\u7cca\u6027\u7684\u7a33\u5065\u3001\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u80fd\u66f4\u6709\u6548\u5730\u652f\u6301\u91cd\u65b0RLHF\u8bad\u7ec3\u3002"}}
{"id": "2510.06096", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06096", "abs": "https://arxiv.org/abs/2510.06096", "authors": ["Matthieu Bou", "Nyal Patel", "Arjun Jagota", "Satyapriya Krishna", "Sonali Parbhoo"], "title": "The Alignment Auditor: A Bayesian Framework for Verifying and Refining LLM Objectives", "comment": "Preprint", "summary": "The objectives that Large Language Models (LLMs) implicitly optimize remain\ndangerously opaque, making trustworthy alignment and auditing a grand\nchallenge. While Inverse Reinforcement Learning (IRL) can infer reward\nfunctions from behaviour, existing approaches either produce a single,\noverconfident reward estimate or fail to address the fundamental ambiguity of\nthe task (non-identifiability). This paper introduces a principled auditing\nframework that re-frames reward inference from a simple estimation task to a\ncomprehensive process for verification. Our framework leverages Bayesian IRL to\nnot only recover a distribution over objectives but to enable three critical\naudit capabilities: (i) Quantifying and systematically reducing\nnon-identifiability by demonstrating posterior contraction over sequential\nrounds of evidence; (ii) Providing actionable, uncertainty-aware diagnostics\nthat expose spurious shortcuts and identify out-of-distribution prompts where\nthe inferred objective cannot be trusted; and (iii) Validating policy-level\nutility by showing that the refined, low-uncertainty reward can be used\ndirectly in RLHF to achieve training dynamics and toxicity reductions\ncomparable to the ground-truth alignment process. Empirically, our framework\nsuccessfully audits a detoxified LLM, yielding a well-calibrated and\ninterpretable objective that strengthens alignment guarantees. Overall, this\nwork provides a practical toolkit for auditors, safety teams, and regulators to\nverify what LLMs are truly trying to achieve, moving us toward more trustworthy\nand accountable AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8d1d\u53f6\u65af\u9006\u5f3a\u5316\u5b66\u4e60\u7684LLM\u76ee\u6807\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u975e\u53ef\u8bc6\u522b\u6027\u3001\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u8bca\u65ad\u548c\u9a8c\u8bc1\u7b56\u7565\u7ea7\u6548\u7528\u6765\u589e\u5f3aLLM\u5bf9\u9f50\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9690\u5f0f\u4f18\u5316\u7684\u76ee\u6807\u4e0d\u900f\u660e\uff0c\u4f7f\u5f97\u53ef\u4fe1\u5bf9\u9f50\u548c\u5ba1\u8ba1\u6210\u4e3a\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u4ea7\u751f\u5355\u4e00\u3001\u8fc7\u5ea6\u81ea\u4fe1\u7684\u5956\u52b1\u4f30\u8ba1\uff0c\u8981\u4e48\u672a\u80fd\u89e3\u51b3\u4efb\u52a1\u7684\u57fa\u672c\u6a21\u7cca\u6027\uff08\u975e\u53ef\u8bc6\u522b\u6027\uff09\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u6062\u590d\u76ee\u6807\u5206\u5e03\uff0c\u8fd8\u5b9e\u73b0\u4e09\u4e2a\u5173\u952e\u5ba1\u8ba1\u80fd\u529b\uff1a\u91cf\u5316\u5e76\u7cfb\u7edf\u51cf\u5c11\u975e\u53ef\u8bc6\u522b\u6027\u3001\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u4e0d\u786e\u5b9a\u6027\u8bca\u65ad\u3001\u9a8c\u8bc1\u7b56\u7565\u7ea7\u6548\u7528\u3002", "result": "\u6846\u67b6\u6210\u529f\u5ba1\u8ba1\u4e86\u4e00\u4e2a\u53bb\u6bd2\u5316\u7684LLM\uff0c\u4ea7\u751f\u4e86\u826f\u597d\u6821\u51c6\u548c\u53ef\u89e3\u91ca\u7684\u76ee\u6807\uff0c\u589e\u5f3a\u4e86\u5bf9\u9f50\u4fdd\u8bc1\u3002\u7ecf\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u7cbe\u70bc\u7684\u4f4e\u4e0d\u786e\u5b9a\u6027\u5956\u52b1\u53ef\u4ee5\u76f4\u63a5\u7528\u4e8eRLHF\uff0c\u5b9e\u73b0\u4e0e\u771f\u5b9e\u5bf9\u9f50\u8fc7\u7a0b\u76f8\u5f53\u7684\u8bad\u7ec3\u52a8\u6001\u548c\u6bd2\u6027\u964d\u4f4e\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5ba1\u8ba1\u4eba\u5458\u3001\u5b89\u5168\u56e2\u961f\u548c\u76d1\u7ba1\u673a\u6784\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u9a8c\u8bc1LLM\u771f\u6b63\u8bd5\u56fe\u5b9e\u73b0\u7684\u76ee\u6807\uff0c\u63a8\u52a8AI\u5411\u66f4\u53ef\u4fe1\u548c\u53ef\u95ee\u8d23\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2510.06106", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.06106", "abs": "https://arxiv.org/abs/2510.06106", "authors": ["Alessandro Favero"], "title": "The Physics of Data and Tasks: Theories of Locality and Compositionality in Deep Learning", "comment": "PhD dissertation. Preprint", "summary": "Deep neural networks have achieved remarkable success, yet our understanding\nof how they learn remains limited. These models can learn high-dimensional\ntasks, which is generally statistically intractable due to the curse of\ndimensionality. This apparent paradox suggests that learnable data must have an\nunderlying latent structure. What is the nature of this structure? How do\nneural networks encode and exploit it, and how does it quantitatively impact\nperformance - for instance, how does generalization improve with the number of\ntraining examples? This thesis addresses these questions by studying the roles\nof locality and compositionality in data, tasks, and deep learning\nrepresentations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u5b66\u4e60\u9ad8\u7ef4\u4efb\u52a1\uff0c\u63a2\u8ba8\u6570\u636e\u7684\u6f5c\u5728\u7ed3\u6784\u7279\u6027\uff0c\u7279\u522b\u662f\u5c40\u90e8\u6027\u548c\u7ec4\u5408\u6027\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u7edf\u8ba1\u4e0a\u96be\u4ee5\u5b66\u4e60\u9ad8\u7ef4\u4efb\u52a1\uff0c\u4f46\u5b9e\u9645\u4e0a\u5374\u80fd\u6210\u529f\uff0c\u8fd9\u8868\u660e\u53ef\u5b66\u4e60\u6570\u636e\u5fc5\u987b\u5177\u6709\u6f5c\u5728\u7684\u5e95\u5c42\u7ed3\u6784\u3002\u8bba\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u79cd\u7ed3\u6784\u7684\u672c\u8d28\u53ca\u5176\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u6570\u636e\u3001\u4efb\u52a1\u548c\u6df1\u5ea6\u5b66\u4e60\u8868\u793a\u4e2d\u7684\u5c40\u90e8\u6027\u548c\u7ec4\u5408\u6027\u4f5c\u7528\u6765\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u673a\u5236\u3002", "result": "\u8bba\u6587\u53d1\u73b0\u5c40\u90e8\u6027\u548c\u7ec4\u5408\u6027\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u6709\u6548\u5b66\u4e60\u9ad8\u7ef4\u4efb\u52a1\u7684\u5173\u952e\u7ed3\u6784\u7279\u6027\u3002", "conclusion": "\u6570\u636e\u7684\u5c40\u90e8\u6027\u548c\u7ec4\u5408\u6027\u7ed3\u6784\u4f7f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u514b\u670d\u7ef4\u5ea6\u8bc5\u5492\uff0c\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60\u548c\u6cdb\u5316\u3002"}}
{"id": "2510.06108", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06108", "abs": "https://arxiv.org/abs/2510.06108", "authors": ["Prateek Humane", "Paolo Cudrano", "Daniel Z. Kaplan", "Matteo Matteucci", "Supriyo Chakraborty", "Irina Rish"], "title": "Influence Functions for Efficient Data Selection in Reasoning", "comment": null, "summary": "Fine-tuning large language models (LLMs) on chain-of-thought (CoT) data shows\nthat a small amount of high-quality data can outperform massive datasets. Yet,\nwhat constitutes \"quality\" remains ill-defined. Existing reasoning methods rely\non indirect heuristics such as problem difficulty or trace length, while\ninstruction-tuning has explored a broader range of automated selection\nstrategies, but rarely in the context of reasoning. We propose to define\nreasoning data quality using influence functions, which measure the causal\neffect of individual CoT examples on downstream accuracy, and introduce\ninfluence-based pruning, which consistently outperforms perplexity and\nembedding-based baselines on math reasoning within a model family.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5f71\u54cd\u51fd\u6570\u6765\u5b9a\u4e49\u63a8\u7406\u6570\u636e\u8d28\u91cf\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u5f71\u54cd\u7684\u526a\u679d\u65b9\u6cd5\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u4e8e\u56f0\u60d1\u5ea6\u548c\u5d4c\u5165\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u95ee\u9898\u96be\u5ea6\u6216\u8f68\u8ff9\u957f\u5ea6\u7b49\u95f4\u63a5\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u800c\u6307\u4ee4\u8c03\u4f18\u867d\u7136\u63a2\u7d22\u4e86\u66f4\u5e7f\u6cdb\u7684\u81ea\u52a8\u9009\u62e9\u7b56\u7565\uff0c\u4f46\u5f88\u5c11\u5728\u63a8\u7406\u80cc\u666f\u4e0b\u5e94\u7528\u3002\u4ec0\u4e48\u6784\u6210\"\u8d28\u91cf\"\u63a8\u7406\u6570\u636e\u4ecd\u4e0d\u660e\u786e\u3002", "method": "\u4f7f\u7528\u5f71\u54cd\u51fd\u6570\u6765\u8861\u91cf\u5355\u4e2a\u601d\u7ef4\u94fe\u793a\u4f8b\u5bf9\u4e0b\u6e38\u51c6\u786e\u6027\u7684\u56e0\u679c\u6548\u5e94\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u5f71\u54cd\u7684\u526a\u679d\u65b9\u6cd5\u3002", "result": "\u5728\u6a21\u578b\u5bb6\u65cf\u5185\u7684\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u5f71\u54cd\u7684\u526a\u679d\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u56f0\u60d1\u5ea6\u548c\u5d4c\u5165\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5f71\u54cd\u51fd\u6570\u53ef\u4ee5\u6709\u6548\u5b9a\u4e49\u63a8\u7406\u6570\u636e\u8d28\u91cf\uff0c\u57fa\u4e8e\u5f71\u54cd\u7684\u526a\u679d\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.06122", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.06122", "abs": "https://arxiv.org/abs/2510.06122", "authors": ["Markus Krimmel", "Philip Hartout", "Karsten Borgwardt", "Dexiong Chen"], "title": "PolyGraph Discrepancy: a classifier-based metric for graph generation", "comment": null, "summary": "Existing methods for evaluating graph generative models primarily rely on\nMaximum Mean Discrepancy (MMD) metrics based on graph descriptors. While these\nmetrics can rank generative models, they do not provide an absolute measure of\nperformance. Their values are also highly sensitive to extrinsic parameters,\nnamely kernel and descriptor parametrization, making them incomparable across\ndifferent graph descriptors. We introduce PolyGraph Discrepancy (PGD), a new\nevaluation framework that addresses these limitations. It approximates the\nJensen-Shannon distance of graph distributions by fitting binary classifiers to\ndistinguish between real and generated graphs, featurized by these descriptors.\nThe data log-likelihood of these classifiers approximates a variational lower\nbound on the JS distance between the two distributions. Resulting metrics are\nconstrained to the unit interval [0,1] and are comparable across different\ngraph descriptors. We further derive a theoretically grounded summary metric\nthat combines these individual metrics to provide a maximally tight lower bound\non the distance for the given descriptors. Thorough experiments demonstrate\nthat PGD provides a more robust and insightful evaluation compared to MMD\nmetrics. The PolyGraph framework for benchmarking graph generative models is\nmade publicly available at https://github.com/BorgwardtLab/polygraph-benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e86PolyGraph Discrepancy (PGD)\u6846\u67b6\uff0c\u901a\u8fc7\u4e8c\u5143\u5206\u7c7b\u5668\u8fd1\u4f3c\u56fe\u5206\u5e03\u7684Jensen-Shannon\u8ddd\u79bb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8eMMD\u7684\u56fe\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u56fe\u63cf\u8ff0\u7b26\u7684MMD\u6307\u6807\uff0c\u8fd9\u4e9b\u6307\u6807\u53ea\u80fd\u76f8\u5bf9\u6392\u5e8f\u6a21\u578b\uff0c\u65e0\u6cd5\u63d0\u4f9b\u7edd\u5bf9\u6027\u80fd\u5ea6\u91cf\uff0c\u4e14\u5bf9\u6838\u51fd\u6570\u548c\u63cf\u8ff0\u7b26\u53c2\u6570\u5316\u9ad8\u5ea6\u654f\u611f\uff0c\u5bfc\u81f4\u4e0d\u540c\u63cf\u8ff0\u7b26\u95f4\u7684\u7ed3\u679c\u4e0d\u53ef\u6bd4\u8f83\u3002", "method": "\u901a\u8fc7\u62df\u5408\u4e8c\u5143\u5206\u7c7b\u5668\u6765\u533a\u5206\u771f\u5b9e\u56fe\u548c\u751f\u6210\u56fe\uff0c\u4f7f\u7528\u56fe\u63cf\u8ff0\u7b26\u4f5c\u4e3a\u7279\u5f81\u3002\u5206\u7c7b\u5668\u7684\u6570\u636e\u5bf9\u6570\u4f3c\u7136\u8fd1\u4f3c\u4e8e\u4e24\u4e2a\u5206\u5e03\u95f4JS\u8ddd\u79bb\u7684\u53d8\u5206\u4e0b\u754c\u3002", "result": "PGD\u6307\u6807\u88ab\u7ea6\u675f\u5728\u5355\u4f4d\u533a\u95f4[0,1]\u5185\uff0c\u53ef\u5728\u4e0d\u540c\u56fe\u63cf\u8ff0\u7b26\u95f4\u8fdb\u884c\u6bd4\u8f83\u3002\u5b9e\u9a8c\u8868\u660ePGD\u6bd4MMD\u6307\u6807\u63d0\u4f9b\u66f4\u9c81\u68d2\u548c\u6df1\u5165\u7684\u8bc4\u4f30\u3002", "conclusion": "PGD\u6846\u67b6\u89e3\u51b3\u4e86\u73b0\u6709\u56fe\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u6bd4\u8f83\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2510.06125", "categories": ["cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.06125", "abs": "https://arxiv.org/abs/2510.06125", "authors": ["Moumita Kamal", "Douglas A. Talbert"], "title": "Downsized and Compromised?: Assessing the Faithfulness of Model Compression", "comment": "Submitted to and under review at Springer Machine Learning Journal", "summary": "In real-world applications, computational constraints often require\ntransforming large models into smaller, more efficient versions through model\ncompression. While these techniques aim to reduce size and computational cost\nwithout sacrificing performance, their evaluations have traditionally focused\non the trade-off between size and accuracy, overlooking the aspect of model\nfaithfulness. This limited view is insufficient for high-stakes domains like\nhealthcare, finance, and criminal justice, where compressed models must remain\nfaithful to the behavior of their original counterparts. This paper presents a\nnovel approach to evaluating faithfulness in compressed models, moving beyond\nstandard metrics. We introduce and demonstrate a set of faithfulness metrics\nthat capture how model behavior changes post-compression. Our contributions\ninclude introducing techniques to assess predictive consistency between the\noriginal and compressed models using model agreement, and applying chi-squared\ntests to detect statistically significant changes in predictive patterns across\nboth the overall dataset and demographic subgroups, thereby exposing shifts\nthat aggregate fairness metrics may obscure. We demonstrate our approaches by\napplying quantization and pruning to artificial neural networks (ANNs) trained\non three diverse and socially meaningful datasets. Our findings show that high\naccuracy does not guarantee faithfulness, and our statistical tests detect\nsubtle yet significant shifts that are missed by standard metrics, such as\nAccuracy and Equalized Odds. The proposed metrics provide a practical and more\ndirect method for ensuring that efficiency gains through compression do not\ncompromise the fairness or faithfulness essential for trustworthy AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u538b\u7f29\u6a21\u578b\u5fe0\u5b9e\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u51c6\u786e\u7387\u6307\u6807\uff0c\u901a\u8fc7\u6a21\u578b\u4e00\u81f4\u6027\u548c\u5361\u65b9\u68c0\u9a8c\u6765\u68c0\u6d4b\u538b\u7f29\u540e\u6a21\u578b\u884c\u4e3a\u7684\u53d8\u5316\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u5b50\u7ec4\u4e2d\u7684\u9884\u6d4b\u6a21\u5f0f\u53d8\u5316\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u6a21\u578b\u538b\u7f29\u6280\u672f\u867d\u7136\u80fd\u51cf\u5c0f\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u4f20\u7edf\u8bc4\u4f30\u53ea\u5173\u6ce8\u5927\u5c0f\u4e0e\u51c6\u786e\u7387\u7684\u6743\u8861\uff0c\u5ffd\u89c6\u4e86\u6a21\u578b\u5fe0\u5b9e\u5ea6\u3002\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5982\u533b\u7597\u3001\u91d1\u878d\u548c\u5211\u4e8b\u53f8\u6cd5\u4e2d\uff0c\u538b\u7f29\u6a21\u578b\u5fc5\u987b\u4fdd\u6301\u4e0e\u539f\u6a21\u578b\u884c\u4e3a\u7684\u4e00\u81f4\u6027\u3002", "method": "\u5f15\u5165\u4e00\u7ec4\u5fe0\u5b9e\u5ea6\u6307\u6807\uff0c\u5305\u62ec\u4f7f\u7528\u6a21\u578b\u4e00\u81f4\u6027\u8bc4\u4f30\u9884\u6d4b\u4e00\u81f4\u6027\uff0c\u5e94\u7528\u5361\u65b9\u68c0\u9a8c\u68c0\u6d4b\u6574\u4f53\u6570\u636e\u96c6\u548c\u4eba\u53e3\u7edf\u8ba1\u5b50\u7ec4\u4e2d\u9884\u6d4b\u6a21\u5f0f\u7684\u7edf\u8ba1\u663e\u8457\u53d8\u5316\u3002\u5728\u4e09\u4e2a\u5177\u6709\u793e\u4f1a\u610f\u4e49\u7684\u6570\u636e\u96c6\u4e0a\u5bf9\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u91cf\u5316\u548c\u526a\u679d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u9ad8\u51c6\u786e\u7387\u4e0d\u80fd\u4fdd\u8bc1\u5fe0\u5b9e\u5ea6\uff0c\u7edf\u8ba1\u6d4b\u8bd5\u68c0\u6d4b\u5230\u4e86\u6807\u51c6\u6307\u6807\uff08\u5982\u51c6\u786e\u7387\u548c\u5747\u7b49\u51e0\u7387\uff09\u9057\u6f0f\u7684\u7ec6\u5fae\u4f46\u663e\u8457\u7684\u53d8\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u6307\u6807\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u66f4\u76f4\u63a5\u7684\u65b9\u6cd5\uff0c\u786e\u4fdd\u901a\u8fc7\u538b\u7f29\u83b7\u5f97\u7684\u6548\u7387\u63d0\u5347\u4e0d\u4f1a\u635f\u5bb3\u53ef\u4fe1AI\u6240\u5fc5\u9700\u7684\u516c\u5e73\u6027\u6216\u5fe0\u5b9e\u5ea6\u3002"}}
{"id": "2510.06126", "categories": ["cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.06126", "abs": "https://arxiv.org/abs/2510.06126", "authors": ["Haoxin Wang", "Xiaolong Tu", "Hongyu Ke", "Huirong Chai", "Dawei Chen", "Kyungtae Han"], "title": "lm-Meter: Unveiling Runtime Inference Latency for On-Device Language Models", "comment": "This is the preprint version of the paper accepted to The 10th\n  ACM/IEEE Symposium on Edge Computing (SEC 2025)", "summary": "Large Language Models (LLMs) are increasingly integrated into everyday\napplications, but their prevalent cloud-based deployment raises growing\nconcerns around data privacy and long-term sustainability. Running LLMs locally\non mobile and edge devices (on-device LLMs) offers the promise of enhanced\nprivacy, reliability, and reduced communication costs. However, realizing this\nvision remains challenging due to substantial memory and compute demands, as\nwell as limited visibility into performance-efficiency trade-offs on\nresource-constrained hardware. We propose lm-Meter, the first lightweight,\nonline latency profiler tailored for on-device LLM inference. lm-Meter captures\nfine-grained, real-time latency at both phase (e.g., embedding, prefill,\ndecode, softmax, sampling) and kernel levels without auxiliary devices. We\nimplement lm-Meter on commercial mobile platforms and demonstrate its high\nprofiling accuracy with minimal system overhead, e.g., only 2.58% throughput\nreduction in prefill and 0.99% in decode under the most constrained Powersave\ngovernor. Leveraging lm-Meter, we conduct comprehensive empirical studies\nrevealing phase- and kernel-level bottlenecks in on-device LLM inference,\nquantifying accuracy-efficiency trade-offs, and identifying systematic\noptimization opportunities. lm-Meter provides unprecedented visibility into the\nruntime behavior of LLMs on constrained platforms, laying the foundation for\ninformed optimization and accelerating the democratization of on-device LLM\nsystems. Code and tutorials are available at\nhttps://github.com/amai-gsu/LM-Meter.", "AI": {"tldr": "\u63d0\u51fa\u4e86lm-Meter\uff0c\u7b2c\u4e00\u4e2a\u4e13\u4e3a\u8bbe\u5907\u7aefLLM\u63a8\u7406\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u5728\u7ebf\u5ef6\u8fdf\u5206\u6790\u5668\uff0c\u80fd\u591f\u5728\u4e0d\u4f7f\u7528\u8f85\u52a9\u8bbe\u5907\u7684\u60c5\u51b5\u4e0b\u6355\u83b7\u7ec6\u7c92\u5ea6\u7684\u5b9e\u65f6\u5ef6\u8fdf\uff0c\u4e3a\u8bbe\u5907\u7aefLLM\u7cfb\u7edf\u7684\u4f18\u5316\u63d0\u4f9b\u5173\u952e\u6d1e\u5bdf\u3002", "motivation": "\u968f\u7740LLM\u5728\u65e5\u5e38\u5e94\u7528\u4e2d\u7684\u96c6\u6210\u5ea6\u63d0\u9ad8\uff0c\u57fa\u4e8e\u4e91\u7684\u90e8\u7f72\u65b9\u5f0f\u5f15\u53d1\u4e86\u6570\u636e\u9690\u79c1\u548c\u53ef\u6301\u7eed\u6027\u62c5\u5fe7\u3002\u5728\u79fb\u52a8\u548c\u8fb9\u7f18\u8bbe\u5907\u4e0a\u672c\u5730\u8fd0\u884cLLM\u53ef\u4ee5\u589e\u5f3a\u9690\u79c1\u6027\u3001\u53ef\u9760\u6027\u548c\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u4f46\u7531\u4e8e\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u5927\uff0c\u4ee5\u53ca\u5728\u8d44\u6e90\u53d7\u9650\u786c\u4ef6\u4e0a\u6027\u80fd\u6548\u7387\u6743\u8861\u7684\u53ef\u89c1\u6027\u6709\u9650\uff0c\u5b9e\u73b0\u8fd9\u4e00\u613f\u666f\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u4e86lm-Meter\uff0c\u8fd9\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5728\u7ebf\u5ef6\u8fdf\u5206\u6790\u5668\uff0c\u80fd\u591f\u5728\u9636\u6bb5\u7ea7\u522b\uff08\u5982\u5d4c\u5165\u3001\u9884\u586b\u5145\u3001\u89e3\u7801\u3001softmax\u3001\u91c7\u6837\uff09\u548c\u5185\u6838\u7ea7\u522b\u6355\u83b7\u7ec6\u7c92\u5ea6\u7684\u5b9e\u65f6\u5ef6\u8fdf\uff0c\u65e0\u9700\u8f85\u52a9\u8bbe\u5907\u3002\u5728\u5546\u7528\u79fb\u52a8\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u8be5\u7cfb\u7edf\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u9ad8\u5206\u6790\u7cbe\u5ea6\u548c\u4f4e\u7cfb\u7edf\u5f00\u9500\u3002", "result": "lm-Meter\u5728\u5546\u7528\u79fb\u52a8\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u6027\u80fd\u5206\u6790\uff0c\u5728\u6700\u5177\u7ea6\u675f\u7684Powersave\u8c03\u63a7\u5668\u4e0b\uff0c\u9884\u586b\u5145\u9636\u6bb5\u7684\u541e\u5410\u91cf\u4ec5\u964d\u4f4e2.58%\uff0c\u89e3\u7801\u9636\u6bb5\u4ec5\u964d\u4f4e0.99%\u3002\u901a\u8fc7lm-Meter\u8fdb\u884c\u7684\u5b9e\u8bc1\u7814\u7a76\u63ed\u793a\u4e86\u8bbe\u5907\u7aefLLM\u63a8\u7406\u4e2d\u7684\u9636\u6bb5\u548c\u5185\u6838\u7ea7\u74f6\u9888\uff0c\u91cf\u5316\u4e86\u7cbe\u5ea6\u6548\u7387\u6743\u8861\uff0c\u5e76\u8bc6\u522b\u4e86\u7cfb\u7edf\u6027\u4f18\u5316\u673a\u4f1a\u3002", "conclusion": "lm-Meter\u4e3a\u53d7\u9650\u5e73\u53f0\u4e0aLLM\u7684\u8fd0\u884c\u65f6\u884c\u4e3a\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u53ef\u89c1\u6027\uff0c\u4e3a\u77e5\u60c5\u4f18\u5316\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u52a0\u901f\u4e86\u8bbe\u5907\u7aefLLM\u7cfb\u7edf\u7684\u6c11\u4e3b\u5316\u8fdb\u7a0b\u3002"}}
{"id": "2510.06138", "categories": ["cs.LG", "cs.AI", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.06138", "abs": "https://arxiv.org/abs/2510.06138", "authors": ["Rushiv Arora"], "title": "Multi-Task Reinforcement Learning with Language-Encoded Gated Policy Networks", "comment": "14 pages, 3 figures, 12 tables, 2 appendices. Currently under review", "summary": "Multi-task reinforcement learning often relies on task metadata -- such as\nbrief natural-language descriptions -- to guide behavior across diverse\nobjectives. We present Lexical Policy Networks (LEXPOL), a language-conditioned\nmixture-of-policies architecture for multi-task RL. LEXPOL encodes task\nmetadata with a text encoder and uses a learned gating module to select or\nblend among multiple sub-policies, enabling end-to-end training across tasks.\nOn MetaWorld benchmarks, LEXPOL matches or exceeds strong multi-task baselines\nin success rate and sample efficiency, without task-specific retraining. To\nanalyze the mechanism, we further study settings with fixed expert policies\nobtained independently of the gate and show that the learned language gate\ncomposes these experts to produce behaviors appropriate to novel task\ndescriptions and unseen task combinations. These results indicate that\nnatural-language metadata can effectively index and recombine reusable skills\nwithin a single policy.", "AI": {"tldr": "LEXPOL\u662f\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u6761\u4ef6\u6df7\u5408\u7b56\u7565\u7684\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u901a\u8fc7\u6587\u672c\u7f16\u7801\u5668\u5904\u7406\u4efb\u52a1\u5143\u6570\u636e\uff0c\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u95e8\u63a7\u6a21\u5757\u9009\u62e9\u548c\u6df7\u5408\u591a\u4e2a\u5b50\u7b56\u7565\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "motivation": "\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u4f9d\u8d56\u4efb\u52a1\u5143\u6570\u636e\uff08\u5982\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\uff09\u6765\u6307\u5bfc\u4e0d\u540c\u76ee\u6807\u7684\u884c\u4e3a\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5229\u7528\u8bed\u8a00\u4fe1\u606f\u6765\u7d22\u5f15\u548c\u7ec4\u5408\u53ef\u91cd\u7528\u6280\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLEXPOL\u67b6\u6784\uff0c\u4f7f\u7528\u6587\u672c\u7f16\u7801\u5668\u7f16\u7801\u4efb\u52a1\u5143\u6570\u636e\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u95e8\u63a7\u6a21\u5757\u9009\u62e9\u548c\u6df7\u5408\u591a\u4e2a\u5b50\u7b56\u7565\uff0c\u652f\u6301\u7aef\u5230\u7aef\u8de8\u4efb\u52a1\u8bad\u7ec3\u3002", "result": "\u5728MetaWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLEXPOL\u5728\u6210\u529f\u7387\u548c\u6837\u672c\u6548\u7387\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8fc7\u5f3a\u5927\u591a\u4efb\u52a1\u57fa\u7ebf\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u91cd\u8bad\u7ec3\u3002\u5b66\u4e60\u5230\u7684\u8bed\u8a00\u95e8\u63a7\u80fd\u591f\u7ec4\u5408\u4e13\u5bb6\u7b56\u7565\u4ee5\u5904\u7406\u65b0\u4efb\u52a1\u63cf\u8ff0\u548c\u672a\u89c1\u4efb\u52a1\u7ec4\u5408\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u5143\u6570\u636e\u53ef\u4ee5\u6709\u6548\u5730\u5728\u5355\u4e00\u7b56\u7565\u4e2d\u7d22\u5f15\u548c\u91cd\u7ec4\u53ef\u91cd\u7528\u6280\u80fd\uff0c\u4e3a\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bed\u8a00\u6761\u4ef6\u63a7\u5236\u673a\u5236\u3002"}}
{"id": "2510.06141", "categories": ["cs.LG", "cs.MA", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.06141", "abs": "https://arxiv.org/abs/2510.06141", "authors": ["Aleksandar Armacki", "Ali H. Sayed"], "title": "Improved High-probability Convergence Guarantees of Decentralized SGD", "comment": "39 pages", "summary": "Convergence in high-probability (HP) has been receiving increasing interest,\ndue to its attractive properties, such as exponentially decaying tail bounds\nand strong guarantees for each individual run of an algorithm. While HP\nguarantees are extensively studied in centralized settings, much less is\nunderstood in the decentralized, networked setup. Existing HP studies in\ndecentralized settings impose strong assumptions, like uniformly bounded\ngradients, or asymptotically vanishing noise, resulting in a significant gap\nbetween assumptions used to establish convergence in the HP and the\nmean-squared error (MSE) sense, even for vanilla Decentralized Stochastic\nGradient Descent ($\\mathtt{DSGD}$) algorithm. This is contrary to centralized\nsettings, where it is known that $\\mathtt{SGD}$ converges in HP under the same\nconditions on the cost function as needed to guarantee MSE convergence.\nMotivated by this observation, we revisit HP guarantees for $\\mathtt{DSGD}$ in\nthe presence of light-tailed noise. We show that $\\mathtt{DSGD}$ converges in\nHP under the same conditions on the cost as in the MSE sense, removing\nuniformly bounded gradients and other restrictive assumptions, while\nsimultaneously achieving order-optimal rates for both non-convex and strongly\nconvex costs. Moreover, our improved analysis yields linear speed-up in the\nnumber of users, demonstrating that $\\mathtt{DSGD}$ maintains strong\nperformance in the HP sense and matches existing MSE guarantees. Our improved\nresults stem from a careful analysis of the MGF of quantities of interest\n(norm-squared of gradient or optimality gap) and the MGF of the consensus gap\nbetween users' models. To achieve linear speed-up, we provide a novel result on\nthe variance-reduction effect of decentralized methods in the HP sense and more\nfine-grained bounds on the MGF for strongly convex costs, which are both of\nindependent interest.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u53bb\u4e2d\u5fc3\u5316\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08DSGD\uff09\u7b97\u6cd5\u5728\u9ad8\u6982\u7387\uff08HP\uff09\u610f\u4e49\u4e0b\u7684\u6536\u655b\u6027\uff0c\u6d88\u9664\u4e86\u5bf9\u68af\u5ea6\u4e00\u81f4\u6709\u754c\u7b49\u5f3a\u5047\u8bbe\uff0c\u5728\u8f7b\u5c3e\u566a\u58f0\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u6536\u655b\u76f8\u540c\u7684\u6761\u4ef6\uff0c\u5e76\u83b7\u5f97\u4e86\u7ebf\u6027\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u53bb\u4e2d\u5fc3\u5316\u8bbe\u7f6e\u4e2d\u7684\u9ad8\u6982\u7387\u6536\u655b\u7814\u7a76\u9700\u8981\u5f3a\u5047\u8bbe\u6761\u4ef6\uff08\u5982\u68af\u5ea6\u4e00\u81f4\u6709\u754c\u6216\u6e10\u8fd1\u6d88\u5931\u566a\u58f0\uff09\uff0c\u5bfc\u81f4HP\u6536\u655b\u4e0eMSE\u6536\u655b\u7684\u5047\u8bbe\u6761\u4ef6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u8fd9\u4e0e\u96c6\u4e2d\u5f0f\u8bbe\u7f6e\u4e2dSGD\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u540c\u65f6\u5b9e\u73b0HP\u548cMSE\u6536\u655b\u7684\u60c5\u51b5\u5f62\u6210\u5bf9\u6bd4\u3002", "method": "\u901a\u8fc7\u4ed4\u7ec6\u5206\u6790\u611f\u5174\u8da3\u91cf\uff08\u68af\u5ea6\u8303\u6570\u5e73\u65b9\u6216\u6700\u4f18\u6027\u95f4\u9699\uff09\u7684\u77e9\u751f\u6210\u51fd\u6570\uff08MGF\uff09\u4ee5\u53ca\u7528\u6237\u6a21\u578b\u95f4\u5171\u8bc6\u95f4\u9699\u7684MGF\uff0c\u63d0\u4f9b\u4e86\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u5728HP\u610f\u4e49\u4e0b\u7684\u65b9\u5dee\u7f29\u51cf\u6548\u5e94\u65b0\u7ed3\u679c\uff0c\u5e76\u5bf9\u5f3a\u51f8\u6210\u672c\u51fd\u6570\u7ed9\u51fa\u4e86\u66f4\u7cbe\u7ec6\u7684MGF\u8fb9\u754c\u3002", "result": "\u8bc1\u660e\u4e86DSGD\u5728\u8f7b\u5c3e\u566a\u58f0\u4e0b\uff0c\u5728\u975e\u51f8\u548c\u5f3a\u51f8\u6210\u672c\u51fd\u6570\u4e0a\u90fd\u80fd\u5b9e\u73b0HP\u6536\u655b\uff0c\u4e14\u8fbe\u5230\u9636\u6700\u4f18\u6536\u655b\u901f\u7387\uff0c\u540c\u65f6\u83b7\u5f97\u7528\u6237\u6570\u91cf\u7684\u7ebf\u6027\u52a0\u901f\u6548\u679c\uff0c\u5339\u914d\u73b0\u6709\u7684MSE\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u53bb\u4e2d\u5fc3\u5316\u8bbe\u7f6e\u4e2dHP\u6536\u655b\u4e0eMSE\u6536\u655b\u5047\u8bbe\u6761\u4ef6\u7684\u5dee\u8ddd\uff0c\u8bc1\u660e\u4e86DSGD\u5728HP\u610f\u4e49\u4e0a\u4fdd\u6301\u5f3a\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u65b9\u5dee\u7f29\u51cf\u6548\u5e94\u7684\u65b0\u7406\u89e3\u3002"}}
{"id": "2510.06151", "categories": ["cs.LG", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.06151", "abs": "https://arxiv.org/abs/2510.06151", "authors": ["Aju Ani Justus", "Chris Baber"], "title": "LLMs as Policy-Agnostic Teammates: A Case Study in Human Proxy Design for Heterogeneous Agent Teams", "comment": "This is a preprint of a paper presented at the \\textit{European\n  Conference on Artificial Intelligence (ECAI 2025)}. It is made publicly\n  available for the benefit of the research community and should be regarded as\n  a preprint rather than a formally reviewed publication", "summary": "A critical challenge in modelling Heterogeneous-Agent Teams is training\nagents to collaborate with teammates whose policies are inaccessible or\nnon-stationary, such as humans. Traditional approaches rely on expensive\nhuman-in-the-loop data, which limits scalability. We propose using Large\nLanguage Models (LLMs) as policy-agnostic human proxies to generate synthetic\ndata that mimics human decision-making. To evaluate this, we conduct three\nexperiments in a grid-world capture game inspired by Stag Hunt, a game theory\nparadigm that balances risk and reward. In Experiment 1, we compare decisions\nfrom 30 human participants and 2 expert judges with outputs from LLaMA 3.1 and\nMixtral 8x22B models. LLMs, prompted with game-state observations and reward\nstructures, align more closely with experts than participants, demonstrating\nconsistency in applying underlying decision criteria. Experiment 2 modifies\nprompts to induce risk-sensitive strategies (e.g. \"be risk averse\"). LLM\noutputs mirror human participants' variability, shifting between risk-averse\nand risk-seeking behaviours. Finally, Experiment 3 tests LLMs in a dynamic\ngrid-world where the LLM agents generate movement actions. LLMs produce\ntrajectories resembling human participants' paths. While LLMs cannot yet fully\nreplicate human adaptability, their prompt-guided diversity offers a scalable\nfoundation for simulating policy-agnostic teammates.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7b56\u7565\u4e0d\u53ef\u77e5\u7684\u4eba\u7c7b\u4ee3\u7406\uff0c\u751f\u6210\u6a21\u62df\u4eba\u7c7b\u51b3\u7b56\u7684\u5408\u6210\u6570\u636e\uff0c\u4ee5\u89e3\u51b3\u5f02\u6784\u667a\u80fd\u4f53\u56e2\u961f\u4e2d\u4e0e\u7b56\u7565\u4e0d\u53ef\u8bbf\u95ee\u6216\u975e\u5e73\u7a33\u961f\u53cb\u534f\u4f5c\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u53c2\u4e0e\u6570\u636e\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u6a21\u62df\u4eba\u7c7b\u51b3\u7b56\uff0c\u4ee5\u8bad\u7ec3\u667a\u80fd\u4f53\u4e0e\u7b56\u7565\u4e0d\u53ef\u8bbf\u95ee\u7684\u961f\u53cb\u534f\u4f5c\u3002", "method": "\u5728\u53d7Stag Hunt\u542f\u53d1\u7684\u7f51\u683c\u4e16\u754c\u6355\u83b7\u6e38\u620f\u4e2d\u8fdb\u884c\u4e86\u4e09\u4e2a\u5b9e\u9a8c\uff1a\u6bd4\u8f83\u4eba\u7c7b\u53c2\u4e0e\u8005\u3001\u4e13\u5bb6\u4e0eLLM\u7684\u51b3\u7b56\uff1b\u901a\u8fc7\u63d0\u793a\u8bf1\u5bfc\u98ce\u9669\u654f\u611f\u7b56\u7565\uff1b\u5728\u52a8\u6001\u7f51\u683c\u4e16\u754c\u4e2d\u6d4b\u8bd5LLM\u751f\u6210\u79fb\u52a8\u52a8\u4f5c\u3002", "result": "LLM\u51b3\u7b56\u4e0e\u4e13\u5bb6\u66f4\u4e00\u81f4\uff1b\u901a\u8fc7\u63d0\u793a\u53ef\u6a21\u62df\u4eba\u7c7b\u98ce\u9669\u884c\u4e3a\u53d8\u5316\uff1bLLM\u751f\u6210\u7684\u8f68\u8ff9\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u8def\u5f84\u76f8\u4f3c\u3002", "conclusion": "\u867d\u7136LLM\u5c1a\u4e0d\u80fd\u5b8c\u5168\u590d\u5236\u4eba\u7c7b\u9002\u5e94\u6027\uff0c\u4f46\u5176\u63d0\u793a\u5f15\u5bfc\u7684\u591a\u6837\u6027\u4e3a\u6a21\u62df\u7b56\u7565\u4e0d\u53ef\u77e5\u961f\u53cb\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u57fa\u7840\u3002"}}
{"id": "2510.06162", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06162", "abs": "https://arxiv.org/abs/2510.06162", "authors": ["Christopher Kolberg", "Katharina Eggensperger", "Nico Pfeifer"], "title": "TabPFN-Wide: Continued Pre-Training for Extreme Feature Counts", "comment": null, "summary": "Revealing novel insights from the relationship between molecular measurements\nand pathology remains a very impactful application of machine learning in\nbiomedicine. Data in this domain typically contain only a few observations but\nthousands of potentially noisy features, posing challenges for conventional\nmachine learning approaches. While prior-data fitted networks emerge as\nfoundation models for tabular data, they are currently not suited to handle\nlarge feature counts (>500). Although feature reduction enables their\napplication, it hinders feature importance analysis. We propose a strategy that\nextends existing models through continued pre-training on synthetic data\nsampled from a customized prior. The resulting model, TabPFN-Wide, matches or\nexceeds its base model's performance while exhibiting improved robustness to\nnoise. It seamlessly scales beyond 50,000 features, regardless of noise levels,\nwhile maintaining inherent interpretability, which is critical for biomedical\napplications. Our results show that prior-informed adaptation is suitable to\nenhance the capability of foundation models for high-dimensional data. On\nreal-world biomedical datasets many of the most relevant features identified by\nthe model overlap with previous biological findings, while others propose\npotential starting points for future studies.", "AI": {"tldr": "\u63d0\u51faTabPFN-Wide\u6a21\u578b\uff0c\u901a\u8fc7\u7ee7\u7eed\u5728\u5b9a\u5236\u5148\u9a8c\u7684\u5408\u6210\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u6765\u6269\u5c55\u73b0\u6709\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u8d85\u8fc750,000\u4e2a\u7279\u5f81\u7684\u9ad8\u7ef4\u751f\u7269\u533b\u5b66\u6570\u636e\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u533b\u5b66\u9886\u57df\u4e2d\u6570\u636e\u7279\u5f81\u591a\u4f46\u89c2\u6d4b\u5c11\u3001\u7279\u5f81\u566a\u58f0\u5927\u7684\u6311\u6218\uff0c\u73b0\u6709\u57fa\u7840\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u5927\u91cf\u7279\u5f81(>500)\uff0c\u800c\u7279\u5f81\u964d\u7ef4\u53c8\u963b\u788d\u4e86\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u3002", "method": "\u901a\u8fc7\u7ee7\u7eed\u5728\u5b9a\u5236\u5148\u9a8c\u7684\u5408\u6210\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u73b0\u6709\u6a21\u578b\uff0c\u6269\u5c55\u5176\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "TabPFN-Wide\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u5339\u914d\u6216\u8d85\u8fc7\u57fa\u7840\u6a21\u578b\uff0c\u5bf9\u566a\u58f0\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u65e0\u7f1d\u6269\u5c55\u523050,000\u591a\u4e2a\u7279\u5f81\uff0c\u5e76\u5728\u771f\u5b9e\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e2d\u8bc6\u522b\u51fa\u4e0e\u5148\u524d\u751f\u7269\u5b66\u53d1\u73b0\u91cd\u53e0\u7684\u76f8\u5173\u7279\u5f81\u3002", "conclusion": "\u57fa\u4e8e\u5148\u9a8c\u4fe1\u606f\u7684\u9002\u5e94\u662f\u589e\u5f3a\u57fa\u7840\u6a21\u578b\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u80fd\u529b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u751f\u7269\u533b\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u8d77\u70b9\u3002"}}
{"id": "2510.06165", "categories": ["cs.LG", "eess.SP", "math.ST", "stat.ML", "stat.TH", "68Q32, 68T01"], "pdf": "https://arxiv.org/pdf/2510.06165", "abs": "https://arxiv.org/abs/2510.06165", "authors": ["Kurt Butler", "Guanchao Feng", "Petar Djuric"], "title": "Higher-Order Feature Attribution: Bridging Statistics, Explainable AI, and Topological Signal Processing", "comment": "5 pages, 3 figures", "summary": "Feature attributions are post-training analysis methods that assess how\nvarious input features of a machine learning model contribute to an output\nprediction. Their interpretation is straightforward when features act\nindependently, but becomes less direct when the predictive model involves\ninteractions such as multiplicative relationships or joint feature\ncontributions. In this work, we propose a general theory of higher-order\nfeature attribution, which we develop on the foundation of Integrated Gradients\n(IG). This work extends existing frameworks in the literature on explainable\nAI. When using IG as the method of feature attribution, we discover natural\nconnections to statistics and topological signal processing. We provide several\ntheoretical results that establish the theory, and we validate our theory on a\nfew examples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79ef\u5206\u68af\u5ea6\u7684\u9ad8\u9636\u7279\u5f81\u5f52\u56e0\u7406\u8bba\uff0c\u7528\u4e8e\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7279\u5f81\u4ea4\u4e92\u4f5c\u7528\u7684\u8d21\u732e\u3002", "motivation": "\u5f53\u9884\u6d4b\u6a21\u578b\u6d89\u53ca\u7279\u5f81\u4ea4\u4e92\uff08\u5982\u4e58\u6cd5\u5173\u7cfb\u6216\u8054\u5408\u7279\u5f81\u8d21\u732e\uff09\u65f6\uff0c\u4f20\u7edf\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u7684\u89e3\u91ca\u53d8\u5f97\u4e0d\u76f4\u63a5\uff0c\u9700\u8981\u53d1\u5c55\u80fd\u591f\u5904\u7406\u9ad8\u9636\u4ea4\u4e92\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5728\u79ef\u5206\u68af\u5ea6(IG)\u7684\u57fa\u7840\u4e0a\u6784\u5efa\u9ad8\u9636\u7279\u5f81\u5f52\u56e0\u7684\u4e00\u822c\u7406\u8bba\uff0c\u5efa\u7acb\u4e0e\u7edf\u8ba1\u5b66\u548c\u62d3\u6251\u4fe1\u53f7\u5904\u7406\u7684\u81ea\u7136\u8054\u7cfb\u3002", "result": "\u63d0\u4f9b\u4e86\u591a\u4e2a\u7406\u8bba\u7ed3\u679c\u6765\u652f\u6491\u8be5\u7406\u8bba\uff0c\u5e76\u5728\u51e0\u4e2a\u793a\u4f8b\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6269\u5c55\u4e86\u53ef\u89e3\u91caAI\u6587\u732e\u4e2d\u7684\u73b0\u6709\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u590d\u6742\u6a21\u578b\u4e2d\u7684\u7279\u5f81\u4ea4\u4e92\u8d21\u732e\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.06174", "categories": ["cs.LG", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.06174", "abs": "https://arxiv.org/abs/2510.06174", "authors": ["Nathan X. Kodama", "Michael Hinczewski"], "title": "Thermodynamic Performance Limits for Score-Based Diffusion Models", "comment": null, "summary": "We establish a fundamental connection between score-based diffusion models\nand non-equilibrium thermodynamics by deriving performance limits based on\nentropy rates. Our main theoretical contribution is a lower bound on the\nnegative log-likelihood of the data that relates model performance to entropy\nrates of diffusion processes. We numerically validate this bound on a synthetic\ndataset and investigate its tightness. By building a bridge to entropy rates -\nsystem, intrinsic, and exchange entropy - we provide new insights into the\nthermodynamic operation of these models, drawing parallels to Maxwell's demon\nand implications for thermodynamic computing hardware. Our framework connects\ngenerative modeling performance to fundamental physical principles through\nstochastic thermodynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\u4e0e\u975e\u5e73\u8861\u70ed\u529b\u5b66\u4e4b\u95f4\u7684\u57fa\u672c\u8054\u7cfb\uff0c\u901a\u8fc7\u71b5\u7387\u63a8\u5bfc\u6027\u80fd\u6781\u9650\uff0c\u5c06\u751f\u6210\u6a21\u578b\u6027\u80fd\u4e0e\u57fa\u672c\u7269\u7406\u539f\u7406\u8054\u7cfb\u8d77\u6765\u3002", "motivation": "\u5efa\u7acb\u6269\u6563\u6a21\u578b\u4e0e\u70ed\u529b\u5b66\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u901a\u8fc7\u71b5\u7387\u63d0\u4f9b\u6027\u80fd\u6781\u9650\u5206\u6790\uff0c\u4e3a\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u7684\u70ed\u529b\u5b66\u64cd\u4f5c\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "method": "\u63a8\u5bfc\u4e86\u6570\u636e\u8d1f\u5bf9\u6570\u4f3c\u7136\u7684\u4e0b\u754c\uff0c\u5c06\u6a21\u578b\u6027\u80fd\u4e0e\u6269\u6563\u8fc7\u7a0b\u7684\u71b5\u7387\u76f8\u5173\u8054\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6570\u503c\u9a8c\u8bc1\u3002", "result": "\u5efa\u7acb\u4e86\u6027\u80fd\u4e0e\u71b5\u7387\u4e4b\u95f4\u7684\u7406\u8bba\u754c\u9650\uff0c\u9a8c\u8bc1\u4e86\u754c\u9650\u7684\u7d27\u5bc6\u5ea6\uff0c\u5e76\u5c06\u6a21\u578b\u64cd\u4f5c\u4e0e\u9ea6\u514b\u65af\u97e6\u5996\u548c\u70ed\u529b\u5b66\u8ba1\u7b97\u786c\u4ef6\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u968f\u673a\u70ed\u529b\u5b66\u5c06\u751f\u6210\u5efa\u6a21\u6027\u80fd\u4e0e\u57fa\u672c\u7269\u7406\u539f\u7406\u8fde\u63a5\u8d77\u6765\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u70ed\u529b\u5b66\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.06181", "categories": ["cs.LG", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.06181", "abs": "https://arxiv.org/abs/2510.06181", "authors": ["Jinwen Xu", "Qin Lu", "Georgios B. Giannakis"], "title": "Conformalized Gaussian processes for online uncertainty quantification over graphs", "comment": null, "summary": "Uncertainty quantification (UQ) over graphs arises in a number of\nsafety-critical applications in network science. The Gaussian process (GP), as\na classical Bayesian framework for UQ, has been developed to handle\ngraph-structured data by devising topology-aware kernel functions. However,\nsuch GP-based approaches are limited not only by the prohibitive computational\ncomplexity, but also the strict modeling assumptions that might yield poor\ncoverage, especially with labels arriving on the fly. To effect scalability, we\ndevise a novel graph-aware parametric GP model by leveraging the random feature\n(RF)-based kernel approximation, which is amenable to efficient recursive\nBayesian model updates. To further allow for adaptivity, an ensemble of\ngraph-aware RF-based scalable GPs have been leveraged, with per-GP weight\nadapted to data arriving incrementally. To ensure valid coverage with\nrobustness to model mis-specification, we wed the GP-based set predictors with\nthe online conformal prediction framework, which post-processes the prediction\nsets using adaptive thresholds. Experimental results the proposed method yields\nimproved coverage and efficient prediction sets over existing baselines by\nadaptively ensembling the GP models and setting the key threshold parameters in\nCP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u7279\u5f81\u548c\u56fe\u611f\u77e5\u7684\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\uff0c\u901a\u8fc7\u96c6\u6210\u5b66\u4e60\u548c\u5728\u7ebf\u5171\u5f62\u9884\u6d4b\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5bf9\u56fe\u7ed3\u6784\u6570\u636e\u7684\u9ad8\u6548\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u63d0\u5347\u4e86\u8986\u76d6\u7387\u548c\u9884\u6d4b\u96c6\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u9ad8\u65af\u8fc7\u7a0b\u65b9\u6cd5\u5728\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u65f6\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u5efa\u6a21\u5047\u8bbe\u4e25\u683c\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6807\u7b7e\u52a8\u6001\u5230\u8fbe\u7684\u60c5\u51b5\u4e0b\u8986\u76d6\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u4e14\u81ea\u9002\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u968f\u673a\u7279\u5f81\u8fdb\u884c\u6838\u8fd1\u4f3c\u6784\u5efa\u56fe\u611f\u77e5\u53c2\u6570\u5316\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\uff0c\u91c7\u7528\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u81ea\u9002\u5e94\u8c03\u6574\u5404GP\u6743\u91cd\uff0c\u5e76\u7ed3\u5408\u5728\u7ebf\u5171\u5f62\u9884\u6d4b\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u9608\u503c\u5904\u7406\u9884\u6d4b\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94\u96c6\u6210GP\u6a21\u578b\u548c\u8bbe\u7f6e\u5171\u5f62\u9884\u6d4b\u5173\u952e\u9608\u503c\u53c2\u6570\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u4e86\u66f4\u597d\u7684\u8986\u76d6\u7387\u548c\u66f4\u9ad8\u6548\u7684\u9884\u6d4b\u96c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u7ed3\u6784\u6570\u636e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u8986\u76d6\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.06190", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06190", "abs": "https://arxiv.org/abs/2510.06190", "authors": ["Chenxiao Yang", "Cai Zhou", "David Wipf", "Zhiyuan Li"], "title": "On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond", "comment": null, "summary": "This paper formally studies generation processes, including auto-regressive\nnext-token prediction and masked diffusion, that abstract beyond architectural\nspecifics. At this level of abstraction, we quantify their benefits and\nlimitations through measurable criteria such as computational hardness and\nlearnability. In particular, we demonstrate that allowing generation to proceed\nbeyond autoregression and current masked diffusion, with capabilities to\nrewrite and length-variable edit, can bring significant theoretical and\nempirical advantages, with important implications for frontier LLMs that aspire\nto tackle increasingly hard problems and work universally across domains beyond\nnatural language, such as coding and science.", "AI": {"tldr": "\u672c\u6587\u4ece\u5f62\u5f0f\u5316\u89d2\u5ea6\u7814\u7a76\u751f\u6210\u8fc7\u7a0b\uff0c\u5305\u62ec\u81ea\u56de\u5f52\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u548c\u63a9\u7801\u6269\u6563\uff0c\u91cf\u5316\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u53ef\u5b66\u4e60\u6027\uff0c\u8bc1\u660e\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u7684\u751f\u6210\u80fd\u529b\u80fd\u5e26\u6765\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u8fc7\u7a0b\u7684\u62bd\u8c61\u7406\u8bba\u6846\u67b6\uff0c\u8d85\u8d8a\u5177\u4f53\u67b6\u6784\u7ec6\u8282\uff0c\u91cf\u5316\u5206\u6790\u4e0d\u540c\u751f\u6210\u65b9\u6cd5\u7684\u7406\u8bba\u5c40\u9650\u6027\u548c\u4f18\u52bf\u3002", "method": "\u5f62\u5f0f\u5316\u5206\u6790\u81ea\u56de\u5f52\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u548c\u63a9\u7801\u6269\u6563\u751f\u6210\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u53ef\u5b66\u4e60\u6027\u7b49\u53ef\u6d4b\u91cf\u6807\u51c6\u8fdb\u884c\u91cf\u5316\u8bc4\u4f30\u3002", "result": "\u8bc1\u660e\u5141\u8bb8\u751f\u6210\u8fc7\u7a0b\u8d85\u8d8a\u81ea\u56de\u5f52\u548c\u5f53\u524d\u63a9\u7801\u6269\u6563\uff0c\u5177\u5907\u91cd\u5199\u548c\u957f\u5ea6\u53ef\u53d8\u7f16\u8f91\u80fd\u529b\uff0c\u80fd\u5e26\u6765\u663e\u8457\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u4f18\u52bf\u3002", "conclusion": "\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u8d85\u8d8a\u4f20\u7edf\u751f\u6210\u65b9\u6cd5\uff0c\u5177\u5907\u66f4\u7075\u6d3b\u7684\u751f\u6210\u80fd\u529b\uff0c\u4ee5\u5e94\u5bf9\u65e5\u76ca\u590d\u6742\u7684\u95ee\u9898\u5e76\u6269\u5c55\u5230\u7f16\u7a0b\u548c\u79d1\u5b66\u7b49\u81ea\u7136\u8bed\u8a00\u4e4b\u5916\u7684\u9886\u57df\u3002"}}
{"id": "2510.06203", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06203", "abs": "https://arxiv.org/abs/2510.06203", "authors": ["Seungeun Rho", "Aaron Trinh", "Danfei Xu", "Sehoon Ha"], "title": "Reference Grounded Skill Discovery", "comment": null, "summary": "Scaling unsupervised skill discovery algorithms to high-DoF agents remains\nchallenging. As dimensionality increases, the exploration space grows\nexponentially, while the manifold of meaningful skills remains limited.\nTherefore, semantic meaningfulness becomes essential to effectively guide\nexploration in high-dimensional spaces. In this work, we present\nReference-Grounded Skill Discovery (RGSD), a novel algorithm that grounds skill\ndiscovery in a semantically meaningful latent space using reference data. RGSD\nfirst performs contrastive pretraining to embed motions on a unit hypersphere,\nclustering each reference trajectory into a distinct direction. This grounding\nenables skill discovery to simultaneously involve both imitation of reference\nbehaviors and the discovery of semantically related diverse behaviors. On a\nsimulated SMPL humanoid with 359-D observations and 69-D actions, RGSD learns\nstructured skills including walking, running, punching, and side stepping, and\nalso discovers related novel behaviors. In downstream control tasks, RGSD\noutperforms imitation-based skill acquisition baselines. Our results suggest\nthat lightweight reference-guided grounding offers a practical path to\ndiscovering semantically rich and structured skills in high-DoF systems.", "AI": {"tldr": "RGSD\u7b97\u6cd5\u901a\u8fc7\u53c2\u8003\u6570\u636e\u5728\u8bed\u4e49\u6f5c\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u6280\u80fd\u53d1\u73b0\uff0c\u5728\u9ad8\u7ef4\u7cfb\u7edf\u4e2d\u540c\u65f6\u6a21\u4eff\u53c2\u8003\u884c\u4e3a\u5e76\u53d1\u73b0\u8bed\u4e49\u76f8\u5173\u7684\u591a\u6837\u5316\u884c\u4e3a", "motivation": "\u5c06\u65e0\u76d1\u7763\u6280\u80fd\u53d1\u73b0\u6269\u5c55\u5230\u9ad8\u81ea\u7531\u5ea6\u7cfb\u7edf\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u63a2\u7d22\u7a7a\u95f4\u5448\u6307\u6570\u589e\u957f\u800c\u610f\u4e49\u6280\u80fd\u6d41\u5f62\u6709\u9650\uff0c\u9700\u8981\u8bed\u4e49\u610f\u4e49\u6765\u6709\u6548\u6307\u5bfc\u9ad8\u7ef4\u7a7a\u95f4\u63a2\u7d22", "method": "RGSD\u9996\u5148\u901a\u8fc7\u5bf9\u6bd4\u9884\u8bad\u7ec3\u5c06\u52a8\u4f5c\u5d4c\u5165\u5355\u4f4d\u8d85\u7403\u9762\uff0c\u5c06\u6bcf\u4e2a\u53c2\u8003\u8f68\u8ff9\u805a\u7c7b\u4e3a\u4e0d\u540c\u65b9\u5411\uff0c\u4f7f\u6280\u80fd\u53d1\u73b0\u80fd\u540c\u65f6\u6a21\u4eff\u53c2\u8003\u884c\u4e3a\u5e76\u53d1\u73b0\u8bed\u4e49\u76f8\u5173\u7684\u591a\u6837\u5316\u884c\u4e3a", "result": "\u5728359\u7ef4\u89c2\u6d4b\u548c69\u7ef4\u52a8\u4f5c\u7684SMPL\u4eba\u5f62\u6a21\u62df\u5668\u4e2d\uff0cRGSD\u5b66\u4e60\u4e86\u5305\u62ec\u884c\u8d70\u3001\u5954\u8dd1\u3001\u51fa\u62f3\u3001\u4fa7\u6b65\u7b49\u7ed3\u6784\u5316\u6280\u80fd\uff0c\u5e76\u53d1\u73b0\u4e86\u76f8\u5173\u7684\u65b0\u884c\u4e3a\uff0c\u5728\u4e0b\u6e38\u63a7\u5236\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u4e8e\u6a21\u4eff\u7684\u6280\u80fd\u83b7\u53d6\u57fa\u7ebf", "conclusion": "\u8f7b\u91cf\u7ea7\u53c2\u8003\u5f15\u5bfc\u7684grounding\u4e3a\u5728\u9ad8\u81ea\u7531\u5ea6\u7cfb\u7edf\u4e2d\u53d1\u73b0\u8bed\u4e49\u4e30\u5bcc\u548c\u7ed3\u6784\u5316\u7684\u6280\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84"}}
{"id": "2510.06213", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06213", "abs": "https://arxiv.org/abs/2510.06213", "authors": ["Albert Catalan-Tatjer", "Niccol\u00f2 Ajroldi", "Jonas Geiping"], "title": "Training Dynamics Impact Post-Training Quantization Robustness", "comment": null, "summary": "While post-training quantization is widely adopted for efficient deployment\nof large language models, the mechanisms underlying quantization robustness\nremain unclear. We conduct a comprehensive analysis of quantization degradation\nacross open-source language model training trajectories up to 32B parameters\nand 15T training tokens to accurately assess the relationship between training\ndynamics and quantization performance. Our key finding is that quantization\nerrors in large-scale training runs are driven by a complex interplay between\nlearning rate and other training hyperparameters. Specifically, once learning\nrates decay, validation loss and quantization error diverge, largely\nindependent of training data scale. To investigate interventions on the\ntraining dynamics and identify specific configurations that can modulate\nquantization robustness favorably, we train our own models in controlled\nexperiments up to 100B tokens. Our results challenge the assumption that\nincreasing dataset scale inherently compromises quantization effectiveness,\ndemonstrating instead that strategic training hyperparameter interventions can\nimprove quantization quality at scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8f68\u8ff9\uff0c\u53d1\u73b0\u91cf\u5316\u8bef\u5dee\u4e3b\u8981\u7531\u5b66\u4e60\u7387\u4e0e\u5176\u4ed6\u8bad\u7ec3\u8d85\u53c2\u6570\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u9a71\u52a8\uff0c\u800c\u975e\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u3002\u7814\u7a76\u8868\u660e\u901a\u8fc7\u7b56\u7565\u6027\u8c03\u6574\u8bad\u7ec3\u8d85\u53c2\u6570\u53ef\u4ee5\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u4e2d\u6539\u5584\u91cf\u5316\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1\u540e\u8bad\u7ec3\u91cf\u5316\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\uff0c\u4f46\u91cf\u5316\u9c81\u68d2\u6027\u7684\u5185\u5728\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u65e8\u5728\u51c6\u786e\u8bc4\u4f30\u8bad\u7ec3\u52a8\u6001\u4e0e\u91cf\u5316\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5bf9\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8f68\u8ff9\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff08\u6700\u592732B\u53c2\u6570\u548c15T\u8bad\u7ec3token\uff09\uff0c\u5e76\u5728\u53d7\u63a7\u5b9e\u9a8c\u4e2d\u8bad\u7ec3\u81ea\u5df1\u7684\u6a21\u578b\uff08\u6700\u591a100B token\uff09\uff0c\u7814\u7a76\u8bad\u7ec3\u52a8\u6001\u5e72\u9884\u63aa\u65bd\u3002", "result": "\u53d1\u73b0\u4e00\u65e6\u5b66\u4e60\u7387\u8870\u51cf\uff0c\u9a8c\u8bc1\u635f\u5931\u548c\u91cf\u5316\u8bef\u5dee\u5c31\u4f1a\u53d1\u6563\uff0c\u8fd9\u4e0e\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u57fa\u672c\u65e0\u5173\u3002\u6311\u6218\u4e86\u589e\u52a0\u6570\u636e\u96c6\u89c4\u6a21\u4f1a\u635f\u5bb3\u91cf\u5316\u6548\u679c\u7684\u5047\u8bbe\u3002", "conclusion": "\u7b56\u7565\u6027\u7684\u8bad\u7ec3\u8d85\u53c2\u6570\u5e72\u9884\u53ef\u4ee5\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u4e2d\u6539\u5584\u91cf\u5316\u8d28\u91cf\uff0c\u91cf\u5316\u8bef\u5dee\u4e3b\u8981\u7531\u5b66\u4e60\u7387\u4e0e\u5176\u4ed6\u8d85\u53c2\u6570\u7684\u76f8\u4e92\u4f5c\u7528\u9a71\u52a8\uff0c\u800c\u975e\u5355\u7eaf\u7684\u6570\u636e\u89c4\u6a21\u3002"}}
{"id": "2510.06214", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06214", "abs": "https://arxiv.org/abs/2510.06214", "authors": ["Mingkang Zhu", "Xi Chen", "Bei Yu", "Hengshuang Zhao", "Jiaya Jia"], "title": "Stratified GRPO: Handling Structural Heterogeneity in Reinforcement Learning of LLM Search Agents", "comment": null, "summary": "Large language model (LLM) agents increasingly rely on external tools such as\nsearch engines to solve complex, multi-step problems, and reinforcement\nlearning (RL) has become a key paradigm for training them. However, the\ntrajectories of search agents are structurally heterogeneous, where variations\nin the number, placement, and outcomes of search calls lead to fundamentally\ndifferent answer directions and reward distributions. Standard policy gradient\nmethods, which use a single global baseline, suffer from what we identify and\nformalize as cross-stratum bias-an \"apples-to-oranges\" comparison of\nheterogeneous trajectories. This cross-stratum bias distorts credit assignment\nand hinders exploration of complex, multi-step search strategies. To address\nthis, we propose Stratified GRPO, whose central component, Stratified Advantage\nNormalization (SAN), partitions trajectories into homogeneous strata based on\ntheir structural properties and computes advantages locally within each\nstratum. This ensures that trajectories are evaluated only against their true\npeers. Our analysis proves that SAN eliminates cross-stratum bias, yields\nconditionally unbiased unit-variance estimates inside each stratum, and retains\nthe global unbiasedness and unit-variance properties enjoyed by standard\nnormalization, resulting in a more pure and scale-stable learning signal. To\nimprove practical stability under finite-sample regimes, we further linearly\nblend SAN with the global estimator. Extensive experiments on diverse\nsingle-hop and multi-hop question-answering benchmarks demonstrate that\nStratified GRPO consistently and substantially outperforms GRPO by up to 11.3\npoints, achieving higher training rewards, greater training stability, and more\neffective search policies. These results establish stratification as a\nprincipled remedy for structural heterogeneity in RL for LLM search agents.", "AI": {"tldr": "\u63d0\u51faStratified GRPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u4f18\u52bf\u5f52\u4e00\u5316\u89e3\u51b3LLM\u641c\u7d22\u667a\u80fd\u4f53\u4e2d\u7684\u8de8\u5c42\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u591a\u6b65\u641c\u7d22\u7b56\u7565\u7684\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u5728\u89e3\u51b3\u590d\u6742\u591a\u6b65\u95ee\u9898\u65f6\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\uff0c\u4f46\u641c\u7d22\u8f68\u8ff9\u5b58\u5728\u7ed3\u6784\u6027\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u6807\u51c6\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u51fa\u73b0\u8de8\u5c42\u504f\u5dee\uff0c\u963b\u788d\u590d\u6742\u641c\u7d22\u7b56\u7565\u7684\u63a2\u7d22\u3002", "method": "\u63d0\u51faStratified GRPO\u65b9\u6cd5\uff0c\u6838\u5fc3\u662f\u5206\u5c42\u4f18\u52bf\u5f52\u4e00\u5316(SAN)\uff0c\u6839\u636e\u8f68\u8ff9\u7ed3\u6784\u7279\u6027\u5c06\u8f68\u8ff9\u5212\u5206\u4e3a\u540c\u8d28\u5c42\uff0c\u5728\u6bcf\u5c42\u5185\u5c40\u90e8\u8ba1\u7b97\u4f18\u52bf\u503c\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u6df7\u5408SAN\u4e0e\u5168\u5c40\u4f30\u8ba1\u5668\u63d0\u9ad8\u5b9e\u9645\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u591a\u79cd\u5355\u8df3\u548c\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cStratified GRPO\u6bd4GRPO\u63d0\u5347\u9ad8\u8fbe11.3\u5206\uff0c\u83b7\u5f97\u66f4\u9ad8\u7684\u8bad\u7ec3\u5956\u52b1\u3001\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u66f4\u6709\u6548\u7684\u641c\u7d22\u7b56\u7565\u3002", "conclusion": "\u5206\u5c42\u65b9\u6cd5\u4e3aLLM\u641c\u7d22\u667a\u80fd\u4f53\u4e2d\u7684\u7ed3\u6784\u6027\u5f02\u8d28\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
